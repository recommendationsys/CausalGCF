2023-05-13 14:40:30.683: my pid: 3280
2023-05-13 14:40:30.683: model: model.general_recommender.SGL
2023-05-13 14:40:30.683: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:40:30.683: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:49:58.416: my pid: 2932
2023-05-13 14:49:58.416: model: model.general_recommender.SGL
2023-05-13 14:49:58.416: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:49:58.416: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:51:09.790: my pid: 11500
2023-05-13 14:51:09.790: model: model.general_recommender.SGL
2023-05-13 14:51:09.790: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:51:09.790: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:51:36.909: my pid: 9568
2023-05-13 14:51:36.909: model: model.general_recommender.SGL
2023-05-13 14:51:36.909: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:51:36.909: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:52:20.886: my pid: 4104
2023-05-13 14:52:20.887: model: model.general_recommender.SGL
2023-05-13 14:52:20.887: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:52:20.887: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:52:49.173: my pid: 9376
2023-05-13 14:52:49.173: model: model.general_recommender.SGL
2023-05-13 14:52:49.173: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:52:49.173: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:53:37.636: my pid: 6084
2023-05-13 14:53:37.636: model: model.general_recommender.SGL
2023-05-13 14:53:37.636: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:53:37.636: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:54:45.811: my pid: 9208
2023-05-13 14:54:45.811: model: model.general_recommender.SGL
2023-05-13 14:54:45.811: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:54:45.811: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:55:30.740: my pid: 7156
2023-05-13 14:55:30.740: model: model.general_recommender.SGL
2023-05-13 14:55:30.740: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:55:30.741: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:55:34.098: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 14:55:42.488: [iter 1 : loss : 0.7721 = 0.6930 + 0.0791 + 0.0000, time: 8.390557]
2023-05-13 14:55:42.668: epoch 1:	0.00177110  	0.01293638  	0.00680118  
2023-05-13 14:55:42.668: Find a better model.
2023-05-13 14:57:16.592: my pid: 12324
2023-05-13 14:57:16.592: model: model.general_recommender.SGL
2023-05-13 14:57:16.592: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:57:16.592: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:57:19.666: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 14:57:27.594: [iter 1 : loss : 0.7721 = 0.6930 + 0.0791 + 0.0000, time: 7.927750]
2023-05-13 14:57:27.751: epoch 1:	0.00177110  	0.01293638  	0.00680118  
2023-05-13 14:57:27.751: Find a better model.
2023-05-13 14:58:00.802: my pid: 8700
2023-05-13 14:58:00.803: model: model.general_recommender.SGL
2023-05-13 14:58:00.803: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 14:58:00.803: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 14:58:36.989: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:01:37.265: my pid: 10676
2023-05-13 15:01:37.265: model: model.general_recommender.SGL
2023-05-13 15:01:37.265: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 15:01:37.265: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 15:01:40.370: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:01:48.307: [iter 1 : loss : 0.7721 = 0.6930 + 0.0791 + 0.0000, time: 7.937919]
2023-05-13 15:01:48.463: epoch 1:	0.00177110  	0.01293638  	0.00680118  
2023-05-13 15:01:48.463: Find a better model.
2023-05-13 15:01:56.515: [iter 2 : loss : 0.7718 = 0.6928 + 0.0790 + 0.0000, time: 8.049466]
2023-05-13 15:01:56.723: epoch 2:	0.00343634  	0.02524448  	0.01251210  
2023-05-13 15:01:56.723: Find a better model.
2023-05-13 15:02:04.681: [iter 3 : loss : 0.7716 = 0.6924 + 0.0791 + 0.0000, time: 7.957029]
2023-05-13 15:02:04.864: epoch 3:	0.00626583  	0.04548822  	0.02187729  
2023-05-13 15:02:04.864: Find a better model.
2023-05-13 15:02:12.667: [iter 4 : loss : 0.7710 = 0.6917 + 0.0793 + 0.0000, time: 7.802419]
2023-05-13 15:02:12.825: epoch 4:	0.00940581  	0.06857740  	0.03272893  
2023-05-13 15:02:12.825: Find a better model.
2023-05-13 15:02:20.475: [iter 5 : loss : 0.7698 = 0.6902 + 0.0796 + 0.0000, time: 7.648180]
2023-05-13 15:02:20.637: epoch 5:	0.01330804  	0.09725621  	0.04583875  
2023-05-13 15:02:20.637: Find a better model.
2023-05-13 15:02:28.056: [iter 6 : loss : 0.7669 = 0.6868 + 0.0801 + 0.0000, time: 7.417424]
2023-05-13 15:02:28.220: epoch 6:	0.01643402  	0.11974374  	0.05805308  
2023-05-13 15:02:28.220: Find a better model.
2023-05-13 15:02:35.464: [iter 7 : loss : 0.7591 = 0.6779 + 0.0811 + 0.0000, time: 7.243430]
2023-05-13 15:02:35.625: epoch 7:	0.01820518  	0.13231736  	0.06569976  
2023-05-13 15:02:35.625: Find a better model.
2023-05-13 15:02:42.832: [iter 8 : loss : 0.7401 = 0.6566 + 0.0834 + 0.0001, time: 7.206097]
2023-05-13 15:02:42.975: epoch 8:	0.01888260  	0.13849165  	0.06920413  
2023-05-13 15:02:42.975: Find a better model.
2023-05-13 15:02:50.067: [iter 9 : loss : 0.6995 = 0.6117 + 0.0877 + 0.0002, time: 7.091517]
2023-05-13 15:02:50.210: epoch 9:	0.01862857  	0.13818556  	0.06875501  
2023-05-13 15:02:57.270: [iter 10 : loss : 0.6344 = 0.5410 + 0.0931 + 0.0003, time: 7.057253]
2023-05-13 15:02:57.411: epoch 10:	0.01850861  	0.13755853  	0.06820644  
2023-05-13 15:03:04.461: [iter 11 : loss : 0.5595 = 0.4613 + 0.0977 + 0.0004, time: 7.047958]
2023-05-13 15:03:04.619: epoch 11:	0.01840276  	0.13673262  	0.06809896  
2023-05-13 15:03:11.732: [iter 12 : loss : 0.4944 = 0.3932 + 0.1006 + 0.0006, time: 7.112553]
2023-05-13 15:03:11.891: epoch 12:	0.01833925  	0.13565475  	0.06826816  
2023-05-13 15:03:19.096: [iter 13 : loss : 0.4471 = 0.3442 + 0.1022 + 0.0007, time: 7.202579]
2023-05-13 15:03:19.250: epoch 13:	0.01848744  	0.13683373  	0.06891564  
2023-05-13 15:03:26.471: [iter 14 : loss : 0.4111 = 0.3073 + 0.1029 + 0.0009, time: 7.220004]
2023-05-13 15:03:26.623: epoch 14:	0.01871325  	0.13860206  	0.06986226  
2023-05-13 15:03:26.624: Find a better model.
2023-05-13 15:03:34.116: [iter 15 : loss : 0.3858 = 0.2816 + 0.1032 + 0.0010, time: 7.491061]
2023-05-13 15:03:34.264: epoch 15:	0.01891788  	0.14002945  	0.07059259  
2023-05-13 15:03:34.264: Find a better model.
2023-05-13 15:03:41.654: [iter 16 : loss : 0.3644 = 0.2602 + 0.1031 + 0.0011, time: 7.389209]
2023-05-13 15:03:41.812: epoch 16:	0.01912958  	0.14153621  	0.07143576  
2023-05-13 15:03:41.812: Find a better model.
2023-05-13 15:03:49.337: [iter 17 : loss : 0.3485 = 0.2444 + 0.1029 + 0.0012, time: 7.524112]
2023-05-13 15:03:49.481: epoch 17:	0.01927072  	0.14249633  	0.07204870  
2023-05-13 15:03:49.481: Find a better model.
2023-05-13 15:03:56.854: [iter 18 : loss : 0.3338 = 0.2298 + 0.1027 + 0.0013, time: 7.369687]
2023-05-13 15:03:57.003: epoch 18:	0.01951770  	0.14387684  	0.07297262  
2023-05-13 15:03:57.003: Find a better model.
2023-05-13 15:04:04.470: [iter 19 : loss : 0.3199 = 0.2161 + 0.1023 + 0.0014, time: 7.466698]
2023-05-13 15:04:04.616: epoch 19:	0.01968705  	0.14525598  	0.07385880  
2023-05-13 15:04:04.617: Find a better model.
2023-05-13 15:04:11.893: [iter 20 : loss : 0.3104 = 0.2070 + 0.1019 + 0.0015, time: 7.272758]
2023-05-13 15:04:12.037: epoch 20:	0.01984936  	0.14641394  	0.07457008  
2023-05-13 15:04:12.037: Find a better model.
2023-05-13 15:04:19.239: [iter 21 : loss : 0.3010 = 0.1980 + 0.1015 + 0.0016, time: 7.199091]
2023-05-13 15:04:19.396: epoch 21:	0.02002578  	0.14823462  	0.07549863  
2023-05-13 15:04:19.396: Find a better model.
2023-05-13 15:04:26.633: [iter 22 : loss : 0.2928 = 0.1900 + 0.1011 + 0.0017, time: 7.236064]
2023-05-13 15:04:26.792: epoch 22:	0.02033626  	0.15009263  	0.07655784  
2023-05-13 15:04:26.792: Find a better model.
2023-05-13 15:04:34.028: [iter 23 : loss : 0.2846 = 0.1822 + 0.1006 + 0.0017, time: 7.234159]
2023-05-13 15:04:34.184: epoch 23:	0.02054795  	0.15174960  	0.07764050  
2023-05-13 15:04:34.185: Find a better model.
2023-05-13 15:04:41.425: [iter 24 : loss : 0.2782 = 0.1763 + 0.1002 + 0.0018, time: 7.238788]
2023-05-13 15:04:41.591: epoch 24:	0.02073142  	0.15274154  	0.07832255  
2023-05-13 15:04:41.591: Find a better model.
2023-05-13 15:04:48.820: [iter 25 : loss : 0.2715 = 0.1699 + 0.0997 + 0.0019, time: 7.228310]
2023-05-13 15:04:48.976: epoch 25:	0.02091489  	0.15450259  	0.07901435  
2023-05-13 15:04:48.976: Find a better model.
2023-05-13 15:04:56.203: [iter 26 : loss : 0.2681 = 0.1668 + 0.0994 + 0.0019, time: 7.223956]
2023-05-13 15:04:56.363: epoch 26:	0.02106307  	0.15587142  	0.07961578  
2023-05-13 15:04:56.363: Find a better model.
2023-05-13 15:05:03.600: [iter 27 : loss : 0.2604 = 0.1595 + 0.0989 + 0.0020, time: 7.235635]
2023-05-13 15:05:03.758: epoch 27:	0.02116893  	0.15655659  	0.08033238  
2023-05-13 15:05:03.758: Find a better model.
2023-05-13 15:05:11.028: [iter 28 : loss : 0.2555 = 0.1548 + 0.0985 + 0.0021, time: 7.269065]
2023-05-13 15:05:11.185: epoch 28:	0.02143002  	0.15848036  	0.08124474  
2023-05-13 15:05:11.186: Find a better model.
2023-05-13 15:05:18.414: [iter 29 : loss : 0.2510 = 0.1507 + 0.0981 + 0.0021, time: 7.227413]
2023-05-13 15:05:18.557: epoch 29:	0.02158526  	0.15961543  	0.08192401  
2023-05-13 15:05:18.557: Find a better model.
2023-05-13 15:05:25.793: [iter 30 : loss : 0.2446 = 0.1446 + 0.0978 + 0.0022, time: 7.233423]
2023-05-13 15:05:25.949: epoch 30:	0.02178284  	0.16152227  	0.08272989  
2023-05-13 15:05:25.950: Find a better model.
2023-05-13 15:05:33.206: [iter 31 : loss : 0.2410 = 0.1414 + 0.0974 + 0.0023, time: 7.254095]
2023-05-13 15:05:33.362: epoch 31:	0.02193809  	0.16226509  	0.08338125  
2023-05-13 15:05:33.362: Find a better model.
2023-05-13 15:05:40.807: [iter 32 : loss : 0.2353 = 0.1361 + 0.0970 + 0.0023, time: 7.444667]
2023-05-13 15:05:40.963: epoch 32:	0.02205804  	0.16330212  	0.08423670  
2023-05-13 15:05:40.963: Find a better model.
2023-05-13 15:05:48.151: [iter 33 : loss : 0.2327 = 0.1337 + 0.0966 + 0.0024, time: 7.186053]
2023-05-13 15:05:48.307: epoch 33:	0.02224857  	0.16487962  	0.08484133  
2023-05-13 15:05:48.308: Find a better model.
2023-05-13 15:05:55.704: [iter 34 : loss : 0.2285 = 0.1298 + 0.0963 + 0.0024, time: 7.394713]
2023-05-13 15:05:55.855: epoch 34:	0.02236853  	0.16566469  	0.08545007  
2023-05-13 15:05:55.855: Find a better model.
2023-05-13 15:06:03.322: [iter 35 : loss : 0.2252 = 0.1268 + 0.0960 + 0.0025, time: 7.465534]
2023-05-13 15:06:03.465: epoch 35:	0.02249554  	0.16617414  	0.08583707  
2023-05-13 15:06:03.465: Find a better model.
2023-05-13 15:06:11.068: [iter 36 : loss : 0.2217 = 0.1235 + 0.0957 + 0.0025, time: 7.601741]
2023-05-13 15:06:11.210: epoch 36:	0.02260139  	0.16735579  	0.08659349  
2023-05-13 15:06:11.210: Find a better model.
2023-05-13 15:06:18.595: [iter 37 : loss : 0.2180 = 0.1201 + 0.0953 + 0.0026, time: 7.383850]
2023-05-13 15:06:18.754: epoch 37:	0.02268607  	0.16790484  	0.08704009  
2023-05-13 15:06:18.754: Find a better model.
2023-05-13 15:06:25.986: [iter 38 : loss : 0.2162 = 0.1185 + 0.0950 + 0.0027, time: 7.230360]
2023-05-13 15:06:26.141: epoch 38:	0.02286954  	0.16911028  	0.08788450  
2023-05-13 15:06:26.141: Find a better model.
2023-05-13 15:06:33.591: [iter 39 : loss : 0.2118 = 0.1143 + 0.0947 + 0.0027, time: 7.448806]
2023-05-13 15:06:33.737: epoch 39:	0.02310945  	0.17086914  	0.08876470  
2023-05-13 15:06:33.737: Find a better model.
2023-05-13 15:06:40.982: [iter 40 : loss : 0.2087 = 0.1114 + 0.0945 + 0.0028, time: 7.243196]
2023-05-13 15:06:41.135: epoch 40:	0.02329999  	0.17224327  	0.08922553  
2023-05-13 15:06:41.135: Find a better model.
2023-05-13 15:06:48.391: [iter 41 : loss : 0.2070 = 0.1100 + 0.0942 + 0.0028, time: 7.255492]
2023-05-13 15:06:48.546: epoch 41:	0.02341289  	0.17275962  	0.08988509  
2023-05-13 15:06:48.546: Find a better model.
2023-05-13 15:06:55.568: [iter 42 : loss : 0.2048 = 0.1081 + 0.0939 + 0.0029, time: 7.019966]
2023-05-13 15:06:55.714: epoch 42:	0.02342700  	0.17327657  	0.09047518  
2023-05-13 15:06:55.714: Find a better model.
2023-05-13 15:07:02.990: [iter 43 : loss : 0.2008 = 0.1043 + 0.0936 + 0.0029, time: 7.274728]
2023-05-13 15:07:03.137: epoch 43:	0.02346934  	0.17321089  	0.09089985  
2023-05-13 15:07:10.387: [iter 44 : loss : 0.1973 = 0.1010 + 0.0933 + 0.0030, time: 7.248983]
2023-05-13 15:07:10.541: epoch 44:	0.02353284  	0.17365111  	0.09138336  
2023-05-13 15:07:10.541: Find a better model.
2023-05-13 15:07:17.775: [iter 45 : loss : 0.1954 = 0.0993 + 0.0931 + 0.0030, time: 7.232834]
2023-05-13 15:07:17.917: epoch 45:	0.02363163  	0.17404135  	0.09195618  
2023-05-13 15:07:17.918: Find a better model.
2023-05-13 15:07:25.129: [iter 46 : loss : 0.1928 = 0.0970 + 0.0928 + 0.0031, time: 7.210319]
2023-05-13 15:07:25.272: epoch 46:	0.02368103  	0.17460918  	0.09231870  
2023-05-13 15:07:25.272: Find a better model.
2023-05-13 15:07:32.556: [iter 47 : loss : 0.1921 = 0.0963 + 0.0927 + 0.0031, time: 7.283224]
2023-05-13 15:07:32.709: epoch 47:	0.02382922  	0.17610575  	0.09310620  
2023-05-13 15:07:32.710: Find a better model.
2023-05-13 15:07:39.958: [iter 48 : loss : 0.1884 = 0.0928 + 0.0924 + 0.0032, time: 7.246001]
2023-05-13 15:07:40.115: epoch 48:	0.02386450  	0.17612512  	0.09332048  
2023-05-13 15:07:40.115: Find a better model.
2023-05-13 15:07:47.365: [iter 49 : loss : 0.1850 = 0.0895 + 0.0922 + 0.0032, time: 7.248997]
2023-05-13 15:07:47.520: epoch 49:	0.02395623  	0.17695153  	0.09403723  
2023-05-13 15:07:47.520: Find a better model.
2023-05-13 15:07:54.754: [iter 50 : loss : 0.1844 = 0.0893 + 0.0919 + 0.0033, time: 7.232272]
2023-05-13 15:07:54.909: epoch 50:	0.02402680  	0.17761101  	0.09434999  
2023-05-13 15:07:54.909: Find a better model.
2023-05-13 15:08:02.159: [iter 51 : loss : 0.1815 = 0.0864 + 0.0918 + 0.0033, time: 7.248130]
2023-05-13 15:08:02.314: epoch 51:	0.02421732  	0.17850697  	0.09495286  
2023-05-13 15:08:02.314: Find a better model.
2023-05-13 15:08:09.548: [iter 52 : loss : 0.1813 = 0.0864 + 0.0916 + 0.0034, time: 7.231403]
2023-05-13 15:08:09.689: epoch 52:	0.02424554  	0.17914815  	0.09529120  
2023-05-13 15:08:09.690: Find a better model.
2023-05-13 15:08:16.763: [iter 53 : loss : 0.1791 = 0.0843 + 0.0914 + 0.0034, time: 7.072883]
2023-05-13 15:08:16.922: epoch 53:	0.02429494  	0.17949191  	0.09545855  
2023-05-13 15:08:16.922: Find a better model.
2023-05-13 15:08:24.117: [iter 54 : loss : 0.1770 = 0.0824 + 0.0912 + 0.0034, time: 7.194010]
2023-05-13 15:08:24.260: epoch 54:	0.02435139  	0.17980827  	0.09573141  
2023-05-13 15:08:24.261: Find a better model.
2023-05-13 15:08:31.289: [iter 55 : loss : 0.1751 = 0.0807 + 0.0910 + 0.0035, time: 7.026801]
2023-05-13 15:08:31.445: epoch 55:	0.02449957  	0.18078108  	0.09633027  
2023-05-13 15:08:31.445: Find a better model.
2023-05-13 15:08:38.562: [iter 56 : loss : 0.1736 = 0.0793 + 0.0908 + 0.0035, time: 7.115810]
2023-05-13 15:08:38.715: epoch 56:	0.02459130  	0.18191485  	0.09702469  
2023-05-13 15:08:38.715: Find a better model.
2023-05-13 15:08:45.942: [iter 57 : loss : 0.1716 = 0.0775 + 0.0906 + 0.0036, time: 7.226477]
2023-05-13 15:08:46.096: epoch 57:	0.02459836  	0.18171781  	0.09709059  
2023-05-13 15:08:53.316: [iter 58 : loss : 0.1698 = 0.0757 + 0.0904 + 0.0036, time: 7.217377]
2023-05-13 15:08:53.469: epoch 58:	0.02467598  	0.18192887  	0.09755751  
2023-05-13 15:08:53.469: Find a better model.
2023-05-13 15:09:00.729: [iter 59 : loss : 0.1686 = 0.0747 + 0.0902 + 0.0037, time: 7.259214]
2023-05-13 15:09:00.872: epoch 59:	0.02467598  	0.18200694  	0.09787966  
2023-05-13 15:09:00.872: Find a better model.
2023-05-13 15:09:08.130: [iter 60 : loss : 0.1671 = 0.0733 + 0.0901 + 0.0037, time: 7.255950]
2023-05-13 15:09:08.282: epoch 60:	0.02481711  	0.18303087  	0.09854762  
2023-05-13 15:09:08.282: Find a better model.
2023-05-13 15:09:15.539: [iter 61 : loss : 0.1657 = 0.0721 + 0.0899 + 0.0038, time: 7.255540]
2023-05-13 15:09:15.692: epoch 61:	0.02481005  	0.18298890  	0.09860286  
2023-05-13 15:09:22.905: [iter 62 : loss : 0.1641 = 0.0706 + 0.0898 + 0.0038, time: 7.211918]
2023-05-13 15:09:23.062: epoch 62:	0.02484533  	0.18331328  	0.09879500  
2023-05-13 15:09:23.062: Find a better model.
2023-05-13 15:09:30.153: [iter 63 : loss : 0.1632 = 0.0698 + 0.0896 + 0.0038, time: 7.089217]
2023-05-13 15:09:30.308: epoch 63:	0.02490178  	0.18364324  	0.09908410  
2023-05-13 15:09:30.308: Find a better model.
2023-05-13 15:09:37.517: [iter 64 : loss : 0.1615 = 0.0682 + 0.0894 + 0.0039, time: 7.208554]
2023-05-13 15:09:37.671: epoch 64:	0.02501468  	0.18447939  	0.09975267  
2023-05-13 15:09:37.671: Find a better model.
2023-05-13 15:09:44.905: [iter 65 : loss : 0.1605 = 0.0673 + 0.0893 + 0.0039, time: 7.232945]
2023-05-13 15:09:45.063: epoch 65:	0.02501469  	0.18414667  	0.09984395  
2023-05-13 15:09:52.281: [iter 66 : loss : 0.1588 = 0.0657 + 0.0891 + 0.0040, time: 7.217397]
2023-05-13 15:09:52.438: epoch 66:	0.02507114  	0.18447119  	0.10026759  
2023-05-13 15:09:59.718: [iter 67 : loss : 0.1575 = 0.0645 + 0.0890 + 0.0040, time: 7.278556]
2023-05-13 15:09:59.872: epoch 67:	0.02512053  	0.18506809  	0.10073487  
2023-05-13 15:09:59.872: Find a better model.
2023-05-13 15:10:06.919: [iter 68 : loss : 0.1572 = 0.0644 + 0.0888 + 0.0041, time: 7.046250]
2023-05-13 15:10:07.061: epoch 68:	0.02509231  	0.18449481  	0.10086602  
2023-05-13 15:10:14.130: [iter 69 : loss : 0.1553 = 0.0625 + 0.0887 + 0.0041, time: 7.067911]
2023-05-13 15:10:14.284: epoch 69:	0.02509936  	0.18479005  	0.10105318  
2023-05-13 15:10:21.304: [iter 70 : loss : 0.1535 = 0.0607 + 0.0886 + 0.0041, time: 7.018003]
2023-05-13 15:10:21.460: epoch 70:	0.02521932  	0.18594587  	0.10154188  
2023-05-13 15:10:21.460: Find a better model.
2023-05-13 15:10:28.522: [iter 71 : loss : 0.1522 = 0.0595 + 0.0885 + 0.0042, time: 7.060490]
2023-05-13 15:10:28.677: epoch 71:	0.02525461  	0.18644305  	0.10187303  
2023-05-13 15:10:28.677: Find a better model.
2023-05-13 15:10:35.892: [iter 72 : loss : 0.1522 = 0.0596 + 0.0884 + 0.0042, time: 7.214708]
2023-05-13 15:10:36.033: epoch 72:	0.02524050  	0.18628143  	0.10197500  
2023-05-13 15:10:43.296: [iter 73 : loss : 0.1504 = 0.0580 + 0.0882 + 0.0043, time: 7.260357]
2023-05-13 15:10:43.448: epoch 73:	0.02532518  	0.18677929  	0.10220896  
2023-05-13 15:10:43.448: Find a better model.
2023-05-13 15:10:50.684: [iter 74 : loss : 0.1489 = 0.0565 + 0.0881 + 0.0043, time: 7.234072]
2023-05-13 15:10:50.839: epoch 74:	0.02543808  	0.18769042  	0.10264280  
2023-05-13 15:10:50.839: Find a better model.
2023-05-13 15:10:58.103: [iter 75 : loss : 0.1486 = 0.0562 + 0.0880 + 0.0043, time: 7.261939]
2023-05-13 15:10:58.258: epoch 75:	0.02546631  	0.18792722  	0.10308466  
2023-05-13 15:10:58.259: Find a better model.
2023-05-13 15:11:05.496: [iter 76 : loss : 0.1476 = 0.0553 + 0.0879 + 0.0044, time: 7.235333]
2023-05-13 15:11:05.650: epoch 76:	0.02557215  	0.18865623  	0.10349607  
2023-05-13 15:11:05.651: Find a better model.
2023-05-13 15:11:12.892: [iter 77 : loss : 0.1465 = 0.0543 + 0.0878 + 0.0044, time: 7.239963]
2023-05-13 15:11:13.045: epoch 77:	0.02556510  	0.18860021  	0.10364634  
2023-05-13 15:11:20.285: [iter 78 : loss : 0.1458 = 0.0536 + 0.0877 + 0.0045, time: 7.238622]
2023-05-13 15:11:20.441: epoch 78:	0.02556510  	0.18856880  	0.10372011  
2023-05-13 15:11:27.687: [iter 79 : loss : 0.1444 = 0.0523 + 0.0876 + 0.0045, time: 7.244859]
2023-05-13 15:11:27.839: epoch 79:	0.02557921  	0.18833563  	0.10387775  
2023-05-13 15:11:35.086: [iter 80 : loss : 0.1439 = 0.0518 + 0.0875 + 0.0045, time: 7.246212]
2023-05-13 15:11:35.244: epoch 80:	0.02560038  	0.18830714  	0.10385672  
2023-05-13 15:11:42.503: [iter 81 : loss : 0.1434 = 0.0514 + 0.0873 + 0.0046, time: 7.258749]
2023-05-13 15:11:42.657: epoch 81:	0.02567094  	0.18902862  	0.10416986  
2023-05-13 15:11:42.657: Find a better model.
2023-05-13 15:11:49.860: [iter 82 : loss : 0.1421 = 0.0502 + 0.0872 + 0.0046, time: 7.202034]
2023-05-13 15:11:50.000: epoch 82:	0.02574151  	0.18931271  	0.10452352  
2023-05-13 15:11:50.000: Find a better model.
2023-05-13 15:11:57.273: [iter 83 : loss : 0.1412 = 0.0494 + 0.0872 + 0.0047, time: 7.269279]
2023-05-13 15:11:57.429: epoch 83:	0.02572740  	0.18935886  	0.10477202  
2023-05-13 15:11:57.430: Find a better model.
2023-05-13 15:12:04.656: [iter 84 : loss : 0.1410 = 0.0492 + 0.0871 + 0.0047, time: 7.224929]
2023-05-13 15:12:04.800: epoch 84:	0.02584030  	0.19015533  	0.10521853  
2023-05-13 15:12:04.800: Find a better model.
2023-05-13 15:12:12.053: [iter 85 : loss : 0.1400 = 0.0484 + 0.0869 + 0.0047, time: 7.252125]
2023-05-13 15:12:12.197: epoch 85:	0.02587558  	0.19033121  	0.10543315  
2023-05-13 15:12:12.197: Find a better model.
2023-05-13 15:12:19.436: [iter 86 : loss : 0.1399 = 0.0483 + 0.0868 + 0.0048, time: 7.236437]
2023-05-13 15:12:19.591: epoch 86:	0.02595320  	0.19094582  	0.10559345  
2023-05-13 15:12:19.591: Find a better model.
2023-05-13 15:12:26.676: [iter 87 : loss : 0.1373 = 0.0457 + 0.0868 + 0.0048, time: 7.083415]
2023-05-13 15:12:26.828: epoch 87:	0.02600260  	0.19132389  	0.10584668  
2023-05-13 15:12:26.828: Find a better model.
2023-05-13 15:12:34.057: [iter 88 : loss : 0.1365 = 0.0450 + 0.0867 + 0.0049, time: 7.228141]
2023-05-13 15:12:34.216: epoch 88:	0.02610844  	0.19193326  	0.10607523  
2023-05-13 15:12:34.217: Find a better model.
2023-05-13 15:12:41.440: [iter 89 : loss : 0.1363 = 0.0449 + 0.0866 + 0.0049, time: 7.222510]
2023-05-13 15:12:41.594: epoch 89:	0.02613666  	0.19237414  	0.10650405  
2023-05-13 15:12:41.594: Find a better model.
2023-05-13 15:12:48.823: [iter 90 : loss : 0.1367 = 0.0453 + 0.0865 + 0.0049, time: 7.226323]
2023-05-13 15:12:48.976: epoch 90:	0.02613666  	0.19232398  	0.10644461  
2023-05-13 15:12:56.059: [iter 91 : loss : 0.1356 = 0.0442 + 0.0864 + 0.0050, time: 7.081982]
2023-05-13 15:12:56.216: epoch 91:	0.02613666  	0.19207403  	0.10650078  
2023-05-13 15:13:03.448: [iter 92 : loss : 0.1347 = 0.0433 + 0.0864 + 0.0050, time: 7.231125]
2023-05-13 15:13:03.604: epoch 92:	0.02608727  	0.19188097  	0.10652278  
2023-05-13 15:13:10.860: [iter 93 : loss : 0.1347 = 0.0434 + 0.0863 + 0.0050, time: 7.253643]
2023-05-13 15:13:11.002: epoch 93:	0.02612255  	0.19213733  	0.10666303  
2023-05-13 15:13:18.218: [iter 94 : loss : 0.1327 = 0.0414 + 0.0862 + 0.0051, time: 7.215225]
2023-05-13 15:13:18.373: epoch 94:	0.02612961  	0.19255550  	0.10685219  
2023-05-13 15:13:18.373: Find a better model.
2023-05-13 15:13:25.458: [iter 95 : loss : 0.1322 = 0.0410 + 0.0861 + 0.0051, time: 7.084181]
2023-05-13 15:13:25.612: epoch 95:	0.02611549  	0.19229962  	0.10689995  
2023-05-13 15:13:32.654: [iter 96 : loss : 0.1322 = 0.0410 + 0.0860 + 0.0051, time: 7.041682]
2023-05-13 15:13:32.808: epoch 96:	0.02621428  	0.19300164  	0.10718748  
2023-05-13 15:13:32.808: Find a better model.
2023-05-13 15:13:39.863: [iter 97 : loss : 0.1304 = 0.0393 + 0.0860 + 0.0052, time: 7.054024]
2023-05-13 15:13:40.017: epoch 97:	0.02620722  	0.19308120  	0.10722772  
2023-05-13 15:13:40.017: Find a better model.
2023-05-13 15:13:47.204: [iter 98 : loss : 0.1317 = 0.0405 + 0.0859 + 0.0052, time: 7.185710]
2023-05-13 15:13:47.359: epoch 98:	0.02623545  	0.19319165  	0.10744808  
2023-05-13 15:13:47.359: Find a better model.
2023-05-13 15:13:54.448: [iter 99 : loss : 0.1303 = 0.0392 + 0.0858 + 0.0053, time: 7.086393]
2023-05-13 15:13:54.602: epoch 99:	0.02621428  	0.19280167  	0.10755962  
2023-05-13 15:14:01.846: [iter 100 : loss : 0.1294 = 0.0384 + 0.0857 + 0.0053, time: 7.243474]
2023-05-13 15:14:02.000: epoch 100:	0.02622839  	0.19304585  	0.10767343  
2023-05-13 15:14:09.042: [iter 101 : loss : 0.1293 = 0.0384 + 0.0857 + 0.0053, time: 7.040685]
2023-05-13 15:14:09.186: epoch 101:	0.02626368  	0.19303110  	0.10777668  
2023-05-13 15:14:16.213: [iter 102 : loss : 0.1280 = 0.0370 + 0.0856 + 0.0054, time: 7.025908]
2023-05-13 15:14:16.365: epoch 102:	0.02631307  	0.19362894  	0.10799403  
2023-05-13 15:14:16.365: Find a better model.
2023-05-13 15:14:23.429: [iter 103 : loss : 0.1279 = 0.0370 + 0.0855 + 0.0054, time: 7.060627]
2023-05-13 15:14:23.583: epoch 103:	0.02632719  	0.19364163  	0.10805394  
2023-05-13 15:14:23.583: Find a better model.
2023-05-13 15:14:30.642: [iter 104 : loss : 0.1283 = 0.0374 + 0.0854 + 0.0054, time: 7.057552]
2023-05-13 15:14:30.785: epoch 104:	0.02641186  	0.19453779  	0.10836338  
2023-05-13 15:14:30.785: Find a better model.
2023-05-13 15:14:37.834: [iter 105 : loss : 0.1278 = 0.0369 + 0.0854 + 0.0055, time: 7.048262]
2023-05-13 15:14:37.988: epoch 105:	0.02634130  	0.19362694  	0.10824569  
2023-05-13 15:14:44.994: [iter 106 : loss : 0.1271 = 0.0362 + 0.0853 + 0.0055, time: 7.004218]
2023-05-13 15:14:45.137: epoch 106:	0.02636953  	0.19386990  	0.10829940  
2023-05-13 15:14:52.229: [iter 107 : loss : 0.1263 = 0.0354 + 0.0853 + 0.0055, time: 7.090997]
2023-05-13 15:14:52.386: epoch 107:	0.02648949  	0.19502914  	0.10867877  
2023-05-13 15:14:52.386: Find a better model.
2023-05-13 15:14:59.424: [iter 108 : loss : 0.1261 = 0.0354 + 0.0852 + 0.0056, time: 7.036233]
2023-05-13 15:14:59.579: epoch 108:	0.02646832  	0.19507803  	0.10875756  
2023-05-13 15:14:59.579: Find a better model.
2023-05-13 15:15:06.631: [iter 109 : loss : 0.1248 = 0.0341 + 0.0851 + 0.0056, time: 7.049077]
2023-05-13 15:15:06.783: epoch 109:	0.02646126  	0.19504924  	0.10859777  
2023-05-13 15:15:13.792: [iter 110 : loss : 0.1239 = 0.0332 + 0.0851 + 0.0056, time: 7.007670]
2023-05-13 15:15:13.946: epoch 110:	0.02647537  	0.19534738  	0.10880437  
2023-05-13 15:15:13.946: Find a better model.
2023-05-13 15:15:21.012: [iter 111 : loss : 0.1242 = 0.0335 + 0.0850 + 0.0057, time: 7.064609]
2023-05-13 15:15:21.154: epoch 111:	0.02645420  	0.19483997  	0.10863950  
2023-05-13 15:15:28.214: [iter 112 : loss : 0.1241 = 0.0334 + 0.0850 + 0.0057, time: 7.059726]
2023-05-13 15:15:28.371: epoch 112:	0.02646832  	0.19507940  	0.10879986  
2023-05-13 15:15:35.405: [iter 113 : loss : 0.1238 = 0.0331 + 0.0849 + 0.0057, time: 7.031941]
2023-05-13 15:15:35.558: epoch 113:	0.02658828  	0.19601965  	0.10906784  
2023-05-13 15:15:35.558: Find a better model.
2023-05-13 15:15:42.587: [iter 114 : loss : 0.1228 = 0.0322 + 0.0848 + 0.0058, time: 7.027391]
2023-05-13 15:15:42.741: epoch 114:	0.02649655  	0.19537228  	0.10886472  
2023-05-13 15:15:49.989: [iter 115 : loss : 0.1225 = 0.0318 + 0.0848 + 0.0058, time: 7.246412]
2023-05-13 15:15:50.143: epoch 115:	0.02652477  	0.19522759  	0.10896218  
2023-05-13 15:15:57.205: [iter 116 : loss : 0.1218 = 0.0311 + 0.0848 + 0.0058, time: 7.059778]
2023-05-13 15:15:57.362: epoch 116:	0.02649655  	0.19538133  	0.10886735  
2023-05-13 15:16:04.578: [iter 117 : loss : 0.1215 = 0.0310 + 0.0847 + 0.0059, time: 7.215503]
2023-05-13 15:16:04.733: epoch 117:	0.02653183  	0.19530736  	0.10901096  
2023-05-13 15:16:11.966: [iter 118 : loss : 0.1216 = 0.0311 + 0.0846 + 0.0059, time: 7.232011]
2023-05-13 15:16:12.121: epoch 118:	0.02652477  	0.19551139  	0.10915422  
2023-05-13 15:16:19.200: [iter 119 : loss : 0.1207 = 0.0302 + 0.0846 + 0.0059, time: 7.078288]
2023-05-13 15:16:19.359: epoch 119:	0.02646831  	0.19493335  	0.10910593  
2023-05-13 15:16:26.402: [iter 120 : loss : 0.1207 = 0.0302 + 0.0846 + 0.0060, time: 7.041724]
2023-05-13 15:16:26.555: epoch 120:	0.02652477  	0.19550425  	0.10913517  
2023-05-13 15:16:33.579: [iter 121 : loss : 0.1206 = 0.0301 + 0.0845 + 0.0060, time: 7.023057]
2023-05-13 15:16:33.722: epoch 121:	0.02656005  	0.19558537  	0.10930264  
2023-05-13 15:16:40.744: [iter 122 : loss : 0.1198 = 0.0294 + 0.0845 + 0.0060, time: 7.020591]
2023-05-13 15:16:40.902: epoch 122:	0.02656005  	0.19541833  	0.10934254  
2023-05-13 15:16:47.970: [iter 123 : loss : 0.1198 = 0.0293 + 0.0844 + 0.0060, time: 7.066874]
2023-05-13 15:16:48.117: epoch 123:	0.02652477  	0.19527622  	0.10926402  
2023-05-13 15:16:55.182: [iter 124 : loss : 0.1188 = 0.0284 + 0.0844 + 0.0061, time: 7.064251]
2023-05-13 15:16:55.334: epoch 124:	0.02651772  	0.19534871  	0.10931141  
2023-05-13 15:17:02.387: [iter 125 : loss : 0.1184 = 0.0280 + 0.0843 + 0.0061, time: 7.052170]
2023-05-13 15:17:02.540: epoch 125:	0.02656005  	0.19565842  	0.10938868  
2023-05-13 15:17:09.757: [iter 126 : loss : 0.1183 = 0.0280 + 0.0842 + 0.0061, time: 7.215966]
2023-05-13 15:17:09.915: epoch 126:	0.02646831  	0.19478765  	0.10916137  
2023-05-13 15:17:16.996: [iter 127 : loss : 0.1175 = 0.0271 + 0.0842 + 0.0062, time: 7.079927]
2023-05-13 15:17:17.149: epoch 127:	0.02655299  	0.19544460  	0.10928520  
2023-05-13 15:17:24.195: [iter 128 : loss : 0.1187 = 0.0283 + 0.0842 + 0.0062, time: 7.045086]
2023-05-13 15:17:24.349: epoch 128:	0.02653182  	0.19525971  	0.10947516  
2023-05-13 15:17:31.384: [iter 129 : loss : 0.1177 = 0.0274 + 0.0841 + 0.0062, time: 7.033540]
2023-05-13 15:17:31.543: epoch 129:	0.02651771  	0.19515935  	0.10942535  
2023-05-13 15:17:38.757: [iter 130 : loss : 0.1178 = 0.0275 + 0.0841 + 0.0063, time: 7.213509]
2023-05-13 15:17:38.920: epoch 130:	0.02652477  	0.19513816  	0.10936294  
2023-05-13 15:17:46.225: [iter 131 : loss : 0.1169 = 0.0266 + 0.0840 + 0.0063, time: 7.302994]
2023-05-13 15:17:46.386: epoch 131:	0.02660944  	0.19600691  	0.10971749  
2023-05-13 15:17:53.556: [iter 132 : loss : 0.1171 = 0.0267 + 0.0840 + 0.0063, time: 7.168282]
2023-05-13 15:17:53.712: epoch 132:	0.02666589  	0.19640122  	0.10984208  
2023-05-13 15:17:53.712: Find a better model.
2023-05-13 15:18:00.772: [iter 133 : loss : 0.1160 = 0.0257 + 0.0840 + 0.0063, time: 7.057866]
2023-05-13 15:18:00.931: epoch 133:	0.02663767  	0.19620121  	0.10981900  
2023-05-13 15:18:07.969: [iter 134 : loss : 0.1165 = 0.0262 + 0.0839 + 0.0064, time: 7.036996]
2023-05-13 15:18:08.127: epoch 134:	0.02663061  	0.19587959  	0.10972901  
2023-05-13 15:18:15.153: [iter 135 : loss : 0.1162 = 0.0259 + 0.0839 + 0.0064, time: 7.025492]
2023-05-13 15:18:15.297: epoch 135:	0.02665178  	0.19627689  	0.10990088  
2023-05-13 15:18:22.351: [iter 136 : loss : 0.1159 = 0.0257 + 0.0838 + 0.0064, time: 7.051950]
2023-05-13 15:18:22.496: epoch 136:	0.02665884  	0.19588834  	0.10981642  
2023-05-13 15:18:29.559: [iter 137 : loss : 0.1155 = 0.0252 + 0.0838 + 0.0065, time: 7.061609]
2023-05-13 15:18:29.713: epoch 137:	0.02662356  	0.19590232  	0.10971067  
2023-05-13 15:18:36.717: [iter 138 : loss : 0.1152 = 0.0249 + 0.0838 + 0.0065, time: 7.001995]
2023-05-13 15:18:36.859: epoch 138:	0.02668001  	0.19590066  	0.10981071  
2023-05-13 15:18:43.929: [iter 139 : loss : 0.1150 = 0.0248 + 0.0837 + 0.0065, time: 7.068923]
2023-05-13 15:18:44.084: epoch 139:	0.02667295  	0.19602308  	0.10980269  
2023-05-13 15:18:51.151: [iter 140 : loss : 0.1143 = 0.0241 + 0.0837 + 0.0065, time: 7.065962]
2023-05-13 15:18:51.303: epoch 140:	0.02658121  	0.19569248  	0.10976130  
2023-05-13 15:18:58.326: [iter 141 : loss : 0.1148 = 0.0245 + 0.0836 + 0.0066, time: 7.022043]
2023-05-13 15:18:58.473: epoch 141:	0.02664472  	0.19608817  	0.10980523  
2023-05-13 15:19:05.523: [iter 142 : loss : 0.1139 = 0.0237 + 0.0836 + 0.0066, time: 7.047577]
2023-05-13 15:19:05.680: epoch 142:	0.02663767  	0.19594407  	0.10983263  
2023-05-13 15:19:12.740: [iter 143 : loss : 0.1139 = 0.0237 + 0.0836 + 0.0066, time: 7.059018]
2023-05-13 15:19:12.895: epoch 143:	0.02668706  	0.19627655  	0.10997640  
2023-05-13 15:19:19.983: [iter 144 : loss : 0.1135 = 0.0233 + 0.0835 + 0.0067, time: 7.087665]
2023-05-13 15:19:20.136: epoch 144:	0.02668001  	0.19605559  	0.11000322  
2023-05-13 15:19:27.577: [iter 145 : loss : 0.1136 = 0.0234 + 0.0835 + 0.0067, time: 7.439137]
2023-05-13 15:19:27.733: epoch 145:	0.02667295  	0.19584489  	0.10999588  
2023-05-13 15:19:34.924: [iter 146 : loss : 0.1135 = 0.0234 + 0.0835 + 0.0067, time: 7.190890]
2023-05-13 15:19:35.084: epoch 146:	0.02672940  	0.19621664  	0.11002078  
2023-05-13 15:19:42.144: [iter 147 : loss : 0.1135 = 0.0234 + 0.0834 + 0.0067, time: 7.057713]
2023-05-13 15:19:42.298: epoch 147:	0.02672940  	0.19611536  	0.10987409  
2023-05-13 15:19:49.393: [iter 148 : loss : 0.1121 = 0.0220 + 0.0834 + 0.0068, time: 7.092830]
2023-05-13 15:19:49.548: epoch 148:	0.02671529  	0.19598553  	0.10990810  
2023-05-13 15:19:56.524: [iter 149 : loss : 0.1126 = 0.0224 + 0.0834 + 0.0068, time: 6.974303]
2023-05-13 15:19:56.670: epoch 149:	0.02670823  	0.19608761  	0.10994158  
2023-05-13 15:20:03.708: [iter 150 : loss : 0.1122 = 0.0220 + 0.0833 + 0.0068, time: 7.036259]
2023-05-13 15:20:03.860: epoch 150:	0.02668706  	0.19574483  	0.10987888  
2023-05-13 15:20:10.914: [iter 151 : loss : 0.1122 = 0.0220 + 0.0833 + 0.0068, time: 7.052588]
2023-05-13 15:20:11.070: epoch 151:	0.02673646  	0.19603804  	0.10998647  
2023-05-13 15:20:18.312: [iter 152 : loss : 0.1116 = 0.0215 + 0.0833 + 0.0069, time: 7.240181]
2023-05-13 15:20:18.463: epoch 152:	0.02672940  	0.19620754  	0.11007665  
2023-05-13 15:20:25.518: [iter 153 : loss : 0.1106 = 0.0205 + 0.0832 + 0.0069, time: 7.052996]
2023-05-13 15:20:25.673: epoch 153:	0.02669412  	0.19616535  	0.10992330  
2023-05-13 15:20:32.683: [iter 154 : loss : 0.1109 = 0.0208 + 0.0832 + 0.0069, time: 7.008262]
2023-05-13 15:20:32.839: epoch 154:	0.02678586  	0.19671388  	0.11022621  
2023-05-13 15:20:32.839: Find a better model.
2023-05-13 15:20:39.922: [iter 155 : loss : 0.1117 = 0.0216 + 0.0832 + 0.0069, time: 7.082448]
2023-05-13 15:20:40.077: epoch 155:	0.02679291  	0.19667000  	0.11028644  
2023-05-13 15:20:47.302: [iter 156 : loss : 0.1111 = 0.0210 + 0.0831 + 0.0070, time: 7.222860]
2023-05-13 15:20:47.454: epoch 156:	0.02681409  	0.19674513  	0.11039675  
2023-05-13 15:20:47.454: Find a better model.
2023-05-13 15:20:54.495: [iter 157 : loss : 0.1110 = 0.0209 + 0.0831 + 0.0070, time: 7.039431]
2023-05-13 15:20:54.638: epoch 157:	0.02679997  	0.19668640  	0.11019439  
2023-05-13 15:21:01.685: [iter 158 : loss : 0.1103 = 0.0202 + 0.0831 + 0.0070, time: 7.045051]
2023-05-13 15:21:01.841: epoch 158:	0.02677880  	0.19635899  	0.11023821  
2023-05-13 15:21:08.890: [iter 159 : loss : 0.1108 = 0.0207 + 0.0830 + 0.0070, time: 7.048333]
2023-05-13 15:21:09.043: epoch 159:	0.02684232  	0.19667135  	0.11048614  
2023-05-13 15:21:16.106: [iter 160 : loss : 0.1101 = 0.0200 + 0.0830 + 0.0071, time: 7.062510]
2023-05-13 15:21:16.259: epoch 160:	0.02680704  	0.19668406  	0.11044013  
2023-05-13 15:21:23.283: [iter 161 : loss : 0.1099 = 0.0198 + 0.0830 + 0.0071, time: 7.022052]
2023-05-13 15:21:23.429: epoch 161:	0.02678587  	0.19626456  	0.11027854  
2023-05-13 15:21:30.461: [iter 162 : loss : 0.1092 = 0.0191 + 0.0830 + 0.0071, time: 7.030065]
2023-05-13 15:21:30.610: epoch 162:	0.02675764  	0.19608574  	0.11022183  
2023-05-13 15:21:37.685: [iter 163 : loss : 0.1096 = 0.0195 + 0.0829 + 0.0071, time: 7.073865]
2023-05-13 15:21:37.837: epoch 163:	0.02670825  	0.19579835  	0.11012564  
2023-05-13 15:21:44.897: [iter 164 : loss : 0.1093 = 0.0192 + 0.0829 + 0.0072, time: 7.059087]
2023-05-13 15:21:45.052: epoch 164:	0.02668002  	0.19529480  	0.11014800  
2023-05-13 15:21:52.090: [iter 165 : loss : 0.1093 = 0.0192 + 0.0829 + 0.0072, time: 7.037870]
2023-05-13 15:21:52.247: epoch 165:	0.02666591  	0.19504665  	0.10994211  
2023-05-13 15:21:59.256: [iter 166 : loss : 0.1090 = 0.0189 + 0.0829 + 0.0072, time: 7.007983]
2023-05-13 15:21:59.400: epoch 166:	0.02664473  	0.19514795  	0.10998866  
2023-05-13 15:22:06.469: [iter 167 : loss : 0.1093 = 0.0192 + 0.0829 + 0.0072, time: 7.067708]
2023-05-13 15:22:06.622: epoch 167:	0.02672235  	0.19538347  	0.11013469  
2023-05-13 15:22:13.688: [iter 168 : loss : 0.1087 = 0.0186 + 0.0828 + 0.0073, time: 7.064079]
2023-05-13 15:22:13.842: epoch 168:	0.02664473  	0.19462696  	0.10991576  
2023-05-13 15:22:20.857: [iter 169 : loss : 0.1087 = 0.0186 + 0.0828 + 0.0073, time: 7.013787]
2023-05-13 15:22:21.013: epoch 169:	0.02667296  	0.19494474  	0.11004646  
2023-05-13 15:22:28.049: [iter 170 : loss : 0.1083 = 0.0182 + 0.0828 + 0.0073, time: 7.033865]
2023-05-13 15:22:28.205: epoch 170:	0.02666590  	0.19499417  	0.11012587  
2023-05-13 15:22:35.267: [iter 171 : loss : 0.1089 = 0.0188 + 0.0827 + 0.0073, time: 7.061472]
2023-05-13 15:22:35.421: epoch 171:	0.02672235  	0.19561091  	0.11048561  
2023-05-13 15:22:42.461: [iter 172 : loss : 0.1077 = 0.0177 + 0.0827 + 0.0073, time: 7.038323]
2023-05-13 15:22:42.605: epoch 172:	0.02672235  	0.19562283  	0.11042508  
2023-05-13 15:22:49.647: [iter 173 : loss : 0.1086 = 0.0186 + 0.0827 + 0.0074, time: 7.040704]
2023-05-13 15:22:49.792: epoch 173:	0.02668707  	0.19534348  	0.11034136  
2023-05-13 15:22:56.821: [iter 174 : loss : 0.1082 = 0.0181 + 0.0827 + 0.0074, time: 7.026485]
2023-05-13 15:22:56.965: epoch 174:	0.02675058  	0.19571961  	0.11047842  
2023-05-13 15:23:04.029: [iter 175 : loss : 0.1076 = 0.0175 + 0.0827 + 0.0074, time: 7.062905]
2023-05-13 15:23:04.183: epoch 175:	0.02671530  	0.19565326  	0.11029824  
2023-05-13 15:23:11.254: [iter 176 : loss : 0.1074 = 0.0173 + 0.0826 + 0.0074, time: 7.069921]
2023-05-13 15:23:11.409: epoch 176:	0.02665179  	0.19537008  	0.11025112  
2023-05-13 15:23:18.441: [iter 177 : loss : 0.1076 = 0.0175 + 0.0826 + 0.0075, time: 7.030827]
2023-05-13 15:23:18.584: epoch 177:	0.02671530  	0.19586961  	0.11028010  
2023-05-13 15:23:25.623: [iter 178 : loss : 0.1068 = 0.0167 + 0.0826 + 0.0075, time: 7.037618]
2023-05-13 15:23:25.781: epoch 178:	0.02667295  	0.19511965  	0.11011284  
2023-05-13 15:23:32.838: [iter 179 : loss : 0.1068 = 0.0168 + 0.0826 + 0.0075, time: 7.054345]
2023-05-13 15:23:32.991: epoch 179:	0.02670824  	0.19569330  	0.11038204  
2023-05-13 15:23:40.021: [iter 180 : loss : 0.1070 = 0.0169 + 0.0826 + 0.0075, time: 7.028807]
2023-05-13 15:23:40.176: epoch 180:	0.02668001  	0.19537129  	0.11011442  
2023-05-13 15:23:47.238: [iter 181 : loss : 0.1072 = 0.0172 + 0.0825 + 0.0076, time: 7.061348]
2023-05-13 15:23:47.395: epoch 181:	0.02666590  	0.19518612  	0.11021417  
2023-05-13 15:23:47.395: Early stopping is trigger at epoch: 181
2023-05-13 15:23:47.395: best_result@epoch 156:

2023-05-13 15:23:47.395: 		0.0268      	0.1967      	0.1104      
2023-05-13 15:25:58.303: my pid: 12688
2023-05-13 15:25:58.303: model: model.general_recommender.SGL
2023-05-13 15:25:58.303: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 15:25:58.303: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 15:26:01.465: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:26:09.843: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.378122]
2023-05-13 15:26:10.012: epoch 1:	0.00151002  	0.01022077  	0.00542658  
2023-05-13 15:26:10.012: Find a better model.
2023-05-13 15:26:18.231: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.218184]
2023-05-13 15:26:18.440: epoch 2:	0.00289303  	0.02147222  	0.01082848  
2023-05-13 15:26:18.440: Find a better model.
2023-05-13 15:26:38.577: my pid: 404
2023-05-13 15:26:38.577: model: model.general_recommender.SGL
2023-05-13 15:26:38.577: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 15:26:38.577: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 15:26:41.631: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:26:48.753: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.122613]
2023-05-13 15:26:48.901: epoch 1:	0.00196162  	0.01356582  	0.00689553  
2023-05-13 15:26:48.902: Find a better model.
2023-05-13 15:26:56.176: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.272744]
2023-05-13 15:26:56.368: epoch 2:	0.00452298  	0.03183420  	0.01582556  
2023-05-13 15:26:56.368: Find a better model.
2023-05-13 15:27:03.370: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.000033]
2023-05-13 15:27:03.543: epoch 3:	0.00738069  	0.05300945  	0.02582289  
2023-05-13 15:27:03.543: Find a better model.
2023-05-13 15:27:10.354: [iter 4 : loss : 0.7714 = 0.6914 + 0.0800 + 0.0000, time: 6.810455]
2023-05-13 15:27:10.504: epoch 4:	0.01107113  	0.07996041  	0.03739849  
2023-05-13 15:27:10.505: Find a better model.
2023-05-13 15:27:17.163: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 6.656281]
2023-05-13 15:27:17.318: epoch 5:	0.01397134  	0.10048582  	0.04808241  
2023-05-13 15:27:17.319: Find a better model.
2023-05-13 15:27:23.935: [iter 6 : loss : 0.7660 = 0.6850 + 0.0810 + 0.0000, time: 6.615576]
2023-05-13 15:27:24.075: epoch 6:	0.01677979  	0.12177137  	0.05957906  
2023-05-13 15:27:24.075: Find a better model.
2023-05-13 15:27:30.535: [iter 7 : loss : 0.7562 = 0.6740 + 0.0822 + 0.0000, time: 6.457822]
2023-05-13 15:27:30.685: epoch 7:	0.01819812  	0.13270357  	0.06583305  
2023-05-13 15:27:30.685: Find a better model.
2023-05-13 15:27:37.094: [iter 8 : loss : 0.7334 = 0.6483 + 0.0850 + 0.0001, time: 6.408819]
2023-05-13 15:27:37.247: epoch 8:	0.01877677  	0.13830298  	0.06888762  
2023-05-13 15:27:37.247: Find a better model.
2023-05-13 15:27:43.741: [iter 9 : loss : 0.6873 = 0.5974 + 0.0897 + 0.0002, time: 6.492786]
2023-05-13 15:27:43.894: epoch 9:	0.01832515  	0.13572603  	0.06772375  
2023-05-13 15:27:50.136: [iter 10 : loss : 0.6189 = 0.5236 + 0.0950 + 0.0003, time: 6.241302]
2023-05-13 15:27:50.277: epoch 10:	0.01829692  	0.13518710  	0.06738545  
2023-05-13 15:27:56.527: [iter 11 : loss : 0.5457 = 0.4460 + 0.0993 + 0.0005, time: 6.248537]
2023-05-13 15:27:56.666: epoch 11:	0.01816991  	0.13422351  	0.06738117  
2023-05-13 15:28:02.942: [iter 12 : loss : 0.4847 = 0.3824 + 0.1018 + 0.0006, time: 6.273286]
2023-05-13 15:28:03.083: epoch 12:	0.01818402  	0.13398844  	0.06757274  
2023-05-13 15:28:09.338: [iter 13 : loss : 0.4409 = 0.3370 + 0.1031 + 0.0008, time: 6.254337]
2023-05-13 15:28:09.491: epoch 13:	0.01839571  	0.13565442  	0.06845430  
2023-05-13 15:28:15.740: [iter 14 : loss : 0.4071 = 0.3027 + 0.1036 + 0.0009, time: 6.247874]
2023-05-13 15:28:15.890: epoch 14:	0.01866386  	0.13769335  	0.06946286  
2023-05-13 15:28:22.121: [iter 15 : loss : 0.3836 = 0.2788 + 0.1038 + 0.0010, time: 6.228146]
2023-05-13 15:28:22.264: epoch 15:	0.01888967  	0.13975194  	0.07067394  
2023-05-13 15:28:22.264: Find a better model.
2023-05-13 15:28:28.537: [iter 16 : loss : 0.3630 = 0.2583 + 0.1036 + 0.0011, time: 6.272757]
2023-05-13 15:28:28.691: epoch 16:	0.01919310  	0.14169075  	0.07162875  
2023-05-13 15:28:28.691: Find a better model.
2023-05-13 15:28:34.924: [iter 17 : loss : 0.3478 = 0.2432 + 0.1033 + 0.0012, time: 6.231784]
2023-05-13 15:28:35.064: epoch 17:	0.01934835  	0.14277518  	0.07264873  
2023-05-13 15:28:35.064: Find a better model.
2023-05-13 15:28:41.335: [iter 18 : loss : 0.3333 = 0.2290 + 0.1030 + 0.0013, time: 6.270313]
2023-05-13 15:28:41.489: epoch 18:	0.01956710  	0.14446755  	0.07352103  
2023-05-13 15:28:41.489: Find a better model.
2023-05-13 15:28:47.912: [iter 19 : loss : 0.3196 = 0.2156 + 0.1026 + 0.0014, time: 6.421337]
2023-05-13 15:28:48.067: epoch 19:	0.01967294  	0.14526327  	0.07419104  
2023-05-13 15:28:48.068: Find a better model.
2023-05-13 15:28:54.518: [iter 20 : loss : 0.3104 = 0.2067 + 0.1022 + 0.0015, time: 6.448704]
2023-05-13 15:28:54.671: epoch 20:	0.01996226  	0.14724249  	0.07500424  
2023-05-13 15:28:54.671: Find a better model.
2023-05-13 15:29:01.123: [iter 21 : loss : 0.3010 = 0.1977 + 0.1018 + 0.0016, time: 6.450276]
2023-05-13 15:29:01.276: epoch 21:	0.02011751  	0.14837782  	0.07568040  
2023-05-13 15:29:01.276: Find a better model.
2023-05-13 15:29:07.716: [iter 22 : loss : 0.2929 = 0.1899 + 0.1013 + 0.0017, time: 6.439442]
2023-05-13 15:29:07.867: epoch 22:	0.02027980  	0.14937440  	0.07623898  
2023-05-13 15:29:07.868: Find a better model.
2023-05-13 15:29:14.278: [iter 23 : loss : 0.2846 = 0.1820 + 0.1009 + 0.0017, time: 6.408205]
2023-05-13 15:29:14.429: epoch 23:	0.02047738  	0.15083565  	0.07704224  
2023-05-13 15:29:14.429: Find a better model.
2023-05-13 15:29:20.894: [iter 24 : loss : 0.2782 = 0.1760 + 0.1004 + 0.0018, time: 6.464056]
2023-05-13 15:29:21.038: epoch 24:	0.02073142  	0.15282390  	0.07795034  
2023-05-13 15:29:21.039: Find a better model.
2023-05-13 15:29:27.493: [iter 25 : loss : 0.2720 = 0.1701 + 0.1000 + 0.0019, time: 6.451688]
2023-05-13 15:29:27.636: epoch 25:	0.02090783  	0.15349938  	0.07844865  
2023-05-13 15:29:27.636: Find a better model.
2023-05-13 15:29:34.099: [iter 26 : loss : 0.2683 = 0.1668 + 0.0996 + 0.0019, time: 6.462365]
2023-05-13 15:29:34.253: epoch 26:	0.02111247  	0.15468781  	0.07926672  
2023-05-13 15:29:34.253: Find a better model.
2023-05-13 15:29:40.698: [iter 27 : loss : 0.2606 = 0.1594 + 0.0992 + 0.0020, time: 6.443166]
2023-05-13 15:29:40.849: epoch 27:	0.02123949  	0.15564427  	0.07982828  
2023-05-13 15:29:40.849: Find a better model.
2023-05-13 15:29:47.307: [iter 28 : loss : 0.2559 = 0.1551 + 0.0988 + 0.0021, time: 6.456419]
2023-05-13 15:29:47.449: epoch 28:	0.02128889  	0.15615617  	0.08047161  
2023-05-13 15:29:47.450: Find a better model.
2023-05-13 15:29:53.884: [iter 29 : loss : 0.2513 = 0.1508 + 0.0984 + 0.0021, time: 6.433697]
2023-05-13 15:29:54.041: epoch 29:	0.02147235  	0.15760490  	0.08121742  
2023-05-13 15:29:54.041: Find a better model.
2023-05-13 15:30:00.496: [iter 30 : loss : 0.2449 = 0.1447 + 0.0980 + 0.0022, time: 6.454057]
2023-05-13 15:30:00.650: epoch 30:	0.02171933  	0.15923440  	0.08228636  
2023-05-13 15:30:00.651: Find a better model.
2023-05-13 15:30:07.069: [iter 31 : loss : 0.2414 = 0.1415 + 0.0976 + 0.0023, time: 6.417077]
2023-05-13 15:30:07.221: epoch 31:	0.02190280  	0.16102211  	0.08303552  
2023-05-13 15:30:07.222: Find a better model.
2023-05-13 15:30:13.692: [iter 32 : loss : 0.2356 = 0.1360 + 0.0972 + 0.0023, time: 6.469110]
2023-05-13 15:30:13.835: epoch 32:	0.02212154  	0.16267034  	0.08401392  
2023-05-13 15:30:13.835: Find a better model.
2023-05-13 15:30:20.290: [iter 33 : loss : 0.2332 = 0.1339 + 0.0969 + 0.0024, time: 6.454450]
2023-05-13 15:30:20.442: epoch 33:	0.02235440  	0.16431072  	0.08480698  
2023-05-13 15:30:20.443: Find a better model.
2023-05-13 15:30:26.948: [iter 34 : loss : 0.2289 = 0.1299 + 0.0965 + 0.0024, time: 6.503085]
2023-05-13 15:30:27.118: epoch 34:	0.02237558  	0.16466668  	0.08541280  
2023-05-13 15:30:27.118: Find a better model.
2023-05-13 15:30:33.714: [iter 35 : loss : 0.2256 = 0.1268 + 0.0963 + 0.0025, time: 6.592556]
2023-05-13 15:30:33.857: epoch 35:	0.02248142  	0.16552936  	0.08609280  
2023-05-13 15:30:33.857: Find a better model.
2023-05-13 15:30:40.272: [iter 36 : loss : 0.2224 = 0.1238 + 0.0960 + 0.0025, time: 6.412726]
2023-05-13 15:30:40.413: epoch 36:	0.02270018  	0.16711223  	0.08672736  
2023-05-13 15:30:40.413: Find a better model.
2023-05-13 15:30:46.679: [iter 37 : loss : 0.2182 = 0.1200 + 0.0956 + 0.0026, time: 6.265365]
2023-05-13 15:30:46.822: epoch 37:	0.02279897  	0.16795929  	0.08735953  
2023-05-13 15:30:46.822: Find a better model.
2023-05-13 15:30:53.084: [iter 38 : loss : 0.2169 = 0.1189 + 0.0953 + 0.0027, time: 6.261353]
2023-05-13 15:30:53.238: epoch 38:	0.02297538  	0.16914935  	0.08822408  
2023-05-13 15:30:53.238: Find a better model.
2023-05-13 15:30:59.664: [iter 39 : loss : 0.2124 = 0.1146 + 0.0950 + 0.0027, time: 6.424663]
2023-05-13 15:30:59.808: epoch 39:	0.02303184  	0.16992365  	0.08891863  
2023-05-13 15:30:59.808: Find a better model.
2023-05-13 15:31:06.082: [iter 40 : loss : 0.2090 = 0.1115 + 0.0947 + 0.0028, time: 6.271734]
2023-05-13 15:31:06.235: epoch 40:	0.02319414  	0.17113914  	0.08956356  
2023-05-13 15:31:06.236: Find a better model.
2023-05-13 15:31:12.699: [iter 41 : loss : 0.2073 = 0.1101 + 0.0945 + 0.0028, time: 6.462737]
2023-05-13 15:31:12.851: epoch 41:	0.02325059  	0.17125313  	0.08982674  
2023-05-13 15:31:12.852: Find a better model.
2023-05-13 15:31:19.253: [iter 42 : loss : 0.2051 = 0.1081 + 0.0942 + 0.0029, time: 6.400313]
2023-05-13 15:31:19.404: epoch 42:	0.02334232  	0.17157699  	0.09017339  
2023-05-13 15:31:19.404: Find a better model.
2023-05-13 15:31:25.854: [iter 43 : loss : 0.2012 = 0.1044 + 0.0939 + 0.0029, time: 6.448999]
2023-05-13 15:31:26.008: epoch 43:	0.02348346  	0.17261298  	0.09053362  
2023-05-13 15:31:26.008: Find a better model.
2023-05-13 15:31:32.272: [iter 44 : loss : 0.1977 = 0.1011 + 0.0936 + 0.0030, time: 6.262359]
2023-05-13 15:31:32.413: epoch 44:	0.02356813  	0.17312272  	0.09109791  
2023-05-13 15:31:32.413: Find a better model.
2023-05-13 15:31:38.850: [iter 45 : loss : 0.1956 = 0.0992 + 0.0934 + 0.0030, time: 6.436473]
2023-05-13 15:31:39.005: epoch 45:	0.02365987  	0.17399664  	0.09173588  
2023-05-13 15:31:39.005: Find a better model.
2023-05-13 15:31:45.263: [iter 46 : loss : 0.1935 = 0.0973 + 0.0932 + 0.0031, time: 6.257569]
2023-05-13 15:31:45.415: epoch 46:	0.02377277  	0.17466648  	0.09249143  
2023-05-13 15:31:45.415: Find a better model.
2023-05-13 15:31:51.837: [iter 47 : loss : 0.1927 = 0.0966 + 0.0929 + 0.0031, time: 6.420309]
2023-05-13 15:31:51.991: epoch 47:	0.02382217  	0.17503536  	0.09277438  
2023-05-13 15:31:51.991: Find a better model.
2023-05-13 15:31:58.264: [iter 48 : loss : 0.1888 = 0.0929 + 0.0927 + 0.0032, time: 6.271300]
2023-05-13 15:31:58.420: epoch 48:	0.02390684  	0.17559473  	0.09327468  
2023-05-13 15:31:58.420: Find a better model.
2023-05-13 15:32:04.850: [iter 49 : loss : 0.1856 = 0.0898 + 0.0926 + 0.0032, time: 6.428481]
2023-05-13 15:32:05.005: epoch 49:	0.02389979  	0.17541070  	0.09339352  
2023-05-13 15:32:11.418: [iter 50 : loss : 0.1848 = 0.0893 + 0.0923 + 0.0033, time: 6.412261]
2023-05-13 15:32:11.574: epoch 50:	0.02408325  	0.17651212  	0.09413162  
2023-05-13 15:32:11.574: Find a better model.
2023-05-13 15:32:18.050: [iter 51 : loss : 0.1817 = 0.0863 + 0.0921 + 0.0033, time: 6.474481]
2023-05-13 15:32:18.205: epoch 51:	0.02417498  	0.17748165  	0.09457418  
2023-05-13 15:32:18.205: Find a better model.
2023-05-13 15:32:24.641: [iter 52 : loss : 0.1818 = 0.0866 + 0.0919 + 0.0034, time: 6.434463]
2023-05-13 15:32:24.791: epoch 52:	0.02435140  	0.17848173  	0.09523837  
2023-05-13 15:32:24.791: Find a better model.
2023-05-13 15:32:31.226: [iter 53 : loss : 0.1796 = 0.0845 + 0.0917 + 0.0034, time: 6.433176]
2023-05-13 15:32:31.379: epoch 53:	0.02445018  	0.17893764  	0.09570488  
2023-05-13 15:32:31.379: Find a better model.
2023-05-13 15:32:37.856: [iter 54 : loss : 0.1775 = 0.0826 + 0.0915 + 0.0034, time: 6.476343]
2023-05-13 15:32:38.007: epoch 54:	0.02459132  	0.18047689  	0.09636237  
2023-05-13 15:32:38.007: Find a better model.
2023-05-13 15:32:44.397: [iter 55 : loss : 0.1755 = 0.0807 + 0.0913 + 0.0035, time: 6.389275]
2023-05-13 15:32:44.547: epoch 55:	0.02470422  	0.18131091  	0.09671757  
2023-05-13 15:32:44.547: Find a better model.
2023-05-13 15:32:51.039: [iter 56 : loss : 0.1738 = 0.0792 + 0.0911 + 0.0035, time: 6.490152]
2023-05-13 15:32:51.190: epoch 56:	0.02473244  	0.18159261  	0.09712056  
2023-05-13 15:32:51.190: Find a better model.
2023-05-13 15:32:57.639: [iter 57 : loss : 0.1719 = 0.0774 + 0.0909 + 0.0036, time: 6.447641]
2023-05-13 15:32:57.793: epoch 57:	0.02484534  	0.18253584  	0.09742386  
2023-05-13 15:32:57.793: Find a better model.
2023-05-13 15:33:04.185: [iter 58 : loss : 0.1701 = 0.0757 + 0.0908 + 0.0036, time: 6.391784]
2023-05-13 15:33:04.339: epoch 58:	0.02490885  	0.18334998  	0.09791380  
2023-05-13 15:33:04.339: Find a better model.
2023-05-13 15:33:10.806: [iter 59 : loss : 0.1689 = 0.0747 + 0.0906 + 0.0037, time: 6.465288]
2023-05-13 15:33:10.960: epoch 59:	0.02493002  	0.18346377  	0.09815194  
2023-05-13 15:33:10.960: Find a better model.
2023-05-13 15:33:17.408: [iter 60 : loss : 0.1677 = 0.0735 + 0.0904 + 0.0037, time: 6.447466]
2023-05-13 15:33:17.560: epoch 60:	0.02507114  	0.18426120  	0.09868087  
2023-05-13 15:33:17.560: Find a better model.
2023-05-13 15:33:24.033: [iter 61 : loss : 0.1662 = 0.0722 + 0.0903 + 0.0038, time: 6.472218]
2023-05-13 15:33:24.185: epoch 61:	0.02514876  	0.18478334  	0.09920287  
2023-05-13 15:33:24.185: Find a better model.
2023-05-13 15:33:30.432: [iter 62 : loss : 0.1648 = 0.0708 + 0.0901 + 0.0038, time: 6.245559]
2023-05-13 15:33:30.584: epoch 62:	0.02523343  	0.18543284  	0.09950819  
2023-05-13 15:33:30.584: Find a better model.
2023-05-13 15:33:36.990: [iter 63 : loss : 0.1633 = 0.0695 + 0.0899 + 0.0038, time: 6.403814]
2023-05-13 15:33:37.130: epoch 63:	0.02525460  	0.18588613  	0.09975635  
2023-05-13 15:33:37.130: Find a better model.
2023-05-13 15:33:43.426: [iter 64 : loss : 0.1622 = 0.0685 + 0.0898 + 0.0039, time: 6.294330]
2023-05-13 15:33:43.580: epoch 64:	0.02529694  	0.18622810  	0.10008898  
2023-05-13 15:33:43.580: Find a better model.
2023-05-13 15:33:50.002: [iter 65 : loss : 0.1610 = 0.0674 + 0.0896 + 0.0039, time: 6.420080]
2023-05-13 15:33:50.146: epoch 65:	0.02523344  	0.18556291  	0.10002584  
2023-05-13 15:33:56.432: [iter 66 : loss : 0.1594 = 0.0659 + 0.0895 + 0.0040, time: 6.285586]
2023-05-13 15:33:56.575: epoch 66:	0.02527578  	0.18627204  	0.10035489  
2023-05-13 15:33:56.575: Find a better model.
2023-05-13 15:34:03.011: [iter 67 : loss : 0.1579 = 0.0645 + 0.0894 + 0.0040, time: 6.434464]
2023-05-13 15:34:03.165: epoch 67:	0.02533223  	0.18665078  	0.10068732  
2023-05-13 15:34:03.165: Find a better model.
2023-05-13 15:34:09.416: [iter 68 : loss : 0.1577 = 0.0645 + 0.0892 + 0.0041, time: 6.249681]
2023-05-13 15:34:09.568: epoch 68:	0.02538162  	0.18693866  	0.10098512  
2023-05-13 15:34:09.568: Find a better model.
2023-05-13 15:34:15.994: [iter 69 : loss : 0.1553 = 0.0622 + 0.0891 + 0.0041, time: 6.424763]
2023-05-13 15:34:16.149: epoch 69:	0.02534634  	0.18704429  	0.10109785  
2023-05-13 15:34:16.149: Find a better model.
2023-05-13 15:34:22.403: [iter 70 : loss : 0.1539 = 0.0607 + 0.0890 + 0.0041, time: 6.252857]
2023-05-13 15:34:22.555: epoch 70:	0.02541691  	0.18742436  	0.10129707  
2023-05-13 15:34:22.555: Find a better model.
2023-05-13 15:34:28.991: [iter 71 : loss : 0.1526 = 0.0595 + 0.0889 + 0.0042, time: 6.435571]
2023-05-13 15:34:29.144: epoch 71:	0.02544513  	0.18739738  	0.10144557  
2023-05-13 15:34:35.552: [iter 72 : loss : 0.1523 = 0.0593 + 0.0888 + 0.0042, time: 6.405997]
2023-05-13 15:34:35.694: epoch 72:	0.02543102  	0.18684670  	0.10143777  
2023-05-13 15:34:42.150: [iter 73 : loss : 0.1509 = 0.0580 + 0.0886 + 0.0043, time: 6.455014]
2023-05-13 15:34:42.304: epoch 73:	0.02552275  	0.18739569  	0.10174693  
2023-05-13 15:34:48.602: [iter 74 : loss : 0.1496 = 0.0568 + 0.0885 + 0.0043, time: 6.295998]
2023-05-13 15:34:48.753: epoch 74:	0.02553686  	0.18750861  	0.10202778  
2023-05-13 15:34:48.753: Find a better model.
2023-05-13 15:34:55.184: [iter 75 : loss : 0.1489 = 0.0562 + 0.0884 + 0.0043, time: 6.428776]
2023-05-13 15:34:55.338: epoch 75:	0.02560742  	0.18778898  	0.10232996  
2023-05-13 15:34:55.338: Find a better model.
2023-05-13 15:35:01.598: [iter 76 : loss : 0.1478 = 0.0551 + 0.0883 + 0.0044, time: 6.257619]
2023-05-13 15:35:01.751: epoch 76:	0.02572739  	0.18880789  	0.10266851  
2023-05-13 15:35:01.751: Find a better model.
2023-05-13 15:35:08.185: [iter 77 : loss : 0.1469 = 0.0543 + 0.0882 + 0.0044, time: 6.433479]
2023-05-13 15:35:08.339: epoch 77:	0.02579795  	0.18944307  	0.10284704  
2023-05-13 15:35:08.339: Find a better model.
2023-05-13 15:35:14.595: [iter 78 : loss : 0.1459 = 0.0534 + 0.0881 + 0.0045, time: 6.255089]
2023-05-13 15:35:14.737: epoch 78:	0.02575560  	0.18911327  	0.10293260  
2023-05-13 15:35:20.960: [iter 79 : loss : 0.1449 = 0.0524 + 0.0880 + 0.0045, time: 6.220382]
2023-05-13 15:35:21.100: epoch 79:	0.02580500  	0.18924214  	0.10291190  
2023-05-13 15:35:27.384: [iter 80 : loss : 0.1441 = 0.0517 + 0.0879 + 0.0045, time: 6.282699]
2023-05-13 15:35:27.539: epoch 80:	0.02588263  	0.18990700  	0.10323396  
2023-05-13 15:35:27.539: Find a better model.
2023-05-13 15:35:33.966: [iter 81 : loss : 0.1439 = 0.0515 + 0.0878 + 0.0046, time: 6.425549]
2023-05-13 15:35:34.115: epoch 81:	0.02588263  	0.18989959  	0.10338394  
2023-05-13 15:35:40.368: [iter 82 : loss : 0.1425 = 0.0502 + 0.0876 + 0.0046, time: 6.250719]
2023-05-13 15:35:40.510: epoch 82:	0.02583323  	0.18960632  	0.10341940  
2023-05-13 15:35:46.765: [iter 83 : loss : 0.1416 = 0.0494 + 0.0876 + 0.0047, time: 6.254633]
2023-05-13 15:35:46.918: epoch 83:	0.02578383  	0.18914931  	0.10341234  
2023-05-13 15:35:53.166: [iter 84 : loss : 0.1416 = 0.0494 + 0.0875 + 0.0047, time: 6.247019]
2023-05-13 15:35:53.311: epoch 84:	0.02597436  	0.19063871  	0.10390503  
2023-05-13 15:35:53.311: Find a better model.
2023-05-13 15:35:59.585: [iter 85 : loss : 0.1407 = 0.0486 + 0.0874 + 0.0047, time: 6.271871]
2023-05-13 15:35:59.740: epoch 85:	0.02604492  	0.19131994  	0.10429849  
2023-05-13 15:35:59.740: Find a better model.
2023-05-13 15:36:06.160: [iter 86 : loss : 0.1404 = 0.0484 + 0.0873 + 0.0048, time: 6.418554]
2023-05-13 15:36:06.314: epoch 86:	0.02608021  	0.19202918  	0.10460673  
2023-05-13 15:36:06.315: Find a better model.
2023-05-13 15:36:12.544: [iter 87 : loss : 0.1377 = 0.0457 + 0.0872 + 0.0048, time: 6.228055]
2023-05-13 15:36:12.704: epoch 87:	0.02615783  	0.19248714  	0.10480160  
2023-05-13 15:36:12.704: Find a better model.
2023-05-13 15:36:18.967: [iter 88 : loss : 0.1370 = 0.0450 + 0.0871 + 0.0048, time: 6.261749]
2023-05-13 15:36:19.110: epoch 88:	0.02614372  	0.19221033  	0.10490919  
2023-05-13 15:36:25.359: [iter 89 : loss : 0.1367 = 0.0448 + 0.0870 + 0.0049, time: 6.247928]
2023-05-13 15:36:25.514: epoch 89:	0.02617900  	0.19250059  	0.10510226  
2023-05-13 15:36:25.514: Find a better model.
2023-05-13 15:36:31.768: [iter 90 : loss : 0.1373 = 0.0454 + 0.0870 + 0.0049, time: 6.252711]
2023-05-13 15:36:31.921: epoch 90:	0.02627779  	0.19336438  	0.10543641  
2023-05-13 15:36:31.921: Find a better model.
2023-05-13 15:36:38.164: [iter 91 : loss : 0.1360 = 0.0442 + 0.0869 + 0.0050, time: 6.241718]
2023-05-13 15:36:38.307: epoch 91:	0.02629190  	0.19346650  	0.10552902  
2023-05-13 15:36:38.307: Find a better model.
2023-05-13 15:36:44.556: [iter 92 : loss : 0.1350 = 0.0432 + 0.0868 + 0.0050, time: 6.247138]
2023-05-13 15:36:44.712: epoch 92:	0.02630602  	0.19381313  	0.10566423  
2023-05-13 15:36:44.712: Find a better model.
2023-05-13 15:36:50.950: [iter 93 : loss : 0.1353 = 0.0436 + 0.0867 + 0.0050, time: 6.236977]
2023-05-13 15:36:51.104: epoch 93:	0.02627779  	0.19384000  	0.10581768  
2023-05-13 15:36:51.105: Find a better model.
2023-05-13 15:36:57.367: [iter 94 : loss : 0.1332 = 0.0415 + 0.0866 + 0.0051, time: 6.260626]
2023-05-13 15:36:57.522: epoch 94:	0.02633424  	0.19409324  	0.10604222  
2023-05-13 15:36:57.522: Find a better model.
2023-05-13 15:37:03.722: [iter 95 : loss : 0.1327 = 0.0411 + 0.0865 + 0.0051, time: 6.197849]
2023-05-13 15:37:03.878: epoch 95:	0.02629896  	0.19402999  	0.10603784  
2023-05-13 15:37:10.144: [iter 96 : loss : 0.1325 = 0.0410 + 0.0864 + 0.0051, time: 6.263847]
2023-05-13 15:37:10.298: epoch 96:	0.02632013  	0.19419579  	0.10607998  
2023-05-13 15:37:10.298: Find a better model.
2023-05-13 15:37:16.533: [iter 97 : loss : 0.1309 = 0.0393 + 0.0864 + 0.0052, time: 6.234680]
2023-05-13 15:37:16.676: epoch 97:	0.02630602  	0.19391546  	0.10598447  
2023-05-13 15:37:22.950: [iter 98 : loss : 0.1315 = 0.0400 + 0.0863 + 0.0052, time: 6.272480]
2023-05-13 15:37:23.103: epoch 98:	0.02628485  	0.19367933  	0.10614137  
2023-05-13 15:37:29.506: [iter 99 : loss : 0.1307 = 0.0392 + 0.0862 + 0.0052, time: 6.401532]
2023-05-13 15:37:29.648: epoch 99:	0.02634130  	0.19414951  	0.10652921  
2023-05-13 15:37:35.944: [iter 100 : loss : 0.1300 = 0.0385 + 0.0862 + 0.0053, time: 6.294321]
2023-05-13 15:37:36.097: epoch 100:	0.02641892  	0.19456817  	0.10677526  
2023-05-13 15:37:36.097: Find a better model.
2023-05-13 15:37:42.516: [iter 101 : loss : 0.1297 = 0.0382 + 0.0861 + 0.0053, time: 6.418214]
2023-05-13 15:37:42.659: epoch 101:	0.02649654  	0.19527408  	0.10710462  
2023-05-13 15:37:42.660: Find a better model.
2023-05-13 15:37:48.932: [iter 102 : loss : 0.1286 = 0.0372 + 0.0860 + 0.0054, time: 6.270518]
2023-05-13 15:37:49.084: epoch 102:	0.02649653  	0.19464239  	0.10700293  
2023-05-13 15:37:55.325: [iter 103 : loss : 0.1285 = 0.0371 + 0.0860 + 0.0054, time: 6.238307]
2023-05-13 15:37:55.482: epoch 103:	0.02660239  	0.19555844  	0.10730648  
2023-05-13 15:37:55.482: Find a better model.
2023-05-13 15:38:01.718: [iter 104 : loss : 0.1288 = 0.0375 + 0.0859 + 0.0054, time: 6.234994]
2023-05-13 15:38:01.873: epoch 104:	0.02659533  	0.19523637  	0.10762716  
2023-05-13 15:38:08.110: [iter 105 : loss : 0.1283 = 0.0371 + 0.0858 + 0.0055, time: 6.235795]
2023-05-13 15:38:08.253: epoch 105:	0.02663766  	0.19550787  	0.10760850  
2023-05-13 15:38:14.502: [iter 106 : loss : 0.1273 = 0.0361 + 0.0857 + 0.0055, time: 6.246698]
2023-05-13 15:38:14.654: epoch 106:	0.02665178  	0.19599812  	0.10776214  
2023-05-13 15:38:14.654: Find a better model.
2023-05-13 15:38:20.909: [iter 107 : loss : 0.1267 = 0.0355 + 0.0857 + 0.0055, time: 6.253186]
2023-05-13 15:38:21.064: epoch 107:	0.02668706  	0.19611630  	0.10779142  
2023-05-13 15:38:21.064: Find a better model.
2023-05-13 15:38:27.299: [iter 108 : loss : 0.1265 = 0.0353 + 0.0856 + 0.0056, time: 6.232663]
2023-05-13 15:38:27.456: epoch 108:	0.02666589  	0.19621664  	0.10796149  
2023-05-13 15:38:27.457: Find a better model.
2023-05-13 15:38:33.706: [iter 109 : loss : 0.1249 = 0.0337 + 0.0856 + 0.0056, time: 6.247901]
2023-05-13 15:38:33.860: epoch 109:	0.02663061  	0.19585857  	0.10786429  
2023-05-13 15:38:40.103: [iter 110 : loss : 0.1245 = 0.0333 + 0.0855 + 0.0056, time: 6.242630]
2023-05-13 15:38:40.258: epoch 110:	0.02670117  	0.19623359  	0.10795228  
2023-05-13 15:38:40.259: Find a better model.
2023-05-13 15:38:46.481: [iter 111 : loss : 0.1247 = 0.0335 + 0.0855 + 0.0057, time: 6.220409]
2023-05-13 15:38:46.635: epoch 111:	0.02669412  	0.19627070  	0.10797093  
2023-05-13 15:38:46.635: Find a better model.
2023-05-13 15:38:52.890: [iter 112 : loss : 0.1241 = 0.0330 + 0.0854 + 0.0057, time: 6.253163]
2023-05-13 15:38:53.041: epoch 112:	0.02667295  	0.19603111  	0.10796801  
2023-05-13 15:38:59.308: [iter 113 : loss : 0.1242 = 0.0331 + 0.0854 + 0.0057, time: 6.263340]
2023-05-13 15:38:59.463: epoch 113:	0.02663767  	0.19598086  	0.10790757  
2023-05-13 15:39:05.689: [iter 114 : loss : 0.1232 = 0.0321 + 0.0853 + 0.0058, time: 6.223728]
2023-05-13 15:39:05.846: epoch 114:	0.02664473  	0.19572318  	0.10790260  
2023-05-13 15:39:12.093: [iter 115 : loss : 0.1230 = 0.0320 + 0.0853 + 0.0058, time: 6.245075]
2023-05-13 15:39:12.244: epoch 115:	0.02657416  	0.19530886  	0.10782076  
2023-05-13 15:39:18.484: [iter 116 : loss : 0.1219 = 0.0309 + 0.0852 + 0.0058, time: 6.238987]
2023-05-13 15:39:18.640: epoch 116:	0.02663767  	0.19579230  	0.10790619  
2023-05-13 15:39:24.887: [iter 117 : loss : 0.1221 = 0.0311 + 0.0851 + 0.0059, time: 6.244349]
2023-05-13 15:39:25.040: epoch 117:	0.02668000  	0.19600205  	0.10815809  
2023-05-13 15:39:31.284: [iter 118 : loss : 0.1219 = 0.0310 + 0.0851 + 0.0059, time: 6.242883]
2023-05-13 15:39:31.426: epoch 118:	0.02666589  	0.19586548  	0.10815001  
2023-05-13 15:39:37.657: [iter 119 : loss : 0.1209 = 0.0299 + 0.0850 + 0.0059, time: 6.229465]
2023-05-13 15:39:37.813: epoch 119:	0.02672940  	0.19634922  	0.10831247  
2023-05-13 15:39:37.814: Find a better model.
2023-05-13 15:39:44.059: [iter 120 : loss : 0.1212 = 0.0303 + 0.0850 + 0.0059, time: 6.242779]
2023-05-13 15:39:44.213: epoch 120:	0.02675057  	0.19690375  	0.10846743  
2023-05-13 15:39:44.213: Find a better model.
2023-05-13 15:39:50.475: [iter 121 : loss : 0.1211 = 0.0302 + 0.0850 + 0.0060, time: 6.259655]
2023-05-13 15:39:50.621: epoch 121:	0.02677174  	0.19684577  	0.10845753  
2023-05-13 15:39:56.701: [iter 122 : loss : 0.1202 = 0.0292 + 0.0849 + 0.0060, time: 6.079034]
2023-05-13 15:39:56.855: epoch 122:	0.02675057  	0.19681422  	0.10843918  
2023-05-13 15:40:03.081: [iter 123 : loss : 0.1203 = 0.0294 + 0.0849 + 0.0060, time: 6.224735]
2023-05-13 15:40:03.232: epoch 123:	0.02660944  	0.19587803  	0.10824758  
2023-05-13 15:40:09.290: [iter 124 : loss : 0.1195 = 0.0286 + 0.0848 + 0.0061, time: 6.055660]
2023-05-13 15:40:09.443: epoch 124:	0.02665178  	0.19629635  	0.10837604  
2023-05-13 15:40:15.665: [iter 125 : loss : 0.1187 = 0.0279 + 0.0848 + 0.0061, time: 6.221132]
2023-05-13 15:40:15.816: epoch 125:	0.02670823  	0.19680092  	0.10856009  
2023-05-13 15:40:22.063: [iter 126 : loss : 0.1190 = 0.0281 + 0.0847 + 0.0061, time: 6.245891]
2023-05-13 15:40:22.207: epoch 126:	0.02672940  	0.19666237  	0.10852142  
2023-05-13 15:40:28.429: [iter 127 : loss : 0.1179 = 0.0271 + 0.0847 + 0.0062, time: 6.220320]
2023-05-13 15:40:28.586: epoch 127:	0.02670118  	0.19647621  	0.10862184  
2023-05-13 15:40:34.685: [iter 128 : loss : 0.1191 = 0.0282 + 0.0847 + 0.0062, time: 6.095721]
2023-05-13 15:40:34.842: epoch 128:	0.02670118  	0.19658306  	0.10854865  
2023-05-13 15:40:41.065: [iter 129 : loss : 0.1180 = 0.0272 + 0.0846 + 0.0062, time: 6.222117]
2023-05-13 15:40:41.209: epoch 129:	0.02674352  	0.19706751  	0.10889515  
2023-05-13 15:40:41.209: Find a better model.
2023-05-13 15:40:47.471: [iter 130 : loss : 0.1181 = 0.0273 + 0.0845 + 0.0062, time: 6.261450]
2023-05-13 15:40:47.627: epoch 130:	0.02681408  	0.19746527  	0.10902771  
2023-05-13 15:40:47.627: Find a better model.
2023-05-13 15:40:53.849: [iter 131 : loss : 0.1175 = 0.0267 + 0.0845 + 0.0063, time: 6.221014]
2023-05-13 15:40:53.995: epoch 131:	0.02680703  	0.19758135  	0.10904900  
2023-05-13 15:40:53.995: Find a better model.
2023-05-13 15:41:00.080: [iter 132 : loss : 0.1174 = 0.0266 + 0.0845 + 0.0063, time: 6.083452]
2023-05-13 15:41:00.232: epoch 132:	0.02682820  	0.19770329  	0.10912352  
2023-05-13 15:41:00.232: Find a better model.
2023-05-13 15:41:06.457: [iter 133 : loss : 0.1160 = 0.0253 + 0.0844 + 0.0063, time: 6.223137]
2023-05-13 15:41:06.611: epoch 133:	0.02685643  	0.19776385  	0.10921142  
2023-05-13 15:41:06.611: Find a better model.
2023-05-13 15:41:12.855: [iter 134 : loss : 0.1170 = 0.0262 + 0.0844 + 0.0064, time: 6.242110]
2023-05-13 15:41:13.009: epoch 134:	0.02681408  	0.19731626  	0.10899217  
2023-05-13 15:41:19.221: [iter 135 : loss : 0.1167 = 0.0260 + 0.0843 + 0.0064, time: 6.210598]
2023-05-13 15:41:19.372: epoch 135:	0.02682820  	0.19747974  	0.10905543  
2023-05-13 15:41:25.631: [iter 136 : loss : 0.1162 = 0.0255 + 0.0843 + 0.0064, time: 6.256828]
2023-05-13 15:41:25.786: epoch 136:	0.02679997  	0.19741912  	0.10896657  
2023-05-13 15:41:32.027: [iter 137 : loss : 0.1157 = 0.0250 + 0.0843 + 0.0065, time: 6.240492]
2023-05-13 15:41:32.183: epoch 137:	0.02671529  	0.19688465  	0.10872321  
2023-05-13 15:41:38.451: [iter 138 : loss : 0.1156 = 0.0249 + 0.0842 + 0.0065, time: 6.266858]
2023-05-13 15:41:38.605: epoch 138:	0.02673646  	0.19683972  	0.10874516  
2023-05-13 15:41:44.655: [iter 139 : loss : 0.1154 = 0.0247 + 0.0842 + 0.0065, time: 6.049373]
2023-05-13 15:41:44.810: epoch 139:	0.02668707  	0.19645464  	0.10863650  
2023-05-13 15:41:50.856: [iter 140 : loss : 0.1150 = 0.0243 + 0.0842 + 0.0065, time: 6.044504]
2023-05-13 15:41:51.013: epoch 140:	0.02675763  	0.19685788  	0.10883076  
2023-05-13 15:41:57.242: [iter 141 : loss : 0.1154 = 0.0248 + 0.0841 + 0.0066, time: 6.228337]
2023-05-13 15:41:57.396: epoch 141:	0.02674352  	0.19683695  	0.10901742  
2023-05-13 15:42:03.623: [iter 142 : loss : 0.1144 = 0.0237 + 0.0841 + 0.0066, time: 6.225902]
2023-05-13 15:42:03.769: epoch 142:	0.02673646  	0.19672990  	0.10896898  
2023-05-13 15:42:09.810: [iter 143 : loss : 0.1144 = 0.0237 + 0.0841 + 0.0066, time: 6.038857]
2023-05-13 15:42:09.953: epoch 143:	0.02669412  	0.19658217  	0.10880312  
2023-05-13 15:42:16.215: [iter 144 : loss : 0.1139 = 0.0232 + 0.0840 + 0.0066, time: 6.261450]
2023-05-13 15:42:16.371: epoch 144:	0.02665179  	0.19617909  	0.10879820  
2023-05-13 15:42:22.448: [iter 145 : loss : 0.1140 = 0.0233 + 0.0840 + 0.0067, time: 6.073703]
2023-05-13 15:42:22.600: epoch 145:	0.02663767  	0.19608587  	0.10878651  
2023-05-13 15:42:28.821: [iter 146 : loss : 0.1142 = 0.0236 + 0.0840 + 0.0067, time: 6.219570]
2023-05-13 15:42:28.965: epoch 146:	0.02670823  	0.19639282  	0.10876961  
2023-05-13 15:42:35.029: [iter 147 : loss : 0.1139 = 0.0232 + 0.0839 + 0.0067, time: 6.063307]
2023-05-13 15:42:35.182: epoch 147:	0.02665178  	0.19620378  	0.10881829  
2023-05-13 15:42:41.225: [iter 148 : loss : 0.1126 = 0.0220 + 0.0839 + 0.0068, time: 6.042394]
2023-05-13 15:42:41.368: epoch 148:	0.02663061  	0.19570869  	0.10880528  
2023-05-13 15:42:47.429: [iter 149 : loss : 0.1130 = 0.0224 + 0.0839 + 0.0068, time: 6.060025]
2023-05-13 15:42:47.585: epoch 149:	0.02672235  	0.19648920  	0.10907210  
2023-05-13 15:42:53.808: [iter 150 : loss : 0.1126 = 0.0220 + 0.0838 + 0.0068, time: 6.221233]
2023-05-13 15:42:53.960: epoch 150:	0.02670118  	0.19633408  	0.10895380  
2023-05-13 15:43:00.205: [iter 151 : loss : 0.1129 = 0.0223 + 0.0838 + 0.0068, time: 6.243486]
2023-05-13 15:43:00.357: epoch 151:	0.02668707  	0.19633639  	0.10910299  
2023-05-13 15:43:06.575: [iter 152 : loss : 0.1119 = 0.0213 + 0.0837 + 0.0069, time: 6.217075]
2023-05-13 15:43:06.719: epoch 152:	0.02665179  	0.19574448  	0.10891400  
2023-05-13 15:43:12.825: [iter 153 : loss : 0.1112 = 0.0206 + 0.0837 + 0.0069, time: 6.104067]
2023-05-13 15:43:12.977: epoch 153:	0.02664473  	0.19553059  	0.10887354  
2023-05-13 15:43:19.199: [iter 154 : loss : 0.1116 = 0.0210 + 0.0837 + 0.0069, time: 6.219932]
2023-05-13 15:43:19.354: epoch 154:	0.02659534  	0.19539295  	0.10897376  
2023-05-13 15:43:25.419: [iter 155 : loss : 0.1125 = 0.0219 + 0.0837 + 0.0069, time: 6.064107]
2023-05-13 15:43:25.564: epoch 155:	0.02663062  	0.19533212  	0.10902186  
2023-05-13 15:43:31.797: [iter 156 : loss : 0.1117 = 0.0211 + 0.0837 + 0.0070, time: 6.231993]
2023-05-13 15:43:31.951: epoch 156:	0.02661650  	0.19519418  	0.10889643  
2023-05-13 15:43:38.017: [iter 157 : loss : 0.1114 = 0.0208 + 0.0836 + 0.0070, time: 6.064878]
2023-05-13 15:43:38.169: epoch 157:	0.02665178  	0.19559926  	0.10909150  
2023-05-13 15:43:44.393: [iter 158 : loss : 0.1107 = 0.0201 + 0.0836 + 0.0070, time: 6.221222]
2023-05-13 15:43:44.545: epoch 158:	0.02660239  	0.19526283  	0.10893229  
2023-05-13 15:43:44.545: Early stopping is trigger at epoch: 158
2023-05-13 15:43:44.545: best_result@epoch 133:

2023-05-13 15:43:44.545: 		0.0269      	0.1978      	0.1092      
2023-05-13 15:48:31.656: my pid: 14316
2023-05-13 15:48:31.656: model: model.general_recommender.SGL
2023-05-13 15:48:31.656: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 15:48:31.656: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 15:48:34.895: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:48:42.362: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.466437]
2023-05-13 15:48:42.519: epoch 1:	0.00196162  	0.01356582  	0.00689553  
2023-05-13 15:48:42.519: Find a better model.
2023-05-13 15:48:49.952: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.432107]
2023-05-13 15:48:50.158: epoch 2:	0.00452298  	0.03183420  	0.01582556  
2023-05-13 15:48:50.158: Find a better model.
2023-05-13 15:48:57.840: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.680840]
2023-05-13 15:48:58.026: epoch 3:	0.00738069  	0.05300945  	0.02582289  
2023-05-13 15:48:58.026: Find a better model.
2023-05-13 15:49:07.530: my pid: 5640
2023-05-13 15:49:07.530: model: model.general_recommender.SGL
2023-05-13 15:49:07.530: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 15:49:07.530: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 15:49:10.600: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 15:49:18.529: [iter 1 : loss : 0.7721 = 0.6930 + 0.0791 + 0.0000, time: 7.929497]
2023-05-13 15:49:18.682: epoch 1:	0.00163703  	0.01222090  	0.00647027  
2023-05-13 15:49:18.683: Find a better model.
2023-05-13 15:49:26.755: [iter 2 : loss : 0.7718 = 0.6928 + 0.0790 + 0.0000, time: 8.069726]
2023-05-13 15:49:26.943: epoch 2:	0.00340106  	0.02517178  	0.01266448  
2023-05-13 15:49:26.944: Find a better model.
2023-05-13 15:49:34.932: [iter 3 : loss : 0.7715 = 0.6924 + 0.0791 + 0.0000, time: 7.987026]
2023-05-13 15:49:35.101: epoch 3:	0.00611765  	0.04548890  	0.02172093  
2023-05-13 15:49:35.101: Find a better model.
2023-05-13 15:49:42.916: [iter 4 : loss : 0.7710 = 0.6918 + 0.0793 + 0.0000, time: 7.814140]
2023-05-13 15:49:43.076: epoch 4:	0.00924351  	0.06807103  	0.03277893  
2023-05-13 15:49:43.076: Find a better model.
2023-05-13 15:49:50.810: [iter 5 : loss : 0.7699 = 0.6903 + 0.0796 + 0.0000, time: 7.731441]
2023-05-13 15:49:50.969: epoch 5:	0.01310339  	0.09608196  	0.04561374  
2023-05-13 15:49:50.969: Find a better model.
2023-05-13 15:49:58.551: [iter 6 : loss : 0.7671 = 0.6870 + 0.0800 + 0.0000, time: 7.581517]
2023-05-13 15:49:58.692: epoch 6:	0.01612354  	0.11668615  	0.05710157  
2023-05-13 15:49:58.692: Find a better model.
2023-05-13 15:50:06.091: [iter 7 : loss : 0.7596 = 0.6785 + 0.0810 + 0.0000, time: 7.397790]
2023-05-13 15:50:06.245: epoch 7:	0.01823341  	0.13343251  	0.06584804  
2023-05-13 15:50:06.245: Find a better model.
2023-05-13 15:50:13.593: [iter 8 : loss : 0.7413 = 0.6579 + 0.0833 + 0.0001, time: 7.346606]
2023-05-13 15:50:13.753: epoch 8:	0.01872736  	0.13736339  	0.06920335  
2023-05-13 15:50:13.753: Find a better model.
2023-05-13 15:50:20.996: [iter 9 : loss : 0.7015 = 0.6138 + 0.0876 + 0.0002, time: 7.241815]
2023-05-13 15:50:21.152: epoch 9:	0.01851567  	0.13763805  	0.06862479  
2023-05-13 15:50:21.152: Find a better model.
2023-05-13 15:50:28.558: [iter 10 : loss : 0.6368 = 0.5435 + 0.0930 + 0.0003, time: 7.404524]
2023-05-13 15:50:28.705: epoch 10:	0.01840276  	0.13663785  	0.06783857  
2023-05-13 15:50:36.099: [iter 11 : loss : 0.5618 = 0.4637 + 0.0977 + 0.0004, time: 7.393010]
2023-05-13 15:50:36.241: epoch 11:	0.01847333  	0.13703668  	0.06791030  
2023-05-13 15:50:43.466: [iter 12 : loss : 0.4963 = 0.3951 + 0.1006 + 0.0006, time: 7.223044]
2023-05-13 15:50:43.620: epoch 12:	0.01834632  	0.13563523  	0.06785963  
2023-05-13 15:50:50.684: [iter 13 : loss : 0.4485 = 0.3456 + 0.1022 + 0.0007, time: 7.063038]
2023-05-13 15:50:50.841: epoch 13:	0.01842393  	0.13664268  	0.06859976  
2023-05-13 15:50:58.067: [iter 14 : loss : 0.4122 = 0.3084 + 0.1030 + 0.0009, time: 7.225133]
2023-05-13 15:50:58.221: epoch 14:	0.01869207  	0.13834697  	0.06943854  
2023-05-13 15:50:58.221: Find a better model.
2023-05-13 15:51:05.260: [iter 15 : loss : 0.3866 = 0.2823 + 0.1033 + 0.0010, time: 7.036389]
2023-05-13 15:51:05.411: epoch 15:	0.01886849  	0.13991190  	0.07042013  
2023-05-13 15:51:05.412: Find a better model.
2023-05-13 15:51:12.807: [iter 16 : loss : 0.3650 = 0.2607 + 0.1032 + 0.0011, time: 7.394019]
2023-05-13 15:51:12.967: epoch 16:	0.01910136  	0.14165056  	0.07122885  
2023-05-13 15:51:12.968: Find a better model.
2023-05-13 15:51:20.052: [iter 17 : loss : 0.3490 = 0.2448 + 0.1029 + 0.0012, time: 7.083219]
2023-05-13 15:51:20.204: epoch 17:	0.01929894  	0.14292344  	0.07194879  
2023-05-13 15:51:20.204: Find a better model.
2023-05-13 15:51:27.287: [iter 18 : loss : 0.3342 = 0.2301 + 0.1027 + 0.0013, time: 7.080560]
2023-05-13 15:51:27.442: epoch 18:	0.01960943  	0.14486566  	0.07303979  
2023-05-13 15:51:27.442: Find a better model.
2023-05-13 15:51:34.626: [iter 19 : loss : 0.3202 = 0.2164 + 0.1024 + 0.0014, time: 7.182041]
2023-05-13 15:51:34.781: epoch 19:	0.01965883  	0.14552093  	0.07375500  
2023-05-13 15:51:34.781: Find a better model.
2023-05-13 15:51:42.108: [iter 20 : loss : 0.3107 = 0.2073 + 0.1019 + 0.0015, time: 7.325222]
2023-05-13 15:51:42.255: epoch 20:	0.01980701  	0.14676315  	0.07445916  
2023-05-13 15:51:42.255: Find a better model.
2023-05-13 15:51:49.554: [iter 21 : loss : 0.3012 = 0.1981 + 0.1015 + 0.0016, time: 7.297418]
2023-05-13 15:51:49.701: epoch 21:	0.02006106  	0.14853337  	0.07544800  
2023-05-13 15:51:49.701: Find a better model.
2023-05-13 15:51:56.939: [iter 22 : loss : 0.2929 = 0.1901 + 0.1011 + 0.0017, time: 7.236856]
2023-05-13 15:51:57.084: epoch 22:	0.02029392  	0.14972331  	0.07626905  
2023-05-13 15:51:57.084: Find a better model.
2023-05-13 15:52:04.318: [iter 23 : loss : 0.2847 = 0.1823 + 0.1007 + 0.0017, time: 7.232631]
2023-05-13 15:52:04.473: epoch 23:	0.02052678  	0.15137699  	0.07719214  
2023-05-13 15:52:04.473: Find a better model.
2023-05-13 15:52:11.627: [iter 24 : loss : 0.2783 = 0.1763 + 0.1002 + 0.0018, time: 7.152409]
2023-05-13 15:52:11.780: epoch 24:	0.02079493  	0.15357503  	0.07811607  
2023-05-13 15:52:11.781: Find a better model.
2023-05-13 15:52:18.837: [iter 25 : loss : 0.2716 = 0.1699 + 0.0998 + 0.0019, time: 7.053541]
2023-05-13 15:52:18.991: epoch 25:	0.02083021  	0.15390675  	0.07836606  
2023-05-13 15:52:18.991: Find a better model.
2023-05-13 15:52:26.045: [iter 26 : loss : 0.2683 = 0.1669 + 0.0994 + 0.0019, time: 7.053010]
2023-05-13 15:52:26.197: epoch 26:	0.02107719  	0.15578184  	0.07912634  
2023-05-13 15:52:26.198: Find a better model.
2023-05-13 15:52:33.241: [iter 27 : loss : 0.2604 = 0.1595 + 0.0990 + 0.0020, time: 7.042210]
2023-05-13 15:52:33.394: epoch 27:	0.02117598  	0.15692107  	0.07964679  
2023-05-13 15:52:33.394: Find a better model.
2023-05-13 15:52:40.438: [iter 28 : loss : 0.2556 = 0.1549 + 0.0986 + 0.0021, time: 7.042804]
2023-05-13 15:52:40.592: epoch 28:	0.02139474  	0.15825942  	0.08047134  
2023-05-13 15:52:40.592: Find a better model.
2023-05-13 15:52:47.631: [iter 29 : loss : 0.2510 = 0.1507 + 0.0982 + 0.0021, time: 7.038352]
2023-05-13 15:52:47.783: epoch 29:	0.02150059  	0.15877406  	0.08099715  
2023-05-13 15:52:47.783: Find a better model.
2023-05-13 15:52:54.830: [iter 30 : loss : 0.2446 = 0.1446 + 0.0978 + 0.0022, time: 7.045441]
2023-05-13 15:52:54.982: epoch 30:	0.02162761  	0.15977123  	0.08162178  
2023-05-13 15:52:54.983: Find a better model.
2023-05-13 15:53:02.028: [iter 31 : loss : 0.2411 = 0.1414 + 0.0974 + 0.0023, time: 7.043633]
2023-05-13 15:53:02.179: epoch 31:	0.02175462  	0.16088803  	0.08217839  
2023-05-13 15:53:02.179: Find a better model.
2023-05-13 15:53:09.395: [iter 32 : loss : 0.2355 = 0.1361 + 0.0970 + 0.0023, time: 7.214571]
2023-05-13 15:53:09.548: epoch 32:	0.02201571  	0.16324896  	0.08312366  
2023-05-13 15:53:09.549: Find a better model.
2023-05-13 15:53:16.807: [iter 33 : loss : 0.2329 = 0.1338 + 0.0967 + 0.0024, time: 7.257512]
2023-05-13 15:53:16.959: epoch 33:	0.02210744  	0.16337083  	0.08365773  
2023-05-13 15:53:16.960: Find a better model.
2023-05-13 15:53:24.195: [iter 34 : loss : 0.2287 = 0.1299 + 0.0963 + 0.0024, time: 7.233638]
2023-05-13 15:53:24.351: epoch 34:	0.02226269  	0.16457963  	0.08451891  
2023-05-13 15:53:24.351: Find a better model.
2023-05-13 15:53:31.593: [iter 35 : loss : 0.2255 = 0.1270 + 0.0960 + 0.0025, time: 7.241457]
2023-05-13 15:53:31.747: epoch 35:	0.02241087  	0.16597854  	0.08529168  
2023-05-13 15:53:31.748: Find a better model.
2023-05-13 15:53:39.001: [iter 36 : loss : 0.2219 = 0.1236 + 0.0957 + 0.0025, time: 7.251969]
2023-05-13 15:53:39.152: epoch 36:	0.02260845  	0.16719183  	0.08606751  
2023-05-13 15:53:39.152: Find a better model.
2023-05-13 15:53:46.213: [iter 37 : loss : 0.2181 = 0.1201 + 0.0954 + 0.0026, time: 7.059000]
2023-05-13 15:53:46.366: epoch 37:	0.02272840  	0.16792746  	0.08664887  
2023-05-13 15:53:46.366: Find a better model.
2023-05-13 15:53:53.596: [iter 38 : loss : 0.2164 = 0.1187 + 0.0951 + 0.0026, time: 7.228654]
2023-05-13 15:53:53.748: epoch 38:	0.02282719  	0.16828625  	0.08724282  
2023-05-13 15:53:53.748: Find a better model.
2023-05-13 15:54:00.812: [iter 39 : loss : 0.2119 = 0.1144 + 0.0948 + 0.0027, time: 7.061498]
2023-05-13 15:54:00.965: epoch 39:	0.02296832  	0.16940594  	0.08795695  
2023-05-13 15:54:00.965: Find a better model.
2023-05-13 15:54:08.185: [iter 40 : loss : 0.2089 = 0.1116 + 0.0945 + 0.0028, time: 7.218360]
2023-05-13 15:54:08.340: epoch 40:	0.02304594  	0.16992299  	0.08847310  
2023-05-13 15:54:08.341: Find a better model.
2023-05-13 15:54:15.411: [iter 41 : loss : 0.2071 = 0.1101 + 0.0942 + 0.0028, time: 7.068505]
2023-05-13 15:54:15.562: epoch 41:	0.02303888  	0.16995698  	0.08875363  
2023-05-13 15:54:15.563: Find a better model.
2023-05-13 15:54:22.601: [iter 42 : loss : 0.2049 = 0.1082 + 0.0939 + 0.0029, time: 7.037559]
2023-05-13 15:54:22.754: epoch 42:	0.02327881  	0.17217945  	0.08968588  
2023-05-13 15:54:22.755: Find a better model.
2023-05-13 15:54:29.785: [iter 43 : loss : 0.2010 = 0.1045 + 0.0936 + 0.0029, time: 7.027337]
2023-05-13 15:54:29.927: epoch 43:	0.02340582  	0.17275429  	0.09019653  
2023-05-13 15:54:29.927: Find a better model.
2023-05-13 15:54:36.982: [iter 44 : loss : 0.1974 = 0.1011 + 0.0934 + 0.0030, time: 7.054609]
2023-05-13 15:54:37.140: epoch 44:	0.02348345  	0.17325640  	0.09068633  
2023-05-13 15:54:37.140: Find a better model.
2023-05-13 15:54:44.367: [iter 45 : loss : 0.1956 = 0.0995 + 0.0931 + 0.0030, time: 7.225589]
2023-05-13 15:54:44.521: epoch 45:	0.02351873  	0.17328194  	0.09113018  
2023-05-13 15:54:44.522: Find a better model.
2023-05-13 15:54:51.594: [iter 46 : loss : 0.1931 = 0.0972 + 0.0928 + 0.0031, time: 7.071202]
2023-05-13 15:54:51.745: epoch 46:	0.02365986  	0.17424390  	0.09168357  
2023-05-13 15:54:51.746: Find a better model.
2023-05-13 15:54:58.784: [iter 47 : loss : 0.1923 = 0.0965 + 0.0927 + 0.0031, time: 7.037525]
2023-05-13 15:54:58.925: epoch 47:	0.02367398  	0.17467974  	0.09204622  
2023-05-13 15:54:58.925: Find a better model.
2023-05-13 15:55:05.981: [iter 48 : loss : 0.1887 = 0.0930 + 0.0925 + 0.0032, time: 7.054790]
2023-05-13 15:55:06.140: epoch 48:	0.02375865  	0.17563684  	0.09260093  
2023-05-13 15:55:06.140: Find a better model.
2023-05-13 15:55:13.176: [iter 49 : loss : 0.1851 = 0.0897 + 0.0923 + 0.0032, time: 7.033676]
2023-05-13 15:55:13.316: epoch 49:	0.02376571  	0.17541927  	0.09291573  
2023-05-13 15:55:20.368: [iter 50 : loss : 0.1847 = 0.0894 + 0.0920 + 0.0033, time: 7.051753]
2023-05-13 15:55:20.521: epoch 50:	0.02387862  	0.17648177  	0.09356503  
2023-05-13 15:55:20.521: Find a better model.
2023-05-13 15:55:27.765: [iter 51 : loss : 0.1817 = 0.0866 + 0.0918 + 0.0033, time: 7.242413]
2023-05-13 15:55:27.905: epoch 51:	0.02391390  	0.17676927  	0.09377772  
2023-05-13 15:55:27.905: Find a better model.
2023-05-13 15:55:35.142: [iter 52 : loss : 0.1815 = 0.0865 + 0.0916 + 0.0033, time: 7.235571]
2023-05-13 15:55:35.297: epoch 52:	0.02417498  	0.17876935  	0.09449443  
2023-05-13 15:55:35.297: Find a better model.
2023-05-13 15:55:42.370: [iter 53 : loss : 0.1794 = 0.0846 + 0.0914 + 0.0034, time: 7.071088]
2023-05-13 15:55:42.522: epoch 53:	0.02428789  	0.17960234  	0.09508571  
2023-05-13 15:55:42.522: Find a better model.
2023-05-13 15:55:49.738: [iter 54 : loss : 0.1773 = 0.0826 + 0.0912 + 0.0034, time: 7.214546]
2023-05-13 15:55:49.893: epoch 54:	0.02442902  	0.18062422  	0.09550709  
2023-05-13 15:55:49.893: Find a better model.
2023-05-13 15:55:56.959: [iter 55 : loss : 0.1753 = 0.0808 + 0.0910 + 0.0035, time: 7.064745]
2023-05-13 15:55:57.110: epoch 55:	0.02445018  	0.18090227  	0.09601380  
2023-05-13 15:55:57.110: Find a better model.
2023-05-13 15:56:04.328: [iter 56 : loss : 0.1739 = 0.0795 + 0.0908 + 0.0035, time: 7.217085]
2023-05-13 15:56:04.469: epoch 56:	0.02447841  	0.18114583  	0.09645233  
2023-05-13 15:56:04.469: Find a better model.
2023-05-13 15:56:11.559: [iter 57 : loss : 0.1718 = 0.0776 + 0.0906 + 0.0036, time: 7.088368]
2023-05-13 15:56:11.711: epoch 57:	0.02453486  	0.18143910  	0.09670602  
2023-05-13 15:56:11.711: Find a better model.
2023-05-13 15:56:18.936: [iter 58 : loss : 0.1700 = 0.0759 + 0.0905 + 0.0036, time: 7.224080]
2023-05-13 15:56:19.078: epoch 58:	0.02463365  	0.18234357  	0.09721847  
2023-05-13 15:56:19.078: Find a better model.
2023-05-13 15:56:26.158: [iter 59 : loss : 0.1689 = 0.0749 + 0.0903 + 0.0037, time: 7.076880]
2023-05-13 15:56:26.301: epoch 59:	0.02466187  	0.18272084  	0.09739274  
2023-05-13 15:56:26.301: Find a better model.
2023-05-13 15:56:33.360: [iter 60 : loss : 0.1674 = 0.0736 + 0.0902 + 0.0037, time: 7.056823]
2023-05-13 15:56:33.511: epoch 60:	0.02478183  	0.18327489  	0.09788737  
2023-05-13 15:56:33.511: Find a better model.
2023-05-13 15:56:40.748: [iter 61 : loss : 0.1660 = 0.0723 + 0.0899 + 0.0038, time: 7.236104]
2023-05-13 15:56:40.901: epoch 61:	0.02481711  	0.18367127  	0.09812647  
2023-05-13 15:56:40.901: Find a better model.
2023-05-13 15:56:48.138: [iter 62 : loss : 0.1643 = 0.0707 + 0.0898 + 0.0038, time: 7.236040]
2023-05-13 15:56:48.291: epoch 62:	0.02492296  	0.18449625  	0.09860078  
2023-05-13 15:56:48.291: Find a better model.
2023-05-13 15:56:55.518: [iter 63 : loss : 0.1634 = 0.0699 + 0.0897 + 0.0038, time: 7.225810]
2023-05-13 15:56:55.669: epoch 63:	0.02488062  	0.18413788  	0.09876528  
2023-05-13 15:57:02.924: [iter 64 : loss : 0.1619 = 0.0685 + 0.0894 + 0.0039, time: 7.253388]
2023-05-13 15:57:03.066: epoch 64:	0.02500764  	0.18497853  	0.09919228  
2023-05-13 15:57:03.066: Find a better model.
2023-05-13 15:57:10.322: [iter 65 : loss : 0.1608 = 0.0676 + 0.0893 + 0.0039, time: 7.255612]
2023-05-13 15:57:10.475: epoch 65:	0.02500763  	0.18461709  	0.09926272  
2023-05-13 15:57:17.732: [iter 66 : loss : 0.1591 = 0.0660 + 0.0892 + 0.0040, time: 7.256041]
2023-05-13 15:57:17.883: epoch 66:	0.02504997  	0.18497933  	0.09978283  
2023-05-13 15:57:17.884: Find a better model.
2023-05-13 15:57:24.931: [iter 67 : loss : 0.1577 = 0.0646 + 0.0890 + 0.0040, time: 7.045604]
2023-05-13 15:57:25.082: epoch 67:	0.02510642  	0.18528320  	0.10018858  
2023-05-13 15:57:25.082: Find a better model.
2023-05-13 15:57:32.322: [iter 68 : loss : 0.1574 = 0.0645 + 0.0889 + 0.0041, time: 7.238608]
2023-05-13 15:57:32.476: epoch 68:	0.02514170  	0.18548550  	0.10049693  
2023-05-13 15:57:32.477: Find a better model.
2023-05-13 15:57:39.530: [iter 69 : loss : 0.1556 = 0.0627 + 0.0888 + 0.0041, time: 7.052552]
2023-05-13 15:57:39.683: epoch 69:	0.02519110  	0.18564492  	0.10076764  
2023-05-13 15:57:39.683: Find a better model.
2023-05-13 15:57:46.897: [iter 70 : loss : 0.1537 = 0.0609 + 0.0886 + 0.0041, time: 7.213644]
2023-05-13 15:57:47.050: epoch 70:	0.02520521  	0.18619625  	0.10093324  
2023-05-13 15:57:47.050: Find a better model.
2023-05-13 15:57:54.131: [iter 71 : loss : 0.1525 = 0.0598 + 0.0885 + 0.0042, time: 7.079868]
2023-05-13 15:57:54.283: epoch 71:	0.02524755  	0.18636796  	0.10115459  
2023-05-13 15:57:54.283: Find a better model.
2023-05-13 15:58:01.487: [iter 72 : loss : 0.1523 = 0.0597 + 0.0884 + 0.0042, time: 7.201172]
2023-05-13 15:58:01.650: epoch 72:	0.02533223  	0.18723238  	0.10141891  
2023-05-13 15:58:01.650: Find a better model.
2023-05-13 15:58:08.726: [iter 73 : loss : 0.1507 = 0.0582 + 0.0882 + 0.0043, time: 7.074692]
2023-05-13 15:58:08.879: epoch 73:	0.02540985  	0.18773147  	0.10171149  
2023-05-13 15:58:08.879: Find a better model.
2023-05-13 15:58:16.108: [iter 74 : loss : 0.1492 = 0.0567 + 0.0881 + 0.0043, time: 7.228244]
2023-05-13 15:58:16.249: epoch 74:	0.02550864  	0.18829830  	0.10207848  
2023-05-13 15:58:16.249: Find a better model.
2023-05-13 15:58:23.299: [iter 75 : loss : 0.1488 = 0.0564 + 0.0881 + 0.0043, time: 7.048352]
2023-05-13 15:58:23.443: epoch 75:	0.02551570  	0.18853459  	0.10234743  
2023-05-13 15:58:23.443: Find a better model.
2023-05-13 15:58:30.518: [iter 76 : loss : 0.1478 = 0.0555 + 0.0879 + 0.0044, time: 7.073978]
2023-05-13 15:58:30.668: epoch 76:	0.02562155  	0.18936096  	0.10283702  
2023-05-13 15:58:30.668: Find a better model.
2023-05-13 15:58:37.720: [iter 77 : loss : 0.1467 = 0.0545 + 0.0878 + 0.0044, time: 7.051028]
2023-05-13 15:58:37.873: epoch 77:	0.02569212  	0.18978740  	0.10305185  
2023-05-13 15:58:37.873: Find a better model.
2023-05-13 15:58:45.075: [iter 78 : loss : 0.1459 = 0.0538 + 0.0877 + 0.0045, time: 7.201112]
2023-05-13 15:58:45.231: epoch 78:	0.02581913  	0.19045308  	0.10340188  
2023-05-13 15:58:45.231: Find a better model.
2023-05-13 15:58:52.310: [iter 79 : loss : 0.1446 = 0.0525 + 0.0876 + 0.0045, time: 7.078284]
2023-05-13 15:58:52.466: epoch 79:	0.02584735  	0.19053440  	0.10351925  
2023-05-13 15:58:52.466: Find a better model.
2023-05-13 15:58:59.675: [iter 80 : loss : 0.1441 = 0.0520 + 0.0876 + 0.0045, time: 7.207720]
2023-05-13 15:58:59.830: epoch 80:	0.02591086  	0.19119485  	0.10376442  
2023-05-13 15:58:59.830: Find a better model.
2023-05-13 15:59:06.908: [iter 81 : loss : 0.1436 = 0.0516 + 0.0874 + 0.0046, time: 7.077493]
2023-05-13 15:59:07.060: epoch 81:	0.02589674  	0.19103818  	0.10383555  
2023-05-13 15:59:14.269: [iter 82 : loss : 0.1424 = 0.0505 + 0.0873 + 0.0046, time: 7.208342]
2023-05-13 15:59:14.426: epoch 82:	0.02586146  	0.19054538  	0.10377350  
2023-05-13 15:59:21.501: [iter 83 : loss : 0.1414 = 0.0496 + 0.0872 + 0.0047, time: 7.074161]
2023-05-13 15:59:21.652: epoch 83:	0.02591792  	0.19094880  	0.10409732  
2023-05-13 15:59:28.695: [iter 84 : loss : 0.1412 = 0.0494 + 0.0871 + 0.0047, time: 7.040402]
2023-05-13 15:59:28.848: epoch 84:	0.02602377  	0.19183610  	0.10451384  
2023-05-13 15:59:28.848: Find a better model.
2023-05-13 15:59:35.893: [iter 85 : loss : 0.1402 = 0.0485 + 0.0870 + 0.0047, time: 7.044037]
2023-05-13 15:59:36.045: epoch 85:	0.02600965  	0.19150372  	0.10455343  
2023-05-13 15:59:43.085: [iter 86 : loss : 0.1402 = 0.0486 + 0.0869 + 0.0048, time: 7.038051]
2023-05-13 15:59:43.227: epoch 86:	0.02603788  	0.19189873  	0.10481895  
2023-05-13 15:59:43.227: Find a better model.
2023-05-13 15:59:50.269: [iter 87 : loss : 0.1375 = 0.0459 + 0.0868 + 0.0048, time: 7.041550]
2023-05-13 15:59:50.427: epoch 87:	0.02604494  	0.19172105  	0.10499907  
2023-05-13 15:59:57.480: [iter 88 : loss : 0.1367 = 0.0451 + 0.0867 + 0.0048, time: 7.051803]
2023-05-13 15:59:57.633: epoch 88:	0.02608021  	0.19190417  	0.10525737  
2023-05-13 15:59:57.634: Find a better model.
2023-05-13 16:00:04.669: [iter 89 : loss : 0.1365 = 0.0450 + 0.0866 + 0.0049, time: 7.032984]
2023-05-13 16:00:04.811: epoch 89:	0.02615783  	0.19257265  	0.10564367  
2023-05-13 16:00:04.811: Find a better model.
2023-05-13 16:00:11.875: [iter 90 : loss : 0.1370 = 0.0455 + 0.0865 + 0.0049, time: 7.063545]
2023-05-13 16:00:12.027: epoch 90:	0.02615078  	0.19255334  	0.10567499  
2023-05-13 16:00:19.059: [iter 91 : loss : 0.1358 = 0.0444 + 0.0864 + 0.0050, time: 7.030160]
2023-05-13 16:00:19.199: epoch 91:	0.02617194  	0.19257726  	0.10578579  
2023-05-13 16:00:19.200: Find a better model.
2023-05-13 16:00:26.249: [iter 92 : loss : 0.1349 = 0.0435 + 0.0864 + 0.0050, time: 7.048001]
2023-05-13 16:00:26.401: epoch 92:	0.02617195  	0.19284175  	0.10593058  
2023-05-13 16:00:26.401: Find a better model.
2023-05-13 16:00:33.475: [iter 93 : loss : 0.1349 = 0.0436 + 0.0863 + 0.0050, time: 7.072954]
2023-05-13 16:00:33.630: epoch 93:	0.02620723  	0.19331978  	0.10612970  
2023-05-13 16:00:33.630: Find a better model.
2023-05-13 16:00:40.674: [iter 94 : loss : 0.1329 = 0.0416 + 0.0862 + 0.0051, time: 7.041929]
2023-05-13 16:00:40.824: epoch 94:	0.02619311  	0.19329531  	0.10629663  
2023-05-13 16:00:47.872: [iter 95 : loss : 0.1324 = 0.0411 + 0.0861 + 0.0051, time: 7.046948]
2023-05-13 16:00:48.026: epoch 95:	0.02609432  	0.19249812  	0.10626911  
2023-05-13 16:00:55.061: [iter 96 : loss : 0.1324 = 0.0412 + 0.0861 + 0.0051, time: 7.033813]
2023-05-13 16:00:55.203: epoch 96:	0.02621429  	0.19288269  	0.10663840  
2023-05-13 16:01:02.247: [iter 97 : loss : 0.1305 = 0.0394 + 0.0860 + 0.0052, time: 7.042833]
2023-05-13 16:01:02.389: epoch 97:	0.02623545  	0.19316354  	0.10673561  
2023-05-13 16:01:09.450: [iter 98 : loss : 0.1319 = 0.0408 + 0.0859 + 0.0052, time: 7.060042]
2023-05-13 16:01:09.603: epoch 98:	0.02630601  	0.19366024  	0.10701974  
2023-05-13 16:01:09.603: Find a better model.
2023-05-13 16:01:16.651: [iter 99 : loss : 0.1304 = 0.0394 + 0.0858 + 0.0052, time: 7.047091]
2023-05-13 16:01:16.804: epoch 99:	0.02635541  	0.19398147  	0.10716547  
2023-05-13 16:01:16.804: Find a better model.
2023-05-13 16:01:23.830: [iter 100 : loss : 0.1297 = 0.0387 + 0.0857 + 0.0053, time: 7.025515]
2023-05-13 16:01:23.971: epoch 100:	0.02636248  	0.19426198  	0.10735181  
2023-05-13 16:01:23.972: Find a better model.
2023-05-13 16:01:31.040: [iter 101 : loss : 0.1296 = 0.0386 + 0.0857 + 0.0053, time: 7.066839]
2023-05-13 16:01:31.196: epoch 101:	0.02634130  	0.19451638  	0.10731946  
2023-05-13 16:01:31.196: Find a better model.
2023-05-13 16:01:38.265: [iter 102 : loss : 0.1282 = 0.0372 + 0.0856 + 0.0053, time: 7.068004]
2023-05-13 16:01:38.418: epoch 102:	0.02634836  	0.19436793  	0.10740617  
2023-05-13 16:01:45.441: [iter 103 : loss : 0.1281 = 0.0371 + 0.0856 + 0.0054, time: 7.022280]
2023-05-13 16:01:45.597: epoch 103:	0.02641892  	0.19476978  	0.10769113  
2023-05-13 16:01:45.597: Find a better model.
2023-05-13 16:01:52.648: [iter 104 : loss : 0.1285 = 0.0376 + 0.0855 + 0.0054, time: 7.049786]
2023-05-13 16:01:52.803: epoch 104:	0.02646832  	0.19535694  	0.10778713  
2023-05-13 16:01:52.803: Find a better model.
2023-05-13 16:01:59.859: [iter 105 : loss : 0.1278 = 0.0370 + 0.0854 + 0.0055, time: 7.055821]
2023-05-13 16:02:00.012: epoch 105:	0.02641186  	0.19499737  	0.10767423  
2023-05-13 16:02:07.028: [iter 106 : loss : 0.1274 = 0.0365 + 0.0854 + 0.0055, time: 7.013348]
2023-05-13 16:02:07.182: epoch 106:	0.02645421  	0.19514154  	0.10774061  
2023-05-13 16:02:14.229: [iter 107 : loss : 0.1264 = 0.0355 + 0.0853 + 0.0055, time: 7.046483]
2023-05-13 16:02:14.371: epoch 107:	0.02647538  	0.19513120  	0.10784926  
2023-05-13 16:02:21.432: [iter 108 : loss : 0.1264 = 0.0356 + 0.0852 + 0.0055, time: 7.059498]
2023-05-13 16:02:21.589: epoch 108:	0.02644010  	0.19503126  	0.10790177  
2023-05-13 16:02:28.632: [iter 109 : loss : 0.1249 = 0.0341 + 0.0852 + 0.0056, time: 7.042350]
2023-05-13 16:02:28.785: epoch 109:	0.02646832  	0.19527377  	0.10794831  
2023-05-13 16:02:35.818: [iter 110 : loss : 0.1240 = 0.0333 + 0.0851 + 0.0056, time: 7.032231]
2023-05-13 16:02:35.971: epoch 110:	0.02641893  	0.19501156  	0.10795926  
2023-05-13 16:02:43.024: [iter 111 : loss : 0.1243 = 0.0336 + 0.0850 + 0.0057, time: 7.051119]
2023-05-13 16:02:43.178: epoch 111:	0.02646832  	0.19523178  	0.10810627  
2023-05-13 16:02:50.228: [iter 112 : loss : 0.1243 = 0.0336 + 0.0850 + 0.0057, time: 7.048097]
2023-05-13 16:02:50.368: epoch 112:	0.02650360  	0.19525184  	0.10829895  
2023-05-13 16:02:57.415: [iter 113 : loss : 0.1240 = 0.0333 + 0.0850 + 0.0057, time: 7.046150]
2023-05-13 16:02:57.566: epoch 113:	0.02651772  	0.19529210  	0.10818122  
2023-05-13 16:03:04.616: [iter 114 : loss : 0.1231 = 0.0325 + 0.0849 + 0.0057, time: 7.049216]
2023-05-13 16:03:04.769: epoch 114:	0.02652477  	0.19541824  	0.10821824  
2023-05-13 16:03:04.770: Find a better model.
2023-05-13 16:03:11.809: [iter 115 : loss : 0.1226 = 0.0320 + 0.0848 + 0.0058, time: 7.037548]
2023-05-13 16:03:11.954: epoch 115:	0.02657417  	0.19560134  	0.10836573  
2023-05-13 16:03:11.955: Find a better model.
2023-05-13 16:03:19.005: [iter 116 : loss : 0.1219 = 0.0313 + 0.0848 + 0.0058, time: 7.049695]
2023-05-13 16:03:19.157: epoch 116:	0.02656711  	0.19555494  	0.10833514  
2023-05-13 16:03:26.188: [iter 117 : loss : 0.1216 = 0.0311 + 0.0847 + 0.0059, time: 7.029972]
2023-05-13 16:03:26.342: epoch 117:	0.02658122  	0.19563489  	0.10837128  
2023-05-13 16:03:26.342: Find a better model.
2023-05-13 16:03:33.407: [iter 118 : loss : 0.1217 = 0.0312 + 0.0847 + 0.0059, time: 7.064779]
2023-05-13 16:03:33.548: epoch 118:	0.02660945  	0.19595489  	0.10863759  
2023-05-13 16:03:33.548: Find a better model.
2023-05-13 16:03:40.586: [iter 119 : loss : 0.1209 = 0.0303 + 0.0846 + 0.0059, time: 7.037117]
2023-05-13 16:03:40.741: epoch 119:	0.02654594  	0.19530433  	0.10872097  
2023-05-13 16:03:47.814: [iter 120 : loss : 0.1209 = 0.0304 + 0.0846 + 0.0059, time: 7.071574]
2023-05-13 16:03:47.967: epoch 120:	0.02656711  	0.19544347  	0.10888611  
2023-05-13 16:03:55.000: [iter 121 : loss : 0.1208 = 0.0303 + 0.0845 + 0.0060, time: 7.031533]
2023-05-13 16:03:55.152: epoch 121:	0.02652477  	0.19520107  	0.10896336  
2023-05-13 16:04:02.178: [iter 122 : loss : 0.1199 = 0.0295 + 0.0845 + 0.0060, time: 7.025127]
2023-05-13 16:04:02.336: epoch 122:	0.02651772  	0.19481474  	0.10890058  
2023-05-13 16:04:09.385: [iter 123 : loss : 0.1199 = 0.0294 + 0.0844 + 0.0060, time: 7.048419]
2023-05-13 16:04:09.536: epoch 123:	0.02648949  	0.19442555  	0.10869345  
2023-05-13 16:04:16.389: [iter 124 : loss : 0.1190 = 0.0285 + 0.0844 + 0.0061, time: 6.852089]
2023-05-13 16:04:16.542: epoch 124:	0.02656006  	0.19482796  	0.10886591  
2023-05-13 16:04:23.570: [iter 125 : loss : 0.1186 = 0.0282 + 0.0843 + 0.0061, time: 7.026138]
2023-05-13 16:04:23.723: epoch 125:	0.02658122  	0.19544208  	0.10897017  
2023-05-13 16:04:30.579: [iter 126 : loss : 0.1185 = 0.0281 + 0.0843 + 0.0061, time: 6.854848]
2023-05-13 16:04:30.719: epoch 126:	0.02660945  	0.19564210  	0.10899016  
2023-05-13 16:04:37.583: [iter 127 : loss : 0.1175 = 0.0272 + 0.0842 + 0.0062, time: 6.862998]
2023-05-13 16:04:37.723: epoch 127:	0.02656005  	0.19499426  	0.10898361  
2023-05-13 16:04:44.775: [iter 128 : loss : 0.1188 = 0.0284 + 0.0842 + 0.0062, time: 7.050488]
2023-05-13 16:04:44.921: epoch 128:	0.02663061  	0.19551031  	0.10916159  
2023-05-13 16:04:51.962: [iter 129 : loss : 0.1178 = 0.0275 + 0.0841 + 0.0062, time: 7.040119]
2023-05-13 16:04:52.119: epoch 129:	0.02655299  	0.19480000  	0.10905946  
2023-05-13 16:04:59.159: [iter 130 : loss : 0.1179 = 0.0276 + 0.0841 + 0.0062, time: 7.038325]
2023-05-13 16:04:59.302: epoch 130:	0.02660238  	0.19527425  	0.10917069  
2023-05-13 16:05:06.179: [iter 131 : loss : 0.1170 = 0.0267 + 0.0840 + 0.0063, time: 6.876735]
2023-05-13 16:05:06.334: epoch 131:	0.02651771  	0.19476365  	0.10896753  
2023-05-13 16:05:13.369: [iter 132 : loss : 0.1171 = 0.0268 + 0.0840 + 0.0063, time: 7.032600]
2023-05-13 16:05:13.522: epoch 132:	0.02653887  	0.19494860  	0.10902639  
2023-05-13 16:05:20.561: [iter 133 : loss : 0.1161 = 0.0258 + 0.0840 + 0.0063, time: 7.038104]
2023-05-13 16:05:20.702: epoch 133:	0.02656005  	0.19509220  	0.10912915  
2023-05-13 16:05:27.758: [iter 134 : loss : 0.1166 = 0.0263 + 0.0840 + 0.0064, time: 7.054669]
2023-05-13 16:05:27.912: epoch 134:	0.02656710  	0.19510952  	0.10938712  
2023-05-13 16:05:34.974: [iter 135 : loss : 0.1164 = 0.0261 + 0.0839 + 0.0064, time: 7.059985]
2023-05-13 16:05:35.129: epoch 135:	0.02659533  	0.19511630  	0.10947507  
2023-05-13 16:05:42.138: [iter 136 : loss : 0.1160 = 0.0258 + 0.0838 + 0.0064, time: 7.007680]
2023-05-13 16:05:42.289: epoch 136:	0.02652476  	0.19494121  	0.10943963  
2023-05-13 16:05:49.169: [iter 137 : loss : 0.1156 = 0.0254 + 0.0838 + 0.0065, time: 6.877707]
2023-05-13 16:05:49.322: epoch 137:	0.02655299  	0.19517024  	0.10944584  
2023-05-13 16:05:56.344: [iter 138 : loss : 0.1153 = 0.0250 + 0.0838 + 0.0065, time: 7.021196]
2023-05-13 16:05:56.498: epoch 138:	0.02654593  	0.19493730  	0.10947312  
2023-05-13 16:06:03.548: [iter 139 : loss : 0.1151 = 0.0248 + 0.0837 + 0.0065, time: 7.047918]
2023-05-13 16:06:03.689: epoch 139:	0.02652477  	0.19530870  	0.10972530  
2023-05-13 16:06:10.725: [iter 140 : loss : 0.1144 = 0.0242 + 0.0837 + 0.0065, time: 7.033617]
2023-05-13 16:06:10.880: epoch 140:	0.02641186  	0.19421855  	0.10910414  
2023-05-13 16:06:17.757: [iter 141 : loss : 0.1149 = 0.0247 + 0.0836 + 0.0066, time: 6.876213]
2023-05-13 16:06:17.908: epoch 141:	0.02647537  	0.19444120  	0.10915835  
2023-05-13 16:06:24.946: [iter 142 : loss : 0.1140 = 0.0238 + 0.0836 + 0.0066, time: 7.035603]
2023-05-13 16:06:25.098: epoch 142:	0.02650359  	0.19478284  	0.10940232  
2023-05-13 16:06:31.948: [iter 143 : loss : 0.1140 = 0.0238 + 0.0836 + 0.0066, time: 6.849841]
2023-05-13 16:06:32.102: epoch 143:	0.02652477  	0.19484936  	0.10944865  
2023-05-13 16:06:32.102: Early stopping is trigger at epoch: 143
2023-05-13 16:06:32.102: best_result@epoch 118:

2023-05-13 16:06:32.102: 		0.0266      	0.1960      	0.1086      
2023-05-13 18:09:13.338: my pid: 6688
2023-05-13 18:09:13.338: model: model.general_recommender.SGL
2023-05-13 18:09:13.338: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 18:09:13.338: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 18:09:16.383: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 18:09:24.412: [iter 1 : loss : 0.7721 = 0.6930 + 0.0791 + 0.0000, time: 8.028380]
2023-05-13 18:09:24.567: epoch 1:	0.00163703  	0.01222090  	0.00647027  
2023-05-13 18:09:24.567: Find a better model.
2023-05-13 18:09:32.701: [iter 2 : loss : 0.7718 = 0.6928 + 0.0790 + 0.0000, time: 8.132948]
2023-05-13 18:09:32.876: epoch 2:	0.00340106  	0.02517178  	0.01266448  
2023-05-13 18:09:32.876: Find a better model.
2023-05-13 18:09:40.853: [iter 3 : loss : 0.7715 = 0.6924 + 0.0791 + 0.0000, time: 7.974136]
2023-05-13 18:09:41.017: epoch 3:	0.00611765  	0.04548890  	0.02172093  
2023-05-13 18:09:41.017: Find a better model.
2023-05-13 18:09:48.848: [iter 4 : loss : 0.7710 = 0.6918 + 0.0793 + 0.0000, time: 7.829380]
2023-05-13 18:09:48.994: epoch 4:	0.00924351  	0.06807103  	0.03277893  
2023-05-13 18:09:48.994: Find a better model.
2023-05-13 18:09:56.625: [iter 5 : loss : 0.7699 = 0.6903 + 0.0796 + 0.0000, time: 7.629609]
2023-05-13 18:09:56.781: epoch 5:	0.01310339  	0.09608196  	0.04561374  
2023-05-13 18:09:56.781: Find a better model.
2023-05-13 18:10:04.223: [iter 6 : loss : 0.7671 = 0.6870 + 0.0800 + 0.0000, time: 7.440545]
2023-05-13 18:10:04.366: epoch 6:	0.01612354  	0.11668615  	0.05710157  
2023-05-13 18:10:04.366: Find a better model.
2023-05-13 18:10:11.826: [iter 7 : loss : 0.7596 = 0.6785 + 0.0810 + 0.0000, time: 7.459670]
2023-05-13 18:10:11.980: epoch 7:	0.01823341  	0.13343251  	0.06584804  
2023-05-13 18:10:11.980: Find a better model.
2023-05-13 18:10:19.398: [iter 8 : loss : 0.7413 = 0.6579 + 0.0833 + 0.0001, time: 7.416555]
2023-05-13 18:10:19.551: epoch 8:	0.01872736  	0.13736339  	0.06920335  
2023-05-13 18:10:19.551: Find a better model.
2023-05-13 18:10:26.783: [iter 9 : loss : 0.7015 = 0.6138 + 0.0876 + 0.0002, time: 7.231168]
2023-05-13 18:10:26.933: epoch 9:	0.01851567  	0.13763805  	0.06862479  
2023-05-13 18:10:26.934: Find a better model.
2023-05-13 18:10:34.175: [iter 10 : loss : 0.6368 = 0.5435 + 0.0930 + 0.0003, time: 7.239818]
2023-05-13 18:10:34.329: epoch 10:	0.01840276  	0.13663785  	0.06783857  
2023-05-13 18:10:41.578: [iter 11 : loss : 0.5618 = 0.4637 + 0.0977 + 0.0004, time: 7.248600]
2023-05-13 18:10:41.729: epoch 11:	0.01847333  	0.13703668  	0.06791030  
2023-05-13 18:10:48.982: [iter 12 : loss : 0.4963 = 0.3951 + 0.1006 + 0.0006, time: 7.251962]
2023-05-13 18:10:49.136: epoch 12:	0.01834632  	0.13563523  	0.06785963  
2023-05-13 18:10:56.397: [iter 13 : loss : 0.4485 = 0.3456 + 0.1022 + 0.0007, time: 7.260312]
2023-05-13 18:10:56.549: epoch 13:	0.01842393  	0.13664268  	0.06859976  
2023-05-13 18:11:03.776: [iter 14 : loss : 0.4122 = 0.3084 + 0.1030 + 0.0009, time: 7.224941]
2023-05-13 18:11:03.933: epoch 14:	0.01869207  	0.13834697  	0.06943854  
2023-05-13 18:11:03.933: Find a better model.
2023-05-13 18:11:11.181: [iter 15 : loss : 0.3866 = 0.2823 + 0.1033 + 0.0010, time: 7.247146]
2023-05-13 18:11:11.332: epoch 15:	0.01886849  	0.13991190  	0.07042013  
2023-05-13 18:11:11.332: Find a better model.
2023-05-13 18:11:18.585: [iter 16 : loss : 0.3650 = 0.2607 + 0.1032 + 0.0011, time: 7.251200]
2023-05-13 18:11:18.740: epoch 16:	0.01910136  	0.14165056  	0.07122885  
2023-05-13 18:11:18.740: Find a better model.
2023-05-13 18:11:25.997: [iter 17 : loss : 0.3490 = 0.2448 + 0.1029 + 0.0012, time: 7.254845]
2023-05-13 18:11:26.147: epoch 17:	0.01929894  	0.14292344  	0.07194879  
2023-05-13 18:11:26.148: Find a better model.
2023-05-13 18:11:33.571: [iter 18 : loss : 0.3342 = 0.2301 + 0.1027 + 0.0013, time: 7.421266]
2023-05-13 18:11:33.722: epoch 18:	0.01960943  	0.14486566  	0.07303979  
2023-05-13 18:11:33.722: Find a better model.
2023-05-13 18:11:41.174: [iter 19 : loss : 0.3202 = 0.2164 + 0.1024 + 0.0014, time: 7.450047]
2023-05-13 18:11:41.328: epoch 19:	0.01965883  	0.14552093  	0.07375500  
2023-05-13 18:11:41.328: Find a better model.
2023-05-13 18:11:48.767: [iter 20 : loss : 0.3107 = 0.2073 + 0.1019 + 0.0015, time: 7.438151]
2023-05-13 18:11:48.923: epoch 20:	0.01980701  	0.14676315  	0.07445916  
2023-05-13 18:11:48.924: Find a better model.
2023-05-13 18:11:56.186: [iter 21 : loss : 0.3012 = 0.1981 + 0.1015 + 0.0016, time: 7.261083]
2023-05-13 18:11:56.338: epoch 21:	0.02006106  	0.14853337  	0.07544800  
2023-05-13 18:11:56.338: Find a better model.
2023-05-13 18:12:03.747: [iter 22 : loss : 0.2929 = 0.1901 + 0.1011 + 0.0017, time: 7.407428]
2023-05-13 18:12:03.900: epoch 22:	0.02029392  	0.14972331  	0.07626905  
2023-05-13 18:12:03.900: Find a better model.
2023-05-13 18:12:11.162: [iter 23 : loss : 0.2847 = 0.1823 + 0.1007 + 0.0017, time: 7.260449]
2023-05-13 18:12:11.314: epoch 23:	0.02052678  	0.15137699  	0.07719214  
2023-05-13 18:12:11.315: Find a better model.
2023-05-13 18:12:18.571: [iter 24 : loss : 0.2783 = 0.1763 + 0.1002 + 0.0018, time: 7.254622]
2023-05-13 18:12:18.724: epoch 24:	0.02079493  	0.15357503  	0.07811607  
2023-05-13 18:12:18.724: Find a better model.
2023-05-13 18:12:25.931: [iter 25 : loss : 0.2716 = 0.1699 + 0.0998 + 0.0019, time: 7.206414]
2023-05-13 18:12:26.078: epoch 25:	0.02083021  	0.15390675  	0.07836606  
2023-05-13 18:12:26.079: Find a better model.
2023-05-13 18:12:33.162: [iter 26 : loss : 0.2683 = 0.1669 + 0.0994 + 0.0019, time: 7.081727]
2023-05-13 18:12:33.318: epoch 26:	0.02107719  	0.15578184  	0.07912634  
2023-05-13 18:12:33.318: Find a better model.
2023-05-13 18:12:40.560: [iter 27 : loss : 0.2604 = 0.1595 + 0.0990 + 0.0020, time: 7.241488]
2023-05-13 18:12:40.712: epoch 27:	0.02117598  	0.15692107  	0.07964679  
2023-05-13 18:12:40.712: Find a better model.
2023-05-13 18:12:47.940: [iter 28 : loss : 0.2556 = 0.1549 + 0.0986 + 0.0021, time: 7.226128]
2023-05-13 18:12:48.094: epoch 28:	0.02139474  	0.15825942  	0.08047134  
2023-05-13 18:12:48.094: Find a better model.
2023-05-13 18:12:55.153: [iter 29 : loss : 0.2510 = 0.1507 + 0.0982 + 0.0021, time: 7.056209]
2023-05-13 18:12:55.306: epoch 29:	0.02150059  	0.15877406  	0.08099715  
2023-05-13 18:12:55.307: Find a better model.
2023-05-13 18:13:02.538: [iter 30 : loss : 0.2446 = 0.1446 + 0.0978 + 0.0022, time: 7.229860]
2023-05-13 18:13:02.690: epoch 30:	0.02162761  	0.15977123  	0.08162178  
2023-05-13 18:13:02.690: Find a better model.
2023-05-13 18:13:09.930: [iter 31 : loss : 0.2411 = 0.1414 + 0.0974 + 0.0023, time: 7.239197]
2023-05-13 18:13:10.086: epoch 31:	0.02175462  	0.16088803  	0.08217839  
2023-05-13 18:13:10.086: Find a better model.
2023-05-13 18:13:17.322: [iter 32 : loss : 0.2355 = 0.1361 + 0.0970 + 0.0023, time: 7.233439]
2023-05-13 18:13:17.476: epoch 32:	0.02201571  	0.16324896  	0.08312366  
2023-05-13 18:13:17.476: Find a better model.
2023-05-13 18:13:24.739: [iter 33 : loss : 0.2329 = 0.1338 + 0.0967 + 0.0024, time: 7.261568]
2023-05-13 18:13:24.882: epoch 33:	0.02210744  	0.16337083  	0.08365773  
2023-05-13 18:13:24.882: Find a better model.
2023-05-13 18:13:32.148: [iter 34 : loss : 0.2287 = 0.1299 + 0.0963 + 0.0024, time: 7.264499]
2023-05-13 18:13:32.300: epoch 34:	0.02226269  	0.16457963  	0.08451891  
2023-05-13 18:13:32.301: Find a better model.
2023-05-13 18:13:39.547: [iter 35 : loss : 0.2255 = 0.1270 + 0.0960 + 0.0025, time: 7.245283]
2023-05-13 18:13:39.702: epoch 35:	0.02241087  	0.16597854  	0.08529168  
2023-05-13 18:13:39.702: Find a better model.
2023-05-13 18:13:47.107: [iter 36 : loss : 0.2219 = 0.1236 + 0.0957 + 0.0025, time: 7.403996]
2023-05-13 18:13:47.263: epoch 36:	0.02260845  	0.16719183  	0.08606751  
2023-05-13 18:13:47.263: Find a better model.
2023-05-13 18:13:54.538: [iter 37 : loss : 0.2181 = 0.1201 + 0.0954 + 0.0026, time: 7.272548]
2023-05-13 18:13:54.689: epoch 37:	0.02272840  	0.16792746  	0.08664887  
2023-05-13 18:13:54.689: Find a better model.
2023-05-13 18:14:02.100: [iter 38 : loss : 0.2164 = 0.1187 + 0.0951 + 0.0026, time: 7.409962]
2023-05-13 18:14:02.242: epoch 38:	0.02282719  	0.16828625  	0.08724282  
2023-05-13 18:14:02.242: Find a better model.
2023-05-13 18:14:09.505: [iter 39 : loss : 0.2119 = 0.1144 + 0.0948 + 0.0027, time: 7.260830]
2023-05-13 18:14:09.655: epoch 39:	0.02296832  	0.16940594  	0.08795695  
2023-05-13 18:14:09.655: Find a better model.
2023-05-13 18:14:16.916: [iter 40 : loss : 0.2089 = 0.1116 + 0.0945 + 0.0028, time: 7.258847]
2023-05-13 18:14:17.069: epoch 40:	0.02304594  	0.16992299  	0.08847310  
2023-05-13 18:14:17.070: Find a better model.
2023-05-13 18:14:24.127: [iter 41 : loss : 0.2071 = 0.1101 + 0.0942 + 0.0028, time: 7.053669]
2023-05-13 18:14:24.277: epoch 41:	0.02303888  	0.16995698  	0.08875363  
2023-05-13 18:14:24.277: Find a better model.
2023-05-13 18:14:31.322: [iter 42 : loss : 0.2049 = 0.1082 + 0.0939 + 0.0029, time: 7.042964]
2023-05-13 18:14:31.473: epoch 42:	0.02327881  	0.17217945  	0.08968588  
2023-05-13 18:14:31.473: Find a better model.
2023-05-13 18:14:38.707: [iter 43 : loss : 0.2010 = 0.1045 + 0.0936 + 0.0029, time: 7.232742]
2023-05-13 18:14:38.858: epoch 43:	0.02340582  	0.17275429  	0.09019653  
2023-05-13 18:14:38.858: Find a better model.
2023-05-13 18:14:45.927: [iter 44 : loss : 0.1974 = 0.1011 + 0.0934 + 0.0030, time: 7.065495]
2023-05-13 18:14:46.080: epoch 44:	0.02348345  	0.17325640  	0.09068633  
2023-05-13 18:14:46.080: Find a better model.
2023-05-13 18:14:53.290: [iter 45 : loss : 0.1956 = 0.0995 + 0.0931 + 0.0030, time: 7.208995]
2023-05-13 18:14:53.441: epoch 45:	0.02351873  	0.17328194  	0.09113018  
2023-05-13 18:14:53.441: Find a better model.
2023-05-13 18:15:00.691: [iter 46 : loss : 0.1931 = 0.0972 + 0.0928 + 0.0031, time: 7.249010]
2023-05-13 18:15:00.842: epoch 46:	0.02365986  	0.17424390  	0.09168357  
2023-05-13 18:15:00.842: Find a better model.
2023-05-13 18:15:07.905: [iter 47 : loss : 0.1923 = 0.0965 + 0.0927 + 0.0031, time: 7.061326]
2023-05-13 18:15:08.047: epoch 47:	0.02367398  	0.17467974  	0.09204622  
2023-05-13 18:15:08.047: Find a better model.
2023-05-13 18:15:15.114: [iter 48 : loss : 0.1887 = 0.0930 + 0.0925 + 0.0032, time: 7.065724]
2023-05-13 18:15:15.269: epoch 48:	0.02375865  	0.17563684  	0.09260093  
2023-05-13 18:15:15.269: Find a better model.
2023-05-13 18:15:22.312: [iter 49 : loss : 0.1851 = 0.0897 + 0.0923 + 0.0032, time: 7.042252]
2023-05-13 18:15:22.463: epoch 49:	0.02376571  	0.17541927  	0.09291573  
2023-05-13 18:15:29.683: [iter 50 : loss : 0.1847 = 0.0894 + 0.0920 + 0.0033, time: 7.219106]
2023-05-13 18:15:29.837: epoch 50:	0.02387862  	0.17648177  	0.09356503  
2023-05-13 18:15:29.837: Find a better model.
2023-05-13 18:15:37.089: [iter 51 : loss : 0.1817 = 0.0866 + 0.0918 + 0.0033, time: 7.251168]
2023-05-13 18:15:37.243: epoch 51:	0.02391390  	0.17676927  	0.09377772  
2023-05-13 18:15:37.243: Find a better model.
2023-05-13 18:15:44.481: [iter 52 : loss : 0.1815 = 0.0865 + 0.0916 + 0.0033, time: 7.237021]
2023-05-13 18:15:44.637: epoch 52:	0.02417498  	0.17876935  	0.09449443  
2023-05-13 18:15:44.637: Find a better model.
2023-05-13 18:15:51.880: [iter 53 : loss : 0.1794 = 0.0846 + 0.0914 + 0.0034, time: 7.240657]
2023-05-13 18:15:52.023: epoch 53:	0.02428789  	0.17960234  	0.09508571  
2023-05-13 18:15:52.023: Find a better model.
2023-05-13 18:15:59.267: [iter 54 : loss : 0.1773 = 0.0826 + 0.0912 + 0.0034, time: 7.242430]
2023-05-13 18:15:59.418: epoch 54:	0.02442902  	0.18062422  	0.09550709  
2023-05-13 18:15:59.418: Find a better model.
2023-05-13 18:16:06.664: [iter 55 : loss : 0.1753 = 0.0808 + 0.0910 + 0.0035, time: 7.245179]
2023-05-13 18:16:06.818: epoch 55:	0.02445018  	0.18090227  	0.09601380  
2023-05-13 18:16:06.818: Find a better model.
2023-05-13 18:16:14.074: [iter 56 : loss : 0.1739 = 0.0795 + 0.0908 + 0.0035, time: 7.254232]
2023-05-13 18:16:14.232: epoch 56:	0.02447841  	0.18114583  	0.09645233  
2023-05-13 18:16:14.233: Find a better model.
2023-05-13 18:16:21.465: [iter 57 : loss : 0.1718 = 0.0776 + 0.0906 + 0.0036, time: 7.230475]
2023-05-13 18:16:21.620: epoch 57:	0.02453486  	0.18143910  	0.09670602  
2023-05-13 18:16:21.620: Find a better model.
2023-05-13 18:16:28.686: [iter 58 : loss : 0.1700 = 0.0759 + 0.0905 + 0.0036, time: 7.064623]
2023-05-13 18:16:28.837: epoch 58:	0.02463365  	0.18234357  	0.09721847  
2023-05-13 18:16:28.837: Find a better model.
2023-05-13 18:16:36.052: [iter 59 : loss : 0.1689 = 0.0749 + 0.0903 + 0.0037, time: 7.213363]
2023-05-13 18:16:36.206: epoch 59:	0.02466187  	0.18272084  	0.09739274  
2023-05-13 18:16:36.206: Find a better model.
2023-05-13 18:16:43.457: [iter 60 : loss : 0.1674 = 0.0736 + 0.0902 + 0.0037, time: 7.250278]
2023-05-13 18:16:43.612: epoch 60:	0.02478183  	0.18327489  	0.09788737  
2023-05-13 18:16:43.612: Find a better model.
2023-05-13 18:16:50.681: [iter 61 : loss : 0.1660 = 0.0723 + 0.0899 + 0.0038, time: 7.067816]
2023-05-13 18:16:50.832: epoch 61:	0.02481711  	0.18367127  	0.09812647  
2023-05-13 18:16:50.832: Find a better model.
2023-05-13 18:16:58.043: [iter 62 : loss : 0.1643 = 0.0707 + 0.0898 + 0.0038, time: 7.209054]
2023-05-13 18:16:58.196: epoch 62:	0.02492296  	0.18449625  	0.09860078  
2023-05-13 18:16:58.196: Find a better model.
2023-05-13 18:17:05.274: [iter 63 : loss : 0.1634 = 0.0699 + 0.0897 + 0.0038, time: 7.075198]
2023-05-13 18:17:05.428: epoch 63:	0.02488062  	0.18413788  	0.09876528  
2023-05-13 18:17:12.646: [iter 64 : loss : 0.1619 = 0.0685 + 0.0894 + 0.0039, time: 7.216849]
2023-05-13 18:17:12.802: epoch 64:	0.02500764  	0.18497853  	0.09919228  
2023-05-13 18:17:12.802: Find a better model.
2023-05-13 18:17:20.064: [iter 65 : loss : 0.1608 = 0.0676 + 0.0893 + 0.0039, time: 7.261065]
2023-05-13 18:17:20.209: epoch 65:	0.02500763  	0.18461709  	0.09926272  
2023-05-13 18:17:27.439: [iter 66 : loss : 0.1591 = 0.0660 + 0.0892 + 0.0040, time: 7.227938]
2023-05-13 18:17:27.594: epoch 66:	0.02504997  	0.18497933  	0.09978283  
2023-05-13 18:17:27.594: Find a better model.
2023-05-13 18:17:34.845: [iter 67 : loss : 0.1577 = 0.0646 + 0.0890 + 0.0040, time: 7.249469]
2023-05-13 18:17:34.998: epoch 67:	0.02510642  	0.18528320  	0.10018858  
2023-05-13 18:17:34.998: Find a better model.
2023-05-13 18:17:42.236: [iter 68 : loss : 0.1574 = 0.0645 + 0.0889 + 0.0041, time: 7.236835]
2023-05-13 18:17:42.391: epoch 68:	0.02514170  	0.18548550  	0.10049693  
2023-05-13 18:17:42.391: Find a better model.
2023-05-13 18:17:49.646: [iter 69 : loss : 0.1556 = 0.0627 + 0.0888 + 0.0041, time: 7.252470]
2023-05-13 18:17:49.799: epoch 69:	0.02519110  	0.18564492  	0.10076764  
2023-05-13 18:17:49.800: Find a better model.
2023-05-13 18:17:57.054: [iter 70 : loss : 0.1537 = 0.0609 + 0.0886 + 0.0041, time: 7.253300]
2023-05-13 18:17:57.199: epoch 70:	0.02520521  	0.18619625  	0.10093324  
2023-05-13 18:17:57.199: Find a better model.
2023-05-13 18:18:04.253: [iter 71 : loss : 0.1525 = 0.0598 + 0.0885 + 0.0042, time: 7.051864]
2023-05-13 18:18:04.406: epoch 71:	0.02524755  	0.18636796  	0.10115459  
2023-05-13 18:18:04.406: Find a better model.
2023-05-13 18:18:11.639: [iter 72 : loss : 0.1523 = 0.0597 + 0.0884 + 0.0042, time: 7.232006]
2023-05-13 18:18:11.782: epoch 72:	0.02533223  	0.18723238  	0.10141891  
2023-05-13 18:18:11.782: Find a better model.
2023-05-13 18:18:19.004: [iter 73 : loss : 0.1507 = 0.0582 + 0.0882 + 0.0043, time: 7.221257]
2023-05-13 18:18:19.145: epoch 73:	0.02540985  	0.18773147  	0.10171149  
2023-05-13 18:18:19.145: Find a better model.
2023-05-13 18:18:26.244: [iter 74 : loss : 0.1492 = 0.0567 + 0.0881 + 0.0043, time: 7.097399]
2023-05-13 18:18:26.398: epoch 74:	0.02550864  	0.18829830  	0.10207848  
2023-05-13 18:18:26.398: Find a better model.
2023-05-13 18:18:33.626: [iter 75 : loss : 0.1488 = 0.0564 + 0.0881 + 0.0043, time: 7.225639]
2023-05-13 18:18:33.780: epoch 75:	0.02551570  	0.18853459  	0.10234743  
2023-05-13 18:18:33.780: Find a better model.
2023-05-13 18:18:41.008: [iter 76 : loss : 0.1478 = 0.0555 + 0.0879 + 0.0044, time: 7.225615]
2023-05-13 18:18:41.159: epoch 76:	0.02562155  	0.18936096  	0.10283702  
2023-05-13 18:18:41.160: Find a better model.
2023-05-13 18:18:48.419: [iter 77 : loss : 0.1467 = 0.0545 + 0.0878 + 0.0044, time: 7.257779]
2023-05-13 18:18:48.573: epoch 77:	0.02569212  	0.18978740  	0.10305185  
2023-05-13 18:18:48.573: Find a better model.
2023-05-13 18:18:55.635: [iter 78 : loss : 0.1459 = 0.0538 + 0.0877 + 0.0045, time: 7.060115]
2023-05-13 18:18:55.785: epoch 78:	0.02581913  	0.19045308  	0.10340188  
2023-05-13 18:18:55.785: Find a better model.
2023-05-13 18:19:02.837: [iter 79 : loss : 0.1446 = 0.0525 + 0.0876 + 0.0045, time: 7.050965]
2023-05-13 18:19:02.988: epoch 79:	0.02584735  	0.19053440  	0.10351925  
2023-05-13 18:19:02.988: Find a better model.
2023-05-13 18:19:10.196: [iter 80 : loss : 0.1441 = 0.0520 + 0.0876 + 0.0045, time: 7.207041]
2023-05-13 18:19:10.349: epoch 80:	0.02591086  	0.19119485  	0.10376442  
2023-05-13 18:19:10.349: Find a better model.
2023-05-13 18:19:17.611: [iter 81 : loss : 0.1436 = 0.0516 + 0.0874 + 0.0046, time: 7.261151]
2023-05-13 18:19:17.762: epoch 81:	0.02589674  	0.19103818  	0.10383555  
2023-05-13 18:19:24.994: [iter 82 : loss : 0.1424 = 0.0505 + 0.0873 + 0.0046, time: 7.231090]
2023-05-13 18:19:25.140: epoch 82:	0.02586146  	0.19054538  	0.10377350  
2023-05-13 18:19:32.412: [iter 83 : loss : 0.1414 = 0.0496 + 0.0872 + 0.0047, time: 7.270970]
2023-05-13 18:19:32.570: epoch 83:	0.02591792  	0.19094880  	0.10409732  
2023-05-13 18:19:39.807: [iter 84 : loss : 0.1412 = 0.0494 + 0.0871 + 0.0047, time: 7.235948]
2023-05-13 18:19:39.959: epoch 84:	0.02602377  	0.19183610  	0.10451384  
2023-05-13 18:19:39.960: Find a better model.
2023-05-13 18:19:47.208: [iter 85 : loss : 0.1402 = 0.0485 + 0.0870 + 0.0047, time: 7.247031]
2023-05-13 18:19:47.360: epoch 85:	0.02600965  	0.19150372  	0.10455343  
2023-05-13 18:19:54.605: [iter 86 : loss : 0.1402 = 0.0486 + 0.0869 + 0.0048, time: 7.242867]
2023-05-13 18:19:54.757: epoch 86:	0.02603788  	0.19189873  	0.10481895  
2023-05-13 18:19:54.757: Find a better model.
2023-05-13 18:20:01.977: [iter 87 : loss : 0.1375 = 0.0459 + 0.0868 + 0.0048, time: 7.219100]
2023-05-13 18:20:02.129: epoch 87:	0.02604494  	0.19172105  	0.10499907  
2023-05-13 18:20:09.398: [iter 88 : loss : 0.1367 = 0.0451 + 0.0867 + 0.0048, time: 7.266643]
2023-05-13 18:20:09.553: epoch 88:	0.02608021  	0.19190417  	0.10525737  
2023-05-13 18:20:09.553: Find a better model.
2023-05-13 18:20:16.789: [iter 89 : loss : 0.1365 = 0.0450 + 0.0866 + 0.0049, time: 7.235849]
2023-05-13 18:20:16.942: epoch 89:	0.02615783  	0.19257265  	0.10564367  
2023-05-13 18:20:16.942: Find a better model.
2023-05-13 18:20:24.179: [iter 90 : loss : 0.1370 = 0.0455 + 0.0865 + 0.0049, time: 7.234423]
2023-05-13 18:20:24.333: epoch 90:	0.02615078  	0.19255334  	0.10567499  
2023-05-13 18:20:31.586: [iter 91 : loss : 0.1358 = 0.0444 + 0.0864 + 0.0050, time: 7.251778]
2023-05-13 18:20:31.737: epoch 91:	0.02617194  	0.19257726  	0.10578579  
2023-05-13 18:20:31.737: Find a better model.
2023-05-13 18:20:38.963: [iter 92 : loss : 0.1349 = 0.0435 + 0.0864 + 0.0050, time: 7.223567]
2023-05-13 18:20:39.115: epoch 92:	0.02617195  	0.19284175  	0.10593058  
2023-05-13 18:20:39.115: Find a better model.
2023-05-13 18:20:46.359: [iter 93 : loss : 0.1349 = 0.0436 + 0.0863 + 0.0050, time: 7.242090]
2023-05-13 18:20:46.501: epoch 93:	0.02620723  	0.19331978  	0.10612970  
2023-05-13 18:20:46.501: Find a better model.
2023-05-13 18:20:53.591: [iter 94 : loss : 0.1329 = 0.0416 + 0.0862 + 0.0051, time: 7.088633]
2023-05-13 18:20:53.742: epoch 94:	0.02619311  	0.19329531  	0.10629663  
2023-05-13 18:21:00.964: [iter 95 : loss : 0.1324 = 0.0411 + 0.0861 + 0.0051, time: 7.221859]
2023-05-13 18:21:01.120: epoch 95:	0.02609432  	0.19249812  	0.10626911  
2023-05-13 18:21:08.376: [iter 96 : loss : 0.1324 = 0.0412 + 0.0861 + 0.0051, time: 7.254800]
2023-05-13 18:21:08.527: epoch 96:	0.02621429  	0.19288269  	0.10663840  
2023-05-13 18:21:15.761: [iter 97 : loss : 0.1305 = 0.0394 + 0.0860 + 0.0052, time: 7.232567]
2023-05-13 18:21:15.913: epoch 97:	0.02623545  	0.19316354  	0.10673561  
2023-05-13 18:21:23.178: [iter 98 : loss : 0.1319 = 0.0408 + 0.0859 + 0.0052, time: 7.263637]
2023-05-13 18:21:23.329: epoch 98:	0.02630601  	0.19366024  	0.10701974  
2023-05-13 18:21:23.329: Find a better model.
2023-05-13 18:21:30.575: [iter 99 : loss : 0.1304 = 0.0394 + 0.0858 + 0.0052, time: 7.244786]
2023-05-13 18:21:30.731: epoch 99:	0.02635541  	0.19398147  	0.10716547  
2023-05-13 18:21:30.731: Find a better model.
2023-05-13 18:21:37.953: [iter 100 : loss : 0.1297 = 0.0387 + 0.0857 + 0.0053, time: 7.221282]
2023-05-13 18:21:38.104: epoch 100:	0.02636248  	0.19426198  	0.10735181  
2023-05-13 18:21:38.104: Find a better model.
2023-05-13 18:21:45.345: [iter 101 : loss : 0.1296 = 0.0386 + 0.0857 + 0.0053, time: 7.239500]
2023-05-13 18:21:45.487: epoch 101:	0.02634130  	0.19451638  	0.10731946  
2023-05-13 18:21:45.487: Find a better model.
2023-05-13 18:21:52.747: [iter 102 : loss : 0.1282 = 0.0372 + 0.0856 + 0.0053, time: 7.258894]
2023-05-13 18:21:52.897: epoch 102:	0.02634836  	0.19436793  	0.10740617  
2023-05-13 18:22:00.151: [iter 103 : loss : 0.1281 = 0.0371 + 0.0856 + 0.0054, time: 7.252743]
2023-05-13 18:22:00.306: epoch 103:	0.02641892  	0.19476978  	0.10769113  
2023-05-13 18:22:00.306: Find a better model.
2023-05-13 18:22:07.561: [iter 104 : loss : 0.1285 = 0.0376 + 0.0855 + 0.0054, time: 7.253073]
2023-05-13 18:22:07.713: epoch 104:	0.02646832  	0.19535694  	0.10778713  
2023-05-13 18:22:07.713: Find a better model.
2023-05-13 18:22:14.951: [iter 105 : loss : 0.1278 = 0.0370 + 0.0854 + 0.0055, time: 7.235303]
2023-05-13 18:22:15.104: epoch 105:	0.02641186  	0.19499737  	0.10767423  
2023-05-13 18:22:22.357: [iter 106 : loss : 0.1274 = 0.0365 + 0.0854 + 0.0055, time: 7.251746]
2023-05-13 18:22:22.507: epoch 106:	0.02645421  	0.19514154  	0.10774061  
2023-05-13 18:22:29.754: [iter 107 : loss : 0.1264 = 0.0355 + 0.0853 + 0.0055, time: 7.244551]
2023-05-13 18:22:29.905: epoch 107:	0.02647538  	0.19513120  	0.10784926  
2023-05-13 18:22:37.137: [iter 108 : loss : 0.1264 = 0.0356 + 0.0852 + 0.0055, time: 7.229487]
2023-05-13 18:22:37.287: epoch 108:	0.02644010  	0.19503126  	0.10790177  
2023-05-13 18:22:44.545: [iter 109 : loss : 0.1249 = 0.0341 + 0.0852 + 0.0056, time: 7.255542]
2023-05-13 18:22:44.697: epoch 109:	0.02646832  	0.19527377  	0.10794831  
2023-05-13 18:22:51.944: [iter 110 : loss : 0.1240 = 0.0333 + 0.0851 + 0.0056, time: 7.246475]
2023-05-13 18:22:52.094: epoch 110:	0.02641893  	0.19501156  	0.10795926  
2023-05-13 18:22:59.336: [iter 111 : loss : 0.1243 = 0.0336 + 0.0850 + 0.0057, time: 7.240379]
2023-05-13 18:22:59.488: epoch 111:	0.02646832  	0.19523178  	0.10810627  
2023-05-13 18:23:06.743: [iter 112 : loss : 0.1243 = 0.0336 + 0.0850 + 0.0057, time: 7.254740]
2023-05-13 18:23:06.895: epoch 112:	0.02650360  	0.19525184  	0.10829895  
2023-05-13 18:23:14.134: [iter 113 : loss : 0.1240 = 0.0333 + 0.0850 + 0.0057, time: 7.238506]
2023-05-13 18:23:14.287: epoch 113:	0.02651772  	0.19529210  	0.10818122  
2023-05-13 18:23:21.522: [iter 114 : loss : 0.1231 = 0.0325 + 0.0849 + 0.0057, time: 7.233381]
2023-05-13 18:23:21.663: epoch 114:	0.02652477  	0.19541824  	0.10821824  
2023-05-13 18:23:21.664: Find a better model.
2023-05-13 18:23:28.751: [iter 115 : loss : 0.1226 = 0.0320 + 0.0848 + 0.0058, time: 7.086420]
2023-05-13 18:23:28.906: epoch 115:	0.02657417  	0.19560134  	0.10836573  
2023-05-13 18:23:28.906: Find a better model.
2023-05-13 18:23:35.939: [iter 116 : loss : 0.1219 = 0.0313 + 0.0848 + 0.0058, time: 7.030978]
2023-05-13 18:23:36.090: epoch 116:	0.02656711  	0.19555494  	0.10833514  
2023-05-13 18:23:43.318: [iter 117 : loss : 0.1216 = 0.0311 + 0.0847 + 0.0059, time: 7.224718]
2023-05-13 18:23:43.473: epoch 117:	0.02658122  	0.19563489  	0.10837128  
2023-05-13 18:23:43.473: Find a better model.
2023-05-13 18:23:50.700: [iter 118 : loss : 0.1217 = 0.0312 + 0.0847 + 0.0059, time: 7.226292]
2023-05-13 18:23:50.845: epoch 118:	0.02660945  	0.19595489  	0.10863759  
2023-05-13 18:23:50.846: Find a better model.
2023-05-13 18:23:57.929: [iter 119 : loss : 0.1209 = 0.0303 + 0.0846 + 0.0059, time: 7.081675]
2023-05-13 18:23:58.081: epoch 119:	0.02654594  	0.19530433  	0.10872097  
2023-05-13 18:24:05.289: [iter 120 : loss : 0.1209 = 0.0304 + 0.0846 + 0.0059, time: 7.206474]
2023-05-13 18:24:05.430: epoch 120:	0.02656711  	0.19544347  	0.10888611  
2023-05-13 18:24:12.525: [iter 121 : loss : 0.1208 = 0.0303 + 0.0845 + 0.0060, time: 7.092518]
2023-05-13 18:24:12.681: epoch 121:	0.02652477  	0.19520107  	0.10896336  
2023-05-13 18:24:19.731: [iter 122 : loss : 0.1199 = 0.0295 + 0.0845 + 0.0060, time: 7.049372]
2023-05-13 18:24:19.888: epoch 122:	0.02651772  	0.19481474  	0.10890058  
2023-05-13 18:24:26.921: [iter 123 : loss : 0.1199 = 0.0294 + 0.0844 + 0.0060, time: 7.031792]
2023-05-13 18:24:27.072: epoch 123:	0.02648949  	0.19442555  	0.10869345  
2023-05-13 18:24:34.114: [iter 124 : loss : 0.1190 = 0.0285 + 0.0844 + 0.0061, time: 7.040358]
2023-05-13 18:24:34.267: epoch 124:	0.02656006  	0.19482796  	0.10886591  
2023-05-13 18:24:41.311: [iter 125 : loss : 0.1186 = 0.0282 + 0.0843 + 0.0061, time: 7.043751]
2023-05-13 18:24:41.464: epoch 125:	0.02658122  	0.19544208  	0.10897017  
2023-05-13 18:24:48.693: [iter 126 : loss : 0.1185 = 0.0281 + 0.0843 + 0.0061, time: 7.227583]
2023-05-13 18:24:48.853: epoch 126:	0.02660945  	0.19564210  	0.10899016  
2023-05-13 18:24:56.080: [iter 127 : loss : 0.1175 = 0.0272 + 0.0842 + 0.0062, time: 7.225689]
2023-05-13 18:24:56.233: epoch 127:	0.02656005  	0.19499426  	0.10898361  
2023-05-13 18:25:03.312: [iter 128 : loss : 0.1188 = 0.0284 + 0.0842 + 0.0062, time: 7.078428]
2023-05-13 18:25:03.464: epoch 128:	0.02663061  	0.19551031  	0.10916159  
2023-05-13 18:25:10.699: [iter 129 : loss : 0.1178 = 0.0275 + 0.0841 + 0.0062, time: 7.233305]
2023-05-13 18:25:10.856: epoch 129:	0.02655299  	0.19480000  	0.10905946  
2023-05-13 18:25:18.090: [iter 130 : loss : 0.1179 = 0.0276 + 0.0841 + 0.0062, time: 7.233534]
2023-05-13 18:25:18.244: epoch 130:	0.02660238  	0.19527425  	0.10917069  
2023-05-13 18:25:25.495: [iter 131 : loss : 0.1170 = 0.0267 + 0.0840 + 0.0063, time: 7.249986]
2023-05-13 18:25:25.648: epoch 131:	0.02651771  	0.19476365  	0.10896753  
2023-05-13 18:25:32.869: [iter 132 : loss : 0.1171 = 0.0268 + 0.0840 + 0.0063, time: 7.219667]
2023-05-13 18:25:33.026: epoch 132:	0.02653887  	0.19494860  	0.10902639  
2023-05-13 18:25:40.088: [iter 133 : loss : 0.1161 = 0.0258 + 0.0840 + 0.0063, time: 7.060909]
2023-05-13 18:25:40.241: epoch 133:	0.02656005  	0.19509220  	0.10912915  
2023-05-13 18:25:47.484: [iter 134 : loss : 0.1166 = 0.0263 + 0.0840 + 0.0064, time: 7.241963]
2023-05-13 18:25:47.636: epoch 134:	0.02656710  	0.19510952  	0.10938712  
2023-05-13 18:25:54.880: [iter 135 : loss : 0.1164 = 0.0261 + 0.0839 + 0.0064, time: 7.243264]
2023-05-13 18:25:55.033: epoch 135:	0.02659533  	0.19511630  	0.10947507  
2023-05-13 18:26:02.284: [iter 136 : loss : 0.1160 = 0.0258 + 0.0838 + 0.0064, time: 7.248983]
2023-05-13 18:26:02.435: epoch 136:	0.02652476  	0.19494121  	0.10943963  
2023-05-13 18:26:09.672: [iter 137 : loss : 0.1156 = 0.0254 + 0.0838 + 0.0065, time: 7.235609]
2023-05-13 18:26:09.815: epoch 137:	0.02655299  	0.19517024  	0.10944584  
2023-05-13 18:26:17.046: [iter 138 : loss : 0.1153 = 0.0250 + 0.0838 + 0.0065, time: 7.228725]
2023-05-13 18:26:17.188: epoch 138:	0.02654593  	0.19493730  	0.10947312  
2023-05-13 18:26:24.271: [iter 139 : loss : 0.1151 = 0.0248 + 0.0837 + 0.0065, time: 7.081720]
2023-05-13 18:26:24.422: epoch 139:	0.02652477  	0.19530870  	0.10972530  
2023-05-13 18:26:31.654: [iter 140 : loss : 0.1144 = 0.0242 + 0.0837 + 0.0065, time: 7.230656]
2023-05-13 18:26:31.810: epoch 140:	0.02641186  	0.19421855  	0.10910414  
2023-05-13 18:26:39.070: [iter 141 : loss : 0.1149 = 0.0247 + 0.0836 + 0.0066, time: 7.258954]
2023-05-13 18:26:39.222: epoch 141:	0.02647537  	0.19444120  	0.10915835  
2023-05-13 18:26:46.267: [iter 142 : loss : 0.1140 = 0.0238 + 0.0836 + 0.0066, time: 7.043390]
2023-05-13 18:26:46.421: epoch 142:	0.02650359  	0.19478284  	0.10940232  
2023-05-13 18:26:53.478: [iter 143 : loss : 0.1140 = 0.0238 + 0.0836 + 0.0066, time: 7.054537]
2023-05-13 18:26:53.631: epoch 143:	0.02652477  	0.19484936  	0.10944865  
2023-05-13 18:26:53.631: Early stopping is trigger at epoch: 143
2023-05-13 18:26:53.631: best_result@epoch 118:

2023-05-13 18:26:53.631: 		0.0266      	0.1960      	0.1086      
2023-05-13 18:43:57.250: my pid: 2112
2023-05-13 18:43:57.250: model: model.general_recommender.SGL
2023-05-13 18:43:57.250: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 18:43:57.250: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 18:44:00.403: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 18:44:08.595: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.191823]
2023-05-13 18:44:08.747: epoch 1:	0.00151002  	0.01022077  	0.00542658  
2023-05-13 18:44:08.748: Find a better model.
2023-05-13 18:44:16.987: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.238055]
2023-05-13 18:44:17.179: epoch 2:	0.00289303  	0.02147222  	0.01082848  
2023-05-13 18:44:17.179: Find a better model.
2023-05-13 18:44:25.198: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.017473]
2023-05-13 18:44:25.366: epoch 3:	0.00537677  	0.04061018  	0.01933218  
2023-05-13 18:44:25.366: Find a better model.
2023-05-13 18:44:33.148: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.780274]
2023-05-13 18:44:33.300: epoch 4:	0.00843205  	0.06219305  	0.02968575  
2023-05-13 18:44:33.301: Find a better model.
2023-05-13 18:44:41.113: [iter 5 : loss : 0.7695 = 0.6906 + 0.0789 + 0.0000, time: 7.810989]
2023-05-13 18:44:41.264: epoch 5:	0.01196025  	0.08688118  	0.04157297  
2023-05-13 18:44:41.264: Find a better model.
2023-05-13 18:44:48.959: [iter 6 : loss : 0.7669 = 0.6876 + 0.0793 + 0.0000, time: 7.692146]
2023-05-13 18:44:49.110: epoch 6:	0.01544613  	0.11202291  	0.05435036  
2023-05-13 18:44:49.110: Find a better model.
2023-05-13 18:44:56.739: [iter 7 : loss : 0.7599 = 0.6797 + 0.0801 + 0.0000, time: 7.628683]
2023-05-13 18:44:56.888: epoch 7:	0.01804288  	0.13131861  	0.06459256  
2023-05-13 18:44:56.889: Find a better model.
2023-05-13 18:45:04.534: [iter 8 : loss : 0.7426 = 0.6603 + 0.0822 + 0.0001, time: 7.642983]
2023-05-13 18:45:04.685: epoch 8:	0.01887555  	0.13847439  	0.06898932  
2023-05-13 18:45:04.685: Find a better model.
2023-05-13 18:45:12.337: [iter 9 : loss : 0.7044 = 0.6179 + 0.0863 + 0.0001, time: 7.650096]
2023-05-13 18:45:12.488: epoch 9:	0.01881204  	0.13935320  	0.06942793  
2023-05-13 18:45:12.488: Find a better model.
2023-05-13 18:45:19.914: [iter 10 : loss : 0.6408 = 0.5487 + 0.0918 + 0.0003, time: 7.424978]
2023-05-13 18:45:20.064: epoch 10:	0.01871325  	0.13884851  	0.06895158  
2023-05-13 18:45:27.523: [iter 11 : loss : 0.5650 = 0.4679 + 0.0967 + 0.0004, time: 7.457176]
2023-05-13 18:45:27.675: epoch 11:	0.01852272  	0.13741691  	0.06865599  
2023-05-13 18:45:35.127: [iter 12 : loss : 0.4980 = 0.3977 + 0.0998 + 0.0006, time: 7.451000]
2023-05-13 18:45:35.276: epoch 12:	0.01845922  	0.13685358  	0.06864744  
2023-05-13 18:45:42.720: [iter 13 : loss : 0.4491 = 0.3469 + 0.1015 + 0.0007, time: 7.442077]
2023-05-13 18:45:42.869: epoch 13:	0.01857917  	0.13789997  	0.06929842  
2023-05-13 18:45:50.303: [iter 14 : loss : 0.4122 = 0.3090 + 0.1024 + 0.0009, time: 7.431800]
2023-05-13 18:45:50.452: epoch 14:	0.01876970  	0.13918978  	0.07002731  
2023-05-13 18:45:57.718: [iter 15 : loss : 0.3863 = 0.2826 + 0.1027 + 0.0010, time: 7.264821]
2023-05-13 18:45:57.866: epoch 15:	0.01891789  	0.14033121  	0.07085794  
2023-05-13 18:45:57.866: Find a better model.
2023-05-13 18:46:05.307: [iter 16 : loss : 0.3645 = 0.2607 + 0.1026 + 0.0011, time: 7.438811]
2023-05-13 18:46:05.455: epoch 16:	0.01918603  	0.14227021  	0.07186163  
2023-05-13 18:46:05.455: Find a better model.
2023-05-13 18:46:12.883: [iter 17 : loss : 0.3484 = 0.2447 + 0.1025 + 0.0012, time: 7.426915]
2023-05-13 18:46:13.052: epoch 17:	0.01944713  	0.14402764  	0.07288322  
2023-05-13 18:46:13.053: Find a better model.
2023-05-13 18:46:20.507: [iter 18 : loss : 0.3334 = 0.2298 + 0.1023 + 0.0013, time: 7.452766]
2023-05-13 18:46:20.673: epoch 18:	0.01956709  	0.14445226  	0.07348125  
2023-05-13 18:46:20.673: Find a better model.
2023-05-13 18:46:28.115: [iter 19 : loss : 0.3195 = 0.2162 + 0.1019 + 0.0014, time: 7.439553]
2023-05-13 18:46:28.281: epoch 19:	0.01975762  	0.14558937  	0.07432640  
2023-05-13 18:46:28.281: Find a better model.
2023-05-13 18:46:35.738: [iter 20 : loss : 0.3100 = 0.2070 + 0.1015 + 0.0015, time: 7.454464]
2023-05-13 18:46:35.887: epoch 20:	0.02001872  	0.14771618  	0.07525734  
2023-05-13 18:46:35.887: Find a better model.
2023-05-13 18:46:43.521: [iter 21 : loss : 0.3005 = 0.1979 + 0.1010 + 0.0016, time: 7.632099]
2023-05-13 18:46:43.671: epoch 21:	0.02025863  	0.14978606  	0.07608690  
2023-05-13 18:46:43.671: Find a better model.
2023-05-13 18:46:51.295: [iter 22 : loss : 0.2923 = 0.1899 + 0.1007 + 0.0017, time: 7.623397]
2023-05-13 18:46:51.445: epoch 22:	0.02038565  	0.15055761  	0.07658760  
2023-05-13 18:46:51.445: Find a better model.
2023-05-13 18:46:58.900: [iter 23 : loss : 0.2842 = 0.1822 + 0.1003 + 0.0017, time: 7.453568]
2023-05-13 18:46:59.065: epoch 23:	0.02064674  	0.15263051  	0.07760208  
2023-05-13 18:46:59.065: Find a better model.
2023-05-13 18:47:06.486: [iter 24 : loss : 0.2777 = 0.1761 + 0.0998 + 0.0018, time: 7.419729]
2023-05-13 18:47:06.633: epoch 24:	0.02081608  	0.15384048  	0.07814872  
2023-05-13 18:47:06.633: Find a better model.
2023-05-13 18:47:13.893: [iter 25 : loss : 0.2710 = 0.1697 + 0.0993 + 0.0019, time: 7.256931]
2023-05-13 18:47:14.041: epoch 25:	0.02098545  	0.15491614  	0.07881803  
2023-05-13 18:47:14.041: Find a better model.
2023-05-13 18:47:21.471: [iter 26 : loss : 0.2676 = 0.1667 + 0.0989 + 0.0019, time: 7.428328]
2023-05-13 18:47:21.619: epoch 26:	0.02114069  	0.15569581  	0.07927857  
2023-05-13 18:47:21.619: Find a better model.
2023-05-13 18:47:28.886: [iter 27 : loss : 0.2597 = 0.1592 + 0.0985 + 0.0020, time: 7.265275]
2023-05-13 18:47:29.033: epoch 27:	0.02137356  	0.15732896  	0.08001004  
2023-05-13 18:47:29.034: Find a better model.
2023-05-13 18:47:36.478: [iter 28 : loss : 0.2549 = 0.1547 + 0.0982 + 0.0021, time: 7.442453]
2023-05-13 18:47:36.626: epoch 28:	0.02159232  	0.15894817  	0.08098771  
2023-05-13 18:47:36.627: Find a better model.
2023-05-13 18:47:44.057: [iter 29 : loss : 0.2503 = 0.1504 + 0.0977 + 0.0021, time: 7.428344]
2023-05-13 18:47:44.204: epoch 29:	0.02170523  	0.15991716  	0.08166461  
2023-05-13 18:47:44.204: Find a better model.
2023-05-13 18:47:51.660: [iter 30 : loss : 0.2440 = 0.1445 + 0.0974 + 0.0022, time: 7.453454]
2023-05-13 18:47:51.807: epoch 30:	0.02183930  	0.16131003  	0.08257846  
2023-05-13 18:47:51.807: Find a better model.
2023-05-13 18:47:59.080: [iter 31 : loss : 0.2403 = 0.1411 + 0.0969 + 0.0023, time: 7.271867]
2023-05-13 18:47:59.229: epoch 31:	0.02204393  	0.16273050  	0.08315715  
2023-05-13 18:47:59.229: Find a better model.
2023-05-13 18:48:06.467: [iter 32 : loss : 0.2348 = 0.1359 + 0.0966 + 0.0023, time: 7.235777]
2023-05-13 18:48:06.617: epoch 32:	0.02219212  	0.16396900  	0.08398283  
2023-05-13 18:48:06.617: Find a better model.
2023-05-13 18:48:13.870: [iter 33 : loss : 0.2322 = 0.1337 + 0.0962 + 0.0024, time: 7.250920]
2023-05-13 18:48:14.016: epoch 33:	0.02227680  	0.16474435  	0.08435269  
2023-05-13 18:48:14.016: Find a better model.
2023-05-13 18:48:21.443: [iter 34 : loss : 0.2281 = 0.1298 + 0.0959 + 0.0024, time: 7.424827]
2023-05-13 18:48:21.596: epoch 34:	0.02238970  	0.16579819  	0.08510490  
2023-05-13 18:48:21.596: Find a better model.
2023-05-13 18:48:28.864: [iter 35 : loss : 0.2248 = 0.1267 + 0.0956 + 0.0025, time: 7.265754]
2023-05-13 18:48:29.012: epoch 35:	0.02255905  	0.16686836  	0.08572314  
2023-05-13 18:48:29.012: Find a better model.
2023-05-13 18:48:36.256: [iter 36 : loss : 0.2213 = 0.1235 + 0.0952 + 0.0025, time: 7.240645]
2023-05-13 18:48:36.403: epoch 36:	0.02270724  	0.16806570  	0.08652262  
2023-05-13 18:48:36.403: Find a better model.
2023-05-13 18:48:43.656: [iter 37 : loss : 0.2174 = 0.1199 + 0.0949 + 0.0026, time: 7.251680]
2023-05-13 18:48:43.817: epoch 37:	0.02283425  	0.16881894  	0.08710517  
2023-05-13 18:48:43.817: Find a better model.
2023-05-13 18:48:51.058: [iter 38 : loss : 0.2158 = 0.1185 + 0.0946 + 0.0027, time: 7.239192]
2023-05-13 18:48:51.204: epoch 38:	0.02308829  	0.17090820  	0.08829629  
2023-05-13 18:48:51.204: Find a better model.
2023-05-13 18:48:58.433: [iter 39 : loss : 0.2113 = 0.1143 + 0.0943 + 0.0027, time: 7.227323]
2023-05-13 18:48:58.588: epoch 39:	0.02311651  	0.17110197  	0.08872207  
2023-05-13 18:48:58.588: Find a better model.
2023-05-13 18:49:05.833: [iter 40 : loss : 0.2082 = 0.1115 + 0.0940 + 0.0028, time: 7.243465]
2023-05-13 18:49:05.979: epoch 40:	0.02318002  	0.17165631  	0.08917150  
2023-05-13 18:49:05.979: Find a better model.
2023-05-13 18:49:13.243: [iter 41 : loss : 0.2065 = 0.1100 + 0.0937 + 0.0028, time: 7.261493]
2023-05-13 18:49:13.406: epoch 41:	0.02326470  	0.17200848  	0.08969681  
2023-05-13 18:49:13.406: Find a better model.
2023-05-13 18:49:20.652: [iter 42 : loss : 0.2042 = 0.1079 + 0.0934 + 0.0029, time: 7.243304]
2023-05-13 18:49:20.812: epoch 42:	0.02350461  	0.17382967  	0.09068965  
2023-05-13 18:49:20.812: Find a better model.
2023-05-13 18:49:28.045: [iter 43 : loss : 0.2002 = 0.1042 + 0.0931 + 0.0029, time: 7.231836]
2023-05-13 18:49:28.192: epoch 43:	0.02361047  	0.17434128  	0.09113857  
2023-05-13 18:49:28.192: Find a better model.
2023-05-13 18:49:35.439: [iter 44 : loss : 0.1966 = 0.1008 + 0.0928 + 0.0030, time: 7.246088]
2023-05-13 18:49:35.584: epoch 44:	0.02370219  	0.17490925  	0.09158438  
2023-05-13 18:49:35.584: Find a better model.
2023-05-13 18:49:42.813: [iter 45 : loss : 0.1950 = 0.0993 + 0.0926 + 0.0030, time: 7.227007]
2023-05-13 18:49:42.961: epoch 45:	0.02391389  	0.17632657  	0.09229002  
2023-05-13 18:49:42.961: Find a better model.
2023-05-13 18:49:50.424: [iter 46 : loss : 0.1923 = 0.0969 + 0.0923 + 0.0031, time: 7.462113]
2023-05-13 18:49:50.572: epoch 46:	0.02385039  	0.17602128  	0.09244978  
2023-05-13 18:49:57.834: [iter 47 : loss : 0.1915 = 0.0962 + 0.0922 + 0.0031, time: 7.261612]
2023-05-13 18:49:57.981: epoch 47:	0.02394918  	0.17688830  	0.09330023  
2023-05-13 18:49:57.981: Find a better model.
2023-05-13 18:50:05.213: [iter 48 : loss : 0.1877 = 0.0926 + 0.0919 + 0.0032, time: 7.231106]
2023-05-13 18:50:05.359: epoch 48:	0.02392801  	0.17645802  	0.09343610  
2023-05-13 18:50:12.612: [iter 49 : loss : 0.1844 = 0.0895 + 0.0917 + 0.0032, time: 7.250713]
2023-05-13 18:50:12.759: epoch 49:	0.02404797  	0.17731133  	0.09412244  
2023-05-13 18:50:12.759: Find a better model.
2023-05-13 18:50:20.016: [iter 50 : loss : 0.1836 = 0.0889 + 0.0914 + 0.0033, time: 7.255390]
2023-05-13 18:50:20.164: epoch 50:	0.02408325  	0.17765737  	0.09455676  
2023-05-13 18:50:20.164: Find a better model.
2023-05-13 18:50:27.399: [iter 51 : loss : 0.1808 = 0.0862 + 0.0913 + 0.0033, time: 7.234246]
2023-05-13 18:50:27.547: epoch 51:	0.02416087  	0.17859395  	0.09510189  
2023-05-13 18:50:27.547: Find a better model.
2023-05-13 18:50:34.836: [iter 52 : loss : 0.1807 = 0.0862 + 0.0911 + 0.0034, time: 7.287764]
2023-05-13 18:50:34.996: epoch 52:	0.02423849  	0.17923987  	0.09548641  
2023-05-13 18:50:34.996: Find a better model.
2023-05-13 18:50:42.208: [iter 53 : loss : 0.1788 = 0.0845 + 0.0909 + 0.0034, time: 7.209890]
2023-05-13 18:50:42.355: epoch 53:	0.02428083  	0.17926563  	0.09582724  
2023-05-13 18:50:42.355: Find a better model.
2023-05-13 18:50:49.613: [iter 54 : loss : 0.1765 = 0.0824 + 0.0907 + 0.0035, time: 7.257007]
2023-05-13 18:50:49.765: epoch 54:	0.02428788  	0.17969735  	0.09617121  
2023-05-13 18:50:49.766: Find a better model.
2023-05-13 18:50:57.010: [iter 55 : loss : 0.1745 = 0.0806 + 0.0905 + 0.0035, time: 7.243715]
2023-05-13 18:50:57.159: epoch 55:	0.02441490  	0.18023297  	0.09648679  
2023-05-13 18:50:57.159: Find a better model.
2023-05-13 18:51:04.590: [iter 56 : loss : 0.1729 = 0.0791 + 0.0903 + 0.0035, time: 7.429404]
2023-05-13 18:51:04.744: epoch 56:	0.02449252  	0.18077026  	0.09679060  
2023-05-13 18:51:04.745: Find a better model.
2023-05-13 18:51:12.016: [iter 57 : loss : 0.1710 = 0.0774 + 0.0901 + 0.0036, time: 7.269915]
2023-05-13 18:51:12.165: epoch 57:	0.02458425  	0.18160023  	0.09713182  
2023-05-13 18:51:12.165: Find a better model.
2023-05-13 18:51:19.593: [iter 58 : loss : 0.1690 = 0.0755 + 0.0899 + 0.0036, time: 7.426963]
2023-05-13 18:51:19.751: epoch 58:	0.02457720  	0.18188213  	0.09736169  
2023-05-13 18:51:19.751: Find a better model.
2023-05-13 18:51:27.002: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 7.248580]
2023-05-13 18:51:27.148: epoch 59:	0.02466893  	0.18246563  	0.09776647  
2023-05-13 18:51:27.148: Find a better model.
2023-05-13 18:51:34.567: [iter 60 : loss : 0.1666 = 0.0733 + 0.0896 + 0.0037, time: 7.417865]
2023-05-13 18:51:34.715: epoch 60:	0.02483123  	0.18346928  	0.09818994  
2023-05-13 18:51:34.716: Find a better model.
2023-05-13 18:51:41.994: [iter 61 : loss : 0.1652 = 0.0720 + 0.0894 + 0.0038, time: 7.277182]
2023-05-13 18:51:42.143: epoch 61:	0.02491591  	0.18430410  	0.09861686  
2023-05-13 18:51:42.143: Find a better model.
2023-05-13 18:51:49.391: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 7.247279]
2023-05-13 18:51:49.537: epoch 62:	0.02491591  	0.18416104  	0.09869489  
2023-05-13 18:51:56.797: [iter 63 : loss : 0.1625 = 0.0695 + 0.0891 + 0.0039, time: 7.258177]
2023-05-13 18:51:56.943: epoch 63:	0.02498647  	0.18465464  	0.09904663  
2023-05-13 18:51:56.943: Find a better model.
2023-05-13 18:52:04.186: [iter 64 : loss : 0.1610 = 0.0682 + 0.0889 + 0.0039, time: 7.241354]
2023-05-13 18:52:04.332: epoch 64:	0.02510643  	0.18557455  	0.09957846  
2023-05-13 18:52:04.332: Find a better model.
2023-05-13 18:52:11.754: [iter 65 : loss : 0.1599 = 0.0673 + 0.0887 + 0.0039, time: 7.419658]
2023-05-13 18:52:11.915: epoch 65:	0.02513465  	0.18577145  	0.10004656  
2023-05-13 18:52:11.915: Find a better model.
2023-05-13 18:52:19.180: [iter 66 : loss : 0.1583 = 0.0657 + 0.0886 + 0.0040, time: 7.263249]
2023-05-13 18:52:19.327: epoch 66:	0.02513465  	0.18589853  	0.10012504  
2023-05-13 18:52:19.327: Find a better model.
2023-05-13 18:52:26.584: [iter 67 : loss : 0.1569 = 0.0644 + 0.0884 + 0.0040, time: 7.254386]
2023-05-13 18:52:26.735: epoch 67:	0.02521227  	0.18658867  	0.10064670  
2023-05-13 18:52:26.736: Find a better model.
2023-05-13 18:52:34.163: [iter 68 : loss : 0.1565 = 0.0641 + 0.0883 + 0.0041, time: 7.425620]
2023-05-13 18:52:34.309: epoch 68:	0.02531106  	0.18720342  	0.10098125  
2023-05-13 18:52:34.309: Find a better model.
2023-05-13 18:52:41.756: [iter 69 : loss : 0.1548 = 0.0625 + 0.0882 + 0.0041, time: 7.445329]
2023-05-13 18:52:41.917: epoch 69:	0.02528989  	0.18687567  	0.10112407  
2023-05-13 18:52:49.185: [iter 70 : loss : 0.1528 = 0.0606 + 0.0881 + 0.0041, time: 7.264908]
2023-05-13 18:52:49.344: epoch 70:	0.02541691  	0.18791309  	0.10159849  
2023-05-13 18:52:49.344: Find a better model.
2023-05-13 18:52:56.740: [iter 71 : loss : 0.1516 = 0.0595 + 0.0879 + 0.0042, time: 7.394797]
2023-05-13 18:52:56.888: epoch 71:	0.02540984  	0.18761776  	0.10163222  
2023-05-13 18:53:04.170: [iter 72 : loss : 0.1512 = 0.0592 + 0.0878 + 0.0042, time: 7.279913]
2023-05-13 18:53:04.335: epoch 72:	0.02548747  	0.18814038  	0.10200096  
2023-05-13 18:53:04.335: Find a better model.
2023-05-13 18:53:11.556: [iter 73 : loss : 0.1499 = 0.0579 + 0.0877 + 0.0043, time: 7.220180]
2023-05-13 18:53:11.703: epoch 73:	0.02555098  	0.18880680  	0.10224133  
2023-05-13 18:53:11.703: Find a better model.
2023-05-13 18:53:18.961: [iter 74 : loss : 0.1483 = 0.0564 + 0.0875 + 0.0043, time: 7.255184]
2023-05-13 18:53:19.109: epoch 74:	0.02560743  	0.18930764  	0.10261744  
2023-05-13 18:53:19.109: Find a better model.
2023-05-13 18:53:26.362: [iter 75 : loss : 0.1478 = 0.0560 + 0.0875 + 0.0044, time: 7.251974]
2023-05-13 18:53:26.510: epoch 75:	0.02560743  	0.18902017  	0.10286227  
2023-05-13 18:53:33.765: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 7.254414]
2023-05-13 18:53:33.931: epoch 76:	0.02562155  	0.18916638  	0.10268591  
2023-05-13 18:53:41.156: [iter 77 : loss : 0.1457 = 0.0541 + 0.0872 + 0.0044, time: 7.223918]
2023-05-13 18:53:41.321: epoch 77:	0.02574856  	0.19053474  	0.10328951  
2023-05-13 18:53:41.321: Find a better model.
2023-05-13 18:53:48.717: [iter 78 : loss : 0.1450 = 0.0534 + 0.0871 + 0.0045, time: 7.394313]
2023-05-13 18:53:48.864: epoch 78:	0.02576973  	0.19060801  	0.10346586  
2023-05-13 18:53:48.864: Find a better model.
2023-05-13 18:53:56.148: [iter 79 : loss : 0.1437 = 0.0522 + 0.0870 + 0.0045, time: 7.283122]
2023-05-13 18:53:56.308: epoch 79:	0.02580502  	0.19074249  	0.10375923  
2023-05-13 18:53:56.308: Find a better model.
2023-05-13 18:54:03.732: [iter 80 : loss : 0.1430 = 0.0515 + 0.0869 + 0.0046, time: 7.421745]
2023-05-13 18:54:03.896: epoch 80:	0.02584030  	0.19080962  	0.10398995  
2023-05-13 18:54:03.896: Find a better model.
2023-05-13 18:54:11.150: [iter 81 : loss : 0.1427 = 0.0513 + 0.0868 + 0.0046, time: 7.253182]
2023-05-13 18:54:11.297: epoch 81:	0.02581914  	0.19075017  	0.10408498  
2023-05-13 18:54:18.535: [iter 82 : loss : 0.1413 = 0.0501 + 0.0866 + 0.0046, time: 7.237253]
2023-05-13 18:54:18.684: epoch 82:	0.02579797  	0.19077329  	0.10415440  
2023-05-13 18:54:25.939: [iter 83 : loss : 0.1403 = 0.0490 + 0.0866 + 0.0047, time: 7.253454]
2023-05-13 18:54:26.086: epoch 83:	0.02590381  	0.19142565  	0.10460268  
2023-05-13 18:54:26.086: Find a better model.
2023-05-13 18:54:33.328: [iter 84 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.239977]
2023-05-13 18:54:33.489: epoch 84:	0.02592498  	0.19163252  	0.10474296  
2023-05-13 18:54:33.489: Find a better model.
2023-05-13 18:54:40.733: [iter 85 : loss : 0.1391 = 0.0480 + 0.0863 + 0.0047, time: 7.243654]
2023-05-13 18:54:40.895: epoch 85:	0.02598143  	0.19207707  	0.10508670  
2023-05-13 18:54:40.895: Find a better model.
2023-05-13 18:54:48.136: [iter 86 : loss : 0.1393 = 0.0483 + 0.0863 + 0.0048, time: 7.238407]
2023-05-13 18:54:48.297: epoch 86:	0.02592498  	0.19157560  	0.10500851  
2023-05-13 18:54:55.716: [iter 87 : loss : 0.1364 = 0.0454 + 0.0862 + 0.0048, time: 7.417075]
2023-05-13 18:54:55.870: epoch 87:	0.02596027  	0.19193816  	0.10519266  
2023-05-13 18:55:03.118: [iter 88 : loss : 0.1359 = 0.0450 + 0.0861 + 0.0049, time: 7.245645]
2023-05-13 18:55:03.266: epoch 88:	0.02600260  	0.19226956  	0.10537396  
2023-05-13 18:55:03.266: Find a better model.
2023-05-13 18:55:10.699: [iter 89 : loss : 0.1357 = 0.0448 + 0.0860 + 0.0049, time: 7.430942]
2023-05-13 18:55:10.854: epoch 89:	0.02605905  	0.19282962  	0.10562582  
2023-05-13 18:55:10.854: Find a better model.
2023-05-13 18:55:18.112: [iter 90 : loss : 0.1359 = 0.0451 + 0.0859 + 0.0049, time: 7.256554]
2023-05-13 18:55:18.262: epoch 90:	0.02626369  	0.19408526  	0.10618530  
2023-05-13 18:55:18.262: Find a better model.
2023-05-13 18:55:25.515: [iter 91 : loss : 0.1348 = 0.0440 + 0.0858 + 0.0050, time: 7.251696]
2023-05-13 18:55:25.662: epoch 91:	0.02623546  	0.19353226  	0.10614736  
2023-05-13 18:55:32.918: [iter 92 : loss : 0.1338 = 0.0431 + 0.0857 + 0.0050, time: 7.254835]
2023-05-13 18:55:33.066: epoch 92:	0.02615784  	0.19282930  	0.10614622  
2023-05-13 18:55:40.314: [iter 93 : loss : 0.1339 = 0.0432 + 0.0856 + 0.0051, time: 7.244956]
2023-05-13 18:55:40.462: epoch 93:	0.02616490  	0.19276232  	0.10616048  
2023-05-13 18:55:47.710: [iter 94 : loss : 0.1319 = 0.0412 + 0.0856 + 0.0051, time: 7.247717]
2023-05-13 18:55:47.865: epoch 94:	0.02627075  	0.19328606  	0.10627171  
2023-05-13 18:55:55.122: [iter 95 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 7.254957]
2023-05-13 18:55:55.286: epoch 95:	0.02628486  	0.19335739  	0.10643426  
2023-05-13 18:56:02.517: [iter 96 : loss : 0.1313 = 0.0407 + 0.0854 + 0.0052, time: 7.230092]
2023-05-13 18:56:02.683: epoch 96:	0.02625663  	0.19358593  	0.10669418  
2023-05-13 18:56:09.910: [iter 97 : loss : 0.1296 = 0.0390 + 0.0853 + 0.0052, time: 7.224290]
2023-05-13 18:56:10.072: epoch 97:	0.02629897  	0.19368815  	0.10674784  
2023-05-13 18:56:17.312: [iter 98 : loss : 0.1308 = 0.0403 + 0.0853 + 0.0052, time: 7.238112]
2023-05-13 18:56:17.478: epoch 98:	0.02631309  	0.19417621  	0.10691008  
2023-05-13 18:56:17.478: Find a better model.
2023-05-13 18:56:24.891: [iter 99 : loss : 0.1295 = 0.0390 + 0.0852 + 0.0053, time: 7.411559]
2023-05-13 18:56:25.054: epoch 99:	0.02638365  	0.19481575  	0.10722614  
2023-05-13 18:56:25.055: Find a better model.
2023-05-13 18:56:32.296: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 7.239068]
2023-05-13 18:56:32.455: epoch 100:	0.02642599  	0.19512132  	0.10735592  
2023-05-13 18:56:32.456: Find a better model.
2023-05-13 18:56:39.870: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0053, time: 7.412549]
2023-05-13 18:56:40.032: epoch 101:	0.02648950  	0.19553842  	0.10750671  
2023-05-13 18:56:40.032: Find a better model.
2023-05-13 18:56:47.295: [iter 102 : loss : 0.1274 = 0.0370 + 0.0850 + 0.0054, time: 7.261734]
2023-05-13 18:56:47.445: epoch 102:	0.02650361  	0.19564039  	0.10775451  
2023-05-13 18:56:47.445: Find a better model.
2023-05-13 18:56:54.880: [iter 103 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 7.434803]
2023-05-13 18:56:55.027: epoch 103:	0.02657417  	0.19622640  	0.10800178  
2023-05-13 18:56:55.027: Find a better model.
2023-05-13 18:57:02.515: [iter 104 : loss : 0.1276 = 0.0374 + 0.0848 + 0.0054, time: 7.485268]
2023-05-13 18:57:02.666: epoch 104:	0.02656711  	0.19626535  	0.10812299  
2023-05-13 18:57:02.666: Find a better model.
2023-05-13 18:57:09.875: [iter 105 : loss : 0.1269 = 0.0367 + 0.0848 + 0.0055, time: 7.208211]
2023-05-13 18:57:10.022: epoch 105:	0.02655300  	0.19624379  	0.10803276  
2023-05-13 18:57:17.451: [iter 106 : loss : 0.1264 = 0.0362 + 0.0847 + 0.0055, time: 7.428175]
2023-05-13 18:57:17.615: epoch 106:	0.02662357  	0.19656585  	0.10832185  
2023-05-13 18:57:17.615: Find a better model.
2023-05-13 18:57:24.883: [iter 107 : loss : 0.1255 = 0.0353 + 0.0847 + 0.0055, time: 7.267167]
2023-05-13 18:57:25.032: epoch 107:	0.02667296  	0.19709574  	0.10860507  
2023-05-13 18:57:25.032: Find a better model.
2023-05-13 18:57:32.277: [iter 108 : loss : 0.1251 = 0.0350 + 0.0846 + 0.0056, time: 7.242857]
2023-05-13 18:57:32.425: epoch 108:	0.02668002  	0.19692634  	0.10865819  
2023-05-13 18:57:39.671: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 7.243792]
2023-05-13 18:57:39.818: epoch 109:	0.02658123  	0.19622745  	0.10848261  
2023-05-13 18:57:47.069: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0056, time: 7.248218]
2023-05-13 18:57:47.217: epoch 110:	0.02660945  	0.19629456  	0.10853789  
2023-05-13 18:57:54.457: [iter 111 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 7.237631]
2023-05-13 18:57:54.606: epoch 111:	0.02668708  	0.19679834  	0.10880415  
2023-05-13 18:58:01.867: [iter 112 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 7.260315]
2023-05-13 18:58:02.015: epoch 112:	0.02666591  	0.19659244  	0.10902764  
2023-05-13 18:58:09.275: [iter 113 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.258650]
2023-05-13 18:58:09.421: epoch 113:	0.02665180  	0.19680880  	0.10896751  
2023-05-13 18:58:16.651: [iter 114 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 7.229649]
2023-05-13 18:58:16.799: epoch 114:	0.02662357  	0.19635323  	0.10878558  
2023-05-13 18:58:24.058: [iter 115 : loss : 0.1217 = 0.0317 + 0.0842 + 0.0058, time: 7.257492]
2023-05-13 18:58:24.220: epoch 115:	0.02656713  	0.19607258  	0.10879755  
2023-05-13 18:58:31.448: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0058, time: 7.224890]
2023-05-13 18:58:31.597: epoch 116:	0.02659535  	0.19627652  	0.10878244  
2023-05-13 18:58:38.864: [iter 117 : loss : 0.1207 = 0.0308 + 0.0841 + 0.0059, time: 7.265192]
2023-05-13 18:58:39.018: epoch 117:	0.02656007  	0.19637795  	0.10872208  
2023-05-13 18:58:46.255: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.235492]
2023-05-13 18:58:46.403: epoch 118:	0.02665886  	0.19688471  	0.10913575  
2023-05-13 18:58:53.637: [iter 119 : loss : 0.1200 = 0.0301 + 0.0840 + 0.0059, time: 7.232730]
2023-05-13 18:58:53.786: epoch 119:	0.02662358  	0.19692999  	0.10907587  
2023-05-13 18:59:01.031: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 7.243166]
2023-05-13 18:59:01.180: epoch 120:	0.02664475  	0.19717829  	0.10915507  
2023-05-13 18:59:01.180: Find a better model.
2023-05-13 18:59:08.421: [iter 121 : loss : 0.1198 = 0.0299 + 0.0839 + 0.0060, time: 7.240420]
2023-05-13 18:59:08.585: epoch 121:	0.02672943  	0.19813278  	0.10934459  
2023-05-13 18:59:08.585: Find a better model.
2023-05-13 18:59:15.831: [iter 122 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0060, time: 7.243853]
2023-05-13 18:59:15.994: epoch 122:	0.02679293  	0.19839948  	0.10950817  
2023-05-13 18:59:15.994: Find a better model.
2023-05-13 18:59:23.219: [iter 123 : loss : 0.1191 = 0.0292 + 0.0838 + 0.0061, time: 7.224233]
2023-05-13 18:59:23.367: epoch 123:	0.02670120  	0.19737016  	0.10928497  
2023-05-13 18:59:30.619: [iter 124 : loss : 0.1183 = 0.0284 + 0.0837 + 0.0061, time: 7.251540]
2023-05-13 18:59:30.768: epoch 124:	0.02674354  	0.19751447  	0.10945728  
2023-05-13 18:59:38.023: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 7.253126]
2023-05-13 18:59:38.169: epoch 125:	0.02669414  	0.19709651  	0.10938895  
2023-05-13 18:59:45.411: [iter 126 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0062, time: 7.239139]
2023-05-13 18:59:45.558: epoch 126:	0.02668003  	0.19677283  	0.10918455  
2023-05-13 18:59:52.816: [iter 127 : loss : 0.1167 = 0.0269 + 0.0836 + 0.0062, time: 7.256058]
2023-05-13 18:59:52.966: epoch 127:	0.02668002  	0.19663624  	0.10931138  
2023-05-13 19:00:00.220: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 7.252773]
2023-05-13 19:00:00.382: epoch 128:	0.02666591  	0.19672151  	0.10926457  
2023-05-13 19:00:07.841: [iter 129 : loss : 0.1168 = 0.0271 + 0.0835 + 0.0063, time: 7.457969]
2023-05-13 19:00:07.992: epoch 129:	0.02679293  	0.19741198  	0.10972226  
2023-05-13 19:00:15.212: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.219315]
2023-05-13 19:00:15.360: epoch 130:	0.02670120  	0.19684508  	0.10953075  
2023-05-13 19:00:22.613: [iter 131 : loss : 0.1162 = 0.0265 + 0.0834 + 0.0063, time: 7.251449]
2023-05-13 19:00:22.763: epoch 131:	0.02671531  	0.19726321  	0.10976989  
2023-05-13 19:00:30.013: [iter 132 : loss : 0.1162 = 0.0265 + 0.0834 + 0.0063, time: 7.249071]
2023-05-13 19:00:30.161: epoch 132:	0.02668709  	0.19696243  	0.10958406  
2023-05-13 19:00:37.415: [iter 133 : loss : 0.1150 = 0.0253 + 0.0833 + 0.0064, time: 7.251913]
2023-05-13 19:00:37.562: epoch 133:	0.02670826  	0.19690569  	0.10990722  
2023-05-13 19:00:44.982: [iter 134 : loss : 0.1158 = 0.0261 + 0.0833 + 0.0064, time: 7.419245]
2023-05-13 19:00:45.130: epoch 134:	0.02677176  	0.19751565  	0.11017074  
2023-05-13 19:00:52.405: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 7.273299]
2023-05-13 19:00:52.553: epoch 135:	0.02671531  	0.19676918  	0.10991118  
2023-05-13 19:00:59.800: [iter 136 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0065, time: 7.244448]
2023-05-13 19:00:59.954: epoch 136:	0.02682115  	0.19753557  	0.11016432  
2023-05-13 19:01:07.211: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 7.256270]
2023-05-13 19:01:07.364: epoch 137:	0.02678588  	0.19748485  	0.11023229  
2023-05-13 19:01:14.602: [iter 138 : loss : 0.1143 = 0.0246 + 0.0831 + 0.0065, time: 7.236751]
2023-05-13 19:01:14.764: epoch 138:	0.02684233  	0.19792899  	0.11044716  
2023-05-13 19:01:22.005: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0065, time: 7.238794]
2023-05-13 19:01:22.154: epoch 139:	0.02684939  	0.19795384  	0.11045364  
2023-05-13 19:01:29.391: [iter 140 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 7.235795]
2023-05-13 19:01:29.543: epoch 140:	0.02695523  	0.19879647  	0.11067554  
2023-05-13 19:01:29.544: Find a better model.
2023-05-13 19:01:36.792: [iter 141 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0066, time: 7.246594]
2023-05-13 19:01:36.942: epoch 141:	0.02691995  	0.19854076  	0.11067394  
2023-05-13 19:01:44.178: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 7.233012]
2023-05-13 19:01:44.328: epoch 142:	0.02699757  	0.19903119  	0.11086769  
2023-05-13 19:01:44.328: Find a better model.
2023-05-13 19:01:51.583: [iter 143 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0067, time: 7.253846]
2023-05-13 19:01:51.731: epoch 143:	0.02702580  	0.19900362  	0.11098682  
2023-05-13 19:01:58.985: [iter 144 : loss : 0.1128 = 0.0232 + 0.0829 + 0.0067, time: 7.252967]
2023-05-13 19:01:59.146: epoch 144:	0.02704697  	0.19913809  	0.11095826  
2023-05-13 19:01:59.146: Find a better model.
2023-05-13 19:02:06.377: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 7.229515]
2023-05-13 19:02:06.539: epoch 145:	0.02706814  	0.19908036  	0.11122420  
2023-05-13 19:02:13.772: [iter 146 : loss : 0.1129 = 0.0233 + 0.0828 + 0.0067, time: 7.232412]
2023-05-13 19:02:13.920: epoch 146:	0.02694818  	0.19818583  	0.11081316  
2023-05-13 19:02:21.154: [iter 147 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0068, time: 7.231179]
2023-05-13 19:02:21.302: epoch 147:	0.02703991  	0.19891690  	0.11106112  
2023-05-13 19:02:28.562: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.259865]
2023-05-13 19:02:28.711: epoch 148:	0.02700463  	0.19882354  	0.11115983  
2023-05-13 19:02:35.971: [iter 149 : loss : 0.1120 = 0.0225 + 0.0827 + 0.0068, time: 7.258945]
2023-05-13 19:02:36.127: epoch 149:	0.02698346  	0.19861338  	0.11100886  
2023-05-13 19:02:43.374: [iter 150 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.246703]
2023-05-13 19:02:43.535: epoch 150:	0.02703285  	0.19906604  	0.11114492  
2023-05-13 19:02:50.765: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 7.227582]
2023-05-13 19:02:50.912: epoch 151:	0.02696934  	0.19865508  	0.11090387  
2023-05-13 19:02:58.155: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.241567]
2023-05-13 19:02:58.306: epoch 152:	0.02702579  	0.19906422  	0.11107253  
2023-05-13 19:03:05.557: [iter 153 : loss : 0.1100 = 0.0205 + 0.0826 + 0.0069, time: 7.248296]
2023-05-13 19:03:05.707: epoch 153:	0.02696934  	0.19880645  	0.11088952  
2023-05-13 19:03:12.952: [iter 154 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0069, time: 7.242284]
2023-05-13 19:03:13.102: epoch 154:	0.02698345  	0.19881129  	0.11106749  
2023-05-13 19:03:20.366: [iter 155 : loss : 0.1111 = 0.0217 + 0.0825 + 0.0070, time: 7.260273]
2023-05-13 19:03:20.513: epoch 155:	0.02705401  	0.19903478  	0.11106752  
2023-05-13 19:03:27.759: [iter 156 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0070, time: 7.245671]
2023-05-13 19:03:27.923: epoch 156:	0.02699051  	0.19871038  	0.11095170  
2023-05-13 19:03:35.142: [iter 157 : loss : 0.1102 = 0.0208 + 0.0824 + 0.0070, time: 7.216868]
2023-05-13 19:03:35.290: epoch 157:	0.02691289  	0.19812155  	0.11082416  
2023-05-13 19:03:42.540: [iter 158 : loss : 0.1095 = 0.0201 + 0.0824 + 0.0070, time: 7.247994]
2023-05-13 19:03:42.689: epoch 158:	0.02698345  	0.19860969  	0.11093593  
2023-05-13 19:03:49.954: [iter 159 : loss : 0.1100 = 0.0205 + 0.0824 + 0.0071, time: 7.264544]
2023-05-13 19:03:50.126: epoch 159:	0.02692700  	0.19841526  	0.11070000  
2023-05-13 19:03:57.362: [iter 160 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.235000]
2023-05-13 19:03:57.511: epoch 160:	0.02694817  	0.19824693  	0.11049512  
2023-05-13 19:04:04.929: [iter 161 : loss : 0.1091 = 0.0196 + 0.0823 + 0.0071, time: 7.416783]
2023-05-13 19:04:05.075: epoch 161:	0.02696934  	0.19853061  	0.11091643  
2023-05-13 19:04:12.333: [iter 162 : loss : 0.1086 = 0.0191 + 0.0823 + 0.0071, time: 7.256403]
2023-05-13 19:04:12.482: epoch 162:	0.02698345  	0.19802275  	0.11080051  
2023-05-13 19:04:19.903: [iter 163 : loss : 0.1089 = 0.0195 + 0.0823 + 0.0072, time: 7.419106]
2023-05-13 19:04:20.052: epoch 163:	0.02694111  	0.19797251  	0.11050650  
2023-05-13 19:04:27.332: [iter 164 : loss : 0.1085 = 0.0191 + 0.0823 + 0.0072, time: 7.279165]
2023-05-13 19:04:27.494: epoch 164:	0.02694816  	0.19780281  	0.11031576  
2023-05-13 19:04:34.733: [iter 165 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.237326]
2023-05-13 19:04:34.897: epoch 165:	0.02694111  	0.19779460  	0.11036756  
2023-05-13 19:04:42.126: [iter 166 : loss : 0.1083 = 0.0189 + 0.0822 + 0.0072, time: 7.227360]
2023-05-13 19:04:42.277: epoch 166:	0.02690583  	0.19752595  	0.11032221  
2023-05-13 19:04:49.529: [iter 167 : loss : 0.1085 = 0.0190 + 0.0822 + 0.0073, time: 7.251391]
2023-05-13 19:04:49.676: epoch 167:	0.02690583  	0.19719310  	0.11038946  
2023-05-13 19:04:56.914: [iter 168 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 7.236430]
2023-05-13 19:04:57.062: epoch 168:	0.02689878  	0.19705981  	0.11057904  
2023-05-13 19:05:04.309: [iter 169 : loss : 0.1079 = 0.0185 + 0.0821 + 0.0073, time: 7.245868]
2023-05-13 19:05:04.460: epoch 169:	0.02688466  	0.19725721  	0.11049459  
2023-05-13 19:05:04.460: Early stopping is trigger at epoch: 169
2023-05-13 19:05:04.460: best_result@epoch 144:

2023-05-13 19:05:04.460: 		0.0270      	0.1991      	0.1110      
2023-05-13 19:06:43.305: my pid: 11836
2023-05-13 19:06:43.305: model: model.general_recommender.SGL
2023-05-13 19:06:43.305: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 19:06:43.305: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 19:06:46.425: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 19:06:54.710: [iter 1 : loss : 0.7714 = 0.6930 + 0.0784 + 0.0000, time: 8.284336]
2023-05-13 19:06:54.861: epoch 1:	0.00162292  	0.01180996  	0.00580293  
2023-05-13 19:06:54.861: Find a better model.
2023-05-13 19:07:03.316: [iter 2 : loss : 0.7710 = 0.6929 + 0.0781 + 0.0000, time: 8.454191]
2023-05-13 19:07:03.503: epoch 2:	0.00282952  	0.02087802  	0.01071886  
2023-05-13 19:07:03.503: Find a better model.
2023-05-13 19:07:11.746: [iter 3 : loss : 0.7707 = 0.6926 + 0.0782 + 0.0000, time: 8.241393]
2023-05-13 19:07:11.914: epoch 3:	0.00512275  	0.03813418  	0.01816734  
2023-05-13 19:07:11.914: Find a better model.
2023-05-13 19:07:19.927: [iter 4 : loss : 0.7703 = 0.6921 + 0.0782 + 0.0000, time: 8.011824]
2023-05-13 19:07:20.080: epoch 4:	0.00777583  	0.05708859  	0.02741142  
2023-05-13 19:07:20.081: Find a better model.
2023-05-13 19:07:28.119: [iter 5 : loss : 0.7693 = 0.6909 + 0.0784 + 0.0000, time: 8.037369]
2023-05-13 19:07:28.280: epoch 5:	0.01129694  	0.08255678  	0.03962002  
2023-05-13 19:07:28.280: Find a better model.
2023-05-13 19:07:36.128: [iter 6 : loss : 0.7670 = 0.6883 + 0.0787 + 0.0000, time: 7.846838]
2023-05-13 19:07:36.281: epoch 6:	0.01499452  	0.10850871  	0.05328599  
2023-05-13 19:07:36.281: Find a better model.
2023-05-13 19:07:44.073: [iter 7 : loss : 0.7608 = 0.6813 + 0.0794 + 0.0000, time: 7.790131]
2023-05-13 19:07:44.222: epoch 7:	0.01790176  	0.13058949  	0.06455463  
2023-05-13 19:07:44.222: Find a better model.
2023-05-13 19:07:51.852: [iter 8 : loss : 0.7454 = 0.6641 + 0.0812 + 0.0001, time: 7.628603]
2023-05-13 19:07:51.999: epoch 8:	0.01876971  	0.13762635  	0.06941611  
2023-05-13 19:07:51.999: Find a better model.
2023-05-13 19:07:59.475: [iter 9 : loss : 0.7105 = 0.6254 + 0.0849 + 0.0001, time: 7.475903]
2023-05-13 19:07:59.624: epoch 9:	0.01885439  	0.13949879  	0.06988870  
2023-05-13 19:07:59.624: Find a better model.
2023-05-13 19:08:07.105: [iter 10 : loss : 0.6497 = 0.5591 + 0.0903 + 0.0002, time: 7.479621]
2023-05-13 19:08:07.255: epoch 10:	0.01884732  	0.13928095  	0.06931219  
2023-05-13 19:08:14.666: [iter 11 : loss : 0.5736 = 0.4778 + 0.0954 + 0.0004, time: 7.409338]
2023-05-13 19:08:14.813: epoch 11:	0.01871325  	0.13804752  	0.06898147  
2023-05-13 19:08:22.257: [iter 12 : loss : 0.5042 = 0.4048 + 0.0988 + 0.0005, time: 7.442488]
2023-05-13 19:08:22.403: epoch 12:	0.01850861  	0.13635853  	0.06875011  
2023-05-13 19:08:29.883: [iter 13 : loss : 0.4529 = 0.3515 + 0.1007 + 0.0007, time: 7.479283]
2023-05-13 19:08:30.030: epoch 13:	0.01853683  	0.13683677  	0.06914416  
2023-05-13 19:08:37.448: [iter 14 : loss : 0.4145 = 0.3119 + 0.1018 + 0.0008, time: 7.416086]
2023-05-13 19:08:37.598: epoch 14:	0.01872736  	0.13862334  	0.07004207  
2023-05-13 19:08:45.046: [iter 15 : loss : 0.3875 = 0.2844 + 0.1021 + 0.0010, time: 7.446935]
2023-05-13 19:08:45.194: epoch 15:	0.01891083  	0.13958956  	0.07078903  
2023-05-13 19:08:45.194: Find a better model.
2023-05-13 19:08:52.630: [iter 16 : loss : 0.3650 = 0.2618 + 0.1021 + 0.0011, time: 7.434821]
2023-05-13 19:08:52.777: epoch 16:	0.01903785  	0.14042000  	0.07142729  
2023-05-13 19:08:52.777: Find a better model.
2023-05-13 19:09:00.270: [iter 17 : loss : 0.3485 = 0.2453 + 0.1019 + 0.0012, time: 7.491119]
2023-05-13 19:09:00.420: epoch 17:	0.01926366  	0.14230262  	0.07246784  
2023-05-13 19:09:00.420: Find a better model.
2023-05-13 19:09:07.854: [iter 18 : loss : 0.3333 = 0.2302 + 0.1017 + 0.0013, time: 7.432919]
2023-05-13 19:09:08.002: epoch 18:	0.01961649  	0.14465341  	0.07338548  
2023-05-13 19:09:08.002: Find a better model.
2023-05-13 19:09:15.455: [iter 19 : loss : 0.3191 = 0.2163 + 0.1014 + 0.0014, time: 7.452382]
2023-05-13 19:09:15.602: epoch 19:	0.01982819  	0.14595447  	0.07440988  
2023-05-13 19:09:15.602: Find a better model.
2023-05-13 19:09:23.049: [iter 20 : loss : 0.3095 = 0.2070 + 0.1010 + 0.0015, time: 7.444710]
2023-05-13 19:09:23.199: epoch 20:	0.02001166  	0.14719792  	0.07498044  
2023-05-13 19:09:23.199: Find a better model.
2023-05-13 19:09:30.626: [iter 21 : loss : 0.2999 = 0.1978 + 0.1005 + 0.0016, time: 7.426565]
2023-05-13 19:09:30.774: epoch 21:	0.02018102  	0.14845932  	0.07573391  
2023-05-13 19:09:30.774: Find a better model.
2023-05-13 19:09:38.254: [iter 22 : loss : 0.2916 = 0.1898 + 0.1002 + 0.0017, time: 7.478102]
2023-05-13 19:09:38.400: epoch 22:	0.02039271  	0.14996712  	0.07646856  
2023-05-13 19:09:38.400: Find a better model.
2023-05-13 19:09:45.828: [iter 23 : loss : 0.2833 = 0.1818 + 0.0998 + 0.0017, time: 7.426096]
2023-05-13 19:09:45.977: epoch 23:	0.02060440  	0.15181813  	0.07752264  
2023-05-13 19:09:45.977: Find a better model.
2023-05-13 19:09:53.423: [iter 24 : loss : 0.2768 = 0.1757 + 0.0993 + 0.0018, time: 7.444899]
2023-05-13 19:09:53.574: epoch 24:	0.02077376  	0.15320539  	0.07823773  
2023-05-13 19:09:53.574: Find a better model.
2023-05-13 19:10:01.064: [iter 25 : loss : 0.2702 = 0.1694 + 0.0989 + 0.0019, time: 7.488501]
2023-05-13 19:10:01.213: epoch 25:	0.02096429  	0.15447824  	0.07899671  
2023-05-13 19:10:01.213: Find a better model.
2023-05-13 19:10:08.637: [iter 26 : loss : 0.2666 = 0.1662 + 0.0984 + 0.0019, time: 7.422234]
2023-05-13 19:10:08.785: epoch 26:	0.02112659  	0.15563357  	0.07983922  
2023-05-13 19:10:08.785: Find a better model.
2023-05-13 19:10:16.204: [iter 27 : loss : 0.2588 = 0.1588 + 0.0980 + 0.0020, time: 7.417694]
2023-05-13 19:10:16.367: epoch 27:	0.02129594  	0.15729651  	0.08065154  
2023-05-13 19:10:16.367: Find a better model.
2023-05-13 19:10:23.852: [iter 28 : loss : 0.2539 = 0.1542 + 0.0977 + 0.0021, time: 7.483401]
2023-05-13 19:10:23.999: epoch 28:	0.02138768  	0.15798610  	0.08133271  
2023-05-13 19:10:24.000: Find a better model.
2023-05-13 19:10:31.435: [iter 29 : loss : 0.2493 = 0.1500 + 0.0972 + 0.0021, time: 7.433963]
2023-05-13 19:10:31.583: epoch 29:	0.02161349  	0.15951592  	0.08227980  
2023-05-13 19:10:31.583: Find a better model.
2023-05-13 19:10:39.017: [iter 30 : loss : 0.2430 = 0.1439 + 0.0969 + 0.0022, time: 7.432864]
2023-05-13 19:10:39.165: epoch 30:	0.02171934  	0.16008672  	0.08270161  
2023-05-13 19:10:39.165: Find a better model.
2023-05-13 19:10:46.623: [iter 31 : loss : 0.2392 = 0.1405 + 0.0964 + 0.0023, time: 7.455459]
2023-05-13 19:10:46.775: epoch 31:	0.02188164  	0.16162135  	0.08347613  
2023-05-13 19:10:46.775: Find a better model.
2023-05-13 19:10:54.441: [iter 32 : loss : 0.2338 = 0.1354 + 0.0961 + 0.0023, time: 7.664513]
2023-05-13 19:10:54.589: epoch 32:	0.02198043  	0.16214179  	0.08384203  
2023-05-13 19:10:54.590: Find a better model.
2023-05-13 19:11:02.205: [iter 33 : loss : 0.2311 = 0.1330 + 0.0957 + 0.0024, time: 7.613670]
2023-05-13 19:11:02.355: epoch 33:	0.02222740  	0.16444652  	0.08484504  
2023-05-13 19:11:02.355: Find a better model.
2023-05-13 19:11:09.629: [iter 34 : loss : 0.2270 = 0.1292 + 0.0954 + 0.0024, time: 7.271639]
2023-05-13 19:11:09.776: epoch 34:	0.02234030  	0.16526334  	0.08532924  
2023-05-13 19:11:09.776: Find a better model.
2023-05-13 19:11:17.190: [iter 35 : loss : 0.2236 = 0.1261 + 0.0951 + 0.0025, time: 7.411815]
2023-05-13 19:11:17.342: epoch 35:	0.02255905  	0.16732068  	0.08621410  
2023-05-13 19:11:17.342: Find a better model.
2023-05-13 19:11:24.797: [iter 36 : loss : 0.2201 = 0.1228 + 0.0947 + 0.0026, time: 7.453988]
2023-05-13 19:11:24.947: epoch 36:	0.02270018  	0.16837171  	0.08695820  
2023-05-13 19:11:24.947: Find a better model.
2023-05-13 19:11:32.391: [iter 37 : loss : 0.2162 = 0.1192 + 0.0944 + 0.0026, time: 7.440782]
2023-05-13 19:11:32.552: epoch 37:	0.02284131  	0.16979091  	0.08766539  
2023-05-13 19:11:32.552: Find a better model.
2023-05-13 19:11:40.219: [iter 38 : loss : 0.2147 = 0.1179 + 0.0941 + 0.0027, time: 7.665754]
2023-05-13 19:11:40.373: epoch 38:	0.02301067  	0.17071065  	0.08836411  
2023-05-13 19:11:40.373: Find a better model.
2023-05-13 19:11:47.804: [iter 39 : loss : 0.2102 = 0.1136 + 0.0938 + 0.0027, time: 7.429613]
2023-05-13 19:11:47.954: epoch 39:	0.02303184  	0.17080460  	0.08877366  
2023-05-13 19:11:47.955: Find a better model.
2023-05-13 19:11:55.391: [iter 40 : loss : 0.2070 = 0.1107 + 0.0935 + 0.0028, time: 7.435024]
2023-05-13 19:11:55.554: epoch 40:	0.02320120  	0.17234351  	0.08937837  
2023-05-13 19:11:55.554: Find a better model.
2023-05-13 19:12:03.184: [iter 41 : loss : 0.2053 = 0.1092 + 0.0932 + 0.0028, time: 7.629138]
2023-05-13 19:12:03.354: epoch 41:	0.02332115  	0.17288014  	0.09005176  
2023-05-13 19:12:03.354: Find a better model.
2023-05-13 19:12:10.768: [iter 42 : loss : 0.2031 = 0.1074 + 0.0929 + 0.0029, time: 7.412912]
2023-05-13 19:12:10.917: epoch 42:	0.02344816  	0.17378268  	0.09054721  
2023-05-13 19:12:10.917: Find a better model.
2023-05-13 19:12:18.423: [iter 43 : loss : 0.1991 = 0.1036 + 0.0926 + 0.0029, time: 7.504314]
2023-05-13 19:12:18.572: epoch 43:	0.02358224  	0.17486192  	0.09135933  
2023-05-13 19:12:18.572: Find a better model.
2023-05-13 19:12:25.993: [iter 44 : loss : 0.1955 = 0.1002 + 0.0923 + 0.0030, time: 7.418700]
2023-05-13 19:12:26.157: epoch 44:	0.02362458  	0.17525055  	0.09196509  
2023-05-13 19:12:26.157: Find a better model.
2023-05-13 19:12:33.560: [iter 45 : loss : 0.1939 = 0.0987 + 0.0921 + 0.0030, time: 7.401150]
2023-05-13 19:12:33.707: epoch 45:	0.02373748  	0.17585850  	0.09263618  
2023-05-13 19:12:33.708: Find a better model.
2023-05-13 19:12:41.203: [iter 46 : loss : 0.1912 = 0.0963 + 0.0918 + 0.0031, time: 7.493094]
2023-05-13 19:12:41.357: epoch 46:	0.02375865  	0.17618749  	0.09300181  
2023-05-13 19:12:41.357: Find a better model.
2023-05-13 19:12:48.789: [iter 47 : loss : 0.1905 = 0.0957 + 0.0916 + 0.0031, time: 7.429826]
2023-05-13 19:12:48.938: epoch 47:	0.02389978  	0.17711164  	0.09354489  
2023-05-13 19:12:48.938: Find a better model.
2023-05-13 19:12:56.365: [iter 48 : loss : 0.1865 = 0.0919 + 0.0914 + 0.0032, time: 7.425437]
2023-05-13 19:12:56.531: epoch 48:	0.02392095  	0.17718913  	0.09391718  
2023-05-13 19:12:56.531: Find a better model.
2023-05-13 19:13:03.966: [iter 49 : loss : 0.1833 = 0.0889 + 0.0912 + 0.0032, time: 7.434185]
2023-05-13 19:13:04.113: epoch 49:	0.02412559  	0.17851198  	0.09468854  
2023-05-13 19:13:04.114: Find a better model.
2023-05-13 19:13:11.568: [iter 50 : loss : 0.1826 = 0.0884 + 0.0909 + 0.0033, time: 7.451723]
2023-05-13 19:13:11.716: epoch 50:	0.02415381  	0.17890994  	0.09503754  
2023-05-13 19:13:11.716: Find a better model.
2023-05-13 19:13:18.968: [iter 51 : loss : 0.1796 = 0.0855 + 0.0908 + 0.0033, time: 7.251381]
2023-05-13 19:13:19.116: epoch 51:	0.02421732  	0.17969459  	0.09539646  
2023-05-13 19:13:19.117: Find a better model.
2023-05-13 19:13:26.536: [iter 52 : loss : 0.1795 = 0.0856 + 0.0906 + 0.0034, time: 7.416818]
2023-05-13 19:13:26.699: epoch 52:	0.02425260  	0.17976491  	0.09573258  
2023-05-13 19:13:26.699: Find a better model.
2023-05-13 19:13:33.955: [iter 53 : loss : 0.1776 = 0.0838 + 0.0903 + 0.0034, time: 7.254828]
2023-05-13 19:13:34.104: epoch 53:	0.02440784  	0.18084356  	0.09641343  
2023-05-13 19:13:34.105: Find a better model.
2023-05-13 19:13:41.398: [iter 54 : loss : 0.1754 = 0.0817 + 0.0902 + 0.0035, time: 7.291855]
2023-05-13 19:13:41.557: epoch 54:	0.02443607  	0.18140598  	0.09684096  
2023-05-13 19:13:41.557: Find a better model.
2023-05-13 19:13:48.951: [iter 55 : loss : 0.1735 = 0.0801 + 0.0899 + 0.0035, time: 7.392755]
2023-05-13 19:13:49.099: epoch 55:	0.02447135  	0.18153404  	0.09714991  
2023-05-13 19:13:49.099: Find a better model.
2023-05-13 19:13:56.356: [iter 56 : loss : 0.1717 = 0.0784 + 0.0898 + 0.0036, time: 7.254722]
2023-05-13 19:13:56.504: epoch 56:	0.02459131  	0.18229057  	0.09768233  
2023-05-13 19:13:56.504: Find a better model.
2023-05-13 19:14:03.923: [iter 57 : loss : 0.1700 = 0.0768 + 0.0896 + 0.0036, time: 7.417578]
2023-05-13 19:14:04.073: epoch 57:	0.02466188  	0.18295893  	0.09783562  
2023-05-13 19:14:04.073: Find a better model.
2023-05-13 19:14:11.368: [iter 58 : loss : 0.1679 = 0.0749 + 0.0894 + 0.0037, time: 7.294405]
2023-05-13 19:14:11.520: epoch 58:	0.02478890  	0.18348193  	0.09836873  
2023-05-13 19:14:11.520: Find a better model.
2023-05-13 19:14:18.928: [iter 59 : loss : 0.1670 = 0.0741 + 0.0892 + 0.0037, time: 7.405134]
2023-05-13 19:14:19.076: epoch 59:	0.02495120  	0.18503928  	0.09888022  
2023-05-13 19:14:19.076: Find a better model.
2023-05-13 19:14:26.356: [iter 60 : loss : 0.1656 = 0.0728 + 0.0891 + 0.0037, time: 7.278261]
2023-05-13 19:14:26.514: epoch 60:	0.02497236  	0.18511696  	0.09915734  
2023-05-13 19:14:26.514: Find a better model.
2023-05-13 19:14:33.920: [iter 61 : loss : 0.1641 = 0.0714 + 0.0889 + 0.0038, time: 7.405062]
2023-05-13 19:14:34.068: epoch 61:	0.02507115  	0.18596666  	0.09947661  
2023-05-13 19:14:34.068: Find a better model.
2023-05-13 19:14:41.343: [iter 62 : loss : 0.1626 = 0.0700 + 0.0887 + 0.0038, time: 7.271270]
2023-05-13 19:14:41.498: epoch 62:	0.02507821  	0.18573323  	0.09953239  
2023-05-13 19:14:48.745: [iter 63 : loss : 0.1613 = 0.0689 + 0.0886 + 0.0039, time: 7.246223]
2023-05-13 19:14:48.891: epoch 63:	0.02512760  	0.18604045  	0.09985477  
2023-05-13 19:14:48.892: Find a better model.
2023-05-13 19:14:56.130: [iter 64 : loss : 0.1601 = 0.0679 + 0.0884 + 0.0039, time: 7.236013]
2023-05-13 19:14:56.279: epoch 64:	0.02512761  	0.18587740  	0.10010111  
2023-05-13 19:15:03.551: [iter 65 : loss : 0.1589 = 0.0667 + 0.0882 + 0.0040, time: 7.271003]
2023-05-13 19:15:03.698: epoch 65:	0.02517700  	0.18626113  	0.10048202  
2023-05-13 19:15:03.698: Find a better model.
2023-05-13 19:15:11.106: [iter 66 : loss : 0.1570 = 0.0650 + 0.0881 + 0.0040, time: 7.406910]
2023-05-13 19:15:11.252: epoch 66:	0.02512055  	0.18583199  	0.10070207  
2023-05-13 19:15:18.706: [iter 67 : loss : 0.1558 = 0.0638 + 0.0880 + 0.0040, time: 7.452041]
2023-05-13 19:15:18.858: epoch 67:	0.02519112  	0.18629529  	0.10095013  
2023-05-13 19:15:18.858: Find a better model.
2023-05-13 19:15:26.335: [iter 68 : loss : 0.1554 = 0.0636 + 0.0878 + 0.0041, time: 7.475739]
2023-05-13 19:15:26.483: epoch 68:	0.02524757  	0.18655089  	0.10121360  
2023-05-13 19:15:26.483: Find a better model.
2023-05-13 19:15:33.944: [iter 69 : loss : 0.1536 = 0.0618 + 0.0877 + 0.0041, time: 7.459185]
2023-05-13 19:15:34.094: epoch 69:	0.02535341  	0.18733874  	0.10149519  
2023-05-13 19:15:34.095: Find a better model.
2023-05-13 19:15:41.507: [iter 70 : loss : 0.1517 = 0.0600 + 0.0876 + 0.0042, time: 7.410760]
2023-05-13 19:15:41.656: epoch 70:	0.02538164  	0.18770793  	0.10176591  
2023-05-13 19:15:41.656: Find a better model.
2023-05-13 19:15:48.925: [iter 71 : loss : 0.1505 = 0.0589 + 0.0874 + 0.0042, time: 7.267503]
2023-05-13 19:15:49.072: epoch 71:	0.02535341  	0.18718840  	0.10178784  
2023-05-13 19:15:56.505: [iter 72 : loss : 0.1504 = 0.0589 + 0.0873 + 0.0043, time: 7.431649]
2023-05-13 19:15:56.672: epoch 72:	0.02548043  	0.18788405  	0.10228504  
2023-05-13 19:15:56.672: Find a better model.
2023-05-13 19:16:04.101: [iter 73 : loss : 0.1489 = 0.0574 + 0.0872 + 0.0043, time: 7.428545]
2023-05-13 19:16:04.250: epoch 73:	0.02554394  	0.18821919  	0.10251327  
2023-05-13 19:16:04.250: Find a better model.
2023-05-13 19:16:11.508: [iter 74 : loss : 0.1473 = 0.0560 + 0.0870 + 0.0043, time: 7.256955]
2023-05-13 19:16:11.675: epoch 74:	0.02566389  	0.18906607  	0.10300660  
2023-05-13 19:16:11.675: Find a better model.
2023-05-13 19:16:18.909: [iter 75 : loss : 0.1470 = 0.0556 + 0.0870 + 0.0044, time: 7.232735]
2023-05-13 19:16:19.057: epoch 75:	0.02556510  	0.18859217  	0.10290372  
2023-05-13 19:16:26.484: [iter 76 : loss : 0.1460 = 0.0548 + 0.0868 + 0.0044, time: 7.425984]
2023-05-13 19:16:26.631: epoch 76:	0.02564978  	0.18903184  	0.10317312  
2023-05-13 19:16:33.903: [iter 77 : loss : 0.1448 = 0.0537 + 0.0867 + 0.0045, time: 7.269371]
2023-05-13 19:16:34.067: epoch 77:	0.02571329  	0.18951878  	0.10339387  
2023-05-13 19:16:34.067: Find a better model.
2023-05-13 19:16:41.294: [iter 78 : loss : 0.1440 = 0.0529 + 0.0866 + 0.0045, time: 7.224444]
2023-05-13 19:16:41.450: epoch 78:	0.02568507  	0.18959460  	0.10349785  
2023-05-13 19:16:41.450: Find a better model.
2023-05-13 19:16:48.708: [iter 79 : loss : 0.1428 = 0.0517 + 0.0865 + 0.0045, time: 7.257297]
2023-05-13 19:16:48.869: epoch 79:	0.02577679  	0.19023179  	0.10375325  
2023-05-13 19:16:48.869: Find a better model.
2023-05-13 19:16:56.278: [iter 80 : loss : 0.1422 = 0.0512 + 0.0864 + 0.0046, time: 7.406883]
2023-05-13 19:16:56.430: epoch 80:	0.02586854  	0.19120397  	0.10400402  
2023-05-13 19:16:56.430: Find a better model.
2023-05-13 19:17:03.693: [iter 81 : loss : 0.1418 = 0.0509 + 0.0863 + 0.0046, time: 7.260995]
2023-05-13 19:17:03.841: epoch 81:	0.02584031  	0.19081569  	0.10412396  
2023-05-13 19:17:11.260: [iter 82 : loss : 0.1405 = 0.0497 + 0.0861 + 0.0047, time: 7.417507]
2023-05-13 19:17:11.406: epoch 82:	0.02588971  	0.19092220  	0.10428867  
2023-05-13 19:17:18.689: [iter 83 : loss : 0.1394 = 0.0487 + 0.0861 + 0.0047, time: 7.280216]
2023-05-13 19:17:18.854: epoch 83:	0.02598144  	0.19173424  	0.10459167  
2023-05-13 19:17:18.854: Find a better model.
2023-05-13 19:17:26.262: [iter 84 : loss : 0.1396 = 0.0489 + 0.0860 + 0.0047, time: 7.404854]
2023-05-13 19:17:26.410: epoch 84:	0.02601672  	0.19171603  	0.10476717  
2023-05-13 19:17:33.670: [iter 85 : loss : 0.1382 = 0.0476 + 0.0858 + 0.0048, time: 7.255740]
2023-05-13 19:17:33.817: epoch 85:	0.02608729  	0.19248301  	0.10503674  
2023-05-13 19:17:33.817: Find a better model.
2023-05-13 19:17:41.248: [iter 86 : loss : 0.1384 = 0.0479 + 0.0857 + 0.0048, time: 7.429027]
2023-05-13 19:17:41.396: epoch 86:	0.02617903  	0.19275993  	0.10532593  
2023-05-13 19:17:41.396: Find a better model.
2023-05-13 19:17:48.689: [iter 87 : loss : 0.1355 = 0.0450 + 0.0857 + 0.0048, time: 7.290649]
2023-05-13 19:17:48.840: epoch 87:	0.02626370  	0.19352771  	0.10577342  
2023-05-13 19:17:48.840: Find a better model.
2023-05-13 19:17:56.286: [iter 88 : loss : 0.1349 = 0.0444 + 0.0856 + 0.0049, time: 7.444937]
2023-05-13 19:17:56.456: epoch 88:	0.02634133  	0.19405253  	0.10589918  
2023-05-13 19:17:56.456: Find a better model.
2023-05-13 19:18:03.861: [iter 89 : loss : 0.1347 = 0.0443 + 0.0855 + 0.0049, time: 7.404689]
2023-05-13 19:18:04.008: epoch 89:	0.02632721  	0.19377679  	0.10597412  
2023-05-13 19:18:11.271: [iter 90 : loss : 0.1351 = 0.0448 + 0.0854 + 0.0050, time: 7.261250]
2023-05-13 19:18:11.421: epoch 90:	0.02638366  	0.19424155  	0.10630105  
2023-05-13 19:18:11.421: Find a better model.
2023-05-13 19:18:18.682: [iter 91 : loss : 0.1337 = 0.0435 + 0.0853 + 0.0050, time: 7.259156]
2023-05-13 19:18:18.829: epoch 91:	0.02634132  	0.19410740  	0.10618503  
2023-05-13 19:18:26.257: [iter 92 : loss : 0.1329 = 0.0427 + 0.0852 + 0.0050, time: 7.425787]
2023-05-13 19:18:26.408: epoch 92:	0.02636955  	0.19415765  	0.10642400  
2023-05-13 19:18:33.827: [iter 93 : loss : 0.1331 = 0.0429 + 0.0851 + 0.0051, time: 7.417942]
2023-05-13 19:18:33.976: epoch 93:	0.02639072  	0.19443646  	0.10661571  
2023-05-13 19:18:33.976: Find a better model.
2023-05-13 19:18:41.432: [iter 94 : loss : 0.1310 = 0.0408 + 0.0851 + 0.0051, time: 7.455308]
2023-05-13 19:18:41.582: epoch 94:	0.02645423  	0.19495748  	0.10688186  
2023-05-13 19:18:41.582: Find a better model.
2023-05-13 19:18:49.037: [iter 95 : loss : 0.1305 = 0.0403 + 0.0850 + 0.0051, time: 7.454019]
2023-05-13 19:18:49.184: epoch 95:	0.02651067  	0.19545066  	0.10702416  
2023-05-13 19:18:49.184: Find a better model.
2023-05-13 19:18:56.456: [iter 96 : loss : 0.1304 = 0.0403 + 0.0849 + 0.0052, time: 7.270566]
2023-05-13 19:18:56.604: epoch 96:	0.02651067  	0.19520344  	0.10696179  
2023-05-13 19:19:04.027: [iter 97 : loss : 0.1288 = 0.0388 + 0.0848 + 0.0052, time: 7.420459]
2023-05-13 19:19:04.177: epoch 97:	0.02661652  	0.19602621  	0.10721947  
2023-05-13 19:19:04.177: Find a better model.
2023-05-13 19:19:11.665: [iter 98 : loss : 0.1298 = 0.0397 + 0.0848 + 0.0053, time: 7.486227]
2023-05-13 19:19:11.813: epoch 98:	0.02648951  	0.19495118  	0.10698339  
2023-05-13 19:19:19.251: [iter 99 : loss : 0.1285 = 0.0385 + 0.0847 + 0.0053, time: 7.435844]
2023-05-13 19:19:19.412: epoch 99:	0.02653185  	0.19537719  	0.10720365  
2023-05-13 19:19:26.829: [iter 100 : loss : 0.1278 = 0.0378 + 0.0846 + 0.0053, time: 7.415502]
2023-05-13 19:19:26.977: epoch 100:	0.02660241  	0.19583265  	0.10735118  
2023-05-13 19:19:34.453: [iter 101 : loss : 0.1277 = 0.0377 + 0.0845 + 0.0054, time: 7.475031]
2023-05-13 19:19:34.612: epoch 101:	0.02658830  	0.19578722  	0.10751029  
2023-05-13 19:19:42.054: [iter 102 : loss : 0.1265 = 0.0366 + 0.0845 + 0.0054, time: 7.440175]
2023-05-13 19:19:42.203: epoch 102:	0.02659535  	0.19578266  	0.10760481  
2023-05-13 19:19:49.613: [iter 103 : loss : 0.1263 = 0.0365 + 0.0844 + 0.0054, time: 7.408795]
2023-05-13 19:19:49.776: epoch 103:	0.02660947  	0.19587138  	0.10775618  
2023-05-13 19:19:57.238: [iter 104 : loss : 0.1268 = 0.0370 + 0.0843 + 0.0055, time: 7.460143]
2023-05-13 19:19:57.385: epoch 104:	0.02659536  	0.19578022  	0.10780028  
2023-05-13 19:20:04.841: [iter 105 : loss : 0.1259 = 0.0362 + 0.0843 + 0.0055, time: 7.454809]
2023-05-13 19:20:04.988: epoch 105:	0.02654595  	0.19538055  	0.10783873  
2023-05-13 19:20:12.422: [iter 106 : loss : 0.1255 = 0.0358 + 0.0842 + 0.0055, time: 7.432773]
2023-05-13 19:20:12.575: epoch 106:	0.02651772  	0.19503069  	0.10789784  
2023-05-13 19:20:20.020: [iter 107 : loss : 0.1246 = 0.0348 + 0.0841 + 0.0056, time: 7.444078]
2023-05-13 19:20:20.170: epoch 107:	0.02658829  	0.19516473  	0.10801804  
2023-05-13 19:20:27.609: [iter 108 : loss : 0.1244 = 0.0348 + 0.0841 + 0.0056, time: 7.436404]
2023-05-13 19:20:27.757: epoch 108:	0.02667297  	0.19608991  	0.10834550  
2023-05-13 19:20:27.757: Find a better model.
2023-05-13 19:20:35.043: [iter 109 : loss : 0.1230 = 0.0334 + 0.0840 + 0.0056, time: 7.284000]
2023-05-13 19:20:35.191: epoch 109:	0.02667297  	0.19603102  	0.10828386  
2023-05-13 19:20:42.607: [iter 110 : loss : 0.1226 = 0.0330 + 0.0839 + 0.0057, time: 7.415593]
2023-05-13 19:20:42.775: epoch 110:	0.02666592  	0.19585532  	0.10828058  
2023-05-13 19:20:50.200: [iter 111 : loss : 0.1226 = 0.0330 + 0.0839 + 0.0057, time: 7.424483]
2023-05-13 19:20:50.372: epoch 111:	0.02663769  	0.19564572  	0.10834692  
2023-05-13 19:20:57.837: [iter 112 : loss : 0.1224 = 0.0328 + 0.0838 + 0.0057, time: 7.464248]
2023-05-13 19:20:57.986: epoch 112:	0.02669414  	0.19590041  	0.10840451  
2023-05-13 19:21:05.422: [iter 113 : loss : 0.1223 = 0.0327 + 0.0838 + 0.0058, time: 7.434976]
2023-05-13 19:21:05.594: epoch 113:	0.02665886  	0.19568625  	0.10838200  
2023-05-13 19:21:12.990: [iter 114 : loss : 0.1213 = 0.0318 + 0.0837 + 0.0058, time: 7.394147]
2023-05-13 19:21:13.140: epoch 114:	0.02672942  	0.19622922  	0.10850818  
2023-05-13 19:21:13.140: Find a better model.
2023-05-13 19:21:20.584: [iter 115 : loss : 0.1207 = 0.0312 + 0.0837 + 0.0058, time: 7.442476]
2023-05-13 19:21:20.730: epoch 115:	0.02677882  	0.19655961  	0.10873193  
2023-05-13 19:21:20.730: Find a better model.
2023-05-13 19:21:28.191: [iter 116 : loss : 0.1200 = 0.0305 + 0.0836 + 0.0059, time: 7.459322]
2023-05-13 19:21:28.353: epoch 116:	0.02682821  	0.19708878  	0.10894936  
2023-05-13 19:21:28.353: Find a better model.
2023-05-13 19:21:35.770: [iter 117 : loss : 0.1200 = 0.0305 + 0.0836 + 0.0059, time: 7.416201]
2023-05-13 19:21:35.917: epoch 117:	0.02675059  	0.19646081  	0.10878034  
2023-05-13 19:21:43.189: [iter 118 : loss : 0.1201 = 0.0307 + 0.0835 + 0.0059, time: 7.269598]
2023-05-13 19:21:43.338: epoch 118:	0.02685644  	0.19713427  	0.10920245  
2023-05-13 19:21:43.338: Find a better model.
2023-05-13 19:21:50.598: [iter 119 : loss : 0.1190 = 0.0296 + 0.0834 + 0.0060, time: 7.256769]
2023-05-13 19:21:50.751: epoch 119:	0.02695523  	0.19828393  	0.10946687  
2023-05-13 19:21:50.751: Find a better model.
2023-05-13 19:21:58.175: [iter 120 : loss : 0.1192 = 0.0298 + 0.0834 + 0.0060, time: 7.423572]
2023-05-13 19:21:58.324: epoch 120:	0.02687055  	0.19750404  	0.10933816  
2023-05-13 19:22:05.769: [iter 121 : loss : 0.1190 = 0.0296 + 0.0833 + 0.0060, time: 7.443653]
2023-05-13 19:22:05.919: epoch 121:	0.02687056  	0.19741738  	0.10936837  
2023-05-13 19:22:13.378: [iter 122 : loss : 0.1183 = 0.0289 + 0.0833 + 0.0061, time: 7.456279]
2023-05-13 19:22:13.525: epoch 122:	0.02687762  	0.19766343  	0.10942609  
2023-05-13 19:22:20.783: [iter 123 : loss : 0.1182 = 0.0289 + 0.0833 + 0.0061, time: 7.256273]
2023-05-13 19:22:20.930: epoch 123:	0.02687761  	0.19761166  	0.10940767  
2023-05-13 19:22:28.410: [iter 124 : loss : 0.1174 = 0.0281 + 0.0832 + 0.0061, time: 7.478775]
2023-05-13 19:22:28.559: epoch 124:	0.02682116  	0.19718145  	0.10947678  
2023-05-13 19:22:35.980: [iter 125 : loss : 0.1168 = 0.0275 + 0.0831 + 0.0062, time: 7.419882]
2023-05-13 19:22:36.136: epoch 125:	0.02674354  	0.19643310  	0.10944100  
2023-05-13 19:22:43.576: [iter 126 : loss : 0.1168 = 0.0275 + 0.0831 + 0.0062, time: 7.438348]
2023-05-13 19:22:43.736: epoch 126:	0.02677177  	0.19695684  	0.10939758  
2023-05-13 19:22:51.195: [iter 127 : loss : 0.1158 = 0.0266 + 0.0831 + 0.0062, time: 7.457357]
2023-05-13 19:22:51.341: epoch 127:	0.02683527  	0.19729473  	0.10956367  
2023-05-13 19:22:58.751: [iter 128 : loss : 0.1170 = 0.0277 + 0.0830 + 0.0063, time: 7.407835]
2023-05-13 19:22:58.899: epoch 128:	0.02682821  	0.19728664  	0.10972691  
2023-05-13 19:23:06.339: [iter 129 : loss : 0.1161 = 0.0269 + 0.0830 + 0.0063, time: 7.438229]
2023-05-13 19:23:06.488: epoch 129:	0.02682821  	0.19706802  	0.10974655  
2023-05-13 19:23:13.974: [iter 130 : loss : 0.1161 = 0.0269 + 0.0829 + 0.0063, time: 7.483540]
2023-05-13 19:23:14.121: epoch 130:	0.02685644  	0.19778308  	0.10991385  
2023-05-13 19:23:21.576: [iter 131 : loss : 0.1153 = 0.0261 + 0.0829 + 0.0063, time: 7.452726]
2023-05-13 19:23:21.729: epoch 131:	0.02691995  	0.19807228  	0.10992478  
2023-05-13 19:23:29.140: [iter 132 : loss : 0.1156 = 0.0263 + 0.0829 + 0.0064, time: 7.410206]
2023-05-13 19:23:29.290: epoch 132:	0.02698345  	0.19842063  	0.11014955  
2023-05-13 19:23:29.290: Find a better model.
2023-05-13 19:23:36.737: [iter 133 : loss : 0.1142 = 0.0250 + 0.0828 + 0.0064, time: 7.445139]
2023-05-13 19:23:36.888: epoch 133:	0.02694817  	0.19827352  	0.11020603  
2023-05-13 19:23:44.155: [iter 134 : loss : 0.1149 = 0.0258 + 0.0828 + 0.0064, time: 7.266212]
2023-05-13 19:23:44.306: epoch 134:	0.02695522  	0.19819462  	0.11027485  
2023-05-13 19:23:51.776: [iter 135 : loss : 0.1146 = 0.0254 + 0.0827 + 0.0065, time: 7.468522]
2023-05-13 19:23:51.924: epoch 135:	0.02694817  	0.19802505  	0.11033240  
2023-05-13 19:23:59.343: [iter 136 : loss : 0.1143 = 0.0252 + 0.0827 + 0.0065, time: 7.417076]
2023-05-13 19:23:59.493: epoch 136:	0.02694111  	0.19816159  	0.11028417  
2023-05-13 19:24:06.922: [iter 137 : loss : 0.1138 = 0.0247 + 0.0826 + 0.0065, time: 7.427870]
2023-05-13 19:24:07.073: epoch 137:	0.02693405  	0.19815488  	0.11014874  
2023-05-13 19:24:14.568: [iter 138 : loss : 0.1135 = 0.0243 + 0.0826 + 0.0065, time: 7.493642]
2023-05-13 19:24:14.715: epoch 138:	0.02695522  	0.19847465  	0.11024834  
2023-05-13 19:24:14.716: Find a better model.
2023-05-13 19:24:22.123: [iter 139 : loss : 0.1134 = 0.0243 + 0.0825 + 0.0066, time: 7.406080]
2023-05-13 19:24:22.273: epoch 139:	0.02697639  	0.19857207  	0.11018341  
2023-05-13 19:24:22.273: Find a better model.
2023-05-13 19:24:29.716: [iter 140 : loss : 0.1130 = 0.0239 + 0.0825 + 0.0066, time: 7.439831]
2023-05-13 19:24:29.868: epoch 140:	0.02692700  	0.19850583  	0.11030334  
2023-05-13 19:24:37.139: [iter 141 : loss : 0.1135 = 0.0244 + 0.0825 + 0.0066, time: 7.269155]
2023-05-13 19:24:37.287: epoch 141:	0.02686348  	0.19784714  	0.11031114  
2023-05-13 19:24:44.556: [iter 142 : loss : 0.1123 = 0.0232 + 0.0824 + 0.0067, time: 7.267787]
2023-05-13 19:24:44.706: epoch 142:	0.02687760  	0.19781396  	0.11036847  
2023-05-13 19:24:52.116: [iter 143 : loss : 0.1125 = 0.0235 + 0.0824 + 0.0067, time: 7.408825]
2023-05-13 19:24:52.267: epoch 143:	0.02685643  	0.19765072  	0.11030528  
2023-05-13 19:24:59.523: [iter 144 : loss : 0.1119 = 0.0228 + 0.0823 + 0.0067, time: 7.254733]
2023-05-13 19:24:59.671: epoch 144:	0.02685643  	0.19765307  	0.11047376  
2023-05-13 19:25:06.915: [iter 145 : loss : 0.1119 = 0.0229 + 0.0823 + 0.0067, time: 7.242744]
2023-05-13 19:25:07.063: epoch 145:	0.02689171  	0.19734688  	0.11041153  
2023-05-13 19:25:14.359: [iter 146 : loss : 0.1121 = 0.0231 + 0.0823 + 0.0068, time: 7.294418]
2023-05-13 19:25:14.525: epoch 146:	0.02690583  	0.19770305  	0.11048973  
2023-05-13 19:25:21.901: [iter 147 : loss : 0.1122 = 0.0232 + 0.0823 + 0.0068, time: 7.375014]
2023-05-13 19:25:22.049: epoch 147:	0.02701167  	0.19864678  	0.11088522  
2023-05-13 19:25:22.049: Find a better model.
2023-05-13 19:25:29.541: [iter 148 : loss : 0.1106 = 0.0215 + 0.0822 + 0.0068, time: 7.489839]
2023-05-13 19:25:29.690: epoch 148:	0.02696933  	0.19837211  	0.11087259  
2023-05-13 19:25:36.930: [iter 149 : loss : 0.1113 = 0.0223 + 0.0822 + 0.0068, time: 7.238670]
2023-05-13 19:25:37.077: epoch 149:	0.02694816  	0.19815013  	0.11078993  
2023-05-13 19:25:44.314: [iter 150 : loss : 0.1108 = 0.0218 + 0.0822 + 0.0069, time: 7.234128]
2023-05-13 19:25:44.475: epoch 150:	0.02695522  	0.19800524  	0.11085060  
2023-05-13 19:25:51.888: [iter 151 : loss : 0.1106 = 0.0216 + 0.0821 + 0.0069, time: 7.410776]
2023-05-13 19:25:52.039: epoch 151:	0.02694110  	0.19777058  	0.11070961  
2023-05-13 19:25:59.309: [iter 152 : loss : 0.1101 = 0.0210 + 0.0821 + 0.0069, time: 7.267999]
2023-05-13 19:25:59.458: epoch 152:	0.02684232  	0.19706446  	0.11016111  
2023-05-13 19:26:06.880: [iter 153 : loss : 0.1091 = 0.0201 + 0.0821 + 0.0069, time: 7.419739]
2023-05-13 19:26:07.029: epoch 153:	0.02689877  	0.19745192  	0.11047930  
2023-05-13 19:26:14.294: [iter 154 : loss : 0.1098 = 0.0207 + 0.0820 + 0.0070, time: 7.263505]
2023-05-13 19:26:14.443: epoch 154:	0.02687055  	0.19716044  	0.11053598  
2023-05-13 19:26:21.871: [iter 155 : loss : 0.1104 = 0.0214 + 0.0820 + 0.0070, time: 7.426777]
2023-05-13 19:26:22.022: epoch 155:	0.02686349  	0.19743921  	0.11055817  
2023-05-13 19:26:29.286: [iter 156 : loss : 0.1096 = 0.0206 + 0.0820 + 0.0070, time: 7.261878]
2023-05-13 19:26:29.434: epoch 156:	0.02684232  	0.19722116  	0.11047260  
2023-05-13 19:26:36.866: [iter 157 : loss : 0.1095 = 0.0205 + 0.0819 + 0.0071, time: 7.431097]
2023-05-13 19:26:37.016: epoch 157:	0.02686348  	0.19746614  	0.11066515  
2023-05-13 19:26:44.298: [iter 158 : loss : 0.1087 = 0.0197 + 0.0819 + 0.0071, time: 7.279570]
2023-05-13 19:26:44.445: epoch 158:	0.02694817  	0.19824506  	0.11079141  
2023-05-13 19:26:51.687: [iter 159 : loss : 0.1092 = 0.0202 + 0.0819 + 0.0071, time: 7.241245]
2023-05-13 19:26:51.834: epoch 159:	0.02699756  	0.19846483  	0.11071093  
2023-05-13 19:26:59.260: [iter 160 : loss : 0.1087 = 0.0198 + 0.0818 + 0.0071, time: 7.425422]
2023-05-13 19:26:59.411: epoch 160:	0.02699756  	0.19848721  	0.11090167  
2023-05-13 19:27:06.687: [iter 161 : loss : 0.1083 = 0.0193 + 0.0818 + 0.0072, time: 7.275253]
2023-05-13 19:27:06.835: epoch 161:	0.02698345  	0.19829887  	0.11068529  
2023-05-13 19:27:14.260: [iter 162 : loss : 0.1079 = 0.0189 + 0.0818 + 0.0072, time: 7.424142]
2023-05-13 19:27:14.409: epoch 162:	0.02698345  	0.19833322  	0.11063603  
2023-05-13 19:27:21.678: [iter 163 : loss : 0.1082 = 0.0192 + 0.0817 + 0.0072, time: 7.267058]
2023-05-13 19:27:21.826: epoch 163:	0.02699756  	0.19843169  	0.11054997  
2023-05-13 19:27:29.100: [iter 164 : loss : 0.1078 = 0.0188 + 0.0817 + 0.0072, time: 7.272015]
2023-05-13 19:27:29.249: epoch 164:	0.02696228  	0.19828358  	0.11054792  
2023-05-13 19:27:36.462: [iter 165 : loss : 0.1078 = 0.0189 + 0.0817 + 0.0073, time: 7.210994]
2023-05-13 19:27:36.611: epoch 165:	0.02687760  	0.19734190  	0.11031618  
2023-05-13 19:27:43.861: [iter 166 : loss : 0.1075 = 0.0185 + 0.0817 + 0.0073, time: 7.246847]
2023-05-13 19:27:44.022: epoch 166:	0.02693406  	0.19752349  	0.11028257  
2023-05-13 19:27:51.449: [iter 167 : loss : 0.1080 = 0.0190 + 0.0817 + 0.0073, time: 7.426581]
2023-05-13 19:27:51.597: epoch 167:	0.02682820  	0.19680028  	0.11004048  
2023-05-13 19:27:58.892: [iter 168 : loss : 0.1070 = 0.0181 + 0.0816 + 0.0073, time: 7.294563]
2023-05-13 19:27:59.057: epoch 168:	0.02683526  	0.19684778  	0.10991852  
2023-05-13 19:28:06.457: [iter 169 : loss : 0.1074 = 0.0184 + 0.0816 + 0.0074, time: 7.398470]
2023-05-13 19:28:06.605: epoch 169:	0.02683526  	0.19705707  	0.10996339  
2023-05-13 19:28:13.851: [iter 170 : loss : 0.1069 = 0.0179 + 0.0816 + 0.0074, time: 7.245326]
2023-05-13 19:28:14.001: epoch 170:	0.02691288  	0.19761014  	0.11028236  
2023-05-13 19:28:21.274: [iter 171 : loss : 0.1075 = 0.0186 + 0.0816 + 0.0074, time: 7.271070]
2023-05-13 19:28:21.421: epoch 171:	0.02689877  	0.19741011  	0.11015867  
2023-05-13 19:28:28.661: [iter 172 : loss : 0.1062 = 0.0173 + 0.0815 + 0.0074, time: 7.238935]
2023-05-13 19:28:28.810: epoch 172:	0.02687760  	0.19729707  	0.11004856  
2023-05-13 19:28:28.811: Early stopping is trigger at epoch: 172
2023-05-13 19:28:28.811: best_result@epoch 147:

2023-05-13 19:28:28.811: 		0.0270      	0.1986      	0.1109      
2023-05-13 19:34:48.224: my pid: 11024
2023-05-13 19:34:48.224: model: model.general_recommender.SGL
2023-05-13 19:34:48.224: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 19:34:48.224: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 19:34:51.357: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 19:34:59.799: [iter 1 : loss : 0.7712 = 0.6930 + 0.0782 + 0.0000, time: 8.441873]
2023-05-13 19:34:59.962: epoch 1:	0.00162292  	0.01159665  	0.00567931  
2023-05-13 19:34:59.963: Find a better model.
2023-05-13 19:35:08.546: [iter 2 : loss : 0.7707 = 0.6929 + 0.0778 + 0.0000, time: 8.581827]
2023-05-13 19:35:08.734: epoch 2:	0.00268840  	0.01959877  	0.00963503  
2023-05-13 19:35:08.734: Find a better model.
2023-05-13 19:35:16.958: [iter 3 : loss : 0.7705 = 0.6926 + 0.0778 + 0.0000, time: 8.222956]
2023-05-13 19:35:17.134: epoch 3:	0.00473466  	0.03529252  	0.01717857  
2023-05-13 19:35:17.134: Find a better model.
2023-05-13 19:35:25.355: [iter 4 : loss : 0.7701 = 0.6922 + 0.0779 + 0.0000, time: 8.220066]
2023-05-13 19:35:25.505: epoch 4:	0.00720429  	0.05228785  	0.02579726  
2023-05-13 19:35:25.505: Find a better model.
2023-05-13 19:35:33.549: [iter 5 : loss : 0.7692 = 0.6912 + 0.0780 + 0.0000, time: 8.043320]
2023-05-13 19:35:33.699: epoch 5:	0.01037255  	0.07472656  	0.03623707  
2023-05-13 19:35:33.699: Find a better model.
2023-05-13 19:35:41.539: [iter 6 : loss : 0.7673 = 0.6890 + 0.0782 + 0.0000, time: 7.837428]
2023-05-13 19:35:41.687: epoch 6:	0.01395723  	0.10112345  	0.04835453  
2023-05-13 19:35:41.687: Find a better model.
2023-05-13 19:35:49.319: [iter 7 : loss : 0.7620 = 0.6831 + 0.0788 + 0.0000, time: 7.630638]
2023-05-13 19:35:49.466: epoch 7:	0.01703382  	0.12358531  	0.06042834  
2023-05-13 19:35:49.466: Find a better model.
2023-05-13 19:35:57.110: [iter 8 : loss : 0.7488 = 0.6685 + 0.0803 + 0.0001, time: 7.643452]
2023-05-13 19:35:57.259: epoch 8:	0.01836042  	0.13455512  	0.06702355  
2023-05-13 19:35:57.259: Find a better model.
2023-05-13 19:36:04.919: [iter 9 : loss : 0.7184 = 0.6347 + 0.0835 + 0.0001, time: 7.658827]
2023-05-13 19:36:05.084: epoch 9:	0.01872736  	0.13764247  	0.06912876  
2023-05-13 19:36:05.084: Find a better model.
2023-05-13 19:36:12.714: [iter 10 : loss : 0.6628 = 0.5740 + 0.0886 + 0.0002, time: 7.629341]
2023-05-13 19:36:12.860: epoch 10:	0.01884732  	0.13932404  	0.06920850  
2023-05-13 19:36:12.860: Find a better model.
2023-05-13 19:36:20.507: [iter 11 : loss : 0.5883 = 0.4942 + 0.0938 + 0.0004, time: 7.645405]
2023-05-13 19:36:20.654: epoch 11:	0.01862857  	0.13793257  	0.06860700  
2023-05-13 19:36:28.302: [iter 12 : loss : 0.5163 = 0.4182 + 0.0975 + 0.0005, time: 7.646452]
2023-05-13 19:36:28.451: epoch 12:	0.01866386  	0.13801761  	0.06896740  
2023-05-13 19:36:36.097: [iter 13 : loss : 0.4616 = 0.3612 + 0.0997 + 0.0007, time: 7.645509]
2023-05-13 19:36:36.263: epoch 13:	0.01863562  	0.13785866  	0.06927607  
2023-05-13 19:36:43.896: [iter 14 : loss : 0.4203 = 0.3186 + 0.1009 + 0.0008, time: 7.630009]
2023-05-13 19:36:44.043: epoch 14:	0.01876970  	0.13911930  	0.07012983  
2023-05-13 19:36:51.509: [iter 15 : loss : 0.3915 = 0.2891 + 0.1014 + 0.0010, time: 7.463720]
2023-05-13 19:36:51.656: epoch 15:	0.01904490  	0.14115840  	0.07121198  
2023-05-13 19:36:51.656: Find a better model.
2023-05-13 19:36:59.309: [iter 16 : loss : 0.3679 = 0.2654 + 0.1014 + 0.0011, time: 7.652219]
2023-05-13 19:36:59.454: epoch 16:	0.01913664  	0.14169568  	0.07174762  
2023-05-13 19:36:59.454: Find a better model.
2023-05-13 19:37:07.111: [iter 17 : loss : 0.3505 = 0.2479 + 0.1014 + 0.0012, time: 7.656196]
2023-05-13 19:37:07.258: epoch 17:	0.01936245  	0.14308786  	0.07248363  
2023-05-13 19:37:07.258: Find a better model.
2023-05-13 19:37:14.851: [iter 18 : loss : 0.3347 = 0.2323 + 0.1012 + 0.0013, time: 7.590874]
2023-05-13 19:37:15.000: epoch 18:	0.01968705  	0.14518332  	0.07363741  
2023-05-13 19:37:15.000: Find a better model.
2023-05-13 19:37:22.488: [iter 19 : loss : 0.3202 = 0.2179 + 0.1008 + 0.0014, time: 7.486744]
2023-05-13 19:37:22.636: epoch 19:	0.01993404  	0.14703396  	0.07457788  
2023-05-13 19:37:22.636: Find a better model.
2023-05-13 19:37:30.258: [iter 20 : loss : 0.3100 = 0.2081 + 0.1004 + 0.0015, time: 7.620435]
2023-05-13 19:37:30.408: epoch 20:	0.02020219  	0.14930974  	0.07532470  
2023-05-13 19:37:30.409: Find a better model.
2023-05-13 19:37:38.058: [iter 21 : loss : 0.3002 = 0.1986 + 0.1000 + 0.0016, time: 7.647750]
2023-05-13 19:37:38.209: epoch 21:	0.02036449  	0.15012644  	0.07592435  
2023-05-13 19:37:38.209: Find a better model.
2023-05-13 19:37:45.660: [iter 22 : loss : 0.2917 = 0.1904 + 0.0997 + 0.0017, time: 7.449294]
2023-05-13 19:37:45.810: epoch 22:	0.02051973  	0.15144645  	0.07686165  
2023-05-13 19:37:45.810: Find a better model.
2023-05-13 19:37:53.259: [iter 23 : loss : 0.2834 = 0.1824 + 0.0992 + 0.0017, time: 7.448145]
2023-05-13 19:37:53.409: epoch 23:	0.02066085  	0.15278152  	0.07758048  
2023-05-13 19:37:53.409: Find a better model.
2023-05-13 19:38:01.066: [iter 24 : loss : 0.2767 = 0.1760 + 0.0988 + 0.0018, time: 7.655799]
2023-05-13 19:38:01.216: epoch 24:	0.02091489  	0.15439503  	0.07845358  
2023-05-13 19:38:01.217: Find a better model.
2023-05-13 19:38:08.659: [iter 25 : loss : 0.2698 = 0.1696 + 0.0984 + 0.0019, time: 7.440854]
2023-05-13 19:38:08.826: epoch 25:	0.02106308  	0.15555562  	0.07910778  
2023-05-13 19:38:08.827: Find a better model.
2023-05-13 19:38:16.266: [iter 26 : loss : 0.2663 = 0.1664 + 0.0980 + 0.0019, time: 7.438139]
2023-05-13 19:38:16.414: epoch 26:	0.02123244  	0.15649670  	0.07983237  
2023-05-13 19:38:16.414: Find a better model.
2023-05-13 19:38:24.042: [iter 27 : loss : 0.2583 = 0.1588 + 0.0975 + 0.0020, time: 7.626714]
2023-05-13 19:38:24.194: epoch 27:	0.02134535  	0.15755036  	0.08068427  
2023-05-13 19:38:24.194: Find a better model.
2023-05-13 19:38:31.649: [iter 28 : loss : 0.2533 = 0.1541 + 0.0972 + 0.0021, time: 7.453160]
2023-05-13 19:38:31.796: epoch 28:	0.02154999  	0.15874030  	0.08138128  
2023-05-13 19:38:31.796: Find a better model.
2023-05-13 19:38:39.254: [iter 29 : loss : 0.2489 = 0.1500 + 0.0967 + 0.0021, time: 7.456922]
2023-05-13 19:38:39.401: epoch 29:	0.02164172  	0.15914378  	0.08183605  
2023-05-13 19:38:39.401: Find a better model.
2023-05-13 19:38:47.063: [iter 30 : loss : 0.2424 = 0.1438 + 0.0964 + 0.0022, time: 7.659680]
2023-05-13 19:38:47.219: epoch 30:	0.02184635  	0.16056938  	0.08267635  
2023-05-13 19:38:47.220: Find a better model.
2023-05-13 19:38:54.652: [iter 31 : loss : 0.2386 = 0.1404 + 0.0960 + 0.0023, time: 7.431332]
2023-05-13 19:38:54.799: epoch 31:	0.02195220  	0.16176917  	0.08325153  
2023-05-13 19:38:54.799: Find a better model.
2023-05-13 19:39:02.447: [iter 32 : loss : 0.2330 = 0.1350 + 0.0956 + 0.0023, time: 7.645226]
2023-05-13 19:39:02.595: epoch 32:	0.02206510  	0.16254105  	0.08384567  
2023-05-13 19:39:02.595: Find a better model.
2023-05-13 19:39:10.230: [iter 33 : loss : 0.2304 = 0.1327 + 0.0952 + 0.0024, time: 7.633453]
2023-05-13 19:39:10.376: epoch 33:	0.02226974  	0.16414142  	0.08459631  
2023-05-13 19:39:10.376: Find a better model.
2023-05-13 19:39:18.039: [iter 34 : loss : 0.2263 = 0.1290 + 0.0949 + 0.0025, time: 7.660988]
2023-05-13 19:39:18.199: epoch 34:	0.02241087  	0.16502777  	0.08515026  
2023-05-13 19:39:18.199: Find a better model.
2023-05-13 19:39:25.830: [iter 35 : loss : 0.2229 = 0.1258 + 0.0946 + 0.0025, time: 7.629972]
2023-05-13 19:39:25.980: epoch 35:	0.02259433  	0.16634755  	0.08592695  
2023-05-13 19:39:25.980: Find a better model.
2023-05-13 19:39:33.614: [iter 36 : loss : 0.2193 = 0.1225 + 0.0943 + 0.0026, time: 7.632995]
2023-05-13 19:39:33.763: epoch 36:	0.02265784  	0.16647488  	0.08627690  
2023-05-13 19:39:33.763: Find a better model.
2023-05-13 19:39:41.427: [iter 37 : loss : 0.2155 = 0.1189 + 0.0940 + 0.0026, time: 7.663355]
2023-05-13 19:39:41.575: epoch 37:	0.02289776  	0.16876812  	0.08718520  
2023-05-13 19:39:41.575: Find a better model.
2023-05-13 19:39:49.224: [iter 38 : loss : 0.2139 = 0.1175 + 0.0937 + 0.0027, time: 7.647739]
2023-05-13 19:39:49.376: epoch 38:	0.02296832  	0.16932227  	0.08779589  
2023-05-13 19:39:49.376: Find a better model.
2023-05-13 19:39:57.034: [iter 39 : loss : 0.2093 = 0.1132 + 0.0934 + 0.0027, time: 7.657102]
2023-05-13 19:39:57.182: epoch 39:	0.02313768  	0.17072079  	0.08838344  
2023-05-13 19:39:57.182: Find a better model.
2023-05-13 19:40:04.833: [iter 40 : loss : 0.2062 = 0.1104 + 0.0931 + 0.0028, time: 7.648956]
2023-05-13 19:40:04.982: epoch 40:	0.02327880  	0.17170742  	0.08892819  
2023-05-13 19:40:04.982: Find a better model.
2023-05-13 19:40:12.621: [iter 41 : loss : 0.2045 = 0.1089 + 0.0928 + 0.0028, time: 7.635645]
2023-05-13 19:40:12.769: epoch 41:	0.02337054  	0.17252965  	0.08946205  
2023-05-13 19:40:12.769: Find a better model.
2023-05-13 19:40:20.434: [iter 42 : loss : 0.2023 = 0.1070 + 0.0925 + 0.0029, time: 7.661975]
2023-05-13 19:40:20.597: epoch 42:	0.02348345  	0.17324157  	0.08990090  
2023-05-13 19:40:20.597: Find a better model.
2023-05-13 19:40:28.225: [iter 43 : loss : 0.1984 = 0.1032 + 0.0922 + 0.0029, time: 7.625815]
2023-05-13 19:40:28.371: epoch 43:	0.02358930  	0.17431785  	0.09076092  
2023-05-13 19:40:28.372: Find a better model.
2023-05-13 19:40:35.829: [iter 44 : loss : 0.1949 = 0.1000 + 0.0919 + 0.0030, time: 7.454678]
2023-05-13 19:40:35.975: epoch 44:	0.02358224  	0.17429964  	0.09091547  
2023-05-13 19:40:43.621: [iter 45 : loss : 0.1930 = 0.0982 + 0.0917 + 0.0030, time: 7.645472]
2023-05-13 19:40:43.768: epoch 45:	0.02373749  	0.17570202  	0.09169204  
2023-05-13 19:40:43.768: Find a better model.
2023-05-13 19:40:51.429: [iter 46 : loss : 0.1904 = 0.0958 + 0.0914 + 0.0031, time: 7.659732]
2023-05-13 19:40:51.577: epoch 46:	0.02377982  	0.17581995  	0.09205233  
2023-05-13 19:40:51.577: Find a better model.
2023-05-13 19:40:59.242: [iter 47 : loss : 0.1897 = 0.0953 + 0.0912 + 0.0031, time: 7.663407]
2023-05-13 19:40:59.390: epoch 47:	0.02384333  	0.17634675  	0.09255523  
2023-05-13 19:40:59.390: Find a better model.
2023-05-13 19:41:07.010: [iter 48 : loss : 0.1856 = 0.0915 + 0.0910 + 0.0032, time: 7.618320]
2023-05-13 19:41:07.159: epoch 48:	0.02397741  	0.17725055  	0.09299311  
2023-05-13 19:41:07.159: Find a better model.
2023-05-13 19:41:14.803: [iter 49 : loss : 0.1827 = 0.0887 + 0.0908 + 0.0032, time: 7.642584]
2023-05-13 19:41:14.953: epoch 49:	0.02407619  	0.17794074  	0.09346827  
2023-05-13 19:41:14.953: Find a better model.
2023-05-13 19:41:22.607: [iter 50 : loss : 0.1817 = 0.0879 + 0.0905 + 0.0033, time: 7.653296]
2023-05-13 19:41:22.758: epoch 50:	0.02413970  	0.17865764  	0.09411979  
2023-05-13 19:41:22.758: Find a better model.
2023-05-13 19:41:30.418: [iter 51 : loss : 0.1788 = 0.0851 + 0.0904 + 0.0033, time: 7.658740]
2023-05-13 19:41:30.567: epoch 51:	0.02413970  	0.17886345  	0.09422612  
2023-05-13 19:41:30.567: Find a better model.
2023-05-13 19:41:38.227: [iter 52 : loss : 0.1788 = 0.0853 + 0.0901 + 0.0034, time: 7.659111]
2023-05-13 19:41:38.376: epoch 52:	0.02425260  	0.17936867  	0.09470866  
2023-05-13 19:41:38.376: Find a better model.
2023-05-13 19:41:46.014: [iter 53 : loss : 0.1767 = 0.0834 + 0.0899 + 0.0034, time: 7.636122]
2023-05-13 19:41:46.163: epoch 53:	0.02428084  	0.17980780  	0.09485330  
2023-05-13 19:41:46.163: Find a better model.
2023-05-13 19:41:53.813: [iter 54 : loss : 0.1746 = 0.0814 + 0.0897 + 0.0035, time: 7.648168]
2023-05-13 19:41:53.961: epoch 54:	0.02428789  	0.17973801  	0.09528916  
2023-05-13 19:42:01.597: [iter 55 : loss : 0.1730 = 0.0799 + 0.0895 + 0.0035, time: 7.634786]
2023-05-13 19:42:01.744: epoch 55:	0.02435845  	0.18013774  	0.09577850  
2023-05-13 19:42:01.744: Find a better model.
2023-05-13 19:42:09.422: [iter 56 : loss : 0.1710 = 0.0781 + 0.0893 + 0.0036, time: 7.676084]
2023-05-13 19:42:09.569: epoch 56:	0.02440079  	0.18073402  	0.09620412  
2023-05-13 19:42:09.569: Find a better model.
2023-05-13 19:42:17.198: [iter 57 : loss : 0.1691 = 0.0763 + 0.0892 + 0.0036, time: 7.628695]
2023-05-13 19:42:17.368: epoch 57:	0.02449252  	0.18141799  	0.09667129  
2023-05-13 19:42:17.369: Find a better model.
2023-05-13 19:42:24.993: [iter 58 : loss : 0.1674 = 0.0747 + 0.0890 + 0.0037, time: 7.622221]
2023-05-13 19:42:25.143: epoch 58:	0.02449252  	0.18148717  	0.09676313  
2023-05-13 19:42:25.143: Find a better model.
2023-05-13 19:42:32.576: [iter 59 : loss : 0.1663 = 0.0738 + 0.0888 + 0.0037, time: 7.432332]
2023-05-13 19:42:32.726: epoch 59:	0.02463365  	0.18223043  	0.09711148  
2023-05-13 19:42:32.726: Find a better model.
2023-05-13 19:42:40.360: [iter 60 : loss : 0.1649 = 0.0725 + 0.0887 + 0.0038, time: 7.633027]
2023-05-13 19:42:40.521: epoch 60:	0.02475362  	0.18307717  	0.09780116  
2023-05-13 19:42:40.521: Find a better model.
2023-05-13 19:42:48.164: [iter 61 : loss : 0.1634 = 0.0711 + 0.0885 + 0.0038, time: 7.642381]
2023-05-13 19:42:48.324: epoch 61:	0.02488063  	0.18422754  	0.09823572  
2023-05-13 19:42:48.325: Find a better model.
2023-05-13 19:42:55.777: [iter 62 : loss : 0.1618 = 0.0696 + 0.0883 + 0.0038, time: 7.451107]
2023-05-13 19:42:55.927: epoch 62:	0.02496531  	0.18461622  	0.09865262  
2023-05-13 19:42:55.927: Find a better model.
2023-05-13 19:43:03.553: [iter 63 : loss : 0.1605 = 0.0685 + 0.0882 + 0.0039, time: 7.624237]
2023-05-13 19:43:03.700: epoch 63:	0.02501470  	0.18472178  	0.09893894  
2023-05-13 19:43:03.700: Find a better model.
2023-05-13 19:43:11.336: [iter 64 : loss : 0.1594 = 0.0675 + 0.0879 + 0.0039, time: 7.634229]
2023-05-13 19:43:11.492: epoch 64:	0.02506409  	0.18523882  	0.09923346  
2023-05-13 19:43:11.492: Find a better model.
2023-05-13 19:43:18.970: [iter 65 : loss : 0.1582 = 0.0664 + 0.0878 + 0.0040, time: 7.477633]
2023-05-13 19:43:19.132: epoch 65:	0.02510643  	0.18600065  	0.09976057  
2023-05-13 19:43:19.132: Find a better model.
2023-05-13 19:43:26.564: [iter 66 : loss : 0.1565 = 0.0648 + 0.0877 + 0.0040, time: 7.430020]
2023-05-13 19:43:26.714: epoch 66:	0.02521934  	0.18697055  	0.10015474  
2023-05-13 19:43:26.714: Find a better model.
2023-05-13 19:43:34.337: [iter 67 : loss : 0.1552 = 0.0636 + 0.0876 + 0.0041, time: 7.622792]
2023-05-13 19:43:34.484: epoch 67:	0.02515583  	0.18632445  	0.10031039  
2023-05-13 19:43:41.951: [iter 68 : loss : 0.1549 = 0.0634 + 0.0874 + 0.0041, time: 7.464434]
2023-05-13 19:43:42.099: epoch 68:	0.02517699  	0.18632454  	0.10054345  
2023-05-13 19:43:49.721: [iter 69 : loss : 0.1529 = 0.0615 + 0.0873 + 0.0041, time: 7.619342]
2023-05-13 19:43:49.871: epoch 69:	0.02528990  	0.18740338  	0.10094108  
2023-05-13 19:43:49.871: Find a better model.
2023-05-13 19:43:57.352: [iter 70 : loss : 0.1513 = 0.0599 + 0.0872 + 0.0042, time: 7.480071]
2023-05-13 19:43:57.503: epoch 70:	0.02526167  	0.18708840  	0.10105453  
2023-05-13 19:44:04.941: [iter 71 : loss : 0.1497 = 0.0585 + 0.0870 + 0.0042, time: 7.436416]
2023-05-13 19:44:05.107: epoch 71:	0.02544514  	0.18829077  	0.10163351  
2023-05-13 19:44:05.107: Find a better model.
2023-05-13 19:44:12.537: [iter 72 : loss : 0.1498 = 0.0586 + 0.0869 + 0.0043, time: 7.429571]
2023-05-13 19:44:12.685: epoch 72:	0.02545925  	0.18836501  	0.10199847  
2023-05-13 19:44:12.685: Find a better model.
2023-05-13 19:44:20.132: [iter 73 : loss : 0.1482 = 0.0571 + 0.0868 + 0.0043, time: 7.445522]
2023-05-13 19:44:20.292: epoch 73:	0.02544514  	0.18805391  	0.10201418  
2023-05-13 19:44:27.741: [iter 74 : loss : 0.1468 = 0.0558 + 0.0866 + 0.0044, time: 7.446121]
2023-05-13 19:44:27.887: epoch 74:	0.02552981  	0.18879293  	0.10242115  
2023-05-13 19:44:27.887: Find a better model.
2023-05-13 19:44:35.341: [iter 75 : loss : 0.1463 = 0.0554 + 0.0866 + 0.0044, time: 7.453621]
2023-05-13 19:44:35.499: epoch 75:	0.02559333  	0.18947811  	0.10277519  
2023-05-13 19:44:35.499: Find a better model.
2023-05-13 19:44:42.925: [iter 76 : loss : 0.1453 = 0.0544 + 0.0864 + 0.0044, time: 7.425082]
2023-05-13 19:44:43.074: epoch 76:	0.02563566  	0.18958671  	0.10305545  
2023-05-13 19:44:43.074: Find a better model.
2023-05-13 19:44:50.533: [iter 77 : loss : 0.1442 = 0.0534 + 0.0863 + 0.0045, time: 7.458408]
2023-05-13 19:44:50.695: epoch 77:	0.02562155  	0.18944472  	0.10301373  
2023-05-13 19:44:58.147: [iter 78 : loss : 0.1433 = 0.0526 + 0.0862 + 0.0045, time: 7.450532]
2023-05-13 19:44:58.310: epoch 78:	0.02564978  	0.18951210  	0.10298540  
2023-05-13 19:45:05.714: [iter 79 : loss : 0.1421 = 0.0515 + 0.0861 + 0.0046, time: 7.400593]
2023-05-13 19:45:05.859: epoch 79:	0.02567801  	0.18974377  	0.10323325  
2023-05-13 19:45:05.859: Find a better model.
2023-05-13 19:45:13.308: [iter 80 : loss : 0.1416 = 0.0510 + 0.0860 + 0.0046, time: 7.448351]
2023-05-13 19:45:13.459: epoch 80:	0.02572740  	0.18988325  	0.10333432  
2023-05-13 19:45:13.459: Find a better model.
2023-05-13 19:45:20.905: [iter 81 : loss : 0.1413 = 0.0508 + 0.0859 + 0.0046, time: 7.443161]
2023-05-13 19:45:21.056: epoch 81:	0.02581913  	0.19043098  	0.10358445  
2023-05-13 19:45:21.056: Find a better model.
2023-05-13 19:45:28.515: [iter 82 : loss : 0.1398 = 0.0494 + 0.0857 + 0.0047, time: 7.458294]
2023-05-13 19:45:28.663: epoch 82:	0.02584030  	0.19036250  	0.10369249  
2023-05-13 19:45:36.116: [iter 83 : loss : 0.1390 = 0.0486 + 0.0857 + 0.0047, time: 7.451126]
2023-05-13 19:45:36.263: epoch 83:	0.02578385  	0.19017325  	0.10380223  
2023-05-13 19:45:43.697: [iter 84 : loss : 0.1390 = 0.0487 + 0.0856 + 0.0048, time: 7.432975]
2023-05-13 19:45:43.861: epoch 84:	0.02587559  	0.19092038  	0.10409567  
2023-05-13 19:45:43.861: Find a better model.
2023-05-13 19:45:51.301: [iter 85 : loss : 0.1378 = 0.0475 + 0.0854 + 0.0048, time: 7.438465]
2023-05-13 19:45:51.471: epoch 85:	0.02593204  	0.19116971  	0.10432016  
2023-05-13 19:45:51.472: Find a better model.
2023-05-13 19:45:58.894: [iter 86 : loss : 0.1376 = 0.0475 + 0.0853 + 0.0048, time: 7.419398]
2023-05-13 19:45:59.043: epoch 86:	0.02597438  	0.19172308  	0.10454897  
2023-05-13 19:45:59.043: Find a better model.
2023-05-13 19:46:06.493: [iter 87 : loss : 0.1350 = 0.0448 + 0.0853 + 0.0049, time: 7.447526]
2023-05-13 19:46:06.656: epoch 87:	0.02598143  	0.19163913  	0.10477908  
2023-05-13 19:46:14.084: [iter 88 : loss : 0.1345 = 0.0444 + 0.0852 + 0.0049, time: 7.427413]
2023-05-13 19:46:14.233: epoch 88:	0.02602377  	0.19188485  	0.10485492  
2023-05-13 19:46:14.233: Find a better model.
2023-05-13 19:46:21.697: [iter 89 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 7.462516]
2023-05-13 19:46:21.858: epoch 89:	0.02605200  	0.19223638  	0.10490894  
2023-05-13 19:46:21.858: Find a better model.
2023-05-13 19:46:29.289: [iter 90 : loss : 0.1347 = 0.0447 + 0.0850 + 0.0050, time: 7.429734]
2023-05-13 19:46:29.437: epoch 90:	0.02610845  	0.19247708  	0.10516167  
2023-05-13 19:46:29.437: Find a better model.
2023-05-13 19:46:36.882: [iter 91 : loss : 0.1332 = 0.0433 + 0.0849 + 0.0050, time: 7.443705]
2023-05-13 19:46:37.049: epoch 91:	0.02613668  	0.19306579  	0.10523239  
2023-05-13 19:46:37.049: Find a better model.
2023-05-13 19:46:44.486: [iter 92 : loss : 0.1325 = 0.0426 + 0.0848 + 0.0051, time: 7.435836]
2023-05-13 19:46:44.637: epoch 92:	0.02622135  	0.19394100  	0.10560944  
2023-05-13 19:46:44.637: Find a better model.
2023-05-13 19:46:52.104: [iter 93 : loss : 0.1325 = 0.0427 + 0.0847 + 0.0051, time: 7.465225]
2023-05-13 19:46:52.252: epoch 93:	0.02616490  	0.19337931  	0.10568994  
2023-05-13 19:46:59.680: [iter 94 : loss : 0.1305 = 0.0407 + 0.0847 + 0.0051, time: 7.427029]
2023-05-13 19:46:59.828: epoch 94:	0.02624958  	0.19421490  	0.10600265  
2023-05-13 19:46:59.828: Find a better model.
2023-05-13 19:47:07.281: [iter 95 : loss : 0.1299 = 0.0402 + 0.0846 + 0.0052, time: 7.451714]
2023-05-13 19:47:07.428: epoch 95:	0.02622135  	0.19385479  	0.10595273  
2023-05-13 19:47:14.868: [iter 96 : loss : 0.1298 = 0.0401 + 0.0845 + 0.0052, time: 7.439291]
2023-05-13 19:47:15.019: epoch 96:	0.02627075  	0.19425367  	0.10623372  
2023-05-13 19:47:15.019: Find a better model.
2023-05-13 19:47:22.463: [iter 97 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0052, time: 7.442691]
2023-05-13 19:47:22.610: epoch 97:	0.02641187  	0.19507350  	0.10644526  
2023-05-13 19:47:22.611: Find a better model.
2023-05-13 19:47:30.060: [iter 98 : loss : 0.1292 = 0.0396 + 0.0844 + 0.0053, time: 7.448691]
2023-05-13 19:47:30.207: epoch 98:	0.02644716  	0.19517596  	0.10666787  
2023-05-13 19:47:30.207: Find a better model.
2023-05-13 19:47:37.667: [iter 99 : loss : 0.1279 = 0.0383 + 0.0843 + 0.0053, time: 7.457351]
2023-05-13 19:47:37.822: epoch 99:	0.02650361  	0.19584607  	0.10684814  
2023-05-13 19:47:37.822: Find a better model.
2023-05-13 19:47:45.266: [iter 100 : loss : 0.1274 = 0.0378 + 0.0842 + 0.0054, time: 7.442113]
2023-05-13 19:47:45.416: epoch 100:	0.02653184  	0.19638902  	0.10701721  
2023-05-13 19:47:45.416: Find a better model.
2023-05-13 19:47:52.865: [iter 101 : loss : 0.1272 = 0.0377 + 0.0841 + 0.0054, time: 7.447893]
2023-05-13 19:47:53.026: epoch 101:	0.02651772  	0.19624500  	0.10702603  
2023-05-13 19:48:00.654: [iter 102 : loss : 0.1260 = 0.0365 + 0.0841 + 0.0054, time: 7.626093]
2023-05-13 19:48:00.806: epoch 102:	0.02653889  	0.19636360  	0.10695598  
2023-05-13 19:48:08.452: [iter 103 : loss : 0.1258 = 0.0363 + 0.0840 + 0.0055, time: 7.642998]
2023-05-13 19:48:08.612: epoch 103:	0.02665886  	0.19733657  	0.10738739  
2023-05-13 19:48:08.612: Find a better model.
2023-05-13 19:48:16.069: [iter 104 : loss : 0.1265 = 0.0370 + 0.0839 + 0.0055, time: 7.454910]
2023-05-13 19:48:16.231: epoch 104:	0.02670825  	0.19782566  	0.10764976  
2023-05-13 19:48:16.231: Find a better model.
2023-05-13 19:48:23.837: [iter 105 : loss : 0.1255 = 0.0361 + 0.0839 + 0.0055, time: 7.604478]
2023-05-13 19:48:23.984: epoch 105:	0.02672942  	0.19795071  	0.10784852  
2023-05-13 19:48:23.984: Find a better model.
2023-05-13 19:48:31.644: [iter 106 : loss : 0.1251 = 0.0357 + 0.0838 + 0.0056, time: 7.659084]
2023-05-13 19:48:31.797: epoch 106:	0.02675059  	0.19781649  	0.10789003  
2023-05-13 19:48:39.452: [iter 107 : loss : 0.1241 = 0.0348 + 0.0838 + 0.0056, time: 7.652484]
2023-05-13 19:48:39.617: epoch 107:	0.02663063  	0.19682692  	0.10760289  
2023-05-13 19:48:47.235: [iter 108 : loss : 0.1239 = 0.0346 + 0.0837 + 0.0056, time: 7.617402]
2023-05-13 19:48:47.401: epoch 108:	0.02672237  	0.19729805  	0.10778522  
2023-05-13 19:48:54.855: [iter 109 : loss : 0.1225 = 0.0333 + 0.0836 + 0.0057, time: 7.452420]
2023-05-13 19:48:55.005: epoch 109:	0.02682821  	0.19812964  	0.10785636  
2023-05-13 19:48:55.005: Find a better model.
2023-05-13 19:49:02.638: [iter 110 : loss : 0.1220 = 0.0328 + 0.0835 + 0.0057, time: 7.630367]
2023-05-13 19:49:02.785: epoch 110:	0.02675765  	0.19787477  	0.10780542  
2023-05-13 19:49:10.433: [iter 111 : loss : 0.1220 = 0.0328 + 0.0835 + 0.0057, time: 7.647291]
2023-05-13 19:49:10.589: epoch 111:	0.02681410  	0.19788346  	0.10797764  
2023-05-13 19:49:18.037: [iter 112 : loss : 0.1220 = 0.0327 + 0.0834 + 0.0058, time: 7.447254]
2023-05-13 19:49:18.184: epoch 112:	0.02672942  	0.19735168  	0.10783710  
2023-05-13 19:49:25.812: [iter 113 : loss : 0.1219 = 0.0327 + 0.0834 + 0.0058, time: 7.626056]
2023-05-13 19:49:25.977: epoch 113:	0.02683526  	0.19770536  	0.10811695  
2023-05-13 19:49:33.622: [iter 114 : loss : 0.1208 = 0.0316 + 0.0833 + 0.0058, time: 7.644139]
2023-05-13 19:49:33.781: epoch 114:	0.02676470  	0.19738129  	0.10807842  
2023-05-13 19:49:41.427: [iter 115 : loss : 0.1202 = 0.0311 + 0.0833 + 0.0059, time: 7.644108]
2023-05-13 19:49:41.578: epoch 115:	0.02682821  	0.19765806  	0.10836471  
2023-05-13 19:49:49.029: [iter 116 : loss : 0.1195 = 0.0304 + 0.0832 + 0.0059, time: 7.450200]
2023-05-13 19:49:49.194: epoch 116:	0.02676470  	0.19702755  	0.10830683  
2023-05-13 19:49:56.804: [iter 117 : loss : 0.1196 = 0.0305 + 0.0832 + 0.0059, time: 7.607458]
2023-05-13 19:49:56.968: epoch 117:	0.02677882  	0.19731808  	0.10822570  
2023-05-13 19:50:04.603: [iter 118 : loss : 0.1195 = 0.0305 + 0.0831 + 0.0060, time: 7.634282]
2023-05-13 19:50:04.754: epoch 118:	0.02688466  	0.19795629  	0.10846335  
2023-05-13 19:50:12.232: [iter 119 : loss : 0.1184 = 0.0294 + 0.0831 + 0.0060, time: 7.477207]
2023-05-13 19:50:12.397: epoch 119:	0.02684232  	0.19753246  	0.10835113  
2023-05-13 19:50:19.821: [iter 120 : loss : 0.1187 = 0.0297 + 0.0830 + 0.0060, time: 7.423124]
2023-05-13 19:50:19.970: epoch 120:	0.02684233  	0.19741528  	0.10829822  
2023-05-13 19:50:27.417: [iter 121 : loss : 0.1186 = 0.0296 + 0.0829 + 0.0061, time: 7.446290]
2023-05-13 19:50:27.570: epoch 121:	0.02691995  	0.19808677  	0.10873711  
2023-05-13 19:50:35.014: [iter 122 : loss : 0.1178 = 0.0288 + 0.0829 + 0.0061, time: 7.442613]
2023-05-13 19:50:35.164: epoch 122:	0.02694817  	0.19821313  	0.10875564  
2023-05-13 19:50:35.164: Find a better model.
2023-05-13 19:50:42.608: [iter 123 : loss : 0.1179 = 0.0289 + 0.0829 + 0.0061, time: 7.441852]
2023-05-13 19:50:42.754: epoch 123:	0.02691994  	0.19810860  	0.10887764  
2023-05-13 19:50:50.396: [iter 124 : loss : 0.1170 = 0.0281 + 0.0828 + 0.0062, time: 7.640633]
2023-05-13 19:50:50.557: epoch 124:	0.02695522  	0.19854358  	0.10900351  
2023-05-13 19:50:50.557: Find a better model.
2023-05-13 19:50:58.003: [iter 125 : loss : 0.1163 = 0.0274 + 0.0827 + 0.0062, time: 7.443208]
2023-05-13 19:50:58.164: epoch 125:	0.02689878  	0.19799814  	0.10869642  
2023-05-13 19:51:05.773: [iter 126 : loss : 0.1165 = 0.0276 + 0.0827 + 0.0062, time: 7.608003]
2023-05-13 19:51:05.918: epoch 126:	0.02692700  	0.19814996  	0.10888378  
2023-05-13 19:51:13.567: [iter 127 : loss : 0.1155 = 0.0266 + 0.0827 + 0.0062, time: 7.647100]
2023-05-13 19:51:13.716: epoch 127:	0.02693406  	0.19822532  	0.10895939  
2023-05-13 19:51:21.200: [iter 128 : loss : 0.1166 = 0.0277 + 0.0826 + 0.0063, time: 7.483352]
2023-05-13 19:51:21.348: epoch 128:	0.02690584  	0.19787224  	0.10881707  
2023-05-13 19:51:28.800: [iter 129 : loss : 0.1159 = 0.0270 + 0.0826 + 0.0063, time: 7.449279]
2023-05-13 19:51:28.965: epoch 129:	0.02691289  	0.19803810  	0.10874753  
2023-05-13 19:51:36.583: [iter 130 : loss : 0.1155 = 0.0267 + 0.0825 + 0.0063, time: 7.617224]
2023-05-13 19:51:36.749: epoch 130:	0.02683527  	0.19752100  	0.10859317  
2023-05-13 19:51:44.194: [iter 131 : loss : 0.1148 = 0.0260 + 0.0825 + 0.0064, time: 7.444313]
2023-05-13 19:51:44.343: epoch 131:	0.02689172  	0.19827542  	0.10903031  
2023-05-13 19:51:51.784: [iter 132 : loss : 0.1150 = 0.0261 + 0.0825 + 0.0064, time: 7.438966]
2023-05-13 19:51:51.930: epoch 132:	0.02691289  	0.19813712  	0.10904025  
2023-05-13 19:51:59.599: [iter 133 : loss : 0.1139 = 0.0250 + 0.0824 + 0.0064, time: 7.668413]
2023-05-13 19:51:59.748: epoch 133:	0.02691289  	0.19780290  	0.10908770  
2023-05-13 19:52:07.393: [iter 134 : loss : 0.1144 = 0.0256 + 0.0824 + 0.0065, time: 7.644261]
2023-05-13 19:52:07.539: epoch 134:	0.02685644  	0.19753163  	0.10903367  
2023-05-13 19:52:14.971: [iter 135 : loss : 0.1142 = 0.0254 + 0.0823 + 0.0065, time: 7.430255]
2023-05-13 19:52:15.118: epoch 135:	0.02680704  	0.19714279  	0.10886718  
2023-05-13 19:52:22.766: [iter 136 : loss : 0.1139 = 0.0251 + 0.0823 + 0.0065, time: 7.645906]
2023-05-13 19:52:22.914: epoch 136:	0.02682821  	0.19706886  	0.10885930  
2023-05-13 19:52:30.382: [iter 137 : loss : 0.1133 = 0.0245 + 0.0822 + 0.0065, time: 7.465978]
2023-05-13 19:52:30.529: epoch 137:	0.02680703  	0.19703642  	0.10893396  
2023-05-13 19:52:37.965: [iter 138 : loss : 0.1130 = 0.0242 + 0.0822 + 0.0066, time: 7.434085]
2023-05-13 19:52:38.128: epoch 138:	0.02679998  	0.19687417  	0.10894323  
2023-05-13 19:52:45.734: [iter 139 : loss : 0.1129 = 0.0241 + 0.0821 + 0.0066, time: 7.604261]
2023-05-13 19:52:45.881: epoch 139:	0.02687054  	0.19750349  	0.10926508  
2023-05-13 19:52:53.363: [iter 140 : loss : 0.1124 = 0.0237 + 0.0821 + 0.0066, time: 7.480425]
2023-05-13 19:52:53.517: epoch 140:	0.02683526  	0.19684076  	0.10911123  
2023-05-13 19:53:00.962: [iter 141 : loss : 0.1129 = 0.0242 + 0.0821 + 0.0067, time: 7.443075]
2023-05-13 19:53:01.109: epoch 141:	0.02678586  	0.19698450  	0.10910656  
2023-05-13 19:53:08.543: [iter 142 : loss : 0.1119 = 0.0232 + 0.0820 + 0.0067, time: 7.433372]
2023-05-13 19:53:08.697: epoch 142:	0.02670824  	0.19632277  	0.10900475  
2023-05-13 19:53:16.161: [iter 143 : loss : 0.1120 = 0.0232 + 0.0820 + 0.0067, time: 7.463106]
2023-05-13 19:53:16.319: epoch 143:	0.02676469  	0.19681296  	0.10922314  
2023-05-13 19:53:23.762: [iter 144 : loss : 0.1113 = 0.0226 + 0.0820 + 0.0067, time: 7.442726]
2023-05-13 19:53:23.927: epoch 144:	0.02672941  	0.19669910  	0.10915448  
2023-05-13 19:53:31.513: [iter 145 : loss : 0.1114 = 0.0228 + 0.0819 + 0.0068, time: 7.584564]
2023-05-13 19:53:31.665: epoch 145:	0.02675059  	0.19676723  	0.10905056  
2023-05-13 19:53:39.147: [iter 146 : loss : 0.1117 = 0.0230 + 0.0819 + 0.0068, time: 7.481008]
2023-05-13 19:53:39.301: epoch 146:	0.02675058  	0.19645216  	0.10909384  
2023-05-13 19:53:46.734: [iter 147 : loss : 0.1117 = 0.0230 + 0.0819 + 0.0068, time: 7.430828]
2023-05-13 19:53:46.881: epoch 147:	0.02677175  	0.19644102  	0.10909407  
2023-05-13 19:53:54.528: [iter 148 : loss : 0.1102 = 0.0216 + 0.0818 + 0.0069, time: 7.646419]
2023-05-13 19:53:54.682: epoch 148:	0.02670825  	0.19606845  	0.10912772  
2023-05-13 19:54:02.153: [iter 149 : loss : 0.1108 = 0.0221 + 0.0818 + 0.0069, time: 7.468652]
2023-05-13 19:54:02.301: epoch 149:	0.02668002  	0.19580364  	0.10906103  
2023-05-13 19:54:02.301: Early stopping is trigger at epoch: 149
2023-05-13 19:54:02.301: best_result@epoch 124:

2023-05-13 19:54:02.301: 		0.0270      	0.1985      	0.1090      
2023-05-13 19:54:35.438: my pid: 6544
2023-05-13 19:54:35.438: model: model.general_recommender.SGL
2023-05-13 19:54:35.438: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-13 19:54:35.438: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-13 19:54:38.576: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-13 19:54:46.990: [iter 1 : loss : 0.7709 = 0.6930 + 0.0779 + 0.0000, time: 8.414147]
2023-05-13 19:54:47.158: epoch 1:	0.00156647  	0.01102941  	0.00539953  
2023-05-13 19:54:47.158: Find a better model.
2023-05-13 19:54:55.771: [iter 2 : loss : 0.7705 = 0.6929 + 0.0776 + 0.0000, time: 8.612106]
2023-05-13 19:54:55.963: epoch 2:	0.00267429  	0.01963827  	0.00957223  
2023-05-13 19:54:55.963: Find a better model.
2023-05-13 19:55:04.364: [iter 3 : loss : 0.7703 = 0.6927 + 0.0776 + 0.0000, time: 8.398643]
2023-05-13 19:55:04.555: epoch 3:	0.00448770  	0.03294769  	0.01584906  
2023-05-13 19:55:04.555: Find a better model.
2023-05-13 19:55:12.976: [iter 4 : loss : 0.7699 = 0.6923 + 0.0776 + 0.0000, time: 8.420066]
2023-05-13 19:55:13.135: epoch 4:	0.00664686  	0.04816134  	0.02304090  
2023-05-13 19:55:13.135: Find a better model.
2023-05-13 19:55:21.179: [iter 5 : loss : 0.7692 = 0.6915 + 0.0777 + 0.0000, time: 8.041834]
2023-05-13 19:55:21.328: epoch 5:	0.00933524  	0.06819560  	0.03240265  
2023-05-13 19:55:21.328: Find a better model.
2023-05-13 19:55:29.341: [iter 6 : loss : 0.7675 = 0.6896 + 0.0779 + 0.0000, time: 8.010423]
2023-05-13 19:55:29.491: epoch 6:	0.01290581  	0.09281930  	0.04457604  
2023-05-13 19:55:29.491: Find a better model.
2023-05-13 19:55:37.330: [iter 7 : loss : 0.7631 = 0.6847 + 0.0783 + 0.0000, time: 7.836994]
2023-05-13 19:55:37.485: epoch 7:	0.01600357  	0.11604181  	0.05640109  
2023-05-13 19:55:37.485: Find a better model.
2023-05-13 19:55:45.357: [iter 8 : loss : 0.7520 = 0.6724 + 0.0796 + 0.0001, time: 7.870680]
2023-05-13 19:55:45.508: epoch 8:	0.01783824  	0.13028103  	0.06492905  
2023-05-13 19:55:45.508: Find a better model.
2023-05-13 19:55:53.300: [iter 9 : loss : 0.7258 = 0.6433 + 0.0823 + 0.0001, time: 7.791268]
2023-05-13 19:55:53.452: epoch 9:	0.01857211  	0.13592775  	0.06807917  
2023-05-13 19:55:53.452: Find a better model.
2023-05-13 19:56:01.114: [iter 10 : loss : 0.6758 = 0.5886 + 0.0870 + 0.0002, time: 7.660359]
2023-05-13 19:56:01.264: epoch 10:	0.01872737  	0.13842848  	0.06894725  
2023-05-13 19:56:01.264: Find a better model.
2023-05-13 19:56:09.135: [iter 11 : loss : 0.6040 = 0.5114 + 0.0923 + 0.0003, time: 7.869376]
2023-05-13 19:56:09.286: epoch 11:	0.01864268  	0.13776736  	0.06855301  
2023-05-13 19:56:16.927: [iter 12 : loss : 0.5299 = 0.4330 + 0.0964 + 0.0005, time: 7.639726]
2023-05-13 19:56:17.075: epoch 12:	0.01859329  	0.13750318  	0.06874074  
2023-05-13 19:56:24.918: [iter 13 : loss : 0.4718 = 0.3723 + 0.0989 + 0.0006, time: 7.841240]
2023-05-13 19:56:25.066: epoch 13:	0.01852272  	0.13744392  	0.06890817  
2023-05-13 19:56:32.930: [iter 14 : loss : 0.4274 = 0.3263 + 0.1003 + 0.0008, time: 7.863228]
2023-05-13 19:56:33.090: epoch 14:	0.01872736  	0.13886827  	0.06983024  
2023-05-13 19:56:33.090: Find a better model.
2023-05-13 19:56:40.920: [iter 15 : loss : 0.3966 = 0.2947 + 0.1009 + 0.0009, time: 7.827384]
2023-05-13 19:56:41.069: epoch 15:	0.01891083  	0.14023145  	0.07063589  
2023-05-13 19:56:41.069: Find a better model.
2023-05-13 19:56:48.898: [iter 16 : loss : 0.3716 = 0.2695 + 0.1010 + 0.0011, time: 7.826614]
2023-05-13 19:56:49.048: epoch 16:	0.01919309  	0.14206889  	0.07171018  
2023-05-13 19:56:49.048: Find a better model.
2023-05-13 19:56:56.716: [iter 17 : loss : 0.3532 = 0.2510 + 0.1010 + 0.0012, time: 7.667361]
2023-05-13 19:56:56.862: epoch 17:	0.01934834  	0.14311625  	0.07265272  
2023-05-13 19:56:56.862: Find a better model.
2023-05-13 19:57:04.679: [iter 18 : loss : 0.3367 = 0.2346 + 0.1008 + 0.0013, time: 7.814502]
2023-05-13 19:57:04.843: epoch 18:	0.01958120  	0.14452472  	0.07348378  
2023-05-13 19:57:04.843: Find a better model.
2023-05-13 19:57:12.683: [iter 19 : loss : 0.3218 = 0.2199 + 0.1005 + 0.0014, time: 7.837706]
2023-05-13 19:57:12.828: epoch 19:	0.01983524  	0.14651090  	0.07424814  
2023-05-13 19:57:12.828: Find a better model.
2023-05-13 19:57:20.721: [iter 20 : loss : 0.3114 = 0.2098 + 0.1002 + 0.0015, time: 7.889317]
2023-05-13 19:57:20.867: epoch 20:	0.02003283  	0.14774616  	0.07512566  
2023-05-13 19:57:20.867: Find a better model.
2023-05-13 19:57:28.675: [iter 21 : loss : 0.3012 = 0.1999 + 0.0997 + 0.0016, time: 7.807031]
2023-05-13 19:57:28.826: epoch 21:	0.02019513  	0.14881289  	0.07574273  
2023-05-13 19:57:28.826: Find a better model.
2023-05-13 19:57:36.693: [iter 22 : loss : 0.2926 = 0.1915 + 0.0994 + 0.0016, time: 7.866562]
2023-05-13 19:57:36.841: epoch 22:	0.02038565  	0.15054810  	0.07647716  
2023-05-13 19:57:36.842: Find a better model.
2023-05-13 19:57:44.718: [iter 23 : loss : 0.2841 = 0.1834 + 0.0989 + 0.0017, time: 7.874769]
2023-05-13 19:57:44.870: epoch 23:	0.02056206  	0.15160894  	0.07742346  
2023-05-13 19:57:44.870: Find a better model.
2023-05-13 19:57:52.692: [iter 24 : loss : 0.2772 = 0.1768 + 0.0985 + 0.0018, time: 7.821200]
2023-05-13 19:57:52.858: epoch 24:	0.02094312  	0.15452455  	0.07875095  
2023-05-13 19:57:52.858: Find a better model.
2023-05-13 19:58:00.687: [iter 25 : loss : 0.2703 = 0.1703 + 0.0981 + 0.0019, time: 7.828195]
2023-05-13 19:58:00.835: epoch 25:	0.02119715  	0.15620515  	0.07950903  
2023-05-13 19:58:00.835: Find a better model.
2023-05-13 19:58:08.730: [iter 26 : loss : 0.2664 = 0.1668 + 0.0977 + 0.0019, time: 7.894300]
2023-05-13 19:58:08.897: epoch 26:	0.02130300  	0.15678991  	0.07996892  
2023-05-13 19:58:08.897: Find a better model.
2023-05-13 19:58:16.670: [iter 27 : loss : 0.2585 = 0.1592 + 0.0972 + 0.0020, time: 7.771548]
2023-05-13 19:58:16.839: epoch 27:	0.02147236  	0.15789986  	0.08066110  
2023-05-13 19:58:16.839: Find a better model.
2023-05-13 19:58:24.673: [iter 28 : loss : 0.2535 = 0.1545 + 0.0969 + 0.0021, time: 7.832862]
2023-05-13 19:58:24.824: epoch 28:	0.02170523  	0.15977344  	0.08163501  
2023-05-13 19:58:24.824: Find a better model.
2023-05-13 19:58:32.711: [iter 29 : loss : 0.2490 = 0.1504 + 0.0964 + 0.0021, time: 7.886741]
2023-05-13 19:58:32.858: epoch 29:	0.02187458  	0.16105430  	0.08250016  
2023-05-13 19:58:32.858: Find a better model.
2023-05-13 19:58:40.847: [iter 30 : loss : 0.2424 = 0.1441 + 0.0961 + 0.0022, time: 7.987436]
2023-05-13 19:58:40.995: epoch 30:	0.02200159  	0.16233596  	0.08324020  
2023-05-13 19:58:40.995: Find a better model.
2023-05-13 19:58:48.887: [iter 31 : loss : 0.2386 = 0.1407 + 0.0957 + 0.0023, time: 7.890477]
2023-05-13 19:58:49.036: epoch 31:	0.02214978  	0.16344135  	0.08397721  
2023-05-13 19:58:49.036: Find a better model.
2023-05-13 19:58:56.885: [iter 32 : loss : 0.2330 = 0.1353 + 0.0953 + 0.0023, time: 7.848133]
2023-05-13 19:58:57.050: epoch 32:	0.02226268  	0.16380751  	0.08453077  
2023-05-13 19:58:57.051: Find a better model.
2023-05-13 19:59:04.885: [iter 33 : loss : 0.2304 = 0.1330 + 0.0949 + 0.0024, time: 7.833685]
2023-05-13 19:59:05.032: epoch 33:	0.02239675  	0.16490415  	0.08498114  
2023-05-13 19:59:05.033: Find a better model.
2023-05-13 19:59:12.875: [iter 34 : loss : 0.2263 = 0.1293 + 0.0946 + 0.0025, time: 7.840281]
2023-05-13 19:59:13.022: epoch 34:	0.02252377  	0.16542172  	0.08537529  
2023-05-13 19:59:13.022: Find a better model.
2023-05-13 19:59:20.848: [iter 35 : loss : 0.2227 = 0.1259 + 0.0943 + 0.0025, time: 7.823879]
2023-05-13 19:59:20.994: epoch 35:	0.02253082  	0.16582236  	0.08579595  
2023-05-13 19:59:20.994: Find a better model.
2023-05-13 19:59:28.852: [iter 36 : loss : 0.2193 = 0.1227 + 0.0940 + 0.0026, time: 7.856481]
2023-05-13 19:59:29.004: epoch 36:	0.02277780  	0.16752042  	0.08667660  
2023-05-13 19:59:29.004: Find a better model.
2023-05-13 19:59:36.655: [iter 37 : loss : 0.2155 = 0.1192 + 0.0937 + 0.0026, time: 7.649731]
2023-05-13 19:59:36.805: epoch 37:	0.02296127  	0.16937895  	0.08758362  
2023-05-13 19:59:36.805: Find a better model.
2023-05-13 19:59:44.478: [iter 38 : loss : 0.2136 = 0.1176 + 0.0934 + 0.0027, time: 7.670617]
2023-05-13 19:59:44.624: epoch 38:	0.02307416  	0.17020413  	0.08825464  
2023-05-13 19:59:44.624: Find a better model.
2023-05-13 19:59:52.444: [iter 39 : loss : 0.2092 = 0.1134 + 0.0931 + 0.0027, time: 7.818739]
2023-05-13 19:59:52.593: epoch 39:	0.02319412  	0.17094795  	0.08877876  
2023-05-13 19:59:52.593: Find a better model.
2023-05-13 20:00:00.255: [iter 40 : loss : 0.2060 = 0.1104 + 0.0928 + 0.0028, time: 7.660813]
2023-05-13 20:00:00.420: epoch 40:	0.02334232  	0.17247848  	0.08955960  
2023-05-13 20:00:00.421: Find a better model.
2023-05-13 20:00:08.238: [iter 41 : loss : 0.2042 = 0.1089 + 0.0925 + 0.0028, time: 7.816487]
2023-05-13 20:00:08.383: epoch 41:	0.02340583  	0.17259768  	0.08997965  
2023-05-13 20:00:08.383: Find a better model.
2023-05-13 20:00:16.247: [iter 42 : loss : 0.2021 = 0.1071 + 0.0922 + 0.0029, time: 7.861485]
2023-05-13 20:00:16.394: epoch 42:	0.02358223  	0.17399919  	0.09072585  
2023-05-13 20:00:16.394: Find a better model.
2023-05-13 20:00:24.248: [iter 43 : loss : 0.1982 = 0.1033 + 0.0919 + 0.0029, time: 7.852608]
2023-05-13 20:00:24.395: epoch 43:	0.02368102  	0.17441289  	0.09120110  
2023-05-13 20:00:24.395: Find a better model.
2023-05-13 20:00:32.213: [iter 44 : loss : 0.1945 = 0.0999 + 0.0916 + 0.0030, time: 7.816184]
2023-05-13 20:00:32.359: epoch 44:	0.02370926  	0.17472906  	0.09156756  
2023-05-13 20:00:32.359: Find a better model.
2023-05-13 20:00:40.232: [iter 45 : loss : 0.1928 = 0.0983 + 0.0914 + 0.0031, time: 7.870905]
2023-05-13 20:00:40.378: epoch 45:	0.02385744  	0.17593735  	0.09244449  
2023-05-13 20:00:40.378: Find a better model.
2023-05-13 20:00:48.029: [iter 46 : loss : 0.1901 = 0.0959 + 0.0911 + 0.0031, time: 7.649074]
2023-05-13 20:00:48.188: epoch 46:	0.02396329  	0.17684260  	0.09289616  
2023-05-13 20:00:48.189: Find a better model.
2023-05-13 20:00:55.854: [iter 47 : loss : 0.1894 = 0.0953 + 0.0909 + 0.0032, time: 7.663406]
2023-05-13 20:00:56.000: epoch 47:	0.02405502  	0.17725550  	0.09332482  
2023-05-13 20:00:56.000: Find a better model.
2023-05-13 20:01:03.828: [iter 48 : loss : 0.1855 = 0.0916 + 0.0907 + 0.0032, time: 7.827701]
2023-05-13 20:01:03.990: epoch 48:	0.02417498  	0.17833029  	0.09400137  
2023-05-13 20:01:03.990: Find a better model.
2023-05-13 20:01:11.608: [iter 49 : loss : 0.1824 = 0.0887 + 0.0905 + 0.0033, time: 7.617118]
2023-05-13 20:01:11.758: epoch 49:	0.02425259  	0.17879957  	0.09436531  
2023-05-13 20:01:11.758: Find a better model.
2023-05-13 20:01:19.413: [iter 50 : loss : 0.1815 = 0.0879 + 0.0902 + 0.0033, time: 7.652309]
2023-05-13 20:01:19.564: epoch 50:	0.02431610  	0.17939858  	0.09464967  
2023-05-13 20:01:19.564: Find a better model.
2023-05-13 20:01:27.204: [iter 51 : loss : 0.1785 = 0.0851 + 0.0901 + 0.0034, time: 7.638845]
2023-05-13 20:01:27.351: epoch 51:	0.02434433  	0.17965434  	0.09496860  
2023-05-13 20:01:27.351: Find a better model.
2023-05-13 20:01:35.169: [iter 52 : loss : 0.1786 = 0.0853 + 0.0899 + 0.0034, time: 7.817014]
2023-05-13 20:01:35.319: epoch 52:	0.02437961  	0.17969126  	0.09544815  
2023-05-13 20:01:35.319: Find a better model.
2023-05-13 20:01:43.028: [iter 53 : loss : 0.1765 = 0.0834 + 0.0896 + 0.0034, time: 7.707862]
2023-05-13 20:01:43.189: epoch 53:	0.02449957  	0.18097071  	0.09581718  
2023-05-13 20:01:43.190: Find a better model.
2023-05-13 20:01:51.010: [iter 54 : loss : 0.1742 = 0.0813 + 0.0894 + 0.0035, time: 7.818229]
2023-05-13 20:01:51.157: epoch 54:	0.02449957  	0.18100761  	0.09598628  
2023-05-13 20:01:51.157: Find a better model.
2023-05-13 20:01:58.998: [iter 55 : loss : 0.1726 = 0.0798 + 0.0892 + 0.0035, time: 7.839967]
2023-05-13 20:01:59.145: epoch 55:	0.02453486  	0.18132192  	0.09626073  
2023-05-13 20:01:59.145: Find a better model.
2023-05-13 20:02:07.011: [iter 56 : loss : 0.1708 = 0.0781 + 0.0891 + 0.0036, time: 7.865395]
2023-05-13 20:02:07.175: epoch 56:	0.02466187  	0.18207121  	0.09671373  
2023-05-13 20:02:07.175: Find a better model.
2023-05-13 20:02:15.012: [iter 57 : loss : 0.1688 = 0.0763 + 0.0889 + 0.0036, time: 7.834836]
2023-05-13 20:02:15.157: epoch 57:	0.02474654  	0.18264668  	0.09703413  
2023-05-13 20:02:15.157: Find a better model.
2023-05-13 20:02:22.815: [iter 58 : loss : 0.1670 = 0.0746 + 0.0887 + 0.0037, time: 7.656501]
2023-05-13 20:02:22.979: epoch 58:	0.02481006  	0.18318033  	0.09764909  
2023-05-13 20:02:22.979: Find a better model.
2023-05-13 20:02:30.816: [iter 59 : loss : 0.1660 = 0.0738 + 0.0885 + 0.0037, time: 7.835579]
2023-05-13 20:02:30.960: epoch 59:	0.02488768  	0.18374904  	0.09777220  
2023-05-13 20:02:30.961: Find a better model.
2023-05-13 20:02:38.762: [iter 60 : loss : 0.1646 = 0.0724 + 0.0884 + 0.0038, time: 7.799812]
2023-05-13 20:02:38.911: epoch 60:	0.02488768  	0.18361007  	0.09807768  
2023-05-13 20:02:46.575: [iter 61 : loss : 0.1632 = 0.0712 + 0.0882 + 0.0038, time: 7.661470]
2023-05-13 20:02:46.720: epoch 61:	0.02491591  	0.18391970  	0.09844662  
2023-05-13 20:02:46.720: Find a better model.
2023-05-13 20:02:54.401: [iter 62 : loss : 0.1617 = 0.0698 + 0.0880 + 0.0039, time: 7.680567]
2023-05-13 20:02:54.551: epoch 62:	0.02485945  	0.18350223  	0.09852540  
2023-05-13 20:03:02.161: [iter 63 : loss : 0.1602 = 0.0684 + 0.0879 + 0.0039, time: 7.608956]
2023-05-13 20:03:02.308: epoch 63:	0.02498646  	0.18437186  	0.09901288  
2023-05-13 20:03:02.308: Find a better model.
2023-05-13 20:03:10.167: [iter 64 : loss : 0.1591 = 0.0675 + 0.0877 + 0.0039, time: 7.857341]
2023-05-13 20:03:10.316: epoch 64:	0.02504997  	0.18485245  	0.09926847  
2023-05-13 20:03:10.316: Find a better model.
2023-05-13 20:03:17.991: [iter 65 : loss : 0.1579 = 0.0664 + 0.0875 + 0.0040, time: 7.673870]
2023-05-13 20:03:18.137: epoch 65:	0.02516287  	0.18572351  	0.09983774  
2023-05-13 20:03:18.137: Find a better model.
2023-05-13 20:03:25.960: [iter 66 : loss : 0.1564 = 0.0649 + 0.0874 + 0.0040, time: 7.822014]
2023-05-13 20:03:26.111: epoch 66:	0.02523344  	0.18624461  	0.10025594  
2023-05-13 20:03:26.111: Find a better model.
2023-05-13 20:03:33.936: [iter 67 : loss : 0.1549 = 0.0636 + 0.0873 + 0.0041, time: 7.824470]
2023-05-13 20:03:34.083: epoch 67:	0.02528990  	0.18665156  	0.10060573  
2023-05-13 20:03:34.083: Find a better model.
2023-05-13 20:03:41.977: [iter 68 : loss : 0.1544 = 0.0632 + 0.0871 + 0.0041, time: 7.892358]
2023-05-13 20:03:42.124: epoch 68:	0.02532518  	0.18685292  	0.10102073  
2023-05-13 20:03:42.124: Find a better model.
2023-05-13 20:03:49.983: [iter 69 : loss : 0.1526 = 0.0614 + 0.0870 + 0.0042, time: 7.858467]
2023-05-13 20:03:50.134: epoch 69:	0.02537458  	0.18703406  	0.10105629  
2023-05-13 20:03:50.134: Find a better model.
2023-05-13 20:03:57.951: [iter 70 : loss : 0.1510 = 0.0599 + 0.0869 + 0.0042, time: 7.816199]
2023-05-13 20:03:58.113: epoch 70:	0.02538163  	0.18703245  	0.10116898  
2023-05-13 20:04:05.948: [iter 71 : loss : 0.1496 = 0.0586 + 0.0867 + 0.0042, time: 7.833629]
2023-05-13 20:04:06.096: epoch 71:	0.02545925  	0.18776956  	0.10167824  
2023-05-13 20:04:06.096: Find a better model.
2023-05-13 20:04:13.939: [iter 72 : loss : 0.1494 = 0.0585 + 0.0866 + 0.0043, time: 7.842162]
2023-05-13 20:04:14.086: epoch 72:	0.02543103  	0.18729623  	0.10175285  
2023-05-13 20:04:21.740: [iter 73 : loss : 0.1479 = 0.0571 + 0.0865 + 0.0043, time: 7.652720]
2023-05-13 20:04:21.891: epoch 73:	0.02549454  	0.18783046  	0.10189849  
2023-05-13 20:04:21.891: Find a better model.
2023-05-13 20:04:29.566: [iter 74 : loss : 0.1464 = 0.0557 + 0.0864 + 0.0044, time: 7.673269]
2023-05-13 20:04:29.730: epoch 74:	0.02560744  	0.18865956  	0.10220476  
2023-05-13 20:04:29.730: Find a better model.
2023-05-13 20:04:37.344: [iter 75 : loss : 0.1460 = 0.0553 + 0.0863 + 0.0044, time: 7.612829]
2023-05-13 20:04:37.489: epoch 75:	0.02557921  	0.18838477  	0.10220549  
2023-05-13 20:04:45.140: [iter 76 : loss : 0.1450 = 0.0545 + 0.0861 + 0.0045, time: 7.649601]
2023-05-13 20:04:45.305: epoch 76:	0.02564272  	0.18862405  	0.10241681  
2023-05-13 20:04:52.938: [iter 77 : loss : 0.1441 = 0.0536 + 0.0860 + 0.0045, time: 7.632766]
2023-05-13 20:04:53.085: epoch 77:	0.02564978  	0.18881860  	0.10261567  
2023-05-13 20:04:53.085: Find a better model.
2023-05-13 20:05:00.718: [iter 78 : loss : 0.1431 = 0.0527 + 0.0859 + 0.0045, time: 7.630871]
2023-05-13 20:05:00.867: epoch 78:	0.02569918  	0.18924628  	0.10297484  
2023-05-13 20:05:00.867: Find a better model.
2023-05-13 20:05:08.503: [iter 79 : loss : 0.1418 = 0.0515 + 0.0858 + 0.0046, time: 7.634202]
2023-05-13 20:05:08.652: epoch 79:	0.02569212  	0.18921778  	0.10308202  
2023-05-13 20:05:16.321: [iter 80 : loss : 0.1412 = 0.0509 + 0.0857 + 0.0046, time: 7.666595]
2023-05-13 20:05:16.470: epoch 80:	0.02581913  	0.18992759  	0.10347624  
2023-05-13 20:05:16.470: Find a better model.
2023-05-13 20:05:24.114: [iter 81 : loss : 0.1410 = 0.0507 + 0.0856 + 0.0047, time: 7.641476]
2023-05-13 20:05:24.262: epoch 81:	0.02577680  	0.18999200  	0.10357259  
2023-05-13 20:05:24.262: Find a better model.
2023-05-13 20:05:31.910: [iter 82 : loss : 0.1395 = 0.0494 + 0.0855 + 0.0047, time: 7.646773]
2023-05-13 20:05:32.057: epoch 82:	0.02573445  	0.18964820  	0.10361643  
2023-05-13 20:05:39.729: [iter 83 : loss : 0.1386 = 0.0485 + 0.0854 + 0.0047, time: 7.670775]
2023-05-13 20:05:39.880: epoch 83:	0.02584030  	0.19061255  	0.10418420  
2023-05-13 20:05:39.880: Find a better model.
2023-05-13 20:05:47.493: [iter 84 : loss : 0.1386 = 0.0485 + 0.0853 + 0.0048, time: 7.610229]
2023-05-13 20:05:47.642: epoch 84:	0.02596026  	0.19136144  	0.10433757  
2023-05-13 20:05:47.642: Find a better model.
2023-05-13 20:05:55.306: [iter 85 : loss : 0.1374 = 0.0474 + 0.0852 + 0.0048, time: 7.662773]
2023-05-13 20:05:55.469: epoch 85:	0.02599554  	0.19182408  	0.10476602  
2023-05-13 20:05:55.469: Find a better model.
2023-05-13 20:06:03.112: [iter 86 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0049, time: 7.641571]
2023-05-13 20:06:03.253: epoch 86:	0.02608022  	0.19238842  	0.10500062  
2023-05-13 20:06:03.253: Find a better model.
2023-05-13 20:06:10.829: [iter 87 : loss : 0.1347 = 0.0448 + 0.0850 + 0.0049, time: 7.574456]
2023-05-13 20:06:10.981: epoch 87:	0.02608728  	0.19254039  	0.10507559  
2023-05-13 20:06:10.981: Find a better model.
2023-05-13 20:06:18.449: [iter 88 : loss : 0.1342 = 0.0444 + 0.0849 + 0.0049, time: 7.465735]
2023-05-13 20:06:18.598: epoch 88:	0.02607317  	0.19215761  	0.10510997  
2023-05-13 20:06:26.045: [iter 89 : loss : 0.1338 = 0.0440 + 0.0848 + 0.0050, time: 7.446093]
2023-05-13 20:06:26.197: epoch 89:	0.02615079  	0.19280499  	0.10530667  
2023-05-13 20:06:26.197: Find a better model.
2023-05-13 20:06:33.647: [iter 90 : loss : 0.1345 = 0.0447 + 0.0847 + 0.0050, time: 7.448577]
2023-05-13 20:06:33.800: epoch 90:	0.02618607  	0.19303995  	0.10555185  
2023-05-13 20:06:33.801: Find a better model.
2023-05-13 20:06:41.279: [iter 91 : loss : 0.1330 = 0.0434 + 0.0846 + 0.0050, time: 7.476775]
2023-05-13 20:06:41.430: epoch 91:	0.02626369  	0.19349666  	0.10581125  
2023-05-13 20:06:41.430: Find a better model.
2023-05-13 20:06:48.869: [iter 92 : loss : 0.1322 = 0.0426 + 0.0845 + 0.0051, time: 7.438311]
2023-05-13 20:06:49.021: epoch 92:	0.02615784  	0.19295251  	0.10563866  
2023-05-13 20:06:56.451: [iter 93 : loss : 0.1323 = 0.0427 + 0.0844 + 0.0051, time: 7.428633]
2023-05-13 20:06:56.601: epoch 93:	0.02620018  	0.19350019  	0.10589103  
2023-05-13 20:06:56.602: Find a better model.
2023-05-13 20:07:04.047: [iter 94 : loss : 0.1303 = 0.0407 + 0.0844 + 0.0052, time: 7.443427]
2023-05-13 20:07:04.200: epoch 94:	0.02624252  	0.19362970  	0.10611489  
2023-05-13 20:07:04.200: Find a better model.
2023-05-13 20:07:11.672: [iter 95 : loss : 0.1297 = 0.0402 + 0.0843 + 0.0052, time: 7.469541]
2023-05-13 20:07:11.821: epoch 95:	0.02620723  	0.19358496  	0.10616167  
2023-05-13 20:07:19.241: [iter 96 : loss : 0.1296 = 0.0401 + 0.0842 + 0.0052, time: 7.417507]
2023-05-13 20:07:19.390: epoch 96:	0.02629897  	0.19428715  	0.10644884  
2023-05-13 20:07:19.390: Find a better model.
2023-05-13 20:07:26.871: [iter 97 : loss : 0.1280 = 0.0386 + 0.0842 + 0.0053, time: 7.480478]
2023-05-13 20:07:27.025: epoch 97:	0.02636248  	0.19467676  	0.10659075  
2023-05-13 20:07:27.025: Find a better model.
2023-05-13 20:07:34.451: [iter 98 : loss : 0.1290 = 0.0396 + 0.0841 + 0.0053, time: 7.424008]
2023-05-13 20:07:34.601: epoch 98:	0.02641187  	0.19518980  	0.10689094  
2023-05-13 20:07:34.601: Find a better model.
2023-05-13 20:07:42.036: [iter 99 : loss : 0.1278 = 0.0384 + 0.0840 + 0.0053, time: 7.433881]
2023-05-13 20:07:42.187: epoch 99:	0.02639776  	0.19514720  	0.10689669  
2023-05-13 20:07:49.618: [iter 100 : loss : 0.1272 = 0.0379 + 0.0839 + 0.0054, time: 7.429381]
2023-05-13 20:07:49.768: epoch 100:	0.02648949  	0.19590950  	0.10710522  
2023-05-13 20:07:49.768: Find a better model.
2023-05-13 20:07:57.223: [iter 101 : loss : 0.1269 = 0.0376 + 0.0839 + 0.0054, time: 7.453107]
2023-05-13 20:07:57.374: epoch 101:	0.02654595  	0.19612218  	0.10729304  
2023-05-13 20:07:57.374: Find a better model.
2023-05-13 20:08:05.005: [iter 102 : loss : 0.1257 = 0.0364 + 0.0838 + 0.0054, time: 7.628888]
2023-05-13 20:08:05.157: epoch 102:	0.02649655  	0.19569166  	0.10722164  
2023-05-13 20:08:12.601: [iter 103 : loss : 0.1255 = 0.0363 + 0.0837 + 0.0055, time: 7.443697]
2023-05-13 20:08:12.752: epoch 103:	0.02655300  	0.19598369  	0.10730445  
2023-05-13 20:08:20.410: [iter 104 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0055, time: 7.655914]
2023-05-13 20:08:20.561: epoch 104:	0.02663062  	0.19688591  	0.10775218  
2023-05-13 20:08:20.561: Find a better model.
2023-05-13 20:08:28.061: [iter 105 : loss : 0.1252 = 0.0360 + 0.0836 + 0.0056, time: 7.498137]
2023-05-13 20:08:28.215: epoch 105:	0.02658828  	0.19649784  	0.10769559  
2023-05-13 20:08:35.610: [iter 106 : loss : 0.1248 = 0.0357 + 0.0835 + 0.0056, time: 7.394374]
2023-05-13 20:08:35.760: epoch 106:	0.02661650  	0.19655541  	0.10784104  
2023-05-13 20:08:43.240: [iter 107 : loss : 0.1238 = 0.0347 + 0.0835 + 0.0056, time: 7.479238]
2023-05-13 20:08:43.393: epoch 107:	0.02663768  	0.19667344  	0.10785805  
2023-05-13 20:08:50.796: [iter 108 : loss : 0.1236 = 0.0346 + 0.0834 + 0.0056, time: 7.401723]
2023-05-13 20:08:50.946: epoch 108:	0.02667296  	0.19667345  	0.10776899  
2023-05-13 20:08:58.402: [iter 109 : loss : 0.1223 = 0.0333 + 0.0833 + 0.0057, time: 7.453896]
2023-05-13 20:08:58.553: epoch 109:	0.02663768  	0.19661376  	0.10767263  
2023-05-13 20:09:06.024: [iter 110 : loss : 0.1217 = 0.0328 + 0.0833 + 0.0057, time: 7.470371]
2023-05-13 20:09:06.176: epoch 110:	0.02669413  	0.19715990  	0.10783130  
2023-05-13 20:09:06.176: Find a better model.
2023-05-13 20:09:13.607: [iter 111 : loss : 0.1217 = 0.0327 + 0.0832 + 0.0058, time: 7.430277]
2023-05-13 20:09:13.757: epoch 111:	0.02671530  	0.19694801  	0.10789829  
2023-05-13 20:09:21.186: [iter 112 : loss : 0.1215 = 0.0326 + 0.0832 + 0.0058, time: 7.428053]
2023-05-13 20:09:21.339: epoch 112:	0.02676470  	0.19747998  	0.10800335  
2023-05-13 20:09:21.339: Find a better model.
2023-05-13 20:09:28.803: [iter 113 : loss : 0.1216 = 0.0326 + 0.0831 + 0.0058, time: 7.463012]
2023-05-13 20:09:28.954: epoch 113:	0.02668002  	0.19664223  	0.10775249  
2023-05-13 20:09:36.389: [iter 114 : loss : 0.1205 = 0.0316 + 0.0830 + 0.0059, time: 7.433438]
2023-05-13 20:09:36.539: epoch 114:	0.02677880  	0.19708437  	0.10808237  
2023-05-13 20:09:43.987: [iter 115 : loss : 0.1201 = 0.0312 + 0.0830 + 0.0059, time: 7.446201]
2023-05-13 20:09:44.135: epoch 115:	0.02673646  	0.19681017  	0.10811231  
2023-05-13 20:09:51.613: [iter 116 : loss : 0.1192 = 0.0304 + 0.0829 + 0.0059, time: 7.475386]
2023-05-13 20:09:51.763: epoch 116:	0.02671530  	0.19664247  	0.10821079  
2023-05-13 20:09:59.359: [iter 117 : loss : 0.1192 = 0.0304 + 0.0829 + 0.0060, time: 7.593812]
2023-05-13 20:09:59.510: epoch 117:	0.02679997  	0.19764273  	0.10851914  
2023-05-13 20:09:59.510: Find a better model.
2023-05-13 20:10:07.005: [iter 118 : loss : 0.1193 = 0.0305 + 0.0828 + 0.0060, time: 7.493465]
2023-05-13 20:10:07.156: epoch 118:	0.02672941  	0.19726139  	0.10870314  
2023-05-13 20:10:14.801: [iter 119 : loss : 0.1182 = 0.0294 + 0.0828 + 0.0060, time: 7.644724]
2023-05-13 20:10:14.952: epoch 119:	0.02682114  	0.19744582  	0.10863443  
2023-05-13 20:10:22.545: [iter 120 : loss : 0.1185 = 0.0297 + 0.0827 + 0.0060, time: 7.592129]
2023-05-13 20:10:22.695: epoch 120:	0.02677175  	0.19722641  	0.10858519  
2023-05-13 20:10:30.165: [iter 121 : loss : 0.1184 = 0.0296 + 0.0827 + 0.0061, time: 7.468957]
2023-05-13 20:10:30.315: epoch 121:	0.02678586  	0.19739754  	0.10868055  
2023-05-13 20:10:37.785: [iter 122 : loss : 0.1176 = 0.0288 + 0.0826 + 0.0061, time: 7.467779]
2023-05-13 20:10:37.936: epoch 122:	0.02669413  	0.19647902  	0.10858452  
2023-05-13 20:10:45.356: [iter 123 : loss : 0.1176 = 0.0289 + 0.0826 + 0.0061, time: 7.418209]
2023-05-13 20:10:45.509: epoch 123:	0.02668707  	0.19639979  	0.10847254  
2023-05-13 20:10:52.772: [iter 124 : loss : 0.1165 = 0.0278 + 0.0825 + 0.0062, time: 7.260718]
2023-05-13 20:10:52.921: epoch 124:	0.02666590  	0.19604181  	0.10843454  
2023-05-13 20:11:00.376: [iter 125 : loss : 0.1160 = 0.0273 + 0.0825 + 0.0062, time: 7.454252]
2023-05-13 20:11:00.527: epoch 125:	0.02675764  	0.19677705  	0.10873391  
2023-05-13 20:11:07.952: [iter 126 : loss : 0.1161 = 0.0275 + 0.0824 + 0.0062, time: 7.423052]
2023-05-13 20:11:08.101: epoch 126:	0.02680703  	0.19731110  	0.10875838  
2023-05-13 20:11:15.548: [iter 127 : loss : 0.1152 = 0.0266 + 0.0824 + 0.0063, time: 7.445348]
2023-05-13 20:11:15.702: epoch 127:	0.02677174  	0.19679381  	0.10871388  
2023-05-13 20:11:23.165: [iter 128 : loss : 0.1163 = 0.0277 + 0.0824 + 0.0063, time: 7.461723]
2023-05-13 20:11:23.316: epoch 128:	0.02672941  	0.19657102  	0.10889560  
2023-05-13 20:11:30.737: [iter 129 : loss : 0.1156 = 0.0270 + 0.0823 + 0.0063, time: 7.419636]
2023-05-13 20:11:30.889: epoch 129:	0.02678586  	0.19696048  	0.10906300  
2023-05-13 20:11:38.141: [iter 130 : loss : 0.1154 = 0.0268 + 0.0822 + 0.0064, time: 7.251065]
2023-05-13 20:11:38.292: epoch 130:	0.02672235  	0.19647440  	0.10891861  
2023-05-13 20:11:45.736: [iter 131 : loss : 0.1144 = 0.0258 + 0.0822 + 0.0064, time: 7.441709]
2023-05-13 20:11:45.887: epoch 131:	0.02670824  	0.19639972  	0.10887283  
2023-05-13 20:11:53.317: [iter 132 : loss : 0.1148 = 0.0262 + 0.0822 + 0.0064, time: 7.427499]
2023-05-13 20:11:53.468: epoch 132:	0.02678586  	0.19694735  	0.10906940  
2023-05-13 20:12:00.964: [iter 133 : loss : 0.1137 = 0.0252 + 0.0821 + 0.0064, time: 7.494954]
2023-05-13 20:12:01.115: epoch 133:	0.02673647  	0.19629097  	0.10900234  
2023-05-13 20:12:08.567: [iter 134 : loss : 0.1141 = 0.0255 + 0.0821 + 0.0065, time: 7.451204]
2023-05-13 20:12:08.724: epoch 134:	0.02670118  	0.19590493  	0.10911755  
2023-05-13 20:12:16.124: [iter 135 : loss : 0.1140 = 0.0255 + 0.0820 + 0.0065, time: 7.399703]
2023-05-13 20:12:16.276: epoch 135:	0.02669412  	0.19572324  	0.10887469  
2023-05-13 20:12:23.737: [iter 136 : loss : 0.1137 = 0.0251 + 0.0820 + 0.0065, time: 7.459594]
2023-05-13 20:12:23.891: epoch 136:	0.02677175  	0.19611450  	0.10904432  
2023-05-13 20:12:31.348: [iter 137 : loss : 0.1130 = 0.0245 + 0.0819 + 0.0066, time: 7.456690]
2023-05-13 20:12:31.498: epoch 137:	0.02673646  	0.19615737  	0.10900620  
2023-05-13 20:12:38.911: [iter 138 : loss : 0.1128 = 0.0243 + 0.0819 + 0.0066, time: 7.411518]
2023-05-13 20:12:39.061: epoch 138:	0.02677175  	0.19671792  	0.10917223  
2023-05-13 20:12:46.520: [iter 139 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0066, time: 7.458182]
2023-05-13 20:12:46.671: epoch 139:	0.02672941  	0.19663762  	0.10920487  
2023-05-13 20:12:54.142: [iter 140 : loss : 0.1122 = 0.0237 + 0.0818 + 0.0067, time: 7.470200]
2023-05-13 20:12:54.294: epoch 140:	0.02666590  	0.19585222  	0.10910134  
2023-05-13 20:13:01.705: [iter 141 : loss : 0.1126 = 0.0241 + 0.0818 + 0.0067, time: 7.409172]
2023-05-13 20:13:01.861: epoch 141:	0.02672235  	0.19634584  	0.10930319  
2023-05-13 20:13:09.350: [iter 142 : loss : 0.1118 = 0.0233 + 0.0818 + 0.0067, time: 7.487572]
2023-05-13 20:13:09.502: epoch 142:	0.02667296  	0.19607328  	0.10938591  
2023-05-13 20:13:09.502: Early stopping is trigger at epoch: 142
2023-05-13 20:13:09.502: best_result@epoch 117:

2023-05-13 20:13:09.502: 		0.0268      	0.1976      	0.1085      
2023-05-14 17:56:49.739: my pid: 6676
2023-05-14 17:56:49.739: model: model.general_recommender.SGL
2023-05-14 17:56:49.739: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-14 17:56:49.739: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-14 17:56:52.848: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-14 17:57:00.140: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.292084]
2023-05-14 17:57:00.292: epoch 1:	0.00221564  	0.01518528  	0.00772544  
2023-05-14 17:57:00.293: Find a better model.
2023-05-14 17:57:07.655: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.361259]
2023-05-14 17:57:07.840: epoch 2:	0.00449476  	0.03100881  	0.01590211  
2023-05-14 17:57:07.840: Find a better model.
2023-05-14 17:57:15.040: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.198096]
2023-05-14 17:57:15.226: epoch 3:	0.00748653  	0.05352484  	0.02580202  
2023-05-14 17:57:15.226: Find a better model.
2023-05-14 17:57:22.238: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.008610]
2023-05-14 17:57:22.393: epoch 4:	0.01072536  	0.07692863  	0.03665071  
2023-05-14 17:57:22.393: Find a better model.
2023-05-14 17:57:29.243: [iter 5 : loss : 0.7687 = 0.6893 + 0.0794 + 0.0000, time: 6.848562]
2023-05-14 17:57:29.389: epoch 5:	0.01437356  	0.10276464  	0.04921317  
2023-05-14 17:57:29.390: Find a better model.
2023-05-14 17:57:36.236: [iter 6 : loss : 0.7642 = 0.6842 + 0.0800 + 0.0000, time: 6.844971]
2023-05-14 17:57:36.396: epoch 6:	0.01685035  	0.12177445  	0.05954504  
2023-05-14 17:57:36.396: Find a better model.
2023-05-14 17:57:43.038: [iter 7 : loss : 0.7523 = 0.6709 + 0.0813 + 0.0001, time: 6.641475]
2023-05-14 17:57:43.194: epoch 7:	0.01827574  	0.13198544  	0.06607554  
2023-05-14 17:57:43.194: Find a better model.
2023-05-14 17:57:49.823: [iter 8 : loss : 0.7251 = 0.6406 + 0.0844 + 0.0001, time: 6.626436]
2023-05-14 17:57:49.980: epoch 8:	0.01862857  	0.13639350  	0.06840094  
2023-05-14 17:57:49.980: Find a better model.
2023-05-14 17:57:56.425: [iter 9 : loss : 0.6731 = 0.5835 + 0.0894 + 0.0002, time: 6.443291]
2023-05-14 17:57:56.566: epoch 9:	0.01848038  	0.13680002  	0.06819579  
2023-05-14 17:57:56.566: Find a better model.
2023-05-14 17:58:03.027: [iter 10 : loss : 0.6011 = 0.5060 + 0.0947 + 0.0003, time: 6.458128]
2023-05-14 17:58:03.182: epoch 10:	0.01837454  	0.13633209  	0.06812022  
2023-05-14 17:58:09.611: [iter 11 : loss : 0.5290 = 0.4298 + 0.0987 + 0.0005, time: 6.427864]
2023-05-14 17:58:09.766: epoch 11:	0.01836043  	0.13583887  	0.06791667  
2023-05-14 17:58:16.215: [iter 12 : loss : 0.4712 = 0.3696 + 0.1010 + 0.0006, time: 6.447530]
2023-05-14 17:58:16.362: epoch 12:	0.01847333  	0.13649495  	0.06847052  
2023-05-14 17:58:22.637: [iter 13 : loss : 0.4301 = 0.3272 + 0.1021 + 0.0008, time: 6.274665]
2023-05-14 17:58:22.794: epoch 13:	0.01852978  	0.13735576  	0.06920649  
2023-05-14 17:58:22.794: Find a better model.
2023-05-14 17:58:29.226: [iter 14 : loss : 0.3987 = 0.2952 + 0.1026 + 0.0009, time: 6.429641]
2023-05-14 17:58:29.383: epoch 14:	0.01876971  	0.13902941  	0.07004292  
2023-05-14 17:58:29.383: Find a better model.
2023-05-14 17:58:35.829: [iter 15 : loss : 0.3764 = 0.2727 + 0.1027 + 0.0010, time: 6.444951]
2023-05-14 17:58:35.972: epoch 15:	0.01894612  	0.14012083  	0.07074230  
2023-05-14 17:58:35.972: Find a better model.
2023-05-14 17:58:42.423: [iter 16 : loss : 0.3568 = 0.2531 + 0.1025 + 0.0012, time: 6.450488]
2023-05-14 17:58:42.566: epoch 16:	0.01926366  	0.14180306  	0.07178690  
2023-05-14 17:58:42.566: Find a better model.
2023-05-14 17:58:49.186: [iter 17 : loss : 0.3423 = 0.2388 + 0.1023 + 0.0013, time: 6.618753]
2023-05-14 17:58:49.330: epoch 17:	0.01940479  	0.14290649  	0.07266855  
2023-05-14 17:58:49.330: Find a better model.
2023-05-14 17:58:55.812: [iter 18 : loss : 0.3282 = 0.2249 + 0.1019 + 0.0014, time: 6.480415]
2023-05-14 17:58:55.968: epoch 18:	0.01954592  	0.14384624  	0.07343023  
2023-05-14 17:58:55.968: Find a better model.
2023-05-14 17:59:02.428: [iter 19 : loss : 0.3151 = 0.2121 + 0.1016 + 0.0014, time: 6.458740]
2023-05-14 17:59:02.588: epoch 19:	0.01981408  	0.14580736  	0.07449833  
2023-05-14 17:59:02.588: Find a better model.
2023-05-14 17:59:09.191: [iter 20 : loss : 0.3060 = 0.2033 + 0.1012 + 0.0015, time: 6.600920]
2023-05-14 17:59:09.334: epoch 20:	0.01989170  	0.14634013  	0.07503683  
2023-05-14 17:59:09.334: Find a better model.
2023-05-14 17:59:15.795: [iter 21 : loss : 0.2968 = 0.1945 + 0.1007 + 0.0016, time: 6.459437]
2023-05-14 17:59:15.938: epoch 21:	0.02015278  	0.14844379  	0.07595300  
2023-05-14 17:59:15.938: Find a better model.
2023-05-14 17:59:22.409: [iter 22 : loss : 0.2890 = 0.1870 + 0.1003 + 0.0017, time: 6.469552]
2023-05-14 17:59:22.567: epoch 22:	0.02039271  	0.14996624  	0.07662833  
2023-05-14 17:59:22.567: Find a better model.
2023-05-14 17:59:29.173: [iter 23 : loss : 0.2810 = 0.1794 + 0.0999 + 0.0018, time: 6.603412]
2023-05-14 17:59:29.332: epoch 23:	0.02069614  	0.15221380  	0.07763916  
2023-05-14 17:59:29.332: Find a better model.
2023-05-14 17:59:35.813: [iter 24 : loss : 0.2747 = 0.1735 + 0.0994 + 0.0018, time: 6.480595]
2023-05-14 17:59:35.971: epoch 24:	0.02084432  	0.15286797  	0.07840723  
2023-05-14 17:59:35.971: Find a better model.
2023-05-14 17:59:42.399: [iter 25 : loss : 0.2685 = 0.1676 + 0.0990 + 0.0019, time: 6.426348]
2023-05-14 17:59:42.555: epoch 25:	0.02099250  	0.15392436  	0.07904744  
2023-05-14 17:59:42.555: Find a better model.
2023-05-14 17:59:49.184: [iter 26 : loss : 0.2647 = 0.1641 + 0.0985 + 0.0020, time: 6.626874]
2023-05-14 17:59:49.341: epoch 26:	0.02121126  	0.15537992  	0.07972797  
2023-05-14 17:59:49.342: Find a better model.
2023-05-14 17:59:55.774: [iter 27 : loss : 0.2572 = 0.1570 + 0.0981 + 0.0020, time: 6.431264]
2023-05-14 17:59:55.933: epoch 27:	0.02129594  	0.15651755  	0.08057222  
2023-05-14 17:59:55.933: Find a better model.
2023-05-14 18:00:02.402: [iter 28 : loss : 0.2526 = 0.1527 + 0.0978 + 0.0021, time: 6.468201]
2023-05-14 18:00:02.558: epoch 28:	0.02141590  	0.15721515  	0.08127296  
2023-05-14 18:00:02.559: Find a better model.
2023-05-14 18:00:08.989: [iter 29 : loss : 0.2479 = 0.1484 + 0.0973 + 0.0022, time: 6.429323]
2023-05-14 18:00:09.146: epoch 29:	0.02157115  	0.15819900  	0.08185856  
2023-05-14 18:00:09.146: Find a better model.
2023-05-14 18:00:15.585: [iter 30 : loss : 0.2416 = 0.1424 + 0.0970 + 0.0022, time: 6.436795]
2023-05-14 18:00:15.742: epoch 30:	0.02181106  	0.16005179  	0.08272815  
2023-05-14 18:00:15.749: Find a better model.
2023-05-14 18:00:22.177: [iter 31 : loss : 0.2381 = 0.1392 + 0.0966 + 0.0023, time: 6.427056]
2023-05-14 18:00:22.335: epoch 31:	0.02206510  	0.16204233  	0.08357767  
2023-05-14 18:00:22.335: Find a better model.
2023-05-14 18:00:28.780: [iter 32 : loss : 0.2325 = 0.1339 + 0.0962 + 0.0024, time: 6.443349]
2023-05-14 18:00:28.938: epoch 32:	0.02221329  	0.16379236  	0.08439368  
2023-05-14 18:00:28.938: Find a better model.
2023-05-14 18:00:35.379: [iter 33 : loss : 0.2302 = 0.1319 + 0.0958 + 0.0024, time: 6.440210]
2023-05-14 18:00:35.540: epoch 33:	0.02237558  	0.16477363  	0.08503591  
2023-05-14 18:00:35.541: Find a better model.
2023-05-14 18:00:41.978: [iter 34 : loss : 0.2259 = 0.1279 + 0.0955 + 0.0025, time: 6.434757]
2023-05-14 18:00:42.134: epoch 34:	0.02236147  	0.16468014  	0.08559509  
2023-05-14 18:00:48.568: [iter 35 : loss : 0.2226 = 0.1249 + 0.0952 + 0.0025, time: 6.433207]
2023-05-14 18:00:48.726: epoch 35:	0.02247437  	0.16543517  	0.08618179  
2023-05-14 18:00:48.726: Find a better model.
2023-05-14 18:00:55.365: [iter 36 : loss : 0.2192 = 0.1217 + 0.0949 + 0.0026, time: 6.638201]
2023-05-14 18:00:55.529: epoch 36:	0.02268607  	0.16716295  	0.08692928  
2023-05-14 18:00:55.529: Find a better model.
2023-05-14 18:01:01.972: [iter 37 : loss : 0.2155 = 0.1182 + 0.0946 + 0.0026, time: 6.442553]
2023-05-14 18:01:02.129: epoch 37:	0.02279897  	0.16758512  	0.08731817  
2023-05-14 18:01:02.129: Find a better model.
2023-05-14 18:01:08.752: [iter 38 : loss : 0.2139 = 0.1169 + 0.0943 + 0.0027, time: 6.620749]
2023-05-14 18:01:08.895: epoch 38:	0.02300361  	0.16924110  	0.08807998  
2023-05-14 18:01:08.895: Find a better model.
2023-05-14 18:01:15.562: [iter 39 : loss : 0.2095 = 0.1128 + 0.0940 + 0.0027, time: 6.666126]
2023-05-14 18:01:15.721: epoch 39:	0.02303184  	0.16946076  	0.08834994  
2023-05-14 18:01:15.721: Find a better model.
2023-05-14 18:01:22.353: [iter 40 : loss : 0.2062 = 0.1097 + 0.0937 + 0.0028, time: 6.631517]
2023-05-14 18:01:22.516: epoch 40:	0.02312358  	0.17017135  	0.08882387  
2023-05-14 18:01:22.516: Find a better model.
2023-05-14 18:01:28.972: [iter 41 : loss : 0.2045 = 0.1082 + 0.0934 + 0.0028, time: 6.455037]
2023-05-14 18:01:29.128: epoch 41:	0.02321531  	0.17090693  	0.08929006  
2023-05-14 18:01:29.129: Find a better model.
2023-05-14 18:01:35.752: [iter 42 : loss : 0.2023 = 0.1062 + 0.0932 + 0.0029, time: 6.622338]
2023-05-14 18:01:35.907: epoch 42:	0.02330704  	0.17153507  	0.08988458  
2023-05-14 18:01:35.907: Find a better model.
2023-05-14 18:01:42.559: [iter 43 : loss : 0.1985 = 0.1027 + 0.0929 + 0.0029, time: 6.650239]
2023-05-14 18:01:42.714: epoch 43:	0.02346934  	0.17274067  	0.09048579  
2023-05-14 18:01:42.714: Find a better model.
2023-05-14 18:01:49.367: [iter 44 : loss : 0.1951 = 0.0995 + 0.0926 + 0.0030, time: 6.650349]
2023-05-14 18:01:49.529: epoch 44:	0.02346229  	0.17272532  	0.09092064  
2023-05-14 18:01:56.204: [iter 45 : loss : 0.1928 = 0.0973 + 0.0924 + 0.0031, time: 6.672770]
2023-05-14 18:01:56.353: epoch 45:	0.02362459  	0.17385995  	0.09155440  
2023-05-14 18:01:56.353: Find a better model.
2023-05-14 18:02:02.740: [iter 46 : loss : 0.1907 = 0.0954 + 0.0921 + 0.0031, time: 6.386391]
2023-05-14 18:02:02.897: epoch 46:	0.02373749  	0.17438631  	0.09203824  
2023-05-14 18:02:02.897: Find a better model.
2023-05-14 18:02:09.347: [iter 47 : loss : 0.1898 = 0.0948 + 0.0919 + 0.0032, time: 6.449856]
2023-05-14 18:02:09.502: epoch 47:	0.02382922  	0.17500100  	0.09250198  
2023-05-14 18:02:09.502: Find a better model.
2023-05-14 18:02:15.923: [iter 48 : loss : 0.1860 = 0.0911 + 0.0917 + 0.0032, time: 6.419390]
2023-05-14 18:02:16.077: epoch 48:	0.02396329  	0.17603867  	0.09308904  
2023-05-14 18:02:16.077: Find a better model.
2023-05-14 18:02:22.518: [iter 49 : loss : 0.1830 = 0.0883 + 0.0915 + 0.0032, time: 6.440333]
2023-05-14 18:02:22.661: epoch 49:	0.02401268  	0.17646027  	0.09367727  
2023-05-14 18:02:22.661: Find a better model.
2023-05-14 18:02:29.129: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.465753]
2023-05-14 18:02:29.283: epoch 50:	0.02409736  	0.17673925  	0.09410839  
2023-05-14 18:02:29.284: Find a better model.
2023-05-14 18:02:35.909: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0033, time: 6.624146]
2023-05-14 18:02:36.064: epoch 51:	0.02413264  	0.17696419  	0.09447662  
2023-05-14 18:02:36.064: Find a better model.
2023-05-14 18:02:42.713: [iter 52 : loss : 0.1791 = 0.0848 + 0.0909 + 0.0034, time: 6.648141]
2023-05-14 18:02:42.866: epoch 52:	0.02430199  	0.17808478  	0.09526155  
2023-05-14 18:02:42.866: Find a better model.
2023-05-14 18:02:49.500: [iter 53 : loss : 0.1771 = 0.0830 + 0.0906 + 0.0034, time: 6.633218]
2023-05-14 18:02:49.657: epoch 53:	0.02436550  	0.17860141  	0.09541138  
2023-05-14 18:02:49.657: Find a better model.
2023-05-14 18:02:56.321: [iter 54 : loss : 0.1751 = 0.0811 + 0.0905 + 0.0035, time: 6.663671]
2023-05-14 18:02:56.478: epoch 54:	0.02444312  	0.17927010  	0.09610055  
2023-05-14 18:02:56.478: Find a better model.
2023-05-14 18:03:02.918: [iter 55 : loss : 0.1731 = 0.0793 + 0.0903 + 0.0035, time: 6.438011]
2023-05-14 18:03:03.073: epoch 55:	0.02455602  	0.18013078  	0.09649414  
2023-05-14 18:03:03.073: Find a better model.
2023-05-14 18:03:09.679: [iter 56 : loss : 0.1714 = 0.0777 + 0.0901 + 0.0036, time: 6.605241]
2023-05-14 18:03:09.820: epoch 56:	0.02466187  	0.18113236  	0.09715656  
2023-05-14 18:03:09.821: Find a better model.
2023-05-14 18:03:16.486: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.664179]
2023-05-14 18:03:16.633: epoch 57:	0.02474655  	0.18182689  	0.09756450  
2023-05-14 18:03:16.633: Find a better model.
2023-05-14 18:03:23.100: [iter 58 : loss : 0.1677 = 0.0742 + 0.0898 + 0.0037, time: 6.466052]
2023-05-14 18:03:23.256: epoch 58:	0.02471832  	0.18163270  	0.09781048  
2023-05-14 18:03:29.709: [iter 59 : loss : 0.1666 = 0.0733 + 0.0896 + 0.0037, time: 6.450573]
2023-05-14 18:03:29.866: epoch 59:	0.02488062  	0.18279441  	0.09831438  
2023-05-14 18:03:29.866: Find a better model.
2023-05-14 18:03:36.298: [iter 60 : loss : 0.1651 = 0.0720 + 0.0894 + 0.0038, time: 6.430140]
2023-05-14 18:03:36.440: epoch 60:	0.02495823  	0.18340603  	0.09866393  
2023-05-14 18:03:36.441: Find a better model.
2023-05-14 18:03:42.885: [iter 61 : loss : 0.1637 = 0.0706 + 0.0892 + 0.0038, time: 6.441798]
2023-05-14 18:03:43.042: epoch 61:	0.02500763  	0.18377843  	0.09897690  
2023-05-14 18:03:43.042: Find a better model.
2023-05-14 18:03:49.491: [iter 62 : loss : 0.1624 = 0.0695 + 0.0891 + 0.0038, time: 6.447628]
2023-05-14 18:03:49.646: epoch 62:	0.02507820  	0.18442719  	0.09936485  
2023-05-14 18:03:49.646: Find a better model.
2023-05-14 18:03:56.097: [iter 63 : loss : 0.1609 = 0.0681 + 0.0889 + 0.0039, time: 6.450743]
2023-05-14 18:03:56.254: epoch 63:	0.02522638  	0.18540788  	0.09989858  
2023-05-14 18:03:56.254: Find a better model.
2023-05-14 18:04:02.701: [iter 64 : loss : 0.1599 = 0.0672 + 0.0887 + 0.0039, time: 6.446348]
2023-05-14 18:04:02.858: epoch 64:	0.02515582  	0.18473925  	0.09999888  
2023-05-14 18:04:09.282: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.422387]
2023-05-14 18:04:09.437: epoch 65:	0.02528989  	0.18569145  	0.10059034  
2023-05-14 18:04:09.437: Find a better model.
2023-05-14 18:04:15.877: [iter 66 : loss : 0.1571 = 0.0646 + 0.0885 + 0.0040, time: 6.438882]
2023-05-14 18:04:16.031: epoch 66:	0.02533929  	0.18646333  	0.10120949  
2023-05-14 18:04:16.031: Find a better model.
2023-05-14 18:04:22.457: [iter 67 : loss : 0.1555 = 0.0631 + 0.0883 + 0.0041, time: 6.424277]
2023-05-14 18:04:22.611: epoch 67:	0.02539573  	0.18711168  	0.10134610  
2023-05-14 18:04:22.611: Find a better model.
2023-05-14 18:04:29.076: [iter 68 : loss : 0.1552 = 0.0630 + 0.0882 + 0.0041, time: 6.463946]
2023-05-14 18:04:29.230: epoch 68:	0.02555097  	0.18845721  	0.10184018  
2023-05-14 18:04:29.230: Find a better model.
2023-05-14 18:04:35.680: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0041, time: 6.449308]
2023-05-14 18:04:35.836: epoch 69:	0.02555803  	0.18834026  	0.10194053  
2023-05-14 18:04:42.270: [iter 70 : loss : 0.1516 = 0.0594 + 0.0880 + 0.0042, time: 6.430174]
2023-05-14 18:04:42.427: epoch 70:	0.02550158  	0.18804371  	0.10198262  
2023-05-14 18:04:48.868: [iter 71 : loss : 0.1504 = 0.0583 + 0.0878 + 0.0042, time: 6.439316]
2023-05-14 18:04:49.023: epoch 71:	0.02555804  	0.18842286  	0.10227134  
2023-05-14 18:04:55.473: [iter 72 : loss : 0.1500 = 0.0580 + 0.0877 + 0.0043, time: 6.449531]
2023-05-14 18:04:55.628: epoch 72:	0.02558626  	0.18867807  	0.10236681  
2023-05-14 18:04:55.628: Find a better model.
2023-05-14 18:05:02.074: [iter 73 : loss : 0.1487 = 0.0568 + 0.0876 + 0.0043, time: 6.445014]
2023-05-14 18:05:02.226: epoch 73:	0.02572034  	0.18945719  	0.10264735  
2023-05-14 18:05:02.226: Find a better model.
2023-05-14 18:05:08.664: [iter 74 : loss : 0.1474 = 0.0555 + 0.0875 + 0.0044, time: 6.435704]
2023-05-14 18:05:08.818: epoch 74:	0.02574856  	0.18954891  	0.10306108  
2023-05-14 18:05:08.819: Find a better model.
2023-05-14 18:05:15.259: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.439582]
2023-05-14 18:05:15.417: epoch 75:	0.02575562  	0.18964630  	0.10317215  
2023-05-14 18:05:15.417: Find a better model.
2023-05-14 18:05:21.872: [iter 76 : loss : 0.1456 = 0.0539 + 0.0872 + 0.0044, time: 6.454236]
2023-05-14 18:05:22.031: epoch 76:	0.02577678  	0.18930730  	0.10326864  
2023-05-14 18:05:28.465: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.432352]
2023-05-14 18:05:28.620: epoch 77:	0.02588262  	0.19034460  	0.10376265  
2023-05-14 18:05:28.620: Find a better model.
2023-05-14 18:05:35.066: [iter 78 : loss : 0.1438 = 0.0522 + 0.0870 + 0.0045, time: 6.444955]
2023-05-14 18:05:35.223: epoch 78:	0.02580500  	0.18993232  	0.10362965  
2023-05-14 18:05:41.648: [iter 79 : loss : 0.1428 = 0.0513 + 0.0869 + 0.0046, time: 6.424574]
2023-05-14 18:05:41.790: epoch 79:	0.02593907  	0.19069542  	0.10385776  
2023-05-14 18:05:41.791: Find a better model.
2023-05-14 18:05:48.242: [iter 80 : loss : 0.1420 = 0.0506 + 0.0868 + 0.0046, time: 6.450499]
2023-05-14 18:05:48.396: epoch 80:	0.02593907  	0.19070157  	0.10388295  
2023-05-14 18:05:48.396: Find a better model.
2023-05-14 18:05:54.857: [iter 81 : loss : 0.1419 = 0.0505 + 0.0867 + 0.0046, time: 6.458861]
2023-05-14 18:05:55.010: epoch 81:	0.02596024  	0.19103165  	0.10411470  
2023-05-14 18:05:55.010: Find a better model.
2023-05-14 18:06:01.446: [iter 82 : loss : 0.1403 = 0.0490 + 0.0866 + 0.0047, time: 6.434242]
2023-05-14 18:06:01.599: epoch 82:	0.02599553  	0.19120561  	0.10431787  
2023-05-14 18:06:01.599: Find a better model.
2023-05-14 18:06:08.058: [iter 83 : loss : 0.1396 = 0.0484 + 0.0865 + 0.0047, time: 6.457213]
2023-05-14 18:06:08.212: epoch 83:	0.02601670  	0.19132207  	0.10449519  
2023-05-14 18:06:08.212: Find a better model.
2023-05-14 18:06:14.640: [iter 84 : loss : 0.1393 = 0.0481 + 0.0864 + 0.0048, time: 6.426899]
2023-05-14 18:06:14.795: epoch 84:	0.02596730  	0.19073632  	0.10448384  
2023-05-14 18:06:21.239: [iter 85 : loss : 0.1387 = 0.0476 + 0.0863 + 0.0048, time: 6.442449]
2023-05-14 18:06:21.395: epoch 85:	0.02598847  	0.19085564  	0.10449588  
2023-05-14 18:06:27.848: [iter 86 : loss : 0.1382 = 0.0472 + 0.0862 + 0.0048, time: 6.450654]
2023-05-14 18:06:28.001: epoch 86:	0.02600258  	0.19107324  	0.10457601  
2023-05-14 18:06:34.430: [iter 87 : loss : 0.1354 = 0.0444 + 0.0861 + 0.0049, time: 6.427949]
2023-05-14 18:06:34.583: epoch 87:	0.02615782  	0.19200067  	0.10486776  
2023-05-14 18:06:34.583: Find a better model.
2023-05-14 18:06:41.036: [iter 88 : loss : 0.1351 = 0.0441 + 0.0861 + 0.0049, time: 6.451586]
2023-05-14 18:06:41.193: epoch 88:	0.02614371  	0.19208021  	0.10502581  
2023-05-14 18:06:41.193: Find a better model.
2023-05-14 18:06:47.630: [iter 89 : loss : 0.1347 = 0.0438 + 0.0859 + 0.0049, time: 6.434958]
2023-05-14 18:06:47.784: epoch 89:	0.02617194  	0.19230741  	0.10509971  
2023-05-14 18:06:47.784: Find a better model.
2023-05-14 18:06:54.221: [iter 90 : loss : 0.1352 = 0.0443 + 0.0859 + 0.0050, time: 6.436353]
2023-05-14 18:06:54.376: epoch 90:	0.02624250  	0.19287889  	0.10544801  
2023-05-14 18:06:54.376: Find a better model.
2023-05-14 18:07:00.821: [iter 91 : loss : 0.1342 = 0.0433 + 0.0858 + 0.0050, time: 6.442489]
2023-05-14 18:07:00.974: epoch 91:	0.02625662  	0.19285862  	0.10554447  
2023-05-14 18:07:07.409: [iter 92 : loss : 0.1331 = 0.0424 + 0.0857 + 0.0051, time: 6.433909]
2023-05-14 18:07:07.561: epoch 92:	0.02622839  	0.19287986  	0.10579734  
2023-05-14 18:07:07.561: Find a better model.
2023-05-14 18:07:13.833: [iter 93 : loss : 0.1333 = 0.0426 + 0.0856 + 0.0051, time: 6.270729]
2023-05-14 18:07:13.985: epoch 93:	0.02633424  	0.19354200  	0.10620987  
2023-05-14 18:07:13.985: Find a better model.
2023-05-14 18:07:20.245: [iter 94 : loss : 0.1313 = 0.0406 + 0.0856 + 0.0051, time: 6.257537]
2023-05-14 18:07:20.400: epoch 94:	0.02628484  	0.19313857  	0.10610646  
2023-05-14 18:07:26.808: [iter 95 : loss : 0.1307 = 0.0400 + 0.0855 + 0.0052, time: 6.406757]
2023-05-14 18:07:26.950: epoch 95:	0.02632718  	0.19345561  	0.10636748  
2023-05-14 18:07:33.225: [iter 96 : loss : 0.1307 = 0.0401 + 0.0854 + 0.0052, time: 6.272973]
2023-05-14 18:07:33.381: epoch 96:	0.02630601  	0.19347514  	0.10631797  
2023-05-14 18:07:39.804: [iter 97 : loss : 0.1291 = 0.0386 + 0.0853 + 0.0052, time: 6.422147]
2023-05-14 18:07:39.957: epoch 97:	0.02639775  	0.19385840  	0.10662586  
2023-05-14 18:07:39.957: Find a better model.
2023-05-14 18:07:46.411: [iter 98 : loss : 0.1299 = 0.0393 + 0.0853 + 0.0053, time: 6.452804]
2023-05-14 18:07:46.566: epoch 98:	0.02644008  	0.19443412  	0.10671278  
2023-05-14 18:07:46.566: Find a better model.
2023-05-14 18:07:53.005: [iter 99 : loss : 0.1287 = 0.0382 + 0.0852 + 0.0053, time: 6.438578]
2023-05-14 18:07:53.160: epoch 99:	0.02652476  	0.19484729  	0.10719895  
2023-05-14 18:07:53.161: Find a better model.
2023-05-14 18:07:59.604: [iter 100 : loss : 0.1282 = 0.0378 + 0.0851 + 0.0053, time: 6.442422]
2023-05-14 18:07:59.758: epoch 100:	0.02659533  	0.19562376  	0.10756156  
2023-05-14 18:07:59.758: Find a better model.
2023-05-14 18:08:06.214: [iter 101 : loss : 0.1278 = 0.0374 + 0.0851 + 0.0054, time: 6.454290]
2023-05-14 18:08:06.370: epoch 101:	0.02660944  	0.19530524  	0.10749264  
2023-05-14 18:08:12.801: [iter 102 : loss : 0.1269 = 0.0365 + 0.0850 + 0.0054, time: 6.430580]
2023-05-14 18:08:12.954: epoch 102:	0.02660944  	0.19558696  	0.10758672  
2023-05-14 18:08:19.390: [iter 103 : loss : 0.1268 = 0.0364 + 0.0850 + 0.0054, time: 6.434253]
2023-05-14 18:08:19.544: epoch 103:	0.02664472  	0.19583710  	0.10764544  
2023-05-14 18:08:19.545: Find a better model.
2023-05-14 18:08:26.011: [iter 104 : loss : 0.1270 = 0.0367 + 0.0848 + 0.0055, time: 6.465746]
2023-05-14 18:08:26.165: epoch 104:	0.02665178  	0.19616172  	0.10798400  
2023-05-14 18:08:26.165: Find a better model.
2023-05-14 18:08:32.599: [iter 105 : loss : 0.1265 = 0.0362 + 0.0847 + 0.0055, time: 6.430983]
2023-05-14 18:08:32.755: epoch 105:	0.02664473  	0.19588247  	0.10795484  
2023-05-14 18:08:39.207: [iter 106 : loss : 0.1256 = 0.0353 + 0.0847 + 0.0056, time: 6.449653]
2023-05-14 18:08:39.365: epoch 106:	0.02672235  	0.19635849  	0.10816336  
2023-05-14 18:08:39.365: Find a better model.
2023-05-14 18:08:45.794: [iter 107 : loss : 0.1248 = 0.0346 + 0.0846 + 0.0056, time: 6.428365]
2023-05-14 18:08:45.951: epoch 107:	0.02665178  	0.19578247  	0.10811856  
2023-05-14 18:08:52.402: [iter 108 : loss : 0.1247 = 0.0344 + 0.0846 + 0.0056, time: 6.450124]
2023-05-14 18:08:52.560: epoch 108:	0.02661650  	0.19572747  	0.10797509  
2023-05-14 18:08:59.183: [iter 109 : loss : 0.1232 = 0.0330 + 0.0845 + 0.0057, time: 6.621732]
2023-05-14 18:08:59.340: epoch 109:	0.02672235  	0.19648974  	0.10847150  
2023-05-14 18:08:59.341: Find a better model.
2023-05-14 18:09:05.770: [iter 110 : loss : 0.1229 = 0.0327 + 0.0845 + 0.0057, time: 6.428164]
2023-05-14 18:09:05.923: epoch 110:	0.02673646  	0.19678721  	0.10845499  
2023-05-14 18:09:05.923: Find a better model.
2023-05-14 18:09:12.378: [iter 111 : loss : 0.1229 = 0.0327 + 0.0844 + 0.0057, time: 6.454767]
2023-05-14 18:09:12.533: epoch 111:	0.02672235  	0.19643457  	0.10858546  
2023-05-14 18:09:18.978: [iter 112 : loss : 0.1224 = 0.0322 + 0.0844 + 0.0058, time: 6.443330]
2023-05-14 18:09:19.133: epoch 112:	0.02675763  	0.19682826  	0.10869891  
2023-05-14 18:09:19.133: Find a better model.
2023-05-14 18:09:25.560: [iter 113 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.425593]
2023-05-14 18:09:25.716: epoch 113:	0.02675057  	0.19665307  	0.10863304  
2023-05-14 18:09:32.156: [iter 114 : loss : 0.1216 = 0.0315 + 0.0843 + 0.0058, time: 6.439128]
2023-05-14 18:09:32.309: epoch 114:	0.02677175  	0.19652393  	0.10856932  
2023-05-14 18:09:38.768: [iter 115 : loss : 0.1212 = 0.0311 + 0.0842 + 0.0059, time: 6.457931]
2023-05-14 18:09:38.921: epoch 115:	0.02673646  	0.19648486  	0.10866428  
2023-05-14 18:09:45.366: [iter 116 : loss : 0.1204 = 0.0304 + 0.0842 + 0.0059, time: 6.443481]
2023-05-14 18:09:45.520: epoch 116:	0.02668707  	0.19617917  	0.10857311  
2023-05-14 18:09:51.784: [iter 117 : loss : 0.1205 = 0.0305 + 0.0841 + 0.0059, time: 6.263414]
2023-05-14 18:09:51.936: epoch 117:	0.02671530  	0.19614923  	0.10859087  
2023-05-14 18:09:58.369: [iter 118 : loss : 0.1201 = 0.0301 + 0.0840 + 0.0059, time: 6.431512]
2023-05-14 18:09:58.521: epoch 118:	0.02682820  	0.19668099  	0.10872968  
2023-05-14 18:10:04.791: [iter 119 : loss : 0.1190 = 0.0291 + 0.0840 + 0.0060, time: 6.268016]
2023-05-14 18:10:04.944: epoch 119:	0.02681408  	0.19651976  	0.10896426  
2023-05-14 18:10:11.359: [iter 120 : loss : 0.1196 = 0.0296 + 0.0840 + 0.0060, time: 6.414416]
2023-05-14 18:10:11.513: epoch 120:	0.02679997  	0.19628105  	0.10881110  
2023-05-14 18:10:17.955: [iter 121 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 6.440826]
2023-05-14 18:10:18.112: epoch 121:	0.02676469  	0.19631661  	0.10883176  
2023-05-14 18:10:24.545: [iter 122 : loss : 0.1188 = 0.0288 + 0.0838 + 0.0061, time: 6.432051]
2023-05-14 18:10:24.702: epoch 122:	0.02672940  	0.19608709  	0.10880962  
2023-05-14 18:10:31.145: [iter 123 : loss : 0.1186 = 0.0287 + 0.0838 + 0.0061, time: 6.442791]
2023-05-14 18:10:31.298: epoch 123:	0.02674352  	0.19576681  	0.10872624  
2023-05-14 18:10:37.749: [iter 124 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 6.450244]
2023-05-14 18:10:37.903: epoch 124:	0.02675764  	0.19564030  	0.10884789  
2023-05-14 18:10:44.340: [iter 125 : loss : 0.1170 = 0.0272 + 0.0837 + 0.0062, time: 6.436064]
2023-05-14 18:10:44.493: epoch 125:	0.02672941  	0.19554055  	0.10891956  
2023-05-14 18:10:50.752: [iter 126 : loss : 0.1173 = 0.0275 + 0.0837 + 0.0062, time: 6.257900]
2023-05-14 18:10:50.907: epoch 126:	0.02679292  	0.19603628  	0.10910195  
2023-05-14 18:10:57.347: [iter 127 : loss : 0.1164 = 0.0265 + 0.0836 + 0.0062, time: 6.439437]
2023-05-14 18:10:57.500: epoch 127:	0.02682820  	0.19607319  	0.10915742  
2023-05-14 18:11:03.748: [iter 128 : loss : 0.1174 = 0.0275 + 0.0836 + 0.0063, time: 6.245692]
2023-05-14 18:11:03.904: epoch 128:	0.02684937  	0.19633803  	0.10922626  
2023-05-14 18:11:10.321: [iter 129 : loss : 0.1165 = 0.0267 + 0.0835 + 0.0063, time: 6.416574]
2023-05-14 18:11:10.475: epoch 129:	0.02685642  	0.19615865  	0.10909431  
2023-05-14 18:11:16.930: [iter 130 : loss : 0.1165 = 0.0268 + 0.0835 + 0.0063, time: 6.453506]
2023-05-14 18:11:17.084: epoch 130:	0.02689876  	0.19665714  	0.10930374  
2023-05-14 18:11:23.545: [iter 131 : loss : 0.1157 = 0.0259 + 0.0835 + 0.0063, time: 6.459105]
2023-05-14 18:11:23.698: epoch 131:	0.02687759  	0.19661297  	0.10932043  
2023-05-14 18:11:29.941: [iter 132 : loss : 0.1158 = 0.0260 + 0.0834 + 0.0064, time: 6.241768]
2023-05-14 18:11:30.095: epoch 132:	0.02696932  	0.19688322  	0.10945845  
2023-05-14 18:11:30.095: Find a better model.
2023-05-14 18:11:36.546: [iter 133 : loss : 0.1146 = 0.0249 + 0.0834 + 0.0064, time: 6.449604]
2023-05-14 18:11:36.700: epoch 133:	0.02691993  	0.19663092  	0.10955236  
2023-05-14 18:11:43.123: [iter 134 : loss : 0.1154 = 0.0256 + 0.0833 + 0.0064, time: 6.422828]
2023-05-14 18:11:43.282: epoch 134:	0.02695521  	0.19712564  	0.10952108  
2023-05-14 18:11:43.282: Find a better model.
2023-05-14 18:11:49.717: [iter 135 : loss : 0.1152 = 0.0254 + 0.0833 + 0.0065, time: 6.433907]
2023-05-14 18:11:49.873: epoch 135:	0.02693404  	0.19705595  	0.10952429  
2023-05-14 18:11:56.308: [iter 136 : loss : 0.1145 = 0.0248 + 0.0832 + 0.0065, time: 6.432889]
2023-05-14 18:11:56.463: epoch 136:	0.02687759  	0.19640137  	0.10922466  
2023-05-14 18:12:02.921: [iter 137 : loss : 0.1143 = 0.0246 + 0.0832 + 0.0065, time: 6.455853]
2023-05-14 18:12:03.075: epoch 137:	0.02691288  	0.19655249  	0.10934570  
2023-05-14 18:12:09.504: [iter 138 : loss : 0.1140 = 0.0243 + 0.0832 + 0.0065, time: 6.425781]
2023-05-14 18:12:09.657: epoch 138:	0.02694111  	0.19706136  	0.10964581  
2023-05-14 18:12:16.102: [iter 139 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.443570]
2023-05-14 18:12:16.254: epoch 139:	0.02691288  	0.19648333  	0.10951219  
2023-05-14 18:12:22.712: [iter 140 : loss : 0.1134 = 0.0237 + 0.0831 + 0.0066, time: 6.456253]
2023-05-14 18:12:22.865: epoch 140:	0.02689876  	0.19660287  	0.10944480  
2023-05-14 18:12:29.119: [iter 141 : loss : 0.1138 = 0.0241 + 0.0830 + 0.0066, time: 6.252908]
2023-05-14 18:12:29.275: epoch 141:	0.02690582  	0.19673224  	0.10975362  
2023-05-14 18:12:35.718: [iter 142 : loss : 0.1129 = 0.0232 + 0.0830 + 0.0067, time: 6.441898]
2023-05-14 18:12:35.873: epoch 142:	0.02699050  	0.19755544  	0.10986225  
2023-05-14 18:12:35.873: Find a better model.
2023-05-14 18:12:42.303: [iter 143 : loss : 0.1128 = 0.0232 + 0.0830 + 0.0067, time: 6.428044]
2023-05-14 18:12:42.457: epoch 143:	0.02693404  	0.19763103  	0.10992883  
2023-05-14 18:12:42.457: Find a better model.
2023-05-14 18:12:48.891: [iter 144 : loss : 0.1123 = 0.0226 + 0.0830 + 0.0067, time: 6.433537]
2023-05-14 18:12:49.045: epoch 144:	0.02692699  	0.19760872  	0.10997321  
2023-05-14 18:12:55.321: [iter 145 : loss : 0.1124 = 0.0227 + 0.0829 + 0.0067, time: 6.274775]
2023-05-14 18:12:55.476: epoch 145:	0.02691288  	0.19733375  	0.10992619  
2023-05-14 18:13:01.887: [iter 146 : loss : 0.1124 = 0.0228 + 0.0829 + 0.0068, time: 6.410695]
2023-05-14 18:13:02.045: epoch 146:	0.02686348  	0.19694827  	0.10999913  
2023-05-14 18:13:08.317: [iter 147 : loss : 0.1123 = 0.0226 + 0.0828 + 0.0068, time: 6.270877]
2023-05-14 18:13:08.473: epoch 147:	0.02694816  	0.19754361  	0.11002915  
2023-05-14 18:13:14.883: [iter 148 : loss : 0.1111 = 0.0215 + 0.0828 + 0.0068, time: 6.409544]
2023-05-14 18:13:15.041: epoch 148:	0.02689171  	0.19719031  	0.10995617  
2023-05-14 18:13:21.308: [iter 149 : loss : 0.1115 = 0.0218 + 0.0828 + 0.0068, time: 6.266131]
2023-05-14 18:13:21.466: epoch 149:	0.02699755  	0.19781169  	0.11012954  
2023-05-14 18:13:21.466: Find a better model.
2023-05-14 18:13:27.887: [iter 150 : loss : 0.1110 = 0.0213 + 0.0828 + 0.0069, time: 6.419879]
2023-05-14 18:13:28.043: epoch 150:	0.02699755  	0.19799146  	0.11012822  
2023-05-14 18:13:28.043: Find a better model.
2023-05-14 18:13:34.486: [iter 151 : loss : 0.1113 = 0.0217 + 0.0827 + 0.0069, time: 6.442393]
2023-05-14 18:13:34.638: epoch 151:	0.02701167  	0.19843636  	0.11025907  
2023-05-14 18:13:34.638: Find a better model.
2023-05-14 18:13:40.904: [iter 152 : loss : 0.1106 = 0.0209 + 0.0827 + 0.0069, time: 6.263900]
2023-05-14 18:13:41.061: epoch 152:	0.02701166  	0.19833843  	0.11031832  
2023-05-14 18:13:47.486: [iter 153 : loss : 0.1097 = 0.0201 + 0.0827 + 0.0070, time: 6.423162]
2023-05-14 18:13:47.643: epoch 153:	0.02703283  	0.19871639  	0.11041806  
2023-05-14 18:13:47.643: Find a better model.
2023-05-14 18:13:54.082: [iter 154 : loss : 0.1101 = 0.0205 + 0.0826 + 0.0070, time: 6.438383]
2023-05-14 18:13:54.236: epoch 154:	0.02701166  	0.19825344  	0.11027044  
2023-05-14 18:14:00.494: [iter 155 : loss : 0.1107 = 0.0211 + 0.0826 + 0.0070, time: 6.255679]
2023-05-14 18:14:00.647: epoch 155:	0.02699049  	0.19832708  	0.11018904  
2023-05-14 18:14:07.097: [iter 156 : loss : 0.1100 = 0.0204 + 0.0826 + 0.0070, time: 6.448498]
2023-05-14 18:14:07.254: epoch 156:	0.02700460  	0.19855730  	0.11029682  
2023-05-14 18:14:13.493: [iter 157 : loss : 0.1100 = 0.0204 + 0.0825 + 0.0071, time: 6.237901]
2023-05-14 18:14:13.650: epoch 157:	0.02700461  	0.19868597  	0.11037542  
2023-05-14 18:14:20.059: [iter 158 : loss : 0.1093 = 0.0197 + 0.0825 + 0.0071, time: 6.407951]
2023-05-14 18:14:20.215: epoch 158:	0.02704695  	0.19924575  	0.11050643  
2023-05-14 18:14:20.215: Find a better model.
2023-05-14 18:14:26.482: [iter 159 : loss : 0.1096 = 0.0200 + 0.0825 + 0.0071, time: 6.264410]
2023-05-14 18:14:26.634: epoch 159:	0.02702578  	0.19904181  	0.11046917  
2023-05-14 18:14:33.078: [iter 160 : loss : 0.1093 = 0.0196 + 0.0825 + 0.0071, time: 6.442326]
2023-05-14 18:14:33.230: epoch 160:	0.02708929  	0.19905399  	0.11055340  
2023-05-14 18:14:39.669: [iter 161 : loss : 0.1088 = 0.0192 + 0.0824 + 0.0072, time: 6.438043]
2023-05-14 18:14:39.823: epoch 161:	0.02701167  	0.19885194  	0.11042456  
2023-05-14 18:14:46.267: [iter 162 : loss : 0.1082 = 0.0186 + 0.0824 + 0.0072, time: 6.443672]
2023-05-14 18:14:46.421: epoch 162:	0.02709635  	0.19944839  	0.11070982  
2023-05-14 18:14:46.421: Find a better model.
2023-05-14 18:14:52.852: [iter 163 : loss : 0.1086 = 0.0190 + 0.0824 + 0.0072, time: 6.429655]
2023-05-14 18:14:53.006: epoch 163:	0.02711046  	0.19966237  	0.11070375  
2023-05-14 18:14:53.006: Find a better model.
2023-05-14 18:14:59.274: [iter 164 : loss : 0.1085 = 0.0189 + 0.0824 + 0.0072, time: 6.266665]
2023-05-14 18:14:59.427: epoch 164:	0.02705401  	0.19897276  	0.11058372  
2023-05-14 18:15:05.663: [iter 165 : loss : 0.1081 = 0.0186 + 0.0823 + 0.0073, time: 6.234227]
2023-05-14 18:15:05.819: epoch 165:	0.02707518  	0.19936737  	0.11049724  
2023-05-14 18:15:12.074: [iter 166 : loss : 0.1079 = 0.0183 + 0.0823 + 0.0073, time: 6.254736]
2023-05-14 18:15:12.215: epoch 166:	0.02702578  	0.19885665  	0.11051950  
2023-05-14 18:15:18.475: [iter 167 : loss : 0.1083 = 0.0188 + 0.0823 + 0.0073, time: 6.257943]
2023-05-14 18:15:18.629: epoch 167:	0.02703989  	0.19894832  	0.11040048  
2023-05-14 18:15:24.867: [iter 168 : loss : 0.1077 = 0.0181 + 0.0823 + 0.0073, time: 6.235707]
2023-05-14 18:15:25.024: epoch 168:	0.02696227  	0.19843586  	0.11030062  
2023-05-14 18:15:31.262: [iter 169 : loss : 0.1080 = 0.0184 + 0.0823 + 0.0073, time: 6.236483]
2023-05-14 18:15:31.418: epoch 169:	0.02690582  	0.19805469  	0.11023441  
2023-05-14 18:15:37.663: [iter 170 : loss : 0.1074 = 0.0178 + 0.0822 + 0.0074, time: 6.243442]
2023-05-14 18:15:37.815: epoch 170:	0.02692699  	0.19836323  	0.11035726  
2023-05-14 18:15:44.235: [iter 171 : loss : 0.1078 = 0.0182 + 0.0822 + 0.0074, time: 6.418340]
2023-05-14 18:15:44.388: epoch 171:	0.02691288  	0.19842957  	0.11039851  
2023-05-14 18:15:50.839: [iter 172 : loss : 0.1071 = 0.0175 + 0.0821 + 0.0074, time: 6.448102]
2023-05-14 18:15:50.992: epoch 172:	0.02700461  	0.19865501  	0.11044527  
2023-05-14 18:15:57.264: [iter 173 : loss : 0.1076 = 0.0180 + 0.0821 + 0.0074, time: 6.270135]
2023-05-14 18:15:57.420: epoch 173:	0.02696227  	0.19831198  	0.11033357  
2023-05-14 18:16:03.653: [iter 174 : loss : 0.1071 = 0.0175 + 0.0821 + 0.0075, time: 6.232354]
2023-05-14 18:16:03.808: epoch 174:	0.02697638  	0.19836296  	0.11050306  
2023-05-14 18:16:10.238: [iter 175 : loss : 0.1065 = 0.0169 + 0.0821 + 0.0075, time: 6.427920]
2023-05-14 18:16:10.392: epoch 175:	0.02691993  	0.19818656  	0.11027277  
2023-05-14 18:16:16.645: [iter 176 : loss : 0.1064 = 0.0168 + 0.0821 + 0.0075, time: 6.252381]
2023-05-14 18:16:16.800: epoch 176:	0.02689171  	0.19798443  	0.11007796  
2023-05-14 18:16:23.242: [iter 177 : loss : 0.1067 = 0.0171 + 0.0821 + 0.0075, time: 6.439542]
2023-05-14 18:16:23.397: epoch 177:	0.02684232  	0.19740908  	0.10985251  
2023-05-14 18:16:29.651: [iter 178 : loss : 0.1062 = 0.0167 + 0.0820 + 0.0075, time: 6.253267]
2023-05-14 18:16:29.805: epoch 178:	0.02688466  	0.19797744  	0.11010942  
2023-05-14 18:16:36.227: [iter 179 : loss : 0.1063 = 0.0167 + 0.0820 + 0.0076, time: 6.418709]
2023-05-14 18:16:36.381: epoch 179:	0.02696933  	0.19850259  	0.11029135  
2023-05-14 18:16:42.634: [iter 180 : loss : 0.1062 = 0.0167 + 0.0820 + 0.0076, time: 6.250013]
2023-05-14 18:16:42.787: epoch 180:	0.02701873  	0.19884740  	0.11027512  
2023-05-14 18:16:49.225: [iter 181 : loss : 0.1063 = 0.0167 + 0.0820 + 0.0076, time: 6.436605]
2023-05-14 18:16:49.378: epoch 181:	0.02699050  	0.19812112  	0.11005369  
2023-05-14 18:16:55.640: [iter 182 : loss : 0.1059 = 0.0164 + 0.0819 + 0.0076, time: 6.260704]
2023-05-14 18:16:55.795: epoch 182:	0.02696933  	0.19785987  	0.11016919  
2023-05-14 18:17:02.210: [iter 183 : loss : 0.1060 = 0.0164 + 0.0819 + 0.0077, time: 6.414400]
2023-05-14 18:17:02.364: epoch 183:	0.02701168  	0.19822906  	0.11029249  
2023-05-14 18:17:08.624: [iter 184 : loss : 0.1057 = 0.0161 + 0.0819 + 0.0077, time: 6.258956]
2023-05-14 18:17:08.778: epoch 184:	0.02699757  	0.19815166  	0.11019404  
2023-05-14 18:17:15.028: [iter 185 : loss : 0.1053 = 0.0157 + 0.0819 + 0.0077, time: 6.247710]
2023-05-14 18:17:15.184: epoch 185:	0.02696934  	0.19799747  	0.11005459  
2023-05-14 18:17:21.433: [iter 186 : loss : 0.1054 = 0.0158 + 0.0819 + 0.0077, time: 6.248096]
2023-05-14 18:17:21.590: epoch 186:	0.02699756  	0.19821389  	0.11012607  
2023-05-14 18:17:27.824: [iter 187 : loss : 0.1055 = 0.0160 + 0.0818 + 0.0077, time: 6.233150]
2023-05-14 18:17:27.977: epoch 187:	0.02700462  	0.19834451  	0.11014386  
2023-05-14 18:17:34.395: [iter 188 : loss : 0.1049 = 0.0153 + 0.0818 + 0.0078, time: 6.417387]
2023-05-14 18:17:34.537: epoch 188:	0.02699051  	0.19846371  	0.11028203  
2023-05-14 18:17:34.537: Early stopping is trigger at epoch: 188
2023-05-14 18:17:34.537: best_result@epoch 163:

2023-05-14 18:17:34.537: 		0.0271      	0.1997      	0.1107      
2023-05-15 09:14:26.237: my pid: 12688
2023-05-15 09:14:26.237: model: model.general_recommender.SGL
2023-05-15 09:14:26.237: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 09:14:26.237: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 09:14:29.320: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 09:14:36.698: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.378747]
2023-05-15 09:14:36.855: epoch 1:	0.00213802  	0.01477929  	0.00751341  
2023-05-15 09:14:36.855: Find a better model.
2023-05-15 09:14:44.398: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.540521]
2023-05-15 09:14:44.604: epoch 2:	0.00414901  	0.02843760  	0.01447369  
2023-05-15 09:14:44.604: Find a better model.
2023-05-15 09:14:52.020: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.414232]
2023-05-15 09:14:52.191: epoch 3:	0.00678798  	0.04679074  	0.02342998  
2023-05-15 09:14:52.192: Find a better model.
2023-05-15 09:14:59.426: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.233087]
2023-05-15 09:14:59.589: epoch 4:	0.01002678  	0.07174171  	0.03453141  
2023-05-15 09:14:59.589: Find a better model.
2023-05-15 09:15:06.809: [iter 5 : loss : 0.7685 = 0.6899 + 0.0785 + 0.0000, time: 7.219027]
2023-05-15 09:15:06.965: epoch 5:	0.01320925  	0.09511336  	0.04582155  
2023-05-15 09:15:06.965: Find a better model.
2023-05-15 09:15:13.807: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.841634]
2023-05-15 09:15:13.962: epoch 6:	0.01619411  	0.11620260  	0.05791716  
2023-05-15 09:15:13.962: Find a better model.
2023-05-15 09:15:20.615: [iter 7 : loss : 0.7541 = 0.6740 + 0.0801 + 0.0000, time: 6.651623]
2023-05-15 09:15:20.766: epoch 7:	0.01819107  	0.13157348  	0.06642682  
2023-05-15 09:15:20.766: Find a better model.
2023-05-15 09:15:27.578: [iter 8 : loss : 0.7299 = 0.6471 + 0.0827 + 0.0001, time: 6.810189]
2023-05-15 09:15:27.732: epoch 8:	0.01915076  	0.13995357  	0.06977665  
2023-05-15 09:15:27.732: Find a better model.
2023-05-15 09:15:34.407: [iter 9 : loss : 0.6819 = 0.5945 + 0.0873 + 0.0002, time: 6.673545]
2023-05-15 09:15:34.562: epoch 9:	0.01890378  	0.13954249  	0.06942453  
2023-05-15 09:15:41.178: [iter 10 : loss : 0.6116 = 0.5187 + 0.0926 + 0.0003, time: 6.615481]
2023-05-15 09:15:41.320: epoch 10:	0.01872031  	0.13818780  	0.06914438  
2023-05-15 09:15:47.800: [iter 11 : loss : 0.5373 = 0.4400 + 0.0969 + 0.0005, time: 6.477533]
2023-05-15 09:15:47.954: epoch 11:	0.01868503  	0.13804288  	0.06906526  
2023-05-15 09:15:54.397: [iter 12 : loss : 0.4762 = 0.3762 + 0.0994 + 0.0006, time: 6.441849]
2023-05-15 09:15:54.551: epoch 12:	0.01865680  	0.13779783  	0.06928346  
2023-05-15 09:16:00.982: [iter 13 : loss : 0.4326 = 0.3311 + 0.1008 + 0.0008, time: 6.429591]
2023-05-15 09:16:01.134: epoch 13:	0.01875559  	0.13850762  	0.06965893  
2023-05-15 09:16:07.575: [iter 14 : loss : 0.3994 = 0.2971 + 0.1014 + 0.0009, time: 6.438712]
2023-05-15 09:16:07.729: epoch 14:	0.01895318  	0.13992290  	0.07042021  
2023-05-15 09:16:14.344: [iter 15 : loss : 0.3761 = 0.2734 + 0.1016 + 0.0010, time: 6.614507]
2023-05-15 09:16:14.490: epoch 15:	0.01911548  	0.14099921  	0.07127465  
2023-05-15 09:16:14.490: Find a better model.
2023-05-15 09:16:20.979: [iter 16 : loss : 0.3559 = 0.2532 + 0.1015 + 0.0012, time: 6.487667]
2023-05-15 09:16:21.133: epoch 16:	0.01929189  	0.14215401  	0.07194357  
2023-05-15 09:16:21.133: Find a better model.
2023-05-15 09:16:27.757: [iter 17 : loss : 0.3409 = 0.2384 + 0.1013 + 0.0013, time: 6.622028]
2023-05-15 09:16:27.912: epoch 17:	0.01955298  	0.14417562  	0.07310092  
2023-05-15 09:16:27.913: Find a better model.
2023-05-15 09:16:34.396: [iter 18 : loss : 0.3266 = 0.2243 + 0.1009 + 0.0014, time: 6.481726]
2023-05-15 09:16:34.554: epoch 18:	0.01975762  	0.14568052  	0.07400516  
2023-05-15 09:16:34.554: Find a better model.
2023-05-15 09:16:40.979: [iter 19 : loss : 0.3132 = 0.2111 + 0.1006 + 0.0014, time: 6.424478]
2023-05-15 09:16:41.134: epoch 19:	0.01997638  	0.14668037  	0.07471737  
2023-05-15 09:16:41.134: Find a better model.
2023-05-15 09:16:47.579: [iter 20 : loss : 0.3040 = 0.2022 + 0.1002 + 0.0015, time: 6.443749]
2023-05-15 09:16:47.735: epoch 20:	0.02013162  	0.14763016  	0.07550710  
2023-05-15 09:16:47.735: Find a better model.
2023-05-15 09:16:54.362: [iter 21 : loss : 0.2948 = 0.1934 + 0.0998 + 0.0016, time: 6.625450]
2023-05-15 09:16:54.518: epoch 21:	0.02032920  	0.14917265  	0.07642853  
2023-05-15 09:16:54.518: Find a better model.
2023-05-15 09:17:00.973: [iter 22 : loss : 0.2868 = 0.1858 + 0.0994 + 0.0017, time: 6.453878]
2023-05-15 09:17:01.130: epoch 22:	0.02049151  	0.15030929  	0.07697164  
2023-05-15 09:17:01.130: Find a better model.
2023-05-15 09:17:07.759: [iter 23 : loss : 0.2787 = 0.1780 + 0.0990 + 0.0018, time: 6.627341]
2023-05-15 09:17:07.914: epoch 23:	0.02067497  	0.15155584  	0.07765375  
2023-05-15 09:17:07.914: Find a better model.
2023-05-15 09:17:14.386: [iter 24 : loss : 0.2725 = 0.1722 + 0.0985 + 0.0019, time: 6.470325]
2023-05-15 09:17:14.543: epoch 24:	0.02089373  	0.15325467  	0.07860562  
2023-05-15 09:17:14.543: Find a better model.
2023-05-15 09:17:21.145: [iter 25 : loss : 0.2661 = 0.1661 + 0.0981 + 0.0019, time: 6.600420]
2023-05-15 09:17:21.299: epoch 25:	0.02100663  	0.15431063  	0.07917792  
2023-05-15 09:17:21.299: Find a better model.
2023-05-15 09:17:27.929: [iter 26 : loss : 0.2624 = 0.1628 + 0.0977 + 0.0020, time: 6.628052]
2023-05-15 09:17:28.086: epoch 26:	0.02129595  	0.15623082  	0.08011766  
2023-05-15 09:17:28.086: Find a better model.
2023-05-15 09:17:34.727: [iter 27 : loss : 0.2547 = 0.1555 + 0.0972 + 0.0021, time: 6.639677]
2023-05-15 09:17:34.882: epoch 27:	0.02134535  	0.15713885  	0.08061413  
2023-05-15 09:17:34.882: Find a better model.
2023-05-15 09:17:41.521: [iter 28 : loss : 0.2500 = 0.1510 + 0.0969 + 0.0021, time: 6.637639]
2023-05-15 09:17:41.676: epoch 28:	0.02144414  	0.15780792  	0.08133575  
2023-05-15 09:17:41.676: Find a better model.
2023-05-15 09:17:48.142: [iter 29 : loss : 0.2457 = 0.1471 + 0.0964 + 0.0022, time: 6.464635]
2023-05-15 09:17:48.285: epoch 29:	0.02173345  	0.15972768  	0.08225867  
2023-05-15 09:17:48.285: Find a better model.
2023-05-15 09:17:54.939: [iter 30 : loss : 0.2394 = 0.1410 + 0.0961 + 0.0022, time: 6.652114]
2023-05-15 09:17:55.096: epoch 30:	0.02182518  	0.16018958  	0.08273157  
2023-05-15 09:17:55.096: Find a better model.
2023-05-15 09:18:01.749: [iter 31 : loss : 0.2356 = 0.1376 + 0.0957 + 0.0023, time: 6.651526]
2023-05-15 09:18:01.905: epoch 31:	0.02195925  	0.16116416  	0.08326580  
2023-05-15 09:18:01.905: Find a better model.
2023-05-15 09:18:08.512: [iter 32 : loss : 0.2302 = 0.1325 + 0.0953 + 0.0024, time: 6.606179]
2023-05-15 09:18:08.668: epoch 32:	0.02204393  	0.16197781  	0.08389077  
2023-05-15 09:18:08.668: Find a better model.
2023-05-15 09:18:15.132: [iter 33 : loss : 0.2276 = 0.1302 + 0.0950 + 0.0024, time: 6.462977]
2023-05-15 09:18:15.286: epoch 33:	0.02224151  	0.16413377  	0.08476309  
2023-05-15 09:18:15.286: Find a better model.
2023-05-15 09:18:21.744: [iter 34 : loss : 0.2236 = 0.1265 + 0.0946 + 0.0025, time: 6.457497]
2023-05-15 09:18:21.902: epoch 34:	0.02221329  	0.16430837  	0.08540512  
2023-05-15 09:18:21.902: Find a better model.
2023-05-15 09:18:28.523: [iter 35 : loss : 0.2203 = 0.1233 + 0.0944 + 0.0025, time: 6.619468]
2023-05-15 09:18:28.666: epoch 35:	0.02231914  	0.16506235  	0.08602150  
2023-05-15 09:18:28.666: Find a better model.
2023-05-15 09:18:35.138: [iter 36 : loss : 0.2168 = 0.1202 + 0.0940 + 0.0026, time: 6.469838]
2023-05-15 09:18:35.294: epoch 36:	0.02251672  	0.16628627  	0.08668465  
2023-05-15 09:18:35.294: Find a better model.
2023-05-15 09:18:41.938: [iter 37 : loss : 0.2131 = 0.1167 + 0.0937 + 0.0027, time: 6.642034]
2023-05-15 09:18:42.096: epoch 37:	0.02271430  	0.16766262  	0.08730310  
2023-05-15 09:18:42.096: Find a better model.
2023-05-15 09:18:48.719: [iter 38 : loss : 0.2116 = 0.1155 + 0.0934 + 0.0027, time: 6.622129]
2023-05-15 09:18:48.874: epoch 38:	0.02291188  	0.16891441  	0.08789083  
2023-05-15 09:18:48.875: Find a better model.
2023-05-15 09:18:55.509: [iter 39 : loss : 0.2072 = 0.1113 + 0.0931 + 0.0028, time: 6.633429]
2023-05-15 09:18:55.670: epoch 39:	0.02312358  	0.17008488  	0.08888812  
2023-05-15 09:18:55.670: Find a better model.
2023-05-15 09:19:02.309: [iter 40 : loss : 0.2040 = 0.1083 + 0.0928 + 0.0028, time: 6.638099]
2023-05-15 09:19:02.467: epoch 40:	0.02317298  	0.17052540  	0.08923177  
2023-05-15 09:19:02.467: Find a better model.
2023-05-15 09:19:08.913: [iter 41 : loss : 0.2023 = 0.1069 + 0.0925 + 0.0029, time: 6.444763]
2023-05-15 09:19:09.056: epoch 41:	0.02327883  	0.17135188  	0.08999881  
2023-05-15 09:19:09.056: Find a better model.
2023-05-15 09:19:15.719: [iter 42 : loss : 0.2000 = 0.1048 + 0.0923 + 0.0029, time: 6.662024]
2023-05-15 09:19:15.874: epoch 42:	0.02344818  	0.17259084  	0.09065889  
2023-05-15 09:19:15.874: Find a better model.
2023-05-15 09:19:22.505: [iter 43 : loss : 0.1962 = 0.1012 + 0.0920 + 0.0030, time: 6.629340]
2023-05-15 09:19:22.663: epoch 43:	0.02349758  	0.17272285  	0.09098648  
2023-05-15 09:19:22.664: Find a better model.
2023-05-15 09:19:29.130: [iter 44 : loss : 0.1929 = 0.0982 + 0.0917 + 0.0030, time: 6.465622]
2023-05-15 09:19:29.283: epoch 44:	0.02361047  	0.17344093  	0.09188014  
2023-05-15 09:19:29.284: Find a better model.
2023-05-15 09:19:35.898: [iter 45 : loss : 0.1907 = 0.0962 + 0.0915 + 0.0031, time: 6.611948]
2023-05-15 09:19:36.053: epoch 45:	0.02364576  	0.17371835  	0.09232400  
2023-05-15 09:19:36.053: Find a better model.
2023-05-15 09:19:42.506: [iter 46 : loss : 0.1885 = 0.0941 + 0.0913 + 0.0031, time: 6.451395]
2023-05-15 09:19:42.663: epoch 46:	0.02376572  	0.17465457  	0.09293980  
2023-05-15 09:19:42.663: Find a better model.
2023-05-15 09:19:49.273: [iter 47 : loss : 0.1878 = 0.0936 + 0.0910 + 0.0032, time: 6.608337]
2023-05-15 09:19:49.425: epoch 47:	0.02395624  	0.17600694  	0.09349908  
2023-05-15 09:19:49.425: Find a better model.
2023-05-15 09:19:55.896: [iter 48 : loss : 0.1838 = 0.0897 + 0.0908 + 0.0032, time: 6.470501]
2023-05-15 09:19:56.049: epoch 48:	0.02409737  	0.17713228  	0.09392737  
2023-05-15 09:19:56.049: Find a better model.
2023-05-15 09:20:02.499: [iter 49 : loss : 0.1809 = 0.0870 + 0.0906 + 0.0033, time: 6.447938]
2023-05-15 09:20:02.643: epoch 49:	0.02411148  	0.17697845  	0.09414592  
2023-05-15 09:20:09.099: [iter 50 : loss : 0.1797 = 0.0860 + 0.0904 + 0.0033, time: 6.454955]
2023-05-15 09:20:09.253: epoch 50:	0.02423144  	0.17782347  	0.09477001  
2023-05-15 09:20:09.253: Find a better model.
2023-05-15 09:20:15.864: [iter 51 : loss : 0.1770 = 0.0834 + 0.0902 + 0.0034, time: 6.610587]
2023-05-15 09:20:16.020: epoch 51:	0.02422438  	0.17747556  	0.09509394  
2023-05-15 09:20:22.667: [iter 52 : loss : 0.1770 = 0.0836 + 0.0900 + 0.0034, time: 6.646497]
2023-05-15 09:20:22.820: epoch 52:	0.02434434  	0.17852879  	0.09545468  
2023-05-15 09:20:22.820: Find a better model.
2023-05-15 09:20:29.495: [iter 53 : loss : 0.1748 = 0.0816 + 0.0898 + 0.0035, time: 6.672802]
2023-05-15 09:20:29.651: epoch 53:	0.02447136  	0.17942192  	0.09598241  
2023-05-15 09:20:29.651: Find a better model.
2023-05-15 09:20:36.256: [iter 54 : loss : 0.1729 = 0.0798 + 0.0896 + 0.0035, time: 6.602133]
2023-05-15 09:20:36.410: epoch 54:	0.02445019  	0.17926015  	0.09610279  
2023-05-15 09:20:42.892: [iter 55 : loss : 0.1711 = 0.0781 + 0.0894 + 0.0036, time: 6.480199]
2023-05-15 09:20:43.044: epoch 55:	0.02444313  	0.17923063  	0.09614479  
2023-05-15 09:20:49.663: [iter 56 : loss : 0.1694 = 0.0765 + 0.0892 + 0.0036, time: 6.617684]
2023-05-15 09:20:49.816: epoch 56:	0.02457720  	0.18037662  	0.09672290  
2023-05-15 09:20:49.816: Find a better model.
2023-05-15 09:20:56.476: [iter 57 : loss : 0.1677 = 0.0750 + 0.0891 + 0.0037, time: 6.657629]
2023-05-15 09:20:56.616: epoch 57:	0.02462660  	0.18098442  	0.09711523  
2023-05-15 09:20:56.616: Find a better model.
2023-05-15 09:21:03.092: [iter 58 : loss : 0.1656 = 0.0730 + 0.0889 + 0.0037, time: 6.475863]
2023-05-15 09:21:03.248: epoch 58:	0.02472538  	0.18180129  	0.09765146  
2023-05-15 09:21:03.248: Find a better model.
2023-05-15 09:21:09.879: [iter 59 : loss : 0.1646 = 0.0721 + 0.0887 + 0.0037, time: 6.629420]
2023-05-15 09:21:10.032: epoch 59:	0.02480301  	0.18222070  	0.09795157  
2023-05-15 09:21:10.032: Find a better model.
2023-05-15 09:21:16.664: [iter 60 : loss : 0.1631 = 0.0708 + 0.0885 + 0.0038, time: 6.630691]
2023-05-15 09:21:16.807: epoch 60:	0.02488063  	0.18275078  	0.09838145  
2023-05-15 09:21:16.807: Find a better model.
2023-05-15 09:21:23.454: [iter 61 : loss : 0.1619 = 0.0697 + 0.0884 + 0.0038, time: 6.644471]
2023-05-15 09:21:23.594: epoch 61:	0.02495119  	0.18329939  	0.09872219  
2023-05-15 09:21:23.594: Find a better model.
2023-05-15 09:21:30.241: [iter 62 : loss : 0.1604 = 0.0683 + 0.0882 + 0.0039, time: 6.644855]
2023-05-15 09:21:30.394: epoch 62:	0.02495119  	0.18351194  	0.09890150  
2023-05-15 09:21:30.394: Find a better model.
2023-05-15 09:21:37.064: [iter 63 : loss : 0.1590 = 0.0671 + 0.0881 + 0.0039, time: 6.667858]
2023-05-15 09:21:37.218: epoch 63:	0.02497941  	0.18382451  	0.09893787  
2023-05-15 09:21:37.218: Find a better model.
2023-05-15 09:21:43.850: [iter 64 : loss : 0.1581 = 0.0663 + 0.0879 + 0.0040, time: 6.630009]
2023-05-15 09:21:44.001: epoch 64:	0.02507821  	0.18408731  	0.09927612  
2023-05-15 09:21:44.002: Find a better model.
2023-05-15 09:21:50.652: [iter 65 : loss : 0.1567 = 0.0649 + 0.0877 + 0.0040, time: 6.648952]
2023-05-15 09:21:50.814: epoch 65:	0.02507821  	0.18405440  	0.09949867  
2023-05-15 09:21:57.462: [iter 66 : loss : 0.1553 = 0.0636 + 0.0876 + 0.0041, time: 6.644721]
2023-05-15 09:21:57.615: epoch 66:	0.02518405  	0.18489756  	0.09995241  
2023-05-15 09:21:57.615: Find a better model.
2023-05-15 09:22:04.064: [iter 67 : loss : 0.1536 = 0.0620 + 0.0875 + 0.0041, time: 6.447776]
2023-05-15 09:22:04.217: epoch 67:	0.02521932  	0.18474589  	0.10028430  
2023-05-15 09:22:11.033: [iter 68 : loss : 0.1535 = 0.0621 + 0.0873 + 0.0041, time: 6.814367]
2023-05-15 09:22:11.187: epoch 68:	0.02530401  	0.18565923  	0.10066947  
2023-05-15 09:22:11.187: Find a better model.
2023-05-15 09:22:17.856: [iter 69 : loss : 0.1516 = 0.0602 + 0.0872 + 0.0042, time: 6.667842]
2023-05-15 09:22:18.007: epoch 69:	0.02537457  	0.18636821  	0.10111655  
2023-05-15 09:22:18.007: Find a better model.
2023-05-15 09:22:24.674: [iter 70 : loss : 0.1498 = 0.0585 + 0.0871 + 0.0042, time: 6.664365]
2023-05-15 09:22:24.829: epoch 70:	0.02543807  	0.18698089  	0.10144666  
2023-05-15 09:22:24.829: Find a better model.
2023-05-15 09:22:31.625: [iter 71 : loss : 0.1487 = 0.0575 + 0.0870 + 0.0043, time: 6.795225]
2023-05-15 09:22:31.786: epoch 71:	0.02541690  	0.18686104  	0.10157002  
2023-05-15 09:22:38.440: [iter 72 : loss : 0.1482 = 0.0570 + 0.0869 + 0.0043, time: 6.650598]
2023-05-15 09:22:38.592: epoch 72:	0.02545924  	0.18719043  	0.10176779  
2023-05-15 09:22:38.592: Find a better model.
2023-05-15 09:22:45.239: [iter 73 : loss : 0.1470 = 0.0559 + 0.0867 + 0.0044, time: 6.645961]
2023-05-15 09:22:45.393: epoch 73:	0.02555803  	0.18793096  	0.10191273  
2023-05-15 09:22:45.393: Find a better model.
2023-05-15 09:22:52.019: [iter 74 : loss : 0.1456 = 0.0546 + 0.0866 + 0.0044, time: 6.624265]
2023-05-15 09:22:52.159: epoch 74:	0.02561448  	0.18858983  	0.10228420  
2023-05-15 09:22:52.159: Find a better model.
2023-05-15 09:22:58.838: [iter 75 : loss : 0.1451 = 0.0541 + 0.0865 + 0.0044, time: 6.678388]
2023-05-15 09:22:58.993: epoch 75:	0.02563565  	0.18864585  	0.10255826  
2023-05-15 09:22:58.993: Find a better model.
2023-05-15 09:23:05.626: [iter 76 : loss : 0.1440 = 0.0532 + 0.0864 + 0.0045, time: 6.632491]
2023-05-15 09:23:05.781: epoch 76:	0.02572033  	0.18925917  	0.10303668  
2023-05-15 09:23:05.781: Find a better model.
2023-05-15 09:23:12.438: [iter 77 : loss : 0.1432 = 0.0524 + 0.0863 + 0.0045, time: 6.654338]
2023-05-15 09:23:12.591: epoch 77:	0.02579089  	0.19001465  	0.10337164  
2023-05-15 09:23:12.591: Find a better model.
2023-05-15 09:23:19.239: [iter 78 : loss : 0.1422 = 0.0515 + 0.0862 + 0.0046, time: 6.647481]
2023-05-15 09:23:19.394: epoch 78:	0.02579090  	0.19033907  	0.10340130  
2023-05-15 09:23:19.395: Find a better model.
2023-05-15 09:23:26.037: [iter 79 : loss : 0.1411 = 0.0505 + 0.0861 + 0.0046, time: 6.640610]
2023-05-15 09:23:26.188: epoch 79:	0.02579090  	0.18997552  	0.10352913  
2023-05-15 09:23:32.820: [iter 80 : loss : 0.1404 = 0.0498 + 0.0860 + 0.0046, time: 6.630748]
2023-05-15 09:23:32.974: epoch 80:	0.02583324  	0.19069915  	0.10377911  
2023-05-15 09:23:32.974: Find a better model.
2023-05-15 09:23:39.641: [iter 81 : loss : 0.1402 = 0.0496 + 0.0859 + 0.0047, time: 6.665983]
2023-05-15 09:23:39.795: epoch 81:	0.02581914  	0.19048795  	0.10372356  
2023-05-15 09:23:46.419: [iter 82 : loss : 0.1388 = 0.0483 + 0.0858 + 0.0047, time: 6.623084]
2023-05-15 09:23:46.570: epoch 82:	0.02584030  	0.19082935  	0.10415443  
2023-05-15 09:23:46.570: Find a better model.
2023-05-15 09:23:53.225: [iter 83 : loss : 0.1379 = 0.0475 + 0.0857 + 0.0048, time: 6.654262]
2023-05-15 09:23:53.378: epoch 83:	0.02593203  	0.19121578  	0.10438225  
2023-05-15 09:23:53.378: Find a better model.
2023-05-15 09:23:59.998: [iter 84 : loss : 0.1379 = 0.0475 + 0.0856 + 0.0048, time: 6.619525]
2023-05-15 09:24:00.156: epoch 84:	0.02603787  	0.19212766  	0.10479162  
2023-05-15 09:24:00.156: Find a better model.
2023-05-15 09:24:06.785: [iter 85 : loss : 0.1370 = 0.0467 + 0.0855 + 0.0048, time: 6.627662]
2023-05-15 09:24:06.938: epoch 85:	0.02611549  	0.19303998  	0.10493686  
2023-05-15 09:24:06.938: Find a better model.
2023-05-15 09:24:13.411: [iter 86 : loss : 0.1369 = 0.0466 + 0.0854 + 0.0049, time: 6.472260]
2023-05-15 09:24:13.551: epoch 86:	0.02615783  	0.19343354  	0.10526489  
2023-05-15 09:24:13.552: Find a better model.
2023-05-15 09:24:20.008: [iter 87 : loss : 0.1339 = 0.0437 + 0.0853 + 0.0049, time: 6.454787]
2023-05-15 09:24:20.161: epoch 87:	0.02624957  	0.19405164  	0.10563889  
2023-05-15 09:24:20.161: Find a better model.
2023-05-15 09:24:26.609: [iter 88 : loss : 0.1334 = 0.0433 + 0.0852 + 0.0049, time: 6.446488]
2023-05-15 09:24:26.764: epoch 88:	0.02618607  	0.19330238  	0.10535172  
2023-05-15 09:24:33.233: [iter 89 : loss : 0.1331 = 0.0430 + 0.0851 + 0.0050, time: 6.467460]
2023-05-15 09:24:33.387: epoch 89:	0.02610844  	0.19264744  	0.10532983  
2023-05-15 09:24:39.816: [iter 90 : loss : 0.1336 = 0.0435 + 0.0851 + 0.0050, time: 6.426069]
2023-05-15 09:24:39.970: epoch 90:	0.02624251  	0.19324721  	0.10572554  
2023-05-15 09:24:46.571: [iter 91 : loss : 0.1324 = 0.0424 + 0.0849 + 0.0051, time: 6.600192]
2023-05-15 09:24:46.715: epoch 91:	0.02629191  	0.19359545  	0.10589347  
2023-05-15 09:24:53.202: [iter 92 : loss : 0.1317 = 0.0417 + 0.0849 + 0.0051, time: 6.485662]
2023-05-15 09:24:53.354: epoch 92:	0.02634837  	0.19413979  	0.10618460  
2023-05-15 09:24:53.355: Find a better model.
2023-05-15 09:24:59.999: [iter 93 : loss : 0.1318 = 0.0419 + 0.0848 + 0.0051, time: 6.642984]
2023-05-15 09:25:00.155: epoch 93:	0.02626369  	0.19389345  	0.10610445  
2023-05-15 09:25:06.788: [iter 94 : loss : 0.1299 = 0.0400 + 0.0847 + 0.0052, time: 6.631911]
2023-05-15 09:25:06.945: epoch 94:	0.02637659  	0.19429040  	0.10645965  
2023-05-15 09:25:06.945: Find a better model.
2023-05-15 09:25:13.403: [iter 95 : loss : 0.1292 = 0.0393 + 0.0846 + 0.0052, time: 6.457921]
2023-05-15 09:25:13.558: epoch 95:	0.02636953  	0.19434893  	0.10660115  
2023-05-15 09:25:13.558: Find a better model.
2023-05-15 09:25:20.020: [iter 96 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.460863]
2023-05-15 09:25:20.174: epoch 96:	0.02639776  	0.19478956  	0.10661055  
2023-05-15 09:25:20.174: Find a better model.
2023-05-15 09:25:26.775: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 6.600117]
2023-05-15 09:25:26.919: epoch 97:	0.02650361  	0.19580688  	0.10697498  
2023-05-15 09:25:26.920: Find a better model.
2023-05-15 09:25:33.394: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.473328]
2023-05-15 09:25:33.548: epoch 98:	0.02646127  	0.19540060  	0.10698233  
2023-05-15 09:25:40.171: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 6.621720]
2023-05-15 09:25:40.324: epoch 99:	0.02653183  	0.19590268  	0.10726871  
2023-05-15 09:25:40.324: Find a better model.
2023-05-15 09:25:46.956: [iter 100 : loss : 0.1267 = 0.0371 + 0.0843 + 0.0054, time: 6.630836]
2023-05-15 09:25:47.114: epoch 100:	0.02653183  	0.19592471  	0.10746225  
2023-05-15 09:25:47.114: Find a better model.
2023-05-15 09:25:53.586: [iter 101 : loss : 0.1263 = 0.0367 + 0.0842 + 0.0054, time: 6.471462]
2023-05-15 09:25:53.738: epoch 101:	0.02646833  	0.19567199  	0.10748148  
2023-05-15 09:26:00.367: [iter 102 : loss : 0.1255 = 0.0359 + 0.0842 + 0.0055, time: 6.626983]
2023-05-15 09:26:00.521: epoch 102:	0.02656006  	0.19616425  	0.10772180  
2023-05-15 09:26:00.521: Find a better model.
2023-05-15 09:26:07.153: [iter 103 : loss : 0.1252 = 0.0356 + 0.0841 + 0.0055, time: 6.629524]
2023-05-15 09:26:07.308: epoch 103:	0.02658123  	0.19641303  	0.10780874  
2023-05-15 09:26:07.308: Find a better model.
2023-05-15 09:26:13.978: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.668463]
2023-05-15 09:26:14.134: epoch 104:	0.02653889  	0.19623122  	0.10797086  
2023-05-15 09:26:20.748: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.612979]
2023-05-15 09:26:20.906: epoch 105:	0.02660239  	0.19645736  	0.10822818  
2023-05-15 09:26:20.906: Find a better model.
2023-05-15 09:26:27.365: [iter 106 : loss : 0.1243 = 0.0349 + 0.0839 + 0.0056, time: 6.458710]
2023-05-15 09:26:27.518: epoch 106:	0.02663768  	0.19671817  	0.10821935  
2023-05-15 09:26:27.518: Find a better model.
2023-05-15 09:26:34.139: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.618145]
2023-05-15 09:26:34.291: epoch 107:	0.02665885  	0.19669156  	0.10831004  
2023-05-15 09:26:40.953: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 6.659161]
2023-05-15 09:26:41.112: epoch 108:	0.02668707  	0.19672853  	0.10828047  
2023-05-15 09:26:41.112: Find a better model.
2023-05-15 09:26:47.764: [iter 109 : loss : 0.1219 = 0.0325 + 0.0837 + 0.0057, time: 6.649657]
2023-05-15 09:26:47.917: epoch 109:	0.02672941  	0.19698341  	0.10840248  
2023-05-15 09:26:47.917: Find a better model.
2023-05-15 09:26:54.552: [iter 110 : loss : 0.1214 = 0.0320 + 0.0837 + 0.0057, time: 6.632824]
2023-05-15 09:26:54.705: epoch 110:	0.02665179  	0.19628981  	0.10822161  
2023-05-15 09:27:01.356: [iter 111 : loss : 0.1214 = 0.0321 + 0.0836 + 0.0058, time: 6.648906]
2023-05-15 09:27:01.511: epoch 111:	0.02660240  	0.19614899  	0.10821716  
2023-05-15 09:27:08.161: [iter 112 : loss : 0.1211 = 0.0318 + 0.0835 + 0.0058, time: 6.649046]
2023-05-15 09:27:08.314: epoch 112:	0.02662357  	0.19637549  	0.10840534  
2023-05-15 09:27:14.954: [iter 113 : loss : 0.1213 = 0.0319 + 0.0835 + 0.0058, time: 6.638703]
2023-05-15 09:27:15.096: epoch 113:	0.02665886  	0.19662197  	0.10835011  
2023-05-15 09:27:21.550: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.453079]
2023-05-15 09:27:21.706: epoch 114:	0.02661652  	0.19660468  	0.10834186  
2023-05-15 09:27:28.333: [iter 115 : loss : 0.1200 = 0.0307 + 0.0834 + 0.0059, time: 6.625419]
2023-05-15 09:27:28.478: epoch 115:	0.02668003  	0.19702403  	0.10851707  
2023-05-15 09:27:28.478: Find a better model.
2023-05-15 09:27:35.113: [iter 116 : loss : 0.1190 = 0.0297 + 0.0833 + 0.0059, time: 6.633507]
2023-05-15 09:27:35.256: epoch 116:	0.02663063  	0.19669558  	0.10853723  
2023-05-15 09:27:41.905: [iter 117 : loss : 0.1191 = 0.0298 + 0.0833 + 0.0060, time: 6.646155]
2023-05-15 09:27:42.047: epoch 117:	0.02659535  	0.19634354  	0.10848840  
2023-05-15 09:27:48.533: [iter 118 : loss : 0.1190 = 0.0298 + 0.0832 + 0.0060, time: 6.485030]
2023-05-15 09:27:48.688: epoch 118:	0.02668708  	0.19698018  	0.10881604  
2023-05-15 09:27:55.148: [iter 119 : loss : 0.1180 = 0.0288 + 0.0832 + 0.0060, time: 6.459066]
2023-05-15 09:27:55.303: epoch 119:	0.02677176  	0.19788927  	0.10894801  
2023-05-15 09:27:55.303: Find a better model.
2023-05-15 09:28:01.924: [iter 120 : loss : 0.1182 = 0.0290 + 0.0831 + 0.0061, time: 6.620322]
2023-05-15 09:28:02.082: epoch 120:	0.02675764  	0.19744207  	0.10889169  
2023-05-15 09:28:08.542: [iter 121 : loss : 0.1182 = 0.0290 + 0.0831 + 0.0061, time: 6.459151]
2023-05-15 09:28:08.696: epoch 121:	0.02677881  	0.19739959  	0.10890274  
2023-05-15 09:28:15.345: [iter 122 : loss : 0.1173 = 0.0282 + 0.0830 + 0.0061, time: 6.646389]
2023-05-15 09:28:15.500: epoch 122:	0.02677175  	0.19743998  	0.10888142  
2023-05-15 09:28:22.146: [iter 123 : loss : 0.1174 = 0.0283 + 0.0830 + 0.0061, time: 6.645941]
2023-05-15 09:28:22.303: epoch 123:	0.02674353  	0.19697018  	0.10883346  
2023-05-15 09:28:28.926: [iter 124 : loss : 0.1166 = 0.0275 + 0.0829 + 0.0062, time: 6.621151]
2023-05-15 09:28:29.080: epoch 124:	0.02675059  	0.19706759  	0.10886901  
2023-05-15 09:28:35.729: [iter 125 : loss : 0.1158 = 0.0267 + 0.0829 + 0.0062, time: 6.647178]
2023-05-15 09:28:35.885: epoch 125:	0.02682115  	0.19763149  	0.10894587  
2023-05-15 09:28:42.513: [iter 126 : loss : 0.1161 = 0.0270 + 0.0829 + 0.0062, time: 6.625955]
2023-05-15 09:28:42.666: epoch 126:	0.02677881  	0.19746372  	0.10888179  
2023-05-15 09:28:49.311: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.644081]
2023-05-15 09:28:49.465: epoch 127:	0.02676470  	0.19697961  	0.10890202  
2023-05-15 09:28:56.117: [iter 128 : loss : 0.1162 = 0.0271 + 0.0828 + 0.0063, time: 6.650982]
2023-05-15 09:28:56.277: epoch 128:	0.02679998  	0.19734308  	0.10906437  
2023-05-15 09:29:02.903: [iter 129 : loss : 0.1153 = 0.0262 + 0.0827 + 0.0063, time: 6.624146]
2023-05-15 09:29:03.054: epoch 129:	0.02688466  	0.19809380  	0.10935325  
2023-05-15 09:29:03.054: Find a better model.
2023-05-15 09:29:09.714: [iter 130 : loss : 0.1155 = 0.0265 + 0.0826 + 0.0064, time: 6.658280]
2023-05-15 09:29:09.867: epoch 130:	0.02698344  	0.19838648  	0.10960525  
2023-05-15 09:29:09.868: Find a better model.
2023-05-15 09:29:16.498: [iter 131 : loss : 0.1146 = 0.0256 + 0.0826 + 0.0064, time: 6.629281]
2023-05-15 09:29:16.654: epoch 131:	0.02691993  	0.19839461  	0.10957221  
2023-05-15 09:29:16.654: Find a better model.
2023-05-15 09:29:23.303: [iter 132 : loss : 0.1146 = 0.0256 + 0.0826 + 0.0064, time: 6.648075]
2023-05-15 09:29:23.456: epoch 132:	0.02694110  	0.19847871  	0.10961600  
2023-05-15 09:29:23.457: Find a better model.
2023-05-15 09:29:30.120: [iter 133 : loss : 0.1135 = 0.0245 + 0.0825 + 0.0064, time: 6.661773]
2023-05-15 09:29:30.275: epoch 133:	0.02696933  	0.19855574  	0.10984305  
2023-05-15 09:29:30.275: Find a better model.
2023-05-15 09:29:36.906: [iter 134 : loss : 0.1140 = 0.0250 + 0.0825 + 0.0065, time: 6.628847]
2023-05-15 09:29:37.061: epoch 134:	0.02694816  	0.19832574  	0.10983998  
2023-05-15 09:29:43.702: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.640407]
2023-05-15 09:29:43.855: epoch 135:	0.02690582  	0.19814047  	0.10992505  
2023-05-15 09:29:50.491: [iter 136 : loss : 0.1136 = 0.0246 + 0.0824 + 0.0065, time: 6.634010]
2023-05-15 09:29:50.644: epoch 136:	0.02687054  	0.19785276  	0.10968488  
2023-05-15 09:29:57.311: [iter 137 : loss : 0.1131 = 0.0242 + 0.0824 + 0.0066, time: 6.665217]
2023-05-15 09:29:57.466: epoch 137:	0.02684232  	0.19783261  	0.10982294  
2023-05-15 09:30:04.109: [iter 138 : loss : 0.1128 = 0.0239 + 0.0823 + 0.0066, time: 6.641301]
2023-05-15 09:30:04.262: epoch 138:	0.02687054  	0.19788964  	0.10966002  
2023-05-15 09:30:10.890: [iter 139 : loss : 0.1128 = 0.0239 + 0.0823 + 0.0066, time: 6.627535]
2023-05-15 09:30:11.044: epoch 139:	0.02689876  	0.19804536  	0.10972197  
2023-05-15 09:30:17.682: [iter 140 : loss : 0.1122 = 0.0232 + 0.0823 + 0.0067, time: 6.636724]
2023-05-15 09:30:17.837: epoch 140:	0.02691993  	0.19792089  	0.10971007  
2023-05-15 09:30:24.481: [iter 141 : loss : 0.1125 = 0.0236 + 0.0822 + 0.0067, time: 6.642324]
2023-05-15 09:30:24.626: epoch 141:	0.02687054  	0.19722290  	0.10950609  
2023-05-15 09:30:31.282: [iter 142 : loss : 0.1117 = 0.0228 + 0.0822 + 0.0067, time: 6.655266]
2023-05-15 09:30:31.439: epoch 142:	0.02681408  	0.19725102  	0.10969612  
2023-05-15 09:30:38.075: [iter 143 : loss : 0.1118 = 0.0229 + 0.0822 + 0.0067, time: 6.634574]
2023-05-15 09:30:38.231: epoch 143:	0.02687054  	0.19777898  	0.10986178  
2023-05-15 09:30:44.863: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.631579]
2023-05-15 09:30:45.018: epoch 144:	0.02692699  	0.19812195  	0.10994890  
2023-05-15 09:30:51.485: [iter 145 : loss : 0.1112 = 0.0224 + 0.0821 + 0.0068, time: 6.466127]
2023-05-15 09:30:51.639: epoch 145:	0.02694110  	0.19813530  	0.11011261  
2023-05-15 09:30:58.263: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.623173]
2023-05-15 09:30:58.421: epoch 146:	0.02698344  	0.19843251  	0.11022032  
2023-05-15 09:31:05.050: [iter 147 : loss : 0.1113 = 0.0224 + 0.0820 + 0.0068, time: 6.627699]
2023-05-15 09:31:05.204: epoch 147:	0.02691287  	0.19812363  	0.11027327  
2023-05-15 09:31:11.700: [iter 148 : loss : 0.1099 = 0.0211 + 0.0820 + 0.0069, time: 6.495800]
2023-05-15 09:31:11.854: epoch 148:	0.02700461  	0.19880950  	0.11040957  
2023-05-15 09:31:11.854: Find a better model.
2023-05-15 09:31:18.477: [iter 149 : loss : 0.1104 = 0.0215 + 0.0820 + 0.0069, time: 6.620929]
2023-05-15 09:31:18.631: epoch 149:	0.02697638  	0.19836272  	0.11040395  
2023-05-15 09:31:25.263: [iter 150 : loss : 0.1100 = 0.0211 + 0.0819 + 0.0069, time: 6.631089]
2023-05-15 09:31:25.421: epoch 150:	0.02706106  	0.19909759  	0.11062874  
2023-05-15 09:31:25.422: Find a better model.
2023-05-15 09:31:32.061: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.638106]
2023-05-15 09:31:32.216: epoch 151:	0.02705401  	0.19905668  	0.11066892  
2023-05-15 09:31:38.852: [iter 152 : loss : 0.1094 = 0.0206 + 0.0819 + 0.0070, time: 6.634610]
2023-05-15 09:31:39.010: epoch 152:	0.02699756  	0.19837941  	0.11048187  
2023-05-15 09:31:45.646: [iter 153 : loss : 0.1087 = 0.0198 + 0.0818 + 0.0070, time: 6.634499]
2023-05-15 09:31:45.802: epoch 153:	0.02695522  	0.19836660  	0.11046983  
2023-05-15 09:31:52.459: [iter 154 : loss : 0.1089 = 0.0201 + 0.0818 + 0.0070, time: 6.655763]
2023-05-15 09:31:52.612: epoch 154:	0.02701167  	0.19872706  	0.11063192  
2023-05-15 09:31:59.247: [iter 155 : loss : 0.1096 = 0.0208 + 0.0818 + 0.0070, time: 6.633545]
2023-05-15 09:31:59.402: epoch 155:	0.02696932  	0.19852749  	0.11058658  
2023-05-15 09:32:06.063: [iter 156 : loss : 0.1089 = 0.0201 + 0.0818 + 0.0071, time: 6.658445]
2023-05-15 09:32:06.219: epoch 156:	0.02695521  	0.19827941  	0.11044864  
2023-05-15 09:32:12.845: [iter 157 : loss : 0.1089 = 0.0201 + 0.0817 + 0.0071, time: 6.623837]
2023-05-15 09:32:12.996: epoch 157:	0.02688465  	0.19751042  	0.11011522  
2023-05-15 09:32:19.636: [iter 158 : loss : 0.1081 = 0.0193 + 0.0817 + 0.0071, time: 6.638857]
2023-05-15 09:32:19.792: epoch 158:	0.02691288  	0.19733255  	0.11001144  
2023-05-15 09:32:26.462: [iter 159 : loss : 0.1085 = 0.0197 + 0.0816 + 0.0072, time: 6.668720]
2023-05-15 09:32:26.619: epoch 159:	0.02698344  	0.19789772  	0.11035420  
2023-05-15 09:32:33.242: [iter 160 : loss : 0.1082 = 0.0194 + 0.0816 + 0.0072, time: 6.621558]
2023-05-15 09:32:33.383: epoch 160:	0.02692699  	0.19764416  	0.11037190  
2023-05-15 09:32:39.859: [iter 161 : loss : 0.1077 = 0.0189 + 0.0816 + 0.0072, time: 6.474695]
2023-05-15 09:32:40.013: epoch 161:	0.02691993  	0.19737266  	0.11028916  
2023-05-15 09:32:46.628: [iter 162 : loss : 0.1071 = 0.0183 + 0.0816 + 0.0072, time: 6.614251]
2023-05-15 09:32:46.781: epoch 162:	0.02687054  	0.19732244  	0.11010943  
2023-05-15 09:32:53.434: [iter 163 : loss : 0.1076 = 0.0188 + 0.0815 + 0.0072, time: 6.651674]
2023-05-15 09:32:53.589: epoch 163:	0.02678586  	0.19670814  	0.10988142  
2023-05-15 09:33:00.235: [iter 164 : loss : 0.1074 = 0.0185 + 0.0815 + 0.0073, time: 6.643994]
2023-05-15 09:33:00.388: epoch 164:	0.02677880  	0.19663738  	0.10991370  
2023-05-15 09:33:07.027: [iter 165 : loss : 0.1072 = 0.0184 + 0.0815 + 0.0073, time: 6.638096]
2023-05-15 09:33:07.179: epoch 165:	0.02677175  	0.19655547  	0.10982466  
2023-05-15 09:33:13.636: [iter 166 : loss : 0.1069 = 0.0181 + 0.0815 + 0.0073, time: 6.455031]
2023-05-15 09:33:13.791: epoch 166:	0.02678586  	0.19689767  	0.11001277  
2023-05-15 09:33:20.431: [iter 167 : loss : 0.1073 = 0.0185 + 0.0814 + 0.0073, time: 6.638624]
2023-05-15 09:33:20.586: epoch 167:	0.02679292  	0.19706672  	0.11016270  
2023-05-15 09:33:27.207: [iter 168 : loss : 0.1066 = 0.0178 + 0.0814 + 0.0074, time: 6.618914]
2023-05-15 09:33:27.350: epoch 168:	0.02677881  	0.19693089  	0.11011184  
2023-05-15 09:33:34.007: [iter 169 : loss : 0.1069 = 0.0181 + 0.0814 + 0.0074, time: 6.655174]
2023-05-15 09:33:34.160: epoch 169:	0.02675058  	0.19662753  	0.11003621  
2023-05-15 09:33:40.826: [iter 170 : loss : 0.1064 = 0.0176 + 0.0814 + 0.0074, time: 6.663702]
2023-05-15 09:33:40.980: epoch 170:	0.02670119  	0.19627537  	0.10998558  
2023-05-15 09:33:47.608: [iter 171 : loss : 0.1067 = 0.0179 + 0.0813 + 0.0074, time: 6.625321]
2023-05-15 09:33:47.760: epoch 171:	0.02674353  	0.19651999  	0.11004609  
2023-05-15 09:33:54.406: [iter 172 : loss : 0.1059 = 0.0171 + 0.0813 + 0.0075, time: 6.643502]
2023-05-15 09:33:54.552: epoch 172:	0.02672941  	0.19642590  	0.10991054  
2023-05-15 09:34:01.185: [iter 173 : loss : 0.1065 = 0.0177 + 0.0813 + 0.0075, time: 6.631876]
2023-05-15 09:34:01.338: epoch 173:	0.02671530  	0.19638269  	0.10983700  
2023-05-15 09:34:07.839: [iter 174 : loss : 0.1061 = 0.0173 + 0.0813 + 0.0075, time: 6.499576]
2023-05-15 09:34:07.993: epoch 174:	0.02672236  	0.19627526  	0.10988828  
2023-05-15 09:34:14.623: [iter 175 : loss : 0.1056 = 0.0168 + 0.0813 + 0.0075, time: 6.628991]
2023-05-15 09:34:14.777: epoch 175:	0.02668002  	0.19612640  	0.10984077  
2023-05-15 09:34:14.777: Early stopping is trigger at epoch: 175
2023-05-15 09:34:14.777: best_result@epoch 150:

2023-05-15 09:34:14.777: 		0.0271      	0.1991      	0.1106      
2023-05-15 09:52:21.316: my pid: 14148
2023-05-15 09:52:21.316: model: model.general_recommender.SGL
2023-05-15 09:52:21.316: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 09:52:21.316: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 09:52:24.393: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 09:52:31.890: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.496739]
2023-05-15 09:52:32.045: epoch 1:	0.00197573  	0.01364060  	0.00723148  
2023-05-15 09:52:32.045: Find a better model.
2023-05-15 09:52:39.682: [iter 2 : loss : 0.7706 = 0.6928 + 0.0777 + 0.0000, time: 7.635970]
2023-05-15 09:52:39.875: epoch 2:	0.00390205  	0.02715741  	0.01362028  
2023-05-15 09:52:39.875: Find a better model.
2023-05-15 09:52:47.252: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.374653]
2023-05-15 09:52:47.439: epoch 3:	0.00642107  	0.04468342  	0.02207168  
2023-05-15 09:52:47.439: Find a better model.
2023-05-15 09:52:54.878: [iter 4 : loss : 0.7697 = 0.6920 + 0.0778 + 0.0000, time: 7.438139]
2023-05-15 09:52:55.032: epoch 4:	0.00918000  	0.06521513  	0.03198237  
2023-05-15 09:52:55.032: Find a better model.
2023-05-15 09:53:02.278: [iter 5 : loss : 0.7685 = 0.6906 + 0.0779 + 0.0000, time: 7.244965]
2023-05-15 09:53:02.429: epoch 5:	0.01198848  	0.08558112  	0.04212977  
2023-05-15 09:53:02.429: Find a better model.
2023-05-15 09:53:09.618: [iter 6 : loss : 0.7655 = 0.6873 + 0.0782 + 0.0000, time: 7.187239]
2023-05-15 09:53:09.768: epoch 6:	0.01522033  	0.10877005  	0.05412753  
2023-05-15 09:53:09.768: Find a better model.
2023-05-15 09:53:16.832: [iter 7 : loss : 0.7575 = 0.6785 + 0.0789 + 0.0000, time: 7.062922]
2023-05-15 09:53:16.981: epoch 7:	0.01762655  	0.12673028  	0.06399603  
2023-05-15 09:53:16.981: Find a better model.
2023-05-15 09:53:24.024: [iter 8 : loss : 0.7385 = 0.6575 + 0.0809 + 0.0001, time: 7.042235]
2023-05-15 09:53:24.177: epoch 8:	0.01872736  	0.13696162  	0.06851712  
2023-05-15 09:53:24.177: Find a better model.
2023-05-15 09:53:31.033: [iter 9 : loss : 0.6982 = 0.6132 + 0.0849 + 0.0002, time: 6.854195]
2023-05-15 09:53:31.188: epoch 9:	0.01897434  	0.14072454  	0.06984076  
2023-05-15 09:53:31.188: Find a better model.
2023-05-15 09:53:38.207: [iter 10 : loss : 0.6335 = 0.5431 + 0.0901 + 0.0003, time: 7.017955]
2023-05-15 09:53:38.360: epoch 10:	0.01872030  	0.13868462  	0.06916036  
2023-05-15 09:53:45.051: [iter 11 : loss : 0.5579 = 0.4626 + 0.0949 + 0.0004, time: 6.690088]
2023-05-15 09:53:45.192: epoch 11:	0.01863563  	0.13777184  	0.06912450  
2023-05-15 09:53:51.825: [iter 12 : loss : 0.4916 = 0.3931 + 0.0980 + 0.0006, time: 6.632239]
2023-05-15 09:53:51.979: epoch 12:	0.01857212  	0.13752957  	0.06924385  
2023-05-15 09:53:58.635: [iter 13 : loss : 0.4433 = 0.3429 + 0.0996 + 0.0007, time: 6.655254]
2023-05-15 09:53:58.788: epoch 13:	0.01874853  	0.13868125  	0.07002199  
2023-05-15 09:54:05.622: [iter 14 : loss : 0.4068 = 0.3055 + 0.1005 + 0.0009, time: 6.832571]
2023-05-15 09:54:05.777: epoch 14:	0.01896023  	0.14043970  	0.07094438  
2023-05-15 09:54:12.602: [iter 15 : loss : 0.3813 = 0.2794 + 0.1008 + 0.0010, time: 6.824289]
2023-05-15 09:54:12.756: epoch 15:	0.01909430  	0.14158469  	0.07160127  
2023-05-15 09:54:12.757: Find a better model.
2023-05-15 09:54:19.620: [iter 16 : loss : 0.3597 = 0.2577 + 0.1008 + 0.0011, time: 6.862546]
2023-05-15 09:54:19.771: epoch 16:	0.01931306  	0.14269549  	0.07235512  
2023-05-15 09:54:19.771: Find a better model.
2023-05-15 09:54:26.624: [iter 17 : loss : 0.3437 = 0.2418 + 0.1006 + 0.0012, time: 6.851579]
2023-05-15 09:54:26.776: epoch 17:	0.01943302  	0.14369753  	0.07311824  
2023-05-15 09:54:26.776: Find a better model.
2023-05-15 09:54:33.414: [iter 18 : loss : 0.3287 = 0.2270 + 0.1004 + 0.0013, time: 6.637378]
2023-05-15 09:54:33.555: epoch 18:	0.01960237  	0.14425430  	0.07390681  
2023-05-15 09:54:33.555: Find a better model.
2023-05-15 09:54:40.211: [iter 19 : loss : 0.3148 = 0.2133 + 0.1000 + 0.0014, time: 6.655549]
2023-05-15 09:54:40.368: epoch 19:	0.01987053  	0.14591816  	0.07478242  
2023-05-15 09:54:40.368: Find a better model.
2023-05-15 09:54:47.006: [iter 20 : loss : 0.3053 = 0.2041 + 0.0996 + 0.0015, time: 6.634596]
2023-05-15 09:54:47.147: epoch 20:	0.02001166  	0.14715141  	0.07553498  
2023-05-15 09:54:47.147: Find a better model.
2023-05-15 09:54:53.804: [iter 21 : loss : 0.2957 = 0.1949 + 0.0992 + 0.0016, time: 6.654344]
2023-05-15 09:54:53.955: epoch 21:	0.02024453  	0.14921717  	0.07644074  
2023-05-15 09:54:53.955: Find a better model.
2023-05-15 09:55:00.612: [iter 22 : loss : 0.2875 = 0.1870 + 0.0988 + 0.0017, time: 6.655046]
2023-05-15 09:55:00.764: epoch 22:	0.02042800  	0.15083902  	0.07730174  
2023-05-15 09:55:00.764: Find a better model.
2023-05-15 09:55:07.415: [iter 23 : loss : 0.2793 = 0.1791 + 0.0984 + 0.0018, time: 6.649443]
2023-05-15 09:55:07.568: epoch 23:	0.02064675  	0.15239355  	0.07813220  
2023-05-15 09:55:07.569: Find a better model.
2023-05-15 09:55:14.358: [iter 24 : loss : 0.2729 = 0.1731 + 0.0979 + 0.0018, time: 6.787569]
2023-05-15 09:55:14.502: epoch 24:	0.02090784  	0.15428686  	0.07922198  
2023-05-15 09:55:14.502: Find a better model.
2023-05-15 09:55:21.193: [iter 25 : loss : 0.2662 = 0.1667 + 0.0976 + 0.0019, time: 6.690599]
2023-05-15 09:55:21.346: epoch 25:	0.02101368  	0.15493360  	0.07992315  
2023-05-15 09:55:21.346: Find a better model.
2023-05-15 09:55:27.979: [iter 26 : loss : 0.2627 = 0.1635 + 0.0971 + 0.0020, time: 6.631119]
2023-05-15 09:55:28.120: epoch 26:	0.02126772  	0.15681036  	0.08080353  
2023-05-15 09:55:28.120: Find a better model.
2023-05-15 09:55:34.786: [iter 27 : loss : 0.2548 = 0.1560 + 0.0967 + 0.0020, time: 6.663280]
2023-05-15 09:55:34.936: epoch 27:	0.02140180  	0.15764031  	0.08133082  
2023-05-15 09:55:34.936: Find a better model.
2023-05-15 09:55:41.568: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 6.630730]
2023-05-15 09:55:41.720: epoch 28:	0.02162055  	0.15929623  	0.08229522  
2023-05-15 09:55:41.720: Find a better model.
2023-05-15 09:55:48.210: [iter 29 : loss : 0.2455 = 0.1474 + 0.0959 + 0.0022, time: 6.488536]
2023-05-15 09:55:48.363: epoch 29:	0.02177579  	0.16033132  	0.08293463  
2023-05-15 09:55:48.363: Find a better model.
2023-05-15 09:55:54.955: [iter 30 : loss : 0.2390 = 0.1412 + 0.0956 + 0.0022, time: 6.590303]
2023-05-15 09:55:55.107: epoch 30:	0.02196631  	0.16224940  	0.08393987  
2023-05-15 09:55:55.107: Find a better model.
2023-05-15 09:56:01.762: [iter 31 : loss : 0.2354 = 0.1379 + 0.0952 + 0.0023, time: 6.653735]
2023-05-15 09:56:01.913: epoch 31:	0.02210039  	0.16319123  	0.08444764  
2023-05-15 09:56:01.913: Find a better model.
2023-05-15 09:56:08.582: [iter 32 : loss : 0.2299 = 0.1326 + 0.0948 + 0.0024, time: 6.666251]
2023-05-15 09:56:08.735: epoch 32:	0.02221329  	0.16410062  	0.08495874  
2023-05-15 09:56:08.735: Find a better model.
2023-05-15 09:56:15.378: [iter 33 : loss : 0.2272 = 0.1303 + 0.0944 + 0.0024, time: 6.642699]
2023-05-15 09:56:15.534: epoch 33:	0.02241793  	0.16576256  	0.08586214  
2023-05-15 09:56:15.534: Find a better model.
2023-05-15 09:56:22.166: [iter 34 : loss : 0.2233 = 0.1267 + 0.0941 + 0.0025, time: 6.629250]
2023-05-15 09:56:22.316: epoch 34:	0.02250261  	0.16641891  	0.08658749  
2023-05-15 09:56:22.316: Find a better model.
2023-05-15 09:56:28.982: [iter 35 : loss : 0.2199 = 0.1235 + 0.0938 + 0.0025, time: 6.665337]
2023-05-15 09:56:29.135: epoch 35:	0.02265785  	0.16758324  	0.08735345  
2023-05-15 09:56:29.135: Find a better model.
2023-05-15 09:56:35.773: [iter 36 : loss : 0.2162 = 0.1201 + 0.0935 + 0.0026, time: 6.637447]
2023-05-15 09:56:35.926: epoch 36:	0.02271430  	0.16758263  	0.08764306  
2023-05-15 09:56:42.564: [iter 37 : loss : 0.2125 = 0.1167 + 0.0932 + 0.0027, time: 6.636830]
2023-05-15 09:56:42.703: epoch 37:	0.02273547  	0.16766813  	0.08795477  
2023-05-15 09:56:42.703: Find a better model.
2023-05-15 09:56:49.351: [iter 38 : loss : 0.2110 = 0.1154 + 0.0929 + 0.0027, time: 6.647538]
2023-05-15 09:56:49.511: epoch 38:	0.02294716  	0.16972457  	0.08885053  
2023-05-15 09:56:49.511: Find a better model.
2023-05-15 09:56:56.156: [iter 39 : loss : 0.2065 = 0.1112 + 0.0926 + 0.0028, time: 6.644371]
2023-05-15 09:56:56.296: epoch 39:	0.02305301  	0.17098510  	0.08949606  
2023-05-15 09:56:56.296: Find a better model.
2023-05-15 09:57:02.958: [iter 40 : loss : 0.2034 = 0.1083 + 0.0923 + 0.0028, time: 6.658968]
2023-05-15 09:57:03.109: epoch 40:	0.02319414  	0.17186157  	0.08995992  
2023-05-15 09:57:03.109: Find a better model.
2023-05-15 09:57:09.761: [iter 41 : loss : 0.2018 = 0.1069 + 0.0920 + 0.0029, time: 6.650285]
2023-05-15 09:57:09.901: epoch 41:	0.02335643  	0.17280346  	0.09046921  
2023-05-15 09:57:09.901: Find a better model.
2023-05-15 09:57:16.552: [iter 42 : loss : 0.1994 = 0.1048 + 0.0917 + 0.0029, time: 6.649447]
2023-05-15 09:57:16.704: epoch 42:	0.02339877  	0.17295375  	0.09105710  
2023-05-15 09:57:16.705: Find a better model.
2023-05-15 09:57:23.518: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 6.811646]
2023-05-15 09:57:23.660: epoch 43:	0.02358224  	0.17428513  	0.09174775  
2023-05-15 09:57:23.660: Find a better model.
2023-05-15 09:57:30.350: [iter 44 : loss : 0.1923 = 0.0981 + 0.0912 + 0.0030, time: 6.688802]
2023-05-15 09:57:30.502: epoch 44:	0.02372337  	0.17535387  	0.09223559  
2023-05-15 09:57:30.502: Find a better model.
2023-05-15 09:57:37.159: [iter 45 : loss : 0.1901 = 0.0961 + 0.0910 + 0.0031, time: 6.654002]
2023-05-15 09:57:37.310: epoch 45:	0.02391389  	0.17647648  	0.09302352  
2023-05-15 09:57:37.310: Find a better model.
2023-05-15 09:57:43.945: [iter 46 : loss : 0.1876 = 0.0938 + 0.0907 + 0.0031, time: 6.633256]
2023-05-15 09:57:44.097: epoch 46:	0.02398445  	0.17692018  	0.09350724  
2023-05-15 09:57:44.097: Find a better model.
2023-05-15 09:57:50.768: [iter 47 : loss : 0.1869 = 0.0932 + 0.0905 + 0.0032, time: 6.669429]
2023-05-15 09:57:50.919: epoch 47:	0.02406914  	0.17745443  	0.09406707  
2023-05-15 09:57:50.919: Find a better model.
2023-05-15 09:57:57.537: [iter 48 : loss : 0.1831 = 0.0896 + 0.0903 + 0.0032, time: 6.616053]
2023-05-15 09:57:57.691: epoch 48:	0.02410442  	0.17776729  	0.09447279  
2023-05-15 09:57:57.691: Find a better model.
2023-05-15 09:58:04.334: [iter 49 : loss : 0.1802 = 0.0868 + 0.0901 + 0.0033, time: 6.641825]
2023-05-15 09:58:04.486: epoch 49:	0.02425966  	0.17887029  	0.09501839  
2023-05-15 09:58:04.486: Find a better model.
2023-05-15 09:58:11.130: [iter 50 : loss : 0.1792 = 0.0860 + 0.0899 + 0.0033, time: 6.642606]
2023-05-15 09:58:11.283: epoch 50:	0.02431611  	0.17968649  	0.09551779  
2023-05-15 09:58:11.283: Find a better model.
2023-05-15 09:58:17.925: [iter 51 : loss : 0.1763 = 0.0833 + 0.0896 + 0.0034, time: 6.641618]
2023-05-15 09:58:18.078: epoch 51:	0.02444312  	0.18027607  	0.09587929  
2023-05-15 09:58:18.078: Find a better model.
2023-05-15 09:58:24.734: [iter 52 : loss : 0.1763 = 0.0834 + 0.0895 + 0.0034, time: 6.654206]
2023-05-15 09:58:24.875: epoch 52:	0.02442195  	0.18018472  	0.09627330  
2023-05-15 09:58:31.538: [iter 53 : loss : 0.1742 = 0.0814 + 0.0892 + 0.0035, time: 6.661762]
2023-05-15 09:58:31.694: epoch 53:	0.02459130  	0.18132147  	0.09689631  
2023-05-15 09:58:31.694: Find a better model.
2023-05-15 09:58:38.324: [iter 54 : loss : 0.1722 = 0.0796 + 0.0891 + 0.0035, time: 6.628816]
2023-05-15 09:58:38.477: epoch 54:	0.02471832  	0.18242130  	0.09745386  
2023-05-15 09:58:38.477: Find a better model.
2023-05-15 09:58:45.121: [iter 55 : loss : 0.1703 = 0.0778 + 0.0889 + 0.0036, time: 6.643235]
2023-05-15 09:58:45.273: epoch 55:	0.02478183  	0.18286905  	0.09782529  
2023-05-15 09:58:45.273: Find a better model.
2023-05-15 09:58:51.923: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.648310]
2023-05-15 09:58:52.075: epoch 56:	0.02485239  	0.18325837  	0.09810940  
2023-05-15 09:58:52.075: Find a better model.
2023-05-15 09:58:58.724: [iter 57 : loss : 0.1669 = 0.0747 + 0.0885 + 0.0037, time: 6.647812]
2023-05-15 09:58:58.877: epoch 57:	0.02487356  	0.18357411  	0.09834621  
2023-05-15 09:58:58.877: Find a better model.
2023-05-15 09:59:05.524: [iter 58 : loss : 0.1648 = 0.0728 + 0.0883 + 0.0037, time: 6.645173]
2023-05-15 09:59:05.680: epoch 58:	0.02493001  	0.18396303  	0.09859622  
2023-05-15 09:59:05.680: Find a better model.
2023-05-15 09:59:12.329: [iter 59 : loss : 0.1638 = 0.0719 + 0.0882 + 0.0038, time: 6.647485]
2023-05-15 09:59:12.481: epoch 59:	0.02503585  	0.18470199  	0.09911256  
2023-05-15 09:59:12.481: Find a better model.
2023-05-15 09:59:19.123: [iter 60 : loss : 0.1624 = 0.0706 + 0.0880 + 0.0038, time: 6.640970]
2023-05-15 09:59:19.277: epoch 60:	0.02516993  	0.18572731  	0.09964553  
2023-05-15 09:59:19.277: Find a better model.
2023-05-15 09:59:25.911: [iter 61 : loss : 0.1612 = 0.0695 + 0.0878 + 0.0038, time: 6.631986]
2023-05-15 09:59:26.062: epoch 61:	0.02521933  	0.18586195  	0.09976921  
2023-05-15 09:59:26.062: Find a better model.
2023-05-15 09:59:32.894: [iter 62 : loss : 0.1597 = 0.0682 + 0.0877 + 0.0039, time: 6.829726]
2023-05-15 09:59:33.049: epoch 62:	0.02524755  	0.18602389  	0.10002617  
2023-05-15 09:59:33.049: Find a better model.
2023-05-15 09:59:39.712: [iter 63 : loss : 0.1583 = 0.0669 + 0.0875 + 0.0039, time: 6.662467]
2023-05-15 09:59:39.862: epoch 63:	0.02529695  	0.18644385  	0.10036876  
2023-05-15 09:59:39.862: Find a better model.
2023-05-15 09:59:46.675: [iter 64 : loss : 0.1572 = 0.0659 + 0.0873 + 0.0040, time: 6.810752]
2023-05-15 09:59:46.830: epoch 64:	0.02535340  	0.18679452  	0.10058057  
2023-05-15 09:59:46.830: Find a better model.
2023-05-15 09:59:53.688: [iter 65 : loss : 0.1561 = 0.0649 + 0.0872 + 0.0040, time: 6.856568]
2023-05-15 09:59:53.841: epoch 65:	0.02536751  	0.18710102  	0.10098182  
2023-05-15 09:59:53.842: Find a better model.
2023-05-15 10:00:00.689: [iter 66 : loss : 0.1545 = 0.0634 + 0.0871 + 0.0041, time: 6.846009]
2023-05-15 10:00:00.840: epoch 66:	0.02544513  	0.18770906  	0.10124061  
2023-05-15 10:00:00.840: Find a better model.
2023-05-15 10:00:07.684: [iter 67 : loss : 0.1529 = 0.0619 + 0.0869 + 0.0041, time: 6.842213]
2023-05-15 10:00:07.837: epoch 67:	0.02555803  	0.18843348  	0.10160857  
2023-05-15 10:00:07.837: Find a better model.
2023-05-15 10:00:14.684: [iter 68 : loss : 0.1526 = 0.0616 + 0.0868 + 0.0042, time: 6.845673]
2023-05-15 10:00:14.837: epoch 68:	0.02557214  	0.18842082  	0.10189567  
2023-05-15 10:00:21.689: [iter 69 : loss : 0.1509 = 0.0600 + 0.0867 + 0.0042, time: 6.851468]
2023-05-15 10:00:21.841: epoch 69:	0.02562859  	0.18864621  	0.10207426  
2023-05-15 10:00:21.841: Find a better model.
2023-05-15 10:00:28.680: [iter 70 : loss : 0.1492 = 0.0584 + 0.0866 + 0.0042, time: 6.837305]
2023-05-15 10:00:28.831: epoch 70:	0.02564977  	0.18873669  	0.10235851  
2023-05-15 10:00:28.831: Find a better model.
2023-05-15 10:00:35.503: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.671011]
2023-05-15 10:00:35.644: epoch 71:	0.02574151  	0.18928124  	0.10291946  
2023-05-15 10:00:35.644: Find a better model.
2023-05-15 10:00:42.271: [iter 72 : loss : 0.1477 = 0.0570 + 0.0863 + 0.0043, time: 6.625916]
2023-05-15 10:00:42.424: epoch 72:	0.02579796  	0.18958458  	0.10302083  
2023-05-15 10:00:42.424: Find a better model.
2023-05-15 10:00:49.102: [iter 73 : loss : 0.1462 = 0.0556 + 0.0862 + 0.0044, time: 6.676622]
2023-05-15 10:00:49.253: epoch 73:	0.02581913  	0.19010893  	0.10334974  
2023-05-15 10:00:49.254: Find a better model.
2023-05-15 10:00:56.061: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.805712]
2023-05-15 10:00:56.213: epoch 74:	0.02586852  	0.19060442  	0.10375603  
2023-05-15 10:00:56.213: Find a better model.
2023-05-15 10:01:02.891: [iter 75 : loss : 0.1444 = 0.0540 + 0.0860 + 0.0044, time: 6.675422]
2023-05-15 10:01:03.043: epoch 75:	0.02587558  	0.19045565  	0.10396200  
2023-05-15 10:01:09.674: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 6.630452]
2023-05-15 10:01:09.831: epoch 76:	0.02594615  	0.19076775  	0.10395524  
2023-05-15 10:01:09.831: Find a better model.
2023-05-15 10:01:16.697: [iter 77 : loss : 0.1426 = 0.0523 + 0.0857 + 0.0045, time: 6.865633]
2023-05-15 10:01:16.849: epoch 77:	0.02596732  	0.19085173  	0.10396345  
2023-05-15 10:01:16.849: Find a better model.
2023-05-15 10:01:23.667: [iter 78 : loss : 0.1416 = 0.0514 + 0.0856 + 0.0046, time: 6.816382]
2023-05-15 10:01:23.822: epoch 78:	0.02596026  	0.19117723  	0.10419210  
2023-05-15 10:01:23.822: Find a better model.
2023-05-15 10:01:30.474: [iter 79 : loss : 0.1405 = 0.0504 + 0.0855 + 0.0046, time: 6.651378]
2023-05-15 10:01:30.615: epoch 79:	0.02600260  	0.19136587  	0.10425513  
2023-05-15 10:01:30.615: Find a better model.
2023-05-15 10:01:37.274: [iter 80 : loss : 0.1396 = 0.0495 + 0.0854 + 0.0047, time: 6.657153]
2023-05-15 10:01:37.428: epoch 80:	0.02607317  	0.19185224  	0.10457779  
2023-05-15 10:01:37.428: Find a better model.
2023-05-15 10:01:44.261: [iter 81 : loss : 0.1393 = 0.0493 + 0.0853 + 0.0047, time: 6.830448]
2023-05-15 10:01:44.410: epoch 81:	0.02610845  	0.19231029  	0.10479316  
2023-05-15 10:01:44.411: Find a better model.
2023-05-15 10:01:51.059: [iter 82 : loss : 0.1382 = 0.0482 + 0.0852 + 0.0047, time: 6.645452]
2023-05-15 10:01:51.213: epoch 82:	0.02621429  	0.19304784  	0.10509510  
2023-05-15 10:01:51.213: Find a better model.
2023-05-15 10:01:57.880: [iter 83 : loss : 0.1370 = 0.0471 + 0.0851 + 0.0048, time: 6.663912]
2023-05-15 10:01:58.032: epoch 83:	0.02625663  	0.19317833  	0.10537825  
2023-05-15 10:01:58.032: Find a better model.
2023-05-15 10:02:04.818: [iter 84 : loss : 0.1370 = 0.0472 + 0.0850 + 0.0048, time: 6.785601]
2023-05-15 10:02:04.958: epoch 84:	0.02632014  	0.19390099  	0.10553694  
2023-05-15 10:02:04.958: Find a better model.
2023-05-15 10:02:11.639: [iter 85 : loss : 0.1361 = 0.0463 + 0.0849 + 0.0048, time: 6.679703]
2023-05-15 10:02:11.800: epoch 85:	0.02632720  	0.19382492  	0.10563961  
2023-05-15 10:02:18.450: [iter 86 : loss : 0.1359 = 0.0462 + 0.0848 + 0.0049, time: 6.648380]
2023-05-15 10:02:18.603: epoch 86:	0.02629897  	0.19360968  	0.10558492  
2023-05-15 10:02:25.241: [iter 87 : loss : 0.1332 = 0.0435 + 0.0847 + 0.0049, time: 6.636897]
2023-05-15 10:02:25.395: epoch 87:	0.02633425  	0.19377503  	0.10563274  
2023-05-15 10:02:32.037: [iter 88 : loss : 0.1328 = 0.0432 + 0.0847 + 0.0050, time: 6.640673]
2023-05-15 10:02:32.191: epoch 88:	0.02644010  	0.19413593  	0.10611118  
2023-05-15 10:02:32.191: Find a better model.
2023-05-15 10:02:38.884: [iter 89 : loss : 0.1325 = 0.0429 + 0.0845 + 0.0050, time: 6.691221]
2023-05-15 10:02:39.037: epoch 89:	0.02645421  	0.19458111  	0.10630141  
2023-05-15 10:02:39.037: Find a better model.
2023-05-15 10:02:45.630: [iter 90 : loss : 0.1329 = 0.0434 + 0.0845 + 0.0050, time: 6.591173]
2023-05-15 10:02:45.770: epoch 90:	0.02652478  	0.19532113  	0.10656031  
2023-05-15 10:02:45.770: Find a better model.
2023-05-15 10:02:52.437: [iter 91 : loss : 0.1317 = 0.0422 + 0.0844 + 0.0051, time: 6.665884]
2023-05-15 10:02:52.590: epoch 91:	0.02655300  	0.19537519  	0.10659198  
2023-05-15 10:02:52.590: Find a better model.
2023-05-15 10:02:59.224: [iter 92 : loss : 0.1310 = 0.0416 + 0.0843 + 0.0051, time: 6.633173]
2023-05-15 10:02:59.365: epoch 92:	0.02658829  	0.19558860  	0.10679744  
2023-05-15 10:02:59.365: Find a better model.
2023-05-15 10:03:06.030: [iter 93 : loss : 0.1311 = 0.0417 + 0.0842 + 0.0052, time: 6.664516]
2023-05-15 10:03:06.184: epoch 93:	0.02662357  	0.19587769  	0.10697519  
2023-05-15 10:03:06.184: Find a better model.
2023-05-15 10:03:12.842: [iter 94 : loss : 0.1291 = 0.0398 + 0.0842 + 0.0052, time: 6.656176]
2023-05-15 10:03:12.995: epoch 94:	0.02667297  	0.19647464  	0.10726552  
2023-05-15 10:03:12.996: Find a better model.
2023-05-15 10:03:19.650: [iter 95 : loss : 0.1285 = 0.0392 + 0.0841 + 0.0052, time: 6.653754]
2023-05-15 10:03:19.792: epoch 95:	0.02669414  	0.19682936  	0.10729976  
2023-05-15 10:03:19.793: Find a better model.
2023-05-15 10:03:26.425: [iter 96 : loss : 0.1285 = 0.0392 + 0.0840 + 0.0053, time: 6.630640]
2023-05-15 10:03:26.577: epoch 96:	0.02668708  	0.19669805  	0.10726194  
2023-05-15 10:03:33.228: [iter 97 : loss : 0.1268 = 0.0376 + 0.0839 + 0.0053, time: 6.649265]
2023-05-15 10:03:33.381: epoch 97:	0.02675059  	0.19737558  	0.10749992  
2023-05-15 10:03:33.381: Find a better model.
2023-05-15 10:03:40.037: [iter 98 : loss : 0.1276 = 0.0385 + 0.0838 + 0.0053, time: 6.654695]
2023-05-15 10:03:40.193: epoch 98:	0.02672942  	0.19746840  	0.10766570  
2023-05-15 10:03:40.193: Find a better model.
2023-05-15 10:03:46.855: [iter 99 : loss : 0.1267 = 0.0375 + 0.0838 + 0.0054, time: 6.660520]
2023-05-15 10:03:47.003: epoch 99:	0.02666591  	0.19678631  	0.10755533  
2023-05-15 10:03:53.614: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 6.608546]
2023-05-15 10:03:53.761: epoch 100:	0.02673648  	0.19718504  	0.10769589  
2023-05-15 10:04:00.244: [iter 101 : loss : 0.1256 = 0.0365 + 0.0836 + 0.0054, time: 6.481584]
2023-05-15 10:04:00.398: epoch 101:	0.02672236  	0.19684921  	0.10765019  
2023-05-15 10:04:07.009: [iter 102 : loss : 0.1247 = 0.0357 + 0.0836 + 0.0055, time: 6.609955]
2023-05-15 10:04:07.161: epoch 102:	0.02665180  	0.19662313  	0.10765537  
2023-05-15 10:04:13.801: [iter 103 : loss : 0.1243 = 0.0353 + 0.0835 + 0.0055, time: 6.639815]
2023-05-15 10:04:13.955: epoch 103:	0.02672942  	0.19700909  	0.10778015  
2023-05-15 10:04:20.414: [iter 104 : loss : 0.1247 = 0.0357 + 0.0834 + 0.0056, time: 6.455863]
2023-05-15 10:04:20.568: epoch 104:	0.02677881  	0.19714391  	0.10800519  
2023-05-15 10:04:27.209: [iter 105 : loss : 0.1242 = 0.0353 + 0.0833 + 0.0056, time: 6.639955]
2023-05-15 10:04:27.363: epoch 105:	0.02679998  	0.19730327  	0.10792899  
2023-05-15 10:04:33.988: [iter 106 : loss : 0.1237 = 0.0348 + 0.0833 + 0.0056, time: 6.623345]
2023-05-15 10:04:34.144: epoch 106:	0.02678587  	0.19731562  	0.10806268  
2023-05-15 10:04:40.808: [iter 107 : loss : 0.1227 = 0.0338 + 0.0832 + 0.0056, time: 6.662341]
2023-05-15 10:04:40.964: epoch 107:	0.02682821  	0.19748729  	0.10824995  
2023-05-15 10:04:40.964: Find a better model.
2023-05-15 10:04:47.587: [iter 108 : loss : 0.1223 = 0.0335 + 0.0832 + 0.0057, time: 6.622034]
2023-05-15 10:04:47.739: epoch 108:	0.02679292  	0.19757180  	0.10828201  
2023-05-15 10:04:47.740: Find a better model.
2023-05-15 10:04:54.386: [iter 109 : loss : 0.1213 = 0.0325 + 0.0831 + 0.0057, time: 6.643674]
2023-05-15 10:04:54.538: epoch 109:	0.02688466  	0.19816820  	0.10845112  
2023-05-15 10:04:54.538: Find a better model.
2023-05-15 10:05:01.192: [iter 110 : loss : 0.1207 = 0.0319 + 0.0831 + 0.0058, time: 6.653681]
2023-05-15 10:05:01.347: epoch 110:	0.02682821  	0.19757888  	0.10817207  
2023-05-15 10:05:07.986: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 6.637932]
2023-05-15 10:05:08.141: epoch 111:	0.02684937  	0.19758072  	0.10825737  
2023-05-15 10:05:14.780: [iter 112 : loss : 0.1205 = 0.0317 + 0.0829 + 0.0058, time: 6.638102]
2023-05-15 10:05:14.934: epoch 112:	0.02681409  	0.19764869  	0.10807739  
2023-05-15 10:05:21.419: [iter 113 : loss : 0.1204 = 0.0317 + 0.0829 + 0.0059, time: 6.483212]
2023-05-15 10:05:21.574: epoch 113:	0.02679998  	0.19760811  	0.10817043  
2023-05-15 10:05:28.174: [iter 114 : loss : 0.1197 = 0.0309 + 0.0828 + 0.0059, time: 6.598653]
2023-05-15 10:05:28.330: epoch 114:	0.02689877  	0.19835497  	0.10833231  
2023-05-15 10:05:28.330: Find a better model.
2023-05-15 10:05:34.971: [iter 115 : loss : 0.1192 = 0.0305 + 0.0828 + 0.0059, time: 6.639178]
2023-05-15 10:05:35.131: epoch 115:	0.02687760  	0.19810735  	0.10831562  
2023-05-15 10:05:41.781: [iter 116 : loss : 0.1182 = 0.0296 + 0.0827 + 0.0060, time: 6.649290]
2023-05-15 10:05:41.933: epoch 116:	0.02679292  	0.19754918  	0.10824595  
2023-05-15 10:05:48.566: [iter 117 : loss : 0.1184 = 0.0297 + 0.0827 + 0.0060, time: 6.631211]
2023-05-15 10:05:48.721: epoch 117:	0.02675059  	0.19723384  	0.10810161  
2023-05-15 10:05:55.360: [iter 118 : loss : 0.1184 = 0.0297 + 0.0826 + 0.0060, time: 6.638743]
2023-05-15 10:05:55.505: epoch 118:	0.02677881  	0.19748700  	0.10845504  
2023-05-15 10:06:02.170: [iter 119 : loss : 0.1173 = 0.0287 + 0.0826 + 0.0061, time: 6.662199]
2023-05-15 10:06:02.324: epoch 119:	0.02682821  	0.19796352  	0.10861499  
2023-05-15 10:06:08.955: [iter 120 : loss : 0.1175 = 0.0289 + 0.0825 + 0.0061, time: 6.629772]
2023-05-15 10:06:09.109: epoch 120:	0.02684938  	0.19815746  	0.10885043  
2023-05-15 10:06:15.760: [iter 121 : loss : 0.1175 = 0.0289 + 0.0825 + 0.0061, time: 6.648534]
2023-05-15 10:06:15.915: epoch 121:	0.02691994  	0.19866791  	0.10923092  
2023-05-15 10:06:15.915: Find a better model.
2023-05-15 10:06:22.564: [iter 122 : loss : 0.1167 = 0.0281 + 0.0824 + 0.0061, time: 6.648516]
2023-05-15 10:06:22.718: epoch 122:	0.02686349  	0.19806440  	0.10892973  
2023-05-15 10:06:29.355: [iter 123 : loss : 0.1167 = 0.0282 + 0.0824 + 0.0062, time: 6.634310]
2023-05-15 10:06:29.507: epoch 123:	0.02682821  	0.19753449  	0.10874908  
2023-05-15 10:06:36.150: [iter 124 : loss : 0.1158 = 0.0273 + 0.0823 + 0.0062, time: 6.642810]
2023-05-15 10:06:36.293: epoch 124:	0.02685643  	0.19774975  	0.10883747  
2023-05-15 10:06:42.978: [iter 125 : loss : 0.1151 = 0.0266 + 0.0823 + 0.0062, time: 6.683022]
2023-05-15 10:06:43.130: epoch 125:	0.02685643  	0.19782102  	0.10898080  
2023-05-15 10:06:49.772: [iter 126 : loss : 0.1154 = 0.0269 + 0.0823 + 0.0063, time: 6.640123]
2023-05-15 10:06:49.927: epoch 126:	0.02680703  	0.19755521  	0.10886413  
2023-05-15 10:06:56.547: [iter 127 : loss : 0.1143 = 0.0258 + 0.0822 + 0.0063, time: 6.618435]
2023-05-15 10:06:56.711: epoch 127:	0.02680703  	0.19773082  	0.10876475  
2023-05-15 10:07:03.341: [iter 128 : loss : 0.1153 = 0.0268 + 0.0822 + 0.0063, time: 6.628943]
2023-05-15 10:07:03.492: epoch 128:	0.02686349  	0.19763014  	0.10891347  
2023-05-15 10:07:10.141: [iter 129 : loss : 0.1146 = 0.0261 + 0.0821 + 0.0064, time: 6.648209]
2023-05-15 10:07:10.297: epoch 129:	0.02683526  	0.19774020  	0.10897047  
2023-05-15 10:07:16.952: [iter 130 : loss : 0.1146 = 0.0262 + 0.0821 + 0.0064, time: 6.653904]
2023-05-15 10:07:17.093: epoch 130:	0.02681409  	0.19772199  	0.10911942  
2023-05-15 10:07:23.745: [iter 131 : loss : 0.1139 = 0.0254 + 0.0820 + 0.0064, time: 6.649893]
2023-05-15 10:07:23.896: epoch 131:	0.02684937  	0.19772765  	0.10905904  
2023-05-15 10:07:30.544: [iter 132 : loss : 0.1139 = 0.0255 + 0.0820 + 0.0065, time: 6.646292]
2023-05-15 10:07:30.699: epoch 132:	0.02673647  	0.19686885  	0.10880720  
2023-05-15 10:07:37.329: [iter 133 : loss : 0.1128 = 0.0243 + 0.0819 + 0.0065, time: 6.628675]
2023-05-15 10:07:37.471: epoch 133:	0.02674352  	0.19727607  	0.10898527  
2023-05-15 10:07:44.129: [iter 134 : loss : 0.1133 = 0.0249 + 0.0819 + 0.0065, time: 6.655951]
2023-05-15 10:07:44.287: epoch 134:	0.02679997  	0.19790857  	0.10914284  
2023-05-15 10:07:50.910: [iter 135 : loss : 0.1131 = 0.0247 + 0.0818 + 0.0065, time: 6.619489]
2023-05-15 10:07:51.052: epoch 135:	0.02679292  	0.19755393  	0.10898668  
2023-05-15 10:07:57.544: [iter 136 : loss : 0.1129 = 0.0245 + 0.0818 + 0.0066, time: 6.490863]
2023-05-15 10:07:57.695: epoch 136:	0.02675764  	0.19722591  	0.10897199  
2023-05-15 10:08:04.339: [iter 137 : loss : 0.1125 = 0.0241 + 0.0818 + 0.0066, time: 6.642889]
2023-05-15 10:08:04.492: epoch 137:	0.02677880  	0.19778934  	0.10919171  
2023-05-15 10:08:11.122: [iter 138 : loss : 0.1122 = 0.0238 + 0.0817 + 0.0066, time: 6.627283]
2023-05-15 10:08:11.269: epoch 138:	0.02677880  	0.19779454  	0.10914415  
2023-05-15 10:08:17.913: [iter 139 : loss : 0.1119 = 0.0235 + 0.0817 + 0.0067, time: 6.642455]
2023-05-15 10:08:18.065: epoch 139:	0.02677880  	0.19756910  	0.10915118  
2023-05-15 10:08:24.532: [iter 140 : loss : 0.1114 = 0.0230 + 0.0817 + 0.0067, time: 6.466390]
2023-05-15 10:08:24.684: epoch 140:	0.02677174  	0.19729385  	0.10921448  
2023-05-15 10:08:31.301: [iter 141 : loss : 0.1118 = 0.0234 + 0.0816 + 0.0067, time: 6.615972]
2023-05-15 10:08:31.456: epoch 141:	0.02679997  	0.19763084  	0.10935529  
2023-05-15 10:08:38.092: [iter 142 : loss : 0.1111 = 0.0228 + 0.0816 + 0.0067, time: 6.633591]
2023-05-15 10:08:38.233: epoch 142:	0.02672234  	0.19688290  	0.10920151  
2023-05-15 10:08:44.735: [iter 143 : loss : 0.1110 = 0.0227 + 0.0816 + 0.0068, time: 6.500871]
2023-05-15 10:08:44.891: epoch 143:	0.02671529  	0.19695118  	0.10910411  
2023-05-15 10:08:51.327: [iter 144 : loss : 0.1106 = 0.0223 + 0.0815 + 0.0068, time: 6.434256]
2023-05-15 10:08:51.480: epoch 144:	0.02675057  	0.19733639  	0.10924294  
2023-05-15 10:08:58.107: [iter 145 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.625450]
2023-05-15 10:08:58.260: epoch 145:	0.02672234  	0.19684978  	0.10903660  
2023-05-15 10:09:04.712: [iter 146 : loss : 0.1107 = 0.0224 + 0.0814 + 0.0068, time: 6.450563]
2023-05-15 10:09:04.867: epoch 146:	0.02682819  	0.19773346  	0.10940029  
2023-05-15 10:09:04.867: Early stopping is trigger at epoch: 146
2023-05-15 10:09:04.867: best_result@epoch 121:

2023-05-15 10:09:04.867: 		0.0269      	0.1987      	0.1092      
2023-05-15 10:15:14.628: my pid: 3352
2023-05-15 10:15:14.628: model: model.general_recommender.SGL
2023-05-15 10:15:14.628: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 10:15:14.628: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 10:15:17.804: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 10:15:25.441: [iter 1 : loss : 0.7707 = 0.6930 + 0.0777 + 0.0000, time: 7.636697]
2023-05-15 10:15:25.595: epoch 1:	0.00184872  	0.01300010  	0.00658795  
2023-05-15 10:15:25.595: Find a better model.
2023-05-15 10:15:33.479: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.882061]
2023-05-15 10:15:33.668: epoch 2:	0.00335167  	0.02376241  	0.01205332  
2023-05-15 10:15:33.668: Find a better model.
2023-05-15 10:15:41.377: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.706457]
2023-05-15 10:15:41.543: epoch 3:	0.00573663  	0.04004405  	0.02062817  
2023-05-15 10:15:41.543: Find a better model.
2023-05-15 10:15:49.179: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.634660]
2023-05-15 10:15:49.343: epoch 4:	0.00832621  	0.05839108  	0.02918037  
2023-05-15 10:15:49.343: Find a better model.
2023-05-15 10:15:56.812: [iter 5 : loss : 0.7685 = 0.6912 + 0.0774 + 0.0000, time: 7.467402]
2023-05-15 10:15:56.975: epoch 5:	0.01086650  	0.07745952  	0.03797746  
2023-05-15 10:15:56.976: Find a better model.
2023-05-15 10:16:04.186: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.209356]
2023-05-15 10:16:04.340: epoch 6:	0.01368908  	0.09834242  	0.04817654  
2023-05-15 10:16:04.341: Find a better model.
2023-05-15 10:16:11.386: [iter 7 : loss : 0.7604 = 0.6823 + 0.0781 + 0.0000, time: 7.044079]
2023-05-15 10:16:11.529: epoch 7:	0.01649753  	0.11912762  	0.05949352  
2023-05-15 10:16:11.529: Find a better model.
2023-05-15 10:16:18.756: [iter 8 : loss : 0.7461 = 0.6665 + 0.0795 + 0.0001, time: 7.225355]
2023-05-15 10:16:18.911: epoch 8:	0.01821223  	0.13355805  	0.06686028  
2023-05-15 10:16:18.911: Find a better model.
2023-05-15 10:16:25.964: [iter 9 : loss : 0.7141 = 0.6313 + 0.0827 + 0.0001, time: 7.050456]
2023-05-15 10:16:26.118: epoch 9:	0.01886144  	0.13884553  	0.06978067  
2023-05-15 10:16:26.118: Find a better model.
2023-05-15 10:16:32.983: [iter 10 : loss : 0.6576 = 0.5696 + 0.0877 + 0.0002, time: 6.864282]
2023-05-15 10:16:33.138: epoch 10:	0.01867091  	0.13787556  	0.06906294  
2023-05-15 10:16:39.956: [iter 11 : loss : 0.5830 = 0.4898 + 0.0928 + 0.0004, time: 6.816605]
2023-05-15 10:16:40.111: epoch 11:	0.01866385  	0.13772857  	0.06907026  
2023-05-15 10:16:46.952: [iter 12 : loss : 0.5114 = 0.4144 + 0.0965 + 0.0005, time: 6.838744]
2023-05-15 10:16:47.104: epoch 12:	0.01854389  	0.13699627  	0.06936450  
2023-05-15 10:16:53.799: [iter 13 : loss : 0.4575 = 0.3581 + 0.0987 + 0.0007, time: 6.693936]
2023-05-15 10:16:53.952: epoch 13:	0.01864974  	0.13830537  	0.07018151  
2023-05-15 10:17:00.791: [iter 14 : loss : 0.4166 = 0.3160 + 0.0998 + 0.0008, time: 6.837703]
2023-05-15 10:17:00.943: epoch 14:	0.01879793  	0.13997743  	0.07090800  
2023-05-15 10:17:00.943: Find a better model.
2023-05-15 10:17:07.770: [iter 15 : loss : 0.3881 = 0.2869 + 0.1003 + 0.0010, time: 6.826111]
2023-05-15 10:17:07.924: epoch 15:	0.01896023  	0.14090794  	0.07181072  
2023-05-15 10:17:07.924: Find a better model.
2023-05-15 10:17:14.739: [iter 16 : loss : 0.3646 = 0.2632 + 0.1004 + 0.0011, time: 6.812088]
2023-05-15 10:17:14.894: epoch 16:	0.01920721  	0.14231187  	0.07266087  
2023-05-15 10:17:14.894: Find a better model.
2023-05-15 10:17:21.734: [iter 17 : loss : 0.3474 = 0.2459 + 0.1003 + 0.0012, time: 6.839322]
2023-05-15 10:17:21.887: epoch 17:	0.01943302  	0.14416528  	0.07352604  
2023-05-15 10:17:21.887: Find a better model.
2023-05-15 10:17:28.745: [iter 18 : loss : 0.3317 = 0.2303 + 0.1001 + 0.0013, time: 6.856094]
2023-05-15 10:17:28.897: epoch 18:	0.01966588  	0.14550070  	0.07428869  
2023-05-15 10:17:28.897: Find a better model.
2023-05-15 10:17:35.733: [iter 19 : loss : 0.3171 = 0.2160 + 0.0998 + 0.0014, time: 6.835089]
2023-05-15 10:17:35.886: epoch 19:	0.01982113  	0.14634265  	0.07494418  
2023-05-15 10:17:35.886: Find a better model.
2023-05-15 10:17:42.754: [iter 20 : loss : 0.3072 = 0.2063 + 0.0994 + 0.0015, time: 6.866110]
2023-05-15 10:17:42.905: epoch 20:	0.02006811  	0.14801995  	0.07585476  
2023-05-15 10:17:42.905: Find a better model.
2023-05-15 10:17:49.740: [iter 21 : loss : 0.2972 = 0.1966 + 0.0990 + 0.0016, time: 6.834005]
2023-05-15 10:17:49.891: epoch 21:	0.02018808  	0.14908856  	0.07645939  
2023-05-15 10:17:49.891: Find a better model.
2023-05-15 10:17:56.758: [iter 22 : loss : 0.2890 = 0.1888 + 0.0986 + 0.0017, time: 6.865822]
2023-05-15 10:17:56.913: epoch 22:	0.02042800  	0.15091482  	0.07722684  
2023-05-15 10:17:56.913: Find a better model.
2023-05-15 10:18:03.726: [iter 23 : loss : 0.2805 = 0.1806 + 0.0982 + 0.0018, time: 6.811390]
2023-05-15 10:18:03.881: epoch 23:	0.02065380  	0.15274774  	0.07819615  
2023-05-15 10:18:03.881: Find a better model.
2023-05-15 10:18:10.731: [iter 24 : loss : 0.2740 = 0.1744 + 0.0977 + 0.0018, time: 6.849729]
2023-05-15 10:18:10.885: epoch 24:	0.02084433  	0.15387677  	0.07907054  
2023-05-15 10:18:10.885: Find a better model.
2023-05-15 10:18:17.727: [iter 25 : loss : 0.2672 = 0.1679 + 0.0974 + 0.0019, time: 6.839430]
2023-05-15 10:18:17.879: epoch 25:	0.02105602  	0.15496619  	0.07972902  
2023-05-15 10:18:17.880: Find a better model.
2023-05-15 10:18:24.558: [iter 26 : loss : 0.2636 = 0.1647 + 0.0969 + 0.0020, time: 6.676344]
2023-05-15 10:18:24.698: epoch 26:	0.02126773  	0.15636778  	0.08037062  
2023-05-15 10:18:24.698: Find a better model.
2023-05-15 10:18:31.349: [iter 27 : loss : 0.2556 = 0.1571 + 0.0965 + 0.0020, time: 6.650780]
2023-05-15 10:18:31.502: epoch 27:	0.02144413  	0.15723260  	0.08113056  
2023-05-15 10:18:31.502: Find a better model.
2023-05-15 10:18:38.160: [iter 28 : loss : 0.2507 = 0.1524 + 0.0961 + 0.0021, time: 6.657226]
2023-05-15 10:18:38.300: epoch 28:	0.02159938  	0.15859984  	0.08195654  
2023-05-15 10:18:38.300: Find a better model.
2023-05-15 10:18:44.923: [iter 29 : loss : 0.2462 = 0.1483 + 0.0957 + 0.0022, time: 6.622164]
2023-05-15 10:18:45.075: epoch 29:	0.02176167  	0.15990904  	0.08273999  
2023-05-15 10:18:45.076: Find a better model.
2023-05-15 10:18:51.717: [iter 30 : loss : 0.2396 = 0.1420 + 0.0954 + 0.0022, time: 6.640178]
2023-05-15 10:18:51.871: epoch 30:	0.02188163  	0.16085991  	0.08329160  
2023-05-15 10:18:51.871: Find a better model.
2023-05-15 10:18:58.545: [iter 31 : loss : 0.2361 = 0.1388 + 0.0950 + 0.0023, time: 6.671566]
2023-05-15 10:18:58.697: epoch 31:	0.02201570  	0.16188116  	0.08390977  
2023-05-15 10:18:58.697: Find a better model.
2023-05-15 10:19:05.322: [iter 32 : loss : 0.2306 = 0.1336 + 0.0946 + 0.0024, time: 6.623237]
2023-05-15 10:19:05.474: epoch 32:	0.02216389  	0.16322334  	0.08465817  
2023-05-15 10:19:05.475: Find a better model.
2023-05-15 10:19:12.315: [iter 33 : loss : 0.2277 = 0.1311 + 0.0942 + 0.0024, time: 6.839221]
2023-05-15 10:19:12.468: epoch 33:	0.02232619  	0.16480641  	0.08548723  
2023-05-15 10:19:12.468: Find a better model.
2023-05-15 10:19:19.312: [iter 34 : loss : 0.2239 = 0.1275 + 0.0939 + 0.0025, time: 6.842641]
2023-05-15 10:19:19.454: epoch 34:	0.02247438  	0.16636449  	0.08633782  
2023-05-15 10:19:19.454: Find a better model.
2023-05-15 10:19:26.108: [iter 35 : loss : 0.2203 = 0.1242 + 0.0936 + 0.0025, time: 6.651796]
2023-05-15 10:19:26.248: epoch 35:	0.02272136  	0.16826797  	0.08718407  
2023-05-15 10:19:26.249: Find a better model.
2023-05-15 10:19:33.101: [iter 36 : loss : 0.2168 = 0.1210 + 0.0933 + 0.0026, time: 6.849818]
2023-05-15 10:19:33.253: epoch 36:	0.02279898  	0.16897830  	0.08762195  
2023-05-15 10:19:33.253: Find a better model.
2023-05-15 10:19:40.124: [iter 37 : loss : 0.2131 = 0.1175 + 0.0929 + 0.0026, time: 6.869143]
2023-05-15 10:19:40.277: epoch 37:	0.02300362  	0.17044891  	0.08839136  
2023-05-15 10:19:40.277: Find a better model.
2023-05-15 10:19:47.103: [iter 38 : loss : 0.2114 = 0.1161 + 0.0927 + 0.0027, time: 6.824583]
2023-05-15 10:19:47.256: epoch 38:	0.02312358  	0.17135128  	0.08900224  
2023-05-15 10:19:47.256: Find a better model.
2023-05-15 10:19:54.114: [iter 39 : loss : 0.2070 = 0.1119 + 0.0923 + 0.0028, time: 6.857489]
2023-05-15 10:19:54.267: epoch 39:	0.02324353  	0.17223532  	0.08965690  
2023-05-15 10:19:54.267: Find a better model.
2023-05-15 10:20:01.137: [iter 40 : loss : 0.2038 = 0.1089 + 0.0921 + 0.0028, time: 6.868757]
2023-05-15 10:20:01.293: epoch 40:	0.02333527  	0.17263936  	0.09003112  
2023-05-15 10:20:01.293: Find a better model.
2023-05-15 10:20:08.137: [iter 41 : loss : 0.2021 = 0.1074 + 0.0918 + 0.0029, time: 6.842608]
2023-05-15 10:20:08.289: epoch 41:	0.02339877  	0.17299823  	0.09051386  
2023-05-15 10:20:08.289: Find a better model.
2023-05-15 10:20:15.099: [iter 42 : loss : 0.1999 = 0.1055 + 0.0915 + 0.0029, time: 6.808712]
2023-05-15 10:20:15.252: epoch 42:	0.02355401  	0.17392749  	0.09120386  
2023-05-15 10:20:15.252: Find a better model.
2023-05-15 10:20:22.115: [iter 43 : loss : 0.1959 = 0.1017 + 0.0912 + 0.0030, time: 6.861988]
2023-05-15 10:20:22.265: epoch 43:	0.02365986  	0.17464925  	0.09177843  
2023-05-15 10:20:22.265: Find a better model.
2023-05-15 10:20:29.121: [iter 44 : loss : 0.1925 = 0.0986 + 0.0909 + 0.0030, time: 6.855085]
2023-05-15 10:20:29.274: epoch 44:	0.02379393  	0.17551605  	0.09240330  
2023-05-15 10:20:29.274: Find a better model.
2023-05-15 10:20:36.100: [iter 45 : loss : 0.1904 = 0.0966 + 0.0907 + 0.0031, time: 6.823806]
2023-05-15 10:20:36.253: epoch 45:	0.02387861  	0.17633045  	0.09299977  
2023-05-15 10:20:36.254: Find a better model.
2023-05-15 10:20:43.096: [iter 46 : loss : 0.1880 = 0.0944 + 0.0905 + 0.0031, time: 6.840733]
2023-05-15 10:20:43.250: epoch 46:	0.02392801  	0.17619394  	0.09316905  
2023-05-15 10:20:50.082: [iter 47 : loss : 0.1873 = 0.0939 + 0.0902 + 0.0032, time: 6.831316]
2023-05-15 10:20:50.234: epoch 47:	0.02391389  	0.17631434  	0.09335478  
2023-05-15 10:20:57.086: [iter 48 : loss : 0.1832 = 0.0900 + 0.0900 + 0.0032, time: 6.850977]
2023-05-15 10:20:57.238: epoch 48:	0.02399151  	0.17677620  	0.09377203  
2023-05-15 10:20:57.238: Find a better model.
2023-05-15 10:21:04.076: [iter 49 : loss : 0.1804 = 0.0873 + 0.0898 + 0.0033, time: 6.835660]
2023-05-15 10:21:04.227: epoch 49:	0.02409029  	0.17722422  	0.09429441  
2023-05-15 10:21:04.227: Find a better model.
2023-05-15 10:21:11.089: [iter 50 : loss : 0.1795 = 0.0866 + 0.0896 + 0.0033, time: 6.859889]
2023-05-15 10:21:11.239: epoch 50:	0.02414674  	0.17768118  	0.09493487  
2023-05-15 10:21:11.239: Find a better model.
2023-05-15 10:21:18.073: [iter 51 : loss : 0.1765 = 0.0837 + 0.0894 + 0.0034, time: 6.833764]
2023-05-15 10:21:18.213: epoch 51:	0.02414674  	0.17790072  	0.09532306  
2023-05-15 10:21:18.213: Find a better model.
2023-05-15 10:21:25.107: [iter 52 : loss : 0.1765 = 0.0839 + 0.0892 + 0.0034, time: 6.891610]
2023-05-15 10:21:25.260: epoch 52:	0.02419613  	0.17820884  	0.09578757  
2023-05-15 10:21:25.260: Find a better model.
2023-05-15 10:21:32.115: [iter 53 : loss : 0.1744 = 0.0820 + 0.0890 + 0.0035, time: 6.853525]
2023-05-15 10:21:32.267: epoch 53:	0.02430904  	0.17888749  	0.09631467  
2023-05-15 10:21:32.268: Find a better model.
2023-05-15 10:21:39.292: [iter 54 : loss : 0.1724 = 0.0801 + 0.0888 + 0.0035, time: 7.022437]
2023-05-15 10:21:39.445: epoch 54:	0.02435138  	0.17932549  	0.09650636  
2023-05-15 10:21:39.446: Find a better model.
2023-05-15 10:21:46.282: [iter 55 : loss : 0.1704 = 0.0782 + 0.0886 + 0.0036, time: 6.835706]
2023-05-15 10:21:46.435: epoch 55:	0.02442194  	0.17964919  	0.09688538  
2023-05-15 10:21:46.435: Find a better model.
2023-05-15 10:21:53.280: [iter 56 : loss : 0.1687 = 0.0767 + 0.0884 + 0.0036, time: 6.844218]
2023-05-15 10:21:53.434: epoch 56:	0.02449956  	0.18044291  	0.09737106  
2023-05-15 10:21:53.434: Find a better model.
2023-05-15 10:22:00.290: [iter 57 : loss : 0.1670 = 0.0751 + 0.0882 + 0.0037, time: 6.855253]
2023-05-15 10:22:00.444: epoch 57:	0.02464775  	0.18139771  	0.09798419  
2023-05-15 10:22:00.444: Find a better model.
2023-05-15 10:22:07.266: [iter 58 : loss : 0.1649 = 0.0732 + 0.0880 + 0.0037, time: 6.820297]
2023-05-15 10:22:07.419: epoch 58:	0.02466186  	0.18141644  	0.09801491  
2023-05-15 10:22:07.419: Find a better model.
2023-05-15 10:22:14.440: [iter 59 : loss : 0.1639 = 0.0723 + 0.0879 + 0.0038, time: 7.019867]
2023-05-15 10:22:14.592: epoch 59:	0.02472537  	0.18195394  	0.09835517  
2023-05-15 10:22:14.592: Find a better model.
2023-05-15 10:22:21.639: [iter 60 : loss : 0.1625 = 0.0710 + 0.0877 + 0.0038, time: 7.046142]
2023-05-15 10:22:21.791: epoch 60:	0.02480299  	0.18299958  	0.09884916  
2023-05-15 10:22:21.791: Find a better model.
2023-05-15 10:22:28.664: [iter 61 : loss : 0.1613 = 0.0699 + 0.0875 + 0.0038, time: 6.872398]
2023-05-15 10:22:28.818: epoch 61:	0.02490883  	0.18314078  	0.09896050  
2023-05-15 10:22:28.818: Find a better model.
2023-05-15 10:22:35.641: [iter 62 : loss : 0.1597 = 0.0684 + 0.0874 + 0.0039, time: 6.822419]
2023-05-15 10:22:35.794: epoch 62:	0.02493000  	0.18358532  	0.09926102  
2023-05-15 10:22:35.794: Find a better model.
2023-05-15 10:22:42.647: [iter 63 : loss : 0.1583 = 0.0671 + 0.0872 + 0.0039, time: 6.851168]
2023-05-15 10:22:42.800: epoch 63:	0.02495823  	0.18376987  	0.09947890  
2023-05-15 10:22:42.800: Find a better model.
2023-05-15 10:22:49.658: [iter 64 : loss : 0.1572 = 0.0662 + 0.0870 + 0.0040, time: 6.856997]
2023-05-15 10:22:49.810: epoch 64:	0.02504996  	0.18432538  	0.09985718  
2023-05-15 10:22:49.810: Find a better model.
2023-05-15 10:22:56.656: [iter 65 : loss : 0.1562 = 0.0653 + 0.0869 + 0.0040, time: 6.844614]
2023-05-15 10:22:56.806: epoch 65:	0.02516286  	0.18522535  	0.10023005  
2023-05-15 10:22:56.806: Find a better model.
2023-05-15 10:23:03.476: [iter 66 : loss : 0.1545 = 0.0637 + 0.0867 + 0.0041, time: 6.669223]
2023-05-15 10:23:03.629: epoch 66:	0.02521932  	0.18543872  	0.10052367  
2023-05-15 10:23:03.629: Find a better model.
2023-05-15 10:23:10.463: [iter 67 : loss : 0.1530 = 0.0623 + 0.0866 + 0.0041, time: 6.832810]
2023-05-15 10:23:10.615: epoch 67:	0.02526166  	0.18607265  	0.10072666  
2023-05-15 10:23:10.615: Find a better model.
2023-05-15 10:23:17.424: [iter 68 : loss : 0.1525 = 0.0619 + 0.0864 + 0.0042, time: 6.807259]
2023-05-15 10:23:17.576: epoch 68:	0.02535340  	0.18645015  	0.10113826  
2023-05-15 10:23:17.576: Find a better model.
2023-05-15 10:23:24.423: [iter 69 : loss : 0.1508 = 0.0603 + 0.0863 + 0.0042, time: 6.845470]
2023-05-15 10:23:24.576: epoch 69:	0.02545219  	0.18699895  	0.10152565  
2023-05-15 10:23:24.576: Find a better model.
2023-05-15 10:23:31.431: [iter 70 : loss : 0.1493 = 0.0588 + 0.0862 + 0.0042, time: 6.853776]
2023-05-15 10:23:31.585: epoch 70:	0.02555803  	0.18789576  	0.10176394  
2023-05-15 10:23:31.585: Find a better model.
2023-05-15 10:23:38.437: [iter 71 : loss : 0.1479 = 0.0575 + 0.0861 + 0.0043, time: 6.850113]
2023-05-15 10:23:38.589: epoch 71:	0.02556510  	0.18783242  	0.10193385  
2023-05-15 10:23:45.417: [iter 72 : loss : 0.1476 = 0.0573 + 0.0860 + 0.0043, time: 6.826444]
2023-05-15 10:23:45.560: epoch 72:	0.02552276  	0.18749937  	0.10188209  
2023-05-15 10:23:52.402: [iter 73 : loss : 0.1463 = 0.0560 + 0.0858 + 0.0044, time: 6.839108]
2023-05-15 10:23:52.555: epoch 73:	0.02561449  	0.18812522  	0.10213663  
2023-05-15 10:23:52.555: Find a better model.
2023-05-15 10:23:59.420: [iter 74 : loss : 0.1447 = 0.0546 + 0.0857 + 0.0044, time: 6.863186]
2023-05-15 10:23:59.572: epoch 74:	0.02572739  	0.18912153  	0.10250580  
2023-05-15 10:23:59.573: Find a better model.
2023-05-15 10:24:06.426: [iter 75 : loss : 0.1444 = 0.0543 + 0.0856 + 0.0044, time: 6.852759]
2023-05-15 10:24:06.578: epoch 75:	0.02567800  	0.18857475  	0.10275318  
2023-05-15 10:24:13.415: [iter 76 : loss : 0.1434 = 0.0534 + 0.0855 + 0.0045, time: 6.834638]
2023-05-15 10:24:13.568: epoch 76:	0.02579090  	0.18892245  	0.10314836  
2023-05-15 10:24:20.425: [iter 77 : loss : 0.1423 = 0.0524 + 0.0854 + 0.0045, time: 6.855643]
2023-05-15 10:24:20.577: epoch 77:	0.02584735  	0.18951805  	0.10328342  
2023-05-15 10:24:20.577: Find a better model.
2023-05-15 10:24:27.423: [iter 78 : loss : 0.1415 = 0.0517 + 0.0853 + 0.0046, time: 6.845070]
2023-05-15 10:24:27.575: epoch 78:	0.02579090  	0.18910564  	0.10337374  
2023-05-15 10:24:34.439: [iter 79 : loss : 0.1403 = 0.0505 + 0.0852 + 0.0046, time: 6.863452]
2023-05-15 10:24:34.594: epoch 79:	0.02584029  	0.18905862  	0.10348152  
2023-05-15 10:24:41.424: [iter 80 : loss : 0.1394 = 0.0496 + 0.0851 + 0.0046, time: 6.828459]
2023-05-15 10:24:41.577: epoch 80:	0.02589674  	0.18923436  	0.10366833  
2023-05-15 10:24:48.417: [iter 81 : loss : 0.1392 = 0.0496 + 0.0849 + 0.0047, time: 6.838792]
2023-05-15 10:24:48.559: epoch 81:	0.02600965  	0.19023514  	0.10410720  
2023-05-15 10:24:48.560: Find a better model.
2023-05-15 10:24:55.389: [iter 82 : loss : 0.1380 = 0.0485 + 0.0849 + 0.0047, time: 6.828231]
2023-05-15 10:24:55.542: epoch 82:	0.02596731  	0.18987022  	0.10409304  
2023-05-15 10:25:02.228: [iter 83 : loss : 0.1370 = 0.0475 + 0.0848 + 0.0048, time: 6.683274]
2023-05-15 10:25:02.380: epoch 83:	0.02600259  	0.19002768  	0.10430770  
2023-05-15 10:25:09.181: [iter 84 : loss : 0.1371 = 0.0476 + 0.0847 + 0.0048, time: 6.799765]
2023-05-15 10:25:09.335: epoch 84:	0.02606610  	0.19059984  	0.10441433  
2023-05-15 10:25:09.335: Find a better model.
2023-05-15 10:25:16.175: [iter 85 : loss : 0.1359 = 0.0465 + 0.0846 + 0.0048, time: 6.838979]
2023-05-15 10:25:16.329: epoch 85:	0.02609432  	0.19082691  	0.10455538  
2023-05-15 10:25:16.329: Find a better model.
2023-05-15 10:25:23.180: [iter 86 : loss : 0.1358 = 0.0465 + 0.0844 + 0.0049, time: 6.848358]
2023-05-15 10:25:23.324: epoch 86:	0.02609434  	0.19114764  	0.10478637  
2023-05-15 10:25:23.324: Find a better model.
2023-05-15 10:25:30.162: [iter 87 : loss : 0.1331 = 0.0438 + 0.0844 + 0.0049, time: 6.836982]
2023-05-15 10:25:30.305: epoch 87:	0.02620018  	0.19203541  	0.10507582  
2023-05-15 10:25:30.305: Find a better model.
2023-05-15 10:25:37.187: [iter 88 : loss : 0.1326 = 0.0433 + 0.0843 + 0.0050, time: 6.879138]
2023-05-15 10:25:37.339: epoch 88:	0.02619312  	0.19188628  	0.10520995  
2023-05-15 10:25:44.188: [iter 89 : loss : 0.1323 = 0.0431 + 0.0842 + 0.0050, time: 6.848228]
2023-05-15 10:25:44.341: epoch 89:	0.02615078  	0.19186513  	0.10514688  
2023-05-15 10:25:51.173: [iter 90 : loss : 0.1329 = 0.0438 + 0.0841 + 0.0050, time: 6.830103]
2023-05-15 10:25:51.315: epoch 90:	0.02627780  	0.19289796  	0.10536493  
2023-05-15 10:25:51.315: Find a better model.
2023-05-15 10:25:58.185: [iter 91 : loss : 0.1315 = 0.0424 + 0.0840 + 0.0051, time: 6.868598]
2023-05-15 10:25:58.340: epoch 91:	0.02632719  	0.19357517  	0.10552961  
2023-05-15 10:25:58.340: Find a better model.
2023-05-15 10:26:05.199: [iter 92 : loss : 0.1307 = 0.0417 + 0.0839 + 0.0051, time: 6.856766]
2023-05-15 10:26:05.353: epoch 92:	0.02625663  	0.19297044  	0.10553139  
2023-05-15 10:26:12.204: [iter 93 : loss : 0.1311 = 0.0421 + 0.0838 + 0.0052, time: 6.849718]
2023-05-15 10:26:12.358: epoch 93:	0.02634131  	0.19348849  	0.10562505  
2023-05-15 10:26:19.163: [iter 94 : loss : 0.1289 = 0.0399 + 0.0838 + 0.0052, time: 6.804483]
2023-05-15 10:26:19.316: epoch 94:	0.02639070  	0.19438218  	0.10598462  
2023-05-15 10:26:19.316: Find a better model.
2023-05-15 10:26:26.168: [iter 95 : loss : 0.1283 = 0.0394 + 0.0837 + 0.0052, time: 6.851209]
2023-05-15 10:26:26.324: epoch 95:	0.02640481  	0.19454992  	0.10624178  
2023-05-15 10:26:26.324: Find a better model.
2023-05-15 10:26:33.194: [iter 96 : loss : 0.1283 = 0.0394 + 0.0836 + 0.0053, time: 6.869281]
2023-05-15 10:26:33.348: epoch 96:	0.02641893  	0.19484571  	0.10632182  
2023-05-15 10:26:33.348: Find a better model.
2023-05-15 10:26:40.158: [iter 97 : loss : 0.1265 = 0.0377 + 0.0835 + 0.0053, time: 6.809042]
2023-05-15 10:26:40.303: epoch 97:	0.02641187  	0.19484505  	0.10639842  
2023-05-15 10:26:47.174: [iter 98 : loss : 0.1275 = 0.0387 + 0.0835 + 0.0053, time: 6.870471]
2023-05-15 10:26:47.328: epoch 98:	0.02647538  	0.19540805  	0.10667928  
2023-05-15 10:26:47.328: Find a better model.
2023-05-15 10:26:54.153: [iter 99 : loss : 0.1264 = 0.0376 + 0.0834 + 0.0054, time: 6.824331]
2023-05-15 10:26:54.312: epoch 99:	0.02648950  	0.19524771  	0.10663061  
2023-05-15 10:27:01.340: [iter 100 : loss : 0.1258 = 0.0371 + 0.0833 + 0.0054, time: 7.025798]
2023-05-15 10:27:01.493: epoch 100:	0.02648950  	0.19543624  	0.10673890  
2023-05-15 10:27:01.493: Find a better model.
2023-05-15 10:27:08.355: [iter 101 : loss : 0.1254 = 0.0367 + 0.0832 + 0.0054, time: 6.860699]
2023-05-15 10:27:08.510: epoch 101:	0.02644716  	0.19537200  	0.10666617  
2023-05-15 10:27:15.343: [iter 102 : loss : 0.1245 = 0.0358 + 0.0832 + 0.0055, time: 6.832750]
2023-05-15 10:27:15.498: epoch 102:	0.02639776  	0.19503215  	0.10661780  
2023-05-15 10:27:22.333: [iter 103 : loss : 0.1240 = 0.0354 + 0.0831 + 0.0055, time: 6.833384]
2023-05-15 10:27:22.477: epoch 103:	0.02642599  	0.19488713  	0.10670321  
2023-05-15 10:27:29.178: [iter 104 : loss : 0.1245 = 0.0359 + 0.0830 + 0.0056, time: 6.699658]
2023-05-15 10:27:29.329: epoch 104:	0.02651067  	0.19558689  	0.10703450  
2023-05-15 10:27:29.330: Find a better model.
2023-05-15 10:27:36.167: [iter 105 : loss : 0.1239 = 0.0353 + 0.0830 + 0.0056, time: 6.835900]
2023-05-15 10:27:36.311: epoch 105:	0.02646127  	0.19504212  	0.10716414  
2023-05-15 10:27:43.160: [iter 106 : loss : 0.1234 = 0.0349 + 0.0829 + 0.0056, time: 6.848426]
2023-05-15 10:27:43.315: epoch 106:	0.02649655  	0.19506648  	0.10729672  
2023-05-15 10:27:50.128: [iter 107 : loss : 0.1225 = 0.0340 + 0.0829 + 0.0056, time: 6.812253]
2023-05-15 10:27:50.284: epoch 107:	0.02657417  	0.19554432  	0.10763928  
2023-05-15 10:27:57.130: [iter 108 : loss : 0.1222 = 0.0337 + 0.0828 + 0.0057, time: 6.842742]
2023-05-15 10:27:57.283: epoch 108:	0.02660240  	0.19579291  	0.10780282  
2023-05-15 10:27:57.284: Find a better model.
2023-05-15 10:28:04.149: [iter 109 : loss : 0.1210 = 0.0326 + 0.0827 + 0.0057, time: 6.864486]
2023-05-15 10:28:04.304: epoch 109:	0.02668001  	0.19641992  	0.10795920  
2023-05-15 10:28:04.304: Find a better model.
2023-05-15 10:28:11.129: [iter 110 : loss : 0.1203 = 0.0319 + 0.0827 + 0.0058, time: 6.822953]
2023-05-15 10:28:11.271: epoch 110:	0.02654594  	0.19529320  	0.10779332  
2023-05-15 10:28:18.113: [iter 111 : loss : 0.1204 = 0.0320 + 0.0826 + 0.0058, time: 6.839382]
2023-05-15 10:28:18.253: epoch 111:	0.02654595  	0.19560328  	0.10778235  
2023-05-15 10:28:25.112: [iter 112 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 6.857995]
2023-05-15 10:28:25.253: epoch 112:	0.02656006  	0.19574261  	0.10798045  
2023-05-15 10:28:32.117: [iter 113 : loss : 0.1203 = 0.0319 + 0.0825 + 0.0059, time: 6.861968]
2023-05-15 10:28:32.258: epoch 113:	0.02654595  	0.19555745  	0.10794542  
2023-05-15 10:28:39.106: [iter 114 : loss : 0.1194 = 0.0311 + 0.0825 + 0.0059, time: 6.845793]
2023-05-15 10:28:39.248: epoch 114:	0.02654595  	0.19521050  	0.10792416  
2023-05-15 10:28:46.107: [iter 115 : loss : 0.1188 = 0.0305 + 0.0824 + 0.0059, time: 6.855727]
2023-05-15 10:28:46.260: epoch 115:	0.02656711  	0.19551726  	0.10809010  
2023-05-15 10:28:53.127: [iter 116 : loss : 0.1181 = 0.0298 + 0.0824 + 0.0060, time: 6.864968]
2023-05-15 10:28:53.278: epoch 116:	0.02653183  	0.19532728  	0.10810804  
2023-05-15 10:29:00.125: [iter 117 : loss : 0.1180 = 0.0298 + 0.0823 + 0.0060, time: 6.845912]
2023-05-15 10:29:00.266: epoch 117:	0.02666591  	0.19635351  	0.10841101  
2023-05-15 10:29:07.114: [iter 118 : loss : 0.1180 = 0.0298 + 0.0822 + 0.0060, time: 6.846416]
2023-05-15 10:29:07.266: epoch 118:	0.02675059  	0.19709137  	0.10869127  
2023-05-15 10:29:07.266: Find a better model.
2023-05-15 10:29:14.127: [iter 119 : loss : 0.1171 = 0.0289 + 0.0822 + 0.0061, time: 6.859478]
2023-05-15 10:29:14.283: epoch 119:	0.02678587  	0.19738771  	0.10881827  
2023-05-15 10:29:14.283: Find a better model.
2023-05-15 10:29:21.093: [iter 120 : loss : 0.1173 = 0.0291 + 0.0821 + 0.0061, time: 6.808382]
2023-05-15 10:29:21.246: epoch 120:	0.02685643  	0.19805215  	0.10898644  
2023-05-15 10:29:21.246: Find a better model.
2023-05-15 10:29:27.925: [iter 121 : loss : 0.1172 = 0.0290 + 0.0821 + 0.0061, time: 6.677732]
2023-05-15 10:29:28.076: epoch 121:	0.02687760  	0.19829045  	0.10924751  
2023-05-15 10:29:28.076: Find a better model.
2023-05-15 10:29:34.922: [iter 122 : loss : 0.1165 = 0.0283 + 0.0820 + 0.0061, time: 6.844224]
2023-05-15 10:29:35.074: epoch 122:	0.02679998  	0.19758458  	0.10896420  
2023-05-15 10:29:41.883: [iter 123 : loss : 0.1163 = 0.0281 + 0.0820 + 0.0062, time: 6.807921]
2023-05-15 10:29:42.035: epoch 123:	0.02690583  	0.19850692  	0.10923264  
2023-05-15 10:29:42.035: Find a better model.
2023-05-15 10:29:48.899: [iter 124 : loss : 0.1154 = 0.0273 + 0.0820 + 0.0062, time: 6.863105]
2023-05-15 10:29:49.049: epoch 124:	0.02691288  	0.19877884  	0.10941852  
2023-05-15 10:29:49.049: Find a better model.
2023-05-15 10:29:55.881: [iter 125 : loss : 0.1147 = 0.0266 + 0.0819 + 0.0062, time: 6.830892]
2023-05-15 10:29:56.035: epoch 125:	0.02691994  	0.19866091  	0.10947438  
2023-05-15 10:30:02.877: [iter 126 : loss : 0.1151 = 0.0270 + 0.0819 + 0.0063, time: 6.840139]
2023-05-15 10:30:03.029: epoch 126:	0.02689877  	0.19862938  	0.10963202  
2023-05-15 10:30:09.698: [iter 127 : loss : 0.1141 = 0.0259 + 0.0818 + 0.0063, time: 6.667608]
2023-05-15 10:30:09.852: epoch 127:	0.02687760  	0.19880983  	0.10955473  
2023-05-15 10:30:09.852: Find a better model.
2023-05-15 10:30:16.680: [iter 128 : loss : 0.1151 = 0.0270 + 0.0818 + 0.0063, time: 6.827068]
2023-05-15 10:30:16.820: epoch 128:	0.02691994  	0.19895275  	0.10966054  
2023-05-15 10:30:16.820: Find a better model.
2023-05-15 10:30:23.691: [iter 129 : loss : 0.1143 = 0.0262 + 0.0817 + 0.0064, time: 6.869461]
2023-05-15 10:30:23.843: epoch 129:	0.02691288  	0.19878937  	0.10956204  
2023-05-15 10:30:30.715: [iter 130 : loss : 0.1143 = 0.0263 + 0.0817 + 0.0064, time: 6.871244]
2023-05-15 10:30:30.869: epoch 130:	0.02700462  	0.19963709  	0.10994307  
2023-05-15 10:30:30.869: Find a better model.
2023-05-15 10:30:37.712: [iter 131 : loss : 0.1134 = 0.0254 + 0.0816 + 0.0064, time: 6.842182]
2023-05-15 10:30:37.868: epoch 131:	0.02698345  	0.19955099  	0.10996189  
2023-05-15 10:30:44.693: [iter 132 : loss : 0.1136 = 0.0256 + 0.0816 + 0.0065, time: 6.823877]
2023-05-15 10:30:44.849: epoch 132:	0.02698344  	0.19960423  	0.10985263  
2023-05-15 10:30:51.665: [iter 133 : loss : 0.1125 = 0.0244 + 0.0816 + 0.0065, time: 6.814528]
2023-05-15 10:30:51.818: epoch 133:	0.02695521  	0.19877908  	0.10977781  
2023-05-15 10:30:58.659: [iter 134 : loss : 0.1131 = 0.0251 + 0.0815 + 0.0065, time: 6.840369]
2023-05-15 10:30:58.813: epoch 134:	0.02695521  	0.19915393  	0.11002757  
2023-05-15 10:31:05.669: [iter 135 : loss : 0.1128 = 0.0248 + 0.0815 + 0.0065, time: 6.853616]
2023-05-15 10:31:05.821: epoch 135:	0.02694109  	0.19899860  	0.10996620  
2023-05-15 10:31:12.669: [iter 136 : loss : 0.1125 = 0.0245 + 0.0814 + 0.0066, time: 6.846326]
2023-05-15 10:31:12.823: epoch 136:	0.02691287  	0.19858463  	0.10993581  
2023-05-15 10:31:19.648: [iter 137 : loss : 0.1121 = 0.0241 + 0.0814 + 0.0066, time: 6.824355]
2023-05-15 10:31:19.791: epoch 137:	0.02689876  	0.19864792  	0.10982493  
2023-05-15 10:31:26.634: [iter 138 : loss : 0.1118 = 0.0238 + 0.0813 + 0.0066, time: 6.841223]
2023-05-15 10:31:26.776: epoch 138:	0.02687053  	0.19822596  	0.10980456  
2023-05-15 10:31:33.656: [iter 139 : loss : 0.1116 = 0.0236 + 0.0813 + 0.0067, time: 6.879217]
2023-05-15 10:31:33.811: epoch 139:	0.02687759  	0.19848888  	0.10992634  
2023-05-15 10:31:40.476: [iter 140 : loss : 0.1110 = 0.0230 + 0.0813 + 0.0067, time: 6.663216]
2023-05-15 10:31:40.632: epoch 140:	0.02689876  	0.19837876  	0.10988221  
2023-05-15 10:31:47.464: [iter 141 : loss : 0.1114 = 0.0235 + 0.0812 + 0.0067, time: 6.830138]
2023-05-15 10:31:47.620: epoch 141:	0.02696932  	0.19905439  	0.11013574  
2023-05-15 10:31:54.454: [iter 142 : loss : 0.1108 = 0.0229 + 0.0812 + 0.0067, time: 6.833614]
2023-05-15 10:31:54.611: epoch 142:	0.02696932  	0.19937925  	0.11020782  
2023-05-15 10:32:01.459: [iter 143 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0068, time: 6.846599]
2023-05-15 10:32:01.616: epoch 143:	0.02696932  	0.19911304  	0.11011031  
2023-05-15 10:32:08.463: [iter 144 : loss : 0.1102 = 0.0223 + 0.0811 + 0.0068, time: 6.845109]
2023-05-15 10:32:08.622: epoch 144:	0.02687053  	0.19839194  	0.10976958  
2023-05-15 10:32:15.470: [iter 145 : loss : 0.1100 = 0.0221 + 0.0811 + 0.0068, time: 6.847300]
2023-05-15 10:32:15.617: epoch 145:	0.02684231  	0.19815493  	0.10974084  
2023-05-15 10:32:22.448: [iter 146 : loss : 0.1106 = 0.0227 + 0.0811 + 0.0068, time: 6.829395]
2023-05-15 10:32:22.601: epoch 146:	0.02680703  	0.19788302  	0.10961007  
2023-05-15 10:32:29.439: [iter 147 : loss : 0.1103 = 0.0224 + 0.0810 + 0.0069, time: 6.837190]
2023-05-15 10:32:29.592: epoch 147:	0.02677880  	0.19779247  	0.10974064  
2023-05-15 10:32:36.481: [iter 148 : loss : 0.1089 = 0.0210 + 0.0810 + 0.0069, time: 6.887334]
2023-05-15 10:32:36.641: epoch 148:	0.02682820  	0.19846223  	0.10983767  
2023-05-15 10:32:43.435: [iter 149 : loss : 0.1095 = 0.0216 + 0.0809 + 0.0069, time: 6.793176]
2023-05-15 10:32:43.586: epoch 149:	0.02680703  	0.19818357  	0.10985494  
2023-05-15 10:32:50.436: [iter 150 : loss : 0.1090 = 0.0211 + 0.0809 + 0.0070, time: 6.848828]
2023-05-15 10:32:50.588: epoch 150:	0.02689876  	0.19872873  	0.11018261  
2023-05-15 10:32:57.431: [iter 151 : loss : 0.1090 = 0.0211 + 0.0809 + 0.0070, time: 6.841174]
2023-05-15 10:32:57.585: epoch 151:	0.02686347  	0.19856562  	0.11014399  
2023-05-15 10:33:04.426: [iter 152 : loss : 0.1084 = 0.0205 + 0.0809 + 0.0070, time: 6.838736]
2023-05-15 10:33:04.579: epoch 152:	0.02680703  	0.19816139  	0.11000319  
2023-05-15 10:33:11.242: [iter 153 : loss : 0.1076 = 0.0197 + 0.0808 + 0.0070, time: 6.661999]
2023-05-15 10:33:11.394: epoch 153:	0.02682819  	0.19834685  	0.11014809  
2023-05-15 10:33:18.223: [iter 154 : loss : 0.1079 = 0.0200 + 0.0808 + 0.0071, time: 6.827176]
2023-05-15 10:33:18.374: epoch 154:	0.02685642  	0.19851488  	0.11026927  
2023-05-15 10:33:25.222: [iter 155 : loss : 0.1086 = 0.0207 + 0.0808 + 0.0071, time: 6.846479]
2023-05-15 10:33:25.374: epoch 155:	0.02694815  	0.19933219  	0.11031380  
2023-05-15 10:33:25.374: Early stopping is trigger at epoch: 155
2023-05-15 10:33:25.374: best_result@epoch 130:

2023-05-15 10:33:25.374: 		0.0270      	0.1996      	0.1099      
2023-05-15 10:42:48.478: my pid: 10980
2023-05-15 10:42:48.478: model: model.general_recommender.SGL
2023-05-15 10:42:48.478: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 10:42:48.478: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 10:42:51.766: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 10:42:59.464: [iter 1 : loss : 0.7705 = 0.6930 + 0.0775 + 0.0000, time: 7.697831]
2023-05-15 10:42:59.618: epoch 1:	0.00173582  	0.01198607  	0.00588008  
2023-05-15 10:42:59.618: Find a better model.
2023-05-15 10:43:07.459: [iter 2 : loss : 0.7700 = 0.6929 + 0.0771 + 0.0000, time: 7.839866]
2023-05-15 10:43:07.653: epoch 2:	0.00290714  	0.02075519  	0.01077855  
2023-05-15 10:43:07.653: Find a better model.
2023-05-15 10:43:15.437: [iter 3 : loss : 0.7698 = 0.6927 + 0.0771 + 0.0000, time: 7.783099]
2023-05-15 10:43:15.619: epoch 3:	0.00516509  	0.03614920  	0.01817844  
2023-05-15 10:43:15.619: Find a better model.
2023-05-15 10:43:23.228: [iter 4 : loss : 0.7694 = 0.6923 + 0.0771 + 0.0000, time: 7.606213]
2023-05-15 10:43:23.389: epoch 4:	0.00742303  	0.05241352  	0.02580732  
2023-05-15 10:43:23.389: Find a better model.
2023-05-15 10:43:30.830: [iter 5 : loss : 0.7685 = 0.6914 + 0.0771 + 0.0000, time: 7.439644]
2023-05-15 10:43:30.973: epoch 5:	0.01018908  	0.07241035  	0.03480626  
2023-05-15 10:43:30.973: Find a better model.
2023-05-15 10:43:38.418: [iter 6 : loss : 0.7666 = 0.6892 + 0.0773 + 0.0000, time: 7.444107]
2023-05-15 10:43:38.579: epoch 6:	0.01298343  	0.09293777  	0.04496445  
2023-05-15 10:43:38.579: Find a better model.
2023-05-15 10:43:45.804: [iter 7 : loss : 0.7614 = 0.6836 + 0.0778 + 0.0000, time: 7.222944]
2023-05-15 10:43:45.959: epoch 7:	0.01590479  	0.11452972  	0.05610172  
2023-05-15 10:43:45.959: Find a better model.
2023-05-15 10:43:53.014: [iter 8 : loss : 0.7487 = 0.6696 + 0.0791 + 0.0001, time: 7.053776]
2023-05-15 10:43:53.166: epoch 8:	0.01768300  	0.12888007  	0.06473136  
2023-05-15 10:43:53.166: Find a better model.
2023-05-15 10:44:00.016: [iter 9 : loss : 0.7198 = 0.6378 + 0.0819 + 0.0001, time: 6.849185]
2023-05-15 10:44:00.169: epoch 9:	0.01855801  	0.13611266  	0.06863328  
2023-05-15 10:44:00.169: Find a better model.
2023-05-15 10:44:07.011: [iter 10 : loss : 0.6672 = 0.5803 + 0.0866 + 0.0002, time: 6.840145]
2023-05-15 10:44:07.166: epoch 10:	0.01855096  	0.13667108  	0.06861342  
2023-05-15 10:44:07.166: Find a better model.
2023-05-15 10:44:13.998: [iter 11 : loss : 0.5944 = 0.5023 + 0.0918 + 0.0004, time: 6.830545]
2023-05-15 10:44:14.142: epoch 11:	0.01852978  	0.13741775  	0.06857768  
2023-05-15 10:44:14.142: Find a better model.
2023-05-15 10:44:20.977: [iter 12 : loss : 0.5212 = 0.4250 + 0.0957 + 0.0005, time: 6.833510]
2023-05-15 10:44:21.131: epoch 12:	0.01849450  	0.13670723  	0.06886412  
2023-05-15 10:44:27.982: [iter 13 : loss : 0.4647 = 0.3659 + 0.0981 + 0.0007, time: 6.849853]
2023-05-15 10:44:28.136: epoch 13:	0.01847333  	0.13665718  	0.06932063  
2023-05-15 10:44:34.979: [iter 14 : loss : 0.4217 = 0.3215 + 0.0994 + 0.0008, time: 6.840883]
2023-05-15 10:44:35.132: epoch 14:	0.01867091  	0.13846865  	0.07023066  
2023-05-15 10:44:35.132: Find a better model.
2023-05-15 10:44:41.697: [iter 15 : loss : 0.3917 = 0.2908 + 0.1000 + 0.0010, time: 6.563550]
2023-05-15 10:44:41.856: epoch 15:	0.01882615  	0.13978906  	0.07096060  
2023-05-15 10:44:41.856: Find a better model.
2023-05-15 10:44:48.585: [iter 16 : loss : 0.3674 = 0.2662 + 0.1001 + 0.0011, time: 6.727791]
2023-05-15 10:44:48.738: epoch 16:	0.01902374  	0.14090241  	0.07157691  
2023-05-15 10:44:48.738: Find a better model.
2023-05-15 10:44:55.394: [iter 17 : loss : 0.3495 = 0.2482 + 0.1001 + 0.0012, time: 6.653840]
2023-05-15 10:44:55.548: epoch 17:	0.01927072  	0.14293292  	0.07266243  
2023-05-15 10:44:55.548: Find a better model.
2023-05-15 10:45:02.193: [iter 18 : loss : 0.3333 = 0.2322 + 0.0999 + 0.0013, time: 6.644729]
2023-05-15 10:45:02.346: epoch 18:	0.01953181  	0.14467686  	0.07361151  
2023-05-15 10:45:02.346: Find a better model.
2023-05-15 10:45:09.011: [iter 19 : loss : 0.3185 = 0.2175 + 0.0996 + 0.0014, time: 6.663397]
2023-05-15 10:45:09.164: epoch 19:	0.01974351  	0.14575815  	0.07449006  
2023-05-15 10:45:09.165: Find a better model.
2023-05-15 10:45:15.977: [iter 20 : loss : 0.3084 = 0.2076 + 0.0992 + 0.0015, time: 6.811075]
2023-05-15 10:45:16.131: epoch 20:	0.01996227  	0.14732750  	0.07540318  
2023-05-15 10:45:16.131: Find a better model.
2023-05-15 10:45:22.963: [iter 21 : loss : 0.2982 = 0.1977 + 0.0989 + 0.0016, time: 6.830487]
2023-05-15 10:45:23.116: epoch 21:	0.02030098  	0.14988160  	0.07630743  
2023-05-15 10:45:23.116: Find a better model.
2023-05-15 10:45:29.979: [iter 22 : loss : 0.2897 = 0.1896 + 0.0985 + 0.0017, time: 6.861769]
2023-05-15 10:45:30.132: epoch 22:	0.02047739  	0.15101387  	0.07685542  
2023-05-15 10:45:30.132: Find a better model.
2023-05-15 10:45:36.959: [iter 23 : loss : 0.2812 = 0.1814 + 0.0981 + 0.0017, time: 6.825225]
2023-05-15 10:45:37.112: epoch 23:	0.02061145  	0.15193360  	0.07759888  
2023-05-15 10:45:37.112: Find a better model.
2023-05-15 10:45:43.778: [iter 24 : loss : 0.2747 = 0.1753 + 0.0976 + 0.0018, time: 6.663933]
2023-05-15 10:45:43.935: epoch 24:	0.02090783  	0.15381058  	0.07858546  
2023-05-15 10:45:43.935: Find a better model.
2023-05-15 10:45:50.770: [iter 25 : loss : 0.2678 = 0.1686 + 0.0972 + 0.0019, time: 6.833415]
2023-05-15 10:45:50.928: epoch 25:	0.02111953  	0.15526766  	0.07938400  
2023-05-15 10:45:50.928: Find a better model.
2023-05-15 10:45:57.764: [iter 26 : loss : 0.2640 = 0.1653 + 0.0968 + 0.0020, time: 6.835047]
2023-05-15 10:45:57.920: epoch 26:	0.02122538  	0.15597749  	0.08003828  
2023-05-15 10:45:57.920: Find a better model.
2023-05-15 10:46:04.767: [iter 27 : loss : 0.2560 = 0.1576 + 0.0964 + 0.0020, time: 6.846650]
2023-05-15 10:46:04.925: epoch 27:	0.02143002  	0.15733187  	0.08088651  
2023-05-15 10:46:04.925: Find a better model.
2023-05-15 10:46:11.748: [iter 28 : loss : 0.2511 = 0.1530 + 0.0960 + 0.0021, time: 6.820524]
2023-05-15 10:46:11.903: epoch 28:	0.02162055  	0.15903632  	0.08181478  
2023-05-15 10:46:11.903: Find a better model.
2023-05-15 10:46:18.742: [iter 29 : loss : 0.2465 = 0.1488 + 0.0956 + 0.0022, time: 6.838439]
2023-05-15 10:46:18.895: epoch 29:	0.02167700  	0.15941809  	0.08220277  
2023-05-15 10:46:18.895: Find a better model.
2023-05-15 10:46:25.578: [iter 30 : loss : 0.2399 = 0.1424 + 0.0953 + 0.0022, time: 6.681556]
2023-05-15 10:46:25.737: epoch 30:	0.02177579  	0.16039766  	0.08283568  
2023-05-15 10:46:25.737: Find a better model.
2023-05-15 10:46:32.546: [iter 31 : loss : 0.2364 = 0.1393 + 0.0948 + 0.0023, time: 6.807379]
2023-05-15 10:46:32.701: epoch 31:	0.02181106  	0.16039300  	0.08318657  
2023-05-15 10:46:39.546: [iter 32 : loss : 0.2309 = 0.1340 + 0.0945 + 0.0024, time: 6.843550]
2023-05-15 10:46:39.687: epoch 32:	0.02191691  	0.16137198  	0.08374549  
2023-05-15 10:46:39.687: Find a better model.
2023-05-15 10:46:46.362: [iter 33 : loss : 0.2280 = 0.1315 + 0.0941 + 0.0024, time: 6.673811]
2023-05-15 10:46:46.518: epoch 33:	0.02218505  	0.16315860  	0.08456828  
2023-05-15 10:46:46.518: Find a better model.
2023-05-15 10:46:53.361: [iter 34 : loss : 0.2241 = 0.1279 + 0.0938 + 0.0025, time: 6.841852]
2023-05-15 10:46:53.515: epoch 34:	0.02241086  	0.16493282  	0.08548698  
2023-05-15 10:46:53.515: Find a better model.
2023-05-15 10:47:00.365: [iter 35 : loss : 0.2205 = 0.1245 + 0.0935 + 0.0025, time: 6.849104]
2023-05-15 10:47:00.519: epoch 35:	0.02256611  	0.16624895  	0.08629712  
2023-05-15 10:47:00.519: Find a better model.
2023-05-15 10:47:07.335: [iter 36 : loss : 0.2170 = 0.1213 + 0.0932 + 0.0026, time: 6.814995]
2023-05-15 10:47:07.478: epoch 36:	0.02274958  	0.16772133  	0.08706711  
2023-05-15 10:47:07.478: Find a better model.
2023-05-15 10:47:14.325: [iter 37 : loss : 0.2133 = 0.1178 + 0.0928 + 0.0027, time: 6.846061]
2023-05-15 10:47:14.480: epoch 37:	0.02283425  	0.16886032  	0.08769009  
2023-05-15 10:47:14.480: Find a better model.
2023-05-15 10:47:21.338: [iter 38 : loss : 0.2115 = 0.1163 + 0.0925 + 0.0027, time: 6.857093]
2023-05-15 10:47:21.490: epoch 38:	0.02301067  	0.17028998  	0.08850464  
2023-05-15 10:47:21.490: Find a better model.
2023-05-15 10:47:28.326: [iter 39 : loss : 0.2072 = 0.1122 + 0.0922 + 0.0028, time: 6.834369]
2023-05-15 10:47:28.466: epoch 39:	0.02319414  	0.17158316  	0.08925200  
2023-05-15 10:47:28.466: Find a better model.
2023-05-15 10:47:35.325: [iter 40 : loss : 0.2039 = 0.1092 + 0.0919 + 0.0028, time: 6.857678]
2023-05-15 10:47:35.479: epoch 40:	0.02329293  	0.17245667  	0.08974943  
2023-05-15 10:47:35.479: Find a better model.
2023-05-15 10:47:42.322: [iter 41 : loss : 0.2023 = 0.1077 + 0.0917 + 0.0029, time: 6.842716]
2023-05-15 10:47:42.477: epoch 41:	0.02342700  	0.17311625  	0.09044185  
2023-05-15 10:47:42.477: Find a better model.
2023-05-15 10:47:49.333: [iter 42 : loss : 0.2000 = 0.1057 + 0.0914 + 0.0029, time: 6.853638]
2023-05-15 10:47:49.488: epoch 42:	0.02350462  	0.17352992  	0.09096524  
2023-05-15 10:47:49.488: Find a better model.
2023-05-15 10:47:56.326: [iter 43 : loss : 0.1960 = 0.1019 + 0.0911 + 0.0030, time: 6.837257]
2023-05-15 10:47:56.480: epoch 43:	0.02365986  	0.17458090  	0.09164588  
2023-05-15 10:47:56.480: Find a better model.
2023-05-15 10:48:03.314: [iter 44 : loss : 0.1926 = 0.0988 + 0.0908 + 0.0030, time: 6.833488]
2023-05-15 10:48:03.469: epoch 44:	0.02372337  	0.17484756  	0.09223677  
2023-05-15 10:48:03.469: Find a better model.
2023-05-15 10:48:10.302: [iter 45 : loss : 0.1906 = 0.0969 + 0.0906 + 0.0031, time: 6.831882]
2023-05-15 10:48:10.455: epoch 45:	0.02382921  	0.17567277  	0.09280315  
2023-05-15 10:48:10.455: Find a better model.
2023-05-15 10:48:17.128: [iter 46 : loss : 0.1881 = 0.0946 + 0.0903 + 0.0031, time: 6.670577]
2023-05-15 10:48:17.281: epoch 46:	0.02392095  	0.17619775  	0.09332448  
2023-05-15 10:48:17.281: Find a better model.
2023-05-15 10:48:24.111: [iter 47 : loss : 0.1873 = 0.0940 + 0.0901 + 0.0032, time: 6.829785]
2023-05-15 10:48:24.268: epoch 47:	0.02397034  	0.17640786  	0.09361964  
2023-05-15 10:48:24.268: Find a better model.
2023-05-15 10:48:31.095: [iter 48 : loss : 0.1834 = 0.0903 + 0.0898 + 0.0032, time: 6.826016]
2023-05-15 10:48:31.250: epoch 48:	0.02402679  	0.17683187  	0.09392714  
2023-05-15 10:48:31.250: Find a better model.
2023-05-15 10:48:38.092: [iter 49 : loss : 0.1804 = 0.0875 + 0.0897 + 0.0033, time: 6.840120]
2023-05-15 10:48:38.246: epoch 49:	0.02417498  	0.17785233  	0.09471633  
2023-05-15 10:48:38.246: Find a better model.
2023-05-15 10:48:44.929: [iter 50 : loss : 0.1795 = 0.0867 + 0.0894 + 0.0033, time: 6.682549]
2023-05-15 10:48:45.082: epoch 50:	0.02416087  	0.17773129  	0.09501480  
2023-05-15 10:48:51.899: [iter 51 : loss : 0.1765 = 0.0839 + 0.0892 + 0.0034, time: 6.815935]
2023-05-15 10:48:52.043: epoch 51:	0.02418909  	0.17802720  	0.09533887  
2023-05-15 10:48:52.043: Find a better model.
2023-05-15 10:48:58.890: [iter 52 : loss : 0.1765 = 0.0840 + 0.0890 + 0.0034, time: 6.844703]
2023-05-15 10:48:59.033: epoch 52:	0.02423848  	0.17812696  	0.09559844  
2023-05-15 10:48:59.033: Find a better model.
2023-05-15 10:49:05.713: [iter 53 : loss : 0.1745 = 0.0822 + 0.0888 + 0.0035, time: 6.679409]
2023-05-15 10:49:05.868: epoch 53:	0.02435139  	0.17926101  	0.09632744  
2023-05-15 10:49:05.868: Find a better model.
2023-05-15 10:49:12.512: [iter 54 : loss : 0.1723 = 0.0802 + 0.0886 + 0.0035, time: 6.642777]
2023-05-15 10:49:12.669: epoch 54:	0.02452074  	0.18058048  	0.09681532  
2023-05-15 10:49:12.669: Find a better model.
2023-05-15 10:49:19.306: [iter 55 : loss : 0.1704 = 0.0784 + 0.0884 + 0.0036, time: 6.635787]
2023-05-15 10:49:19.460: epoch 55:	0.02451368  	0.18046759  	0.09702078  
2023-05-15 10:49:26.280: [iter 56 : loss : 0.1687 = 0.0769 + 0.0882 + 0.0036, time: 6.819407]
2023-05-15 10:49:26.432: epoch 56:	0.02452779  	0.18069412  	0.09718066  
2023-05-15 10:49:26.433: Find a better model.
2023-05-15 10:49:33.104: [iter 57 : loss : 0.1670 = 0.0752 + 0.0881 + 0.0037, time: 6.670028]
2023-05-15 10:49:33.257: epoch 57:	0.02452779  	0.18100454  	0.09735053  
2023-05-15 10:49:33.257: Find a better model.
2023-05-15 10:49:40.062: [iter 58 : loss : 0.1649 = 0.0733 + 0.0879 + 0.0037, time: 6.803466]
2023-05-15 10:49:40.204: epoch 58:	0.02465481  	0.18204936  	0.09789571  
2023-05-15 10:49:40.204: Find a better model.
2023-05-15 10:49:46.904: [iter 59 : loss : 0.1639 = 0.0725 + 0.0877 + 0.0038, time: 6.699806]
2023-05-15 10:49:47.058: epoch 59:	0.02479594  	0.18298665  	0.09845350  
2023-05-15 10:49:47.058: Find a better model.
2023-05-15 10:49:54.059: [iter 60 : loss : 0.1625 = 0.0711 + 0.0876 + 0.0038, time: 6.999916]
2023-05-15 10:49:54.201: epoch 60:	0.02484533  	0.18331183  	0.09868126  
2023-05-15 10:49:54.201: Find a better model.
2023-05-15 10:50:01.082: [iter 61 : loss : 0.1614 = 0.0702 + 0.0874 + 0.0039, time: 6.880249]
2023-05-15 10:50:01.237: epoch 61:	0.02483828  	0.18312091  	0.09894620  
2023-05-15 10:50:08.086: [iter 62 : loss : 0.1596 = 0.0685 + 0.0872 + 0.0039, time: 6.847232]
2023-05-15 10:50:08.239: epoch 62:	0.02485239  	0.18298520  	0.09904379  
2023-05-15 10:50:15.084: [iter 63 : loss : 0.1583 = 0.0673 + 0.0871 + 0.0039, time: 6.843476]
2023-05-15 10:50:15.238: epoch 63:	0.02501469  	0.18430233  	0.09964713  
2023-05-15 10:50:15.238: Find a better model.
2023-05-15 10:50:22.084: [iter 64 : loss : 0.1573 = 0.0664 + 0.0869 + 0.0040, time: 6.844427]
2023-05-15 10:50:22.236: epoch 64:	0.02504292  	0.18465090  	0.09978215  
2023-05-15 10:50:22.236: Find a better model.
2023-05-15 10:50:29.071: [iter 65 : loss : 0.1562 = 0.0655 + 0.0868 + 0.0040, time: 6.832627]
2023-05-15 10:50:29.223: epoch 65:	0.02514170  	0.18519884  	0.10034721  
2023-05-15 10:50:29.224: Find a better model.
2023-05-15 10:50:36.084: [iter 66 : loss : 0.1546 = 0.0639 + 0.0866 + 0.0041, time: 6.858280]
2023-05-15 10:50:36.237: epoch 66:	0.02516287  	0.18532756  	0.10054614  
2023-05-15 10:50:36.237: Find a better model.
2023-05-15 10:50:43.067: [iter 67 : loss : 0.1530 = 0.0624 + 0.0865 + 0.0041, time: 6.828237]
2023-05-15 10:50:43.222: epoch 67:	0.02524049  	0.18588956  	0.10077885  
2023-05-15 10:50:43.223: Find a better model.
2023-05-15 10:50:50.078: [iter 68 : loss : 0.1526 = 0.0621 + 0.0863 + 0.0042, time: 6.854348]
2023-05-15 10:50:50.232: epoch 68:	0.02531106  	0.18608783  	0.10118326  
2023-05-15 10:50:50.232: Find a better model.
2023-05-15 10:50:57.054: [iter 69 : loss : 0.1507 = 0.0604 + 0.0862 + 0.0042, time: 6.819366]
2023-05-15 10:50:57.208: epoch 69:	0.02538868  	0.18664527  	0.10156895  
2023-05-15 10:50:57.208: Find a better model.
2023-05-15 10:51:04.046: [iter 70 : loss : 0.1493 = 0.0590 + 0.0861 + 0.0042, time: 6.837686]
2023-05-15 10:51:04.199: epoch 70:	0.02540985  	0.18683934  	0.10160219  
2023-05-15 10:51:04.199: Find a better model.
2023-05-15 10:51:11.074: [iter 71 : loss : 0.1478 = 0.0576 + 0.0859 + 0.0043, time: 6.873915]
2023-05-15 10:51:11.229: epoch 71:	0.02548747  	0.18773152  	0.10197628  
2023-05-15 10:51:11.229: Find a better model.
2023-05-15 10:51:18.057: [iter 72 : loss : 0.1476 = 0.0574 + 0.0858 + 0.0043, time: 6.826968]
2023-05-15 10:51:18.211: epoch 72:	0.02560037  	0.18844816  	0.10246922  
2023-05-15 10:51:18.212: Find a better model.
2023-05-15 10:51:25.049: [iter 73 : loss : 0.1463 = 0.0562 + 0.0857 + 0.0044, time: 6.836354]
2023-05-15 10:51:25.202: epoch 73:	0.02554392  	0.18795210  	0.10233676  
2023-05-15 10:51:32.054: [iter 74 : loss : 0.1446 = 0.0546 + 0.0856 + 0.0044, time: 6.850317]
2023-05-15 10:51:32.198: epoch 74:	0.02564271  	0.18894899  	0.10281324  
2023-05-15 10:51:32.198: Find a better model.
2023-05-15 10:51:39.036: [iter 75 : loss : 0.1443 = 0.0544 + 0.0855 + 0.0045, time: 6.836044]
2023-05-15 10:51:39.190: epoch 75:	0.02572739  	0.18971932  	0.10314263  
2023-05-15 10:51:39.191: Find a better model.
2023-05-15 10:51:46.045: [iter 76 : loss : 0.1434 = 0.0535 + 0.0853 + 0.0045, time: 6.852676]
2023-05-15 10:51:46.200: epoch 76:	0.02572033  	0.18979883  	0.10323244  
2023-05-15 10:51:46.200: Find a better model.
2023-05-15 10:51:53.032: [iter 77 : loss : 0.1423 = 0.0526 + 0.0852 + 0.0045, time: 6.829919]
2023-05-15 10:51:53.188: epoch 77:	0.02574151  	0.18996759  	0.10350466  
2023-05-15 10:51:53.188: Find a better model.
2023-05-15 10:52:00.041: [iter 78 : loss : 0.1415 = 0.0518 + 0.0851 + 0.0046, time: 6.851089]
2023-05-15 10:52:00.194: epoch 78:	0.02583324  	0.19079632  	0.10376334  
2023-05-15 10:52:00.194: Find a better model.
2023-05-15 10:52:07.038: [iter 79 : loss : 0.1402 = 0.0506 + 0.0850 + 0.0046, time: 6.843098]
2023-05-15 10:52:07.191: epoch 79:	0.02589674  	0.19108534  	0.10395088  
2023-05-15 10:52:07.191: Find a better model.
2023-05-15 10:52:14.026: [iter 80 : loss : 0.1393 = 0.0498 + 0.0849 + 0.0047, time: 6.832652]
2023-05-15 10:52:14.182: epoch 80:	0.02588263  	0.19113488  	0.10386890  
2023-05-15 10:52:14.182: Find a better model.
2023-05-15 10:52:21.032: [iter 81 : loss : 0.1392 = 0.0497 + 0.0848 + 0.0047, time: 6.848978]
2023-05-15 10:52:21.188: epoch 81:	0.02590380  	0.19109468  	0.10392897  
2023-05-15 10:52:28.025: [iter 82 : loss : 0.1380 = 0.0486 + 0.0847 + 0.0047, time: 6.836324]
2023-05-15 10:52:28.180: epoch 82:	0.02602376  	0.19171298  	0.10428697  
2023-05-15 10:52:28.180: Find a better model.
2023-05-15 10:52:35.019: [iter 83 : loss : 0.1370 = 0.0476 + 0.0846 + 0.0048, time: 6.837647]
2023-05-15 10:52:35.162: epoch 83:	0.02608727  	0.19244510  	0.10461498  
2023-05-15 10:52:35.163: Find a better model.
2023-05-15 10:52:42.026: [iter 84 : loss : 0.1370 = 0.0477 + 0.0845 + 0.0048, time: 6.862102]
2023-05-15 10:52:42.181: epoch 84:	0.02613667  	0.19270098  	0.10481937  
2023-05-15 10:52:42.181: Find a better model.
2023-05-15 10:52:49.034: [iter 85 : loss : 0.1359 = 0.0467 + 0.0844 + 0.0049, time: 6.851839]
2023-05-15 10:52:49.175: epoch 85:	0.02615784  	0.19277036  	0.10495158  
2023-05-15 10:52:49.175: Find a better model.
2023-05-15 10:52:56.201: [iter 86 : loss : 0.1358 = 0.0466 + 0.0843 + 0.0049, time: 7.025245]
2023-05-15 10:52:56.358: epoch 86:	0.02621428  	0.19281264  	0.10499539  
2023-05-15 10:52:56.358: Find a better model.
2023-05-15 10:53:03.226: [iter 87 : loss : 0.1330 = 0.0439 + 0.0842 + 0.0049, time: 6.867246]
2023-05-15 10:53:03.381: epoch 87:	0.02626368  	0.19344282  	0.10528801  
2023-05-15 10:53:03.381: Find a better model.
2023-05-15 10:53:10.225: [iter 88 : loss : 0.1324 = 0.0433 + 0.0841 + 0.0050, time: 6.841867]
2023-05-15 10:53:10.378: epoch 88:	0.02635541  	0.19421633  	0.10540084  
2023-05-15 10:53:10.378: Find a better model.
2023-05-15 10:53:17.394: [iter 89 : loss : 0.1322 = 0.0432 + 0.0840 + 0.0050, time: 7.014366]
2023-05-15 10:53:17.547: epoch 89:	0.02633424  	0.19363534  	0.10518260  
2023-05-15 10:53:24.418: [iter 90 : loss : 0.1329 = 0.0439 + 0.0839 + 0.0050, time: 6.868877]
2023-05-15 10:53:24.570: epoch 90:	0.02631308  	0.19352913  	0.10546449  
2023-05-15 10:53:31.421: [iter 91 : loss : 0.1314 = 0.0425 + 0.0838 + 0.0051, time: 6.850097]
2023-05-15 10:53:31.574: epoch 91:	0.02636247  	0.19396324  	0.10578349  
2023-05-15 10:53:38.424: [iter 92 : loss : 0.1307 = 0.0418 + 0.0838 + 0.0051, time: 6.848786]
2023-05-15 10:53:38.576: epoch 92:	0.02632014  	0.19339383  	0.10557173  
2023-05-15 10:53:45.413: [iter 93 : loss : 0.1311 = 0.0422 + 0.0837 + 0.0052, time: 6.836082]
2023-05-15 10:53:45.567: epoch 93:	0.02632013  	0.19345081  	0.10562339  
2023-05-15 10:53:52.408: [iter 94 : loss : 0.1288 = 0.0399 + 0.0836 + 0.0052, time: 6.839921]
2023-05-15 10:53:52.562: epoch 94:	0.02632013  	0.19387311  	0.10587381  
2023-05-15 10:53:59.405: [iter 95 : loss : 0.1282 = 0.0394 + 0.0835 + 0.0052, time: 6.840917]
2023-05-15 10:53:59.559: epoch 95:	0.02636247  	0.19439663  	0.10600861  
2023-05-15 10:53:59.559: Find a better model.
2023-05-15 10:54:06.404: [iter 96 : loss : 0.1282 = 0.0395 + 0.0835 + 0.0053, time: 6.844167]
2023-05-15 10:54:06.557: epoch 96:	0.02640481  	0.19463561  	0.10621779  
2023-05-15 10:54:06.558: Find a better model.
2023-05-15 10:54:13.411: [iter 97 : loss : 0.1265 = 0.0378 + 0.0834 + 0.0053, time: 6.850273]
2023-05-15 10:54:13.564: epoch 97:	0.02639069  	0.19469179  	0.10618668  
2023-05-15 10:54:13.564: Find a better model.
2023-05-15 10:54:20.598: [iter 98 : loss : 0.1274 = 0.0388 + 0.0833 + 0.0053, time: 7.033322]
2023-05-15 10:54:20.752: epoch 98:	0.02650360  	0.19555263  	0.10658172  
2023-05-15 10:54:20.753: Find a better model.
2023-05-15 10:54:27.612: [iter 99 : loss : 0.1263 = 0.0377 + 0.0832 + 0.0054, time: 6.857017]
2023-05-15 10:54:27.761: epoch 99:	0.02652477  	0.19571052  	0.10692786  
2023-05-15 10:54:27.761: Find a better model.
2023-05-15 10:54:34.770: [iter 100 : loss : 0.1257 = 0.0372 + 0.0832 + 0.0054, time: 7.008345]
2023-05-15 10:54:34.925: epoch 100:	0.02648949  	0.19543462  	0.10680981  
2023-05-15 10:54:41.795: [iter 101 : loss : 0.1253 = 0.0368 + 0.0831 + 0.0055, time: 6.868861]
2023-05-15 10:54:41.948: epoch 101:	0.02648244  	0.19529840  	0.10686294  
2023-05-15 10:54:48.800: [iter 102 : loss : 0.1244 = 0.0359 + 0.0830 + 0.0055, time: 6.849831]
2023-05-15 10:54:48.941: epoch 102:	0.02643304  	0.19512992  	0.10694403  
2023-05-15 10:54:55.967: [iter 103 : loss : 0.1240 = 0.0355 + 0.0830 + 0.0055, time: 7.024907]
2023-05-15 10:54:56.122: epoch 103:	0.02641187  	0.19485806  	0.10699302  
2023-05-15 10:55:02.995: [iter 104 : loss : 0.1245 = 0.0361 + 0.0829 + 0.0056, time: 6.870958]
2023-05-15 10:55:03.149: epoch 104:	0.02644715  	0.19514298  	0.10717499  
2023-05-15 10:55:10.170: [iter 105 : loss : 0.1238 = 0.0353 + 0.0828 + 0.0056, time: 7.020213]
2023-05-15 10:55:10.326: epoch 105:	0.02658122  	0.19597054  	0.10751066  
2023-05-15 10:55:10.327: Find a better model.
2023-05-15 10:55:17.186: [iter 106 : loss : 0.1234 = 0.0350 + 0.0828 + 0.0056, time: 6.853553]
2023-05-15 10:55:17.330: epoch 106:	0.02656711  	0.19584499  	0.10768490  
2023-05-15 10:55:24.356: [iter 107 : loss : 0.1224 = 0.0341 + 0.0827 + 0.0057, time: 7.024926]
2023-05-15 10:55:24.509: epoch 107:	0.02656005  	0.19615012  	0.10785303  
2023-05-15 10:55:24.510: Find a better model.
2023-05-15 10:55:31.377: [iter 108 : loss : 0.1221 = 0.0338 + 0.0826 + 0.0057, time: 6.864285]
2023-05-15 10:55:31.529: epoch 108:	0.02662355  	0.19627304  	0.10768274  
2023-05-15 10:55:31.529: Find a better model.
2023-05-15 10:55:38.556: [iter 109 : loss : 0.1209 = 0.0326 + 0.0826 + 0.0057, time: 7.024941]
2023-05-15 10:55:38.707: epoch 109:	0.02662355  	0.19602638  	0.10761873  
2023-05-15 10:55:45.577: [iter 110 : loss : 0.1203 = 0.0321 + 0.0825 + 0.0058, time: 6.868834]
2023-05-15 10:55:45.728: epoch 110:	0.02669412  	0.19656241  	0.10780995  
2023-05-15 10:55:45.728: Find a better model.
2023-05-15 10:55:52.746: [iter 111 : loss : 0.1203 = 0.0320 + 0.0825 + 0.0058, time: 7.016848]
2023-05-15 10:55:52.901: epoch 111:	0.02668707  	0.19650128  	0.10785946  
2023-05-15 10:55:59.761: [iter 112 : loss : 0.1203 = 0.0320 + 0.0824 + 0.0058, time: 6.858210]
2023-05-15 10:55:59.917: epoch 112:	0.02667295  	0.19646809  	0.10803758  
2023-05-15 10:56:06.778: [iter 113 : loss : 0.1201 = 0.0319 + 0.0824 + 0.0059, time: 6.859750]
2023-05-15 10:56:06.932: epoch 113:	0.02664473  	0.19622271  	0.10797435  
2023-05-15 10:56:13.939: [iter 114 : loss : 0.1193 = 0.0311 + 0.0823 + 0.0059, time: 7.006053]
2023-05-15 10:56:14.092: epoch 114:	0.02663768  	0.19624455  	0.10797766  
2023-05-15 10:56:20.974: [iter 115 : loss : 0.1187 = 0.0306 + 0.0822 + 0.0059, time: 6.881318]
2023-05-15 10:56:21.127: epoch 115:	0.02663768  	0.19595233  	0.10821363  
2023-05-15 10:56:28.154: [iter 116 : loss : 0.1180 = 0.0298 + 0.0822 + 0.0060, time: 7.025795]
2023-05-15 10:56:28.308: epoch 116:	0.02671530  	0.19640045  	0.10851219  
2023-05-15 10:56:35.158: [iter 117 : loss : 0.1179 = 0.0298 + 0.0821 + 0.0060, time: 6.848257]
2023-05-15 10:56:35.301: epoch 117:	0.02667296  	0.19622375  	0.10855831  
2023-05-15 10:56:42.160: [iter 118 : loss : 0.1180 = 0.0299 + 0.0821 + 0.0060, time: 6.858150]
2023-05-15 10:56:42.315: epoch 118:	0.02660945  	0.19579761  	0.10842119  
2023-05-15 10:56:49.336: [iter 119 : loss : 0.1170 = 0.0289 + 0.0820 + 0.0061, time: 7.019568]
2023-05-15 10:56:49.495: epoch 119:	0.02676469  	0.19678594  	0.10880719  
2023-05-15 10:56:49.495: Find a better model.
2023-05-15 10:56:56.356: [iter 120 : loss : 0.1173 = 0.0292 + 0.0820 + 0.0061, time: 6.859843]
2023-05-15 10:56:56.511: epoch 120:	0.02670823  	0.19631383  	0.10872311  
2023-05-15 10:57:03.530: [iter 121 : loss : 0.1170 = 0.0290 + 0.0819 + 0.0061, time: 7.018145]
2023-05-15 10:57:03.684: epoch 121:	0.02666590  	0.19595626  	0.10876475  
2023-05-15 10:57:10.558: [iter 122 : loss : 0.1162 = 0.0282 + 0.0819 + 0.0062, time: 6.872982]
2023-05-15 10:57:10.713: epoch 122:	0.02661650  	0.19535303  	0.10860895  
2023-05-15 10:57:17.724: [iter 123 : loss : 0.1162 = 0.0282 + 0.0818 + 0.0062, time: 7.010421]
2023-05-15 10:57:17.880: epoch 123:	0.02677880  	0.19678780  	0.10913328  
2023-05-15 10:57:17.880: Find a better model.
2023-05-15 10:57:24.919: [iter 124 : loss : 0.1153 = 0.0273 + 0.0818 + 0.0062, time: 7.037902]
2023-05-15 10:57:25.072: epoch 124:	0.02682114  	0.19708927  	0.10916140  
2023-05-15 10:57:25.072: Find a better model.
2023-05-15 10:57:31.950: [iter 125 : loss : 0.1146 = 0.0266 + 0.0817 + 0.0063, time: 6.877438]
2023-05-15 10:57:32.101: epoch 125:	0.02679997  	0.19677800  	0.10912013  
2023-05-15 10:57:39.121: [iter 126 : loss : 0.1150 = 0.0270 + 0.0817 + 0.0063, time: 7.017178]
2023-05-15 10:57:39.275: epoch 126:	0.02678586  	0.19685651  	0.10892934  
2023-05-15 10:57:46.135: [iter 127 : loss : 0.1140 = 0.0260 + 0.0817 + 0.0063, time: 6.858108]
2023-05-15 10:57:46.287: epoch 127:	0.02670824  	0.19631276  	0.10876621  
2023-05-15 10:57:53.132: [iter 128 : loss : 0.1149 = 0.0269 + 0.0816 + 0.0063, time: 6.843665]
2023-05-15 10:57:53.272: epoch 128:	0.02671529  	0.19626780  	0.10880018  
2023-05-15 10:58:00.131: [iter 129 : loss : 0.1142 = 0.0262 + 0.0815 + 0.0064, time: 6.856524]
2023-05-15 10:58:00.284: epoch 129:	0.02670824  	0.19602713  	0.10885035  
2023-05-15 10:58:07.120: [iter 130 : loss : 0.1143 = 0.0264 + 0.0815 + 0.0064, time: 6.834869]
2023-05-15 10:58:07.277: epoch 130:	0.02668001  	0.19636317  	0.10898104  
2023-05-15 10:58:14.312: [iter 131 : loss : 0.1134 = 0.0255 + 0.0815 + 0.0064, time: 7.032976]
2023-05-15 10:58:14.465: epoch 131:	0.02670118  	0.19646701  	0.10886354  
2023-05-15 10:58:21.307: [iter 132 : loss : 0.1135 = 0.0256 + 0.0814 + 0.0065, time: 6.840760]
2023-05-15 10:58:21.449: epoch 132:	0.02675058  	0.19664785  	0.10902937  
2023-05-15 10:58:28.308: [iter 133 : loss : 0.1124 = 0.0245 + 0.0814 + 0.0065, time: 6.857254]
2023-05-15 10:58:28.463: epoch 133:	0.02678586  	0.19674866  	0.10938560  
2023-05-15 10:58:35.317: [iter 134 : loss : 0.1130 = 0.0252 + 0.0813 + 0.0065, time: 6.853331]
2023-05-15 10:58:35.474: epoch 134:	0.02678586  	0.19686490  	0.10944684  
2023-05-15 10:58:42.318: [iter 135 : loss : 0.1127 = 0.0249 + 0.0813 + 0.0066, time: 6.843061]
2023-05-15 10:58:42.472: epoch 135:	0.02673646  	0.19665758  	0.10920320  
2023-05-15 10:58:49.302: [iter 136 : loss : 0.1124 = 0.0245 + 0.0813 + 0.0066, time: 6.828904]
2023-05-15 10:58:49.456: epoch 136:	0.02672941  	0.19655231  	0.10934536  
2023-05-15 10:58:56.313: [iter 137 : loss : 0.1120 = 0.0242 + 0.0812 + 0.0066, time: 6.855849]
2023-05-15 10:58:56.466: epoch 137:	0.02677175  	0.19716109  	0.10938505  
2023-05-15 10:58:56.467: Find a better model.
2023-05-15 10:59:03.476: [iter 138 : loss : 0.1117 = 0.0238 + 0.0812 + 0.0066, time: 7.007419]
2023-05-15 10:59:03.631: epoch 138:	0.02680703  	0.19724822  	0.10951094  
2023-05-15 10:59:03.631: Find a better model.
2023-05-15 10:59:10.507: [iter 139 : loss : 0.1116 = 0.0237 + 0.0811 + 0.0067, time: 6.874867]
2023-05-15 10:59:10.664: epoch 139:	0.02681408  	0.19703588  	0.10934747  
2023-05-15 10:59:17.681: [iter 140 : loss : 0.1109 = 0.0231 + 0.0811 + 0.0067, time: 7.015838]
2023-05-15 10:59:17.836: epoch 140:	0.02688465  	0.19751224  	0.10967168  
2023-05-15 10:59:17.836: Find a better model.
2023-05-15 10:59:24.689: [iter 141 : loss : 0.1114 = 0.0236 + 0.0811 + 0.0067, time: 6.852569]
2023-05-15 10:59:24.843: epoch 141:	0.02679997  	0.19698294  	0.10970028  
2023-05-15 10:59:31.707: [iter 142 : loss : 0.1107 = 0.0230 + 0.0810 + 0.0068, time: 6.861486]
2023-05-15 10:59:31.861: epoch 142:	0.02679997  	0.19706614  	0.10973783  
2023-05-15 10:59:38.708: [iter 143 : loss : 0.1106 = 0.0228 + 0.0810 + 0.0068, time: 6.845343]
2023-05-15 10:59:38.862: epoch 143:	0.02679292  	0.19680431  	0.10971286  
2023-05-15 10:59:45.862: [iter 144 : loss : 0.1101 = 0.0224 + 0.0810 + 0.0068, time: 6.999117]
2023-05-15 10:59:46.016: epoch 144:	0.02677175  	0.19688511  	0.10976638  
2023-05-15 10:59:52.890: [iter 145 : loss : 0.1099 = 0.0222 + 0.0809 + 0.0068, time: 6.872307]
2023-05-15 10:59:53.045: epoch 145:	0.02686347  	0.19756052  	0.10997590  
2023-05-15 10:59:53.045: Find a better model.
2023-05-15 10:59:59.899: [iter 146 : loss : 0.1104 = 0.0227 + 0.0809 + 0.0069, time: 6.853642]
2023-05-15 11:00:00.057: epoch 146:	0.02677880  	0.19686745  	0.10986366  
2023-05-15 11:00:07.065: [iter 147 : loss : 0.1102 = 0.0224 + 0.0809 + 0.0069, time: 7.006621]
2023-05-15 11:00:07.217: epoch 147:	0.02673646  	0.19668198  	0.10965412  
2023-05-15 11:00:14.087: [iter 148 : loss : 0.1088 = 0.0211 + 0.0808 + 0.0069, time: 6.868832]
2023-05-15 11:00:14.241: epoch 148:	0.02674352  	0.19681144  	0.10965522  
2023-05-15 11:00:21.080: [iter 149 : loss : 0.1094 = 0.0216 + 0.0808 + 0.0069, time: 6.838450]
2023-05-15 11:00:21.234: epoch 149:	0.02670117  	0.19623926  	0.10950653  
2023-05-15 11:00:28.268: [iter 150 : loss : 0.1089 = 0.0211 + 0.0808 + 0.0070, time: 7.032335]
2023-05-15 11:00:28.421: epoch 150:	0.02670118  	0.19646421  	0.10940556  
2023-05-15 11:00:35.275: [iter 151 : loss : 0.1089 = 0.0212 + 0.0807 + 0.0070, time: 6.851150]
2023-05-15 11:00:35.428: epoch 151:	0.02674352  	0.19666919  	0.10969446  
2023-05-15 11:00:42.283: [iter 152 : loss : 0.1082 = 0.0205 + 0.0807 + 0.0070, time: 6.854111]
2023-05-15 11:00:42.438: epoch 152:	0.02671529  	0.19627839  	0.10959587  
2023-05-15 11:00:49.268: [iter 153 : loss : 0.1075 = 0.0198 + 0.0807 + 0.0070, time: 6.829365]
2023-05-15 11:00:49.420: epoch 153:	0.02672940  	0.19653001  	0.10954738  
2023-05-15 11:00:56.263: [iter 154 : loss : 0.1077 = 0.0200 + 0.0806 + 0.0071, time: 6.840530]
2023-05-15 11:00:56.404: epoch 154:	0.02670118  	0.19648735  	0.10959269  
2023-05-15 11:01:03.276: [iter 155 : loss : 0.1085 = 0.0208 + 0.0806 + 0.0071, time: 6.871341]
2023-05-15 11:01:03.425: epoch 155:	0.02662355  	0.19597852  	0.10939769  
2023-05-15 11:01:10.259: [iter 156 : loss : 0.1079 = 0.0202 + 0.0806 + 0.0071, time: 6.832423]
2023-05-15 11:01:10.412: epoch 156:	0.02665178  	0.19634016  	0.10939233  
2023-05-15 11:01:17.257: [iter 157 : loss : 0.1077 = 0.0200 + 0.0805 + 0.0072, time: 6.841908]
2023-05-15 11:01:17.411: epoch 157:	0.02665884  	0.19598627  	0.10950316  
2023-05-15 11:01:24.258: [iter 158 : loss : 0.1070 = 0.0193 + 0.0805 + 0.0072, time: 6.846037]
2023-05-15 11:01:24.412: epoch 158:	0.02664473  	0.19572993  	0.10935704  
2023-05-15 11:01:31.256: [iter 159 : loss : 0.1074 = 0.0197 + 0.0805 + 0.0072, time: 6.843455]
2023-05-15 11:01:31.411: epoch 159:	0.02667296  	0.19626580  	0.10962572  
2023-05-15 11:01:38.256: [iter 160 : loss : 0.1068 = 0.0191 + 0.0804 + 0.0072, time: 6.843197]
2023-05-15 11:01:38.410: epoch 160:	0.02667296  	0.19604507  	0.10953973  
2023-05-15 11:01:45.244: [iter 161 : loss : 0.1065 = 0.0188 + 0.0804 + 0.0073, time: 6.833747]
2023-05-15 11:01:45.386: epoch 161:	0.02665885  	0.19581291  	0.10951482  
2023-05-15 11:01:52.241: [iter 162 : loss : 0.1060 = 0.0183 + 0.0804 + 0.0073, time: 6.853266]
2023-05-15 11:01:52.393: epoch 162:	0.02665179  	0.19551860  	0.10955442  
2023-05-15 11:01:59.235: [iter 163 : loss : 0.1064 = 0.0187 + 0.0804 + 0.0073, time: 6.839908]
2023-05-15 11:01:59.388: epoch 163:	0.02662356  	0.19543709  	0.10945298  
2023-05-15 11:02:06.237: [iter 164 : loss : 0.1062 = 0.0186 + 0.0804 + 0.0073, time: 6.848163]
2023-05-15 11:02:06.393: epoch 164:	0.02664473  	0.19589655  	0.10964154  
2023-05-15 11:02:13.242: [iter 165 : loss : 0.1060 = 0.0183 + 0.0803 + 0.0074, time: 6.847577]
2023-05-15 11:02:13.398: epoch 165:	0.02655300  	0.19518040  	0.10928820  
2023-05-15 11:02:20.232: [iter 166 : loss : 0.1056 = 0.0179 + 0.0803 + 0.0074, time: 6.833166]
2023-05-15 11:02:20.387: epoch 166:	0.02649655  	0.19487952  	0.10912419  
2023-05-15 11:02:27.232: [iter 167 : loss : 0.1061 = 0.0185 + 0.0803 + 0.0074, time: 6.843815]
2023-05-15 11:02:27.388: epoch 167:	0.02654594  	0.19499895  	0.10934626  
2023-05-15 11:02:34.227: [iter 168 : loss : 0.1054 = 0.0177 + 0.0803 + 0.0074, time: 6.837937]
2023-05-15 11:02:34.379: epoch 168:	0.02658122  	0.19533953  	0.10938396  
2023-05-15 11:02:41.226: [iter 169 : loss : 0.1056 = 0.0179 + 0.0802 + 0.0075, time: 6.846654]
2023-05-15 11:02:41.378: epoch 169:	0.02654594  	0.19506902  	0.10929144  
2023-05-15 11:02:48.215: [iter 170 : loss : 0.1054 = 0.0178 + 0.0802 + 0.0075, time: 6.835270]
2023-05-15 11:02:48.368: epoch 170:	0.02656005  	0.19496724  	0.10923664  
2023-05-15 11:02:48.368: Early stopping is trigger at epoch: 170
2023-05-15 11:02:48.368: best_result@epoch 145:

2023-05-15 11:02:48.368: 		0.0269      	0.1976      	0.1100      
2023-05-15 11:19:36.577: my pid: 5936
2023-05-15 11:19:36.577: model: model.general_recommender.SGL
2023-05-15 11:19:36.577: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 11:19:36.578: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 11:19:39.737: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 11:19:47.897: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.160994]
2023-05-15 11:19:48.053: epoch 1:	0.00133362  	0.00981526  	0.00493421  
2023-05-15 11:19:48.054: Find a better model.
2023-05-15 11:19:56.296: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.240500]
2023-05-15 11:19:56.489: epoch 2:	0.00299887  	0.02247147  	0.01071646  
2023-05-15 11:19:56.489: Find a better model.
2023-05-15 11:20:04.479: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 7.988819]
2023-05-15 11:20:04.666: epoch 3:	0.00535560  	0.03942305  	0.01865841  
2023-05-15 11:20:04.666: Find a better model.
2023-05-15 11:20:12.729: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 8.062015]
2023-05-15 11:20:12.885: epoch 4:	0.00860139  	0.06380547  	0.03076994  
2023-05-15 11:20:12.885: Find a better model.
2023-05-15 11:20:20.637: [iter 5 : loss : 0.7695 = 0.6906 + 0.0789 + 0.0000, time: 7.751187]
2023-05-15 11:20:20.787: epoch 5:	0.01231308  	0.08934295  	0.04332179  
2023-05-15 11:20:20.788: Find a better model.
2023-05-15 11:20:28.473: [iter 6 : loss : 0.7668 = 0.6875 + 0.0793 + 0.0000, time: 7.682539]
2023-05-15 11:20:28.632: epoch 6:	0.01570015  	0.11330869  	0.05620344  
2023-05-15 11:20:28.632: Find a better model.
2023-05-15 11:20:36.227: [iter 7 : loss : 0.7596 = 0.6794 + 0.0802 + 0.0000, time: 7.593076]
2023-05-15 11:20:36.383: epoch 7:	0.01795114  	0.13076770  	0.06595118  
2023-05-15 11:20:36.383: Find a better model.
2023-05-15 11:20:43.880: [iter 8 : loss : 0.7420 = 0.6596 + 0.0823 + 0.0001, time: 7.496113]
2023-05-15 11:20:44.037: epoch 8:	0.01878381  	0.13823317  	0.06973200  
2023-05-15 11:20:44.037: Find a better model.
2023-05-15 11:20:51.616: [iter 9 : loss : 0.7033 = 0.6167 + 0.0865 + 0.0002, time: 7.577332]
2023-05-15 11:20:51.764: epoch 9:	0.01868502  	0.13849358  	0.06996398  
2023-05-15 11:20:51.765: Find a better model.
2023-05-15 11:20:59.033: [iter 10 : loss : 0.6393 = 0.5472 + 0.0918 + 0.0003, time: 7.266912]
2023-05-15 11:20:59.187: epoch 10:	0.01854389  	0.13771090  	0.06900328  
2023-05-15 11:21:06.302: [iter 11 : loss : 0.5638 = 0.4667 + 0.0967 + 0.0004, time: 7.114745]
2023-05-15 11:21:06.444: epoch 11:	0.01839571  	0.13625187  	0.06825416  
2023-05-15 11:21:13.795: [iter 12 : loss : 0.4974 = 0.3969 + 0.0999 + 0.0006, time: 7.348975]
2023-05-15 11:21:13.950: epoch 12:	0.01843805  	0.13664652  	0.06866981  
2023-05-15 11:21:21.419: [iter 13 : loss : 0.4491 = 0.3468 + 0.1016 + 0.0007, time: 7.466818]
2023-05-15 11:21:21.576: epoch 13:	0.01857212  	0.13789181  	0.06927887  
2023-05-15 11:21:28.815: [iter 14 : loss : 0.4122 = 0.3090 + 0.1024 + 0.0009, time: 7.237209]
2023-05-15 11:21:28.971: epoch 14:	0.01869209  	0.13867328  	0.07002604  
2023-05-15 11:21:28.971: Find a better model.
2023-05-15 11:21:36.215: [iter 15 : loss : 0.3866 = 0.2830 + 0.1027 + 0.0010, time: 7.241041]
2023-05-15 11:21:36.371: epoch 15:	0.01890378  	0.14022614  	0.07090932  
2023-05-15 11:21:36.371: Find a better model.
2023-05-15 11:21:43.813: [iter 16 : loss : 0.3647 = 0.2610 + 0.1026 + 0.0011, time: 7.440021]
2023-05-15 11:21:43.971: epoch 16:	0.01909431  	0.14151609  	0.07167811  
2023-05-15 11:21:43.971: Find a better model.
2023-05-15 11:21:51.205: [iter 17 : loss : 0.3487 = 0.2450 + 0.1024 + 0.0012, time: 7.233264]
2023-05-15 11:21:51.359: epoch 17:	0.01936246  	0.14340135  	0.07271675  
2023-05-15 11:21:51.359: Find a better model.
2023-05-15 11:21:58.605: [iter 18 : loss : 0.3334 = 0.2300 + 0.1021 + 0.0013, time: 7.243960]
2023-05-15 11:21:58.768: epoch 18:	0.01951770  	0.14432859  	0.07347491  
2023-05-15 11:21:58.768: Find a better model.
2023-05-15 11:22:06.011: [iter 19 : loss : 0.3194 = 0.2163 + 0.1017 + 0.0014, time: 7.241175]
2023-05-15 11:22:06.164: epoch 19:	0.01970118  	0.14562716  	0.07435577  
2023-05-15 11:22:06.164: Find a better model.
2023-05-15 11:22:13.392: [iter 20 : loss : 0.3099 = 0.2070 + 0.1014 + 0.0015, time: 7.227263]
2023-05-15 11:22:13.536: epoch 20:	0.01994815  	0.14688481  	0.07494434  
2023-05-15 11:22:13.536: Find a better model.
2023-05-15 11:22:20.796: [iter 21 : loss : 0.3002 = 0.1977 + 0.1009 + 0.0016, time: 7.258283]
2023-05-15 11:22:20.951: epoch 21:	0.02025864  	0.14945155  	0.07608761  
2023-05-15 11:22:20.952: Find a better model.
2023-05-15 11:22:28.187: [iter 22 : loss : 0.2920 = 0.1899 + 0.1005 + 0.0017, time: 7.233560]
2023-05-15 11:22:28.329: epoch 22:	0.02056208  	0.15179355  	0.07727513  
2023-05-15 11:22:28.329: Find a better model.
2023-05-15 11:22:35.585: [iter 23 : loss : 0.2838 = 0.1820 + 0.1001 + 0.0017, time: 7.254844]
2023-05-15 11:22:35.728: epoch 23:	0.02074554  	0.15341318  	0.07819238  
2023-05-15 11:22:35.728: Find a better model.
2023-05-15 11:22:42.990: [iter 24 : loss : 0.2771 = 0.1757 + 0.0996 + 0.0018, time: 7.258201]
2023-05-15 11:22:43.147: epoch 24:	0.02090078  	0.15458389  	0.07900956  
2023-05-15 11:22:43.147: Find a better model.
2023-05-15 11:22:50.373: [iter 25 : loss : 0.2707 = 0.1696 + 0.0992 + 0.0019, time: 7.224472]
2023-05-15 11:22:50.517: epoch 25:	0.02101368  	0.15567881  	0.07965927  
2023-05-15 11:22:50.517: Find a better model.
2023-05-15 11:22:57.785: [iter 26 : loss : 0.2669 = 0.1662 + 0.0988 + 0.0019, time: 7.267377]
2023-05-15 11:22:57.941: epoch 26:	0.02125361  	0.15711699  	0.08040577  
2023-05-15 11:22:57.941: Find a better model.
2023-05-15 11:23:05.193: [iter 27 : loss : 0.2592 = 0.1589 + 0.0983 + 0.0020, time: 7.251021]
2023-05-15 11:23:05.351: epoch 27:	0.02138062  	0.15748161  	0.08096524  
2023-05-15 11:23:05.352: Find a better model.
2023-05-15 11:23:12.758: [iter 28 : loss : 0.2542 = 0.1542 + 0.0979 + 0.0021, time: 7.403708]
2023-05-15 11:23:12.914: epoch 28:	0.02162761  	0.15941659  	0.08201524  
2023-05-15 11:23:12.914: Find a better model.
2023-05-15 11:23:20.176: [iter 29 : loss : 0.2498 = 0.1501 + 0.0975 + 0.0021, time: 7.259552]
2023-05-15 11:23:20.329: epoch 29:	0.02177580  	0.16062070  	0.08267630  
2023-05-15 11:23:20.329: Find a better model.
2023-05-15 11:23:27.563: [iter 30 : loss : 0.2433 = 0.1439 + 0.0972 + 0.0022, time: 7.232531]
2023-05-15 11:23:27.707: epoch 30:	0.02198044  	0.16243193  	0.08361933  
2023-05-15 11:23:27.707: Find a better model.
2023-05-15 11:23:34.965: [iter 31 : loss : 0.2396 = 0.1406 + 0.0968 + 0.0023, time: 7.256541]
2023-05-15 11:23:35.119: epoch 31:	0.02224153  	0.16432036  	0.08463811  
2023-05-15 11:23:35.120: Find a better model.
2023-05-15 11:23:42.538: [iter 32 : loss : 0.2341 = 0.1353 + 0.0965 + 0.0023, time: 7.417181]
2023-05-15 11:23:42.697: epoch 32:	0.02238266  	0.16557433  	0.08522726  
2023-05-15 11:23:42.697: Find a better model.
2023-05-15 11:23:49.972: [iter 33 : loss : 0.2316 = 0.1331 + 0.0961 + 0.0024, time: 7.272645]
2023-05-15 11:23:50.126: epoch 33:	0.02239677  	0.16540506  	0.08558937  
2023-05-15 11:23:57.359: [iter 34 : loss : 0.2275 = 0.1293 + 0.0957 + 0.0024, time: 7.231205]
2023-05-15 11:23:57.514: epoch 34:	0.02247439  	0.16603258  	0.08627342  
2023-05-15 11:23:57.514: Find a better model.
2023-05-15 11:24:04.753: [iter 35 : loss : 0.2238 = 0.1259 + 0.0954 + 0.0025, time: 7.237375]
2023-05-15 11:24:04.899: epoch 35:	0.02263669  	0.16715564  	0.08688814  
2023-05-15 11:24:04.900: Find a better model.
2023-05-15 11:24:12.142: [iter 36 : loss : 0.2204 = 0.1228 + 0.0951 + 0.0026, time: 7.240455]
2023-05-15 11:24:12.296: epoch 36:	0.02262962  	0.16700396  	0.08715167  
2023-05-15 11:24:19.563: [iter 37 : loss : 0.2166 = 0.1192 + 0.0948 + 0.0026, time: 7.266420]
2023-05-15 11:24:19.723: epoch 37:	0.02281309  	0.16827513  	0.08794191  
2023-05-15 11:24:19.723: Find a better model.
2023-05-15 11:24:27.124: [iter 38 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0027, time: 7.399945]
2023-05-15 11:24:27.278: epoch 38:	0.02301067  	0.16977294  	0.08882101  
2023-05-15 11:24:27.278: Find a better model.
2023-05-15 11:24:34.747: [iter 39 : loss : 0.2107 = 0.1138 + 0.0942 + 0.0027, time: 7.466676]
2023-05-15 11:24:34.905: epoch 39:	0.02310241  	0.17044805  	0.08937668  
2023-05-15 11:24:34.905: Find a better model.
2023-05-15 11:24:42.159: [iter 40 : loss : 0.2074 = 0.1107 + 0.0939 + 0.0028, time: 7.253912]
2023-05-15 11:24:42.311: epoch 40:	0.02321531  	0.17124332  	0.08981419  
2023-05-15 11:24:42.311: Find a better model.
2023-05-15 11:24:49.548: [iter 41 : loss : 0.2056 = 0.1092 + 0.0936 + 0.0028, time: 7.236604]
2023-05-15 11:24:49.705: epoch 41:	0.02334233  	0.17218037  	0.09038190  
2023-05-15 11:24:49.705: Find a better model.
2023-05-15 11:24:56.945: [iter 42 : loss : 0.2035 = 0.1074 + 0.0933 + 0.0029, time: 7.238777]
2023-05-15 11:24:57.100: epoch 42:	0.02346229  	0.17328148  	0.09117278  
2023-05-15 11:24:57.101: Find a better model.
2023-05-15 11:25:04.333: [iter 43 : loss : 0.1996 = 0.1036 + 0.0930 + 0.0029, time: 7.231052]
2023-05-15 11:25:04.474: epoch 43:	0.02354697  	0.17373618  	0.09159525  
2023-05-15 11:25:04.474: Find a better model.
2023-05-15 11:25:11.733: [iter 44 : loss : 0.1961 = 0.1003 + 0.0928 + 0.0030, time: 7.255929]
2023-05-15 11:25:11.891: epoch 44:	0.02371632  	0.17515755  	0.09216673  
2023-05-15 11:25:11.891: Find a better model.
2023-05-15 11:25:19.135: [iter 45 : loss : 0.1940 = 0.0985 + 0.0925 + 0.0030, time: 7.241839]
2023-05-15 11:25:19.287: epoch 45:	0.02390685  	0.17684504  	0.09305227  
2023-05-15 11:25:19.288: Find a better model.
2023-05-15 11:25:26.528: [iter 46 : loss : 0.1915 = 0.0962 + 0.0923 + 0.0031, time: 7.237791]
2023-05-15 11:25:26.671: epoch 46:	0.02406209  	0.17801264  	0.09361784  
2023-05-15 11:25:26.671: Find a better model.
2023-05-15 11:25:33.927: [iter 47 : loss : 0.1907 = 0.0956 + 0.0920 + 0.0031, time: 7.254299]
2023-05-15 11:25:34.081: epoch 47:	0.02409032  	0.17816176  	0.09403296  
2023-05-15 11:25:34.081: Find a better model.
2023-05-15 11:25:41.326: [iter 48 : loss : 0.1871 = 0.0922 + 0.0918 + 0.0032, time: 7.243716]
2023-05-15 11:25:41.479: epoch 48:	0.02414676  	0.17833890  	0.09428800  
2023-05-15 11:25:41.480: Find a better model.
2023-05-15 11:25:48.901: [iter 49 : loss : 0.1837 = 0.0888 + 0.0916 + 0.0032, time: 7.420113]
2023-05-15 11:25:49.059: epoch 49:	0.02415382  	0.17858814  	0.09483578  
2023-05-15 11:25:49.059: Find a better model.
2023-05-15 11:25:56.330: [iter 50 : loss : 0.1832 = 0.0885 + 0.0914 + 0.0033, time: 7.269977]
2023-05-15 11:25:56.473: epoch 50:	0.02420321  	0.17895709  	0.09537258  
2023-05-15 11:25:56.473: Find a better model.
2023-05-15 11:26:03.897: [iter 51 : loss : 0.1799 = 0.0853 + 0.0912 + 0.0033, time: 7.421291]
2023-05-15 11:26:04.052: epoch 51:	0.02419616  	0.17876646  	0.09552802  
2023-05-15 11:26:11.305: [iter 52 : loss : 0.1800 = 0.0856 + 0.0910 + 0.0034, time: 7.250422]
2023-05-15 11:26:11.460: epoch 52:	0.02431612  	0.17950067  	0.09590274  
2023-05-15 11:26:11.461: Find a better model.
2023-05-15 11:26:18.704: [iter 53 : loss : 0.1780 = 0.0838 + 0.0908 + 0.0034, time: 7.242688]
2023-05-15 11:26:18.849: epoch 53:	0.02437256  	0.17985873  	0.09652195  
2023-05-15 11:26:18.849: Find a better model.
2023-05-15 11:26:26.114: [iter 54 : loss : 0.1758 = 0.0818 + 0.0905 + 0.0035, time: 7.262591]
2023-05-15 11:26:26.268: epoch 54:	0.02450663  	0.18073468  	0.09701946  
2023-05-15 11:26:26.268: Find a better model.
2023-05-15 11:26:33.703: [iter 55 : loss : 0.1738 = 0.0800 + 0.0903 + 0.0035, time: 7.434468]
2023-05-15 11:26:33.857: epoch 55:	0.02459131  	0.18158613  	0.09732167  
2023-05-15 11:26:33.857: Find a better model.
2023-05-15 11:26:41.110: [iter 56 : loss : 0.1721 = 0.0784 + 0.0902 + 0.0036, time: 7.251416]
2023-05-15 11:26:41.261: epoch 56:	0.02456309  	0.18142448  	0.09762530  
2023-05-15 11:26:48.519: [iter 57 : loss : 0.1704 = 0.0768 + 0.0900 + 0.0036, time: 7.256749]
2023-05-15 11:26:48.672: epoch 57:	0.02485945  	0.18349166  	0.09866013  
2023-05-15 11:26:48.672: Find a better model.
2023-05-15 11:26:55.923: [iter 58 : loss : 0.1684 = 0.0749 + 0.0898 + 0.0037, time: 7.249422]
2023-05-15 11:26:56.079: epoch 58:	0.02480301  	0.18288477  	0.09873850  
2023-05-15 11:27:03.314: [iter 59 : loss : 0.1675 = 0.0742 + 0.0896 + 0.0037, time: 7.233834]
2023-05-15 11:27:03.467: epoch 59:	0.02485240  	0.18329906  	0.09902695  
2023-05-15 11:27:10.706: [iter 60 : loss : 0.1661 = 0.0729 + 0.0895 + 0.0037, time: 7.236566]
2023-05-15 11:27:10.856: epoch 60:	0.02495119  	0.18382841  	0.09959998  
2023-05-15 11:27:10.856: Find a better model.
2023-05-15 11:27:18.088: [iter 61 : loss : 0.1645 = 0.0714 + 0.0893 + 0.0038, time: 7.230240]
2023-05-15 11:27:18.230: epoch 61:	0.02502881  	0.18437694  	0.09999253  
2023-05-15 11:27:18.230: Find a better model.
2023-05-15 11:27:25.493: [iter 62 : loss : 0.1630 = 0.0700 + 0.0891 + 0.0038, time: 7.261109]
2023-05-15 11:27:25.644: epoch 62:	0.02504998  	0.18461962  	0.10013081  
2023-05-15 11:27:25.645: Find a better model.
2023-05-15 11:27:32.899: [iter 63 : loss : 0.1617 = 0.0689 + 0.0890 + 0.0039, time: 7.251603]
2023-05-15 11:27:33.056: epoch 63:	0.02508526  	0.18500750  	0.10027495  
2023-05-15 11:27:33.056: Find a better model.
2023-05-15 11:27:40.304: [iter 64 : loss : 0.1608 = 0.0681 + 0.0888 + 0.0039, time: 7.246849]
2023-05-15 11:27:40.456: epoch 64:	0.02516994  	0.18533732  	0.10064169  
2023-05-15 11:27:40.456: Find a better model.
2023-05-15 11:27:47.679: [iter 65 : loss : 0.1594 = 0.0668 + 0.0886 + 0.0040, time: 7.222442]
2023-05-15 11:27:47.822: epoch 65:	0.02521227  	0.18577078  	0.10095225  
2023-05-15 11:27:47.822: Find a better model.
2023-05-15 11:27:55.084: [iter 66 : loss : 0.1579 = 0.0654 + 0.0885 + 0.0040, time: 7.260162]
2023-05-15 11:27:55.238: epoch 66:	0.02516288  	0.18524110  	0.10082088  
2023-05-15 11:28:02.478: [iter 67 : loss : 0.1563 = 0.0639 + 0.0884 + 0.0040, time: 7.237154]
2023-05-15 11:28:02.630: epoch 67:	0.02524050  	0.18596151  	0.10108897  
2023-05-15 11:28:02.630: Find a better model.
2023-05-15 11:28:09.881: [iter 68 : loss : 0.1559 = 0.0635 + 0.0882 + 0.0041, time: 7.249136]
2023-05-15 11:28:10.033: epoch 68:	0.02534635  	0.18685603  	0.10161527  
2023-05-15 11:28:10.033: Find a better model.
2023-05-15 11:28:17.271: [iter 69 : loss : 0.1541 = 0.0619 + 0.0881 + 0.0041, time: 7.234946]
2023-05-15 11:28:17.412: epoch 69:	0.02538163  	0.18714030  	0.10183214  
2023-05-15 11:28:17.412: Find a better model.
2023-05-15 11:28:24.681: [iter 70 : loss : 0.1525 = 0.0603 + 0.0880 + 0.0042, time: 7.266464]
2023-05-15 11:28:24.834: epoch 70:	0.02540280  	0.18712926  	0.10190489  
2023-05-15 11:28:32.078: [iter 71 : loss : 0.1508 = 0.0588 + 0.0879 + 0.0042, time: 7.242530]
2023-05-15 11:28:32.233: epoch 71:	0.02549454  	0.18788835  	0.10235123  
2023-05-15 11:28:32.233: Find a better model.
2023-05-15 11:28:39.462: [iter 72 : loss : 0.1507 = 0.0587 + 0.0877 + 0.0043, time: 7.228688]
2023-05-15 11:28:39.615: epoch 72:	0.02552276  	0.18820629  	0.10245459  
2023-05-15 11:28:39.615: Find a better model.
2023-05-15 11:28:46.851: [iter 73 : loss : 0.1495 = 0.0576 + 0.0876 + 0.0043, time: 7.234548]
2023-05-15 11:28:46.995: epoch 73:	0.02560744  	0.18879536  	0.10288050  
2023-05-15 11:28:46.995: Find a better model.
2023-05-15 11:28:54.243: [iter 74 : loss : 0.1479 = 0.0561 + 0.0875 + 0.0043, time: 7.247625]
2023-05-15 11:28:54.397: epoch 74:	0.02568506  	0.18922701  	0.10312589  
2023-05-15 11:28:54.397: Find a better model.
2023-05-15 11:29:01.634: [iter 75 : loss : 0.1473 = 0.0556 + 0.0874 + 0.0044, time: 7.235469]
2023-05-15 11:29:01.789: epoch 75:	0.02569212  	0.18921635  	0.10330527  
2023-05-15 11:29:09.044: [iter 76 : loss : 0.1465 = 0.0549 + 0.0872 + 0.0044, time: 7.252487]
2023-05-15 11:29:09.202: epoch 76:	0.02575562  	0.18969744  	0.10376236  
2023-05-15 11:29:09.202: Find a better model.
2023-05-15 11:29:16.265: [iter 77 : loss : 0.1455 = 0.0540 + 0.0871 + 0.0045, time: 7.061394]
2023-05-15 11:29:16.417: epoch 77:	0.02582619  	0.19002405  	0.10397675  
2023-05-15 11:29:16.417: Find a better model.
2023-05-15 11:29:23.641: [iter 78 : loss : 0.1446 = 0.0531 + 0.0870 + 0.0045, time: 7.222652]
2023-05-15 11:29:23.795: epoch 78:	0.02591792  	0.19056447  	0.10428438  
2023-05-15 11:29:23.795: Find a better model.
2023-05-15 11:29:31.050: [iter 79 : loss : 0.1434 = 0.0519 + 0.0869 + 0.0045, time: 7.253603]
2023-05-15 11:29:31.199: epoch 79:	0.02588969  	0.19018190  	0.10445324  
2023-05-15 11:29:38.421: [iter 80 : loss : 0.1427 = 0.0513 + 0.0868 + 0.0046, time: 7.220895]
2023-05-15 11:29:38.576: epoch 80:	0.02593909  	0.19043235  	0.10463490  
2023-05-15 11:29:45.848: [iter 81 : loss : 0.1422 = 0.0509 + 0.0867 + 0.0046, time: 7.270280]
2023-05-15 11:29:46.001: epoch 81:	0.02600260  	0.19118944  	0.10506666  
2023-05-15 11:29:46.001: Find a better model.
2023-05-15 11:29:53.212: [iter 82 : loss : 0.1410 = 0.0498 + 0.0866 + 0.0047, time: 7.210012]
2023-05-15 11:29:53.368: epoch 82:	0.02607316  	0.19169831  	0.10540704  
2023-05-15 11:29:53.368: Find a better model.
2023-05-15 11:30:00.449: [iter 83 : loss : 0.1401 = 0.0488 + 0.0865 + 0.0047, time: 7.080146]
2023-05-15 11:30:00.605: epoch 83:	0.02612255  	0.19204523  	0.10569459  
2023-05-15 11:30:00.605: Find a better model.
2023-05-15 11:30:07.828: [iter 84 : loss : 0.1400 = 0.0489 + 0.0864 + 0.0047, time: 7.221476]
2023-05-15 11:30:07.980: epoch 84:	0.02618606  	0.19251668  	0.10599156  
2023-05-15 11:30:07.980: Find a better model.
2023-05-15 11:30:15.235: [iter 85 : loss : 0.1390 = 0.0479 + 0.0863 + 0.0048, time: 7.253944]
2023-05-15 11:30:15.391: epoch 85:	0.02618606  	0.19251937  	0.10605817  
2023-05-15 11:30:15.391: Find a better model.
2023-05-15 11:30:22.639: [iter 86 : loss : 0.1388 = 0.0478 + 0.0862 + 0.0048, time: 7.245501]
2023-05-15 11:30:22.791: epoch 86:	0.02613667  	0.19229308  	0.10601634  
2023-05-15 11:30:30.017: [iter 87 : loss : 0.1360 = 0.0450 + 0.0861 + 0.0048, time: 7.224818]
2023-05-15 11:30:30.169: epoch 87:	0.02622135  	0.19282199  	0.10626660  
2023-05-15 11:30:30.170: Find a better model.
2023-05-15 11:30:37.423: [iter 88 : loss : 0.1353 = 0.0444 + 0.0860 + 0.0049, time: 7.251821]
2023-05-15 11:30:37.575: epoch 88:	0.02624252  	0.19315219  	0.10640541  
2023-05-15 11:30:37.575: Find a better model.
2023-05-15 11:30:44.633: [iter 89 : loss : 0.1352 = 0.0444 + 0.0860 + 0.0049, time: 7.057132]
2023-05-15 11:30:44.788: epoch 89:	0.02636954  	0.19412106  	0.10687967  
2023-05-15 11:30:44.788: Find a better model.
2023-05-15 11:30:52.009: [iter 90 : loss : 0.1357 = 0.0449 + 0.0859 + 0.0050, time: 7.220276]
2023-05-15 11:30:52.165: epoch 90:	0.02634131  	0.19356821  	0.10682990  
2023-05-15 11:30:59.401: [iter 91 : loss : 0.1345 = 0.0437 + 0.0858 + 0.0050, time: 7.235479]
2023-05-15 11:30:59.555: epoch 91:	0.02627780  	0.19312951  	0.10683590  
2023-05-15 11:31:06.624: [iter 92 : loss : 0.1336 = 0.0428 + 0.0857 + 0.0050, time: 7.067276]
2023-05-15 11:31:06.781: epoch 92:	0.02628486  	0.19301887  	0.10701559  
2023-05-15 11:31:14.006: [iter 93 : loss : 0.1337 = 0.0430 + 0.0856 + 0.0051, time: 7.224297]
2023-05-15 11:31:14.151: epoch 93:	0.02635543  	0.19382474  	0.10760566  
2023-05-15 11:31:21.396: [iter 94 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 7.244083]
2023-05-15 11:31:21.550: epoch 94:	0.02632720  	0.19342099  	0.10745873  
2023-05-15 11:31:28.613: [iter 95 : loss : 0.1310 = 0.0404 + 0.0855 + 0.0051, time: 7.061884]
2023-05-15 11:31:28.767: epoch 95:	0.02638366  	0.19391848  	0.10765590  
2023-05-15 11:31:36.010: [iter 96 : loss : 0.1311 = 0.0406 + 0.0854 + 0.0052, time: 7.240234]
2023-05-15 11:31:36.157: epoch 96:	0.02636248  	0.19375439  	0.10780454  
2023-05-15 11:31:43.199: [iter 97 : loss : 0.1294 = 0.0388 + 0.0853 + 0.0052, time: 7.039928]
2023-05-15 11:31:43.354: epoch 97:	0.02644716  	0.19437952  	0.10810257  
2023-05-15 11:31:43.354: Find a better model.
2023-05-15 11:31:50.600: [iter 98 : loss : 0.1304 = 0.0399 + 0.0852 + 0.0053, time: 7.245230]
2023-05-15 11:31:50.756: epoch 98:	0.02647538  	0.19436654  	0.10814498  
2023-05-15 11:31:58.001: [iter 99 : loss : 0.1293 = 0.0389 + 0.0852 + 0.0053, time: 7.242582]
2023-05-15 11:31:58.154: epoch 99:	0.02644010  	0.19402455  	0.10830352  
2023-05-15 11:32:05.383: [iter 100 : loss : 0.1284 = 0.0381 + 0.0851 + 0.0053, time: 7.228842]
2023-05-15 11:32:05.540: epoch 100:	0.02652478  	0.19490568  	0.10855205  
2023-05-15 11:32:05.540: Find a better model.
2023-05-15 11:32:12.766: [iter 101 : loss : 0.1282 = 0.0379 + 0.0850 + 0.0054, time: 7.224628]
2023-05-15 11:32:12.920: epoch 101:	0.02652478  	0.19517145  	0.10872366  
2023-05-15 11:32:12.920: Find a better model.
2023-05-15 11:32:20.172: [iter 102 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 7.249447]
2023-05-15 11:32:20.316: epoch 102:	0.02653889  	0.19517882  	0.10874875  
2023-05-15 11:32:20.316: Find a better model.
2023-05-15 11:32:27.574: [iter 103 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 7.256301]
2023-05-15 11:32:27.731: epoch 103:	0.02659534  	0.19534619  	0.10878243  
2023-05-15 11:32:27.731: Find a better model.
2023-05-15 11:32:34.987: [iter 104 : loss : 0.1276 = 0.0373 + 0.0848 + 0.0055, time: 7.255038]
2023-05-15 11:32:35.142: epoch 104:	0.02667297  	0.19569187  	0.10904093  
2023-05-15 11:32:35.143: Find a better model.
2023-05-15 11:32:42.383: [iter 105 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 7.238317]
2023-05-15 11:32:42.542: epoch 105:	0.02672942  	0.19648483  	0.10913642  
2023-05-15 11:32:42.542: Find a better model.
2023-05-15 11:32:49.580: [iter 106 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 7.036724]
2023-05-15 11:32:49.735: epoch 106:	0.02675765  	0.19680178  	0.10938278  
2023-05-15 11:32:49.736: Find a better model.
2023-05-15 11:32:56.970: [iter 107 : loss : 0.1252 = 0.0350 + 0.0846 + 0.0056, time: 7.233577]
2023-05-15 11:32:57.123: epoch 107:	0.02668003  	0.19605075  	0.10906380  
2023-05-15 11:33:04.374: [iter 108 : loss : 0.1250 = 0.0349 + 0.0845 + 0.0056, time: 7.248981]
2023-05-15 11:33:04.532: epoch 108:	0.02665180  	0.19567400  	0.10909264  
2023-05-15 11:33:11.760: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 7.226583]
2023-05-15 11:33:11.916: epoch 109:	0.02669415  	0.19598410  	0.10916780  
2023-05-15 11:33:19.172: [iter 110 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.254318]
2023-05-15 11:33:19.325: epoch 110:	0.02673648  	0.19642603  	0.10909202  
2023-05-15 11:33:26.563: [iter 111 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.237527]
2023-05-15 11:33:26.706: epoch 111:	0.02668708  	0.19643937  	0.10920727  
2023-05-15 11:33:36.410: [iter 112 : loss : 0.1228 = 0.0328 + 0.0843 + 0.0057, time: 9.701260]
2023-05-15 11:33:36.558: epoch 112:	0.02668709  	0.19633882  	0.10915048  
2023-05-15 11:33:43.562: [iter 113 : loss : 0.1230 = 0.0329 + 0.0843 + 0.0058, time: 7.003031]
2023-05-15 11:33:43.709: epoch 113:	0.02676471  	0.19693381  	0.10943951  
2023-05-15 11:33:43.709: Find a better model.
2023-05-15 11:33:50.758: [iter 114 : loss : 0.1219 = 0.0320 + 0.0842 + 0.0058, time: 7.047926]
2023-05-15 11:33:50.902: epoch 114:	0.02679293  	0.19662879  	0.10945784  
2023-05-15 11:33:57.963: [iter 115 : loss : 0.1214 = 0.0314 + 0.0842 + 0.0058, time: 7.060032]
2023-05-15 11:33:58.106: epoch 115:	0.02681410  	0.19705494  	0.10954254  
2023-05-15 11:33:58.107: Find a better model.
2023-05-15 11:34:05.150: [iter 116 : loss : 0.1207 = 0.0307 + 0.0841 + 0.0059, time: 7.042660]
2023-05-15 11:34:05.291: epoch 116:	0.02681410  	0.19686848  	0.10959931  
2023-05-15 11:34:12.353: [iter 117 : loss : 0.1207 = 0.0308 + 0.0841 + 0.0059, time: 7.060023]
2023-05-15 11:34:12.493: epoch 117:	0.02679293  	0.19684319  	0.10964066  
2023-05-15 11:34:19.542: [iter 118 : loss : 0.1205 = 0.0305 + 0.0840 + 0.0059, time: 7.047483]
2023-05-15 11:34:19.683: epoch 118:	0.02679999  	0.19695666  	0.10973985  
2023-05-15 11:34:26.723: [iter 119 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 7.038949]
2023-05-15 11:34:26.865: epoch 119:	0.02672943  	0.19624223  	0.10953894  
2023-05-15 11:34:33.918: [iter 120 : loss : 0.1200 = 0.0302 + 0.0839 + 0.0060, time: 7.050121]
2023-05-15 11:34:34.060: epoch 120:	0.02675059  	0.19642343  	0.10971925  
2023-05-15 11:34:41.128: [iter 121 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 7.067025]
2023-05-15 11:34:41.270: epoch 121:	0.02685644  	0.19709407  	0.10997795  
2023-05-15 11:34:41.270: Find a better model.
2023-05-15 11:34:48.324: [iter 122 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0061, time: 7.052015]
2023-05-15 11:34:48.467: epoch 122:	0.02689878  	0.19763236  	0.11002836  
2023-05-15 11:34:48.467: Find a better model.
2023-05-15 11:34:55.514: [iter 123 : loss : 0.1189 = 0.0291 + 0.0837 + 0.0061, time: 7.046013]
2023-05-15 11:34:55.655: epoch 123:	0.02689172  	0.19764188  	0.11000282  
2023-05-15 11:34:55.655: Find a better model.
2023-05-15 11:35:02.718: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 7.061996]
2023-05-15 11:35:02.863: epoch 124:	0.02677176  	0.19691285  	0.10977427  
2023-05-15 11:35:09.906: [iter 125 : loss : 0.1173 = 0.0275 + 0.0836 + 0.0061, time: 7.041996]
2023-05-15 11:35:10.050: epoch 125:	0.02670826  	0.19612119  	0.10965417  
2023-05-15 11:35:17.116: [iter 126 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0062, time: 7.065022]
2023-05-15 11:35:17.260: epoch 126:	0.02682116  	0.19731103  	0.10995910  
2023-05-15 11:35:24.303: [iter 127 : loss : 0.1165 = 0.0267 + 0.0836 + 0.0062, time: 7.041993]
2023-05-15 11:35:24.447: epoch 127:	0.02682116  	0.19738318  	0.11008701  
2023-05-15 11:35:31.515: [iter 128 : loss : 0.1176 = 0.0278 + 0.0835 + 0.0062, time: 7.067193]
2023-05-15 11:35:31.657: epoch 128:	0.02676471  	0.19707718  	0.11005598  
2023-05-15 11:35:38.702: [iter 129 : loss : 0.1167 = 0.0269 + 0.0835 + 0.0063, time: 7.043004]
2023-05-15 11:35:38.842: epoch 129:	0.02680705  	0.19727597  	0.11027634  
2023-05-15 11:35:45.902: [iter 130 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 7.057512]
2023-05-15 11:35:46.042: epoch 130:	0.02682115  	0.19695362  	0.11000296  
2023-05-15 11:35:53.103: [iter 131 : loss : 0.1160 = 0.0263 + 0.0834 + 0.0063, time: 7.059994]
2023-05-15 11:35:53.248: epoch 131:	0.02679292  	0.19663534  	0.10991004  
2023-05-15 11:36:00.291: [iter 132 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0064, time: 7.042006]
2023-05-15 11:36:00.433: epoch 132:	0.02675764  	0.19637156  	0.10995524  
2023-05-15 11:36:07.489: [iter 133 : loss : 0.1148 = 0.0252 + 0.0833 + 0.0064, time: 7.053715]
2023-05-15 11:36:07.633: epoch 133:	0.02675059  	0.19631556  	0.11002637  
2023-05-15 11:36:14.692: [iter 134 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 7.057002]
2023-05-15 11:36:14.834: epoch 134:	0.02680704  	0.19637230  	0.11003588  
2023-05-15 11:36:21.886: [iter 135 : loss : 0.1155 = 0.0258 + 0.0832 + 0.0064, time: 7.049995]
2023-05-15 11:36:22.031: epoch 135:	0.02673648  	0.19557825  	0.10977175  
2023-05-15 11:36:29.105: [iter 136 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 7.072993]
2023-05-15 11:36:29.251: epoch 136:	0.02672236  	0.19568710  	0.10983109  
2023-05-15 11:36:36.296: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 7.044330]
2023-05-15 11:36:36.442: epoch 137:	0.02672237  	0.19560331  	0.10994577  
2023-05-15 11:36:43.488: [iter 138 : loss : 0.1142 = 0.0246 + 0.0831 + 0.0065, time: 7.044993]
2023-05-15 11:36:43.633: epoch 138:	0.02669414  	0.19546075  	0.10982916  
2023-05-15 11:36:50.679: [iter 139 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 7.045009]
2023-05-15 11:36:50.823: epoch 139:	0.02673648  	0.19558421  	0.11011674  
2023-05-15 11:36:57.867: [iter 140 : loss : 0.1133 = 0.0237 + 0.0830 + 0.0066, time: 7.042996]
2023-05-15 11:36:58.007: epoch 140:	0.02669414  	0.19554397  	0.10992547  
2023-05-15 11:37:05.060: [iter 141 : loss : 0.1137 = 0.0242 + 0.0829 + 0.0066, time: 7.051172]
2023-05-15 11:37:05.204: epoch 141:	0.02665886  	0.19522960  	0.11001721  
2023-05-15 11:37:12.274: [iter 142 : loss : 0.1131 = 0.0235 + 0.0829 + 0.0066, time: 7.069332]
2023-05-15 11:37:12.415: epoch 142:	0.02670119  	0.19559078  	0.10996848  
2023-05-15 11:37:19.474: [iter 143 : loss : 0.1131 = 0.0235 + 0.0829 + 0.0067, time: 7.057995]
2023-05-15 11:37:19.617: epoch 143:	0.02670120  	0.19552024  	0.11003678  
2023-05-15 11:37:26.676: [iter 144 : loss : 0.1126 = 0.0231 + 0.0829 + 0.0067, time: 7.058080]
2023-05-15 11:37:26.822: epoch 144:	0.02676470  	0.19594662  	0.11009998  
2023-05-15 11:37:33.873: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 7.050325]
2023-05-15 11:37:34.016: epoch 145:	0.02671531  	0.19547836  	0.11001222  
2023-05-15 11:37:41.066: [iter 146 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.049015]
2023-05-15 11:37:41.208: epoch 146:	0.02668003  	0.19549945  	0.10995521  
2023-05-15 11:37:48.258: [iter 147 : loss : 0.1126 = 0.0231 + 0.0827 + 0.0068, time: 7.049043]
2023-05-15 11:37:48.401: epoch 147:	0.02672237  	0.19560541  	0.10992438  
2023-05-15 11:37:55.452: [iter 148 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0068, time: 7.048992]
2023-05-15 11:37:55.599: epoch 148:	0.02676470  	0.19612679  	0.11016378  
2023-05-15 11:37:55.599: Early stopping is trigger at epoch: 148
2023-05-15 11:37:55.599: best_result@epoch 123:

2023-05-15 11:37:55.599: 		0.0269      	0.1976      	0.1100      
2023-05-15 14:37:36.579: my pid: 6952
2023-05-15 14:37:36.579: model: model.general_recommender.SGL
2023-05-15 14:37:36.579: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 14:37:36.579: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 14:37:39.610: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 14:37:47.628: [iter 1 : loss : 0.7718 = 0.6930 + 0.0788 + 0.0000, time: 8.017376]
2023-05-15 14:37:47.782: epoch 1:	0.00140418  	0.01027700  	0.00518717  
2023-05-15 14:37:47.783: Find a better model.
2023-05-15 14:37:55.993: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.207636]
2023-05-15 14:37:56.193: epoch 2:	0.00289303  	0.02138413  	0.01045384  
2023-05-15 14:37:56.193: Find a better model.
2023-05-15 14:38:04.247: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.053709]
2023-05-15 14:38:04.412: epoch 3:	0.00529915  	0.03878091  	0.01861023  
2023-05-15 14:38:04.413: Find a better model.
2023-05-15 14:38:12.213: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.798598]
2023-05-15 14:38:12.377: epoch 4:	0.00866490  	0.06351203  	0.03040159  
2023-05-15 14:38:12.377: Find a better model.
2023-05-15 14:38:20.186: [iter 5 : loss : 0.7695 = 0.6906 + 0.0789 + 0.0000, time: 7.808345]
2023-05-15 14:38:20.332: epoch 5:	0.01250360  	0.09028070  	0.04315503  
2023-05-15 14:38:20.332: Find a better model.
2023-05-15 14:38:28.005: [iter 6 : loss : 0.7669 = 0.6876 + 0.0793 + 0.0000, time: 7.669268]
2023-05-15 14:38:28.152: epoch 6:	0.01582717  	0.11417516  	0.05581870  
2023-05-15 14:38:28.152: Find a better model.
2023-05-15 14:38:35.772: [iter 7 : loss : 0.7598 = 0.6796 + 0.0802 + 0.0000, time: 7.618796]
2023-05-15 14:38:35.914: epoch 7:	0.01789468  	0.12936710  	0.06446089  
2023-05-15 14:38:35.914: Find a better model.
2023-05-15 14:38:43.334: [iter 8 : loss : 0.7424 = 0.6601 + 0.0822 + 0.0001, time: 7.417210]
2023-05-15 14:38:43.486: epoch 8:	0.01889671  	0.13777585  	0.06928029  
2023-05-15 14:38:43.486: Find a better model.
2023-05-15 14:38:50.950: [iter 9 : loss : 0.7041 = 0.6176 + 0.0863 + 0.0001, time: 7.463376]
2023-05-15 14:38:51.104: epoch 9:	0.01881203  	0.13869125  	0.06946438  
2023-05-15 14:38:51.105: Find a better model.
2023-05-15 14:38:58.375: [iter 10 : loss : 0.6403 = 0.5483 + 0.0918 + 0.0003, time: 7.267930]
2023-05-15 14:38:58.526: epoch 10:	0.01872030  	0.13805172  	0.06912232  
2023-05-15 14:39:05.575: [iter 11 : loss : 0.5645 = 0.4674 + 0.0967 + 0.0004, time: 7.047808]
2023-05-15 14:39:05.729: epoch 11:	0.01867797  	0.13775367  	0.06904508  
2023-05-15 14:39:13.169: [iter 12 : loss : 0.4975 = 0.3971 + 0.0998 + 0.0006, time: 7.439120]
2023-05-15 14:39:13.322: epoch 12:	0.01857918  	0.13701987  	0.06893992  
2023-05-15 14:39:20.576: [iter 13 : loss : 0.4488 = 0.3466 + 0.1016 + 0.0007, time: 7.252787]
2023-05-15 14:39:20.727: epoch 13:	0.01866386  	0.13799700  	0.06945717  
2023-05-15 14:39:28.113: [iter 14 : loss : 0.4119 = 0.3086 + 0.1024 + 0.0009, time: 7.385215]
2023-05-15 14:39:28.268: epoch 14:	0.01888966  	0.13950099  	0.07040315  
2023-05-15 14:39:28.268: Find a better model.
2023-05-15 14:39:35.530: [iter 15 : loss : 0.3861 = 0.2825 + 0.1027 + 0.0010, time: 7.260914]
2023-05-15 14:39:35.685: epoch 15:	0.01900256  	0.14074165  	0.07119603  
2023-05-15 14:39:35.685: Find a better model.
2023-05-15 14:39:42.950: [iter 16 : loss : 0.3644 = 0.2606 + 0.1026 + 0.0011, time: 7.263940]
2023-05-15 14:39:43.092: epoch 16:	0.01922132  	0.14226682  	0.07195111  
2023-05-15 14:39:43.092: Find a better model.
2023-05-15 14:39:50.367: [iter 17 : loss : 0.3483 = 0.2446 + 0.1025 + 0.0012, time: 7.272698]
2023-05-15 14:39:50.508: epoch 17:	0.01946830  	0.14397329  	0.07280002  
2023-05-15 14:39:50.508: Find a better model.
2023-05-15 14:39:57.910: [iter 18 : loss : 0.3334 = 0.2299 + 0.1022 + 0.0013, time: 7.400726]
2023-05-15 14:39:58.062: epoch 18:	0.01962354  	0.14494811  	0.07355557  
2023-05-15 14:39:58.062: Find a better model.
2023-05-15 14:40:05.333: [iter 19 : loss : 0.3193 = 0.2161 + 0.1018 + 0.0014, time: 7.270521]
2023-05-15 14:40:05.488: epoch 19:	0.01984230  	0.14636791  	0.07457575  
2023-05-15 14:40:05.489: Find a better model.
2023-05-15 14:40:12.746: [iter 20 : loss : 0.3098 = 0.2069 + 0.1014 + 0.0015, time: 7.256618]
2023-05-15 14:40:12.900: epoch 20:	0.02005400  	0.14723995  	0.07499898  
2023-05-15 14:40:12.900: Find a better model.
2023-05-15 14:40:20.129: [iter 21 : loss : 0.3004 = 0.1978 + 0.1010 + 0.0016, time: 7.227741]
2023-05-15 14:40:20.282: epoch 21:	0.02029392  	0.14922313  	0.07601454  
2023-05-15 14:40:20.282: Find a better model.
2023-05-15 14:40:27.512: [iter 22 : loss : 0.2921 = 0.1898 + 0.1006 + 0.0017, time: 7.229192]
2023-05-15 14:40:27.667: epoch 22:	0.02047032  	0.15076283  	0.07670320  
2023-05-15 14:40:27.668: Find a better model.
2023-05-15 14:40:34.952: [iter 23 : loss : 0.2840 = 0.1820 + 0.1002 + 0.0017, time: 7.283165]
2023-05-15 14:40:35.106: epoch 23:	0.02061145  	0.15150116  	0.07726448  
2023-05-15 14:40:35.107: Find a better model.
2023-05-15 14:40:42.321: [iter 24 : loss : 0.2774 = 0.1759 + 0.0997 + 0.0018, time: 7.211718]
2023-05-15 14:40:42.473: epoch 24:	0.02078787  	0.15310946  	0.07798661  
2023-05-15 14:40:42.474: Find a better model.
2023-05-15 14:40:49.728: [iter 25 : loss : 0.2710 = 0.1697 + 0.0994 + 0.0019, time: 7.253396]
2023-05-15 14:40:49.885: epoch 25:	0.02100662  	0.15464710  	0.07886383  
2023-05-15 14:40:49.886: Find a better model.
2023-05-15 14:40:57.139: [iter 26 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 7.251905]
2023-05-15 14:40:57.294: epoch 26:	0.02121832  	0.15638180  	0.07975301  
2023-05-15 14:40:57.294: Find a better model.
2023-05-15 14:41:04.551: [iter 27 : loss : 0.2595 = 0.1591 + 0.0984 + 0.0020, time: 7.255431]
2023-05-15 14:41:04.702: epoch 27:	0.02136651  	0.15737741  	0.08049228  
2023-05-15 14:41:04.702: Find a better model.
2023-05-15 14:41:12.088: [iter 28 : loss : 0.2548 = 0.1546 + 0.0981 + 0.0021, time: 7.384268]
2023-05-15 14:41:12.244: epoch 28:	0.02146530  	0.15821572  	0.08110280  
2023-05-15 14:41:12.244: Find a better model.
2023-05-15 14:41:19.487: [iter 29 : loss : 0.2504 = 0.1506 + 0.0976 + 0.0021, time: 7.240695]
2023-05-15 14:41:19.641: epoch 29:	0.02159938  	0.15917446  	0.08196267  
2023-05-15 14:41:19.641: Find a better model.
2023-05-15 14:41:26.924: [iter 30 : loss : 0.2439 = 0.1444 + 0.0973 + 0.0022, time: 7.280951]
2023-05-15 14:41:27.067: epoch 30:	0.02178284  	0.16085780  	0.08278448  
2023-05-15 14:41:27.067: Find a better model.
2023-05-15 14:41:34.486: [iter 31 : loss : 0.2403 = 0.1412 + 0.0969 + 0.0023, time: 7.416430]
2023-05-15 14:41:34.639: epoch 31:	0.02192398  	0.16175815  	0.08355995  
2023-05-15 14:41:34.640: Find a better model.
2023-05-15 14:41:42.277: [iter 32 : loss : 0.2348 = 0.1360 + 0.0965 + 0.0023, time: 7.635683]
2023-05-15 14:41:42.432: epoch 32:	0.02202982  	0.16244107  	0.08401074  
2023-05-15 14:41:42.432: Find a better model.
2023-05-15 14:41:49.922: [iter 33 : loss : 0.2319 = 0.1334 + 0.0961 + 0.0024, time: 7.488945]
2023-05-15 14:41:50.075: epoch 33:	0.02224151  	0.16393219  	0.08466017  
2023-05-15 14:41:50.075: Find a better model.
2023-05-15 14:41:57.490: [iter 34 : loss : 0.2279 = 0.1296 + 0.0958 + 0.0024, time: 7.413376]
2023-05-15 14:41:57.642: epoch 34:	0.02230502  	0.16441014  	0.08520985  
2023-05-15 14:41:57.643: Find a better model.
2023-05-15 14:42:05.090: [iter 35 : loss : 0.2243 = 0.1263 + 0.0955 + 0.0025, time: 7.446064]
2023-05-15 14:42:05.245: epoch 35:	0.02244616  	0.16542318  	0.08576252  
2023-05-15 14:42:05.245: Find a better model.
2023-05-15 14:42:12.756: [iter 36 : loss : 0.2210 = 0.1233 + 0.0952 + 0.0025, time: 7.510195]
2023-05-15 14:42:12.909: epoch 36:	0.02251673  	0.16566697  	0.08632680  
2023-05-15 14:42:12.909: Find a better model.
2023-05-15 14:42:20.320: [iter 37 : loss : 0.2169 = 0.1195 + 0.0948 + 0.0026, time: 7.410545]
2023-05-15 14:42:20.475: epoch 37:	0.02269313  	0.16701657  	0.08694269  
2023-05-15 14:42:20.475: Find a better model.
2023-05-15 14:42:27.888: [iter 38 : loss : 0.2154 = 0.1182 + 0.0945 + 0.0027, time: 7.410769]
2023-05-15 14:42:28.043: epoch 38:	0.02284838  	0.16838416  	0.08777151  
2023-05-15 14:42:28.043: Find a better model.
2023-05-15 14:42:35.498: [iter 39 : loss : 0.2110 = 0.1141 + 0.0942 + 0.0027, time: 7.454287]
2023-05-15 14:42:35.651: epoch 39:	0.02296127  	0.16903189  	0.08848841  
2023-05-15 14:42:35.651: Find a better model.
2023-05-15 14:42:43.093: [iter 40 : loss : 0.2075 = 0.1109 + 0.0939 + 0.0028, time: 7.440930]
2023-05-15 14:42:43.238: epoch 40:	0.02304595  	0.16949971  	0.08875785  
2023-05-15 14:42:43.238: Find a better model.
2023-05-15 14:42:50.676: [iter 41 : loss : 0.2059 = 0.1094 + 0.0936 + 0.0028, time: 7.436822]
2023-05-15 14:42:50.830: epoch 41:	0.02320120  	0.17085227  	0.08949328  
2023-05-15 14:42:50.830: Find a better model.
2023-05-15 14:42:58.301: [iter 42 : loss : 0.2039 = 0.1077 + 0.0933 + 0.0029, time: 7.470124]
2023-05-15 14:42:58.456: epoch 42:	0.02327176  	0.17092136  	0.09007068  
2023-05-15 14:42:58.457: Find a better model.
2023-05-15 14:43:05.903: [iter 43 : loss : 0.2001 = 0.1041 + 0.0930 + 0.0029, time: 7.444838]
2023-05-15 14:43:06.058: epoch 43:	0.02341995  	0.17192076  	0.09072460  
2023-05-15 14:43:06.058: Find a better model.
2023-05-15 14:43:13.476: [iter 44 : loss : 0.1964 = 0.1007 + 0.0927 + 0.0030, time: 7.417004]
2023-05-15 14:43:13.633: epoch 44:	0.02356813  	0.17308934  	0.09130771  
2023-05-15 14:43:13.633: Find a better model.
2023-05-15 14:43:21.271: [iter 45 : loss : 0.1945 = 0.0989 + 0.0926 + 0.0030, time: 7.637643]
2023-05-15 14:43:21.427: epoch 45:	0.02363164  	0.17370011  	0.09196300  
2023-05-15 14:43:21.427: Find a better model.
2023-05-15 14:43:28.894: [iter 46 : loss : 0.1920 = 0.0966 + 0.0923 + 0.0031, time: 7.466277]
2023-05-15 14:43:29.046: epoch 46:	0.02368809  	0.17421705  	0.09243453  
2023-05-15 14:43:29.046: Find a better model.
2023-05-15 14:43:36.476: [iter 47 : loss : 0.1913 = 0.0961 + 0.0921 + 0.0031, time: 7.428580]
2023-05-15 14:43:36.629: epoch 47:	0.02379394  	0.17495821  	0.09291994  
2023-05-15 14:43:36.629: Find a better model.
2023-05-15 14:43:44.063: [iter 48 : loss : 0.1874 = 0.0925 + 0.0918 + 0.0032, time: 7.432887]
2023-05-15 14:43:44.218: epoch 48:	0.02382217  	0.17504352  	0.09328027  
2023-05-15 14:43:44.219: Find a better model.
2023-05-15 14:43:51.660: [iter 49 : loss : 0.1840 = 0.0891 + 0.0916 + 0.0032, time: 7.439599]
2023-05-15 14:43:51.802: epoch 49:	0.02399858  	0.17637131  	0.09411102  
2023-05-15 14:43:51.803: Find a better model.
2023-05-15 14:43:59.273: [iter 50 : loss : 0.1835 = 0.0888 + 0.0914 + 0.0033, time: 7.468521]
2023-05-15 14:43:59.429: epoch 50:	0.02404797  	0.17686887  	0.09443415  
2023-05-15 14:43:59.430: Find a better model.
2023-05-15 14:44:06.855: [iter 51 : loss : 0.1803 = 0.0857 + 0.0912 + 0.0033, time: 7.423436]
2023-05-15 14:44:07.008: epoch 51:	0.02416793  	0.17772575  	0.09494790  
2023-05-15 14:44:07.008: Find a better model.
2023-05-15 14:44:14.463: [iter 52 : loss : 0.1803 = 0.0860 + 0.0910 + 0.0034, time: 7.453945]
2023-05-15 14:44:14.616: epoch 52:	0.02430906  	0.17886241  	0.09561203  
2023-05-15 14:44:14.617: Find a better model.
2023-05-15 14:44:22.066: [iter 53 : loss : 0.1782 = 0.0840 + 0.0908 + 0.0034, time: 7.448596]
2023-05-15 14:44:22.220: epoch 53:	0.02438668  	0.17926210  	0.09588177  
2023-05-15 14:44:22.220: Find a better model.
2023-05-15 14:44:29.652: [iter 54 : loss : 0.1762 = 0.0822 + 0.0906 + 0.0035, time: 7.429735]
2023-05-15 14:44:29.804: epoch 54:	0.02440079  	0.17906383  	0.09614700  
2023-05-15 14:44:37.267: [iter 55 : loss : 0.1742 = 0.0803 + 0.0904 + 0.0035, time: 7.460486]
2023-05-15 14:44:37.420: epoch 55:	0.02449958  	0.17991973  	0.09655460  
2023-05-15 14:44:37.420: Find a better model.
2023-05-15 14:44:44.846: [iter 56 : loss : 0.1723 = 0.0785 + 0.0902 + 0.0035, time: 7.424547]
2023-05-15 14:44:45.001: epoch 56:	0.02446429  	0.17984205  	0.09678835  
2023-05-15 14:44:52.447: [iter 57 : loss : 0.1706 = 0.0769 + 0.0901 + 0.0036, time: 7.444668]
2023-05-15 14:44:52.603: epoch 57:	0.02456308  	0.18069905  	0.09718559  
2023-05-15 14:44:52.603: Find a better model.
2023-05-15 14:45:00.039: [iter 58 : loss : 0.1688 = 0.0753 + 0.0899 + 0.0036, time: 7.435207]
2023-05-15 14:45:00.193: epoch 58:	0.02469716  	0.18125461  	0.09768930  
2023-05-15 14:45:00.193: Find a better model.
2023-05-15 14:45:07.642: [iter 59 : loss : 0.1677 = 0.0743 + 0.0897 + 0.0037, time: 7.448037]
2023-05-15 14:45:07.795: epoch 59:	0.02466188  	0.18108216  	0.09777874  
2023-05-15 14:45:15.237: [iter 60 : loss : 0.1662 = 0.0730 + 0.0895 + 0.0037, time: 7.441049]
2023-05-15 14:45:15.379: epoch 60:	0.02476773  	0.18195637  	0.09832685  
2023-05-15 14:45:15.379: Find a better model.
2023-05-15 14:45:22.788: [iter 61 : loss : 0.1648 = 0.0718 + 0.0893 + 0.0038, time: 7.407780]
2023-05-15 14:45:22.930: epoch 61:	0.02482418  	0.18270555  	0.09870023  
2023-05-15 14:45:22.930: Find a better model.
2023-05-15 14:45:30.228: [iter 62 : loss : 0.1634 = 0.0704 + 0.0892 + 0.0038, time: 7.296793]
2023-05-15 14:45:30.374: epoch 62:	0.02487358  	0.18280745  	0.09892618  
2023-05-15 14:45:30.374: Find a better model.
2023-05-15 14:45:37.651: [iter 63 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 7.275888]
2023-05-15 14:45:37.806: epoch 63:	0.02495825  	0.18355094  	0.09926227  
2023-05-15 14:45:37.806: Find a better model.
2023-05-15 14:45:45.022: [iter 64 : loss : 0.1611 = 0.0683 + 0.0889 + 0.0039, time: 7.214914]
2023-05-15 14:45:45.173: epoch 64:	0.02498648  	0.18399155  	0.09958041  
2023-05-15 14:45:45.173: Find a better model.
2023-05-15 14:45:52.415: [iter 65 : loss : 0.1595 = 0.0669 + 0.0887 + 0.0039, time: 7.241417]
2023-05-15 14:45:52.563: epoch 65:	0.02503587  	0.18424681  	0.09986118  
2023-05-15 14:45:52.563: Find a better model.
2023-05-15 14:45:59.815: [iter 66 : loss : 0.1580 = 0.0655 + 0.0886 + 0.0040, time: 7.251933]
2023-05-15 14:45:59.969: epoch 66:	0.02509232  	0.18481475  	0.10038821  
2023-05-15 14:45:59.969: Find a better model.
2023-05-15 14:46:07.236: [iter 67 : loss : 0.1564 = 0.0639 + 0.0884 + 0.0040, time: 7.265098]
2023-05-15 14:46:07.377: epoch 67:	0.02511349  	0.18503398  	0.10054748  
2023-05-15 14:46:07.377: Find a better model.
2023-05-15 14:46:14.579: [iter 68 : loss : 0.1562 = 0.0638 + 0.0883 + 0.0041, time: 7.201017]
2023-05-15 14:46:14.736: epoch 68:	0.02519817  	0.18589245  	0.10103177  
2023-05-15 14:46:14.736: Find a better model.
2023-05-15 14:46:21.996: [iter 69 : loss : 0.1543 = 0.0621 + 0.0881 + 0.0041, time: 7.258862]
2023-05-15 14:46:22.139: epoch 69:	0.02524051  	0.18591660  	0.10110815  
2023-05-15 14:46:22.139: Find a better model.
2023-05-15 14:46:29.418: [iter 70 : loss : 0.1527 = 0.0606 + 0.0880 + 0.0042, time: 7.277778]
2023-05-15 14:46:29.571: epoch 70:	0.02531108  	0.18652450  	0.10131665  
2023-05-15 14:46:29.571: Find a better model.
2023-05-15 14:46:36.800: [iter 71 : loss : 0.1512 = 0.0591 + 0.0879 + 0.0042, time: 7.228379]
2023-05-15 14:46:36.955: epoch 71:	0.02533930  	0.18657017  	0.10151894  
2023-05-15 14:46:36.955: Find a better model.
2023-05-15 14:46:44.368: [iter 72 : loss : 0.1511 = 0.0591 + 0.0878 + 0.0042, time: 7.412907]
2023-05-15 14:46:44.523: epoch 72:	0.02542398  	0.18741348  	0.10196087  
2023-05-15 14:46:44.523: Find a better model.
2023-05-15 14:46:51.825: [iter 73 : loss : 0.1499 = 0.0580 + 0.0877 + 0.0043, time: 7.299782]
2023-05-15 14:46:51.980: epoch 73:	0.02540987  	0.18716837  	0.10204906  
2023-05-15 14:46:59.191: [iter 74 : loss : 0.1482 = 0.0564 + 0.0875 + 0.0043, time: 7.210268]
2023-05-15 14:46:59.343: epoch 74:	0.02552277  	0.18820260  	0.10239001  
2023-05-15 14:46:59.343: Find a better model.
2023-05-15 14:47:06.604: [iter 75 : loss : 0.1475 = 0.0557 + 0.0874 + 0.0044, time: 7.259631]
2023-05-15 14:47:06.759: epoch 75:	0.02557922  	0.18873133  	0.10270250  
2023-05-15 14:47:06.759: Find a better model.
2023-05-15 14:47:14.005: [iter 76 : loss : 0.1468 = 0.0550 + 0.0873 + 0.0044, time: 7.243920]
2023-05-15 14:47:14.158: epoch 76:	0.02556511  	0.18841901  	0.10292615  
2023-05-15 14:47:21.392: [iter 77 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 7.232123]
2023-05-15 14:47:21.533: epoch 77:	0.02564979  	0.18945257  	0.10331681  
2023-05-15 14:47:21.533: Find a better model.
2023-05-15 14:47:28.775: [iter 78 : loss : 0.1449 = 0.0533 + 0.0870 + 0.0045, time: 7.241366]
2023-05-15 14:47:28.929: epoch 78:	0.02565684  	0.18959679  	0.10360184  
2023-05-15 14:47:28.929: Find a better model.
2023-05-15 14:47:36.352: [iter 79 : loss : 0.1436 = 0.0522 + 0.0870 + 0.0045, time: 7.421873]
2023-05-15 14:47:36.510: epoch 79:	0.02578386  	0.19041596  	0.10393268  
2023-05-15 14:47:36.510: Find a better model.
2023-05-15 14:47:43.808: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 7.297343]
2023-05-15 14:47:43.961: epoch 80:	0.02582620  	0.19066201  	0.10391591  
2023-05-15 14:47:43.962: Find a better model.
2023-05-15 14:47:51.174: [iter 81 : loss : 0.1425 = 0.0512 + 0.0868 + 0.0046, time: 7.210844]
2023-05-15 14:47:51.330: epoch 81:	0.02584031  	0.19074410  	0.10417052  
2023-05-15 14:47:51.331: Find a better model.
2023-05-15 14:47:58.585: [iter 82 : loss : 0.1413 = 0.0501 + 0.0866 + 0.0046, time: 7.253433]
2023-05-15 14:47:58.740: epoch 82:	0.02586853  	0.19079642  	0.10427634  
2023-05-15 14:47:58.740: Find a better model.
2023-05-15 14:48:05.989: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.246536]
2023-05-15 14:48:06.144: epoch 83:	0.02591793  	0.19137417  	0.10458419  
2023-05-15 14:48:06.144: Find a better model.
2023-05-15 14:48:13.365: [iter 84 : loss : 0.1403 = 0.0491 + 0.0864 + 0.0047, time: 7.220274]
2023-05-15 14:48:13.519: epoch 84:	0.02596733  	0.19169343  	0.10487588  
2023-05-15 14:48:13.519: Find a better model.
2023-05-15 14:48:20.759: [iter 85 : loss : 0.1391 = 0.0480 + 0.0863 + 0.0048, time: 7.239429]
2023-05-15 14:48:20.915: epoch 85:	0.02600967  	0.19199128  	0.10522582  
2023-05-15 14:48:20.915: Find a better model.
2023-05-15 14:48:28.186: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 7.268925]
2023-05-15 14:48:28.340: epoch 86:	0.02604495  	0.19197452  	0.10533997  
2023-05-15 14:48:35.584: [iter 87 : loss : 0.1363 = 0.0453 + 0.0862 + 0.0048, time: 7.240484]
2023-05-15 14:48:35.739: epoch 87:	0.02612963  	0.19259126  	0.10562993  
2023-05-15 14:48:35.739: Find a better model.
2023-05-15 14:48:42.959: [iter 88 : loss : 0.1359 = 0.0450 + 0.0861 + 0.0049, time: 7.218743]
2023-05-15 14:48:43.113: epoch 88:	0.02612963  	0.19293353  	0.10577128  
2023-05-15 14:48:43.113: Find a better model.
2023-05-15 14:48:50.357: [iter 89 : loss : 0.1354 = 0.0445 + 0.0860 + 0.0049, time: 7.243406]
2023-05-15 14:48:50.513: epoch 89:	0.02612257  	0.19279326  	0.10572714  
2023-05-15 14:48:57.753: [iter 90 : loss : 0.1361 = 0.0452 + 0.0859 + 0.0049, time: 7.237679]
2023-05-15 14:48:57.906: epoch 90:	0.02610140  	0.19265027  	0.10583668  
2023-05-15 14:49:05.155: [iter 91 : loss : 0.1346 = 0.0438 + 0.0858 + 0.0050, time: 7.248241]
2023-05-15 14:49:05.296: epoch 91:	0.02609434  	0.19254373  	0.10604250  
2023-05-15 14:49:12.544: [iter 92 : loss : 0.1338 = 0.0431 + 0.0857 + 0.0050, time: 7.246715]
2023-05-15 14:49:12.702: epoch 92:	0.02610140  	0.19238842  	0.10609683  
2023-05-15 14:49:19.967: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 7.264025]
2023-05-15 14:49:20.122: epoch 93:	0.02619313  	0.19293846  	0.10633334  
2023-05-15 14:49:20.122: Find a better model.
2023-05-15 14:49:27.356: [iter 94 : loss : 0.1317 = 0.0411 + 0.0856 + 0.0051, time: 7.232058]
2023-05-15 14:49:27.508: epoch 94:	0.02625664  	0.19370262  	0.10659205  
2023-05-15 14:49:27.508: Find a better model.
2023-05-15 14:49:34.743: [iter 95 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 7.233925]
2023-05-15 14:49:34.895: epoch 95:	0.02628486  	0.19360474  	0.10669405  
2023-05-15 14:49:42.163: [iter 96 : loss : 0.1312 = 0.0406 + 0.0854 + 0.0052, time: 7.267019]
2023-05-15 14:49:42.316: epoch 96:	0.02627781  	0.19351982  	0.10672249  
2023-05-15 14:49:49.714: [iter 97 : loss : 0.1295 = 0.0390 + 0.0853 + 0.0052, time: 7.395608]
2023-05-15 14:49:49.868: epoch 97:	0.02628486  	0.19353341  	0.10682435  
2023-05-15 14:49:57.339: [iter 98 : loss : 0.1307 = 0.0402 + 0.0853 + 0.0052, time: 7.468703]
2023-05-15 14:49:57.491: epoch 98:	0.02627075  	0.19365932  	0.10692617  
2023-05-15 14:50:04.904: [iter 99 : loss : 0.1294 = 0.0390 + 0.0852 + 0.0053, time: 7.412551]
2023-05-15 14:50:05.058: epoch 99:	0.02624252  	0.19346702  	0.10693336  
2023-05-15 14:50:12.343: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 7.284549]
2023-05-15 14:50:12.496: epoch 100:	0.02634132  	0.19406345  	0.10709220  
2023-05-15 14:50:12.496: Find a better model.
2023-05-15 14:50:19.718: [iter 101 : loss : 0.1283 = 0.0380 + 0.0850 + 0.0053, time: 7.219589]
2023-05-15 14:50:19.873: epoch 101:	0.02637660  	0.19450462  	0.10732536  
2023-05-15 14:50:19.873: Find a better model.
2023-05-15 14:50:27.129: [iter 102 : loss : 0.1274 = 0.0371 + 0.0850 + 0.0054, time: 7.255127]
2023-05-15 14:50:27.284: epoch 102:	0.02640482  	0.19475491  	0.10757361  
2023-05-15 14:50:27.284: Find a better model.
2023-05-15 14:50:34.781: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 7.495589]
2023-05-15 14:50:34.937: epoch 103:	0.02631309  	0.19404069  	0.10744283  
2023-05-15 14:50:42.116: [iter 104 : loss : 0.1275 = 0.0372 + 0.0848 + 0.0055, time: 7.177301]
2023-05-15 14:50:42.256: epoch 104:	0.02646834  	0.19542009  	0.10800688  
2023-05-15 14:50:42.256: Find a better model.
2023-05-15 14:50:49.694: [iter 105 : loss : 0.1269 = 0.0367 + 0.0848 + 0.0055, time: 7.436406]
2023-05-15 14:50:49.853: epoch 105:	0.02638365  	0.19478728  	0.10774170  
2023-05-15 14:50:57.113: [iter 106 : loss : 0.1263 = 0.0362 + 0.0847 + 0.0055, time: 7.258374]
2023-05-15 14:50:57.266: epoch 106:	0.02639776  	0.19499470  	0.10781451  
2023-05-15 14:51:04.525: [iter 107 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0055, time: 7.257873]
2023-05-15 14:51:04.667: epoch 107:	0.02642599  	0.19516562  	0.10808786  
2023-05-15 14:51:11.885: [iter 108 : loss : 0.1252 = 0.0351 + 0.0846 + 0.0056, time: 7.217178]
2023-05-15 14:51:12.039: epoch 108:	0.02646833  	0.19531371  	0.10825589  
2023-05-15 14:51:19.277: [iter 109 : loss : 0.1239 = 0.0337 + 0.0845 + 0.0056, time: 7.237290]
2023-05-15 14:51:19.430: epoch 109:	0.02647538  	0.19550999  	0.10815220  
2023-05-15 14:51:19.430: Find a better model.
2023-05-15 14:51:26.715: [iter 110 : loss : 0.1233 = 0.0332 + 0.0845 + 0.0057, time: 7.284076]
2023-05-15 14:51:26.874: epoch 110:	0.02660240  	0.19644660  	0.10832769  
2023-05-15 14:51:26.874: Find a better model.
2023-05-15 14:51:34.086: [iter 111 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.210624]
2023-05-15 14:51:34.230: epoch 111:	0.02657417  	0.19589028  	0.10826760  
2023-05-15 14:51:41.299: [iter 112 : loss : 0.1229 = 0.0329 + 0.0843 + 0.0057, time: 7.065840]
2023-05-15 14:51:41.453: epoch 112:	0.02656711  	0.19581206  	0.10840857  
2023-05-15 14:51:48.661: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0058, time: 7.206746]
2023-05-15 14:51:48.805: epoch 113:	0.02655300  	0.19534495  	0.10827605  
2023-05-15 14:51:55.895: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 7.089469]
2023-05-15 14:51:56.038: epoch 114:	0.02658829  	0.19564478  	0.10844964  
2023-05-15 14:52:03.286: [iter 115 : loss : 0.1218 = 0.0318 + 0.0842 + 0.0058, time: 7.246444]
2023-05-15 14:52:03.440: epoch 115:	0.02663768  	0.19577944  	0.10846314  
2023-05-15 14:52:10.686: [iter 116 : loss : 0.1208 = 0.0308 + 0.0841 + 0.0058, time: 7.244894]
2023-05-15 14:52:10.828: epoch 116:	0.02659534  	0.19554083  	0.10842227  
2023-05-15 14:52:18.080: [iter 117 : loss : 0.1208 = 0.0308 + 0.0841 + 0.0059, time: 7.250762]
2023-05-15 14:52:18.235: epoch 117:	0.02662356  	0.19534759  	0.10844590  
2023-05-15 14:52:25.457: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.219809]
2023-05-15 14:52:25.611: epoch 118:	0.02667296  	0.19577739  	0.10883527  
2023-05-15 14:52:32.874: [iter 119 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0059, time: 7.262699]
2023-05-15 14:52:33.027: epoch 119:	0.02664473  	0.19566335  	0.10871239  
2023-05-15 14:52:40.262: [iter 120 : loss : 0.1197 = 0.0298 + 0.0839 + 0.0060, time: 7.233941]
2023-05-15 14:52:40.417: epoch 120:	0.02665179  	0.19602230  	0.10880892  
2023-05-15 14:52:47.648: [iter 121 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 7.228706]
2023-05-15 14:52:47.790: epoch 121:	0.02671529  	0.19655405  	0.10903140  
2023-05-15 14:52:47.791: Find a better model.
2023-05-15 14:52:54.868: [iter 122 : loss : 0.1191 = 0.0292 + 0.0838 + 0.0060, time: 7.075684]
2023-05-15 14:52:55.026: epoch 122:	0.02671530  	0.19653316  	0.10917049  
2023-05-15 14:53:02.088: [iter 123 : loss : 0.1190 = 0.0292 + 0.0838 + 0.0061, time: 7.059999]
2023-05-15 14:53:02.242: epoch 123:	0.02666590  	0.19592193  	0.10884044  
2023-05-15 14:53:09.439: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 7.195794]
2023-05-15 14:53:09.593: epoch 124:	0.02672941  	0.19650581  	0.10912257  
2023-05-15 14:53:16.840: [iter 125 : loss : 0.1175 = 0.0276 + 0.0837 + 0.0061, time: 7.246542]
2023-05-15 14:53:16.996: epoch 125:	0.02670119  	0.19651617  	0.10904905  
2023-05-15 14:53:24.095: [iter 126 : loss : 0.1177 = 0.0280 + 0.0836 + 0.0062, time: 7.097452]
2023-05-15 14:53:24.250: epoch 126:	0.02668002  	0.19639893  	0.10906426  
2023-05-15 14:53:31.474: [iter 127 : loss : 0.1168 = 0.0270 + 0.0836 + 0.0062, time: 7.222600]
2023-05-15 14:53:31.627: epoch 127:	0.02665884  	0.19611879  	0.10909443  
2023-05-15 14:53:38.840: [iter 128 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 7.212250]
2023-05-15 14:53:38.995: epoch 128:	0.02672235  	0.19612861  	0.10928071  
2023-05-15 14:53:46.244: [iter 129 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0063, time: 7.248307]
2023-05-15 14:53:46.399: epoch 129:	0.02667296  	0.19599099  	0.10914260  
2023-05-15 14:53:53.646: [iter 130 : loss : 0.1171 = 0.0274 + 0.0834 + 0.0063, time: 7.245548]
2023-05-15 14:53:53.798: epoch 130:	0.02656006  	0.19529617  	0.10905350  
2023-05-15 14:54:00.858: [iter 131 : loss : 0.1160 = 0.0263 + 0.0834 + 0.0063, time: 7.058114]
2023-05-15 14:54:01.011: epoch 131:	0.02659534  	0.19564922  	0.10903316  
2023-05-15 14:54:08.242: [iter 132 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 7.229890]
2023-05-15 14:54:08.394: epoch 132:	0.02669412  	0.19610213  	0.10909615  
2023-05-15 14:54:15.463: [iter 133 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 7.068231]
2023-05-15 14:54:15.617: epoch 133:	0.02661650  	0.19561607  	0.10902036  
2023-05-15 14:54:22.826: [iter 134 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 7.208197]
2023-05-15 14:54:22.981: epoch 134:	0.02667296  	0.19579922  	0.10909089  
2023-05-15 14:54:30.207: [iter 135 : loss : 0.1156 = 0.0259 + 0.0832 + 0.0064, time: 7.222297]
2023-05-15 14:54:30.349: epoch 135:	0.02665885  	0.19580871  	0.10915320  
2023-05-15 14:54:37.633: [iter 136 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0065, time: 7.282213]
2023-05-15 14:54:37.789: epoch 136:	0.02670824  	0.19610575  	0.10945595  
2023-05-15 14:54:45.061: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 7.269878]
2023-05-15 14:54:45.214: epoch 137:	0.02668001  	0.19614461  	0.10945909  
2023-05-15 14:54:52.402: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 7.185915]
2023-05-15 14:54:52.557: epoch 138:	0.02670118  	0.19645213  	0.10960246  
2023-05-15 14:54:59.813: [iter 139 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 7.255661]
2023-05-15 14:54:59.954: epoch 139:	0.02667296  	0.19602777  	0.10967828  
2023-05-15 14:55:07.237: [iter 140 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 7.279147]
2023-05-15 14:55:07.389: epoch 140:	0.02669412  	0.19620205  	0.10965133  
2023-05-15 14:55:14.628: [iter 141 : loss : 0.1140 = 0.0245 + 0.0830 + 0.0066, time: 7.237372]
2023-05-15 14:55:14.782: epoch 141:	0.02668707  	0.19604635  	0.10982989  
2023-05-15 14:55:22.010: [iter 142 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 7.227148]
2023-05-15 14:55:22.155: epoch 142:	0.02668002  	0.19596520  	0.10985611  
2023-05-15 14:55:29.237: [iter 143 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0067, time: 7.080952]
2023-05-15 14:55:29.392: epoch 143:	0.02668707  	0.19637692  	0.11004885  
2023-05-15 14:55:36.586: [iter 144 : loss : 0.1127 = 0.0231 + 0.0829 + 0.0067, time: 7.193352]
2023-05-15 14:55:36.728: epoch 144:	0.02670118  	0.19615294  	0.11001767  
2023-05-15 14:55:43.821: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 7.092088]
2023-05-15 14:55:43.973: epoch 145:	0.02679997  	0.19666928  	0.11026042  
2023-05-15 14:55:43.973: Find a better model.
2023-05-15 14:55:51.239: [iter 146 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.265071]
2023-05-15 14:55:51.392: epoch 146:	0.02677880  	0.19677515  	0.11037660  
2023-05-15 14:55:51.392: Find a better model.
2023-05-15 14:55:58.617: [iter 147 : loss : 0.1127 = 0.0232 + 0.0827 + 0.0068, time: 7.222970]
2023-05-15 14:55:58.772: epoch 147:	0.02679997  	0.19717036  	0.11062161  
2023-05-15 14:55:58.772: Find a better model.
2023-05-15 14:56:05.997: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.223715]
2023-05-15 14:56:06.154: epoch 148:	0.02677880  	0.19686604  	0.11045308  
2023-05-15 14:56:13.396: [iter 149 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 7.240974]
2023-05-15 14:56:13.549: epoch 149:	0.02680703  	0.19723088  	0.11065260  
2023-05-15 14:56:13.549: Find a better model.
2023-05-15 14:56:20.814: [iter 150 : loss : 0.1114 = 0.0218 + 0.0827 + 0.0068, time: 7.264237]
2023-05-15 14:56:20.969: epoch 150:	0.02684231  	0.19739345  	0.11067288  
2023-05-15 14:56:20.969: Find a better model.
2023-05-15 14:56:28.198: [iter 151 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0069, time: 7.227515]
2023-05-15 14:56:28.350: epoch 151:	0.02674352  	0.19662523  	0.11066023  
2023-05-15 14:56:35.577: [iter 152 : loss : 0.1108 = 0.0214 + 0.0826 + 0.0069, time: 7.224507]
2023-05-15 14:56:35.723: epoch 152:	0.02678586  	0.19692490  	0.11071368  
2023-05-15 14:56:42.979: [iter 153 : loss : 0.1097 = 0.0202 + 0.0826 + 0.0069, time: 7.254775]
2023-05-15 14:56:43.137: epoch 153:	0.02675058  	0.19662072  	0.11048579  
2023-05-15 14:56:50.351: [iter 154 : loss : 0.1105 = 0.0210 + 0.0826 + 0.0069, time: 7.212508]
2023-05-15 14:56:50.493: epoch 154:	0.02679291  	0.19675966  	0.11059567  
2023-05-15 14:56:57.756: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 7.261905]
2023-05-15 14:56:57.908: epoch 155:	0.02679998  	0.19707729  	0.11077297  
2023-05-15 14:57:05.010: [iter 156 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0070, time: 7.100992]
2023-05-15 14:57:05.167: epoch 156:	0.02677880  	0.19667606  	0.11073872  
2023-05-15 14:57:12.406: [iter 157 : loss : 0.1102 = 0.0208 + 0.0824 + 0.0070, time: 7.238190]
2023-05-15 14:57:12.559: epoch 157:	0.02673646  	0.19631787  	0.11049594  
2023-05-15 14:57:19.770: [iter 158 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.210412]
2023-05-15 14:57:19.926: epoch 158:	0.02677880  	0.19640815  	0.11060464  
2023-05-15 14:57:27.140: [iter 159 : loss : 0.1095 = 0.0201 + 0.0824 + 0.0071, time: 7.211998]
2023-05-15 14:57:27.285: epoch 159:	0.02672235  	0.19576526  	0.11050312  
2023-05-15 14:57:34.570: [iter 160 : loss : 0.1094 = 0.0200 + 0.0823 + 0.0071, time: 7.282922]
2023-05-15 14:57:34.722: epoch 160:	0.02670824  	0.19522221  	0.11046206  
2023-05-15 14:57:41.955: [iter 161 : loss : 0.1090 = 0.0195 + 0.0823 + 0.0071, time: 7.232087]
2023-05-15 14:57:42.109: epoch 161:	0.02665884  	0.19479086  	0.11015354  
2023-05-15 14:57:49.338: [iter 162 : loss : 0.1084 = 0.0189 + 0.0823 + 0.0072, time: 7.227571]
2023-05-15 14:57:49.493: epoch 162:	0.02672235  	0.19567044  	0.11031686  
2023-05-15 14:57:56.754: [iter 163 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0072, time: 7.258846]
2023-05-15 14:57:56.906: epoch 163:	0.02672235  	0.19591825  	0.11047947  
2023-05-15 14:58:03.954: [iter 164 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.046795]
2023-05-15 14:58:04.096: epoch 164:	0.02667296  	0.19568011  	0.11061960  
2023-05-15 14:58:11.349: [iter 165 : loss : 0.1084 = 0.0189 + 0.0822 + 0.0072, time: 7.251584]
2023-05-15 14:58:11.502: epoch 165:	0.02666590  	0.19526094  	0.11040798  
2023-05-15 14:58:18.585: [iter 166 : loss : 0.1081 = 0.0187 + 0.0822 + 0.0072, time: 7.081605]
2023-05-15 14:58:18.740: epoch 166:	0.02656711  	0.19449297  	0.11011025  
2023-05-15 14:58:25.984: [iter 167 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0073, time: 7.242172]
2023-05-15 14:58:26.126: epoch 167:	0.02659534  	0.19449203  	0.11007252  
2023-05-15 14:58:33.320: [iter 168 : loss : 0.1078 = 0.0183 + 0.0822 + 0.0073, time: 7.191539]
2023-05-15 14:58:33.478: epoch 168:	0.02670824  	0.19527738  	0.11027072  
2023-05-15 14:58:40.555: [iter 169 : loss : 0.1081 = 0.0187 + 0.0821 + 0.0073, time: 7.076074]
2023-05-15 14:58:40.710: epoch 169:	0.02668707  	0.19540219  	0.11029349  
2023-05-15 14:58:47.954: [iter 170 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 7.242392]
2023-05-15 14:58:48.097: epoch 170:	0.02663768  	0.19513866  	0.11014158  
2023-05-15 14:58:55.318: [iter 171 : loss : 0.1081 = 0.0187 + 0.0821 + 0.0074, time: 7.217620]
2023-05-15 14:58:55.473: epoch 171:	0.02662356  	0.19470675  	0.10999672  
2023-05-15 14:59:02.719: [iter 172 : loss : 0.1071 = 0.0176 + 0.0821 + 0.0074, time: 7.244060]
2023-05-15 14:59:02.864: epoch 172:	0.02663768  	0.19460678  	0.10994279  
2023-05-15 14:59:09.954: [iter 173 : loss : 0.1076 = 0.0181 + 0.0820 + 0.0074, time: 7.089435]
2023-05-15 14:59:10.098: epoch 173:	0.02657417  	0.19424886  	0.10965955  
2023-05-15 14:59:17.131: [iter 174 : loss : 0.1076 = 0.0182 + 0.0820 + 0.0074, time: 7.031007]
2023-05-15 14:59:17.286: epoch 174:	0.02658122  	0.19407789  	0.10959832  
2023-05-15 14:59:24.510: [iter 175 : loss : 0.1068 = 0.0173 + 0.0820 + 0.0075, time: 7.222208]
2023-05-15 14:59:24.663: epoch 175:	0.02648243  	0.19340636  	0.10927749  
2023-05-15 14:59:24.664: Early stopping is trigger at epoch: 175
2023-05-15 14:59:24.664: best_result@epoch 150:

2023-05-15 14:59:24.664: 		0.0268      	0.1974      	0.1107      
2023-05-15 14:59:59.873: my pid: 10228
2023-05-15 14:59:59.873: model: model.general_recommender.SGL
2023-05-15 14:59:59.873: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 14:59:59.873: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 15:00:02.957: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 15:00:10.924: [iter 1 : loss : 0.7718 = 0.6930 + 0.0788 + 0.0000, time: 7.966660]
2023-05-15 15:00:11.082: epoch 1:	0.00169348  	0.01204154  	0.00558031  
2023-05-15 15:00:11.082: Find a better model.
2023-05-15 15:00:19.186: [iter 2 : loss : 0.7714 = 0.6928 + 0.0785 + 0.0000, time: 8.103503]
2023-05-15 15:00:19.387: epoch 2:	0.00326700  	0.02401051  	0.01159151  
2023-05-15 15:00:19.387: Find a better model.
2023-05-15 15:00:27.384: [iter 3 : loss : 0.7711 = 0.6925 + 0.0786 + 0.0000, time: 7.996328]
2023-05-15 15:00:27.556: epoch 3:	0.00529915  	0.03877090  	0.01893277  
2023-05-15 15:00:27.556: Find a better model.
2023-05-15 15:00:35.382: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.825606]
2023-05-15 15:00:35.536: epoch 4:	0.00872840  	0.06359542  	0.03002095  
2023-05-15 15:00:35.536: Find a better model.
2023-05-15 15:00:43.285: [iter 5 : loss : 0.7695 = 0.6906 + 0.0789 + 0.0000, time: 7.747219]
2023-05-15 15:00:43.444: epoch 5:	0.01222839  	0.08877189  	0.04234127  
2023-05-15 15:00:43.444: Find a better model.
2023-05-15 15:00:51.119: [iter 6 : loss : 0.7668 = 0.6875 + 0.0794 + 0.0000, time: 7.674460]
2023-05-15 15:00:51.276: epoch 6:	0.01566487  	0.11323500  	0.05519700  
2023-05-15 15:00:51.276: Find a better model.
2023-05-15 15:00:58.698: [iter 7 : loss : 0.7596 = 0.6794 + 0.0802 + 0.0000, time: 7.420820]
2023-05-15 15:00:58.840: epoch 7:	0.01783119  	0.12950680  	0.06396113  
2023-05-15 15:00:58.840: Find a better model.
2023-05-15 15:01:06.086: [iter 8 : loss : 0.7420 = 0.6596 + 0.0823 + 0.0001, time: 7.244992]
2023-05-15 15:01:06.240: epoch 8:	0.01891789  	0.13847455  	0.06875764  
2023-05-15 15:01:06.240: Find a better model.
2023-05-15 15:01:13.472: [iter 9 : loss : 0.7034 = 0.6168 + 0.0864 + 0.0002, time: 7.231443]
2023-05-15 15:01:13.624: epoch 9:	0.01884732  	0.13910772  	0.06930783  
2023-05-15 15:01:13.624: Find a better model.
2023-05-15 15:01:20.692: [iter 10 : loss : 0.6399 = 0.5478 + 0.0919 + 0.0003, time: 7.066618]
2023-05-15 15:01:20.833: epoch 10:	0.01864974  	0.13778518  	0.06843123  
2023-05-15 15:01:27.891: [iter 11 : loss : 0.5645 = 0.4674 + 0.0967 + 0.0004, time: 7.057038]
2023-05-15 15:01:28.032: epoch 11:	0.01857212  	0.13655479  	0.06851833  
2023-05-15 15:01:35.115: [iter 12 : loss : 0.4980 = 0.3976 + 0.0998 + 0.0006, time: 7.080651]
2023-05-15 15:01:35.267: epoch 12:	0.01848039  	0.13591041  	0.06838061  
2023-05-15 15:01:42.289: [iter 13 : loss : 0.4492 = 0.3470 + 0.1015 + 0.0007, time: 7.020419]
2023-05-15 15:01:42.443: epoch 13:	0.01872737  	0.13787548  	0.06911774  
2023-05-15 15:01:49.483: [iter 14 : loss : 0.4122 = 0.3091 + 0.1023 + 0.0009, time: 7.037905]
2023-05-15 15:01:49.635: epoch 14:	0.01901668  	0.14066647  	0.07041327  
2023-05-15 15:01:49.635: Find a better model.
2023-05-15 15:01:56.712: [iter 15 : loss : 0.3864 = 0.2827 + 0.1027 + 0.0010, time: 7.076047]
2023-05-15 15:01:56.851: epoch 15:	0.01909430  	0.14122352  	0.07122004  
2023-05-15 15:01:56.851: Find a better model.
2023-05-15 15:02:04.051: [iter 16 : loss : 0.3645 = 0.2608 + 0.1026 + 0.0011, time: 7.199023]
2023-05-15 15:02:04.204: epoch 16:	0.01922838  	0.14166217  	0.07155611  
2023-05-15 15:02:04.204: Find a better model.
2023-05-15 15:02:11.302: [iter 17 : loss : 0.3485 = 0.2449 + 0.1024 + 0.0012, time: 7.097079]
2023-05-15 15:02:11.443: epoch 17:	0.01941185  	0.14307930  	0.07240018  
2023-05-15 15:02:11.443: Find a better model.
2023-05-15 15:02:18.470: [iter 18 : loss : 0.3334 = 0.2300 + 0.1022 + 0.0013, time: 7.026789]
2023-05-15 15:02:18.625: epoch 18:	0.01960943  	0.14455874  	0.07323983  
2023-05-15 15:02:18.625: Find a better model.
2023-05-15 15:02:25.665: [iter 19 : loss : 0.3194 = 0.2162 + 0.1018 + 0.0014, time: 7.038969]
2023-05-15 15:02:25.809: epoch 19:	0.01979291  	0.14564416  	0.07397188  
2023-05-15 15:02:25.809: Find a better model.
2023-05-15 15:02:32.876: [iter 20 : loss : 0.3100 = 0.2071 + 0.1014 + 0.0015, time: 7.064474]
2023-05-15 15:02:33.029: epoch 20:	0.02001872  	0.14760421  	0.07485655  
2023-05-15 15:02:33.029: Find a better model.
2023-05-15 15:02:40.061: [iter 21 : loss : 0.3003 = 0.1977 + 0.1010 + 0.0016, time: 7.031479]
2023-05-15 15:02:40.205: epoch 21:	0.02015985  	0.14849834  	0.07546601  
2023-05-15 15:02:40.205: Find a better model.
2023-05-15 15:02:47.263: [iter 22 : loss : 0.2924 = 0.1901 + 0.1006 + 0.0017, time: 7.056875]
2023-05-15 15:02:47.416: epoch 22:	0.02037860  	0.15025502  	0.07647183  
2023-05-15 15:02:47.416: Find a better model.
2023-05-15 15:02:54.494: [iter 23 : loss : 0.2840 = 0.1821 + 0.1002 + 0.0017, time: 7.077069]
2023-05-15 15:02:54.647: epoch 23:	0.02057618  	0.15152682  	0.07736121  
2023-05-15 15:02:54.647: Find a better model.
2023-05-15 15:03:01.827: [iter 24 : loss : 0.2776 = 0.1761 + 0.0997 + 0.0018, time: 7.179770]
2023-05-15 15:03:01.983: epoch 24:	0.02073143  	0.15295762  	0.07802443  
2023-05-15 15:03:01.984: Find a better model.
2023-05-15 15:03:09.039: [iter 25 : loss : 0.2710 = 0.1698 + 0.0993 + 0.0019, time: 7.053382]
2023-05-15 15:03:09.196: epoch 25:	0.02087256  	0.15409055  	0.07853326  
2023-05-15 15:03:09.196: Find a better model.
2023-05-15 15:03:16.263: [iter 26 : loss : 0.2674 = 0.1666 + 0.0989 + 0.0019, time: 7.066110]
2023-05-15 15:03:16.417: epoch 26:	0.02113364  	0.15568900  	0.07942907  
2023-05-15 15:03:16.417: Find a better model.
2023-05-15 15:03:23.441: [iter 27 : loss : 0.2597 = 0.1592 + 0.0985 + 0.0020, time: 7.021176]
2023-05-15 15:03:23.594: epoch 27:	0.02135239  	0.15755498  	0.08025299  
2023-05-15 15:03:23.595: Find a better model.
2023-05-15 15:03:30.659: [iter 28 : loss : 0.2548 = 0.1547 + 0.0980 + 0.0021, time: 7.063690]
2023-05-15 15:03:30.812: epoch 28:	0.02145118  	0.15803854  	0.08101536  
2023-05-15 15:03:30.812: Find a better model.
2023-05-15 15:03:37.862: [iter 29 : loss : 0.2500 = 0.1503 + 0.0976 + 0.0021, time: 7.048356]
2023-05-15 15:03:38.014: epoch 29:	0.02162760  	0.15886040  	0.08179510  
2023-05-15 15:03:38.015: Find a better model.
2023-05-15 15:03:45.049: [iter 30 : loss : 0.2439 = 0.1444 + 0.0973 + 0.0022, time: 7.033217]
2023-05-15 15:03:45.206: epoch 30:	0.02176873  	0.15967916  	0.08248124  
2023-05-15 15:03:45.206: Find a better model.
2023-05-15 15:03:52.243: [iter 31 : loss : 0.2403 = 0.1411 + 0.0969 + 0.0023, time: 7.035004]
2023-05-15 15:03:52.396: epoch 31:	0.02192397  	0.16067849  	0.08312696  
2023-05-15 15:03:52.396: Find a better model.
2023-05-15 15:03:59.450: [iter 32 : loss : 0.2347 = 0.1358 + 0.0966 + 0.0023, time: 7.052856]
2023-05-15 15:03:59.604: epoch 32:	0.02209332  	0.16212982  	0.08381321  
2023-05-15 15:03:59.604: Find a better model.
2023-05-15 15:04:06.836: [iter 33 : loss : 0.2320 = 0.1335 + 0.0961 + 0.0024, time: 7.230999]
2023-05-15 15:04:06.989: epoch 33:	0.02229796  	0.16340910  	0.08436102  
2023-05-15 15:04:06.989: Find a better model.
2023-05-15 15:04:14.249: [iter 34 : loss : 0.2281 = 0.1298 + 0.0958 + 0.0024, time: 7.259151]
2023-05-15 15:04:14.404: epoch 34:	0.02240381  	0.16391003  	0.08495684  
2023-05-15 15:04:14.404: Find a better model.
2023-05-15 15:04:21.442: [iter 35 : loss : 0.2246 = 0.1266 + 0.0955 + 0.0025, time: 7.036913]
2023-05-15 15:04:21.596: epoch 35:	0.02263667  	0.16581030  	0.08582229  
2023-05-15 15:04:21.596: Find a better model.
2023-05-15 15:04:28.824: [iter 36 : loss : 0.2209 = 0.1231 + 0.0952 + 0.0025, time: 7.227410]
2023-05-15 15:04:28.966: epoch 36:	0.02277074  	0.16682155  	0.08643338  
2023-05-15 15:04:28.966: Find a better model.
2023-05-15 15:04:36.042: [iter 37 : loss : 0.2172 = 0.1197 + 0.0948 + 0.0026, time: 7.073538]
2023-05-15 15:04:36.186: epoch 37:	0.02286953  	0.16736549  	0.08687355  
2023-05-15 15:04:36.186: Find a better model.
2023-05-15 15:04:43.227: [iter 38 : loss : 0.2156 = 0.1184 + 0.0945 + 0.0027, time: 7.039924]
2023-05-15 15:04:43.379: epoch 38:	0.02300360  	0.16864391  	0.08761835  
2023-05-15 15:04:43.379: Find a better model.
2023-05-15 15:04:50.444: [iter 39 : loss : 0.2110 = 0.1141 + 0.0942 + 0.0027, time: 7.063009]
2023-05-15 15:04:50.598: epoch 39:	0.02305300  	0.16930537  	0.08816279  
2023-05-15 15:04:50.598: Find a better model.
2023-05-15 15:04:57.789: [iter 40 : loss : 0.2079 = 0.1112 + 0.0940 + 0.0028, time: 7.189165]
2023-05-15 15:04:57.947: epoch 40:	0.02318002  	0.17042221  	0.08886681  
2023-05-15 15:04:57.947: Find a better model.
2023-05-15 15:05:05.190: [iter 41 : loss : 0.2061 = 0.1096 + 0.0937 + 0.0028, time: 7.242147]
2023-05-15 15:05:05.344: epoch 41:	0.02318707  	0.17079987  	0.08934756  
2023-05-15 15:05:05.344: Find a better model.
2023-05-15 15:05:12.409: [iter 42 : loss : 0.2039 = 0.1077 + 0.0934 + 0.0029, time: 7.064505]
2023-05-15 15:05:12.563: epoch 42:	0.02327881  	0.17113006  	0.08967992  
2023-05-15 15:05:12.563: Find a better model.
2023-05-15 15:05:19.614: [iter 43 : loss : 0.2001 = 0.1042 + 0.0931 + 0.0029, time: 7.050247]
2023-05-15 15:05:19.770: epoch 43:	0.02330703  	0.17103165  	0.08999188  
2023-05-15 15:05:26.995: [iter 44 : loss : 0.1966 = 0.1009 + 0.0928 + 0.0030, time: 7.223165]
2023-05-15 15:05:27.151: epoch 44:	0.02352578  	0.17263462  	0.09089710  
2023-05-15 15:05:27.151: Find a better model.
2023-05-15 15:05:34.238: [iter 45 : loss : 0.1944 = 0.0988 + 0.0926 + 0.0030, time: 7.086177]
2023-05-15 15:05:34.379: epoch 45:	0.02359634  	0.17284442  	0.09116818  
2023-05-15 15:05:34.379: Find a better model.
2023-05-15 15:05:41.589: [iter 46 : loss : 0.1917 = 0.0963 + 0.0923 + 0.0031, time: 7.208165]
2023-05-15 15:05:41.741: epoch 46:	0.02367397  	0.17373317  	0.09181869  
2023-05-15 15:05:41.741: Find a better model.
2023-05-15 15:05:48.979: [iter 47 : loss : 0.1913 = 0.0961 + 0.0921 + 0.0031, time: 7.235802]
2023-05-15 15:05:49.134: epoch 47:	0.02369514  	0.17360289  	0.09225936  
2023-05-15 15:05:56.396: [iter 48 : loss : 0.1873 = 0.0923 + 0.0918 + 0.0032, time: 7.260104]
2023-05-15 15:05:56.549: epoch 48:	0.02374453  	0.17393187  	0.09272455  
2023-05-15 15:05:56.549: Find a better model.
2023-05-15 15:06:03.770: [iter 49 : loss : 0.1842 = 0.0894 + 0.0916 + 0.0032, time: 7.220041]
2023-05-15 15:06:03.922: epoch 49:	0.02387155  	0.17508554  	0.09333026  
2023-05-15 15:06:03.923: Find a better model.
2023-05-15 15:06:11.204: [iter 50 : loss : 0.1833 = 0.0886 + 0.0914 + 0.0033, time: 7.279526]
2023-05-15 15:06:11.357: epoch 50:	0.02395623  	0.17585999  	0.09384044  
2023-05-15 15:06:11.357: Find a better model.
2023-05-15 15:06:18.567: [iter 51 : loss : 0.1805 = 0.0860 + 0.0913 + 0.0033, time: 7.209282]
2023-05-15 15:06:18.720: epoch 51:	0.02403385  	0.17637354  	0.09431646  
2023-05-15 15:06:18.721: Find a better model.
2023-05-15 15:06:25.957: [iter 52 : loss : 0.1802 = 0.0858 + 0.0910 + 0.0034, time: 7.234783]
2023-05-15 15:06:26.099: epoch 52:	0.02423143  	0.17776132  	0.09510399  
2023-05-15 15:06:26.099: Find a better model.
2023-05-15 15:06:33.191: [iter 53 : loss : 0.1783 = 0.0841 + 0.0908 + 0.0034, time: 7.090794]
2023-05-15 15:06:33.349: epoch 53:	0.02437256  	0.17884959  	0.09564216  
2023-05-15 15:06:33.349: Find a better model.
2023-05-15 15:06:40.386: [iter 54 : loss : 0.1759 = 0.0819 + 0.0906 + 0.0035, time: 7.035610]
2023-05-15 15:06:40.541: epoch 54:	0.02447135  	0.17969732  	0.09629928  
2023-05-15 15:06:40.541: Find a better model.
2023-05-15 15:06:47.781: [iter 55 : loss : 0.1742 = 0.0803 + 0.0904 + 0.0035, time: 7.238589]
2023-05-15 15:06:47.933: epoch 55:	0.02457014  	0.18039960  	0.09689054  
2023-05-15 15:06:47.933: Find a better model.
2023-05-15 15:06:55.014: [iter 56 : loss : 0.1727 = 0.0790 + 0.0902 + 0.0035, time: 7.080038]
2023-05-15 15:06:55.168: epoch 56:	0.02464776  	0.18083756  	0.09746137  
2023-05-15 15:06:55.168: Find a better model.
2023-05-15 15:07:02.342: [iter 57 : loss : 0.1709 = 0.0772 + 0.0901 + 0.0036, time: 7.172927]
2023-05-15 15:07:02.497: epoch 57:	0.02472538  	0.18165162  	0.09770040  
2023-05-15 15:07:02.497: Find a better model.
2023-05-15 15:07:09.772: [iter 58 : loss : 0.1688 = 0.0752 + 0.0899 + 0.0036, time: 7.272409]
2023-05-15 15:07:09.922: epoch 58:	0.02485240  	0.18289238  	0.09814510  
2023-05-15 15:07:09.922: Find a better model.
2023-05-15 15:07:17.277: [iter 59 : loss : 0.1678 = 0.0744 + 0.0897 + 0.0037, time: 7.353422]
2023-05-15 15:07:17.426: epoch 59:	0.02485240  	0.18269809  	0.09825937  
2023-05-15 15:07:24.596: [iter 60 : loss : 0.1661 = 0.0729 + 0.0895 + 0.0037, time: 7.167537]
2023-05-15 15:07:24.755: epoch 60:	0.02483123  	0.18250754  	0.09857745  
2023-05-15 15:07:31.978: [iter 61 : loss : 0.1648 = 0.0717 + 0.0893 + 0.0038, time: 7.222089]
2023-05-15 15:07:32.132: epoch 61:	0.02491591  	0.18272477  	0.09885638  
2023-05-15 15:07:39.348: [iter 62 : loss : 0.1631 = 0.0701 + 0.0892 + 0.0038, time: 7.215190]
2023-05-15 15:07:39.502: epoch 62:	0.02497236  	0.18304028  	0.09917407  
2023-05-15 15:07:39.503: Find a better model.
2023-05-15 15:07:46.566: [iter 63 : loss : 0.1621 = 0.0691 + 0.0890 + 0.0039, time: 7.061958]
2023-05-15 15:07:46.717: epoch 63:	0.02502175  	0.18378267  	0.09946122  
2023-05-15 15:07:46.717: Find a better model.
2023-05-15 15:07:53.769: [iter 64 : loss : 0.1609 = 0.0681 + 0.0889 + 0.0039, time: 7.051025]
2023-05-15 15:07:53.923: epoch 64:	0.02504998  	0.18415070  	0.09983689  
2023-05-15 15:07:53.923: Find a better model.
2023-05-15 15:08:01.150: [iter 65 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0040, time: 7.225108]
2023-05-15 15:08:01.291: epoch 65:	0.02512054  	0.18436590  	0.10016715  
2023-05-15 15:08:01.291: Find a better model.
2023-05-15 15:08:08.351: [iter 66 : loss : 0.1579 = 0.0654 + 0.0886 + 0.0040, time: 7.057209]
2023-05-15 15:08:08.494: epoch 66:	0.02520522  	0.18455864  	0.10040921  
2023-05-15 15:08:08.494: Find a better model.
2023-05-15 15:08:15.755: [iter 67 : loss : 0.1568 = 0.0643 + 0.0884 + 0.0040, time: 7.260250]
2023-05-15 15:08:15.908: epoch 67:	0.02523344  	0.18542324  	0.10075523  
2023-05-15 15:08:15.908: Find a better model.
2023-05-15 15:08:23.124: [iter 68 : loss : 0.1561 = 0.0638 + 0.0883 + 0.0041, time: 7.215466]
2023-05-15 15:08:23.278: epoch 68:	0.02524756  	0.18541987  	0.10086256  
2023-05-15 15:08:30.356: [iter 69 : loss : 0.1541 = 0.0619 + 0.0881 + 0.0041, time: 7.077089]
2023-05-15 15:08:30.511: epoch 69:	0.02530401  	0.18595469  	0.10101014  
2023-05-15 15:08:30.511: Find a better model.
2023-05-15 15:08:37.760: [iter 70 : loss : 0.1527 = 0.0605 + 0.0880 + 0.0042, time: 7.247776]
2023-05-15 15:08:37.912: epoch 70:	0.02536751  	0.18606582  	0.10121670  
2023-05-15 15:08:37.912: Find a better model.
2023-05-15 15:08:45.130: [iter 71 : loss : 0.1509 = 0.0588 + 0.0879 + 0.0042, time: 7.216266]
2023-05-15 15:08:45.285: epoch 71:	0.02543808  	0.18644489  	0.10151277  
2023-05-15 15:08:45.285: Find a better model.
2023-05-15 15:08:52.556: [iter 72 : loss : 0.1511 = 0.0590 + 0.0878 + 0.0042, time: 7.268425]
2023-05-15 15:08:52.710: epoch 72:	0.02552981  	0.18724284  	0.10194188  
2023-05-15 15:08:52.710: Find a better model.
2023-05-15 15:08:59.920: [iter 73 : loss : 0.1498 = 0.0578 + 0.0876 + 0.0043, time: 7.208380]
2023-05-15 15:09:00.078: epoch 73:	0.02560037  	0.18786088  	0.10218760  
2023-05-15 15:09:00.078: Find a better model.
2023-05-15 15:09:07.140: [iter 74 : loss : 0.1482 = 0.0563 + 0.0875 + 0.0043, time: 7.059982]
2023-05-15 15:09:07.291: epoch 74:	0.02567094  	0.18860990  	0.10261068  
2023-05-15 15:09:07.292: Find a better model.
2023-05-15 15:09:14.500: [iter 75 : loss : 0.1477 = 0.0559 + 0.0874 + 0.0044, time: 7.206985]
2023-05-15 15:09:14.642: epoch 75:	0.02570622  	0.18916990  	0.10283415  
2023-05-15 15:09:14.642: Find a better model.
2023-05-15 15:09:21.732: [iter 76 : loss : 0.1466 = 0.0549 + 0.0873 + 0.0044, time: 7.087484]
2023-05-15 15:09:21.886: epoch 76:	0.02574856  	0.18917616  	0.10306342  
2023-05-15 15:09:21.886: Find a better model.
2023-05-15 15:09:28.936: [iter 77 : loss : 0.1456 = 0.0539 + 0.0872 + 0.0045, time: 7.049101]
2023-05-15 15:09:29.077: epoch 77:	0.02578384  	0.18973872  	0.10314160  
2023-05-15 15:09:29.077: Find a better model.
2023-05-15 15:09:36.160: [iter 78 : loss : 0.1446 = 0.0530 + 0.0871 + 0.0045, time: 7.081236]
2023-05-15 15:09:36.314: epoch 78:	0.02577678  	0.18966232  	0.10317325  
2023-05-15 15:09:43.326: [iter 79 : loss : 0.1436 = 0.0521 + 0.0869 + 0.0045, time: 7.011751]
2023-05-15 15:09:43.480: epoch 79:	0.02574150  	0.18920189  	0.10309204  
2023-05-15 15:09:50.709: [iter 80 : loss : 0.1428 = 0.0514 + 0.0869 + 0.0046, time: 7.227763]
2023-05-15 15:09:50.862: epoch 80:	0.02577678  	0.18978509  	0.10343437  
2023-05-15 15:09:50.862: Find a better model.
2023-05-15 15:09:57.957: [iter 81 : loss : 0.1424 = 0.0510 + 0.0867 + 0.0046, time: 7.093552]
2023-05-15 15:09:58.109: epoch 81:	0.02582618  	0.19052230  	0.10360351  
2023-05-15 15:09:58.110: Find a better model.
2023-05-15 15:10:05.312: [iter 82 : loss : 0.1411 = 0.0499 + 0.0866 + 0.0046, time: 7.200752]
2023-05-15 15:10:05.466: epoch 82:	0.02590380  	0.19098537  	0.10391600  
2023-05-15 15:10:05.466: Find a better model.
2023-05-15 15:10:12.707: [iter 83 : loss : 0.1399 = 0.0487 + 0.0865 + 0.0047, time: 7.240201]
2023-05-15 15:10:12.859: epoch 83:	0.02598848  	0.19167492  	0.10425703  
2023-05-15 15:10:12.859: Find a better model.
2023-05-15 15:10:19.902: [iter 84 : loss : 0.1399 = 0.0488 + 0.0864 + 0.0047, time: 7.042263]
2023-05-15 15:10:20.044: epoch 84:	0.02604493  	0.19203731  	0.10450757  
2023-05-15 15:10:20.044: Find a better model.
2023-05-15 15:10:27.106: [iter 85 : loss : 0.1392 = 0.0481 + 0.0864 + 0.0048, time: 7.060714]
2023-05-15 15:10:27.260: epoch 85:	0.02604493  	0.19184987  	0.10468323  
2023-05-15 15:10:34.489: [iter 86 : loss : 0.1395 = 0.0485 + 0.0862 + 0.0048, time: 7.227377]
2023-05-15 15:10:34.644: epoch 86:	0.02615077  	0.19239652  	0.10503846  
2023-05-15 15:10:34.644: Find a better model.
2023-05-15 15:10:41.701: [iter 87 : loss : 0.1361 = 0.0451 + 0.0861 + 0.0048, time: 7.055553]
2023-05-15 15:10:41.854: epoch 87:	0.02617194  	0.19244669  	0.10516123  
2023-05-15 15:10:41.854: Find a better model.
2023-05-15 15:10:48.902: [iter 88 : loss : 0.1354 = 0.0445 + 0.0861 + 0.0049, time: 7.046924]
2023-05-15 15:10:49.044: epoch 88:	0.02623545  	0.19245470  	0.10514883  
2023-05-15 15:10:49.044: Find a better model.
2023-05-15 15:10:56.122: [iter 89 : loss : 0.1353 = 0.0444 + 0.0860 + 0.0049, time: 7.076997]
2023-05-15 15:10:56.275: epoch 89:	0.02628485  	0.19300430  	0.10542171  
2023-05-15 15:10:56.275: Find a better model.
2023-05-15 15:11:03.318: [iter 90 : loss : 0.1358 = 0.0450 + 0.0859 + 0.0050, time: 7.042173]
2023-05-15 15:11:03.470: epoch 90:	0.02637659  	0.19377647  	0.10568941  
2023-05-15 15:11:03.471: Find a better model.
2023-05-15 15:11:10.694: [iter 91 : loss : 0.1345 = 0.0437 + 0.0858 + 0.0050, time: 7.222008]
2023-05-15 15:11:10.835: epoch 91:	0.02641187  	0.19415301  	0.10576776  
2023-05-15 15:11:10.835: Find a better model.
2023-05-15 15:11:17.913: [iter 92 : loss : 0.1336 = 0.0429 + 0.0857 + 0.0050, time: 7.076418]
2023-05-15 15:11:18.064: epoch 92:	0.02639776  	0.19441740  	0.10594796  
2023-05-15 15:11:18.064: Find a better model.
2023-05-15 15:11:25.298: [iter 93 : loss : 0.1340 = 0.0433 + 0.0856 + 0.0051, time: 7.232151]
2023-05-15 15:11:25.453: epoch 93:	0.02636954  	0.19441240  	0.10587245  
2023-05-15 15:11:32.514: [iter 94 : loss : 0.1318 = 0.0411 + 0.0856 + 0.0051, time: 7.058957]
2023-05-15 15:11:32.669: epoch 94:	0.02641893  	0.19492540  	0.10592688  
2023-05-15 15:11:32.669: Find a better model.
2023-05-15 15:11:39.856: [iter 95 : loss : 0.1311 = 0.0405 + 0.0855 + 0.0051, time: 7.185940]
2023-05-15 15:11:40.014: epoch 95:	0.02639071  	0.19449325  	0.10587721  
2023-05-15 15:11:47.075: [iter 96 : loss : 0.1313 = 0.0408 + 0.0854 + 0.0052, time: 7.060593]
2023-05-15 15:11:47.228: epoch 96:	0.02650361  	0.19525585  	0.10630196  
2023-05-15 15:11:47.230: Find a better model.
2023-05-15 15:11:54.272: [iter 97 : loss : 0.1295 = 0.0390 + 0.0853 + 0.0052, time: 7.041558]
2023-05-15 15:11:54.414: epoch 97:	0.02649655  	0.19531961  	0.10635896  
2023-05-15 15:11:54.415: Find a better model.
2023-05-15 15:12:01.492: [iter 98 : loss : 0.1304 = 0.0399 + 0.0852 + 0.0052, time: 7.075750]
2023-05-15 15:12:01.648: epoch 98:	0.02641893  	0.19443388  	0.10626482  
2023-05-15 15:12:08.852: [iter 99 : loss : 0.1292 = 0.0387 + 0.0852 + 0.0053, time: 7.200799]
2023-05-15 15:12:08.991: epoch 99:	0.02641893  	0.19458048  	0.10642418  
2023-05-15 15:12:16.079: [iter 100 : loss : 0.1286 = 0.0382 + 0.0851 + 0.0053, time: 7.087038]
2023-05-15 15:12:16.223: epoch 100:	0.02646832  	0.19481057  	0.10655683  
2023-05-15 15:12:23.269: [iter 101 : loss : 0.1282 = 0.0378 + 0.0850 + 0.0054, time: 7.044219]
2023-05-15 15:12:23.410: epoch 101:	0.02651067  	0.19501278  	0.10679004  
2023-05-15 15:12:30.468: [iter 102 : loss : 0.1273 = 0.0369 + 0.0849 + 0.0054, time: 7.056086]
2023-05-15 15:12:30.609: epoch 102:	0.02660945  	0.19556843  	0.10713402  
2023-05-15 15:12:30.610: Find a better model.
2023-05-15 15:12:37.700: [iter 103 : loss : 0.1270 = 0.0367 + 0.0849 + 0.0054, time: 7.088708]
2023-05-15 15:12:37.853: epoch 103:	0.02665179  	0.19587000  	0.10747372  
2023-05-15 15:12:37.853: Find a better model.
2023-05-15 15:12:45.035: [iter 104 : loss : 0.1277 = 0.0374 + 0.0848 + 0.0055, time: 7.180467]
2023-05-15 15:12:45.179: epoch 104:	0.02662357  	0.19585583  	0.10758235  
2023-05-15 15:12:52.281: [iter 105 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 7.101294]
2023-05-15 15:12:52.433: epoch 105:	0.02658123  	0.19547097  	0.10742408  
2023-05-15 15:12:59.468: [iter 106 : loss : 0.1260 = 0.0358 + 0.0847 + 0.0055, time: 7.034343]
2023-05-15 15:12:59.623: epoch 106:	0.02654595  	0.19500820  	0.10750770  
2023-05-15 15:13:06.663: [iter 107 : loss : 0.1252 = 0.0350 + 0.0846 + 0.0056, time: 7.038860]
2023-05-15 15:13:06.819: epoch 107:	0.02654594  	0.19499996  	0.10768250  
2023-05-15 15:13:13.849: [iter 108 : loss : 0.1251 = 0.0350 + 0.0846 + 0.0056, time: 7.028331]
2023-05-15 15:13:14.002: epoch 108:	0.02656711  	0.19509076  	0.10757954  
2023-05-15 15:13:21.051: [iter 109 : loss : 0.1238 = 0.0337 + 0.0845 + 0.0056, time: 7.047860]
2023-05-15 15:13:21.202: epoch 109:	0.02655300  	0.19525455  	0.10770082  
2023-05-15 15:13:28.259: [iter 110 : loss : 0.1229 = 0.0328 + 0.0845 + 0.0057, time: 7.055272]
2023-05-15 15:13:28.413: epoch 110:	0.02660240  	0.19536173  	0.10777318  
2023-05-15 15:13:35.484: [iter 111 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.063769]
2023-05-15 15:13:35.637: epoch 111:	0.02665180  	0.19587900  	0.10793288  
2023-05-15 15:13:35.637: Find a better model.
2023-05-15 15:13:42.631: [iter 112 : loss : 0.1228 = 0.0328 + 0.0843 + 0.0057, time: 6.993373]
2023-05-15 15:13:42.772: epoch 112:	0.02668708  	0.19611630  	0.10807179  
2023-05-15 15:13:42.772: Find a better model.
2023-05-15 15:13:49.843: [iter 113 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0058, time: 7.069226]
2023-05-15 15:13:49.996: epoch 113:	0.02660946  	0.19572639  	0.10812859  
2023-05-15 15:13:57.062: [iter 114 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 7.065097]
2023-05-15 15:13:57.217: epoch 114:	0.02660240  	0.19559328  	0.10829360  
2023-05-15 15:14:04.242: [iter 115 : loss : 0.1217 = 0.0318 + 0.0841 + 0.0058, time: 7.023579]
2023-05-15 15:14:04.395: epoch 115:	0.02666591  	0.19631049  	0.10844012  
2023-05-15 15:14:04.395: Find a better model.
2023-05-15 15:14:11.452: [iter 116 : loss : 0.1207 = 0.0308 + 0.0841 + 0.0059, time: 7.056357]
2023-05-15 15:14:11.594: epoch 116:	0.02665885  	0.19622067  	0.10833598  
2023-05-15 15:14:18.630: [iter 117 : loss : 0.1205 = 0.0305 + 0.0840 + 0.0059, time: 7.034376]
2023-05-15 15:14:18.784: epoch 117:	0.02668002  	0.19662587  	0.10839121  
2023-05-15 15:14:18.784: Find a better model.
2023-05-15 15:14:25.836: [iter 118 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.051066]
2023-05-15 15:14:25.989: epoch 118:	0.02665885  	0.19645782  	0.10840792  
2023-05-15 15:14:33.025: [iter 119 : loss : 0.1196 = 0.0297 + 0.0840 + 0.0060, time: 7.034622]
2023-05-15 15:14:33.180: epoch 119:	0.02663768  	0.19612713  	0.10825452  
2023-05-15 15:14:40.216: [iter 120 : loss : 0.1198 = 0.0299 + 0.0839 + 0.0060, time: 7.033699]
2023-05-15 15:14:40.367: epoch 120:	0.02660945  	0.19638784  	0.10844679  
2023-05-15 15:14:47.595: [iter 121 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 7.227279]
2023-05-15 15:14:47.751: epoch 121:	0.02659534  	0.19636294  	0.10851611  
2023-05-15 15:14:54.825: [iter 122 : loss : 0.1189 = 0.0290 + 0.0838 + 0.0061, time: 7.072823]
2023-05-15 15:14:54.968: epoch 122:	0.02661651  	0.19636884  	0.10844817  
2023-05-15 15:15:02.013: [iter 123 : loss : 0.1188 = 0.0289 + 0.0838 + 0.0061, time: 7.043540]
2023-05-15 15:15:02.167: epoch 123:	0.02668002  	0.19662301  	0.10868452  
2023-05-15 15:15:09.211: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 7.043701]
2023-05-15 15:15:09.365: epoch 124:	0.02665180  	0.19650023  	0.10863856  
2023-05-15 15:15:16.417: [iter 125 : loss : 0.1173 = 0.0275 + 0.0836 + 0.0061, time: 7.050690]
2023-05-15 15:15:16.570: epoch 125:	0.02668002  	0.19694446  	0.10876071  
2023-05-15 15:15:16.570: Find a better model.
2023-05-15 15:15:23.606: [iter 126 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0062, time: 7.034135]
2023-05-15 15:15:23.763: epoch 126:	0.02672236  	0.19713783  	0.10892620  
2023-05-15 15:15:23.763: Find a better model.
2023-05-15 15:15:30.812: [iter 127 : loss : 0.1166 = 0.0268 + 0.0836 + 0.0062, time: 7.047539]
2023-05-15 15:15:30.969: epoch 127:	0.02677881  	0.19787112  	0.10924786  
2023-05-15 15:15:30.969: Find a better model.
2023-05-15 15:15:38.188: [iter 128 : loss : 0.1176 = 0.0278 + 0.0835 + 0.0062, time: 7.218564]
2023-05-15 15:15:38.341: epoch 128:	0.02670825  	0.19711804  	0.10886715  
2023-05-15 15:15:45.401: [iter 129 : loss : 0.1167 = 0.0269 + 0.0835 + 0.0063, time: 7.058590]
2023-05-15 15:15:45.554: epoch 129:	0.02674353  	0.19762622  	0.10911960  
2023-05-15 15:15:52.598: [iter 130 : loss : 0.1167 = 0.0269 + 0.0834 + 0.0063, time: 7.041817]
2023-05-15 15:15:52.751: epoch 130:	0.02678587  	0.19778505  	0.10923263  
2023-05-15 15:15:59.788: [iter 131 : loss : 0.1160 = 0.0263 + 0.0834 + 0.0063, time: 7.036023]
2023-05-15 15:15:59.931: epoch 131:	0.02687760  	0.19815597  	0.10936952  
2023-05-15 15:15:59.931: Find a better model.
2023-05-15 15:16:07.006: [iter 132 : loss : 0.1162 = 0.0265 + 0.0834 + 0.0064, time: 7.073349]
2023-05-15 15:16:07.157: epoch 132:	0.02684937  	0.19791557  	0.10924166  
2023-05-15 15:16:14.381: [iter 133 : loss : 0.1151 = 0.0254 + 0.0833 + 0.0064, time: 7.221222]
2023-05-15 15:16:14.523: epoch 133:	0.02687054  	0.19805507  	0.10940728  
2023-05-15 15:16:21.593: [iter 134 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 7.068597]
2023-05-15 15:16:21.745: epoch 134:	0.02685643  	0.19809452  	0.10954869  
2023-05-15 15:16:28.984: [iter 135 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0064, time: 7.237631]
2023-05-15 15:16:29.139: epoch 135:	0.02678587  	0.19756414  	0.10938020  
2023-05-15 15:16:36.395: [iter 136 : loss : 0.1150 = 0.0253 + 0.0832 + 0.0065, time: 7.255174]
2023-05-15 15:16:36.551: epoch 136:	0.02678587  	0.19759041  	0.10928516  
2023-05-15 15:16:43.766: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 7.214849]
2023-05-15 15:16:43.918: epoch 137:	0.02683526  	0.19789544  	0.10931136  
2023-05-15 15:16:51.204: [iter 138 : loss : 0.1142 = 0.0246 + 0.0831 + 0.0065, time: 7.284255]
2023-05-15 15:16:51.359: epoch 138:	0.02686348  	0.19793995  	0.10952037  
2023-05-15 15:16:58.559: [iter 139 : loss : 0.1140 = 0.0244 + 0.0830 + 0.0066, time: 7.198487]
2023-05-15 15:16:58.702: epoch 139:	0.02696227  	0.19865544  	0.10989860  
2023-05-15 15:16:58.702: Find a better model.
2023-05-15 15:17:05.968: [iter 140 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 7.263498]
2023-05-15 15:17:06.122: epoch 140:	0.02688465  	0.19807887  	0.10969012  
2023-05-15 15:17:13.340: [iter 141 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 7.216460]
2023-05-15 15:17:13.494: epoch 141:	0.02692699  	0.19868602  	0.11005259  
2023-05-15 15:17:13.494: Find a better model.
2023-05-15 15:17:20.571: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 7.075563]
2023-05-15 15:17:20.726: epoch 142:	0.02688465  	0.19835144  	0.10988707  
2023-05-15 15:17:27.945: [iter 143 : loss : 0.1130 = 0.0234 + 0.0829 + 0.0067, time: 7.218497]
2023-05-15 15:17:28.101: epoch 143:	0.02694816  	0.19901456  	0.11007148  
2023-05-15 15:17:28.101: Find a better model.
2023-05-15 15:17:35.349: [iter 144 : loss : 0.1126 = 0.0231 + 0.0829 + 0.0067, time: 7.247159]
2023-05-15 15:17:35.492: epoch 144:	0.02691288  	0.19846712  	0.10999011  
2023-05-15 15:17:42.552: [iter 145 : loss : 0.1126 = 0.0230 + 0.0828 + 0.0067, time: 7.059289]
2023-05-15 15:17:42.707: epoch 145:	0.02690583  	0.19833137  	0.11000621  
2023-05-15 15:17:49.752: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.043351]
2023-05-15 15:17:49.896: epoch 146:	0.02690583  	0.19831054  	0.11003165  
2023-05-15 15:17:56.974: [iter 147 : loss : 0.1126 = 0.0230 + 0.0828 + 0.0068, time: 7.077262]
2023-05-15 15:17:57.117: epoch 147:	0.02690583  	0.19825563  	0.11008048  
2023-05-15 15:18:04.150: [iter 148 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0068, time: 7.032330]
2023-05-15 15:18:04.305: epoch 148:	0.02689877  	0.19808874  	0.11003365  
2023-05-15 15:18:11.371: [iter 149 : loss : 0.1118 = 0.0222 + 0.0827 + 0.0068, time: 7.063547]
2023-05-15 15:18:11.525: epoch 149:	0.02693405  	0.19849399  	0.11002915  
2023-05-15 15:18:18.544: [iter 150 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0069, time: 7.017682]
2023-05-15 15:18:18.698: epoch 150:	0.02698345  	0.19864325  	0.11014208  
2023-05-15 15:18:25.744: [iter 151 : loss : 0.1113 = 0.0218 + 0.0827 + 0.0069, time: 7.044665]
2023-05-15 15:18:25.896: epoch 151:	0.02706107  	0.19938961  	0.11042242  
2023-05-15 15:18:25.896: Find a better model.
2023-05-15 15:18:32.941: [iter 152 : loss : 0.1107 = 0.0212 + 0.0826 + 0.0069, time: 7.043018]
2023-05-15 15:18:33.095: epoch 152:	0.02700461  	0.19869183  	0.11010993  
2023-05-15 15:18:40.137: [iter 153 : loss : 0.1098 = 0.0203 + 0.0826 + 0.0069, time: 7.041154]
2023-05-15 15:18:40.294: epoch 153:	0.02707518  	0.19923507  	0.11030825  
2023-05-15 15:18:47.347: [iter 154 : loss : 0.1101 = 0.0206 + 0.0825 + 0.0070, time: 7.051239]
2023-05-15 15:18:47.499: epoch 154:	0.02694111  	0.19810051  	0.11004373  
2023-05-15 15:18:54.556: [iter 155 : loss : 0.1110 = 0.0214 + 0.0825 + 0.0070, time: 7.055512]
2023-05-15 15:18:54.711: epoch 155:	0.02686348  	0.19766530  	0.10975342  
2023-05-15 15:19:01.907: [iter 156 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0070, time: 7.195646]
2023-05-15 15:19:02.064: epoch 156:	0.02688465  	0.19792643  	0.10972495  
2023-05-15 15:19:09.126: [iter 157 : loss : 0.1101 = 0.0206 + 0.0825 + 0.0070, time: 7.060323]
2023-05-15 15:19:09.284: epoch 157:	0.02687760  	0.19798434  	0.10964013  
2023-05-15 15:19:16.352: [iter 158 : loss : 0.1094 = 0.0199 + 0.0824 + 0.0071, time: 7.067005]
2023-05-15 15:19:16.507: epoch 158:	0.02687054  	0.19761491  	0.10963851  
2023-05-15 15:19:23.530: [iter 159 : loss : 0.1098 = 0.0203 + 0.0824 + 0.0071, time: 7.021886]
2023-05-15 15:19:23.676: epoch 159:	0.02685643  	0.19750379  	0.10952930  
2023-05-15 15:19:30.760: [iter 160 : loss : 0.1094 = 0.0199 + 0.0824 + 0.0071, time: 7.083241]
2023-05-15 15:19:30.913: epoch 160:	0.02680703  	0.19710243  	0.10945231  
2023-05-15 15:19:37.927: [iter 161 : loss : 0.1088 = 0.0193 + 0.0823 + 0.0071, time: 7.013188]
2023-05-15 15:19:38.080: epoch 161:	0.02684232  	0.19739424  	0.10975347  
2023-05-15 15:19:45.304: [iter 162 : loss : 0.1083 = 0.0188 + 0.0823 + 0.0072, time: 7.223005]
2023-05-15 15:19:45.458: epoch 162:	0.02686349  	0.19750220  	0.10956340  
2023-05-15 15:19:52.513: [iter 163 : loss : 0.1088 = 0.0193 + 0.0823 + 0.0072, time: 7.053997]
2023-05-15 15:19:52.667: epoch 163:	0.02682821  	0.19731937  	0.10938514  
2023-05-15 15:19:59.727: [iter 164 : loss : 0.1085 = 0.0190 + 0.0823 + 0.0072, time: 7.058433]
2023-05-15 15:19:59.884: epoch 164:	0.02677175  	0.19691390  	0.10921580  
2023-05-15 15:20:06.925: [iter 165 : loss : 0.1083 = 0.0188 + 0.0822 + 0.0072, time: 7.039850]
2023-05-15 15:20:07.082: epoch 165:	0.02675764  	0.19692847  	0.10931836  
2023-05-15 15:20:14.133: [iter 166 : loss : 0.1080 = 0.0185 + 0.0822 + 0.0073, time: 7.048562]
2023-05-15 15:20:14.290: epoch 166:	0.02677175  	0.19695616  	0.10930111  
2023-05-15 15:20:21.477: [iter 167 : loss : 0.1084 = 0.0189 + 0.0822 + 0.0073, time: 7.185907]
2023-05-15 15:20:21.632: epoch 167:	0.02684937  	0.19753906  	0.10951011  
2023-05-15 15:20:28.699: [iter 168 : loss : 0.1077 = 0.0182 + 0.0822 + 0.0073, time: 7.065547]
2023-05-15 15:20:28.853: epoch 168:	0.02679997  	0.19696550  	0.10950840  
2023-05-15 15:20:35.926: [iter 169 : loss : 0.1080 = 0.0185 + 0.0821 + 0.0073, time: 7.071784]
2023-05-15 15:20:36.068: epoch 169:	0.02677880  	0.19676812  	0.10959613  
2023-05-15 15:20:43.113: [iter 170 : loss : 0.1075 = 0.0181 + 0.0821 + 0.0074, time: 7.043535]
2023-05-15 15:20:43.269: epoch 170:	0.02676469  	0.19670075  	0.10953945  
2023-05-15 15:20:50.337: [iter 171 : loss : 0.1080 = 0.0185 + 0.0821 + 0.0074, time: 7.066821]
2023-05-15 15:20:50.493: epoch 171:	0.02670119  	0.19639382  	0.10930453  
2023-05-15 15:20:57.494: [iter 172 : loss : 0.1070 = 0.0176 + 0.0821 + 0.0074, time: 6.999882]
2023-05-15 15:20:57.638: epoch 172:	0.02663768  	0.19593017  	0.10923566  
2023-05-15 15:21:04.688: [iter 173 : loss : 0.1075 = 0.0180 + 0.0820 + 0.0074, time: 7.048215]
2023-05-15 15:21:04.839: epoch 173:	0.02676469  	0.19699331  	0.10959664  
2023-05-15 15:21:11.899: [iter 174 : loss : 0.1072 = 0.0178 + 0.0820 + 0.0074, time: 7.058271]
2023-05-15 15:21:12.052: epoch 174:	0.02665885  	0.19612131  	0.10925871  
2023-05-15 15:21:19.089: [iter 175 : loss : 0.1065 = 0.0171 + 0.0820 + 0.0075, time: 7.036394]
2023-05-15 15:21:19.246: epoch 175:	0.02672236  	0.19637501  	0.10941733  
2023-05-15 15:21:26.462: [iter 176 : loss : 0.1064 = 0.0170 + 0.0820 + 0.0075, time: 7.214509]
2023-05-15 15:21:26.615: epoch 176:	0.02663768  	0.19582044  	0.10927982  
2023-05-15 15:21:26.615: Early stopping is trigger at epoch: 176
2023-05-15 15:21:26.615: best_result@epoch 151:

2023-05-15 15:21:26.615: 		0.0271      	0.1994      	0.1104      
2023-05-15 15:32:14.098: my pid: 11572
2023-05-15 15:32:14.098: model: model.general_recommender.SGL
2023-05-15 15:32:14.098: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 15:32:14.098: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 15:32:17.241: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 15:32:25.354: [iter 1 : loss : 0.7718 = 0.6930 + 0.0788 + 0.0000, time: 8.112126]
2023-05-15 15:32:25.498: epoch 1:	0.00159470  	0.01277023  	0.00596743  
2023-05-15 15:32:25.498: Find a better model.
2023-05-15 15:32:33.516: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.017263]
2023-05-15 15:32:33.724: epoch 2:	0.00319644  	0.02394092  	0.01194705  
2023-05-15 15:32:33.724: Find a better model.
2023-05-15 15:32:41.671: [iter 3 : loss : 0.7711 = 0.6925 + 0.0786 + 0.0000, time: 7.946086]
2023-05-15 15:32:41.847: epoch 3:	0.00561667  	0.04083213  	0.01974175  
2023-05-15 15:32:41.847: Find a better model.
2023-05-15 15:32:49.708: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.860236]
2023-05-15 15:32:49.869: epoch 4:	0.00882013  	0.06416804  	0.03077809  
2023-05-15 15:32:49.869: Find a better model.
2023-05-15 15:32:57.643: [iter 5 : loss : 0.7695 = 0.6905 + 0.0789 + 0.0000, time: 7.772758]
2023-05-15 15:32:57.810: epoch 5:	0.01240480  	0.08846410  	0.04269236  
2023-05-15 15:32:57.810: Find a better model.
2023-05-15 15:33:05.261: [iter 6 : loss : 0.7668 = 0.6874 + 0.0794 + 0.0000, time: 7.449574]
2023-05-15 15:33:05.416: epoch 6:	0.01585539  	0.11469278  	0.05549062  
2023-05-15 15:33:05.416: Find a better model.
2023-05-15 15:33:12.899: [iter 7 : loss : 0.7594 = 0.6791 + 0.0803 + 0.0000, time: 7.481793]
2023-05-15 15:33:13.053: epoch 7:	0.01797230  	0.13051830  	0.06486439  
2023-05-15 15:33:13.053: Find a better model.
2023-05-15 15:33:20.421: [iter 8 : loss : 0.7414 = 0.6589 + 0.0824 + 0.0001, time: 7.365748]
2023-05-15 15:33:20.574: epoch 8:	0.01856506  	0.13579392  	0.06834027  
2023-05-15 15:33:20.574: Find a better model.
2023-05-15 15:33:27.838: [iter 9 : loss : 0.7020 = 0.6153 + 0.0866 + 0.0002, time: 7.263252]
2023-05-15 15:33:27.992: epoch 9:	0.01856505  	0.13651963  	0.06867099  
2023-05-15 15:33:27.992: Find a better model.
2023-05-15 15:33:35.256: [iter 10 : loss : 0.6375 = 0.5451 + 0.0921 + 0.0003, time: 7.263407]
2023-05-15 15:33:35.412: epoch 10:	0.01828986  	0.13519152  	0.06777053  
2023-05-15 15:33:42.610: [iter 11 : loss : 0.5620 = 0.4647 + 0.0969 + 0.0004, time: 7.196917]
2023-05-15 15:33:42.753: epoch 11:	0.01821223  	0.13442199  	0.06762356  
2023-05-15 15:33:50.020: [iter 12 : loss : 0.4960 = 0.3954 + 0.1000 + 0.0006, time: 7.265515]
2023-05-15 15:33:50.177: epoch 12:	0.01835337  	0.13577175  	0.06811301  
2023-05-15 15:33:57.445: [iter 13 : loss : 0.4479 = 0.3456 + 0.1016 + 0.0007, time: 7.267099]
2023-05-15 15:33:57.601: epoch 13:	0.01854389  	0.13727781  	0.06889132  
2023-05-15 15:33:57.602: Find a better model.
2023-05-15 15:34:04.827: [iter 14 : loss : 0.4115 = 0.3082 + 0.1024 + 0.0009, time: 7.223297]
2023-05-15 15:34:04.984: epoch 14:	0.01870620  	0.13865556  	0.06976219  
2023-05-15 15:34:04.984: Find a better model.
2023-05-15 15:34:12.233: [iter 15 : loss : 0.3859 = 0.2822 + 0.1028 + 0.0010, time: 7.246394]
2023-05-15 15:34:12.388: epoch 15:	0.01879793  	0.13874963  	0.07030654  
2023-05-15 15:34:12.388: Find a better model.
2023-05-15 15:34:19.596: [iter 16 : loss : 0.3644 = 0.2606 + 0.1027 + 0.0011, time: 7.207045]
2023-05-15 15:34:19.740: epoch 16:	0.01893200  	0.13993447  	0.07090085  
2023-05-15 15:34:19.740: Find a better model.
2023-05-15 15:34:27.009: [iter 17 : loss : 0.3484 = 0.2447 + 0.1025 + 0.0012, time: 7.268023]
2023-05-15 15:34:27.162: epoch 17:	0.01925660  	0.14177747  	0.07200753  
2023-05-15 15:34:27.162: Find a better model.
2023-05-15 15:34:34.414: [iter 18 : loss : 0.3335 = 0.2299 + 0.1023 + 0.0013, time: 7.249200]
2023-05-15 15:34:34.572: epoch 18:	0.01951770  	0.14344391  	0.07286683  
2023-05-15 15:34:34.572: Find a better model.
2023-05-15 15:34:41.810: [iter 19 : loss : 0.3196 = 0.2163 + 0.1019 + 0.0014, time: 7.236541]
2023-05-15 15:34:41.965: epoch 19:	0.01973645  	0.14491701  	0.07380592  
2023-05-15 15:34:41.965: Find a better model.
2023-05-15 15:34:49.205: [iter 20 : loss : 0.3102 = 0.2072 + 0.1015 + 0.0015, time: 7.238305]
2023-05-15 15:34:49.358: epoch 20:	0.01992698  	0.14660433  	0.07456560  
2023-05-15 15:34:49.359: Find a better model.
2023-05-15 15:34:56.630: [iter 21 : loss : 0.3008 = 0.1981 + 0.1011 + 0.0016, time: 7.270471]
2023-05-15 15:34:56.774: epoch 21:	0.02009634  	0.14785378  	0.07532931  
2023-05-15 15:34:56.775: Find a better model.
2023-05-15 15:35:04.016: [iter 22 : loss : 0.2924 = 0.1901 + 0.1007 + 0.0017, time: 7.239665]
2023-05-15 15:35:04.174: epoch 22:	0.02020924  	0.14870612  	0.07589711  
2023-05-15 15:35:04.174: Find a better model.
2023-05-15 15:35:11.404: [iter 23 : loss : 0.2840 = 0.1820 + 0.1002 + 0.0017, time: 7.229136]
2023-05-15 15:35:11.548: epoch 23:	0.02038565  	0.15035032  	0.07680066  
2023-05-15 15:35:11.549: Find a better model.
2023-05-15 15:35:18.823: [iter 24 : loss : 0.2777 = 0.1761 + 0.0998 + 0.0018, time: 7.272721]
2023-05-15 15:35:18.980: epoch 24:	0.02063262  	0.15237851  	0.07781017  
2023-05-15 15:35:18.980: Find a better model.
2023-05-15 15:35:26.181: [iter 25 : loss : 0.2713 = 0.1701 + 0.0994 + 0.0019, time: 7.200591]
2023-05-15 15:35:26.334: epoch 25:	0.02084432  	0.15355514  	0.07851224  
2023-05-15 15:35:26.334: Find a better model.
2023-05-15 15:35:33.589: [iter 26 : loss : 0.2675 = 0.1666 + 0.0990 + 0.0019, time: 7.253938]
2023-05-15 15:35:33.736: epoch 26:	0.02104190  	0.15510698  	0.07925626  
2023-05-15 15:35:33.736: Find a better model.
2023-05-15 15:35:40.788: [iter 27 : loss : 0.2599 = 0.1595 + 0.0984 + 0.0020, time: 7.051232]
2023-05-15 15:35:40.932: epoch 27:	0.02116187  	0.15566176  	0.07972052  
2023-05-15 15:35:40.932: Find a better model.
2023-05-15 15:35:48.169: [iter 28 : loss : 0.2549 = 0.1547 + 0.0981 + 0.0021, time: 7.234792]
2023-05-15 15:35:48.311: epoch 28:	0.02136651  	0.15689768  	0.08067616  
2023-05-15 15:35:48.311: Find a better model.
2023-05-15 15:35:55.609: [iter 29 : loss : 0.2505 = 0.1506 + 0.0977 + 0.0021, time: 7.296366]
2023-05-15 15:35:55.763: epoch 29:	0.02154293  	0.15806794  	0.08147150  
2023-05-15 15:35:55.763: Find a better model.
2023-05-15 15:36:02.977: [iter 30 : loss : 0.2440 = 0.1445 + 0.0973 + 0.0022, time: 7.212710]
2023-05-15 15:36:03.136: epoch 30:	0.02171933  	0.15952329  	0.08221812  
2023-05-15 15:36:03.136: Find a better model.
2023-05-15 15:36:10.193: [iter 31 : loss : 0.2404 = 0.1412 + 0.0969 + 0.0023, time: 7.056008]
2023-05-15 15:36:10.347: epoch 31:	0.02192397  	0.16131113  	0.08304948  
2023-05-15 15:36:10.347: Find a better model.
2023-05-15 15:36:17.589: [iter 32 : loss : 0.2351 = 0.1362 + 0.0966 + 0.0023, time: 7.240126]
2023-05-15 15:36:17.742: epoch 32:	0.02200159  	0.16212572  	0.08382235  
2023-05-15 15:36:17.742: Find a better model.
2023-05-15 15:36:24.979: [iter 33 : loss : 0.2320 = 0.1335 + 0.0962 + 0.0024, time: 7.235018]
2023-05-15 15:36:25.124: epoch 33:	0.02214272  	0.16312423  	0.08435186  
2023-05-15 15:36:25.124: Find a better model.
2023-05-15 15:36:32.357: [iter 34 : loss : 0.2281 = 0.1298 + 0.0959 + 0.0024, time: 7.231071]
2023-05-15 15:36:32.499: epoch 34:	0.02235441  	0.16445740  	0.08522010  
2023-05-15 15:36:32.499: Find a better model.
2023-05-15 15:36:39.780: [iter 35 : loss : 0.2245 = 0.1265 + 0.0955 + 0.0025, time: 7.278840]
2023-05-15 15:36:39.934: epoch 35:	0.02248848  	0.16567360  	0.08590738  
2023-05-15 15:36:39.934: Find a better model.
2023-05-15 15:36:47.166: [iter 36 : loss : 0.2212 = 0.1235 + 0.0952 + 0.0025, time: 7.230814]
2023-05-15 15:36:47.321: epoch 36:	0.02262961  	0.16684102  	0.08648345  
2023-05-15 15:36:47.322: Find a better model.
2023-05-15 15:36:54.595: [iter 37 : loss : 0.2170 = 0.1195 + 0.0948 + 0.0026, time: 7.271611]
2023-05-15 15:36:54.749: epoch 37:	0.02258022  	0.16619302  	0.08667482  
2023-05-15 15:37:01.971: [iter 38 : loss : 0.2155 = 0.1182 + 0.0946 + 0.0027, time: 7.221171]
2023-05-15 15:37:02.124: epoch 38:	0.02269313  	0.16729078  	0.08731659  
2023-05-15 15:37:02.124: Find a better model.
2023-05-15 15:37:09.375: [iter 39 : loss : 0.2112 = 0.1142 + 0.0943 + 0.0027, time: 7.249131]
2023-05-15 15:37:09.529: epoch 39:	0.02283425  	0.16815287  	0.08805469  
2023-05-15 15:37:09.529: Find a better model.
2023-05-15 15:37:16.777: [iter 40 : loss : 0.2078 = 0.1110 + 0.0940 + 0.0028, time: 7.246866]
2023-05-15 15:37:16.931: epoch 40:	0.02289776  	0.16869429  	0.08834831  
2023-05-15 15:37:16.931: Find a better model.
2023-05-15 15:37:24.148: [iter 41 : loss : 0.2063 = 0.1098 + 0.0937 + 0.0028, time: 7.216505]
2023-05-15 15:37:24.293: epoch 41:	0.02309535  	0.17013820  	0.08916558  
2023-05-15 15:37:24.294: Find a better model.
2023-05-15 15:37:31.535: [iter 42 : loss : 0.2039 = 0.1076 + 0.0934 + 0.0029, time: 7.239721]
2023-05-15 15:37:31.692: epoch 42:	0.02323647  	0.17115438  	0.08975922  
2023-05-15 15:37:31.692: Find a better model.
2023-05-15 15:37:38.979: [iter 43 : loss : 0.1999 = 0.1039 + 0.0931 + 0.0029, time: 7.286690]
2023-05-15 15:37:39.135: epoch 43:	0.02333527  	0.17168967  	0.09024143  
2023-05-15 15:37:39.135: Find a better model.
2023-05-15 15:37:46.333: [iter 44 : loss : 0.1967 = 0.1009 + 0.0928 + 0.0030, time: 7.196464]
2023-05-15 15:37:46.488: epoch 44:	0.02343406  	0.17247958  	0.09083267  
2023-05-15 15:37:46.489: Find a better model.
2023-05-15 15:37:53.556: [iter 45 : loss : 0.1944 = 0.0988 + 0.0926 + 0.0030, time: 7.066425]
2023-05-15 15:37:53.710: epoch 45:	0.02352579  	0.17284295  	0.09134758  
2023-05-15 15:37:53.710: Find a better model.
2023-05-15 15:38:00.948: [iter 46 : loss : 0.1921 = 0.0967 + 0.0923 + 0.0031, time: 7.237640]
2023-05-15 15:38:01.090: epoch 46:	0.02359635  	0.17336446  	0.09154581  
2023-05-15 15:38:01.090: Find a better model.
2023-05-15 15:38:08.320: [iter 47 : loss : 0.1911 = 0.0958 + 0.0921 + 0.0031, time: 7.228071]
2023-05-15 15:38:08.477: epoch 47:	0.02370925  	0.17398964  	0.09215182  
2023-05-15 15:38:08.477: Find a better model.
2023-05-15 15:38:15.757: [iter 48 : loss : 0.1873 = 0.0923 + 0.0919 + 0.0032, time: 7.278445]
2023-05-15 15:38:15.912: epoch 48:	0.02373043  	0.17437822  	0.09244718  
2023-05-15 15:38:15.912: Find a better model.
2023-05-15 15:38:23.138: [iter 49 : loss : 0.1843 = 0.0894 + 0.0917 + 0.0032, time: 7.224647]
2023-05-15 15:38:23.292: epoch 49:	0.02387861  	0.17570353  	0.09320116  
2023-05-15 15:38:23.292: Find a better model.
2023-05-15 15:38:30.546: [iter 50 : loss : 0.1834 = 0.0887 + 0.0914 + 0.0033, time: 7.252998]
2023-05-15 15:38:30.702: epoch 50:	0.02394918  	0.17601289  	0.09364903  
2023-05-15 15:38:30.703: Find a better model.
2023-05-15 15:38:38.133: [iter 51 : loss : 0.1806 = 0.0860 + 0.0912 + 0.0033, time: 7.428906]
2023-05-15 15:38:38.287: epoch 51:	0.02400563  	0.17639382  	0.09396270  
2023-05-15 15:38:38.287: Find a better model.
2023-05-15 15:38:45.516: [iter 52 : loss : 0.1805 = 0.0861 + 0.0910 + 0.0034, time: 7.227807]
2023-05-15 15:38:45.670: epoch 52:	0.02409736  	0.17704503  	0.09445514  
2023-05-15 15:38:45.670: Find a better model.
2023-05-15 15:38:52.906: [iter 53 : loss : 0.1783 = 0.0841 + 0.0908 + 0.0034, time: 7.233763]
2023-05-15 15:38:53.059: epoch 53:	0.02429494  	0.17881638  	0.09524035  
2023-05-15 15:38:53.059: Find a better model.
2023-05-15 15:39:00.351: [iter 54 : loss : 0.1762 = 0.0821 + 0.0906 + 0.0035, time: 7.290781]
2023-05-15 15:39:00.506: epoch 54:	0.02430200  	0.17914341  	0.09562869  
2023-05-15 15:39:00.506: Find a better model.
2023-05-15 15:39:07.886: [iter 55 : loss : 0.1742 = 0.0803 + 0.0904 + 0.0035, time: 7.379381]
2023-05-15 15:39:08.031: epoch 55:	0.02442902  	0.18014939  	0.09594850  
2023-05-15 15:39:08.031: Find a better model.
2023-05-15 15:39:15.319: [iter 56 : loss : 0.1724 = 0.0787 + 0.0902 + 0.0035, time: 7.285719]
2023-05-15 15:39:15.482: epoch 56:	0.02449958  	0.18029465  	0.09629111  
2023-05-15 15:39:15.482: Find a better model.
2023-05-15 15:39:22.723: [iter 57 : loss : 0.1709 = 0.0772 + 0.0901 + 0.0036, time: 7.239269]
2023-05-15 15:39:22.879: epoch 57:	0.02458426  	0.18108617  	0.09670039  
2023-05-15 15:39:22.879: Find a better model.
2023-05-15 15:39:30.118: [iter 58 : loss : 0.1688 = 0.0753 + 0.0899 + 0.0036, time: 7.235856]
2023-05-15 15:39:30.273: epoch 58:	0.02464071  	0.18151595  	0.09706273  
2023-05-15 15:39:30.273: Find a better model.
2023-05-15 15:39:37.528: [iter 59 : loss : 0.1678 = 0.0745 + 0.0897 + 0.0037, time: 7.254184]
2023-05-15 15:39:37.682: epoch 59:	0.02466893  	0.18134187  	0.09720511  
2023-05-15 15:39:44.918: [iter 60 : loss : 0.1661 = 0.0729 + 0.0895 + 0.0037, time: 7.234087]
2023-05-15 15:39:45.072: epoch 60:	0.02466893  	0.18173948  	0.09756060  
2023-05-15 15:39:45.072: Find a better model.
2023-05-15 15:39:52.297: [iter 61 : loss : 0.1648 = 0.0717 + 0.0894 + 0.0038, time: 7.223176]
2023-05-15 15:39:52.444: epoch 61:	0.02468304  	0.18172176  	0.09778340  
2023-05-15 15:39:59.739: [iter 62 : loss : 0.1633 = 0.0703 + 0.0892 + 0.0038, time: 7.293231]
2023-05-15 15:39:59.895: epoch 62:	0.02470421  	0.18238790  	0.09817349  
2023-05-15 15:39:59.896: Find a better model.
2023-05-15 15:40:07.280: [iter 63 : loss : 0.1620 = 0.0692 + 0.0890 + 0.0039, time: 7.382966]
2023-05-15 15:40:07.425: epoch 63:	0.02476772  	0.18300681  	0.09848404  
2023-05-15 15:40:07.425: Find a better model.
2023-05-15 15:40:14.687: [iter 64 : loss : 0.1609 = 0.0681 + 0.0889 + 0.0039, time: 7.260937]
2023-05-15 15:40:14.843: epoch 64:	0.02481711  	0.18329144  	0.09864040  
2023-05-15 15:40:14.843: Find a better model.
2023-05-15 15:40:22.131: [iter 65 : loss : 0.1596 = 0.0669 + 0.0887 + 0.0039, time: 7.286767]
2023-05-15 15:40:22.284: epoch 65:	0.02483122  	0.18364675  	0.09905265  
2023-05-15 15:40:22.284: Find a better model.
2023-05-15 15:40:29.478: [iter 66 : loss : 0.1580 = 0.0655 + 0.0886 + 0.0040, time: 7.193033]
2023-05-15 15:40:29.620: epoch 66:	0.02499352  	0.18445894  	0.09941792  
2023-05-15 15:40:29.620: Find a better model.
2023-05-15 15:40:36.893: [iter 67 : loss : 0.1566 = 0.0641 + 0.0884 + 0.0040, time: 7.271830]
2023-05-15 15:40:37.049: epoch 67:	0.02509231  	0.18542925  	0.09986722  
2023-05-15 15:40:37.049: Find a better model.
2023-05-15 15:40:44.317: [iter 68 : loss : 0.1560 = 0.0637 + 0.0882 + 0.0041, time: 7.266834]
2023-05-15 15:40:44.476: epoch 68:	0.02511348  	0.18573163  	0.10025518  
2023-05-15 15:40:44.476: Find a better model.
2023-05-15 15:40:51.695: [iter 69 : loss : 0.1542 = 0.0620 + 0.0881 + 0.0041, time: 7.217656]
2023-05-15 15:40:51.850: epoch 69:	0.02518405  	0.18627053  	0.10066284  
2023-05-15 15:40:51.850: Find a better model.
2023-05-15 15:40:59.105: [iter 70 : loss : 0.1526 = 0.0604 + 0.0880 + 0.0042, time: 7.253969]
2023-05-15 15:40:59.250: epoch 70:	0.02532518  	0.18743265  	0.10124419  
2023-05-15 15:40:59.250: Find a better model.
2023-05-15 15:41:06.476: [iter 71 : loss : 0.1512 = 0.0590 + 0.0879 + 0.0042, time: 7.223297]
2023-05-15 15:41:06.620: epoch 71:	0.02531811  	0.18729152  	0.10119410  
2023-05-15 15:41:13.891: [iter 72 : loss : 0.1510 = 0.0589 + 0.0878 + 0.0042, time: 7.269561]
2023-05-15 15:41:14.044: epoch 72:	0.02537457  	0.18776357  	0.10131202  
2023-05-15 15:41:14.044: Find a better model.
2023-05-15 15:41:21.297: [iter 73 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 7.251481]
2023-05-15 15:41:21.450: epoch 73:	0.02541691  	0.18816876  	0.10160395  
2023-05-15 15:41:21.450: Find a better model.
2023-05-15 15:41:28.676: [iter 74 : loss : 0.1482 = 0.0564 + 0.0875 + 0.0043, time: 7.225601]
2023-05-15 15:41:28.831: epoch 74:	0.02552276  	0.18870497  	0.10199907  
2023-05-15 15:41:28.831: Find a better model.
2023-05-15 15:41:36.255: [iter 75 : loss : 0.1477 = 0.0560 + 0.0874 + 0.0044, time: 7.421924]
2023-05-15 15:41:36.398: epoch 75:	0.02553687  	0.18845847  	0.10228087  
2023-05-15 15:41:43.670: [iter 76 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 7.270036]
2023-05-15 15:41:43.825: epoch 76:	0.02552981  	0.18844786  	0.10238074  
2023-05-15 15:41:51.054: [iter 77 : loss : 0.1457 = 0.0540 + 0.0872 + 0.0044, time: 7.227351]
2023-05-15 15:41:51.207: epoch 77:	0.02571328  	0.18976091  	0.10292827  
2023-05-15 15:41:51.207: Find a better model.
2023-05-15 15:41:58.478: [iter 78 : loss : 0.1448 = 0.0532 + 0.0871 + 0.0045, time: 7.269861]
2023-05-15 15:41:58.634: epoch 78:	0.02578384  	0.19025043  	0.10323193  
2023-05-15 15:41:58.634: Find a better model.
2023-05-15 15:42:05.885: [iter 79 : loss : 0.1435 = 0.0520 + 0.0869 + 0.0045, time: 7.250283]
2023-05-15 15:42:06.041: epoch 79:	0.02576267  	0.19000563  	0.10321035  
2023-05-15 15:42:13.269: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 7.226092]
2023-05-15 15:42:13.424: epoch 80:	0.02577679  	0.19004761  	0.10346462  
2023-05-15 15:42:20.681: [iter 81 : loss : 0.1424 = 0.0511 + 0.0867 + 0.0046, time: 7.254855]
2023-05-15 15:42:20.835: epoch 81:	0.02576973  	0.18983571  	0.10339227  
2023-05-15 15:42:28.061: [iter 82 : loss : 0.1412 = 0.0499 + 0.0866 + 0.0046, time: 7.225340]
2023-05-15 15:42:28.216: epoch 82:	0.02581912  	0.18999070  	0.10353834  
2023-05-15 15:42:35.631: [iter 83 : loss : 0.1402 = 0.0490 + 0.0865 + 0.0047, time: 7.414255]
2023-05-15 15:42:35.785: epoch 83:	0.02581206  	0.18984993  	0.10375351  
2023-05-15 15:42:43.055: [iter 84 : loss : 0.1402 = 0.0490 + 0.0865 + 0.0047, time: 7.268249]
2023-05-15 15:42:43.199: epoch 84:	0.02593907  	0.19084188  	0.10408330  
2023-05-15 15:42:43.199: Find a better model.
2023-05-15 15:42:50.446: [iter 85 : loss : 0.1391 = 0.0480 + 0.0863 + 0.0048, time: 7.246634]
2023-05-15 15:42:50.605: epoch 85:	0.02589673  	0.19048171  	0.10411125  
2023-05-15 15:42:57.837: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 7.230765]
2023-05-15 15:42:57.992: epoch 86:	0.02603081  	0.19136074  	0.10450690  
2023-05-15 15:42:57.992: Find a better model.
2023-05-15 15:43:05.487: [iter 87 : loss : 0.1365 = 0.0455 + 0.0862 + 0.0048, time: 7.494372]
2023-05-15 15:43:05.645: epoch 87:	0.02600964  	0.19139598  	0.10465983  
2023-05-15 15:43:05.645: Find a better model.
2023-05-15 15:43:12.999: [iter 88 : loss : 0.1358 = 0.0448 + 0.0861 + 0.0049, time: 7.352712]
2023-05-15 15:43:13.154: epoch 88:	0.02605198  	0.19148892  	0.10469118  
2023-05-15 15:43:13.154: Find a better model.
2023-05-15 15:43:20.625: [iter 89 : loss : 0.1355 = 0.0446 + 0.0860 + 0.0049, time: 7.470641]
2023-05-15 15:43:20.782: epoch 89:	0.02606609  	0.19143702  	0.10456610  
2023-05-15 15:43:28.296: [iter 90 : loss : 0.1358 = 0.0450 + 0.0859 + 0.0050, time: 7.512223]
2023-05-15 15:43:28.441: epoch 90:	0.02611548  	0.19193633  	0.10486016  
2023-05-15 15:43:28.441: Find a better model.
2023-05-15 15:43:35.833: [iter 91 : loss : 0.1347 = 0.0439 + 0.0858 + 0.0050, time: 7.390888]
2023-05-15 15:43:35.987: epoch 91:	0.02608726  	0.19186649  	0.10478213  
2023-05-15 15:43:43.443: [iter 92 : loss : 0.1337 = 0.0430 + 0.0857 + 0.0050, time: 7.454480]
2023-05-15 15:43:43.600: epoch 92:	0.02611549  	0.19224392  	0.10499682  
2023-05-15 15:43:43.600: Find a better model.
2023-05-15 15:43:50.819: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 7.218369]
2023-05-15 15:43:50.975: epoch 93:	0.02622839  	0.19334529  	0.10539427  
2023-05-15 15:43:50.975: Find a better model.
2023-05-15 15:43:58.418: [iter 94 : loss : 0.1318 = 0.0412 + 0.0856 + 0.0051, time: 7.440911]
2023-05-15 15:43:58.560: epoch 94:	0.02622134  	0.19317392  	0.10542030  
2023-05-15 15:44:05.851: [iter 95 : loss : 0.1312 = 0.0406 + 0.0855 + 0.0051, time: 7.289310]
2023-05-15 15:44:06.008: epoch 95:	0.02621428  	0.19303320  	0.10536337  
2023-05-15 15:44:13.395: [iter 96 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0052, time: 7.385498]
2023-05-15 15:44:13.538: epoch 96:	0.02622133  	0.19325267  	0.10564630  
2023-05-15 15:44:20.822: [iter 97 : loss : 0.1295 = 0.0390 + 0.0853 + 0.0052, time: 7.282865]
2023-05-15 15:44:20.975: epoch 97:	0.02625662  	0.19343328  	0.10582250  
2023-05-15 15:44:20.975: Find a better model.
2023-05-15 15:44:28.428: [iter 98 : loss : 0.1305 = 0.0400 + 0.0853 + 0.0052, time: 7.452069]
2023-05-15 15:44:28.581: epoch 98:	0.02633424  	0.19426721  	0.10598186  
2023-05-15 15:44:28.581: Find a better model.
2023-05-15 15:44:35.825: [iter 99 : loss : 0.1291 = 0.0386 + 0.0852 + 0.0053, time: 7.242845]
2023-05-15 15:44:35.979: epoch 99:	0.02639775  	0.19466063  	0.10625178  
2023-05-15 15:44:35.980: Find a better model.
2023-05-15 15:44:43.385: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 7.403239]
2023-05-15 15:44:43.543: epoch 100:	0.02636247  	0.19414043  	0.10630438  
2023-05-15 15:44:50.841: [iter 101 : loss : 0.1284 = 0.0380 + 0.0851 + 0.0054, time: 7.297492]
2023-05-15 15:44:50.995: epoch 101:	0.02636247  	0.19437721  	0.10645007  
2023-05-15 15:44:58.206: [iter 102 : loss : 0.1274 = 0.0371 + 0.0850 + 0.0054, time: 7.208735]
2023-05-15 15:44:58.358: epoch 102:	0.02630602  	0.19358508  	0.10624500  
2023-05-15 15:45:05.621: [iter 103 : loss : 0.1270 = 0.0367 + 0.0849 + 0.0054, time: 7.260756]
2023-05-15 15:45:05.777: epoch 103:	0.02636953  	0.19404824  	0.10649383  
2023-05-15 15:45:13.006: [iter 104 : loss : 0.1275 = 0.0372 + 0.0848 + 0.0055, time: 7.227666]
2023-05-15 15:45:13.159: epoch 104:	0.02646126  	0.19473922  	0.10691494  
2023-05-15 15:45:13.160: Find a better model.
2023-05-15 15:45:20.562: [iter 105 : loss : 0.1267 = 0.0365 + 0.0848 + 0.0055, time: 7.401151]
2023-05-15 15:45:20.723: epoch 105:	0.02651065  	0.19510533  	0.10684181  
2023-05-15 15:45:20.723: Find a better model.
2023-05-15 15:45:28.011: [iter 106 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 7.286550]
2023-05-15 15:45:28.167: epoch 106:	0.02651064  	0.19502859  	0.10689531  
2023-05-15 15:45:35.385: [iter 107 : loss : 0.1253 = 0.0351 + 0.0847 + 0.0056, time: 7.217533]
2023-05-15 15:45:35.529: epoch 107:	0.02660944  	0.19574694  	0.10699867  
2023-05-15 15:45:35.529: Find a better model.
2023-05-15 15:45:42.773: [iter 108 : loss : 0.1248 = 0.0346 + 0.0846 + 0.0056, time: 7.242736]
2023-05-15 15:45:42.927: epoch 108:	0.02657416  	0.19542311  	0.10711470  
2023-05-15 15:45:50.170: [iter 109 : loss : 0.1238 = 0.0337 + 0.0845 + 0.0056, time: 7.241651]
2023-05-15 15:45:50.326: epoch 109:	0.02656004  	0.19549263  	0.10707107  
2023-05-15 15:45:57.561: [iter 110 : loss : 0.1231 = 0.0330 + 0.0845 + 0.0057, time: 7.233856]
2023-05-15 15:45:57.721: epoch 110:	0.02658827  	0.19596596  	0.10721578  
2023-05-15 15:45:57.722: Find a better model.
2023-05-15 15:46:04.948: [iter 111 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.225442]
2023-05-15 15:46:05.104: epoch 111:	0.02670824  	0.19657403  	0.10761835  
2023-05-15 15:46:05.104: Find a better model.
2023-05-15 15:46:12.398: [iter 112 : loss : 0.1230 = 0.0329 + 0.0843 + 0.0057, time: 7.291741]
2023-05-15 15:46:12.542: epoch 112:	0.02670824  	0.19659612  	0.10757025  
2023-05-15 15:46:12.542: Find a better model.
2023-05-15 15:46:19.785: [iter 113 : loss : 0.1230 = 0.0329 + 0.0843 + 0.0058, time: 7.241865]
2023-05-15 15:46:19.939: epoch 113:	0.02676469  	0.19688423  	0.10763397  
2023-05-15 15:46:19.939: Find a better model.
2023-05-15 15:46:27.195: [iter 114 : loss : 0.1219 = 0.0319 + 0.0842 + 0.0058, time: 7.254414]
2023-05-15 15:46:27.351: epoch 114:	0.02677880  	0.19657508  	0.10771240  
2023-05-15 15:46:34.563: [iter 115 : loss : 0.1218 = 0.0317 + 0.0842 + 0.0058, time: 7.210593]
2023-05-15 15:46:34.705: epoch 115:	0.02678585  	0.19687468  	0.10773248  
2023-05-15 15:46:41.953: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 7.246629]
2023-05-15 15:46:42.107: epoch 116:	0.02678586  	0.19714254  	0.10798722  
2023-05-15 15:46:42.108: Find a better model.
2023-05-15 15:46:49.382: [iter 117 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.271084]
2023-05-15 15:46:49.524: epoch 117:	0.02670118  	0.19650491  	0.10791729  
2023-05-15 15:46:56.744: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.218354]
2023-05-15 15:46:56.897: epoch 118:	0.02670118  	0.19653983  	0.10792869  
2023-05-15 15:47:04.150: [iter 119 : loss : 0.1194 = 0.0295 + 0.0839 + 0.0060, time: 7.250452]
2023-05-15 15:47:04.296: epoch 119:	0.02677175  	0.19667824  	0.10799832  
2023-05-15 15:47:11.577: [iter 120 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 7.280265]
2023-05-15 15:47:11.733: epoch 120:	0.02677175  	0.19666745  	0.10816578  
2023-05-15 15:47:18.947: [iter 121 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 7.212673]
2023-05-15 15:47:19.100: epoch 121:	0.02676469  	0.19687389  	0.10806663  
2023-05-15 15:47:26.348: [iter 122 : loss : 0.1191 = 0.0292 + 0.0838 + 0.0061, time: 7.246968]
2023-05-15 15:47:26.505: epoch 122:	0.02672235  	0.19661865  	0.10802147  
2023-05-15 15:47:33.759: [iter 123 : loss : 0.1189 = 0.0291 + 0.0838 + 0.0061, time: 7.252625]
2023-05-15 15:47:33.902: epoch 123:	0.02670118  	0.19625033  	0.10797599  
2023-05-15 15:47:41.124: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 7.220294]
2023-05-15 15:47:41.276: epoch 124:	0.02672941  	0.19659641  	0.10811625  
2023-05-15 15:47:48.550: [iter 125 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 7.273046]
2023-05-15 15:47:48.697: epoch 125:	0.02679292  	0.19701880  	0.10809276  
2023-05-15 15:47:55.927: [iter 126 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0062, time: 7.228643]
2023-05-15 15:47:56.081: epoch 126:	0.02677175  	0.19685255  	0.10831989  
2023-05-15 15:48:03.155: [iter 127 : loss : 0.1168 = 0.0270 + 0.0836 + 0.0062, time: 7.073539]
2023-05-15 15:48:03.309: epoch 127:	0.02678586  	0.19708574  	0.10836494  
2023-05-15 15:48:10.561: [iter 128 : loss : 0.1177 = 0.0279 + 0.0835 + 0.0062, time: 7.249906]
2023-05-15 15:48:10.714: epoch 128:	0.02677175  	0.19709022  	0.10842949  
2023-05-15 15:48:17.950: [iter 129 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0063, time: 7.233874]
2023-05-15 15:48:18.106: epoch 129:	0.02677175  	0.19669199  	0.10830488  
2023-05-15 15:48:25.319: [iter 130 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.211004]
2023-05-15 15:48:25.472: epoch 130:	0.02676469  	0.19662513  	0.10833958  
2023-05-15 15:48:32.738: [iter 131 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 7.264440]
2023-05-15 15:48:32.882: epoch 131:	0.02676469  	0.19666912  	0.10823376  
2023-05-15 15:48:40.104: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0064, time: 7.218779]
2023-05-15 15:48:40.258: epoch 132:	0.02679996  	0.19682401  	0.10819431  
2023-05-15 15:48:47.493: [iter 133 : loss : 0.1150 = 0.0253 + 0.0833 + 0.0064, time: 7.234224]
2023-05-15 15:48:47.646: epoch 133:	0.02676468  	0.19669823  	0.10842059  
2023-05-15 15:48:54.753: [iter 134 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 7.104617]
2023-05-15 15:48:54.908: epoch 134:	0.02670117  	0.19607320  	0.10848988  
2023-05-15 15:49:02.107: [iter 135 : loss : 0.1152 = 0.0255 + 0.0832 + 0.0064, time: 7.197160]
2023-05-15 15:49:02.262: epoch 135:	0.02663767  	0.19579403  	0.10830323  
2023-05-15 15:49:09.516: [iter 136 : loss : 0.1151 = 0.0254 + 0.0832 + 0.0065, time: 7.252498]
2023-05-15 15:49:09.668: epoch 136:	0.02672235  	0.19620205  	0.10853528  
2023-05-15 15:49:16.902: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 7.233431]
2023-05-15 15:49:17.061: epoch 137:	0.02677174  	0.19668788  	0.10863094  
2023-05-15 15:49:24.296: [iter 138 : loss : 0.1141 = 0.0244 + 0.0831 + 0.0065, time: 7.234576]
2023-05-15 15:49:24.451: epoch 138:	0.02674352  	0.19622727  	0.10851189  
2023-05-15 15:49:31.713: [iter 139 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 7.260214]
2023-05-15 15:49:31.854: epoch 139:	0.02677880  	0.19666740  	0.10864249  
2023-05-15 15:49:38.902: [iter 140 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 7.045758]
2023-05-15 15:49:39.059: epoch 140:	0.02670824  	0.19603495  	0.10843749  
2023-05-15 15:49:46.297: [iter 141 : loss : 0.1140 = 0.0245 + 0.0830 + 0.0066, time: 7.237515]
2023-05-15 15:49:46.451: epoch 141:	0.02672235  	0.19595250  	0.10859337  
2023-05-15 15:49:46.451: Early stopping is trigger at epoch: 141
2023-05-15 15:49:46.451: best_result@epoch 116:

2023-05-15 15:49:46.451: 		0.0268      	0.1971      	0.1080      
2023-05-15 16:20:33.673: my pid: 4236
2023-05-15 16:20:33.673: model: model.general_recommender.SGL
2023-05-15 16:20:33.674: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 16:20:33.674: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 16:20:36.746: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 16:20:44.683: [iter 1 : loss : 0.7718 = 0.6930 + 0.0788 + 0.0000, time: 7.937412]
2023-05-15 16:20:44.839: epoch 1:	0.00165115  	0.01203942  	0.00599483  
2023-05-15 16:20:44.839: Find a better model.
2023-05-15 16:20:52.917: [iter 2 : loss : 0.7714 = 0.6928 + 0.0785 + 0.0000, time: 8.076731]
2023-05-15 16:20:53.123: epoch 2:	0.00315410  	0.02335886  	0.01114080  
2023-05-15 16:20:53.124: Find a better model.
2023-05-15 16:21:01.050: [iter 3 : loss : 0.7711 = 0.6925 + 0.0786 + 0.0000, time: 7.925307]
2023-05-15 16:21:01.229: epoch 3:	0.00565195  	0.04142966  	0.01953099  
2023-05-15 16:21:01.229: Find a better model.
2023-05-15 16:21:09.090: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.858691]
2023-05-15 16:21:09.251: epoch 4:	0.00864373  	0.06332573  	0.03004274  
2023-05-15 16:21:09.251: Find a better model.
2023-05-15 16:21:16.876: [iter 5 : loss : 0.7695 = 0.6905 + 0.0789 + 0.0000, time: 7.624715]
2023-05-15 16:21:17.034: epoch 5:	0.01203082  	0.08745531  	0.04166594  
2023-05-15 16:21:17.034: Find a better model.
2023-05-15 16:21:24.696: [iter 6 : loss : 0.7668 = 0.6874 + 0.0793 + 0.0000, time: 7.660787]
2023-05-15 16:21:24.852: epoch 6:	0.01541789  	0.11119326  	0.05386267  
2023-05-15 16:21:24.852: Find a better model.
2023-05-15 16:21:32.446: [iter 7 : loss : 0.7595 = 0.6792 + 0.0802 + 0.0000, time: 7.591722]
2023-05-15 16:21:32.592: epoch 7:	0.01766889  	0.12820747  	0.06309355  
2023-05-15 16:21:32.592: Find a better model.
2023-05-15 16:21:40.036: [iter 8 : loss : 0.7417 = 0.6593 + 0.0823 + 0.0001, time: 7.440936]
2023-05-15 16:21:40.188: epoch 8:	0.01879085  	0.13806234  	0.06922037  
2023-05-15 16:21:40.188: Find a better model.
2023-05-15 16:21:47.644: [iter 9 : loss : 0.7028 = 0.6163 + 0.0864 + 0.0002, time: 7.454441]
2023-05-15 16:21:47.794: epoch 9:	0.01876264  	0.13807128  	0.06923082  
2023-05-15 16:21:47.794: Find a better model.
2023-05-15 16:21:55.075: [iter 10 : loss : 0.6391 = 0.5470 + 0.0918 + 0.0003, time: 7.279858]
2023-05-15 16:21:55.231: epoch 10:	0.01864974  	0.13772343  	0.06904326  
2023-05-15 16:22:02.614: [iter 11 : loss : 0.5635 = 0.4665 + 0.0966 + 0.0004, time: 7.382180]
2023-05-15 16:22:02.767: epoch 11:	0.01849450  	0.13664952  	0.06859117  
2023-05-15 16:22:10.047: [iter 12 : loss : 0.4969 = 0.3966 + 0.0997 + 0.0006, time: 7.277552]
2023-05-15 16:22:10.200: epoch 12:	0.01851567  	0.13711546  	0.06906806  
2023-05-15 16:22:17.640: [iter 13 : loss : 0.4483 = 0.3462 + 0.1014 + 0.0007, time: 7.438173]
2023-05-15 16:22:17.795: epoch 13:	0.01848038  	0.13673559  	0.06918462  
2023-05-15 16:22:25.246: [iter 14 : loss : 0.4115 = 0.3083 + 0.1022 + 0.0009, time: 7.450883]
2023-05-15 16:22:25.400: epoch 14:	0.01867796  	0.13801110  	0.06987099  
2023-05-15 16:22:32.858: [iter 15 : loss : 0.3856 = 0.2821 + 0.1025 + 0.0010, time: 7.457113]
2023-05-15 16:22:33.013: epoch 15:	0.01896023  	0.14031267  	0.07075094  
2023-05-15 16:22:33.013: Find a better model.
2023-05-15 16:22:40.432: [iter 16 : loss : 0.3639 = 0.2602 + 0.1026 + 0.0011, time: 7.418451]
2023-05-15 16:22:40.582: epoch 16:	0.01917898  	0.14149882  	0.07162686  
2023-05-15 16:22:40.582: Find a better model.
2023-05-15 16:22:48.029: [iter 17 : loss : 0.3477 = 0.2441 + 0.1024 + 0.0012, time: 7.445373]
2023-05-15 16:22:48.183: epoch 17:	0.01933422  	0.14242093  	0.07239699  
2023-05-15 16:22:48.183: Find a better model.
2023-05-15 16:22:55.684: [iter 18 : loss : 0.3328 = 0.2294 + 0.1021 + 0.0013, time: 7.500749]
2023-05-15 16:22:55.840: epoch 18:	0.01967295  	0.14527044  	0.07365477  
2023-05-15 16:22:55.840: Find a better model.
2023-05-15 16:23:03.226: [iter 19 : loss : 0.3188 = 0.2157 + 0.1018 + 0.0014, time: 7.385053]
2023-05-15 16:23:03.383: epoch 19:	0.01990581  	0.14702135  	0.07473496  
2023-05-15 16:23:03.383: Find a better model.
2023-05-15 16:23:10.800: [iter 20 : loss : 0.3096 = 0.2068 + 0.1014 + 0.0015, time: 7.415751]
2023-05-15 16:23:10.955: epoch 20:	0.02007517  	0.14816014  	0.07547186  
2023-05-15 16:23:10.955: Find a better model.
2023-05-15 16:23:18.470: [iter 21 : loss : 0.3000 = 0.1975 + 0.1009 + 0.0016, time: 7.512398]
2023-05-15 16:23:18.624: epoch 21:	0.02023041  	0.14904341  	0.07613154  
2023-05-15 16:23:18.625: Find a better model.
2023-05-15 16:23:25.986: [iter 22 : loss : 0.2918 = 0.1896 + 0.1005 + 0.0017, time: 7.360836]
2023-05-15 16:23:26.143: epoch 22:	0.02041387  	0.14985731  	0.07662150  
2023-05-15 16:23:26.143: Find a better model.
2023-05-15 16:23:33.606: [iter 23 : loss : 0.2838 = 0.1819 + 0.1001 + 0.0017, time: 7.460819]
2023-05-15 16:23:33.765: epoch 23:	0.02056206  	0.15111874  	0.07741108  
2023-05-15 16:23:33.765: Find a better model.
2023-05-15 16:23:41.030: [iter 24 : loss : 0.2773 = 0.1758 + 0.0997 + 0.0018, time: 7.264152]
2023-05-15 16:23:41.173: epoch 24:	0.02079493  	0.15339370  	0.07841145  
2023-05-15 16:23:41.173: Find a better model.
2023-05-15 16:23:48.399: [iter 25 : loss : 0.2707 = 0.1695 + 0.0993 + 0.0019, time: 7.224727]
2023-05-15 16:23:48.540: epoch 25:	0.02097840  	0.15484841  	0.07898406  
2023-05-15 16:23:48.541: Find a better model.
2023-05-15 16:23:55.825: [iter 26 : loss : 0.2670 = 0.1662 + 0.0989 + 0.0019, time: 7.283243]
2023-05-15 16:23:55.979: epoch 26:	0.02115481  	0.15607499  	0.07979607  
2023-05-15 16:23:55.979: Find a better model.
2023-05-15 16:24:03.203: [iter 27 : loss : 0.2594 = 0.1590 + 0.0984 + 0.0020, time: 7.223161]
2023-05-15 16:24:03.358: epoch 27:	0.02127478  	0.15722992  	0.08056670  
2023-05-15 16:24:03.358: Find a better model.
2023-05-15 16:24:10.758: [iter 28 : loss : 0.2546 = 0.1545 + 0.0980 + 0.0021, time: 7.397249]
2023-05-15 16:24:10.902: epoch 28:	0.02143707  	0.15829194  	0.08133958  
2023-05-15 16:24:10.902: Find a better model.
2023-05-15 16:24:18.213: [iter 29 : loss : 0.2501 = 0.1504 + 0.0976 + 0.0021, time: 7.309397]
2023-05-15 16:24:18.365: epoch 29:	0.02157820  	0.15916814  	0.08185543  
2023-05-15 16:24:18.365: Find a better model.
2023-05-15 16:24:25.756: [iter 30 : loss : 0.2437 = 0.1443 + 0.0972 + 0.0022, time: 7.390287]
2023-05-15 16:24:25.903: epoch 30:	0.02178284  	0.16073580  	0.08271667  
2023-05-15 16:24:25.903: Find a better model.
2023-05-15 16:24:33.187: [iter 31 : loss : 0.2403 = 0.1412 + 0.0969 + 0.0023, time: 7.283339]
2023-05-15 16:24:33.348: epoch 31:	0.02185341  	0.16099223  	0.08296519  
2023-05-15 16:24:33.348: Find a better model.
2023-05-15 16:24:40.767: [iter 32 : loss : 0.2344 = 0.1356 + 0.0965 + 0.0023, time: 7.417701]
2023-05-15 16:24:40.926: epoch 32:	0.02195219  	0.16113442  	0.08353800  
2023-05-15 16:24:40.926: Find a better model.
2023-05-15 16:24:48.183: [iter 33 : loss : 0.2319 = 0.1334 + 0.0961 + 0.0024, time: 7.255323]
2023-05-15 16:24:48.338: epoch 33:	0.02217800  	0.16264625  	0.08446392  
2023-05-15 16:24:48.339: Find a better model.
2023-05-15 16:24:55.747: [iter 34 : loss : 0.2278 = 0.1296 + 0.0958 + 0.0024, time: 7.407178]
2023-05-15 16:24:55.891: epoch 34:	0.02229796  	0.16378242  	0.08509015  
2023-05-15 16:24:55.892: Find a better model.
2023-05-15 16:25:03.184: [iter 35 : loss : 0.2244 = 0.1264 + 0.0955 + 0.0025, time: 7.291079]
2023-05-15 16:25:03.339: epoch 35:	0.02249554  	0.16535318  	0.08590735  
2023-05-15 16:25:03.339: Find a better model.
2023-05-15 16:25:10.746: [iter 36 : loss : 0.2208 = 0.1231 + 0.0952 + 0.0025, time: 7.406193]
2023-05-15 16:25:10.890: epoch 36:	0.02260139  	0.16616952  	0.08655046  
2023-05-15 16:25:10.890: Find a better model.
2023-05-15 16:25:18.193: [iter 37 : loss : 0.2168 = 0.1194 + 0.0948 + 0.0026, time: 7.301342]
2023-05-15 16:25:18.348: epoch 37:	0.02274957  	0.16722649  	0.08704641  
2023-05-15 16:25:18.348: Find a better model.
2023-05-15 16:25:25.572: [iter 38 : loss : 0.2153 = 0.1181 + 0.0946 + 0.0027, time: 7.223470]
2023-05-15 16:25:25.724: epoch 38:	0.02291187  	0.16866037  	0.08788250  
2023-05-15 16:25:25.724: Find a better model.
2023-05-15 16:25:32.969: [iter 39 : loss : 0.2109 = 0.1140 + 0.0942 + 0.0027, time: 7.243519]
2023-05-15 16:25:33.124: epoch 39:	0.02303889  	0.16955939  	0.08849160  
2023-05-15 16:25:33.124: Find a better model.
2023-05-15 16:25:40.387: [iter 40 : loss : 0.2077 = 0.1110 + 0.0939 + 0.0028, time: 7.262293]
2023-05-15 16:25:40.540: epoch 40:	0.02329998  	0.17169787  	0.08928794  
2023-05-15 16:25:40.540: Find a better model.
2023-05-15 16:25:47.766: [iter 41 : loss : 0.2061 = 0.1096 + 0.0937 + 0.0028, time: 7.225274]
2023-05-15 16:25:47.924: epoch 41:	0.02327175  	0.17144920  	0.08973526  
2023-05-15 16:25:55.145: [iter 42 : loss : 0.2037 = 0.1075 + 0.0934 + 0.0029, time: 7.220116]
2023-05-15 16:25:55.296: epoch 42:	0.02337760  	0.17236130  	0.09045884  
2023-05-15 16:25:55.297: Find a better model.
2023-05-15 16:26:02.562: [iter 43 : loss : 0.1997 = 0.1037 + 0.0930 + 0.0029, time: 7.264417]
2023-05-15 16:26:02.706: epoch 43:	0.02339171  	0.17183763  	0.09085216  
2023-05-15 16:26:09.959: [iter 44 : loss : 0.1964 = 0.1007 + 0.0928 + 0.0030, time: 7.251024]
2023-05-15 16:26:10.111: epoch 44:	0.02361046  	0.17380385  	0.09182054  
2023-05-15 16:26:10.111: Find a better model.
2023-05-15 16:26:17.363: [iter 45 : loss : 0.1944 = 0.0988 + 0.0926 + 0.0030, time: 7.249412]
2023-05-15 16:26:17.515: epoch 45:	0.02370925  	0.17460677  	0.09235717  
2023-05-15 16:26:17.515: Find a better model.
2023-05-15 16:26:24.768: [iter 46 : loss : 0.1918 = 0.0964 + 0.0923 + 0.0031, time: 7.248213]
2023-05-15 16:26:24.915: epoch 46:	0.02384333  	0.17560424  	0.09290875  
2023-05-15 16:26:24.915: Find a better model.
2023-05-15 16:26:32.155: [iter 47 : loss : 0.1912 = 0.0959 + 0.0921 + 0.0031, time: 7.238074]
2023-05-15 16:26:32.307: epoch 47:	0.02392094  	0.17654742  	0.09361105  
2023-05-15 16:26:32.307: Find a better model.
2023-05-15 16:26:39.566: [iter 48 : loss : 0.1874 = 0.0924 + 0.0918 + 0.0032, time: 7.257993]
2023-05-15 16:26:39.708: epoch 48:	0.02404090  	0.17706606  	0.09398953  
2023-05-15 16:26:39.708: Find a better model.
2023-05-15 16:26:47.148: [iter 49 : loss : 0.1842 = 0.0893 + 0.0917 + 0.0032, time: 7.438416]
2023-05-15 16:26:47.300: epoch 49:	0.02411853  	0.17787132  	0.09439877  
2023-05-15 16:26:47.300: Find a better model.
2023-05-15 16:26:54.740: [iter 50 : loss : 0.1833 = 0.0887 + 0.0914 + 0.0033, time: 7.438505]
2023-05-15 16:26:54.894: epoch 50:	0.02409735  	0.17748281  	0.09470316  
2023-05-15 16:27:02.169: [iter 51 : loss : 0.1804 = 0.0858 + 0.0912 + 0.0033, time: 7.273107]
2023-05-15 16:27:02.321: epoch 51:	0.02419614  	0.17824996  	0.09529507  
2023-05-15 16:27:02.321: Find a better model.
2023-05-15 16:27:09.728: [iter 52 : loss : 0.1802 = 0.0858 + 0.0910 + 0.0034, time: 7.404784]
2023-05-15 16:27:09.879: epoch 52:	0.02424554  	0.17826810  	0.09541825  
2023-05-15 16:27:09.879: Find a better model.
2023-05-15 16:27:17.129: [iter 53 : loss : 0.1783 = 0.0841 + 0.0908 + 0.0034, time: 7.249835]
2023-05-15 16:27:17.281: epoch 53:	0.02439373  	0.17948568  	0.09612134  
2023-05-15 16:27:17.281: Find a better model.
2023-05-15 16:27:24.729: [iter 54 : loss : 0.1760 = 0.0820 + 0.0906 + 0.0035, time: 7.445107]
2023-05-15 16:27:24.882: epoch 54:	0.02455603  	0.18108815  	0.09687488  
2023-05-15 16:27:24.882: Find a better model.
2023-05-15 16:27:32.140: [iter 55 : loss : 0.1744 = 0.0805 + 0.0904 + 0.0035, time: 7.256904]
2023-05-15 16:27:32.293: epoch 55:	0.02460542  	0.18150385  	0.09722610  
2023-05-15 16:27:32.293: Find a better model.
2023-05-15 16:27:39.706: [iter 56 : loss : 0.1726 = 0.0788 + 0.0903 + 0.0035, time: 7.411091]
2023-05-15 16:27:39.858: epoch 56:	0.02461953  	0.18170398  	0.09749763  
2023-05-15 16:27:39.858: Find a better model.
2023-05-15 16:27:47.144: [iter 57 : loss : 0.1707 = 0.0771 + 0.0900 + 0.0036, time: 7.284683]
2023-05-15 16:27:47.297: epoch 57:	0.02471833  	0.18222137  	0.09782341  
2023-05-15 16:27:47.297: Find a better model.
2023-05-15 16:27:54.706: [iter 58 : loss : 0.1689 = 0.0754 + 0.0899 + 0.0036, time: 7.407508]
2023-05-15 16:27:54.857: epoch 58:	0.02488062  	0.18344212  	0.09853393  
2023-05-15 16:27:54.857: Find a better model.
2023-05-15 16:28:02.142: [iter 59 : loss : 0.1675 = 0.0742 + 0.0896 + 0.0037, time: 7.283704]
2023-05-15 16:28:02.296: epoch 59:	0.02492296  	0.18387777  	0.09873330  
2023-05-15 16:28:02.296: Find a better model.
2023-05-15 16:28:09.515: [iter 60 : loss : 0.1662 = 0.0730 + 0.0895 + 0.0037, time: 7.218114]
2023-05-15 16:28:09.667: epoch 60:	0.02501469  	0.18444522  	0.09917707  
2023-05-15 16:28:09.667: Find a better model.
2023-05-15 16:28:17.116: [iter 61 : loss : 0.1648 = 0.0717 + 0.0893 + 0.0038, time: 7.447408]
2023-05-15 16:28:17.267: epoch 61:	0.02506409  	0.18455517  	0.09938937  
2023-05-15 16:28:17.267: Find a better model.
2023-05-15 16:28:24.532: [iter 62 : loss : 0.1630 = 0.0701 + 0.0892 + 0.0038, time: 7.262647]
2023-05-15 16:28:24.684: epoch 62:	0.02507820  	0.18463373  	0.09967674  
2023-05-15 16:28:24.685: Find a better model.
2023-05-15 16:28:32.103: [iter 63 : loss : 0.1619 = 0.0690 + 0.0890 + 0.0039, time: 7.417175]
2023-05-15 16:28:32.244: epoch 63:	0.02513466  	0.18498343  	0.09999097  
2023-05-15 16:28:32.244: Find a better model.
2023-05-15 16:28:39.505: [iter 64 : loss : 0.1607 = 0.0680 + 0.0889 + 0.0039, time: 7.259056]
2023-05-15 16:28:39.656: epoch 64:	0.02526167  	0.18578231  	0.10033893  
2023-05-15 16:28:39.657: Find a better model.
2023-05-15 16:28:47.153: [iter 65 : loss : 0.1596 = 0.0669 + 0.0887 + 0.0039, time: 7.495031]
2023-05-15 16:28:47.306: epoch 65:	0.02533223  	0.18611316  	0.10061737  
2023-05-15 16:28:47.306: Find a better model.
2023-05-15 16:28:54.697: [iter 66 : loss : 0.1581 = 0.0656 + 0.0885 + 0.0040, time: 7.390773]
2023-05-15 16:28:54.850: epoch 66:	0.02535340  	0.18599185  	0.10075849  
2023-05-15 16:29:02.278: [iter 67 : loss : 0.1564 = 0.0639 + 0.0884 + 0.0040, time: 7.426821]
2023-05-15 16:29:02.431: epoch 67:	0.02533223  	0.18587527  	0.10089212  
2023-05-15 16:29:09.917: [iter 68 : loss : 0.1561 = 0.0637 + 0.0883 + 0.0041, time: 7.483869]
2023-05-15 16:29:10.070: epoch 68:	0.02543807  	0.18660116  	0.10135812  
2023-05-15 16:29:10.070: Find a better model.
2023-05-15 16:29:17.290: [iter 69 : loss : 0.1542 = 0.0620 + 0.0881 + 0.0041, time: 7.218204]
2023-05-15 16:29:17.442: epoch 69:	0.02548747  	0.18693505  	0.10151172  
2023-05-15 16:29:17.442: Find a better model.
2023-05-15 16:29:24.703: [iter 70 : loss : 0.1526 = 0.0604 + 0.0880 + 0.0042, time: 7.260100]
2023-05-15 16:29:24.856: epoch 70:	0.02539573  	0.18620096  	0.10153150  
2023-05-15 16:29:32.084: [iter 71 : loss : 0.1510 = 0.0589 + 0.0879 + 0.0042, time: 7.226219]
2023-05-15 16:29:32.240: epoch 71:	0.02552980  	0.18710236  	0.10195857  
2023-05-15 16:29:32.240: Find a better model.
2023-05-15 16:29:39.493: [iter 72 : loss : 0.1509 = 0.0589 + 0.0878 + 0.0042, time: 7.251731]
2023-05-15 16:29:39.646: epoch 72:	0.02557214  	0.18739116  	0.10218834  
2023-05-15 16:29:39.646: Find a better model.
2023-05-15 16:29:47.131: [iter 73 : loss : 0.1494 = 0.0575 + 0.0876 + 0.0043, time: 7.483826]
2023-05-15 16:29:47.285: epoch 73:	0.02564975  	0.18797128  	0.10241000  
2023-05-15 16:29:47.286: Find a better model.
2023-05-15 16:29:54.479: [iter 74 : loss : 0.1482 = 0.0563 + 0.0875 + 0.0043, time: 7.191648]
2023-05-15 16:29:54.634: epoch 74:	0.02576266  	0.18890917  	0.10298209  
2023-05-15 16:29:54.634: Find a better model.
2023-05-15 16:30:01.879: [iter 75 : loss : 0.1475 = 0.0558 + 0.0874 + 0.0044, time: 7.244276]
2023-05-15 16:30:02.021: epoch 75:	0.02576972  	0.18905701  	0.10321146  
2023-05-15 16:30:02.021: Find a better model.
2023-05-15 16:30:09.298: [iter 76 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 7.276700]
2023-05-15 16:30:09.451: epoch 76:	0.02583323  	0.18919647  	0.10344114  
2023-05-15 16:30:09.451: Find a better model.
2023-05-15 16:30:16.868: [iter 77 : loss : 0.1456 = 0.0540 + 0.0871 + 0.0044, time: 7.416142]
2023-05-15 16:30:17.021: epoch 77:	0.02595320  	0.19038571  	0.10381005  
2023-05-15 16:30:17.021: Find a better model.
2023-05-15 16:30:24.438: [iter 78 : loss : 0.1448 = 0.0533 + 0.0871 + 0.0045, time: 7.415904]
2023-05-15 16:30:24.593: epoch 78:	0.02599553  	0.19057646  	0.10416397  
2023-05-15 16:30:24.594: Find a better model.
2023-05-15 16:30:31.891: [iter 79 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0045, time: 7.294693]
2023-05-15 16:30:32.041: epoch 79:	0.02603787  	0.19077080  	0.10432807  
2023-05-15 16:30:32.041: Find a better model.
2023-05-15 16:30:39.446: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 7.403155]
2023-05-15 16:30:39.601: epoch 80:	0.02608021  	0.19138916  	0.10458434  
2023-05-15 16:30:39.601: Find a better model.
2023-05-15 16:30:47.100: [iter 81 : loss : 0.1425 = 0.0511 + 0.0867 + 0.0046, time: 7.497896]
2023-05-15 16:30:47.243: epoch 81:	0.02608727  	0.19116789  	0.10449751  
2023-05-15 16:30:54.468: [iter 82 : loss : 0.1412 = 0.0499 + 0.0866 + 0.0046, time: 7.224206]
2023-05-15 16:30:54.621: epoch 82:	0.02615078  	0.19163375  	0.10479558  
2023-05-15 16:30:54.621: Find a better model.
2023-05-15 16:31:01.860: [iter 83 : loss : 0.1400 = 0.0488 + 0.0865 + 0.0047, time: 7.238218]
2023-05-15 16:31:02.014: epoch 83:	0.02621429  	0.19215700  	0.10515874  
2023-05-15 16:31:02.014: Find a better model.
2023-05-15 16:31:09.284: [iter 84 : loss : 0.1401 = 0.0489 + 0.0865 + 0.0047, time: 7.268370]
2023-05-15 16:31:09.437: epoch 84:	0.02625663  	0.19253285  	0.10541546  
2023-05-15 16:31:09.437: Find a better model.
2023-05-15 16:31:16.826: [iter 85 : loss : 0.1390 = 0.0479 + 0.0864 + 0.0048, time: 7.388101]
2023-05-15 16:31:16.977: epoch 85:	0.02622840  	0.19209859  	0.10539457  
2023-05-15 16:31:24.256: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 7.277785]
2023-05-15 16:31:24.411: epoch 86:	0.02625662  	0.19205967  	0.10534526  
2023-05-15 16:31:31.838: [iter 87 : loss : 0.1362 = 0.0453 + 0.0861 + 0.0048, time: 7.426068]
2023-05-15 16:31:31.992: epoch 87:	0.02631308  	0.19261068  	0.10559814  
2023-05-15 16:31:31.992: Find a better model.
2023-05-15 16:31:39.442: [iter 88 : loss : 0.1357 = 0.0447 + 0.0861 + 0.0049, time: 7.448832]
2023-05-15 16:31:39.584: epoch 88:	0.02633425  	0.19298844  	0.10582342  
2023-05-15 16:31:39.584: Find a better model.
2023-05-15 16:31:46.819: [iter 89 : loss : 0.1354 = 0.0445 + 0.0860 + 0.0049, time: 7.233370]
2023-05-15 16:31:46.976: epoch 89:	0.02637658  	0.19337359  	0.10587000  
2023-05-15 16:31:46.976: Find a better model.
2023-05-15 16:31:54.238: [iter 90 : loss : 0.1360 = 0.0451 + 0.0859 + 0.0050, time: 7.259912]
2023-05-15 16:31:54.381: epoch 90:	0.02640481  	0.19345453  	0.10613918  
2023-05-15 16:31:54.381: Find a better model.
2023-05-15 16:32:01.645: [iter 91 : loss : 0.1346 = 0.0438 + 0.0858 + 0.0050, time: 7.262520]
2023-05-15 16:32:01.798: epoch 91:	0.02638364  	0.19364814  	0.10627517  
2023-05-15 16:32:01.798: Find a better model.
2023-05-15 16:32:09.285: [iter 92 : loss : 0.1338 = 0.0431 + 0.0857 + 0.0050, time: 7.484780]
2023-05-15 16:32:09.440: epoch 92:	0.02639775  	0.19361697  	0.10639415  
2023-05-15 16:32:16.801: [iter 93 : loss : 0.1339 = 0.0432 + 0.0856 + 0.0051, time: 7.360481]
2023-05-15 16:32:16.953: epoch 93:	0.02640480  	0.19348907  	0.10641722  
2023-05-15 16:32:24.229: [iter 94 : loss : 0.1316 = 0.0410 + 0.0856 + 0.0051, time: 7.274147]
2023-05-15 16:32:24.384: epoch 94:	0.02646831  	0.19422415  	0.10676773  
2023-05-15 16:32:24.384: Find a better model.
2023-05-15 16:32:31.644: [iter 95 : loss : 0.1313 = 0.0407 + 0.0855 + 0.0051, time: 7.258240]
2023-05-15 16:32:31.796: epoch 95:	0.02641891  	0.19365613  	0.10669711  
2023-05-15 16:32:39.023: [iter 96 : loss : 0.1313 = 0.0407 + 0.0854 + 0.0052, time: 7.225852]
2023-05-15 16:32:39.162: epoch 96:	0.02643302  	0.19374514  	0.10683884  
2023-05-15 16:32:46.431: [iter 97 : loss : 0.1296 = 0.0391 + 0.0853 + 0.0052, time: 7.267297]
2023-05-15 16:32:46.585: epoch 97:	0.02638363  	0.19342147  	0.10672918  
2023-05-15 16:32:53.831: [iter 98 : loss : 0.1305 = 0.0400 + 0.0853 + 0.0052, time: 7.243956]
2023-05-15 16:32:53.982: epoch 98:	0.02648242  	0.19434574  	0.10698985  
2023-05-15 16:32:53.982: Find a better model.
2023-05-15 16:33:01.205: [iter 99 : loss : 0.1292 = 0.0387 + 0.0852 + 0.0053, time: 7.221144]
2023-05-15 16:33:01.359: epoch 99:	0.02639774  	0.19374123  	0.10694658  
2023-05-15 16:33:08.619: [iter 100 : loss : 0.1286 = 0.0382 + 0.0851 + 0.0053, time: 7.259194]
2023-05-15 16:33:08.771: epoch 100:	0.02651064  	0.19461654  	0.10725179  
2023-05-15 16:33:08.771: Find a better model.
2023-05-15 16:33:16.035: [iter 101 : loss : 0.1283 = 0.0379 + 0.0851 + 0.0053, time: 7.262366]
2023-05-15 16:33:16.188: epoch 101:	0.02647536  	0.19391976  	0.10698857  
2023-05-15 16:33:23.409: [iter 102 : loss : 0.1275 = 0.0371 + 0.0850 + 0.0054, time: 7.220231]
2023-05-15 16:33:23.559: epoch 102:	0.02655298  	0.19451477  	0.10741857  
2023-05-15 16:33:30.825: [iter 103 : loss : 0.1269 = 0.0366 + 0.0849 + 0.0054, time: 7.265662]
2023-05-15 16:33:30.977: epoch 103:	0.02654593  	0.19465956  	0.10754848  
2023-05-15 16:33:30.977: Find a better model.
2023-05-15 16:33:38.213: [iter 104 : loss : 0.1276 = 0.0373 + 0.0848 + 0.0055, time: 7.234964]
2023-05-15 16:33:38.366: epoch 104:	0.02664472  	0.19548438  	0.10798864  
2023-05-15 16:33:38.366: Find a better model.
2023-05-15 16:33:45.601: [iter 105 : loss : 0.1266 = 0.0363 + 0.0847 + 0.0055, time: 7.233686]
2023-05-15 16:33:45.754: epoch 105:	0.02664472  	0.19535972  	0.10798117  
2023-05-15 16:33:53.026: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 7.271238]
2023-05-15 16:33:53.177: epoch 106:	0.02658121  	0.19500513  	0.10783322  
2023-05-15 16:34:00.391: [iter 107 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0056, time: 7.211296]
2023-05-15 16:34:00.534: epoch 107:	0.02651769  	0.19432326  	0.10761552  
2023-05-15 16:34:07.795: [iter 108 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0056, time: 7.259481]
2023-05-15 16:34:07.949: epoch 108:	0.02657416  	0.19475962  	0.10788926  
2023-05-15 16:34:15.406: [iter 109 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0056, time: 7.455544]
2023-05-15 16:34:15.561: epoch 109:	0.02650359  	0.19435292  	0.10770974  
2023-05-15 16:34:22.790: [iter 110 : loss : 0.1234 = 0.0333 + 0.0845 + 0.0057, time: 7.228293]
2023-05-15 16:34:22.943: epoch 110:	0.02652476  	0.19452323  	0.10765538  
2023-05-15 16:34:30.183: [iter 111 : loss : 0.1232 = 0.0332 + 0.0844 + 0.0057, time: 7.238919]
2023-05-15 16:34:30.325: epoch 111:	0.02658121  	0.19476837  	0.10777202  
2023-05-15 16:34:37.592: [iter 112 : loss : 0.1229 = 0.0328 + 0.0843 + 0.0057, time: 7.265973]
2023-05-15 16:34:37.745: epoch 112:	0.02661649  	0.19513838  	0.10797394  
2023-05-15 16:34:44.971: [iter 113 : loss : 0.1226 = 0.0326 + 0.0843 + 0.0058, time: 7.222344]
2023-05-15 16:34:45.125: epoch 113:	0.02664471  	0.19540624  	0.10797521  
2023-05-15 16:34:52.402: [iter 114 : loss : 0.1219 = 0.0319 + 0.0842 + 0.0058, time: 7.276092]
2023-05-15 16:34:52.557: epoch 114:	0.02664472  	0.19518061  	0.10814381  
2023-05-15 16:34:59.779: [iter 115 : loss : 0.1216 = 0.0316 + 0.0842 + 0.0058, time: 7.220859]
2023-05-15 16:34:59.933: epoch 115:	0.02662355  	0.19529279  	0.10820724  
2023-05-15 16:35:07.337: [iter 116 : loss : 0.1208 = 0.0308 + 0.0841 + 0.0059, time: 7.403332]
2023-05-15 16:35:07.478: epoch 116:	0.02665883  	0.19537349  	0.10832719  
2023-05-15 16:35:14.780: [iter 117 : loss : 0.1208 = 0.0309 + 0.0841 + 0.0059, time: 7.300927]
2023-05-15 16:35:14.932: epoch 117:	0.02667295  	0.19537908  	0.10830124  
2023-05-15 16:35:22.157: [iter 118 : loss : 0.1207 = 0.0307 + 0.0840 + 0.0059, time: 7.222940]
2023-05-15 16:35:22.299: epoch 118:	0.02668706  	0.19564772  	0.10856752  
2023-05-15 16:35:22.299: Find a better model.
2023-05-15 16:35:29.578: [iter 119 : loss : 0.1194 = 0.0295 + 0.0840 + 0.0060, time: 7.276987]
2023-05-15 16:35:29.729: epoch 119:	0.02663061  	0.19538671  	0.10848751  
2023-05-15 16:35:36.977: [iter 120 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 7.247585]
2023-05-15 16:35:37.119: epoch 120:	0.02660944  	0.19522312  	0.10832644  
2023-05-15 16:35:44.370: [iter 121 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 7.250384]
2023-05-15 16:35:44.522: epoch 121:	0.02665178  	0.19531992  	0.10846094  
2023-05-15 16:35:51.757: [iter 122 : loss : 0.1192 = 0.0293 + 0.0838 + 0.0060, time: 7.232971]
2023-05-15 16:35:51.909: epoch 122:	0.02671529  	0.19578978  	0.10870709  
2023-05-15 16:35:51.910: Find a better model.
2023-05-15 16:35:59.171: [iter 123 : loss : 0.1189 = 0.0290 + 0.0838 + 0.0061, time: 7.260210]
2023-05-15 16:35:59.316: epoch 123:	0.02667294  	0.19526716  	0.10870162  
2023-05-15 16:36:06.557: [iter 124 : loss : 0.1183 = 0.0284 + 0.0837 + 0.0061, time: 7.238674]
2023-05-15 16:36:06.711: epoch 124:	0.02669411  	0.19569026  	0.10884842  
2023-05-15 16:36:13.977: [iter 125 : loss : 0.1174 = 0.0276 + 0.0836 + 0.0061, time: 7.264014]
2023-05-15 16:36:14.127: epoch 125:	0.02679996  	0.19633612  	0.10893554  
2023-05-15 16:36:14.127: Find a better model.
2023-05-15 16:36:21.354: [iter 126 : loss : 0.1177 = 0.0280 + 0.0836 + 0.0062, time: 7.225205]
2023-05-15 16:36:21.507: epoch 126:	0.02676468  	0.19588758  	0.10886154  
2023-05-15 16:36:28.732: [iter 127 : loss : 0.1168 = 0.0270 + 0.0836 + 0.0062, time: 7.222619]
2023-05-15 16:36:28.886: epoch 127:	0.02675762  	0.19555067  	0.10895058  
2023-05-15 16:36:36.337: [iter 128 : loss : 0.1180 = 0.0282 + 0.0835 + 0.0062, time: 7.449780]
2023-05-15 16:36:36.480: epoch 128:	0.02679290  	0.19560342  	0.10903423  
2023-05-15 16:36:43.737: [iter 129 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.256048]
2023-05-15 16:36:43.890: epoch 129:	0.02677173  	0.19565320  	0.10900209  
2023-05-15 16:36:51.138: [iter 130 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.246482]
2023-05-15 16:36:51.292: epoch 130:	0.02672234  	0.19499230  	0.10895856  
2023-05-15 16:36:58.743: [iter 131 : loss : 0.1159 = 0.0262 + 0.0834 + 0.0063, time: 7.449140]
2023-05-15 16:36:58.896: epoch 131:	0.02673645  	0.19543050  	0.10903075  
2023-05-15 16:37:06.115: [iter 132 : loss : 0.1164 = 0.0267 + 0.0833 + 0.0063, time: 7.218422]
2023-05-15 16:37:06.267: epoch 132:	0.02670117  	0.19494830  	0.10893419  
2023-05-15 16:37:13.533: [iter 133 : loss : 0.1149 = 0.0253 + 0.0833 + 0.0064, time: 7.264820]
2023-05-15 16:37:13.692: epoch 133:	0.02678585  	0.19544946  	0.10910451  
2023-05-15 16:37:20.947: [iter 134 : loss : 0.1155 = 0.0259 + 0.0833 + 0.0064, time: 7.253891]
2023-05-15 16:37:21.099: epoch 134:	0.02681407  	0.19564810  	0.10919278  
2023-05-15 16:37:28.318: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 7.218615]
2023-05-15 16:37:28.459: epoch 135:	0.02684230  	0.19584583  	0.10931804  
2023-05-15 16:37:35.745: [iter 136 : loss : 0.1152 = 0.0255 + 0.0832 + 0.0065, time: 7.283613]
2023-05-15 16:37:35.897: epoch 136:	0.02689875  	0.19620244  	0.10958704  
2023-05-15 16:37:43.122: [iter 137 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.224339]
2023-05-15 16:37:43.274: epoch 137:	0.02685641  	0.19589448  	0.10953648  
2023-05-15 16:37:50.525: [iter 138 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 7.248321]
2023-05-15 16:37:50.675: epoch 138:	0.02680701  	0.19527526  	0.10932758  
2023-05-15 16:37:57.944: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0066, time: 7.268130]
2023-05-15 16:37:58.099: epoch 139:	0.02689170  	0.19616686  	0.10964932  
2023-05-15 16:38:05.303: [iter 140 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 7.202425]
2023-05-15 16:38:05.443: epoch 140:	0.02687758  	0.19558366  	0.10943283  
2023-05-15 16:38:12.691: [iter 141 : loss : 0.1139 = 0.0244 + 0.0830 + 0.0066, time: 7.246910]
2023-05-15 16:38:12.848: epoch 141:	0.02689169  	0.19575925  	0.10945293  
2023-05-15 16:38:20.116: [iter 142 : loss : 0.1131 = 0.0235 + 0.0829 + 0.0066, time: 7.267003]
2023-05-15 16:38:20.267: epoch 142:	0.02679290  	0.19493876  	0.10936017  
2023-05-15 16:38:27.485: [iter 143 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0067, time: 7.215580]
2023-05-15 16:38:27.640: epoch 143:	0.02676468  	0.19499983  	0.10925689  
2023-05-15 16:38:34.882: [iter 144 : loss : 0.1127 = 0.0231 + 0.0829 + 0.0067, time: 7.241875]
2023-05-15 16:38:35.036: epoch 144:	0.02680702  	0.19527633  	0.10946684  
2023-05-15 16:38:42.301: [iter 145 : loss : 0.1126 = 0.0230 + 0.0828 + 0.0067, time: 7.264037]
2023-05-15 16:38:42.453: epoch 145:	0.02673645  	0.19488521  	0.10934577  
2023-05-15 16:38:49.682: [iter 146 : loss : 0.1128 = 0.0232 + 0.0828 + 0.0067, time: 7.228236]
2023-05-15 16:38:49.828: epoch 146:	0.02673645  	0.19463904  	0.10922579  
2023-05-15 16:38:57.109: [iter 147 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0068, time: 7.279556]
2023-05-15 16:38:57.263: epoch 147:	0.02671528  	0.19458383  	0.10924342  
2023-05-15 16:39:04.498: [iter 148 : loss : 0.1113 = 0.0217 + 0.0827 + 0.0068, time: 7.233230]
2023-05-15 16:39:04.641: epoch 148:	0.02682818  	0.19538350  	0.10971002  
2023-05-15 16:39:11.888: [iter 149 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.246195]
2023-05-15 16:39:12.028: epoch 149:	0.02675762  	0.19478357  	0.10952606  
2023-05-15 16:39:19.300: [iter 150 : loss : 0.1113 = 0.0217 + 0.0827 + 0.0068, time: 7.269364]
2023-05-15 16:39:19.452: epoch 150:	0.02678585  	0.19502440  	0.10954905  
2023-05-15 16:39:19.452: Early stopping is trigger at epoch: 150
2023-05-15 16:39:19.452: best_result@epoch 125:

2023-05-15 16:39:19.452: 		0.0268      	0.1963      	0.1089      
2023-05-15 16:42:35.466: my pid: 8872
2023-05-15 16:42:35.466: model: model.general_recommender.SGL
2023-05-15 16:42:35.466: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 16:42:35.466: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 16:42:38.540: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 16:42:46.629: [iter 1 : loss : 0.7718 = 0.6930 + 0.0788 + 0.0000, time: 8.088082]
2023-05-15 16:42:46.787: epoch 1:	0.00149591  	0.01058936  	0.00516678  
2023-05-15 16:42:46.787: Find a better model.
2023-05-15 16:42:54.839: [iter 2 : loss : 0.7714 = 0.6928 + 0.0785 + 0.0000, time: 8.051847]
2023-05-15 16:42:55.042: epoch 2:	0.00293536  	0.02168134  	0.01071413  
2023-05-15 16:42:55.042: Find a better model.
2023-05-15 16:43:03.066: [iter 3 : loss : 0.7711 = 0.6925 + 0.0786 + 0.0000, time: 8.022770]
2023-05-15 16:43:03.240: epoch 3:	0.00533443  	0.03888867  	0.01887591  
2023-05-15 16:43:03.240: Find a better model.
2023-05-15 16:43:11.091: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.849951]
2023-05-15 16:43:11.234: epoch 4:	0.00846027  	0.06110254  	0.02909012  
2023-05-15 16:43:11.234: Find a better model.
2023-05-15 16:43:18.820: [iter 5 : loss : 0.7696 = 0.6906 + 0.0789 + 0.0000, time: 7.584987]
2023-05-15 16:43:18.961: epoch 5:	0.01196732  	0.08713430  	0.04176413  
2023-05-15 16:43:18.961: Find a better model.
2023-05-15 16:43:26.604: [iter 6 : loss : 0.7670 = 0.6876 + 0.0793 + 0.0000, time: 7.642782]
2023-05-15 16:43:26.749: epoch 6:	0.01568604  	0.11312146  	0.05472293  
2023-05-15 16:43:26.749: Find a better model.
2023-05-15 16:43:34.222: [iter 7 : loss : 0.7600 = 0.6798 + 0.0802 + 0.0000, time: 7.472194]
2023-05-15 16:43:34.380: epoch 7:	0.01801465  	0.13044599  	0.06420849  
2023-05-15 16:43:34.380: Find a better model.
2023-05-15 16:43:41.814: [iter 8 : loss : 0.7431 = 0.6608 + 0.0822 + 0.0001, time: 7.431859]
2023-05-15 16:43:41.957: epoch 8:	0.01901667  	0.13945913  	0.06977638  
2023-05-15 16:43:41.957: Find a better model.
2023-05-15 16:43:49.222: [iter 9 : loss : 0.7058 = 0.6196 + 0.0861 + 0.0001, time: 7.264709]
2023-05-15 16:43:49.374: epoch 9:	0.01892495  	0.13928117  	0.06988863  
2023-05-15 16:43:56.633: [iter 10 : loss : 0.6439 = 0.5521 + 0.0915 + 0.0003, time: 7.257925]
2023-05-15 16:43:56.784: epoch 10:	0.01872031  	0.13817285  	0.06883771  
2023-05-15 16:44:03.995: [iter 11 : loss : 0.5688 = 0.4721 + 0.0963 + 0.0004, time: 7.208752]
2023-05-15 16:44:04.151: epoch 11:	0.01860035  	0.13753514  	0.06870131  
2023-05-15 16:44:11.420: [iter 12 : loss : 0.5015 = 0.4014 + 0.0995 + 0.0006, time: 7.268452]
2023-05-15 16:44:11.572: epoch 12:	0.01852272  	0.13676931  	0.06875802  
2023-05-15 16:44:18.820: [iter 13 : loss : 0.4519 = 0.3499 + 0.1013 + 0.0007, time: 7.246552]
2023-05-15 16:44:18.981: epoch 13:	0.01862857  	0.13735922  	0.06917033  
2023-05-15 16:44:26.178: [iter 14 : loss : 0.4139 = 0.3109 + 0.1021 + 0.0009, time: 7.196767]
2023-05-15 16:44:26.331: epoch 14:	0.01882616  	0.13926579  	0.07005271  
2023-05-15 16:44:33.575: [iter 15 : loss : 0.3876 = 0.2841 + 0.1025 + 0.0010, time: 7.243467]
2023-05-15 16:44:33.718: epoch 15:	0.01900257  	0.14059345  	0.07089081  
2023-05-15 16:44:33.718: Find a better model.
2023-05-15 16:44:40.956: [iter 16 : loss : 0.3655 = 0.2619 + 0.1025 + 0.0011, time: 7.235374]
2023-05-15 16:44:41.097: epoch 16:	0.01917898  	0.14161560  	0.07168097  
2023-05-15 16:44:41.097: Find a better model.
2023-05-15 16:44:48.365: [iter 17 : loss : 0.3490 = 0.2455 + 0.1023 + 0.0012, time: 7.266047]
2023-05-15 16:44:48.520: epoch 17:	0.01944007  	0.14346856  	0.07261512  
2023-05-15 16:44:48.521: Find a better model.
2023-05-15 16:44:55.962: [iter 18 : loss : 0.3339 = 0.2305 + 0.1021 + 0.0013, time: 7.440082]
2023-05-15 16:44:56.115: epoch 18:	0.01965177  	0.14513831  	0.07348383  
2023-05-15 16:44:56.115: Find a better model.
2023-05-15 16:45:03.389: [iter 19 : loss : 0.3198 = 0.2167 + 0.1017 + 0.0014, time: 7.273646]
2023-05-15 16:45:03.544: epoch 19:	0.01978585  	0.14583375  	0.07415514  
2023-05-15 16:45:03.544: Find a better model.
2023-05-15 16:45:10.761: [iter 20 : loss : 0.3102 = 0.2073 + 0.1014 + 0.0015, time: 7.215512]
2023-05-15 16:45:10.904: epoch 20:	0.02008223  	0.14810243  	0.07535209  
2023-05-15 16:45:10.904: Find a better model.
2023-05-15 16:45:18.176: [iter 21 : loss : 0.3002 = 0.1977 + 0.1009 + 0.0016, time: 7.270647]
2023-05-15 16:45:18.331: epoch 21:	0.02009634  	0.14775987  	0.07570990  
2023-05-15 16:45:25.590: [iter 22 : loss : 0.2922 = 0.1900 + 0.1005 + 0.0017, time: 7.257932]
2023-05-15 16:45:25.747: epoch 22:	0.02033626  	0.14961395  	0.07665272  
2023-05-15 16:45:25.747: Find a better model.
2023-05-15 16:45:32.958: [iter 23 : loss : 0.2841 = 0.1822 + 0.1002 + 0.0017, time: 7.210548]
2023-05-15 16:45:33.113: epoch 23:	0.02047034  	0.15051755  	0.07726716  
2023-05-15 16:45:33.113: Find a better model.
2023-05-15 16:45:40.345: [iter 24 : loss : 0.2777 = 0.1762 + 0.0997 + 0.0018, time: 7.230379]
2023-05-15 16:45:40.499: epoch 24:	0.02075964  	0.15252532  	0.07827272  
2023-05-15 16:45:40.499: Find a better model.
2023-05-15 16:45:47.719: [iter 25 : loss : 0.2710 = 0.1699 + 0.0992 + 0.0019, time: 7.218112]
2023-05-15 16:45:47.863: epoch 25:	0.02092194  	0.15366204  	0.07881375  
2023-05-15 16:45:47.863: Find a better model.
2023-05-15 16:45:55.139: [iter 26 : loss : 0.2671 = 0.1664 + 0.0988 + 0.0020, time: 7.274692]
2023-05-15 16:45:55.293: epoch 26:	0.02107012  	0.15469241  	0.07931671  
2023-05-15 16:45:55.293: Find a better model.
2023-05-15 16:46:02.562: [iter 27 : loss : 0.2593 = 0.1589 + 0.0983 + 0.0020, time: 7.267575]
2023-05-15 16:46:02.713: epoch 27:	0.02133122  	0.15653154  	0.08031198  
2023-05-15 16:46:02.714: Find a better model.
2023-05-15 16:46:09.961: [iter 28 : loss : 0.2545 = 0.1544 + 0.0980 + 0.0021, time: 7.246417]
2023-05-15 16:46:10.117: epoch 28:	0.02150058  	0.15807638  	0.08125219  
2023-05-15 16:46:10.118: Find a better model.
2023-05-15 16:46:17.340: [iter 29 : loss : 0.2500 = 0.1502 + 0.0976 + 0.0021, time: 7.220804]
2023-05-15 16:46:17.493: epoch 29:	0.02164877  	0.15880346  	0.08204788  
2023-05-15 16:46:17.493: Find a better model.
2023-05-15 16:46:24.716: [iter 30 : loss : 0.2436 = 0.1442 + 0.0972 + 0.0022, time: 7.221757]
2023-05-15 16:46:24.870: epoch 30:	0.02183930  	0.16031696  	0.08276004  
2023-05-15 16:46:24.870: Find a better model.
2023-05-15 16:46:32.127: [iter 31 : loss : 0.2400 = 0.1409 + 0.0968 + 0.0023, time: 7.254303]
2023-05-15 16:46:32.280: epoch 31:	0.02193809  	0.16109878  	0.08329190  
2023-05-15 16:46:32.281: Find a better model.
2023-05-15 16:46:39.508: [iter 32 : loss : 0.2344 = 0.1356 + 0.0965 + 0.0023, time: 7.225413]
2023-05-15 16:46:39.664: epoch 32:	0.02206510  	0.16159227  	0.08402585  
2023-05-15 16:46:39.664: Find a better model.
2023-05-15 16:46:46.917: [iter 33 : loss : 0.2317 = 0.1332 + 0.0960 + 0.0024, time: 7.250708]
2023-05-15 16:46:47.074: epoch 33:	0.02223446  	0.16331817  	0.08472143  
2023-05-15 16:46:47.074: Find a better model.
2023-05-15 16:46:54.125: [iter 34 : loss : 0.2277 = 0.1295 + 0.0957 + 0.0024, time: 7.049418]
2023-05-15 16:46:54.279: epoch 34:	0.02227680  	0.16378309  	0.08537235  
2023-05-15 16:46:54.279: Find a better model.
2023-05-15 16:47:01.497: [iter 35 : loss : 0.2242 = 0.1263 + 0.0954 + 0.0025, time: 7.216440]
2023-05-15 16:47:01.640: epoch 35:	0.02241793  	0.16480672  	0.08585603  
2023-05-15 16:47:01.640: Find a better model.
2023-05-15 16:47:08.953: [iter 36 : loss : 0.2206 = 0.1230 + 0.0951 + 0.0026, time: 7.311793]
2023-05-15 16:47:09.110: epoch 36:	0.02250965  	0.16534668  	0.08633894  
2023-05-15 16:47:09.110: Find a better model.
2023-05-15 16:47:16.306: [iter 37 : loss : 0.2167 = 0.1193 + 0.0948 + 0.0026, time: 7.194963]
2023-05-15 16:47:16.461: epoch 37:	0.02260845  	0.16586898  	0.08687233  
2023-05-15 16:47:16.461: Find a better model.
2023-05-15 16:47:23.723: [iter 38 : loss : 0.2153 = 0.1182 + 0.0945 + 0.0027, time: 7.260990]
2023-05-15 16:47:23.878: epoch 38:	0.02278486  	0.16770363  	0.08777954  
2023-05-15 16:47:23.878: Find a better model.
2023-05-15 16:47:31.151: [iter 39 : loss : 0.2107 = 0.1138 + 0.0941 + 0.0027, time: 7.272308]
2023-05-15 16:47:31.306: epoch 39:	0.02298245  	0.16884297  	0.08836171  
2023-05-15 16:47:31.307: Find a better model.
2023-05-15 16:47:38.539: [iter 40 : loss : 0.2075 = 0.1108 + 0.0939 + 0.0028, time: 7.231330]
2023-05-15 16:47:38.693: epoch 40:	0.02310240  	0.16983397  	0.08905409  
2023-05-15 16:47:38.693: Find a better model.
2023-05-15 16:47:45.904: [iter 41 : loss : 0.2057 = 0.1093 + 0.0935 + 0.0028, time: 7.209938]
2023-05-15 16:47:46.064: epoch 41:	0.02325059  	0.17096490  	0.08973991  
2023-05-15 16:47:46.064: Find a better model.
2023-05-15 16:47:53.293: [iter 42 : loss : 0.2034 = 0.1072 + 0.0932 + 0.0029, time: 7.227811]
2023-05-15 16:47:53.437: epoch 42:	0.02329293  	0.17107446  	0.09037144  
2023-05-15 16:47:53.437: Find a better model.
2023-05-15 16:48:00.693: [iter 43 : loss : 0.1997 = 0.1038 + 0.0930 + 0.0029, time: 7.254822]
2023-05-15 16:48:00.837: epoch 43:	0.02338466  	0.17203842  	0.09080797  
2023-05-15 16:48:00.837: Find a better model.
2023-05-15 16:48:07.922: [iter 44 : loss : 0.1963 = 0.1006 + 0.0927 + 0.0030, time: 7.083526]
2023-05-15 16:48:08.068: epoch 44:	0.02346934  	0.17276080  	0.09131523  
2023-05-15 16:48:08.068: Find a better model.
2023-05-15 16:48:15.330: [iter 45 : loss : 0.1940 = 0.0985 + 0.0925 + 0.0030, time: 7.261428]
2023-05-15 16:48:15.483: epoch 45:	0.02363164  	0.17408353  	0.09206226  
2023-05-15 16:48:15.483: Find a better model.
2023-05-15 16:48:22.710: [iter 46 : loss : 0.1917 = 0.0964 + 0.0922 + 0.0031, time: 7.225062]
2023-05-15 16:48:22.854: epoch 46:	0.02372337  	0.17458881  	0.09250862  
2023-05-15 16:48:22.854: Find a better model.
2023-05-15 16:48:30.082: [iter 47 : loss : 0.1910 = 0.0959 + 0.0920 + 0.0031, time: 7.227747]
2023-05-15 16:48:30.237: epoch 47:	0.02382216  	0.17526853  	0.09305941  
2023-05-15 16:48:30.237: Find a better model.
2023-05-15 16:48:37.521: [iter 48 : loss : 0.1871 = 0.0922 + 0.0918 + 0.0032, time: 7.282721]
2023-05-15 16:48:37.676: epoch 48:	0.02387155  	0.17561330  	0.09334608  
2023-05-15 16:48:37.676: Find a better model.
2023-05-15 16:48:44.923: [iter 49 : loss : 0.1841 = 0.0893 + 0.0915 + 0.0032, time: 7.245404]
2023-05-15 16:48:45.075: epoch 49:	0.02398445  	0.17683452  	0.09391728  
2023-05-15 16:48:45.075: Find a better model.
2023-05-15 16:48:52.297: [iter 50 : loss : 0.1832 = 0.0886 + 0.0913 + 0.0033, time: 7.221426]
2023-05-15 16:48:52.450: epoch 50:	0.02406912  	0.17728993  	0.09436467  
2023-05-15 16:48:52.450: Find a better model.
2023-05-15 16:48:59.683: [iter 51 : loss : 0.1800 = 0.0855 + 0.0911 + 0.0033, time: 7.230846]
2023-05-15 16:48:59.837: epoch 51:	0.02407618  	0.17713554  	0.09461470  
2023-05-15 16:49:07.082: [iter 52 : loss : 0.1799 = 0.0856 + 0.0910 + 0.0034, time: 7.242916]
2023-05-15 16:49:07.237: epoch 52:	0.02404090  	0.17687139  	0.09480075  
2023-05-15 16:49:14.470: [iter 53 : loss : 0.1781 = 0.0839 + 0.0907 + 0.0034, time: 7.231200]
2023-05-15 16:49:14.623: epoch 53:	0.02417497  	0.17791583  	0.09544250  
2023-05-15 16:49:14.623: Find a better model.
2023-05-15 16:49:21.890: [iter 54 : loss : 0.1754 = 0.0815 + 0.0905 + 0.0035, time: 7.265536]
2023-05-15 16:49:22.043: epoch 54:	0.02421731  	0.17794757  	0.09572288  
2023-05-15 16:49:22.043: Find a better model.
2023-05-15 16:49:29.303: [iter 55 : loss : 0.1739 = 0.0801 + 0.0903 + 0.0035, time: 7.259462]
2023-05-15 16:49:29.456: epoch 55:	0.02436550  	0.17919661  	0.09633771  
2023-05-15 16:49:29.457: Find a better model.
2023-05-15 16:49:36.661: [iter 56 : loss : 0.1720 = 0.0783 + 0.0902 + 0.0036, time: 7.202413]
2023-05-15 16:49:36.812: epoch 56:	0.02453485  	0.18023472  	0.09703110  
2023-05-15 16:49:36.813: Find a better model.
2023-05-15 16:49:44.058: [iter 57 : loss : 0.1706 = 0.0770 + 0.0900 + 0.0036, time: 7.244577]
2023-05-15 16:49:44.214: epoch 57:	0.02457718  	0.18041165  	0.09706095  
2023-05-15 16:49:44.214: Find a better model.
2023-05-15 16:49:51.484: [iter 58 : loss : 0.1682 = 0.0748 + 0.0898 + 0.0037, time: 7.268934]
2023-05-15 16:49:51.681: epoch 58:	0.02464774  	0.18099217  	0.09736303  
2023-05-15 16:49:51.681: Find a better model.
2023-05-15 16:49:58.846: [iter 59 : loss : 0.1672 = 0.0739 + 0.0896 + 0.0037, time: 7.163334]
2023-05-15 16:49:58.988: epoch 59:	0.02464774  	0.18035224  	0.09732207  
2023-05-15 16:50:06.273: [iter 60 : loss : 0.1658 = 0.0727 + 0.0894 + 0.0037, time: 7.284167]
2023-05-15 16:50:06.414: epoch 60:	0.02471125  	0.18115117  	0.09767672  
2023-05-15 16:50:06.414: Find a better model.
2023-05-15 16:50:13.653: [iter 61 : loss : 0.1645 = 0.0714 + 0.0893 + 0.0038, time: 7.237841]
2023-05-15 16:50:13.805: epoch 61:	0.02472536  	0.18169159  	0.09819733  
2023-05-15 16:50:13.805: Find a better model.
2023-05-15 16:50:21.081: [iter 62 : loss : 0.1628 = 0.0698 + 0.0891 + 0.0038, time: 7.274797]
2023-05-15 16:50:21.224: epoch 62:	0.02481005  	0.18205163  	0.09837817  
2023-05-15 16:50:21.224: Find a better model.
2023-05-15 16:50:28.471: [iter 63 : loss : 0.1618 = 0.0690 + 0.0889 + 0.0039, time: 7.244760]
2023-05-15 16:50:28.625: epoch 63:	0.02486650  	0.18265450  	0.09873050  
2023-05-15 16:50:28.625: Find a better model.
2023-05-15 16:50:35.854: [iter 64 : loss : 0.1606 = 0.0679 + 0.0888 + 0.0039, time: 7.227766]
2023-05-15 16:50:36.005: epoch 64:	0.02493706  	0.18306284  	0.09902298  
2023-05-15 16:50:36.005: Find a better model.
2023-05-15 16:50:43.328: [iter 65 : loss : 0.1592 = 0.0666 + 0.0886 + 0.0040, time: 7.322278]
2023-05-15 16:50:43.470: epoch 65:	0.02501469  	0.18350571  	0.09937865  
2023-05-15 16:50:43.470: Find a better model.
2023-05-15 16:50:50.656: [iter 66 : loss : 0.1575 = 0.0651 + 0.0885 + 0.0040, time: 7.184522]
2023-05-15 16:50:50.809: epoch 66:	0.02501468  	0.18373315  	0.09956980  
2023-05-15 16:50:50.809: Find a better model.
2023-05-15 16:50:58.045: [iter 67 : loss : 0.1560 = 0.0637 + 0.0883 + 0.0041, time: 7.235682]
2023-05-15 16:50:58.201: epoch 67:	0.02504996  	0.18387450  	0.09970216  
2023-05-15 16:50:58.202: Find a better model.
2023-05-15 16:51:05.423: [iter 68 : loss : 0.1559 = 0.0637 + 0.0882 + 0.0041, time: 7.218364]
2023-05-15 16:51:05.563: epoch 68:	0.02504290  	0.18366225  	0.09986439  
2023-05-15 16:51:12.647: [iter 69 : loss : 0.1541 = 0.0618 + 0.0881 + 0.0041, time: 7.082714]
2023-05-15 16:51:12.800: epoch 69:	0.02505702  	0.18377511  	0.10005029  
2023-05-15 16:51:19.838: [iter 70 : loss : 0.1525 = 0.0603 + 0.0879 + 0.0042, time: 7.037096]
2023-05-15 16:51:19.992: epoch 70:	0.02516287  	0.18469317  	0.10031717  
2023-05-15 16:51:19.993: Find a better model.
2023-05-15 16:51:27.070: [iter 71 : loss : 0.1510 = 0.0589 + 0.0878 + 0.0042, time: 7.075307]
2023-05-15 16:51:27.212: epoch 71:	0.02531106  	0.18620558  	0.10090961  
2023-05-15 16:51:27.212: Find a better model.
2023-05-15 16:51:34.244: [iter 72 : loss : 0.1507 = 0.0587 + 0.0877 + 0.0043, time: 7.031719]
2023-05-15 16:51:34.385: epoch 72:	0.02537457  	0.18630865  	0.10125725  
2023-05-15 16:51:34.385: Find a better model.
2023-05-15 16:51:41.450: [iter 73 : loss : 0.1493 = 0.0574 + 0.0876 + 0.0043, time: 7.063189]
2023-05-15 16:51:41.593: epoch 73:	0.02546630  	0.18719199  	0.10151024  
2023-05-15 16:51:41.593: Find a better model.
2023-05-15 16:51:48.798: [iter 74 : loss : 0.1479 = 0.0561 + 0.0875 + 0.0043, time: 7.203160]
2023-05-15 16:51:48.950: epoch 74:	0.02561448  	0.18837072  	0.10189523  
2023-05-15 16:51:48.950: Find a better model.
2023-05-15 16:51:56.062: [iter 75 : loss : 0.1475 = 0.0558 + 0.0874 + 0.0044, time: 7.110191]
2023-05-15 16:51:56.219: epoch 75:	0.02567093  	0.18884130  	0.10216720  
2023-05-15 16:51:56.220: Find a better model.
2023-05-15 16:52:03.246: [iter 76 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 7.025198]
2023-05-15 16:52:03.400: epoch 76:	0.02570621  	0.18895885  	0.10227376  
2023-05-15 16:52:03.401: Find a better model.
2023-05-15 16:52:10.416: [iter 77 : loss : 0.1452 = 0.0536 + 0.0871 + 0.0045, time: 7.014365]
2023-05-15 16:52:10.569: epoch 77:	0.02574856  	0.18922345  	0.10241857  
2023-05-15 16:52:10.569: Find a better model.
2023-05-15 16:52:17.627: [iter 78 : loss : 0.1444 = 0.0529 + 0.0870 + 0.0045, time: 7.057180]
2023-05-15 16:52:17.781: epoch 78:	0.02569916  	0.18893330  	0.10255723  
2023-05-15 16:52:24.828: [iter 79 : loss : 0.1430 = 0.0516 + 0.0869 + 0.0045, time: 7.046610]
2023-05-15 16:52:24.982: epoch 79:	0.02570622  	0.18902275  	0.10284483  
2023-05-15 16:52:32.037: [iter 80 : loss : 0.1425 = 0.0512 + 0.0868 + 0.0046, time: 7.054290]
2023-05-15 16:52:32.176: epoch 80:	0.02574150  	0.18909650  	0.10296685  
2023-05-15 16:52:39.401: [iter 81 : loss : 0.1422 = 0.0509 + 0.0866 + 0.0046, time: 7.223955]
2023-05-15 16:52:39.542: epoch 81:	0.02569210  	0.18909886  	0.10314554  
2023-05-15 16:52:46.629: [iter 82 : loss : 0.1409 = 0.0497 + 0.0866 + 0.0047, time: 7.084932]
2023-05-15 16:52:46.783: epoch 82:	0.02579089  	0.18960999  	0.10336221  
2023-05-15 16:52:46.783: Find a better model.
2023-05-15 16:52:53.980: [iter 83 : loss : 0.1399 = 0.0488 + 0.0864 + 0.0047, time: 7.195563]
2023-05-15 16:52:54.132: epoch 83:	0.02576972  	0.18970603  	0.10369746  
2023-05-15 16:52:54.132: Find a better model.
2023-05-15 16:53:01.229: [iter 84 : loss : 0.1397 = 0.0485 + 0.0864 + 0.0047, time: 7.096108]
2023-05-15 16:53:01.384: epoch 84:	0.02584028  	0.19021063  	0.10394187  
2023-05-15 16:53:01.384: Find a better model.
2023-05-15 16:53:08.594: [iter 85 : loss : 0.1389 = 0.0479 + 0.0863 + 0.0048, time: 7.208569]
2023-05-15 16:53:08.736: epoch 85:	0.02579795  	0.18971096  	0.10392135  
2023-05-15 16:53:15.787: [iter 86 : loss : 0.1389 = 0.0479 + 0.0862 + 0.0048, time: 7.049767]
2023-05-15 16:53:15.941: epoch 86:	0.02582617  	0.18994619  	0.10402340  
2023-05-15 16:53:23.163: [iter 87 : loss : 0.1360 = 0.0450 + 0.0861 + 0.0049, time: 7.221196]
2023-05-15 16:53:23.319: epoch 87:	0.02593202  	0.19086023  	0.10444042  
2023-05-15 16:53:23.319: Find a better model.
2023-05-15 16:53:30.566: [iter 88 : loss : 0.1352 = 0.0443 + 0.0860 + 0.0049, time: 7.245400]
2023-05-15 16:53:30.717: epoch 88:	0.02593202  	0.19067395  	0.10469676  
2023-05-15 16:53:37.816: [iter 89 : loss : 0.1348 = 0.0439 + 0.0859 + 0.0049, time: 7.097874]
2023-05-15 16:53:37.969: epoch 89:	0.02591086  	0.19061518  	0.10471915  
2023-05-15 16:53:45.194: [iter 90 : loss : 0.1356 = 0.0448 + 0.0858 + 0.0050, time: 7.223518]
2023-05-15 16:53:45.348: epoch 90:	0.02602376  	0.19122347  	0.10496704  
2023-05-15 16:53:45.348: Find a better model.
2023-05-15 16:53:52.416: [iter 91 : loss : 0.1342 = 0.0435 + 0.0857 + 0.0050, time: 7.065891]
2023-05-15 16:53:52.568: epoch 91:	0.02600259  	0.19101959  	0.10507407  
2023-05-15 16:53:59.766: [iter 92 : loss : 0.1334 = 0.0426 + 0.0857 + 0.0050, time: 7.195696]
2023-05-15 16:53:59.917: epoch 92:	0.02603787  	0.19127145  	0.10491981  
2023-05-15 16:53:59.917: Find a better model.
2023-05-15 16:54:07.184: [iter 93 : loss : 0.1339 = 0.0433 + 0.0856 + 0.0051, time: 7.266623]
2023-05-15 16:54:07.344: epoch 93:	0.02606610  	0.19143656  	0.10516361  
2023-05-15 16:54:07.344: Find a better model.
2023-05-15 16:54:14.411: [iter 94 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 7.065609]
2023-05-15 16:54:14.563: epoch 94:	0.02612256  	0.19187498  	0.10531401  
2023-05-15 16:54:14.563: Find a better model.
2023-05-15 16:54:21.774: [iter 95 : loss : 0.1310 = 0.0404 + 0.0854 + 0.0052, time: 7.210330]
2023-05-15 16:54:21.928: epoch 95:	0.02612961  	0.19208136  	0.10554490  
2023-05-15 16:54:21.928: Find a better model.
2023-05-15 16:54:29.152: [iter 96 : loss : 0.1313 = 0.0408 + 0.0854 + 0.0052, time: 7.222491]
2023-05-15 16:54:29.307: epoch 96:	0.02610138  	0.19179219  	0.10561398  
2023-05-15 16:54:36.374: [iter 97 : loss : 0.1295 = 0.0390 + 0.0852 + 0.0052, time: 7.065133]
2023-05-15 16:54:36.528: epoch 97:	0.02610138  	0.19181083  	0.10552795  
2023-05-15 16:54:43.774: [iter 98 : loss : 0.1304 = 0.0400 + 0.0852 + 0.0053, time: 7.244981]
2023-05-15 16:54:43.927: epoch 98:	0.02605199  	0.19123760  	0.10570812  
2023-05-15 16:54:51.178: [iter 99 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 7.249616]
2023-05-15 16:54:51.331: epoch 99:	0.02608021  	0.19144084  	0.10595946  
2023-05-15 16:54:58.567: [iter 100 : loss : 0.1283 = 0.0379 + 0.0850 + 0.0053, time: 7.234028]
2023-05-15 16:54:58.721: epoch 100:	0.02622840  	0.19258165  	0.10619052  
2023-05-15 16:54:58.721: Find a better model.
2023-05-15 16:55:05.765: [iter 101 : loss : 0.1283 = 0.0380 + 0.0850 + 0.0054, time: 7.043037]
2023-05-15 16:55:05.917: epoch 101:	0.02624251  	0.19244951  	0.10635306  
2023-05-15 16:55:12.981: [iter 102 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 7.062707]
2023-05-15 16:55:13.134: epoch 102:	0.02627780  	0.19275048  	0.10645967  
2023-05-15 16:55:13.134: Find a better model.
2023-05-15 16:55:20.328: [iter 103 : loss : 0.1265 = 0.0362 + 0.0848 + 0.0054, time: 7.192907]
2023-05-15 16:55:20.473: epoch 103:	0.02640481  	0.19359498  	0.10672387  
2023-05-15 16:55:20.473: Find a better model.
2023-05-15 16:55:27.553: [iter 104 : loss : 0.1274 = 0.0371 + 0.0848 + 0.0055, time: 7.078896]
2023-05-15 16:55:27.704: epoch 104:	0.02632013  	0.19271182  	0.10669311  
2023-05-15 16:55:34.942: [iter 105 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 7.237127]
2023-05-15 16:55:35.082: epoch 105:	0.02628485  	0.19246191  	0.10664773  
2023-05-15 16:55:42.152: [iter 106 : loss : 0.1257 = 0.0355 + 0.0847 + 0.0055, time: 7.068160]
2023-05-15 16:55:42.304: epoch 106:	0.02633425  	0.19288619  	0.10683337  
2023-05-15 16:55:49.546: [iter 107 : loss : 0.1252 = 0.0350 + 0.0846 + 0.0056, time: 7.241701]
2023-05-15 16:55:49.699: epoch 107:	0.02636247  	0.19283785  	0.10674445  
2023-05-15 16:55:56.938: [iter 108 : loss : 0.1248 = 0.0347 + 0.0845 + 0.0056, time: 7.237724]
2023-05-15 16:55:57.092: epoch 108:	0.02634836  	0.19277576  	0.10684127  
2023-05-15 16:56:04.323: [iter 109 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0056, time: 7.230250]
2023-05-15 16:56:04.467: epoch 109:	0.02639775  	0.19310765  	0.10690943  
2023-05-15 16:56:11.541: [iter 110 : loss : 0.1229 = 0.0328 + 0.0844 + 0.0057, time: 7.073426]
2023-05-15 16:56:11.693: epoch 110:	0.02637658  	0.19287004  	0.10695662  
2023-05-15 16:56:18.765: [iter 111 : loss : 0.1229 = 0.0329 + 0.0844 + 0.0057, time: 7.069608]
2023-05-15 16:56:18.918: epoch 111:	0.02634129  	0.19237272  	0.10690148  
2023-05-15 16:56:26.161: [iter 112 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0057, time: 7.242394]
2023-05-15 16:56:26.303: epoch 112:	0.02641891  	0.19301133  	0.10706680  
2023-05-15 16:56:33.532: [iter 113 : loss : 0.1227 = 0.0327 + 0.0842 + 0.0058, time: 7.228078]
2023-05-15 16:56:33.686: epoch 113:	0.02641186  	0.19279459  	0.10707283  
2023-05-15 16:56:40.918: [iter 114 : loss : 0.1218 = 0.0318 + 0.0842 + 0.0058, time: 7.230291]
2023-05-15 16:56:41.071: epoch 114:	0.02643303  	0.19301420  	0.10709263  
2023-05-15 16:56:48.328: [iter 115 : loss : 0.1216 = 0.0316 + 0.0841 + 0.0058, time: 7.255455]
2023-05-15 16:56:48.484: epoch 115:	0.02647537  	0.19319603  	0.10714877  
2023-05-15 16:56:55.720: [iter 116 : loss : 0.1208 = 0.0308 + 0.0841 + 0.0059, time: 7.235005]
2023-05-15 16:56:55.874: epoch 116:	0.02640480  	0.19253160  	0.10705196  
2023-05-15 16:57:03.128: [iter 117 : loss : 0.1205 = 0.0306 + 0.0840 + 0.0059, time: 7.253121]
2023-05-15 16:57:03.280: epoch 117:	0.02642597  	0.19259481  	0.10709084  
2023-05-15 16:57:10.518: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.236195]
2023-05-15 16:57:10.669: epoch 118:	0.02648948  	0.19293648  	0.10713576  
2023-05-15 16:57:17.899: [iter 119 : loss : 0.1194 = 0.0296 + 0.0839 + 0.0060, time: 7.228657]
2023-05-15 16:57:18.042: epoch 119:	0.02640480  	0.19252603  	0.10715313  
2023-05-15 16:57:25.327: [iter 120 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 7.284186]
2023-05-15 16:57:25.470: epoch 120:	0.02648948  	0.19284195  	0.10740700  
2023-05-15 16:57:32.707: [iter 121 : loss : 0.1196 = 0.0298 + 0.0838 + 0.0060, time: 7.236563]
2023-05-15 16:57:32.848: epoch 121:	0.02645420  	0.19261549  	0.10745624  
2023-05-15 16:57:40.081: [iter 122 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 7.231277]
2023-05-15 16:57:40.234: epoch 122:	0.02651065  	0.19278646  	0.10750312  
2023-05-15 16:57:47.496: [iter 123 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 7.259134]
2023-05-15 16:57:47.648: epoch 123:	0.02651065  	0.19280735  	0.10748116  
2023-05-15 16:57:54.892: [iter 124 : loss : 0.1179 = 0.0282 + 0.0836 + 0.0061, time: 7.241861]
2023-05-15 16:57:55.043: epoch 124:	0.02652476  	0.19309089  	0.10758031  
2023-05-15 16:58:02.282: [iter 125 : loss : 0.1173 = 0.0275 + 0.0836 + 0.0062, time: 7.235964]
2023-05-15 16:58:02.426: epoch 125:	0.02650360  	0.19301431  	0.10764907  
2023-05-15 16:58:09.523: [iter 126 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0062, time: 7.095712]
2023-05-15 16:58:09.663: epoch 126:	0.02655299  	0.19323307  	0.10779703  
2023-05-15 16:58:16.730: [iter 127 : loss : 0.1165 = 0.0267 + 0.0835 + 0.0062, time: 7.066181]
2023-05-15 16:58:16.883: epoch 127:	0.02656005  	0.19346809  	0.10786773  
2023-05-15 16:58:24.096: [iter 128 : loss : 0.1176 = 0.0279 + 0.0835 + 0.0063, time: 7.211349]
2023-05-15 16:58:24.248: epoch 128:	0.02657416  	0.19344810  	0.10808184  
2023-05-15 16:58:24.248: Early stopping is trigger at epoch: 128
2023-05-15 16:58:24.248: best_result@epoch 103:

2023-05-15 16:58:24.248: 		0.0264      	0.1936      	0.1067      
2023-05-15 17:01:41.596: my pid: 2988
2023-05-15 17:01:41.596: model: model.general_recommender.SGL
2023-05-15 17:01:41.596: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 17:01:41.596: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 17:01:44.652: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 17:01:52.836: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.183527]
2023-05-15 17:01:52.991: epoch 1:	0.00157353  	0.01214709  	0.00570890  
2023-05-15 17:01:52.991: Find a better model.
2023-05-15 17:02:01.260: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.266866]
2023-05-15 17:02:01.461: epoch 2:	0.00282952  	0.02197789  	0.01017466  
2023-05-15 17:02:01.462: Find a better model.
2023-05-15 17:02:09.456: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 7.991732]
2023-05-15 17:02:09.624: epoch 3:	0.00496046  	0.03678988  	0.01783908  
2023-05-15 17:02:09.624: Find a better model.
2023-05-15 17:02:17.419: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 7.794303]
2023-05-15 17:02:17.583: epoch 4:	0.00830504  	0.06091770  	0.02886543  
2023-05-15 17:02:17.583: Find a better model.
2023-05-15 17:02:25.448: [iter 5 : loss : 0.7696 = 0.6907 + 0.0789 + 0.0000, time: 7.864347]
2023-05-15 17:02:25.607: epoch 5:	0.01198142  	0.08607474  	0.04064751  
2023-05-15 17:02:25.607: Find a better model.
2023-05-15 17:02:33.245: [iter 6 : loss : 0.7670 = 0.6877 + 0.0793 + 0.0000, time: 7.636836]
2023-05-15 17:02:33.398: epoch 6:	0.01535440  	0.11230581  	0.05340331  
2023-05-15 17:02:33.398: Find a better model.
2023-05-15 17:02:40.813: [iter 7 : loss : 0.7602 = 0.6801 + 0.0801 + 0.0000, time: 7.414466]
2023-05-15 17:02:40.966: epoch 7:	0.01769711  	0.12923978  	0.06303777  
2023-05-15 17:02:40.966: Find a better model.
2023-05-15 17:02:48.214: [iter 8 : loss : 0.7434 = 0.6612 + 0.0821 + 0.0001, time: 7.247029]
2023-05-15 17:02:48.354: epoch 8:	0.01870619  	0.13739388  	0.06848574  
2023-05-15 17:02:48.354: Find a better model.
2023-05-15 17:02:55.615: [iter 9 : loss : 0.7062 = 0.6199 + 0.0861 + 0.0001, time: 7.259860]
2023-05-15 17:02:55.771: epoch 9:	0.01885437  	0.13905317  	0.06946020  
2023-05-15 17:02:55.771: Find a better model.
2023-05-15 17:03:03.183: [iter 10 : loss : 0.6434 = 0.5516 + 0.0915 + 0.0003, time: 7.410059]
2023-05-15 17:03:03.338: epoch 10:	0.01854390  	0.13721828  	0.06817647  
2023-05-15 17:03:10.790: [iter 11 : loss : 0.5677 = 0.4709 + 0.0965 + 0.0004, time: 7.451598]
2023-05-15 17:03:10.947: epoch 11:	0.01852273  	0.13680510  	0.06835710  
2023-05-15 17:03:18.576: [iter 12 : loss : 0.5001 = 0.3999 + 0.0996 + 0.0006, time: 7.626286]
2023-05-15 17:03:18.728: epoch 12:	0.01836043  	0.13557269  	0.06823699  
2023-05-15 17:03:26.167: [iter 13 : loss : 0.4507 = 0.3485 + 0.1014 + 0.0007, time: 7.437089]
2023-05-15 17:03:26.319: epoch 13:	0.01846627  	0.13649803  	0.06874740  
2023-05-15 17:03:33.800: [iter 14 : loss : 0.4132 = 0.3100 + 0.1023 + 0.0009, time: 7.480196]
2023-05-15 17:03:33.956: epoch 14:	0.01874853  	0.13876888  	0.06987610  
2023-05-15 17:03:41.192: [iter 15 : loss : 0.3871 = 0.2834 + 0.1027 + 0.0010, time: 7.233704]
2023-05-15 17:03:41.344: epoch 15:	0.01895317  	0.14021491  	0.07078804  
2023-05-15 17:03:41.344: Find a better model.
2023-05-15 17:03:48.763: [iter 16 : loss : 0.3651 = 0.2614 + 0.1026 + 0.0011, time: 7.418742]
2023-05-15 17:03:48.918: epoch 16:	0.01918603  	0.14174721  	0.07169791  
2023-05-15 17:03:48.918: Find a better model.
2023-05-15 17:03:56.373: [iter 17 : loss : 0.3490 = 0.2454 + 0.1024 + 0.0012, time: 7.453710]
2023-05-15 17:03:56.529: epoch 17:	0.01935540  	0.14304571  	0.07245447  
2023-05-15 17:03:56.529: Find a better model.
2023-05-15 17:04:03.963: [iter 18 : loss : 0.3339 = 0.2304 + 0.1022 + 0.0013, time: 7.432013]
2023-05-15 17:04:04.116: epoch 18:	0.01955298  	0.14432281  	0.07344401  
2023-05-15 17:04:04.116: Find a better model.
2023-05-15 17:04:11.588: [iter 19 : loss : 0.3198 = 0.2166 + 0.1018 + 0.0014, time: 7.471328]
2023-05-15 17:04:11.741: epoch 19:	0.01975057  	0.14529063  	0.07422420  
2023-05-15 17:04:11.741: Find a better model.
2023-05-15 17:04:18.983: [iter 20 : loss : 0.3104 = 0.2074 + 0.1014 + 0.0015, time: 7.241199]
2023-05-15 17:04:19.124: epoch 20:	0.02006811  	0.14750682  	0.07524619  
2023-05-15 17:04:19.124: Find a better model.
2023-05-15 17:04:26.546: [iter 21 : loss : 0.3009 = 0.1983 + 0.1010 + 0.0016, time: 7.419730]
2023-05-15 17:04:26.699: epoch 21:	0.02028685  	0.14915112  	0.07607076  
2023-05-15 17:04:26.699: Find a better model.
2023-05-15 17:04:33.963: [iter 22 : loss : 0.2924 = 0.1902 + 0.1006 + 0.0017, time: 7.263409]
2023-05-15 17:04:34.118: epoch 22:	0.02034330  	0.14963724  	0.07642893  
2023-05-15 17:04:34.118: Find a better model.
2023-05-15 17:04:41.363: [iter 23 : loss : 0.2842 = 0.1822 + 0.1002 + 0.0017, time: 7.244000]
2023-05-15 17:04:41.518: epoch 23:	0.02056911  	0.15122017  	0.07727647  
2023-05-15 17:04:41.518: Find a better model.
2023-05-15 17:04:48.947: [iter 24 : loss : 0.2778 = 0.1763 + 0.0997 + 0.0018, time: 7.427341]
2023-05-15 17:04:49.089: epoch 24:	0.02071730  	0.15232743  	0.07796042  
2023-05-15 17:04:49.089: Find a better model.
2023-05-15 17:04:56.363: [iter 25 : loss : 0.2712 = 0.1700 + 0.0993 + 0.0019, time: 7.273021]
2023-05-15 17:04:56.516: epoch 25:	0.02087960  	0.15364358  	0.07867339  
2023-05-15 17:04:56.516: Find a better model.
2023-05-15 17:05:03.768: [iter 26 : loss : 0.2676 = 0.1667 + 0.0989 + 0.0019, time: 7.250986]
2023-05-15 17:05:03.923: epoch 26:	0.02107013  	0.15451245  	0.07931982  
2023-05-15 17:05:03.923: Find a better model.
2023-05-15 17:05:11.157: [iter 27 : loss : 0.2597 = 0.1593 + 0.0984 + 0.0020, time: 7.231035]
2023-05-15 17:05:11.310: epoch 27:	0.02127477  	0.15594383  	0.08007934  
2023-05-15 17:05:11.310: Find a better model.
2023-05-15 17:05:18.554: [iter 28 : loss : 0.2550 = 0.1549 + 0.0980 + 0.0021, time: 7.243342]
2023-05-15 17:05:18.706: epoch 28:	0.02140180  	0.15702844  	0.08065443  
2023-05-15 17:05:18.706: Find a better model.
2023-05-15 17:05:25.951: [iter 29 : loss : 0.2507 = 0.1509 + 0.0976 + 0.0021, time: 7.244543]
2023-05-15 17:05:26.095: epoch 29:	0.02149353  	0.15793069  	0.08115401  
2023-05-15 17:05:26.095: Find a better model.
2023-05-15 17:05:33.340: [iter 30 : loss : 0.2440 = 0.1445 + 0.0973 + 0.0022, time: 7.242700]
2023-05-15 17:05:33.492: epoch 30:	0.02167700  	0.15943797  	0.08214395  
2023-05-15 17:05:33.492: Find a better model.
2023-05-15 17:05:40.733: [iter 31 : loss : 0.2404 = 0.1412 + 0.0969 + 0.0023, time: 7.239501]
2023-05-15 17:05:40.874: epoch 31:	0.02189575  	0.16112071  	0.08291072  
2023-05-15 17:05:40.874: Find a better model.
2023-05-15 17:05:48.130: [iter 32 : loss : 0.2348 = 0.1359 + 0.0965 + 0.0023, time: 7.255003]
2023-05-15 17:05:48.284: epoch 32:	0.02207216  	0.16220409  	0.08369537  
2023-05-15 17:05:48.284: Find a better model.
2023-05-15 17:05:55.549: [iter 33 : loss : 0.2321 = 0.1336 + 0.0961 + 0.0024, time: 7.263672]
2023-05-15 17:05:55.704: epoch 33:	0.02224151  	0.16326058  	0.08417457  
2023-05-15 17:05:55.704: Find a better model.
2023-05-15 17:06:03.110: [iter 34 : loss : 0.2281 = 0.1299 + 0.0958 + 0.0024, time: 7.405406]
2023-05-15 17:06:03.263: epoch 34:	0.02245320  	0.16486257  	0.08527121  
2023-05-15 17:06:03.264: Find a better model.
2023-05-15 17:06:10.554: [iter 35 : loss : 0.2246 = 0.1267 + 0.0955 + 0.0025, time: 7.287553]
2023-05-15 17:06:10.708: epoch 35:	0.02258727  	0.16572963  	0.08575566  
2023-05-15 17:06:10.708: Find a better model.
2023-05-15 17:06:18.169: [iter 36 : loss : 0.2211 = 0.1234 + 0.0951 + 0.0025, time: 7.460022]
2023-05-15 17:06:18.320: epoch 36:	0.02275663  	0.16716665  	0.08643940  
2023-05-15 17:06:18.320: Find a better model.
2023-05-15 17:06:25.728: [iter 37 : loss : 0.2172 = 0.1198 + 0.0948 + 0.0026, time: 7.406103]
2023-05-15 17:06:25.879: epoch 37:	0.02289071  	0.16799736  	0.08694850  
2023-05-15 17:06:25.879: Find a better model.
2023-05-15 17:06:33.133: [iter 38 : loss : 0.2158 = 0.1186 + 0.0945 + 0.0027, time: 7.253565]
2023-05-15 17:06:33.285: epoch 38:	0.02298950  	0.16896895  	0.08769957  
2023-05-15 17:06:33.285: Find a better model.
2023-05-15 17:06:40.539: [iter 39 : loss : 0.2112 = 0.1143 + 0.0942 + 0.0027, time: 7.252617]
2023-05-15 17:06:40.695: epoch 39:	0.02329293  	0.17103320  	0.08872094  
2023-05-15 17:06:40.695: Find a better model.
2023-05-15 17:06:47.932: [iter 40 : loss : 0.2081 = 0.1114 + 0.0939 + 0.0028, time: 7.236288]
2023-05-15 17:06:48.090: epoch 40:	0.02339877  	0.17193393  	0.08924802  
2023-05-15 17:06:48.091: Find a better model.
2023-05-15 17:06:55.321: [iter 41 : loss : 0.2062 = 0.1097 + 0.0936 + 0.0028, time: 7.229085]
2023-05-15 17:06:55.474: epoch 41:	0.02340582  	0.17182486  	0.08959466  
2023-05-15 17:07:02.735: [iter 42 : loss : 0.2040 = 0.1078 + 0.0933 + 0.0029, time: 7.258650]
2023-05-15 17:07:02.886: epoch 42:	0.02353284  	0.17253019  	0.09035567  
2023-05-15 17:07:02.886: Find a better model.
2023-05-15 17:07:10.118: [iter 43 : loss : 0.2001 = 0.1041 + 0.0931 + 0.0029, time: 7.230615]
2023-05-15 17:07:10.271: epoch 43:	0.02371631  	0.17383069  	0.09108996  
2023-05-15 17:07:10.271: Find a better model.
2023-05-15 17:07:17.516: [iter 44 : loss : 0.1965 = 0.1008 + 0.0927 + 0.0030, time: 7.244203]
2023-05-15 17:07:17.659: epoch 44:	0.02371631  	0.17387852  	0.09137198  
2023-05-15 17:07:17.659: Find a better model.
2023-05-15 17:07:24.903: [iter 45 : loss : 0.1945 = 0.0990 + 0.0925 + 0.0030, time: 7.242877]
2023-05-15 17:07:25.056: epoch 45:	0.02385038  	0.17500514  	0.09206612  
2023-05-15 17:07:25.056: Find a better model.
2023-05-15 17:07:32.308: [iter 46 : loss : 0.1920 = 0.0966 + 0.0923 + 0.0031, time: 7.249360]
2023-05-15 17:07:32.460: epoch 46:	0.02387155  	0.17531897  	0.09247958  
2023-05-15 17:07:32.460: Find a better model.
2023-05-15 17:07:39.721: [iter 47 : loss : 0.1914 = 0.0963 + 0.0921 + 0.0031, time: 7.258917]
2023-05-15 17:07:39.874: epoch 47:	0.02399152  	0.17646232  	0.09303139  
2023-05-15 17:07:39.875: Find a better model.
2023-05-15 17:07:47.122: [iter 48 : loss : 0.1874 = 0.0924 + 0.0918 + 0.0032, time: 7.246746]
2023-05-15 17:07:47.278: epoch 48:	0.02401974  	0.17688647  	0.09342325  
2023-05-15 17:07:47.278: Find a better model.
2023-05-15 17:07:54.490: [iter 49 : loss : 0.1843 = 0.0895 + 0.0916 + 0.0032, time: 7.210506]
2023-05-15 17:07:54.631: epoch 49:	0.02406208  	0.17718385  	0.09368753  
2023-05-15 17:07:54.631: Find a better model.
2023-05-15 17:08:01.900: [iter 50 : loss : 0.1834 = 0.0888 + 0.0914 + 0.0033, time: 7.267667]
2023-05-15 17:08:02.040: epoch 50:	0.02418204  	0.17821953  	0.09416518  
2023-05-15 17:08:02.040: Find a better model.
2023-05-15 17:08:09.287: [iter 51 : loss : 0.1802 = 0.0858 + 0.0911 + 0.0033, time: 7.244516]
2023-05-15 17:08:09.428: epoch 51:	0.02418910  	0.17826077  	0.09444881  
2023-05-15 17:08:09.428: Find a better model.
2023-05-15 17:08:16.679: [iter 52 : loss : 0.1803 = 0.0859 + 0.0910 + 0.0034, time: 7.249691]
2023-05-15 17:08:16.821: epoch 52:	0.02438668  	0.17945614  	0.09520988  
2023-05-15 17:08:16.822: Find a better model.
2023-05-15 17:08:24.093: [iter 53 : loss : 0.1783 = 0.0842 + 0.0907 + 0.0034, time: 7.269711]
2023-05-15 17:08:24.246: epoch 53:	0.02454192  	0.18087852  	0.09590858  
2023-05-15 17:08:24.246: Find a better model.
2023-05-15 17:08:31.479: [iter 54 : loss : 0.1763 = 0.0822 + 0.0906 + 0.0035, time: 7.231532]
2023-05-15 17:08:31.636: epoch 54:	0.02461954  	0.18109614  	0.09629050  
2023-05-15 17:08:31.636: Find a better model.
2023-05-15 17:08:38.885: [iter 55 : loss : 0.1742 = 0.0803 + 0.0904 + 0.0035, time: 7.248298]
2023-05-15 17:08:39.039: epoch 55:	0.02463366  	0.18110996  	0.09643750  
2023-05-15 17:08:39.039: Find a better model.
2023-05-15 17:08:46.269: [iter 56 : loss : 0.1726 = 0.0789 + 0.0902 + 0.0035, time: 7.229003]
2023-05-15 17:08:46.424: epoch 56:	0.02476067  	0.18178287  	0.09696776  
2023-05-15 17:08:46.424: Find a better model.
2023-05-15 17:08:53.496: [iter 57 : loss : 0.1707 = 0.0771 + 0.0900 + 0.0036, time: 7.070520]
2023-05-15 17:08:53.649: epoch 57:	0.02475362  	0.18179412  	0.09725089  
2023-05-15 17:08:53.649: Find a better model.
2023-05-15 17:09:00.888: [iter 58 : loss : 0.1688 = 0.0753 + 0.0898 + 0.0036, time: 7.237998]
2023-05-15 17:09:01.036: epoch 58:	0.02472539  	0.18162961  	0.09739046  
2023-05-15 17:09:08.274: [iter 59 : loss : 0.1679 = 0.0746 + 0.0897 + 0.0037, time: 7.236250]
2023-05-15 17:09:08.426: epoch 59:	0.02478890  	0.18212704  	0.09778848  
2023-05-15 17:09:08.426: Find a better model.
2023-05-15 17:09:15.649: [iter 60 : loss : 0.1662 = 0.0730 + 0.0895 + 0.0037, time: 7.221511]
2023-05-15 17:09:15.804: epoch 60:	0.02485241  	0.18251032  	0.09818682  
2023-05-15 17:09:15.804: Find a better model.
2023-05-15 17:09:22.881: [iter 61 : loss : 0.1647 = 0.0716 + 0.0893 + 0.0038, time: 7.075601]
2023-05-15 17:09:23.023: epoch 61:	0.02490886  	0.18297754  	0.09854864  
2023-05-15 17:09:23.023: Find a better model.
2023-05-15 17:09:30.068: [iter 62 : loss : 0.1629 = 0.0699 + 0.0892 + 0.0038, time: 7.044158]
2023-05-15 17:09:30.210: epoch 62:	0.02494413  	0.18296620  	0.09880175  
2023-05-15 17:09:37.440: [iter 63 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 7.229079]
2023-05-15 17:09:37.588: epoch 63:	0.02502881  	0.18360350  	0.09906284  
2023-05-15 17:09:37.588: Find a better model.
2023-05-15 17:09:44.655: [iter 64 : loss : 0.1609 = 0.0681 + 0.0888 + 0.0039, time: 7.063820]
2023-05-15 17:09:44.808: epoch 64:	0.02501470  	0.18348590  	0.09931623  
2023-05-15 17:09:52.029: [iter 65 : loss : 0.1594 = 0.0668 + 0.0886 + 0.0040, time: 7.220280]
2023-05-15 17:09:52.186: epoch 65:	0.02509232  	0.18431167  	0.09994955  
2023-05-15 17:09:52.186: Find a better model.
2023-05-15 17:09:59.251: [iter 66 : loss : 0.1581 = 0.0656 + 0.0885 + 0.0040, time: 7.063694]
2023-05-15 17:09:59.394: epoch 66:	0.02515583  	0.18507273  	0.10036156  
2023-05-15 17:09:59.394: Find a better model.
2023-05-15 17:10:06.627: [iter 67 : loss : 0.1566 = 0.0641 + 0.0884 + 0.0040, time: 7.230981]
2023-05-15 17:10:06.781: epoch 67:	0.02511349  	0.18477824  	0.10037673  
2023-05-15 17:10:14.024: [iter 68 : loss : 0.1561 = 0.0638 + 0.0882 + 0.0041, time: 7.242213]
2023-05-15 17:10:14.178: epoch 68:	0.02513465  	0.18497428  	0.10066629  
2023-05-15 17:10:21.452: [iter 69 : loss : 0.1542 = 0.0620 + 0.0881 + 0.0041, time: 7.272977]
2023-05-15 17:10:21.607: epoch 69:	0.02508526  	0.18500504  	0.10066879  
2023-05-15 17:10:28.828: [iter 70 : loss : 0.1526 = 0.0604 + 0.0880 + 0.0042, time: 7.220114]
2023-05-15 17:10:28.979: epoch 70:	0.02518405  	0.18584028  	0.10107701  
2023-05-15 17:10:28.979: Find a better model.
2023-05-15 17:10:36.247: [iter 71 : loss : 0.1512 = 0.0591 + 0.0878 + 0.0042, time: 7.266186]
2023-05-15 17:10:36.405: epoch 71:	0.02521933  	0.18590041  	0.10128839  
2023-05-15 17:10:36.405: Find a better model.
2023-05-15 17:10:43.635: [iter 72 : loss : 0.1511 = 0.0591 + 0.0877 + 0.0042, time: 7.227830]
2023-05-15 17:10:43.789: epoch 72:	0.02526872  	0.18630753  	0.10158211  
2023-05-15 17:10:43.790: Find a better model.
2023-05-15 17:10:51.021: [iter 73 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 7.229780]
2023-05-15 17:10:51.163: epoch 73:	0.02533223  	0.18675007  	0.10185046  
2023-05-15 17:10:51.163: Find a better model.
2023-05-15 17:10:58.430: [iter 74 : loss : 0.1481 = 0.0562 + 0.0875 + 0.0043, time: 7.265043]
2023-05-15 17:10:58.573: epoch 74:	0.02541691  	0.18733184  	0.10213447  
2023-05-15 17:10:58.574: Find a better model.
2023-05-15 17:11:05.841: [iter 75 : loss : 0.1476 = 0.0558 + 0.0874 + 0.0044, time: 7.265777]
2023-05-15 17:11:05.995: epoch 75:	0.02545924  	0.18774432  	0.10246082  
2023-05-15 17:11:05.995: Find a better model.
2023-05-15 17:11:13.221: [iter 76 : loss : 0.1467 = 0.0550 + 0.0872 + 0.0044, time: 7.224139]
2023-05-15 17:11:13.377: epoch 76:	0.02554392  	0.18870828  	0.10268328  
2023-05-15 17:11:13.377: Find a better model.
2023-05-15 17:11:20.608: [iter 77 : loss : 0.1455 = 0.0539 + 0.0871 + 0.0045, time: 7.229820]
2023-05-15 17:11:20.762: epoch 77:	0.02567094  	0.18947721  	0.10306405  
2023-05-15 17:11:20.762: Find a better model.
2023-05-15 17:11:28.019: [iter 78 : loss : 0.1446 = 0.0531 + 0.0870 + 0.0045, time: 7.256677]
2023-05-15 17:11:28.173: epoch 78:	0.02574151  	0.19024953  	0.10327788  
2023-05-15 17:11:28.173: Find a better model.
2023-05-15 17:11:35.418: [iter 79 : loss : 0.1436 = 0.0522 + 0.0869 + 0.0045, time: 7.242308]
2023-05-15 17:11:35.560: epoch 79:	0.02575562  	0.19038124  	0.10336655  
2023-05-15 17:11:35.561: Find a better model.
2023-05-15 17:11:42.802: [iter 80 : loss : 0.1428 = 0.0514 + 0.0868 + 0.0046, time: 7.239518]
2023-05-15 17:11:42.958: epoch 80:	0.02584030  	0.19077583  	0.10355094  
2023-05-15 17:11:42.958: Find a better model.
2023-05-15 17:11:50.208: [iter 81 : loss : 0.1427 = 0.0514 + 0.0867 + 0.0046, time: 7.248243]
2023-05-15 17:11:50.362: epoch 81:	0.02580502  	0.19034427  	0.10351513  
2023-05-15 17:11:57.606: [iter 82 : loss : 0.1412 = 0.0499 + 0.0866 + 0.0046, time: 7.242887]
2023-05-15 17:11:57.758: epoch 82:	0.02584735  	0.19048244  	0.10378240  
2023-05-15 17:12:05.008: [iter 83 : loss : 0.1401 = 0.0489 + 0.0865 + 0.0047, time: 7.249118]
2023-05-15 17:12:05.161: epoch 83:	0.02591086  	0.19069920  	0.10412522  
2023-05-15 17:12:12.378: [iter 84 : loss : 0.1400 = 0.0488 + 0.0864 + 0.0047, time: 7.216100]
2023-05-15 17:12:12.520: epoch 84:	0.02596026  	0.19095713  	0.10445667  
2023-05-15 17:12:12.520: Find a better model.
2023-05-15 17:12:19.781: [iter 85 : loss : 0.1392 = 0.0482 + 0.0863 + 0.0048, time: 7.260396]
2023-05-15 17:12:19.933: epoch 85:	0.02593908  	0.19064865  	0.10449395  
2023-05-15 17:12:27.207: [iter 86 : loss : 0.1390 = 0.0480 + 0.0862 + 0.0048, time: 7.273441]
2023-05-15 17:12:27.362: epoch 86:	0.02603082  	0.19140136  	0.10483826  
2023-05-15 17:12:27.362: Find a better model.
2023-05-15 17:12:34.600: [iter 87 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0048, time: 7.235379]
2023-05-15 17:12:34.752: epoch 87:	0.02604494  	0.19149265  	0.10492673  
2023-05-15 17:12:34.752: Find a better model.
2023-05-15 17:12:41.990: [iter 88 : loss : 0.1357 = 0.0449 + 0.0860 + 0.0049, time: 7.236483]
2023-05-15 17:12:42.143: epoch 88:	0.02607316  	0.19190988  	0.10507239  
2023-05-15 17:12:42.143: Find a better model.
2023-05-15 17:12:49.392: [iter 89 : loss : 0.1354 = 0.0445 + 0.0859 + 0.0049, time: 7.247150]
2023-05-15 17:12:49.547: epoch 89:	0.02610844  	0.19197764  	0.10523647  
2023-05-15 17:12:49.547: Find a better model.
2023-05-15 17:12:56.795: [iter 90 : loss : 0.1358 = 0.0450 + 0.0858 + 0.0050, time: 7.246281]
2023-05-15 17:12:56.948: epoch 90:	0.02615784  	0.19242622  	0.10544139  
2023-05-15 17:12:56.948: Find a better model.
2023-05-15 17:13:04.185: [iter 91 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0050, time: 7.235937]
2023-05-15 17:13:04.327: epoch 91:	0.02622840  	0.19275182  	0.10546321  
2023-05-15 17:13:04.327: Find a better model.
2023-05-15 17:13:11.590: [iter 92 : loss : 0.1338 = 0.0431 + 0.0857 + 0.0050, time: 7.260751]
2023-05-15 17:13:11.744: epoch 92:	0.02622135  	0.19321993  	0.10573786  
2023-05-15 17:13:11.745: Find a better model.
2023-05-15 17:13:19.001: [iter 93 : loss : 0.1337 = 0.0431 + 0.0856 + 0.0051, time: 7.254972]
2023-05-15 17:13:19.153: epoch 93:	0.02634131  	0.19401351  	0.10606376  
2023-05-15 17:13:19.153: Find a better model.
2023-05-15 17:13:26.378: [iter 94 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.224538]
2023-05-15 17:13:26.531: epoch 94:	0.02626369  	0.19373319  	0.10610503  
2023-05-15 17:13:33.763: [iter 95 : loss : 0.1313 = 0.0407 + 0.0854 + 0.0051, time: 7.231378]
2023-05-15 17:13:33.918: epoch 95:	0.02632014  	0.19418690  	0.10625926  
2023-05-15 17:13:33.918: Find a better model.
2023-05-15 17:13:41.160: [iter 96 : loss : 0.1311 = 0.0406 + 0.0853 + 0.0052, time: 7.240322]
2023-05-15 17:13:41.303: epoch 96:	0.02634130  	0.19408129  	0.10624935  
2023-05-15 17:13:48.394: [iter 97 : loss : 0.1294 = 0.0389 + 0.0853 + 0.0052, time: 7.090259]
2023-05-15 17:13:48.549: epoch 97:	0.02634836  	0.19412334  	0.10633899  
2023-05-15 17:13:55.778: [iter 98 : loss : 0.1304 = 0.0399 + 0.0852 + 0.0052, time: 7.226150]
2023-05-15 17:13:55.929: epoch 98:	0.02636953  	0.19420287  	0.10658949  
2023-05-15 17:13:55.930: Find a better model.
2023-05-15 17:14:03.172: [iter 99 : loss : 0.1294 = 0.0389 + 0.0851 + 0.0053, time: 7.240809]
2023-05-15 17:14:03.323: epoch 99:	0.02628485  	0.19363537  	0.10636204  
2023-05-15 17:14:10.574: [iter 100 : loss : 0.1287 = 0.0382 + 0.0851 + 0.0053, time: 7.249442]
2023-05-15 17:14:10.728: epoch 100:	0.02635542  	0.19412012  	0.10664082  
2023-05-15 17:14:17.967: [iter 101 : loss : 0.1283 = 0.0379 + 0.0850 + 0.0054, time: 7.235895]
2023-05-15 17:14:18.118: epoch 101:	0.02637659  	0.19414996  	0.10683231  
2023-05-15 17:14:25.361: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 7.241949]
2023-05-15 17:14:25.515: epoch 102:	0.02639776  	0.19449104  	0.10675941  
2023-05-15 17:14:25.515: Find a better model.
2023-05-15 17:14:32.749: [iter 103 : loss : 0.1269 = 0.0366 + 0.0849 + 0.0054, time: 7.232223]
2023-05-15 17:14:32.905: epoch 103:	0.02644716  	0.19468585  	0.10682262  
2023-05-15 17:14:32.905: Find a better model.
2023-05-15 17:14:40.145: [iter 104 : loss : 0.1275 = 0.0372 + 0.0848 + 0.0055, time: 7.237873]
2023-05-15 17:14:40.300: epoch 104:	0.02639776  	0.19424209  	0.10684108  
2023-05-15 17:14:47.565: [iter 105 : loss : 0.1267 = 0.0365 + 0.0847 + 0.0055, time: 7.264351]
2023-05-15 17:14:47.715: epoch 105:	0.02642599  	0.19457708  	0.10696810  
2023-05-15 17:14:54.764: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 7.046500]
2023-05-15 17:14:54.916: epoch 106:	0.02641187  	0.19417489  	0.10691962  
2023-05-15 17:15:02.150: [iter 107 : loss : 0.1254 = 0.0352 + 0.0846 + 0.0056, time: 7.233510]
2023-05-15 17:15:02.291: epoch 107:	0.02638364  	0.19435750  	0.10686446  
2023-05-15 17:15:09.526: [iter 108 : loss : 0.1252 = 0.0351 + 0.0845 + 0.0056, time: 7.233557]
2023-05-15 17:15:09.685: epoch 108:	0.02636247  	0.19419305  	0.10692604  
2023-05-15 17:15:16.927: [iter 109 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0056, time: 7.241484]
2023-05-15 17:15:17.080: epoch 109:	0.02636248  	0.19415967  	0.10695101  
2023-05-15 17:15:24.356: [iter 110 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.275682]
2023-05-15 17:15:24.505: epoch 110:	0.02637658  	0.19422723  	0.10697042  
2023-05-15 17:15:31.745: [iter 111 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.236662]
2023-05-15 17:15:31.899: epoch 111:	0.02641187  	0.19448160  	0.10706954  
2023-05-15 17:15:39.137: [iter 112 : loss : 0.1232 = 0.0331 + 0.0843 + 0.0057, time: 7.235727]
2023-05-15 17:15:39.277: epoch 112:	0.02641893  	0.19461979  	0.10721119  
2023-05-15 17:15:46.510: [iter 113 : loss : 0.1230 = 0.0330 + 0.0842 + 0.0058, time: 7.232381]
2023-05-15 17:15:46.661: epoch 113:	0.02643304  	0.19476406  	0.10726818  
2023-05-15 17:15:46.661: Find a better model.
2023-05-15 17:15:53.932: [iter 114 : loss : 0.1220 = 0.0321 + 0.0842 + 0.0058, time: 7.269911]
2023-05-15 17:15:54.085: epoch 114:	0.02646126  	0.19482835  	0.10751420  
2023-05-15 17:15:54.085: Find a better model.
2023-05-15 17:16:01.337: [iter 115 : loss : 0.1217 = 0.0318 + 0.0841 + 0.0058, time: 7.250666]
2023-05-15 17:16:01.492: epoch 115:	0.02644009  	0.19467168  	0.10738337  
2023-05-15 17:16:08.718: [iter 116 : loss : 0.1207 = 0.0308 + 0.0841 + 0.0059, time: 7.225315]
2023-05-15 17:16:08.870: epoch 116:	0.02645420  	0.19451798  	0.10745259  
2023-05-15 17:16:16.120: [iter 117 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.249698]
2023-05-15 17:16:16.273: epoch 117:	0.02641892  	0.19455311  	0.10759346  
2023-05-15 17:16:23.531: [iter 118 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.256393]
2023-05-15 17:16:23.685: epoch 118:	0.02644715  	0.19474009  	0.10764159  
2023-05-15 17:16:30.936: [iter 119 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 7.250012]
2023-05-15 17:16:31.088: epoch 119:	0.02644009  	0.19422139  	0.10754243  
2023-05-15 17:16:38.324: [iter 120 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 7.234401]
2023-05-15 17:16:38.476: epoch 120:	0.02635542  	0.19382308  	0.10746473  
2023-05-15 17:16:45.722: [iter 121 : loss : 0.1197 = 0.0298 + 0.0838 + 0.0060, time: 7.243218]
2023-05-15 17:16:45.873: epoch 121:	0.02632719  	0.19382250  	0.10750333  
2023-05-15 17:16:53.107: [iter 122 : loss : 0.1190 = 0.0292 + 0.0838 + 0.0061, time: 7.233435]
2023-05-15 17:16:53.257: epoch 122:	0.02631307  	0.19342986  	0.10737257  
2023-05-15 17:17:00.513: [iter 123 : loss : 0.1191 = 0.0292 + 0.0837 + 0.0061, time: 7.254235]
2023-05-15 17:17:00.667: epoch 123:	0.02629896  	0.19353573  	0.10741863  
2023-05-15 17:17:07.910: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 7.241457]
2023-05-15 17:17:08.064: epoch 124:	0.02632719  	0.19380277  	0.10748455  
2023-05-15 17:17:15.321: [iter 125 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0061, time: 7.256505]
2023-05-15 17:17:15.471: epoch 125:	0.02639776  	0.19423468  	0.10757470  
2023-05-15 17:17:22.890: [iter 126 : loss : 0.1177 = 0.0279 + 0.0836 + 0.0062, time: 7.417699]
2023-05-15 17:17:23.041: epoch 126:	0.02631308  	0.19365287  	0.10750188  
2023-05-15 17:17:30.310: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 7.268495]
2023-05-15 17:17:30.450: epoch 127:	0.02628485  	0.19307771  	0.10754193  
2023-05-15 17:17:37.711: [iter 128 : loss : 0.1177 = 0.0279 + 0.0835 + 0.0062, time: 7.258048]
2023-05-15 17:17:37.864: epoch 128:	0.02630601  	0.19319265  	0.10762456  
2023-05-15 17:17:45.112: [iter 129 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0063, time: 7.247684]
2023-05-15 17:17:45.263: epoch 129:	0.02633424  	0.19374287  	0.10772402  
2023-05-15 17:17:52.500: [iter 130 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.235161]
2023-05-15 17:17:52.643: epoch 130:	0.02641186  	0.19415715  	0.10792719  
2023-05-15 17:17:59.900: [iter 131 : loss : 0.1161 = 0.0264 + 0.0834 + 0.0063, time: 7.254977]
2023-05-15 17:18:00.057: epoch 131:	0.02644714  	0.19423352  	0.10801989  
2023-05-15 17:18:07.460: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0064, time: 7.402411]
2023-05-15 17:18:07.613: epoch 132:	0.02646126  	0.19394559  	0.10794809  
2023-05-15 17:18:14.891: [iter 133 : loss : 0.1150 = 0.0253 + 0.0833 + 0.0064, time: 7.277143]
2023-05-15 17:18:15.044: epoch 133:	0.02644714  	0.19368504  	0.10788616  
2023-05-15 17:18:22.461: [iter 134 : loss : 0.1156 = 0.0259 + 0.0832 + 0.0064, time: 7.415764]
2023-05-15 17:18:22.615: epoch 134:	0.02639776  	0.19327529  	0.10792027  
2023-05-15 17:18:29.881: [iter 135 : loss : 0.1154 = 0.0257 + 0.0832 + 0.0064, time: 7.263585]
2023-05-15 17:18:30.037: epoch 135:	0.02643304  	0.19360541  	0.10806186  
2023-05-15 17:18:37.460: [iter 136 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0065, time: 7.421742]
2023-05-15 17:18:37.614: epoch 136:	0.02640481  	0.19332547  	0.10807581  
2023-05-15 17:18:44.890: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 7.274721]
2023-05-15 17:18:45.044: epoch 137:	0.02644714  	0.19392061  	0.10821996  
2023-05-15 17:18:52.461: [iter 138 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 7.415009]
2023-05-15 17:18:52.616: epoch 138:	0.02650359  	0.19411202  	0.10825864  
2023-05-15 17:18:59.882: [iter 139 : loss : 0.1140 = 0.0244 + 0.0830 + 0.0066, time: 7.265206]
2023-05-15 17:19:00.040: epoch 139:	0.02648948  	0.19405194  	0.10840675  
2023-05-15 17:19:00.040: Early stopping is trigger at epoch: 139
2023-05-15 17:19:00.040: best_result@epoch 114:

2023-05-15 17:19:00.040: 		0.0265      	0.1948      	0.1075      
2023-05-15 17:22:52.895: my pid: 12240
2023-05-15 17:22:52.895: model: model.general_recommender.SGL
2023-05-15 17:22:52.895: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 17:22:52.895: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 17:22:56.104: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 17:23:04.231: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.126918]
2023-05-15 17:23:04.376: epoch 1:	0.00134067  	0.00983448  	0.00488910  
2023-05-15 17:23:04.376: Find a better model.
2023-05-15 17:23:12.685: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.307095]
2023-05-15 17:23:12.889: epoch 2:	0.00282247  	0.02075245  	0.01049519  
2023-05-15 17:23:12.889: Find a better model.
2023-05-15 17:23:21.047: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.156910]
2023-05-15 17:23:21.226: epoch 3:	0.00520742  	0.03731384  	0.01817366  
2023-05-15 17:23:21.226: Find a better model.
2023-05-15 17:23:29.420: [iter 4 : loss : 0.7706 = 0.6920 + 0.0787 + 0.0000, time: 8.193082]
2023-05-15 17:23:29.587: epoch 4:	0.00842499  	0.06207108  	0.02898813  
2023-05-15 17:23:29.587: Find a better model.
2023-05-15 17:23:37.586: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 7.996275]
2023-05-15 17:23:37.750: epoch 5:	0.01202376  	0.08813731  	0.04230292  
2023-05-15 17:23:37.750: Find a better model.
2023-05-15 17:23:45.604: [iter 6 : loss : 0.7672 = 0.6879 + 0.0792 + 0.0000, time: 7.852897]
2023-05-15 17:23:45.765: epoch 6:	0.01534028  	0.11189225  	0.05482558  
2023-05-15 17:23:45.765: Find a better model.
2023-05-15 17:23:53.436: [iter 7 : loss : 0.7606 = 0.6805 + 0.0800 + 0.0000, time: 7.669532]
2023-05-15 17:23:53.579: epoch 7:	0.01821225  	0.13296524  	0.06528582  
2023-05-15 17:23:53.579: Find a better model.
2023-05-15 17:24:01.169: [iter 8 : loss : 0.7445 = 0.6624 + 0.0820 + 0.0001, time: 7.586706]
2023-05-15 17:24:01.326: epoch 8:	0.01912252  	0.14066982  	0.06970572  
2023-05-15 17:24:01.326: Find a better model.
2023-05-15 17:24:08.963: [iter 9 : loss : 0.7082 = 0.6222 + 0.0859 + 0.0001, time: 7.634779]
2023-05-15 17:24:09.122: epoch 9:	0.01897435  	0.13955538  	0.06944226  
2023-05-15 17:24:16.800: [iter 10 : loss : 0.6466 = 0.5550 + 0.0913 + 0.0003, time: 7.677649]
2023-05-15 17:24:16.958: epoch 10:	0.01862152  	0.13721173  	0.06816681  
2023-05-15 17:24:24.390: [iter 11 : loss : 0.5711 = 0.4744 + 0.0963 + 0.0004, time: 7.430449]
2023-05-15 17:24:24.546: epoch 11:	0.01854389  	0.13719752  	0.06838106  
2023-05-15 17:24:31.984: [iter 12 : loss : 0.5029 = 0.4028 + 0.0996 + 0.0006, time: 7.435730]
2023-05-15 17:24:32.141: epoch 12:	0.01857211  	0.13722146  	0.06859354  
2023-05-15 17:24:39.567: [iter 13 : loss : 0.4528 = 0.3507 + 0.1014 + 0.0007, time: 7.424510]
2023-05-15 17:24:39.722: epoch 13:	0.01856506  	0.13738257  	0.06900448  
2023-05-15 17:24:47.206: [iter 14 : loss : 0.4148 = 0.3117 + 0.1023 + 0.0008, time: 7.482843]
2023-05-15 17:24:47.365: epoch 14:	0.01868502  	0.13803944  	0.06944497  
2023-05-15 17:24:54.782: [iter 15 : loss : 0.3883 = 0.2847 + 0.1026 + 0.0010, time: 7.414955]
2023-05-15 17:24:54.938: epoch 15:	0.01888966  	0.14017686  	0.07056727  
2023-05-15 17:25:02.360: [iter 16 : loss : 0.3659 = 0.2623 + 0.1025 + 0.0011, time: 7.420563]
2023-05-15 17:25:02.516: epoch 16:	0.01905196  	0.14113779  	0.07121441  
2023-05-15 17:25:02.516: Find a better model.
2023-05-15 17:25:09.977: [iter 17 : loss : 0.3496 = 0.2460 + 0.1024 + 0.0012, time: 7.459099]
2023-05-15 17:25:10.121: epoch 17:	0.01923544  	0.14207956  	0.07190932  
2023-05-15 17:25:10.121: Find a better model.
2023-05-15 17:25:17.568: [iter 18 : loss : 0.3343 = 0.2309 + 0.1021 + 0.0013, time: 7.445341]
2023-05-15 17:25:17.712: epoch 18:	0.01948948  	0.14380604  	0.07283428  
2023-05-15 17:25:17.712: Find a better model.
2023-05-15 17:25:25.169: [iter 19 : loss : 0.3201 = 0.2169 + 0.1018 + 0.0014, time: 7.455184]
2023-05-15 17:25:25.326: epoch 19:	0.01967295  	0.14534223  	0.07375004  
2023-05-15 17:25:25.326: Find a better model.
2023-05-15 17:25:32.987: [iter 20 : loss : 0.3106 = 0.2077 + 0.1014 + 0.0015, time: 7.660278]
2023-05-15 17:25:33.141: epoch 20:	0.01991287  	0.14684927  	0.07458726  
2023-05-15 17:25:33.141: Find a better model.
2023-05-15 17:25:40.758: [iter 21 : loss : 0.3006 = 0.1981 + 0.1010 + 0.0016, time: 7.615825]
2023-05-15 17:25:40.920: epoch 21:	0.02009634  	0.14779313  	0.07522003  
2023-05-15 17:25:40.920: Find a better model.
2023-05-15 17:25:48.573: [iter 22 : loss : 0.2925 = 0.1903 + 0.1006 + 0.0017, time: 7.652071]
2023-05-15 17:25:48.729: epoch 22:	0.02023747  	0.14955264  	0.07593209  
2023-05-15 17:25:48.729: Find a better model.
2023-05-15 17:25:56.165: [iter 23 : loss : 0.2842 = 0.1822 + 0.1002 + 0.0017, time: 7.434996]
2023-05-15 17:25:56.322: epoch 23:	0.02042800  	0.15113446  	0.07678125  
2023-05-15 17:25:56.322: Find a better model.
2023-05-15 17:26:03.930: [iter 24 : loss : 0.2778 = 0.1763 + 0.0997 + 0.0018, time: 7.605182]
2023-05-15 17:26:04.084: epoch 24:	0.02066086  	0.15271628  	0.07752987  
2023-05-15 17:26:04.084: Find a better model.
2023-05-15 17:26:11.516: [iter 25 : loss : 0.2709 = 0.1698 + 0.0992 + 0.0019, time: 7.430950]
2023-05-15 17:26:11.660: epoch 25:	0.02093606  	0.15450896  	0.07847588  
2023-05-15 17:26:11.660: Find a better model.
2023-05-15 17:26:19.134: [iter 26 : loss : 0.2676 = 0.1668 + 0.0989 + 0.0019, time: 7.472124]
2023-05-15 17:26:19.289: epoch 26:	0.02114775  	0.15590501  	0.07915839  
2023-05-15 17:26:19.289: Find a better model.
2023-05-15 17:26:26.771: [iter 27 : loss : 0.2596 = 0.1592 + 0.0984 + 0.0020, time: 7.480705]
2023-05-15 17:26:26.924: epoch 27:	0.02125360  	0.15647104  	0.07981167  
2023-05-15 17:26:26.924: Find a better model.
2023-05-15 17:26:34.317: [iter 28 : loss : 0.2549 = 0.1548 + 0.0980 + 0.0021, time: 7.392410]
2023-05-15 17:26:34.472: epoch 28:	0.02132416  	0.15688911  	0.08040111  
2023-05-15 17:26:34.473: Find a better model.
2023-05-15 17:26:41.923: [iter 29 : loss : 0.2502 = 0.1504 + 0.0976 + 0.0021, time: 7.448698]
2023-05-15 17:26:42.076: epoch 29:	0.02158526  	0.15849745  	0.08120827  
2023-05-15 17:26:42.077: Find a better model.
2023-05-15 17:26:49.570: [iter 30 : loss : 0.2437 = 0.1442 + 0.0972 + 0.0022, time: 7.491939]
2023-05-15 17:26:49.721: epoch 30:	0.02174051  	0.15961529  	0.08189166  
2023-05-15 17:26:49.721: Find a better model.
2023-05-15 17:26:57.125: [iter 31 : loss : 0.2401 = 0.1410 + 0.0968 + 0.0023, time: 7.403038]
2023-05-15 17:26:57.279: epoch 31:	0.02202277  	0.16193762  	0.08291456  
2023-05-15 17:26:57.279: Find a better model.
2023-05-15 17:27:04.889: [iter 32 : loss : 0.2345 = 0.1357 + 0.0965 + 0.0023, time: 7.608933]
2023-05-15 17:27:05.046: epoch 32:	0.02212862  	0.16304697  	0.08366401  
2023-05-15 17:27:05.046: Find a better model.
2023-05-15 17:27:12.505: [iter 33 : loss : 0.2317 = 0.1333 + 0.0961 + 0.0024, time: 7.458023]
2023-05-15 17:27:12.659: epoch 33:	0.02223447  	0.16385397  	0.08432119  
2023-05-15 17:27:12.660: Find a better model.
2023-05-15 17:27:20.139: [iter 34 : loss : 0.2278 = 0.1297 + 0.0957 + 0.0024, time: 7.478042]
2023-05-15 17:27:20.293: epoch 34:	0.02236853  	0.16451956  	0.08495199  
2023-05-15 17:27:20.293: Find a better model.
2023-05-15 17:27:27.716: [iter 35 : loss : 0.2242 = 0.1262 + 0.0954 + 0.0025, time: 7.421988]
2023-05-15 17:27:27.859: epoch 35:	0.02253788  	0.16616085  	0.08565379  
2023-05-15 17:27:27.859: Find a better model.
2023-05-15 17:27:35.293: [iter 36 : loss : 0.2209 = 0.1233 + 0.0951 + 0.0025, time: 7.433524]
2023-05-15 17:27:35.448: epoch 36:	0.02269313  	0.16741429  	0.08637484  
2023-05-15 17:27:35.448: Find a better model.
2023-05-15 17:27:42.901: [iter 37 : loss : 0.2171 = 0.1197 + 0.0948 + 0.0026, time: 7.451130]
2023-05-15 17:27:43.056: epoch 37:	0.02261550  	0.16669635  	0.08647141  
2023-05-15 17:27:50.504: [iter 38 : loss : 0.2154 = 0.1183 + 0.0945 + 0.0027, time: 7.445766]
2023-05-15 17:27:50.658: epoch 38:	0.02285543  	0.16869234  	0.08752900  
2023-05-15 17:27:50.658: Find a better model.
2023-05-15 17:27:58.097: [iter 39 : loss : 0.2109 = 0.1141 + 0.0942 + 0.0027, time: 7.437924]
2023-05-15 17:27:58.251: epoch 39:	0.02300361  	0.16973859  	0.08817970  
2023-05-15 17:27:58.251: Find a better model.
2023-05-15 17:28:05.708: [iter 40 : loss : 0.2076 = 0.1110 + 0.0939 + 0.0028, time: 7.456065]
2023-05-15 17:28:05.861: epoch 40:	0.02308829  	0.17044902  	0.08854545  
2023-05-15 17:28:05.862: Find a better model.
2023-05-15 17:28:13.295: [iter 41 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 7.431350]
2023-05-15 17:28:13.446: epoch 41:	0.02321531  	0.17127222  	0.08932795  
2023-05-15 17:28:13.446: Find a better model.
2023-05-15 17:28:20.929: [iter 42 : loss : 0.2037 = 0.1075 + 0.0933 + 0.0029, time: 7.479394]
2023-05-15 17:28:21.086: epoch 42:	0.02321531  	0.17136782  	0.08969235  
2023-05-15 17:28:21.086: Find a better model.
2023-05-15 17:28:28.463: [iter 43 : loss : 0.1998 = 0.1038 + 0.0930 + 0.0029, time: 7.375473]
2023-05-15 17:28:28.619: epoch 43:	0.02333527  	0.17229772  	0.09016757  
2023-05-15 17:28:28.619: Find a better model.
2023-05-15 17:28:36.056: [iter 44 : loss : 0.1963 = 0.1006 + 0.0927 + 0.0030, time: 7.434989]
2023-05-15 17:28:36.211: epoch 44:	0.02346934  	0.17320609  	0.09081475  
2023-05-15 17:28:36.211: Find a better model.
2023-05-15 17:28:43.651: [iter 45 : loss : 0.1943 = 0.0987 + 0.0926 + 0.0030, time: 7.438209]
2023-05-15 17:28:43.805: epoch 45:	0.02344816  	0.17299975  	0.09117625  
2023-05-15 17:28:51.268: [iter 46 : loss : 0.1917 = 0.0963 + 0.0923 + 0.0031, time: 7.462129]
2023-05-15 17:28:51.423: epoch 46:	0.02361752  	0.17429687  	0.09168870  
2023-05-15 17:28:51.423: Find a better model.
2023-05-15 17:28:58.854: [iter 47 : loss : 0.1909 = 0.0958 + 0.0920 + 0.0031, time: 7.429791]
2023-05-15 17:28:59.006: epoch 47:	0.02382216  	0.17589517  	0.09267326  
2023-05-15 17:28:59.006: Find a better model.
2023-05-15 17:29:06.475: [iter 48 : loss : 0.1871 = 0.0922 + 0.0918 + 0.0032, time: 7.467274]
2023-05-15 17:29:06.627: epoch 48:	0.02383627  	0.17586036  	0.09299155  
2023-05-15 17:29:14.081: [iter 49 : loss : 0.1840 = 0.0892 + 0.0915 + 0.0032, time: 7.453064]
2023-05-15 17:29:14.237: epoch 49:	0.02393506  	0.17679442  	0.09357370  
2023-05-15 17:29:14.237: Find a better model.
2023-05-15 17:29:21.674: [iter 50 : loss : 0.1831 = 0.0885 + 0.0913 + 0.0033, time: 7.435931]
2023-05-15 17:29:21.833: epoch 50:	0.02408324  	0.17770919  	0.09427769  
2023-05-15 17:29:21.833: Find a better model.
2023-05-15 17:29:29.276: [iter 51 : loss : 0.1800 = 0.0855 + 0.0911 + 0.0033, time: 7.442417]
2023-05-15 17:29:29.431: epoch 51:	0.02404090  	0.17761250  	0.09447675  
2023-05-15 17:29:36.673: [iter 52 : loss : 0.1801 = 0.0858 + 0.0909 + 0.0034, time: 7.240106]
2023-05-15 17:29:36.826: epoch 52:	0.02415380  	0.17897540  	0.09509447  
2023-05-15 17:29:36.827: Find a better model.
2023-05-15 17:29:44.252: [iter 53 : loss : 0.1781 = 0.0840 + 0.0907 + 0.0034, time: 7.424039]
2023-05-15 17:29:44.405: epoch 53:	0.02420320  	0.17930640  	0.09552300  
2023-05-15 17:29:44.405: Find a better model.
2023-05-15 17:29:51.865: [iter 54 : loss : 0.1759 = 0.0819 + 0.0905 + 0.0035, time: 7.458894]
2023-05-15 17:29:52.005: epoch 54:	0.02432316  	0.18017256  	0.09591658  
2023-05-15 17:29:52.005: Find a better model.
2023-05-15 17:29:59.444: [iter 55 : loss : 0.1741 = 0.0802 + 0.0904 + 0.0035, time: 7.437207]
2023-05-15 17:29:59.599: epoch 55:	0.02442902  	0.18100059  	0.09628598  
2023-05-15 17:29:59.599: Find a better model.
2023-05-15 17:30:07.028: [iter 56 : loss : 0.1721 = 0.0784 + 0.0902 + 0.0036, time: 7.426999]
2023-05-15 17:30:07.172: epoch 56:	0.02452780  	0.18209587  	0.09686650  
2023-05-15 17:30:07.172: Find a better model.
2023-05-15 17:30:14.447: [iter 57 : loss : 0.1703 = 0.0766 + 0.0900 + 0.0036, time: 7.274641]
2023-05-15 17:30:14.601: epoch 57:	0.02459131  	0.18261591  	0.09714010  
2023-05-15 17:30:14.601: Find a better model.
2023-05-15 17:30:22.054: [iter 58 : loss : 0.1686 = 0.0751 + 0.0898 + 0.0036, time: 7.450881]
2023-05-15 17:30:22.208: epoch 58:	0.02459131  	0.18255560  	0.09749648  
2023-05-15 17:30:29.640: [iter 59 : loss : 0.1675 = 0.0742 + 0.0896 + 0.0037, time: 7.430559]
2023-05-15 17:30:29.782: epoch 59:	0.02465481  	0.18291824  	0.09801503  
2023-05-15 17:30:29.782: Find a better model.
2023-05-15 17:30:37.242: [iter 60 : loss : 0.1659 = 0.0728 + 0.0894 + 0.0037, time: 7.459089]
2023-05-15 17:30:37.397: epoch 60:	0.02471832  	0.18335824  	0.09818950  
2023-05-15 17:30:37.397: Find a better model.
2023-05-15 17:30:44.832: [iter 61 : loss : 0.1646 = 0.0715 + 0.0892 + 0.0038, time: 7.433836]
2023-05-15 17:30:44.988: epoch 61:	0.02480301  	0.18423042  	0.09858857  
2023-05-15 17:30:44.988: Find a better model.
2023-05-15 17:30:52.267: [iter 62 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0038, time: 7.277236]
2023-05-15 17:30:52.423: epoch 62:	0.02483123  	0.18445733  	0.09892899  
2023-05-15 17:30:52.423: Find a better model.
2023-05-15 17:30:59.828: [iter 63 : loss : 0.1616 = 0.0688 + 0.0889 + 0.0039, time: 7.402789]
2023-05-15 17:30:59.968: epoch 63:	0.02493708  	0.18520078  	0.09932711  
2023-05-15 17:30:59.968: Find a better model.
2023-05-15 17:31:07.241: [iter 64 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 7.271108]
2023-05-15 17:31:07.400: epoch 64:	0.02495825  	0.18526624  	0.09953072  
2023-05-15 17:31:07.400: Find a better model.
2023-05-15 17:31:14.819: [iter 65 : loss : 0.1593 = 0.0667 + 0.0886 + 0.0040, time: 7.417005]
2023-05-15 17:31:14.975: epoch 65:	0.02504998  	0.18612522  	0.09989630  
2023-05-15 17:31:14.975: Find a better model.
2023-05-15 17:31:22.256: [iter 66 : loss : 0.1582 = 0.0657 + 0.0885 + 0.0040, time: 7.278942]
2023-05-15 17:31:22.410: epoch 66:	0.02509937  	0.18609025  	0.10016151  
2023-05-15 17:31:29.826: [iter 67 : loss : 0.1563 = 0.0640 + 0.0883 + 0.0040, time: 7.414936]
2023-05-15 17:31:29.980: epoch 67:	0.02513466  	0.18665648  	0.10049561  
2023-05-15 17:31:29.980: Find a better model.
2023-05-15 17:31:37.222: [iter 68 : loss : 0.1559 = 0.0636 + 0.0882 + 0.0041, time: 7.240010]
2023-05-15 17:31:37.380: epoch 68:	0.02521933  	0.18727878  	0.10094836  
2023-05-15 17:31:37.380: Find a better model.
2023-05-15 17:31:44.794: [iter 69 : loss : 0.1540 = 0.0618 + 0.0880 + 0.0041, time: 7.412536]
2023-05-15 17:31:44.937: epoch 69:	0.02526872  	0.18755738  	0.10098867  
2023-05-15 17:31:44.937: Find a better model.
2023-05-15 17:31:52.445: [iter 70 : loss : 0.1522 = 0.0601 + 0.0879 + 0.0042, time: 7.505966]
2023-05-15 17:31:52.597: epoch 70:	0.02533930  	0.18810178  	0.10144361  
2023-05-15 17:31:52.597: Find a better model.
2023-05-15 17:32:00.013: [iter 71 : loss : 0.1510 = 0.0590 + 0.0878 + 0.0042, time: 7.414434]
2023-05-15 17:32:00.168: epoch 71:	0.02539575  	0.18841986  	0.10147309  
2023-05-15 17:32:00.168: Find a better model.
2023-05-15 17:32:07.617: [iter 72 : loss : 0.1508 = 0.0589 + 0.0877 + 0.0043, time: 7.447406]
2023-05-15 17:32:07.772: epoch 72:	0.02547337  	0.18867399  	0.10156232  
2023-05-15 17:32:07.773: Find a better model.
2023-05-15 17:32:15.197: [iter 73 : loss : 0.1493 = 0.0574 + 0.0876 + 0.0043, time: 7.423270]
2023-05-15 17:32:15.339: epoch 73:	0.02548749  	0.18862566  	0.10163213  
2023-05-15 17:32:22.818: [iter 74 : loss : 0.1482 = 0.0564 + 0.0875 + 0.0043, time: 7.476654]
2023-05-15 17:32:22.973: epoch 74:	0.02554394  	0.18905978  	0.10206253  
2023-05-15 17:32:22.973: Find a better model.
2023-05-15 17:32:30.427: [iter 75 : loss : 0.1475 = 0.0558 + 0.0873 + 0.0044, time: 7.453443]
2023-05-15 17:32:30.582: epoch 75:	0.02550866  	0.18866564  	0.10201936  
2023-05-15 17:32:38.024: [iter 76 : loss : 0.1465 = 0.0549 + 0.0872 + 0.0044, time: 7.439414]
2023-05-15 17:32:38.178: epoch 76:	0.02563567  	0.18964341  	0.10253325  
2023-05-15 17:32:38.178: Find a better model.
2023-05-15 17:32:45.595: [iter 77 : loss : 0.1455 = 0.0539 + 0.0871 + 0.0045, time: 7.415971]
2023-05-15 17:32:45.749: epoch 77:	0.02567095  	0.18995328  	0.10280349  
2023-05-15 17:32:45.749: Find a better model.
2023-05-15 17:32:53.199: [iter 78 : loss : 0.1445 = 0.0530 + 0.0870 + 0.0045, time: 7.447366]
2023-05-15 17:32:53.343: epoch 78:	0.02572034  	0.19034398  	0.10299077  
2023-05-15 17:32:53.343: Find a better model.
2023-05-15 17:33:00.817: [iter 79 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0045, time: 7.472868]
2023-05-15 17:33:00.970: epoch 79:	0.02581208  	0.19078708  	0.10323271  
2023-05-15 17:33:00.971: Find a better model.
2023-05-15 17:33:08.382: [iter 80 : loss : 0.1426 = 0.0513 + 0.0868 + 0.0046, time: 7.409122]
2023-05-15 17:33:08.539: epoch 80:	0.02574857  	0.19012973  	0.10322031  
2023-05-15 17:33:15.792: [iter 81 : loss : 0.1421 = 0.0508 + 0.0867 + 0.0046, time: 7.250224]
2023-05-15 17:33:15.947: epoch 81:	0.02586147  	0.19105479  	0.10368922  
2023-05-15 17:33:15.948: Find a better model.
2023-05-15 17:33:23.375: [iter 82 : loss : 0.1411 = 0.0499 + 0.0865 + 0.0047, time: 7.425476]
2023-05-15 17:33:23.534: epoch 82:	0.02588265  	0.19119410  	0.10398275  
2023-05-15 17:33:23.534: Find a better model.
2023-05-15 17:33:30.804: [iter 83 : loss : 0.1399 = 0.0488 + 0.0865 + 0.0047, time: 7.269089]
2023-05-15 17:33:30.959: epoch 83:	0.02586148  	0.19104958  	0.10408907  
2023-05-15 17:33:38.370: [iter 84 : loss : 0.1401 = 0.0489 + 0.0864 + 0.0047, time: 7.409708]
2023-05-15 17:33:38.530: epoch 84:	0.02592499  	0.19149777  	0.10449521  
2023-05-15 17:33:38.530: Find a better model.
2023-05-15 17:33:45.773: [iter 85 : loss : 0.1389 = 0.0478 + 0.0863 + 0.0048, time: 7.242560]
2023-05-15 17:33:45.926: epoch 85:	0.02593204  	0.19148026  	0.10455819  
2023-05-15 17:33:53.392: [iter 86 : loss : 0.1387 = 0.0477 + 0.0862 + 0.0048, time: 7.464567]
2023-05-15 17:33:53.549: epoch 86:	0.02597438  	0.19179434  	0.10476920  
2023-05-15 17:33:53.549: Find a better model.
2023-05-15 17:34:00.957: [iter 87 : loss : 0.1362 = 0.0452 + 0.0861 + 0.0048, time: 7.406287]
2023-05-15 17:34:01.111: epoch 87:	0.02601672  	0.19202682  	0.10506251  
2023-05-15 17:34:01.111: Find a better model.
2023-05-15 17:34:08.362: [iter 88 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 7.249458]
2023-05-15 17:34:08.504: epoch 88:	0.02597438  	0.19171713  	0.10496439  
2023-05-15 17:34:15.762: [iter 89 : loss : 0.1352 = 0.0443 + 0.0859 + 0.0049, time: 7.257531]
2023-05-15 17:34:15.918: epoch 89:	0.02598144  	0.19151512  	0.10498332  
2023-05-15 17:34:23.373: [iter 90 : loss : 0.1354 = 0.0446 + 0.0858 + 0.0050, time: 7.453919]
2023-05-15 17:34:23.528: epoch 90:	0.02604494  	0.19215503  	0.10522451  
2023-05-15 17:34:23.528: Find a better model.
2023-05-15 17:34:30.787: [iter 91 : loss : 0.1345 = 0.0437 + 0.0858 + 0.0050, time: 7.257667]
2023-05-15 17:34:30.944: epoch 91:	0.02613667  	0.19282521  	0.10553404  
2023-05-15 17:34:30.945: Find a better model.
2023-05-15 17:34:38.156: [iter 92 : loss : 0.1334 = 0.0427 + 0.0856 + 0.0050, time: 7.209947]
2023-05-15 17:34:38.313: epoch 92:	0.02613668  	0.19271865  	0.10551408  
2023-05-15 17:34:45.559: [iter 93 : loss : 0.1339 = 0.0432 + 0.0856 + 0.0051, time: 7.245402]
2023-05-15 17:34:45.708: epoch 93:	0.02615784  	0.19295935  	0.10571481  
2023-05-15 17:34:45.708: Find a better model.
2023-05-15 17:34:52.993: [iter 94 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 7.282765]
2023-05-15 17:34:53.148: epoch 94:	0.02610845  	0.19259983  	0.10578970  
2023-05-15 17:35:00.369: [iter 95 : loss : 0.1309 = 0.0404 + 0.0854 + 0.0051, time: 7.220006]
2023-05-15 17:35:00.513: epoch 95:	0.02616489  	0.19324513  	0.10606239  
2023-05-15 17:35:00.513: Find a better model.
2023-05-15 17:35:07.742: [iter 96 : loss : 0.1316 = 0.0410 + 0.0854 + 0.0052, time: 7.227508]
2023-05-15 17:35:07.899: epoch 96:	0.02622135  	0.19368817  	0.10623377  
2023-05-15 17:35:07.899: Find a better model.
2023-05-15 17:35:15.130: [iter 97 : loss : 0.1296 = 0.0391 + 0.0853 + 0.0052, time: 7.229487]
2023-05-15 17:35:15.285: epoch 97:	0.02625663  	0.19423987  	0.10643761  
2023-05-15 17:35:15.285: Find a better model.
2023-05-15 17:35:22.556: [iter 98 : loss : 0.1303 = 0.0399 + 0.0852 + 0.0053, time: 7.269503]
2023-05-15 17:35:22.715: epoch 98:	0.02620724  	0.19420290  	0.10640615  
2023-05-15 17:35:29.958: [iter 99 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 7.241785]
2023-05-15 17:35:30.114: epoch 99:	0.02621429  	0.19397302  	0.10645994  
2023-05-15 17:35:37.343: [iter 100 : loss : 0.1286 = 0.0383 + 0.0850 + 0.0053, time: 7.227169]
2023-05-15 17:35:37.499: epoch 100:	0.02624252  	0.19413342  	0.10668717  
2023-05-15 17:35:44.728: [iter 101 : loss : 0.1282 = 0.0379 + 0.0850 + 0.0054, time: 7.227748]
2023-05-15 17:35:44.880: epoch 101:	0.02635542  	0.19467278  	0.10700659  
2023-05-15 17:35:44.880: Find a better model.
2023-05-15 17:35:52.148: [iter 102 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 7.265882]
2023-05-15 17:35:52.303: epoch 102:	0.02639071  	0.19472012  	0.10698341  
2023-05-15 17:35:52.303: Find a better model.
2023-05-15 17:35:59.709: [iter 103 : loss : 0.1267 = 0.0365 + 0.0848 + 0.0054, time: 7.404185]
2023-05-15 17:35:59.853: epoch 103:	0.02641893  	0.19500798  	0.10729238  
2023-05-15 17:35:59.853: Find a better model.
2023-05-15 17:36:07.132: [iter 104 : loss : 0.1274 = 0.0372 + 0.0848 + 0.0055, time: 7.278401]
2023-05-15 17:36:07.286: epoch 104:	0.02646833  	0.19567995  	0.10753234  
2023-05-15 17:36:07.286: Find a better model.
2023-05-15 17:36:14.524: [iter 105 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 7.236012]
2023-05-15 17:36:14.679: epoch 105:	0.02641187  	0.19539849  	0.10743731  
2023-05-15 17:36:21.957: [iter 106 : loss : 0.1260 = 0.0358 + 0.0847 + 0.0055, time: 7.276223]
2023-05-15 17:36:22.111: epoch 106:	0.02642599  	0.19541253  	0.10760124  
2023-05-15 17:36:29.496: [iter 107 : loss : 0.1250 = 0.0348 + 0.0846 + 0.0056, time: 7.382743]
2023-05-15 17:36:29.652: epoch 107:	0.02645421  	0.19569404  	0.10774847  
2023-05-15 17:36:29.653: Find a better model.
2023-05-15 17:36:37.100: [iter 108 : loss : 0.1251 = 0.0350 + 0.0845 + 0.0056, time: 7.446498]
2023-05-15 17:36:37.256: epoch 108:	0.02649655  	0.19596387  	0.10771137  
2023-05-15 17:36:37.256: Find a better model.
2023-05-15 17:36:44.508: [iter 109 : loss : 0.1234 = 0.0334 + 0.0844 + 0.0056, time: 7.250748]
2023-05-15 17:36:44.651: epoch 109:	0.02656712  	0.19684629  	0.10797119  
2023-05-15 17:36:44.651: Find a better model.
2023-05-15 17:36:51.939: [iter 110 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.287138]
2023-05-15 17:36:52.095: epoch 110:	0.02651067  	0.19655783  	0.10776371  
2023-05-15 17:36:59.496: [iter 111 : loss : 0.1230 = 0.0329 + 0.0844 + 0.0057, time: 7.400195]
2023-05-15 17:36:59.651: epoch 111:	0.02658829  	0.19677684  	0.10782742  
2023-05-15 17:37:06.914: [iter 112 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0057, time: 7.262250]
2023-05-15 17:37:07.068: epoch 112:	0.02658123  	0.19667429  	0.10789158  
2023-05-15 17:37:14.508: [iter 113 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0058, time: 7.439808]
2023-05-15 17:37:14.661: epoch 113:	0.02658124  	0.19641212  	0.10787524  
2023-05-15 17:37:22.124: [iter 114 : loss : 0.1220 = 0.0320 + 0.0842 + 0.0058, time: 7.460208]
2023-05-15 17:37:22.280: epoch 114:	0.02665886  	0.19688338  	0.10814980  
2023-05-15 17:37:22.280: Find a better model.
2023-05-15 17:37:29.720: [iter 115 : loss : 0.1216 = 0.0317 + 0.0841 + 0.0058, time: 7.439863]
2023-05-15 17:37:29.876: epoch 115:	0.02672236  	0.19745788  	0.10848165  
2023-05-15 17:37:29.876: Find a better model.
2023-05-15 17:37:37.323: [iter 116 : loss : 0.1208 = 0.0309 + 0.0841 + 0.0059, time: 7.445714]
2023-05-15 17:37:37.478: epoch 116:	0.02672942  	0.19758689  	0.10843672  
2023-05-15 17:37:37.478: Find a better model.
2023-05-15 17:37:44.892: [iter 117 : loss : 0.1207 = 0.0309 + 0.0840 + 0.0059, time: 7.413287]
2023-05-15 17:37:45.050: epoch 117:	0.02676470  	0.19815105  	0.10867080  
2023-05-15 17:37:45.051: Find a better model.
2023-05-15 17:37:52.318: [iter 118 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0059, time: 7.266434]
2023-05-15 17:37:52.471: epoch 118:	0.02670825  	0.19790962  	0.10862467  
2023-05-15 17:37:59.909: [iter 119 : loss : 0.1194 = 0.0296 + 0.0839 + 0.0060, time: 7.437369]
2023-05-15 17:38:00.070: epoch 119:	0.02672236  	0.19805250  	0.10853586  
2023-05-15 17:38:07.472: [iter 120 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 7.400816]
2023-05-15 17:38:07.628: epoch 120:	0.02674353  	0.19818641  	0.10875961  
2023-05-15 17:38:07.628: Find a better model.
2023-05-15 17:38:15.080: [iter 121 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0060, time: 7.450602]
2023-05-15 17:38:15.224: epoch 121:	0.02668002  	0.19764243  	0.10878956  
2023-05-15 17:38:22.513: [iter 122 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 7.287841]
2023-05-15 17:38:22.667: epoch 122:	0.02662357  	0.19733253  	0.10876845  
2023-05-15 17:38:30.078: [iter 123 : loss : 0.1189 = 0.0292 + 0.0837 + 0.0061, time: 7.409824]
2023-05-15 17:38:30.219: epoch 123:	0.02667296  	0.19762079  	0.10877962  
2023-05-15 17:38:37.469: [iter 124 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0061, time: 7.248130]
2023-05-15 17:38:37.624: epoch 124:	0.02677881  	0.19828585  	0.10920776  
2023-05-15 17:38:37.624: Find a better model.
2023-05-15 17:38:44.873: [iter 125 : loss : 0.1175 = 0.0277 + 0.0836 + 0.0061, time: 7.248728]
2023-05-15 17:38:45.029: epoch 125:	0.02674352  	0.19803162  	0.10912938  
2023-05-15 17:38:52.294: [iter 126 : loss : 0.1175 = 0.0277 + 0.0836 + 0.0062, time: 7.262599]
2023-05-15 17:38:52.451: epoch 126:	0.02675764  	0.19822687  	0.10915799  
2023-05-15 17:38:59.850: [iter 127 : loss : 0.1165 = 0.0268 + 0.0835 + 0.0062, time: 7.397516]
2023-05-15 17:39:00.006: epoch 127:	0.02665179  	0.19747928  	0.10893092  
2023-05-15 17:39:07.446: [iter 128 : loss : 0.1176 = 0.0279 + 0.0835 + 0.0062, time: 7.437577]
2023-05-15 17:39:07.600: epoch 128:	0.02667296  	0.19761568  	0.10902330  
2023-05-15 17:39:15.054: [iter 129 : loss : 0.1166 = 0.0269 + 0.0834 + 0.0063, time: 7.452129]
2023-05-15 17:39:15.210: epoch 129:	0.02670118  	0.19778836  	0.10904521  
2023-05-15 17:39:22.491: [iter 130 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 7.279108]
2023-05-15 17:39:22.646: epoch 130:	0.02668001  	0.19791730  	0.10895002  
2023-05-15 17:39:30.036: [iter 131 : loss : 0.1160 = 0.0264 + 0.0833 + 0.0063, time: 7.389096]
2023-05-15 17:39:30.183: epoch 131:	0.02672235  	0.19812936  	0.10898097  
2023-05-15 17:39:37.451: [iter 132 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0064, time: 7.265687]
2023-05-15 17:39:37.604: epoch 132:	0.02676469  	0.19851416  	0.10917192  
2023-05-15 17:39:37.604: Find a better model.
2023-05-15 17:39:45.054: [iter 133 : loss : 0.1148 = 0.0251 + 0.0833 + 0.0064, time: 7.447749]
2023-05-15 17:39:45.213: epoch 133:	0.02675764  	0.19814806  	0.10913389  
2023-05-15 17:39:52.661: [iter 134 : loss : 0.1154 = 0.0258 + 0.0832 + 0.0064, time: 7.447227]
2023-05-15 17:39:52.819: epoch 134:	0.02675763  	0.19801794  	0.10929544  
2023-05-15 17:40:00.071: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 7.249863]
2023-05-15 17:40:00.228: epoch 135:	0.02668707  	0.19738449  	0.10913923  
2023-05-15 17:40:07.639: [iter 136 : loss : 0.1150 = 0.0253 + 0.0831 + 0.0065, time: 7.410062]
2023-05-15 17:40:07.794: epoch 136:	0.02668001  	0.19744961  	0.10919425  
2023-05-15 17:40:15.047: [iter 137 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.252057]
2023-05-15 17:40:15.201: epoch 137:	0.02667295  	0.19734196  	0.10941838  
2023-05-15 17:40:22.632: [iter 138 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0065, time: 7.429897]
2023-05-15 17:40:22.786: epoch 138:	0.02665178  	0.19716446  	0.10940177  
2023-05-15 17:40:30.058: [iter 139 : loss : 0.1139 = 0.0244 + 0.0830 + 0.0066, time: 7.269840]
2023-05-15 17:40:30.214: epoch 139:	0.02670823  	0.19769925  	0.10973976  
2023-05-15 17:40:37.433: [iter 140 : loss : 0.1134 = 0.0239 + 0.0830 + 0.0066, time: 7.215908]
2023-05-15 17:40:37.576: epoch 140:	0.02665884  	0.19758157  	0.10962564  
2023-05-15 17:40:44.836: [iter 141 : loss : 0.1139 = 0.0244 + 0.0829 + 0.0066, time: 7.259006]
2023-05-15 17:40:44.989: epoch 141:	0.02681409  	0.19853911  	0.10996437  
2023-05-15 17:40:44.989: Find a better model.
2023-05-15 17:40:52.238: [iter 142 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0066, time: 7.248153]
2023-05-15 17:40:52.394: epoch 142:	0.02672941  	0.19783811  	0.10982899  
2023-05-15 17:40:59.651: [iter 143 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.256401]
2023-05-15 17:40:59.802: epoch 143:	0.02673646  	0.19759211  	0.10971300  
2023-05-15 17:41:07.239: [iter 144 : loss : 0.1126 = 0.0230 + 0.0828 + 0.0067, time: 7.435795]
2023-05-15 17:41:07.396: epoch 144:	0.02669412  	0.19734284  	0.10964301  
2023-05-15 17:41:14.793: [iter 145 : loss : 0.1125 = 0.0230 + 0.0828 + 0.0067, time: 7.396662]
2023-05-15 17:41:14.950: epoch 145:	0.02671529  	0.19709931  	0.10979412  
2023-05-15 17:41:22.236: [iter 146 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 7.284863]
2023-05-15 17:41:22.390: epoch 146:	0.02671529  	0.19734359  	0.10976512  
2023-05-15 17:41:29.644: [iter 147 : loss : 0.1125 = 0.0230 + 0.0827 + 0.0068, time: 7.252364]
2023-05-15 17:41:29.802: epoch 147:	0.02668707  	0.19733217  	0.10964686  
2023-05-15 17:41:37.201: [iter 148 : loss : 0.1113 = 0.0218 + 0.0827 + 0.0068, time: 7.397013]
2023-05-15 17:41:37.359: epoch 148:	0.02663767  	0.19680293  	0.10979053  
2023-05-15 17:41:44.621: [iter 149 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0068, time: 7.261731]
2023-05-15 17:41:44.773: epoch 149:	0.02665884  	0.19712244  	0.10989357  
2023-05-15 17:41:52.026: [iter 150 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0069, time: 7.251071]
2023-05-15 17:41:52.170: epoch 150:	0.02665884  	0.19714695  	0.10994629  
2023-05-15 17:41:59.441: [iter 151 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0069, time: 7.269647]
2023-05-15 17:41:59.594: epoch 151:	0.02660945  	0.19692689  	0.10984882  
2023-05-15 17:42:06.799: [iter 152 : loss : 0.1106 = 0.0211 + 0.0826 + 0.0069, time: 7.203671]
2023-05-15 17:42:06.955: epoch 152:	0.02670118  	0.19769923  	0.11010022  
2023-05-15 17:42:14.367: [iter 153 : loss : 0.1098 = 0.0203 + 0.0825 + 0.0069, time: 7.410066]
2023-05-15 17:42:14.520: epoch 153:	0.02665884  	0.19715734  	0.10977121  
2023-05-15 17:42:21.798: [iter 154 : loss : 0.1102 = 0.0207 + 0.0825 + 0.0070, time: 7.277089]
2023-05-15 17:42:21.943: epoch 154:	0.02668001  	0.19733633  	0.10994946  
2023-05-15 17:42:29.213: [iter 155 : loss : 0.1109 = 0.0214 + 0.0825 + 0.0070, time: 7.268241]
2023-05-15 17:42:29.371: epoch 155:	0.02668001  	0.19702610  	0.10996521  
2023-05-15 17:42:36.591: [iter 156 : loss : 0.1101 = 0.0207 + 0.0824 + 0.0070, time: 7.217525]
2023-05-15 17:42:36.746: epoch 156:	0.02664473  	0.19676737  	0.10982270  
2023-05-15 17:42:43.990: [iter 157 : loss : 0.1101 = 0.0206 + 0.0824 + 0.0070, time: 7.242796]
2023-05-15 17:42:44.145: epoch 157:	0.02668001  	0.19704257  	0.10992156  
2023-05-15 17:42:51.417: [iter 158 : loss : 0.1093 = 0.0199 + 0.0824 + 0.0071, time: 7.270330]
2023-05-15 17:42:51.570: epoch 158:	0.02659533  	0.19672725  	0.11000525  
2023-05-15 17:42:58.825: [iter 159 : loss : 0.1096 = 0.0202 + 0.0823 + 0.0071, time: 7.252033]
2023-05-15 17:42:58.980: epoch 159:	0.02658828  	0.19660287  	0.10990320  
2023-05-15 17:43:06.367: [iter 160 : loss : 0.1093 = 0.0199 + 0.0823 + 0.0071, time: 7.385850]
2023-05-15 17:43:06.524: epoch 160:	0.02658122  	0.19641860  	0.10990926  
2023-05-15 17:43:13.788: [iter 161 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0071, time: 7.263919]
2023-05-15 17:43:13.943: epoch 161:	0.02659533  	0.19673587  	0.10999928  
2023-05-15 17:43:21.200: [iter 162 : loss : 0.1082 = 0.0188 + 0.0823 + 0.0072, time: 7.254647]
2023-05-15 17:43:21.343: epoch 162:	0.02656711  	0.19626699  	0.10984886  
2023-05-15 17:43:28.597: [iter 163 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.252735]
2023-05-15 17:43:28.752: epoch 163:	0.02658123  	0.19674684  	0.10990490  
2023-05-15 17:43:36.169: [iter 164 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 7.415005]
2023-05-15 17:43:36.323: epoch 164:	0.02657417  	0.19674724  	0.10983501  
2023-05-15 17:43:43.574: [iter 165 : loss : 0.1080 = 0.0185 + 0.0822 + 0.0072, time: 7.249345]
2023-05-15 17:43:43.729: epoch 165:	0.02660240  	0.19694948  	0.10994107  
2023-05-15 17:43:50.982: [iter 166 : loss : 0.1080 = 0.0186 + 0.0822 + 0.0073, time: 7.250734]
2023-05-15 17:43:51.136: epoch 166:	0.02659534  	0.19670583  	0.10965794  
2023-05-15 17:43:51.137: Early stopping is trigger at epoch: 166
2023-05-15 17:43:51.137: best_result@epoch 141:

2023-05-15 17:43:51.137: 		0.0268      	0.1985      	0.1100      
2023-05-15 18:36:10.031: my pid: 9528
2023-05-15 18:36:10.031: model: model.general_recommender.SGL
2023-05-15 18:36:10.031: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 18:36:10.031: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 18:36:13.073: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 18:36:21.295: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.220386]
2023-05-15 18:36:21.450: epoch 1:	0.00148885  	0.01063003  	0.00549043  
2023-05-15 18:36:21.450: Find a better model.
2023-05-15 18:36:29.719: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.267371]
2023-05-15 18:36:29.903: epoch 2:	0.00281541  	0.02099558  	0.01006149  
2023-05-15 18:36:29.903: Find a better model.
2023-05-15 18:36:38.121: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.216673]
2023-05-15 18:36:38.295: epoch 3:	0.00522153  	0.04043141  	0.01876951  
2023-05-15 18:36:38.295: Find a better model.
2023-05-15 18:36:46.324: [iter 4 : loss : 0.7706 = 0.6919 + 0.0787 + 0.0000, time: 8.026071]
2023-05-15 18:36:46.485: epoch 4:	0.00811452  	0.06020720  	0.02896955  
2023-05-15 18:36:46.485: Find a better model.
2023-05-15 18:36:54.358: [iter 5 : loss : 0.7695 = 0.6907 + 0.0789 + 0.0000, time: 7.871742]
2023-05-15 18:36:54.510: epoch 5:	0.01203787  	0.08809181  	0.04182817  
2023-05-15 18:36:54.510: Find a better model.
2023-05-15 18:37:02.298: [iter 6 : loss : 0.7670 = 0.6877 + 0.0792 + 0.0000, time: 7.787544]
2023-05-15 18:37:02.452: epoch 6:	0.01548846  	0.11280631  	0.05546009  
2023-05-15 18:37:02.452: Find a better model.
2023-05-15 18:37:10.094: [iter 7 : loss : 0.7601 = 0.6800 + 0.0801 + 0.0000, time: 7.640633]
2023-05-15 18:37:10.245: epoch 7:	0.01785236  	0.13086689  	0.06487801  
2023-05-15 18:37:10.245: Find a better model.
2023-05-15 18:37:17.695: [iter 8 : loss : 0.7431 = 0.6609 + 0.0821 + 0.0001, time: 7.447917]
2023-05-15 18:37:17.849: epoch 8:	0.01892494  	0.13811868  	0.06926192  
2023-05-15 18:37:17.849: Find a better model.
2023-05-15 18:37:25.334: [iter 9 : loss : 0.7053 = 0.6189 + 0.0862 + 0.0001, time: 7.482364]
2023-05-15 18:37:25.486: epoch 9:	0.01875559  	0.13778916  	0.06900533  
2023-05-15 18:37:32.861: [iter 10 : loss : 0.6420 = 0.5501 + 0.0916 + 0.0003, time: 7.373764]
2023-05-15 18:37:33.007: epoch 10:	0.01858623  	0.13712323  	0.06849518  
2023-05-15 18:37:40.491: [iter 11 : loss : 0.5663 = 0.4695 + 0.0964 + 0.0004, time: 7.483213]
2023-05-15 18:37:40.642: epoch 11:	0.01848038  	0.13619061  	0.06816594  
2023-05-15 18:37:48.094: [iter 12 : loss : 0.4994 = 0.3991 + 0.0997 + 0.0006, time: 7.451102]
2023-05-15 18:37:48.252: epoch 12:	0.01843099  	0.13580209  	0.06806535  
2023-05-15 18:37:55.872: [iter 13 : loss : 0.4501 = 0.3480 + 0.1014 + 0.0007, time: 7.618637]
2023-05-15 18:37:56.031: epoch 13:	0.01852977  	0.13706820  	0.06869292  
2023-05-15 18:38:03.464: [iter 14 : loss : 0.4126 = 0.3095 + 0.1022 + 0.0009, time: 7.431781]
2023-05-15 18:38:03.608: epoch 14:	0.01876969  	0.13898540  	0.06979485  
2023-05-15 18:38:03.609: Find a better model.
2023-05-15 18:38:11.090: [iter 15 : loss : 0.3866 = 0.2831 + 0.1026 + 0.0010, time: 7.480556]
2023-05-15 18:38:11.245: epoch 15:	0.01893905  	0.14024487  	0.07077627  
2023-05-15 18:38:11.245: Find a better model.
2023-05-15 18:38:18.849: [iter 16 : loss : 0.3645 = 0.2609 + 0.1026 + 0.0011, time: 7.602684]
2023-05-15 18:38:19.008: epoch 16:	0.01915780  	0.14175680  	0.07183012  
2023-05-15 18:38:19.008: Find a better model.
2023-05-15 18:38:26.700: [iter 17 : loss : 0.3485 = 0.2448 + 0.1024 + 0.0012, time: 7.689603]
2023-05-15 18:38:26.856: epoch 17:	0.01930599  	0.14273787  	0.07235584  
2023-05-15 18:38:26.856: Find a better model.
2023-05-15 18:38:34.449: [iter 18 : loss : 0.3332 = 0.2297 + 0.1022 + 0.0013, time: 7.591079]
2023-05-15 18:38:34.603: epoch 18:	0.01948946  	0.14388134  	0.07310290  
2023-05-15 18:38:34.603: Find a better model.
2023-05-15 18:38:42.056: [iter 19 : loss : 0.3195 = 0.2163 + 0.1018 + 0.0014, time: 7.451936]
2023-05-15 18:38:42.198: epoch 19:	0.01975056  	0.14581248  	0.07411672  
2023-05-15 18:38:42.198: Find a better model.
2023-05-15 18:38:49.647: [iter 20 : loss : 0.3095 = 0.2066 + 0.1014 + 0.0015, time: 7.447761]
2023-05-15 18:38:49.801: epoch 20:	0.01991992  	0.14690490  	0.07467688  
2023-05-15 18:38:49.801: Find a better model.
2023-05-15 18:38:57.274: [iter 21 : loss : 0.3001 = 0.1975 + 0.1010 + 0.0016, time: 7.471996]
2023-05-15 18:38:57.417: epoch 21:	0.02008927  	0.14778465  	0.07531058  
2023-05-15 18:38:57.417: Find a better model.
2023-05-15 18:39:04.836: [iter 22 : loss : 0.2920 = 0.1898 + 0.1006 + 0.0017, time: 7.417332]
2023-05-15 18:39:04.979: epoch 22:	0.02026569  	0.14915448  	0.07586341  
2023-05-15 18:39:04.979: Find a better model.
2023-05-15 18:39:12.447: [iter 23 : loss : 0.2838 = 0.1819 + 0.1001 + 0.0017, time: 7.467143]
2023-05-15 18:39:12.603: epoch 23:	0.02044210  	0.15010338  	0.07657231  
2023-05-15 18:39:12.603: Find a better model.
2023-05-15 18:39:20.052: [iter 24 : loss : 0.2775 = 0.1760 + 0.0997 + 0.0018, time: 7.447788]
2023-05-15 18:39:20.211: epoch 24:	0.02061851  	0.15148018  	0.07739934  
2023-05-15 18:39:20.212: Find a better model.
2023-05-15 18:39:27.639: [iter 25 : loss : 0.2708 = 0.1696 + 0.0993 + 0.0019, time: 7.425444]
2023-05-15 18:39:27.795: epoch 25:	0.02079493  	0.15306337  	0.07831560  
2023-05-15 18:39:27.795: Find a better model.
2023-05-15 18:39:35.246: [iter 26 : loss : 0.2672 = 0.1663 + 0.0990 + 0.0019, time: 7.450395]
2023-05-15 18:39:35.401: epoch 26:	0.02094311  	0.15377226  	0.07884122  
2023-05-15 18:39:35.401: Find a better model.
2023-05-15 18:39:42.826: [iter 27 : loss : 0.2594 = 0.1589 + 0.0985 + 0.0020, time: 7.423880]
2023-05-15 18:39:42.984: epoch 27:	0.02110541  	0.15514086  	0.07974202  
2023-05-15 18:39:42.985: Find a better model.
2023-05-15 18:39:50.418: [iter 28 : loss : 0.2548 = 0.1547 + 0.0981 + 0.0021, time: 7.431348]
2023-05-15 18:39:50.572: epoch 28:	0.02134533  	0.15730350  	0.08064052  
2023-05-15 18:39:50.572: Find a better model.
2023-05-15 18:39:57.999: [iter 29 : loss : 0.2502 = 0.1504 + 0.0977 + 0.0021, time: 7.426405]
2023-05-15 18:39:58.159: epoch 29:	0.02167699  	0.15945446  	0.08156120  
2023-05-15 18:39:58.159: Find a better model.
2023-05-15 18:40:05.638: [iter 30 : loss : 0.2437 = 0.1441 + 0.0973 + 0.0022, time: 7.476756]
2023-05-15 18:40:05.792: epoch 30:	0.02181812  	0.16115855  	0.08233010  
2023-05-15 18:40:05.792: Find a better model.
2023-05-15 18:40:13.210: [iter 31 : loss : 0.2403 = 0.1411 + 0.0969 + 0.0023, time: 7.415664]
2023-05-15 18:40:13.366: epoch 31:	0.02188869  	0.16163722  	0.08277876  
2023-05-15 18:40:13.366: Find a better model.
2023-05-15 18:40:20.811: [iter 32 : loss : 0.2345 = 0.1355 + 0.0966 + 0.0023, time: 7.443568]
2023-05-15 18:40:20.954: epoch 32:	0.02190281  	0.16196972  	0.08326912  
2023-05-15 18:40:20.954: Find a better model.
2023-05-15 18:40:28.435: [iter 33 : loss : 0.2319 = 0.1333 + 0.0962 + 0.0024, time: 7.480272]
2023-05-15 18:40:28.589: epoch 33:	0.02212861  	0.16373502  	0.08410403  
2023-05-15 18:40:28.589: Find a better model.
2023-05-15 18:40:36.029: [iter 34 : loss : 0.2277 = 0.1294 + 0.0959 + 0.0024, time: 7.438429]
2023-05-15 18:40:36.185: epoch 34:	0.02234736  	0.16442655  	0.08505673  
2023-05-15 18:40:36.186: Find a better model.
2023-05-15 18:40:43.642: [iter 35 : loss : 0.2242 = 0.1262 + 0.0956 + 0.0025, time: 7.454973]
2023-05-15 18:40:43.795: epoch 35:	0.02264374  	0.16629620  	0.08611253  
2023-05-15 18:40:43.795: Find a better model.
2023-05-15 18:40:51.222: [iter 36 : loss : 0.2210 = 0.1233 + 0.0952 + 0.0025, time: 7.426290]
2023-05-15 18:40:51.376: epoch 36:	0.02274252  	0.16668212  	0.08664605  
2023-05-15 18:40:51.376: Find a better model.
2023-05-15 18:40:59.007: [iter 37 : loss : 0.2171 = 0.1196 + 0.0949 + 0.0026, time: 7.629647]
2023-05-15 18:40:59.162: epoch 37:	0.02280604  	0.16761829  	0.08710191  
2023-05-15 18:40:59.162: Find a better model.
2023-05-15 18:41:06.592: [iter 38 : loss : 0.2155 = 0.1182 + 0.0946 + 0.0027, time: 7.425781]
2023-05-15 18:41:06.747: epoch 38:	0.02291894  	0.16848637  	0.08757404  
2023-05-15 18:41:06.747: Find a better model.
2023-05-15 18:41:14.210: [iter 39 : loss : 0.2111 = 0.1141 + 0.0943 + 0.0027, time: 7.462231]
2023-05-15 18:41:14.367: epoch 39:	0.02307418  	0.17016211  	0.08867434  
2023-05-15 18:41:14.367: Find a better model.
2023-05-15 18:41:21.788: [iter 40 : loss : 0.2079 = 0.1112 + 0.0940 + 0.0028, time: 7.419667]
2023-05-15 18:41:21.946: epoch 40:	0.02310240  	0.17033060  	0.08896019  
2023-05-15 18:41:21.947: Find a better model.
2023-05-15 18:41:29.423: [iter 41 : loss : 0.2060 = 0.1095 + 0.0937 + 0.0028, time: 7.475094]
2023-05-15 18:41:29.566: epoch 41:	0.02311652  	0.16996302  	0.08915356  
2023-05-15 18:41:36.981: [iter 42 : loss : 0.2039 = 0.1076 + 0.0934 + 0.0029, time: 7.413601]
2023-05-15 18:41:37.122: epoch 42:	0.02318708  	0.17096686  	0.08980282  
2023-05-15 18:41:37.122: Find a better model.
2023-05-15 18:41:44.390: [iter 43 : loss : 0.2000 = 0.1040 + 0.0931 + 0.0029, time: 7.265785]
2023-05-15 18:41:44.544: epoch 43:	0.02332116  	0.17182566  	0.09033322  
2023-05-15 18:41:44.544: Find a better model.
2023-05-15 18:41:51.812: [iter 44 : loss : 0.1966 = 0.1008 + 0.0929 + 0.0030, time: 7.267005]
2023-05-15 18:41:51.965: epoch 44:	0.02349757  	0.17335962  	0.09114647  
2023-05-15 18:41:51.965: Find a better model.
2023-05-15 18:41:59.366: [iter 45 : loss : 0.1943 = 0.0986 + 0.0927 + 0.0030, time: 7.399399]
2023-05-15 18:41:59.518: epoch 45:	0.02370220  	0.17536078  	0.09205474  
2023-05-15 18:41:59.518: Find a better model.
2023-05-15 18:42:06.782: [iter 46 : loss : 0.1920 = 0.0965 + 0.0924 + 0.0031, time: 7.262756]
2023-05-15 18:42:06.934: epoch 46:	0.02373043  	0.17559314  	0.09245193  
2023-05-15 18:42:06.934: Find a better model.
2023-05-15 18:42:14.202: [iter 47 : loss : 0.1913 = 0.0961 + 0.0921 + 0.0031, time: 7.266480]
2023-05-15 18:42:14.358: epoch 47:	0.02382923  	0.17658387  	0.09301206  
2023-05-15 18:42:14.359: Find a better model.
2023-05-15 18:42:21.770: [iter 48 : loss : 0.1873 = 0.0922 + 0.0919 + 0.0032, time: 7.410574]
2023-05-15 18:42:21.913: epoch 48:	0.02400564  	0.17778088  	0.09376065  
2023-05-15 18:42:21.914: Find a better model.
2023-05-15 18:42:29.403: [iter 49 : loss : 0.1842 = 0.0893 + 0.0917 + 0.0032, time: 7.487962]
2023-05-15 18:42:29.559: epoch 49:	0.02401975  	0.17786375  	0.09407694  
2023-05-15 18:42:29.559: Find a better model.
2023-05-15 18:42:36.982: [iter 50 : loss : 0.1834 = 0.0886 + 0.0915 + 0.0033, time: 7.421498]
2023-05-15 18:42:37.135: epoch 50:	0.02406915  	0.17830901  	0.09453959  
2023-05-15 18:42:37.136: Find a better model.
2023-05-15 18:42:44.555: [iter 51 : loss : 0.1805 = 0.0859 + 0.0913 + 0.0033, time: 7.418275]
2023-05-15 18:42:44.697: epoch 51:	0.02411854  	0.17887726  	0.09485615  
2023-05-15 18:42:44.697: Find a better model.
2023-05-15 18:42:52.190: [iter 52 : loss : 0.1803 = 0.0859 + 0.0911 + 0.0034, time: 7.492174]
2023-05-15 18:42:52.346: epoch 52:	0.02419616  	0.17966159  	0.09545470  
2023-05-15 18:42:52.346: Find a better model.
2023-05-15 18:42:59.752: [iter 53 : loss : 0.1784 = 0.0842 + 0.0908 + 0.0034, time: 7.404871]
2023-05-15 18:42:59.906: epoch 53:	0.02424555  	0.17991108  	0.09577852  
2023-05-15 18:42:59.906: Find a better model.
2023-05-15 18:43:07.366: [iter 54 : loss : 0.1763 = 0.0822 + 0.0906 + 0.0035, time: 7.459301]
2023-05-15 18:43:07.519: epoch 54:	0.02431611  	0.18030556  	0.09614284  
2023-05-15 18:43:07.519: Find a better model.
2023-05-15 18:43:14.957: [iter 55 : loss : 0.1743 = 0.0803 + 0.0905 + 0.0035, time: 7.436526]
2023-05-15 18:43:15.111: epoch 55:	0.02435140  	0.18025029  	0.09633273  
2023-05-15 18:43:22.551: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 7.439016]
2023-05-15 18:43:22.706: epoch 56:	0.02444313  	0.18111296  	0.09680523  
2023-05-15 18:43:22.706: Find a better model.
2023-05-15 18:43:30.141: [iter 57 : loss : 0.1709 = 0.0773 + 0.0901 + 0.0036, time: 7.433885]
2023-05-15 18:43:30.281: epoch 57:	0.02452075  	0.18140256  	0.09714539  
2023-05-15 18:43:30.281: Find a better model.
2023-05-15 18:43:37.600: [iter 58 : loss : 0.1690 = 0.0755 + 0.0899 + 0.0036, time: 7.316826]
2023-05-15 18:43:37.753: epoch 58:	0.02453486  	0.18176889  	0.09751099  
2023-05-15 18:43:37.753: Find a better model.
2023-05-15 18:43:45.163: [iter 59 : loss : 0.1678 = 0.0744 + 0.0897 + 0.0037, time: 7.409146]
2023-05-15 18:43:45.318: epoch 59:	0.02455604  	0.18191989  	0.09787468  
2023-05-15 18:43:45.318: Find a better model.
2023-05-15 18:43:52.745: [iter 60 : loss : 0.1663 = 0.0730 + 0.0896 + 0.0037, time: 7.424929]
2023-05-15 18:43:52.898: epoch 60:	0.02467600  	0.18284890  	0.09847174  
2023-05-15 18:43:52.899: Find a better model.
2023-05-15 18:44:00.326: [iter 61 : loss : 0.1648 = 0.0717 + 0.0894 + 0.0038, time: 7.425823]
2023-05-15 18:44:00.482: epoch 61:	0.02470423  	0.18294139  	0.09872651  
2023-05-15 18:44:00.482: Find a better model.
2023-05-15 18:44:07.757: [iter 62 : loss : 0.1632 = 0.0702 + 0.0892 + 0.0038, time: 7.273349]
2023-05-15 18:44:07.914: epoch 62:	0.02475362  	0.18322970  	0.09884230  
2023-05-15 18:44:07.914: Find a better model.
2023-05-15 18:44:15.349: [iter 63 : loss : 0.1619 = 0.0690 + 0.0890 + 0.0039, time: 7.432701]
2023-05-15 18:44:15.506: epoch 63:	0.02476067  	0.18326712  	0.09903260  
2023-05-15 18:44:15.506: Find a better model.
2023-05-15 18:44:22.723: [iter 64 : loss : 0.1611 = 0.0683 + 0.0889 + 0.0039, time: 7.216293]
2023-05-15 18:44:22.878: epoch 64:	0.02485240  	0.18392919  	0.09951184  
2023-05-15 18:44:22.878: Find a better model.
2023-05-15 18:44:30.154: [iter 65 : loss : 0.1597 = 0.0671 + 0.0887 + 0.0039, time: 7.274268]
2023-05-15 18:44:30.306: epoch 65:	0.02493708  	0.18433149  	0.09977957  
2023-05-15 18:44:30.306: Find a better model.
2023-05-15 18:44:37.725: [iter 66 : loss : 0.1583 = 0.0657 + 0.0886 + 0.0040, time: 7.418695]
2023-05-15 18:44:37.877: epoch 66:	0.02505704  	0.18528274  	0.10013650  
2023-05-15 18:44:37.878: Find a better model.
2023-05-15 18:44:45.123: [iter 67 : loss : 0.1567 = 0.0642 + 0.0885 + 0.0040, time: 7.243620]
2023-05-15 18:44:45.277: epoch 67:	0.02519111  	0.18587610  	0.10068151  
2023-05-15 18:44:45.278: Find a better model.
2023-05-15 18:44:52.543: [iter 68 : loss : 0.1563 = 0.0639 + 0.0883 + 0.0041, time: 7.263667]
2023-05-15 18:44:52.696: epoch 68:	0.02517700  	0.18562989  	0.10081264  
2023-05-15 18:44:59.934: [iter 69 : loss : 0.1544 = 0.0621 + 0.0882 + 0.0041, time: 7.237356]
2023-05-15 18:45:00.092: epoch 69:	0.02520522  	0.18601072  	0.10115847  
2023-05-15 18:45:00.092: Find a better model.
2023-05-15 18:45:07.311: [iter 70 : loss : 0.1527 = 0.0605 + 0.0881 + 0.0041, time: 7.218061]
2023-05-15 18:45:07.456: epoch 70:	0.02522639  	0.18601178  	0.10127089  
2023-05-15 18:45:07.456: Find a better model.
2023-05-15 18:45:14.732: [iter 71 : loss : 0.1513 = 0.0592 + 0.0879 + 0.0042, time: 7.273317]
2023-05-15 18:45:14.885: epoch 71:	0.02529696  	0.18648349  	0.10146037  
2023-05-15 18:45:14.885: Find a better model.
2023-05-15 18:45:22.318: [iter 72 : loss : 0.1514 = 0.0593 + 0.0878 + 0.0042, time: 7.431336]
2023-05-15 18:45:22.473: epoch 72:	0.02528284  	0.18656123  	0.10155120  
2023-05-15 18:45:22.473: Find a better model.
2023-05-15 18:45:29.916: [iter 73 : loss : 0.1495 = 0.0575 + 0.0876 + 0.0043, time: 7.442277]
2023-05-15 18:45:30.070: epoch 73:	0.02538163  	0.18742757  	0.10196777  
2023-05-15 18:45:30.070: Find a better model.
2023-05-15 18:45:37.513: [iter 74 : loss : 0.1482 = 0.0564 + 0.0875 + 0.0043, time: 7.442035]
2023-05-15 18:45:37.671: epoch 74:	0.02544513  	0.18768695  	0.10229858  
2023-05-15 18:45:37.671: Find a better model.
2023-05-15 18:45:44.929: [iter 75 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0044, time: 7.256539]
2023-05-15 18:45:45.082: epoch 75:	0.02551570  	0.18829992  	0.10252710  
2023-05-15 18:45:45.083: Find a better model.
2023-05-15 18:45:52.301: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 7.215422]
2023-05-15 18:45:52.456: epoch 76:	0.02557921  	0.18869618  	0.10283379  
2023-05-15 18:45:52.456: Find a better model.
2023-05-15 18:45:59.720: [iter 77 : loss : 0.1458 = 0.0541 + 0.0872 + 0.0044, time: 7.263254]
2023-05-15 18:45:59.873: epoch 77:	0.02565682  	0.18931673  	0.10308521  
2023-05-15 18:45:59.873: Find a better model.
2023-05-15 18:46:07.106: [iter 78 : loss : 0.1450 = 0.0534 + 0.0871 + 0.0045, time: 7.231464]
2023-05-15 18:46:07.258: epoch 78:	0.02566388  	0.18944088  	0.10329843  
2023-05-15 18:46:07.259: Find a better model.
2023-05-15 18:46:14.481: [iter 79 : loss : 0.1435 = 0.0520 + 0.0870 + 0.0045, time: 7.220819]
2023-05-15 18:46:14.636: epoch 79:	0.02573445  	0.18998121  	0.10362574  
2023-05-15 18:46:14.636: Find a better model.
2023-05-15 18:46:21.916: [iter 80 : loss : 0.1429 = 0.0515 + 0.0869 + 0.0046, time: 7.278719]
2023-05-15 18:46:22.070: epoch 80:	0.02572033  	0.18989447  	0.10361172  
2023-05-15 18:46:29.309: [iter 81 : loss : 0.1427 = 0.0513 + 0.0868 + 0.0046, time: 7.236692]
2023-05-15 18:46:29.462: epoch 81:	0.02576267  	0.19026542  	0.10384278  
2023-05-15 18:46:29.462: Find a better model.
2023-05-15 18:46:36.872: [iter 82 : loss : 0.1414 = 0.0501 + 0.0866 + 0.0046, time: 7.409324]
2023-05-15 18:46:37.025: epoch 82:	0.02579090  	0.19027621  	0.10397527  
2023-05-15 18:46:37.025: Find a better model.
2023-05-15 18:46:44.284: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.258092]
2023-05-15 18:46:44.439: epoch 83:	0.02584030  	0.19054428  	0.10426708  
2023-05-15 18:46:44.439: Find a better model.
2023-05-15 18:46:51.694: [iter 84 : loss : 0.1401 = 0.0489 + 0.0865 + 0.0047, time: 7.253159]
2023-05-15 18:46:51.848: epoch 84:	0.02588263  	0.19051939  	0.10438220  
2023-05-15 18:46:59.244: [iter 85 : loss : 0.1392 = 0.0481 + 0.0864 + 0.0047, time: 7.393982]
2023-05-15 18:46:59.398: epoch 85:	0.02590380  	0.19063154  	0.10458655  
2023-05-15 18:46:59.399: Find a better model.
2023-05-15 18:47:06.693: [iter 86 : loss : 0.1391 = 0.0480 + 0.0863 + 0.0048, time: 7.291580]
2023-05-15 18:47:06.846: epoch 86:	0.02592497  	0.19073702  	0.10479475  
2023-05-15 18:47:06.846: Find a better model.
2023-05-15 18:47:14.247: [iter 87 : loss : 0.1363 = 0.0453 + 0.0862 + 0.0048, time: 7.399142]
2023-05-15 18:47:14.400: epoch 87:	0.02595320  	0.19110630  	0.10494775  
2023-05-15 18:47:14.400: Find a better model.
2023-05-15 18:47:21.672: [iter 88 : loss : 0.1356 = 0.0447 + 0.0861 + 0.0049, time: 7.270834]
2023-05-15 18:47:21.832: epoch 88:	0.02596731  	0.19085784  	0.10488959  
2023-05-15 18:47:29.083: [iter 89 : loss : 0.1354 = 0.0446 + 0.0860 + 0.0049, time: 7.249880]
2023-05-15 18:47:29.239: epoch 89:	0.02607316  	0.19142346  	0.10512595  
2023-05-15 18:47:29.239: Find a better model.
2023-05-15 18:47:36.488: [iter 90 : loss : 0.1360 = 0.0451 + 0.0859 + 0.0049, time: 7.247636]
2023-05-15 18:47:36.643: epoch 90:	0.02605199  	0.19113472  	0.10515962  
2023-05-15 18:47:44.032: [iter 91 : loss : 0.1348 = 0.0440 + 0.0858 + 0.0050, time: 7.386945]
2023-05-15 18:47:44.185: epoch 91:	0.02603082  	0.19091664  	0.10509937  
2023-05-15 18:47:51.632: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 7.445671]
2023-05-15 18:47:51.791: epoch 92:	0.02596731  	0.19068296  	0.10514665  
2023-05-15 18:47:59.069: [iter 93 : loss : 0.1343 = 0.0436 + 0.0856 + 0.0051, time: 7.277091]
2023-05-15 18:47:59.221: epoch 93:	0.02604493  	0.19163924  	0.10558975  
2023-05-15 18:47:59.221: Find a better model.
2023-05-15 18:48:06.630: [iter 94 : loss : 0.1320 = 0.0413 + 0.0856 + 0.0051, time: 7.407775]
2023-05-15 18:48:06.786: epoch 94:	0.02609432  	0.19166565  	0.10586862  
2023-05-15 18:48:06.786: Find a better model.
2023-05-15 18:48:14.064: [iter 95 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 7.276258]
2023-05-15 18:48:14.218: epoch 95:	0.02614372  	0.19215605  	0.10607320  
2023-05-15 18:48:14.218: Find a better model.
2023-05-15 18:48:21.458: [iter 96 : loss : 0.1311 = 0.0405 + 0.0854 + 0.0052, time: 7.239403]
2023-05-15 18:48:21.602: epoch 96:	0.02611550  	0.19179961  	0.10604158  
2023-05-15 18:48:28.854: [iter 97 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0052, time: 7.249592]
2023-05-15 18:48:29.008: epoch 97:	0.02617900  	0.19228275  	0.10617853  
2023-05-15 18:48:29.008: Find a better model.
2023-05-15 18:48:36.277: [iter 98 : loss : 0.1307 = 0.0402 + 0.0853 + 0.0052, time: 7.268544]
2023-05-15 18:48:36.432: epoch 98:	0.02617195  	0.19208992  	0.10629765  
2023-05-15 18:48:43.662: [iter 99 : loss : 0.1294 = 0.0389 + 0.0852 + 0.0053, time: 7.228787]
2023-05-15 18:48:43.823: epoch 99:	0.02624251  	0.19249605  	0.10641628  
2023-05-15 18:48:43.823: Find a better model.
2023-05-15 18:48:51.044: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 7.220426]
2023-05-15 18:48:51.198: epoch 100:	0.02620723  	0.19227120  	0.10649735  
2023-05-15 18:48:58.454: [iter 101 : loss : 0.1283 = 0.0379 + 0.0850 + 0.0053, time: 7.254508]
2023-05-15 18:48:58.612: epoch 101:	0.02629191  	0.19280301  	0.10677967  
2023-05-15 18:48:58.612: Find a better model.
2023-05-15 18:49:05.857: [iter 102 : loss : 0.1274 = 0.0370 + 0.0850 + 0.0054, time: 7.243933]
2023-05-15 18:49:06.011: epoch 102:	0.02625663  	0.19237235  	0.10654908  
2023-05-15 18:49:13.230: [iter 103 : loss : 0.1272 = 0.0368 + 0.0849 + 0.0054, time: 7.217332]
2023-05-15 18:49:13.383: epoch 103:	0.02626369  	0.19257784  	0.10685769  
2023-05-15 18:49:20.652: [iter 104 : loss : 0.1275 = 0.0373 + 0.0848 + 0.0054, time: 7.267685]
2023-05-15 18:49:20.806: epoch 104:	0.02624957  	0.19252816  	0.10671692  
2023-05-15 18:49:28.039: [iter 105 : loss : 0.1269 = 0.0367 + 0.0848 + 0.0055, time: 7.232103]
2023-05-15 18:49:28.182: epoch 105:	0.02627074  	0.19257192  	0.10683816  
2023-05-15 18:49:35.410: [iter 106 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 7.225950]
2023-05-15 18:49:35.563: epoch 106:	0.02636248  	0.19310594  	0.10697867  
2023-05-15 18:49:35.563: Find a better model.
2023-05-15 18:49:42.826: [iter 107 : loss : 0.1256 = 0.0354 + 0.0847 + 0.0055, time: 7.262586]
2023-05-15 18:49:42.983: epoch 107:	0.02638365  	0.19328982  	0.10713261  
2023-05-15 18:49:42.983: Find a better model.
2023-05-15 18:49:50.230: [iter 108 : loss : 0.1253 = 0.0352 + 0.0846 + 0.0056, time: 7.244686]
2023-05-15 18:49:50.385: epoch 108:	0.02643305  	0.19380344  	0.10739876  
2023-05-15 18:49:50.385: Find a better model.
2023-05-15 18:49:57.797: [iter 109 : loss : 0.1240 = 0.0338 + 0.0845 + 0.0056, time: 7.411505]
2023-05-15 18:49:57.955: epoch 109:	0.02641187  	0.19372617  	0.10728889  
2023-05-15 18:50:05.043: [iter 110 : loss : 0.1233 = 0.0331 + 0.0845 + 0.0056, time: 7.087678]
2023-05-15 18:50:05.190: epoch 110:	0.02641894  	0.19415182  	0.10738253  
2023-05-15 18:50:05.190: Find a better model.
2023-05-15 18:50:12.414: [iter 111 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.223677]
2023-05-15 18:50:12.556: epoch 111:	0.02648244  	0.19433095  	0.10760692  
2023-05-15 18:50:12.556: Find a better model.
2023-05-15 18:50:19.806: [iter 112 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0057, time: 7.248140]
2023-05-15 18:50:19.964: epoch 112:	0.02648950  	0.19431859  	0.10764500  
2023-05-15 18:50:27.218: [iter 113 : loss : 0.1229 = 0.0329 + 0.0843 + 0.0057, time: 7.251100]
2023-05-15 18:50:27.372: epoch 113:	0.02646833  	0.19394310  	0.10749689  
2023-05-15 18:50:34.624: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 7.250467]
2023-05-15 18:50:34.780: epoch 114:	0.02653184  	0.19469024  	0.10771213  
2023-05-15 18:50:34.781: Find a better model.
2023-05-15 18:50:41.998: [iter 115 : loss : 0.1217 = 0.0317 + 0.0842 + 0.0058, time: 7.215677]
2023-05-15 18:50:42.152: epoch 115:	0.02647539  	0.19417764  	0.10772236  
2023-05-15 18:50:49.403: [iter 116 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0058, time: 7.250527]
2023-05-15 18:50:49.558: epoch 116:	0.02651067  	0.19424589  	0.10785669  
2023-05-15 18:50:56.797: [iter 117 : loss : 0.1208 = 0.0309 + 0.0841 + 0.0059, time: 7.236964]
2023-05-15 18:50:56.957: epoch 117:	0.02644010  	0.19394995  	0.10786054  
2023-05-15 18:51:04.190: [iter 118 : loss : 0.1209 = 0.0311 + 0.0840 + 0.0059, time: 7.231593]
2023-05-15 18:51:04.341: epoch 118:	0.02649655  	0.19431169  	0.10798900  
2023-05-15 18:51:11.423: [iter 119 : loss : 0.1198 = 0.0299 + 0.0840 + 0.0059, time: 7.081749]
2023-05-15 18:51:11.576: epoch 119:	0.02647539  	0.19399391  	0.10785279  
2023-05-15 18:51:18.811: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 7.234181]
2023-05-15 18:51:18.964: epoch 120:	0.02649656  	0.19431022  	0.10817958  
2023-05-15 18:51:26.189: [iter 121 : loss : 0.1196 = 0.0298 + 0.0838 + 0.0060, time: 7.223633]
2023-05-15 18:51:26.347: epoch 121:	0.02655301  	0.19466549  	0.10837367  
2023-05-15 18:51:33.575: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 7.226775]
2023-05-15 18:51:33.728: epoch 122:	0.02651772  	0.19424446  	0.10833833  
2023-05-15 18:51:40.987: [iter 123 : loss : 0.1189 = 0.0291 + 0.0838 + 0.0061, time: 7.257187]
2023-05-15 18:51:41.143: epoch 123:	0.02650361  	0.19410253  	0.10810960  
2023-05-15 18:51:48.358: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 7.214274]
2023-05-15 18:51:48.511: epoch 124:	0.02644715  	0.19365576  	0.10811605  
2023-05-15 18:51:55.781: [iter 125 : loss : 0.1173 = 0.0275 + 0.0837 + 0.0061, time: 7.268048]
2023-05-15 18:51:55.934: epoch 125:	0.02644010  	0.19384497  	0.10808289  
2023-05-15 18:52:03.178: [iter 126 : loss : 0.1178 = 0.0281 + 0.0836 + 0.0062, time: 7.241633]
2023-05-15 18:52:03.332: epoch 126:	0.02653183  	0.19473603  	0.10842215  
2023-05-15 18:52:03.332: Find a better model.
2023-05-15 18:52:10.565: [iter 127 : loss : 0.1166 = 0.0269 + 0.0836 + 0.0062, time: 7.231541]
2023-05-15 18:52:10.720: epoch 127:	0.02651067  	0.19462238  	0.10844208  
2023-05-15 18:52:17.977: [iter 128 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 7.254646]
2023-05-15 18:52:18.132: epoch 128:	0.02653183  	0.19461343  	0.10858620  
2023-05-15 18:52:25.374: [iter 129 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 7.241057]
2023-05-15 18:52:25.528: epoch 129:	0.02654595  	0.19473153  	0.10878045  
2023-05-15 18:52:32.771: [iter 130 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.242238]
2023-05-15 18:52:32.927: epoch 130:	0.02660945  	0.19539297  	0.10920170  
2023-05-15 18:52:32.927: Find a better model.
2023-05-15 18:52:40.165: [iter 131 : loss : 0.1161 = 0.0264 + 0.0834 + 0.0063, time: 7.235850]
2023-05-15 18:52:40.323: epoch 131:	0.02653889  	0.19484322  	0.10899275  
2023-05-15 18:52:47.587: [iter 132 : loss : 0.1164 = 0.0267 + 0.0833 + 0.0063, time: 7.262458]
2023-05-15 18:52:47.740: epoch 132:	0.02657417  	0.19510312  	0.10907429  
2023-05-15 18:52:54.956: [iter 133 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 7.214442]
2023-05-15 18:52:55.098: epoch 133:	0.02660945  	0.19516848  	0.10912117  
2023-05-15 18:53:02.357: [iter 134 : loss : 0.1158 = 0.0262 + 0.0833 + 0.0064, time: 7.256383]
2023-05-15 18:53:02.513: epoch 134:	0.02664474  	0.19547316  	0.10930458  
2023-05-15 18:53:02.514: Find a better model.
2023-05-15 18:53:09.762: [iter 135 : loss : 0.1155 = 0.0258 + 0.0832 + 0.0064, time: 7.247437]
2023-05-15 18:53:09.915: epoch 135:	0.02672236  	0.19608539  	0.10952996  
2023-05-15 18:53:09.915: Find a better model.
2023-05-15 18:53:17.138: [iter 136 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0065, time: 7.221065]
2023-05-15 18:53:17.297: epoch 136:	0.02670119  	0.19591510  	0.10945327  
2023-05-15 18:53:24.553: [iter 137 : loss : 0.1147 = 0.0250 + 0.0832 + 0.0065, time: 7.254837]
2023-05-15 18:53:24.697: epoch 137:	0.02681410  	0.19666925  	0.10961568  
2023-05-15 18:53:24.697: Find a better model.
2023-05-15 18:53:31.944: [iter 138 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.243896]
2023-05-15 18:53:32.095: epoch 138:	0.02679292  	0.19643824  	0.10966671  
2023-05-15 18:53:39.316: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0065, time: 7.219725]
2023-05-15 18:53:39.461: epoch 139:	0.02670824  	0.19580817  	0.10954433  
2023-05-15 18:53:46.551: [iter 140 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 7.088753]
2023-05-15 18:53:46.695: epoch 140:	0.02679293  	0.19635318  	0.10971513  
2023-05-15 18:53:53.932: [iter 141 : loss : 0.1139 = 0.0244 + 0.0830 + 0.0066, time: 7.235873]
2023-05-15 18:53:54.088: epoch 141:	0.02668708  	0.19545603  	0.10948081  
2023-05-15 18:54:01.333: [iter 142 : loss : 0.1130 = 0.0235 + 0.0829 + 0.0066, time: 7.243332]
2023-05-15 18:54:01.489: epoch 142:	0.02666590  	0.19527507  	0.10943451  
2023-05-15 18:54:08.745: [iter 143 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0066, time: 7.255414]
2023-05-15 18:54:08.899: epoch 143:	0.02674353  	0.19606696  	0.10964663  
2023-05-15 18:54:16.150: [iter 144 : loss : 0.1127 = 0.0232 + 0.0829 + 0.0067, time: 7.248164]
2023-05-15 18:54:16.299: epoch 144:	0.02675058  	0.19598766  	0.10961667  
2023-05-15 18:54:23.504: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 7.202986]
2023-05-15 18:54:23.660: epoch 145:	0.02669413  	0.19565655  	0.10952351  
2023-05-15 18:54:30.918: [iter 146 : loss : 0.1129 = 0.0233 + 0.0828 + 0.0067, time: 7.257854]
2023-05-15 18:54:31.072: epoch 146:	0.02674353  	0.19580559  	0.10953349  
2023-05-15 18:54:38.342: [iter 147 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0068, time: 7.269363]
2023-05-15 18:54:38.499: epoch 147:	0.02667297  	0.19513696  	0.10951479  
2023-05-15 18:54:45.713: [iter 148 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0068, time: 7.212866]
2023-05-15 18:54:45.856: epoch 148:	0.02664474  	0.19487689  	0.10942091  
2023-05-15 18:54:53.283: [iter 149 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 7.425843]
2023-05-15 18:54:53.430: epoch 149:	0.02660240  	0.19429947  	0.10911267  
2023-05-15 18:55:00.715: [iter 150 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0068, time: 7.284281]
2023-05-15 18:55:00.858: epoch 150:	0.02658123  	0.19427222  	0.10929850  
2023-05-15 18:55:08.276: [iter 151 : loss : 0.1113 = 0.0218 + 0.0826 + 0.0069, time: 7.416277]
2023-05-15 18:55:08.438: epoch 151:	0.02658123  	0.19413608  	0.10927037  
2023-05-15 18:55:15.734: [iter 152 : loss : 0.1107 = 0.0212 + 0.0826 + 0.0069, time: 7.295739]
2023-05-15 18:55:15.878: epoch 152:	0.02660240  	0.19475767  	0.10948025  
2023-05-15 18:55:23.128: [iter 153 : loss : 0.1099 = 0.0204 + 0.0826 + 0.0069, time: 7.249302]
2023-05-15 18:55:23.272: epoch 153:	0.02659534  	0.19478570  	0.10926268  
2023-05-15 18:55:30.501: [iter 154 : loss : 0.1104 = 0.0209 + 0.0826 + 0.0069, time: 7.227207]
2023-05-15 18:55:30.656: epoch 154:	0.02667296  	0.19521801  	0.10948544  
2023-05-15 18:55:37.927: [iter 155 : loss : 0.1110 = 0.0215 + 0.0825 + 0.0070, time: 7.270178]
2023-05-15 18:55:38.080: epoch 155:	0.02669413  	0.19533102  	0.10959117  
2023-05-15 18:55:45.317: [iter 156 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0070, time: 7.235721]
2023-05-15 18:55:45.473: epoch 156:	0.02667296  	0.19498977  	0.10948256  
2023-05-15 18:55:52.681: [iter 157 : loss : 0.1102 = 0.0207 + 0.0824 + 0.0070, time: 7.206287]
2023-05-15 18:55:52.836: epoch 157:	0.02662357  	0.19477816  	0.10941304  
2023-05-15 18:56:00.087: [iter 158 : loss : 0.1094 = 0.0200 + 0.0824 + 0.0070, time: 7.250360]
2023-05-15 18:56:00.242: epoch 158:	0.02675764  	0.19551000  	0.10969930  
2023-05-15 18:56:07.509: [iter 159 : loss : 0.1098 = 0.0204 + 0.0824 + 0.0071, time: 7.265243]
2023-05-15 18:56:07.663: epoch 159:	0.02668002  	0.19479136  	0.10949740  
2023-05-15 18:56:14.887: [iter 160 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.222452]
2023-05-15 18:56:15.041: epoch 160:	0.02663768  	0.19458501  	0.10940900  
2023-05-15 18:56:22.302: [iter 161 : loss : 0.1091 = 0.0196 + 0.0823 + 0.0071, time: 7.259103]
2023-05-15 18:56:22.458: epoch 161:	0.02668002  	0.19493684  	0.10951941  
2023-05-15 18:56:29.678: [iter 162 : loss : 0.1083 = 0.0189 + 0.0823 + 0.0071, time: 7.219380]
2023-05-15 18:56:29.821: epoch 162:	0.02672941  	0.19558305  	0.10972404  
2023-05-15 18:56:29.821: Early stopping is trigger at epoch: 162
2023-05-15 18:56:29.821: best_result@epoch 137:

2023-05-15 18:56:29.821: 		0.0268      	0.1967      	0.1096      
2023-05-15 19:28:10.558: my pid: 9232
2023-05-15 19:28:10.558: model: model.general_recommender.SGL
2023-05-15 19:28:10.558: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 19:28:10.558: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 19:28:13.609: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 19:28:21.642: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.032871]
2023-05-15 19:28:21.798: epoch 1:	0.00142535  	0.01044807  	0.00506349  
2023-05-15 19:28:21.799: Find a better model.
2023-05-15 19:28:30.069: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.268915]
2023-05-15 19:28:30.261: epoch 2:	0.00261784  	0.02013542  	0.00957268  
2023-05-15 19:28:30.261: Find a better model.
2023-05-15 19:28:38.502: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.240537]
2023-05-15 19:28:38.677: epoch 3:	0.00496751  	0.03832722  	0.01839532  
2023-05-15 19:28:38.677: Find a better model.
2023-05-15 19:28:46.628: [iter 4 : loss : 0.7706 = 0.6920 + 0.0787 + 0.0000, time: 7.950078]
2023-05-15 19:28:46.801: epoch 4:	0.00818509  	0.06069654  	0.02915565  
2023-05-15 19:28:46.801: Find a better model.
2023-05-15 19:28:54.675: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 7.873057]
2023-05-15 19:28:54.839: epoch 5:	0.01173444  	0.08494820  	0.04021648  
2023-05-15 19:28:54.839: Find a better model.
2023-05-15 19:29:02.649: [iter 6 : loss : 0.7671 = 0.6878 + 0.0792 + 0.0000, time: 7.807466]
2023-05-15 19:29:02.803: epoch 6:	0.01526267  	0.11027837  	0.05302531  
2023-05-15 19:29:02.803: Find a better model.
2023-05-15 19:29:10.449: [iter 7 : loss : 0.7603 = 0.6803 + 0.0800 + 0.0000, time: 7.645069]
2023-05-15 19:29:10.604: epoch 7:	0.01776064  	0.12921359  	0.06370532  
2023-05-15 19:29:10.604: Find a better model.
2023-05-15 19:29:18.226: [iter 8 : loss : 0.7438 = 0.6617 + 0.0820 + 0.0001, time: 7.621705]
2023-05-15 19:29:18.385: epoch 8:	0.01900962  	0.13874929  	0.06920888  
2023-05-15 19:29:18.385: Find a better model.
2023-05-15 19:29:25.819: [iter 9 : loss : 0.7070 = 0.6208 + 0.0860 + 0.0001, time: 7.431466]
2023-05-15 19:29:25.975: epoch 9:	0.01874854  	0.13826552  	0.06896963  
2023-05-15 19:29:33.309: [iter 10 : loss : 0.6446 = 0.5529 + 0.0914 + 0.0003, time: 7.332640]
2023-05-15 19:29:33.467: epoch 10:	0.01861446  	0.13756564  	0.06850779  
2023-05-15 19:29:40.825: [iter 11 : loss : 0.5690 = 0.4723 + 0.0963 + 0.0004, time: 7.356349]
2023-05-15 19:29:40.982: epoch 11:	0.01833925  	0.13534638  	0.06788567  
2023-05-15 19:29:48.410: [iter 12 : loss : 0.5012 = 0.4011 + 0.0995 + 0.0006, time: 7.427454]
2023-05-15 19:29:48.567: epoch 12:	0.01840982  	0.13590361  	0.06844813  
2023-05-15 19:29:56.192: [iter 13 : loss : 0.4513 = 0.3493 + 0.1013 + 0.0007, time: 7.623485]
2023-05-15 19:29:56.345: epoch 13:	0.01846627  	0.13656929  	0.06884013  
2023-05-15 19:30:03.811: [iter 14 : loss : 0.4134 = 0.3105 + 0.1021 + 0.0009, time: 7.463675]
2023-05-15 19:30:03.966: epoch 14:	0.01869207  	0.13833189  	0.06984531  
2023-05-15 19:30:11.397: [iter 15 : loss : 0.3871 = 0.2837 + 0.1024 + 0.0010, time: 7.428753]
2023-05-15 19:30:11.539: epoch 15:	0.01884732  	0.13992333  	0.07087907  
2023-05-15 19:30:11.539: Find a better model.
2023-05-15 19:30:18.978: [iter 16 : loss : 0.3649 = 0.2614 + 0.1024 + 0.0011, time: 7.437372]
2023-05-15 19:30:19.133: epoch 16:	0.01891083  	0.14006841  	0.07129649  
2023-05-15 19:30:19.133: Find a better model.
2023-05-15 19:30:26.616: [iter 17 : loss : 0.3487 = 0.2453 + 0.1022 + 0.0012, time: 7.481394]
2023-05-15 19:30:26.773: epoch 17:	0.01907312  	0.14115959  	0.07217893  
2023-05-15 19:30:26.773: Find a better model.
2023-05-15 19:30:34.200: [iter 18 : loss : 0.3335 = 0.2302 + 0.1020 + 0.0013, time: 7.425575]
2023-05-15 19:30:34.355: epoch 18:	0.01927776  	0.14247684  	0.07278280  
2023-05-15 19:30:34.355: Find a better model.
2023-05-15 19:30:41.740: [iter 19 : loss : 0.3195 = 0.2164 + 0.1017 + 0.0014, time: 7.383394]
2023-05-15 19:30:41.895: epoch 19:	0.01953886  	0.14397997  	0.07369597  
2023-05-15 19:30:41.895: Find a better model.
2023-05-15 19:30:49.187: [iter 20 : loss : 0.3097 = 0.2069 + 0.1013 + 0.0015, time: 7.290101]
2023-05-15 19:30:49.332: epoch 20:	0.01975761  	0.14550816  	0.07452391  
2023-05-15 19:30:49.332: Find a better model.
2023-05-15 19:30:56.595: [iter 21 : loss : 0.3000 = 0.1976 + 0.1008 + 0.0016, time: 7.262375]
2023-05-15 19:30:56.751: epoch 21:	0.01998342  	0.14748663  	0.07552969  
2023-05-15 19:30:56.752: Find a better model.
2023-05-15 19:31:04.156: [iter 22 : loss : 0.2917 = 0.1896 + 0.1004 + 0.0017, time: 7.402831]
2023-05-15 19:31:04.299: epoch 22:	0.02023746  	0.14945152  	0.07635725  
2023-05-15 19:31:04.299: Find a better model.
2023-05-15 19:31:11.582: [iter 23 : loss : 0.2836 = 0.1818 + 0.1001 + 0.0017, time: 7.281273]
2023-05-15 19:31:11.741: epoch 23:	0.02039976  	0.15046807  	0.07696891  
2023-05-15 19:31:11.741: Find a better model.
2023-05-15 19:31:19.173: [iter 24 : loss : 0.2771 = 0.1758 + 0.0996 + 0.0018, time: 7.430953]
2023-05-15 19:31:19.329: epoch 24:	0.02059733  	0.15179247  	0.07759689  
2023-05-15 19:31:19.329: Find a better model.
2023-05-15 19:31:26.731: [iter 25 : loss : 0.2706 = 0.1696 + 0.0992 + 0.0019, time: 7.400650]
2023-05-15 19:31:26.888: epoch 25:	0.02077375  	0.15332483  	0.07838029  
2023-05-15 19:31:26.888: Find a better model.
2023-05-15 19:31:34.175: [iter 26 : loss : 0.2667 = 0.1660 + 0.0988 + 0.0019, time: 7.285376]
2023-05-15 19:31:34.332: epoch 26:	0.02095016  	0.15431458  	0.07898358  
2023-05-15 19:31:34.332: Find a better model.
2023-05-15 19:31:41.753: [iter 27 : loss : 0.2591 = 0.1587 + 0.0983 + 0.0020, time: 7.419657]
2023-05-15 19:31:41.897: epoch 27:	0.02115480  	0.15534849  	0.08002287  
2023-05-15 19:31:41.897: Find a better model.
2023-05-15 19:31:49.140: [iter 28 : loss : 0.2542 = 0.1541 + 0.0979 + 0.0021, time: 7.242190]
2023-05-15 19:31:49.281: epoch 28:	0.02133827  	0.15637417  	0.08081898  
2023-05-15 19:31:49.282: Find a better model.
2023-05-15 19:31:56.561: [iter 29 : loss : 0.2499 = 0.1503 + 0.0975 + 0.0021, time: 7.277597]
2023-05-15 19:31:56.706: epoch 29:	0.02147235  	0.15771066  	0.08141202  
2023-05-15 19:31:56.707: Find a better model.
2023-05-15 19:32:03.962: [iter 30 : loss : 0.2432 = 0.1438 + 0.0972 + 0.0022, time: 7.254515]
2023-05-15 19:32:04.116: epoch 30:	0.02173345  	0.16013294  	0.08232702  
2023-05-15 19:32:04.116: Find a better model.
2023-05-15 19:32:11.500: [iter 31 : loss : 0.2397 = 0.1407 + 0.0968 + 0.0023, time: 7.383238]
2023-05-15 19:32:11.656: epoch 31:	0.02182518  	0.16067931  	0.08284794  
2023-05-15 19:32:11.656: Find a better model.
2023-05-15 19:32:19.167: [iter 32 : loss : 0.2342 = 0.1354 + 0.0965 + 0.0023, time: 7.508949]
2023-05-15 19:32:19.311: epoch 32:	0.02205805  	0.16245331  	0.08382875  
2023-05-15 19:32:19.311: Find a better model.
2023-05-15 19:32:26.758: [iter 33 : loss : 0.2313 = 0.1330 + 0.0960 + 0.0024, time: 7.445996]
2023-05-15 19:32:26.915: epoch 33:	0.02214273  	0.16285662  	0.08438221  
2023-05-15 19:32:26.915: Find a better model.
2023-05-15 19:32:34.515: [iter 34 : loss : 0.2274 = 0.1293 + 0.0957 + 0.0024, time: 7.598711]
2023-05-15 19:32:34.670: epoch 34:	0.02236148  	0.16452639  	0.08526005  
2023-05-15 19:32:34.670: Find a better model.
2023-05-15 19:32:42.378: [iter 35 : loss : 0.2238 = 0.1259 + 0.0954 + 0.0025, time: 7.706731]
2023-05-15 19:32:42.536: epoch 35:	0.02253083  	0.16579944  	0.08604060  
2023-05-15 19:32:42.536: Find a better model.
2023-05-15 19:32:49.942: [iter 36 : loss : 0.2203 = 0.1227 + 0.0951 + 0.0026, time: 7.404895]
2023-05-15 19:32:50.086: epoch 36:	0.02277780  	0.16775067  	0.08700234  
2023-05-15 19:32:50.086: Find a better model.
2023-05-15 19:32:57.504: [iter 37 : loss : 0.2168 = 0.1194 + 0.0948 + 0.0026, time: 7.415351]
2023-05-15 19:32:57.660: epoch 37:	0.02289071  	0.16846396  	0.08758058  
2023-05-15 19:32:57.660: Find a better model.
2023-05-15 19:33:04.950: [iter 38 : loss : 0.2152 = 0.1181 + 0.0945 + 0.0027, time: 7.289286]
2023-05-15 19:33:05.105: epoch 38:	0.02313063  	0.17053558  	0.08861826  
2023-05-15 19:33:05.105: Find a better model.
2023-05-15 19:33:12.546: [iter 39 : loss : 0.2106 = 0.1138 + 0.0941 + 0.0027, time: 7.439193]
2023-05-15 19:33:12.702: epoch 39:	0.02317297  	0.17063028  	0.08908835  
2023-05-15 19:33:12.702: Find a better model.
2023-05-15 19:33:20.088: [iter 40 : loss : 0.2074 = 0.1107 + 0.0938 + 0.0028, time: 7.383774]
2023-05-15 19:33:20.246: epoch 40:	0.02328587  	0.17156488  	0.08953948  
2023-05-15 19:33:20.246: Find a better model.
2023-05-15 19:33:27.540: [iter 41 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 7.292133]
2023-05-15 19:33:27.694: epoch 41:	0.02338467  	0.17216358  	0.09004137  
2023-05-15 19:33:27.694: Find a better model.
2023-05-15 19:33:35.126: [iter 42 : loss : 0.2035 = 0.1073 + 0.0933 + 0.0029, time: 7.429979]
2023-05-15 19:33:35.280: epoch 42:	0.02345522  	0.17301454  	0.09063473  
2023-05-15 19:33:35.280: Find a better model.
2023-05-15 19:33:42.712: [iter 43 : loss : 0.1995 = 0.1036 + 0.0930 + 0.0029, time: 7.431740]
2023-05-15 19:33:42.867: epoch 43:	0.02365987  	0.17399924  	0.09124424  
2023-05-15 19:33:42.867: Find a better model.
2023-05-15 19:33:50.320: [iter 44 : loss : 0.1960 = 0.1004 + 0.0927 + 0.0030, time: 7.451443]
2023-05-15 19:33:50.478: epoch 44:	0.02368809  	0.17443208  	0.09180231  
2023-05-15 19:33:50.478: Find a better model.
2023-05-15 19:33:57.732: [iter 45 : loss : 0.1939 = 0.0984 + 0.0925 + 0.0030, time: 7.252121]
2023-05-15 19:33:57.886: epoch 45:	0.02384333  	0.17535941  	0.09273581  
2023-05-15 19:33:57.886: Find a better model.
2023-05-15 19:34:05.284: [iter 46 : loss : 0.1913 = 0.0960 + 0.0922 + 0.0031, time: 7.396785]
2023-05-15 19:34:05.439: epoch 46:	0.02392801  	0.17579979  	0.09309790  
2023-05-15 19:34:05.439: Find a better model.
2023-05-15 19:34:12.900: [iter 47 : loss : 0.1909 = 0.0958 + 0.0920 + 0.0031, time: 7.459866]
2023-05-15 19:34:13.052: epoch 47:	0.02397034  	0.17645834  	0.09354620  
2023-05-15 19:34:13.052: Find a better model.
2023-05-15 19:34:20.555: [iter 48 : loss : 0.1868 = 0.0919 + 0.0917 + 0.0032, time: 7.501436]
2023-05-15 19:34:20.700: epoch 48:	0.02399151  	0.17628163  	0.09363654  
2023-05-15 19:34:27.900: [iter 49 : loss : 0.1839 = 0.0891 + 0.0916 + 0.0032, time: 7.197814]
2023-05-15 19:34:28.057: epoch 49:	0.02411852  	0.17737168  	0.09398424  
2023-05-15 19:34:28.058: Find a better model.
2023-05-15 19:34:35.563: [iter 50 : loss : 0.1831 = 0.0885 + 0.0913 + 0.0033, time: 7.503609]
2023-05-15 19:34:35.719: epoch 50:	0.02420320  	0.17763630  	0.09454546  
2023-05-15 19:34:35.719: Find a better model.
2023-05-15 19:34:43.108: [iter 51 : loss : 0.1799 = 0.0854 + 0.0912 + 0.0033, time: 7.388774]
2023-05-15 19:34:43.260: epoch 51:	0.02436550  	0.17924117  	0.09518009  
2023-05-15 19:34:43.260: Find a better model.
2023-05-15 19:34:50.684: [iter 52 : loss : 0.1800 = 0.0856 + 0.0910 + 0.0034, time: 7.422924]
2023-05-15 19:34:50.839: epoch 52:	0.02442901  	0.17956105  	0.09546416  
2023-05-15 19:34:50.839: Find a better model.
2023-05-15 19:34:58.111: [iter 53 : loss : 0.1779 = 0.0838 + 0.0907 + 0.0034, time: 7.269914]
2023-05-15 19:34:58.255: epoch 53:	0.02435844  	0.17908113  	0.09559260  
2023-05-15 19:35:05.506: [iter 54 : loss : 0.1757 = 0.0817 + 0.0905 + 0.0035, time: 7.249099]
2023-05-15 19:35:05.661: epoch 54:	0.02454191  	0.18030125  	0.09622999  
2023-05-15 19:35:05.661: Find a better model.
2023-05-15 19:35:13.040: [iter 55 : loss : 0.1739 = 0.0800 + 0.0904 + 0.0035, time: 7.376256]
2023-05-15 19:35:13.183: epoch 55:	0.02453486  	0.18011530  	0.09629907  
2023-05-15 19:35:20.494: [iter 56 : loss : 0.1721 = 0.0784 + 0.0902 + 0.0035, time: 7.309637]
2023-05-15 19:35:20.636: epoch 56:	0.02456309  	0.18037961  	0.09669371  
2023-05-15 19:35:20.636: Find a better model.
2023-05-15 19:35:27.886: [iter 57 : loss : 0.1702 = 0.0766 + 0.0900 + 0.0036, time: 7.246966]
2023-05-15 19:35:28.042: epoch 57:	0.02464071  	0.18115208  	0.09708238  
2023-05-15 19:35:28.042: Find a better model.
2023-05-15 19:35:35.263: [iter 58 : loss : 0.1684 = 0.0750 + 0.0898 + 0.0036, time: 7.219061]
2023-05-15 19:35:35.407: epoch 58:	0.02462659  	0.18100764  	0.09714646  
2023-05-15 19:35:42.678: [iter 59 : loss : 0.1674 = 0.0740 + 0.0896 + 0.0037, time: 7.268891]
2023-05-15 19:35:42.836: epoch 59:	0.02473244  	0.18176417  	0.09758545  
2023-05-15 19:35:42.836: Find a better model.
2023-05-15 19:35:50.090: [iter 60 : loss : 0.1658 = 0.0726 + 0.0894 + 0.0037, time: 7.252180]
2023-05-15 19:35:50.244: epoch 60:	0.02488768  	0.18265136  	0.09841248  
2023-05-15 19:35:50.244: Find a better model.
2023-05-15 19:35:57.641: [iter 61 : loss : 0.1644 = 0.0713 + 0.0893 + 0.0038, time: 7.395744]
2023-05-15 19:35:57.797: epoch 61:	0.02495119  	0.18360400  	0.09872865  
2023-05-15 19:35:57.798: Find a better model.
2023-05-15 19:36:05.078: [iter 62 : loss : 0.1629 = 0.0699 + 0.0891 + 0.0038, time: 7.279263]
2023-05-15 19:36:05.222: epoch 62:	0.02495825  	0.18346019  	0.09887122  
2023-05-15 19:36:12.662: [iter 63 : loss : 0.1617 = 0.0689 + 0.0890 + 0.0039, time: 7.438242]
2023-05-15 19:36:12.817: epoch 63:	0.02512054  	0.18446675  	0.09935537  
2023-05-15 19:36:12.817: Find a better model.
2023-05-15 19:36:20.055: [iter 64 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 7.235418]
2023-05-15 19:36:20.209: epoch 64:	0.02517699  	0.18496543  	0.09978801  
2023-05-15 19:36:20.210: Find a better model.
2023-05-15 19:36:27.669: [iter 65 : loss : 0.1592 = 0.0666 + 0.0886 + 0.0040, time: 7.457276]
2023-05-15 19:36:27.831: epoch 65:	0.02523344  	0.18560365  	0.10032228  
2023-05-15 19:36:27.831: Find a better model.
2023-05-15 19:36:35.065: [iter 66 : loss : 0.1577 = 0.0652 + 0.0885 + 0.0040, time: 7.233491]
2023-05-15 19:36:35.218: epoch 66:	0.02516994  	0.18509658  	0.10025964  
2023-05-15 19:36:42.442: [iter 67 : loss : 0.1562 = 0.0638 + 0.0884 + 0.0040, time: 7.222591]
2023-05-15 19:36:42.587: epoch 67:	0.02518405  	0.18489122  	0.10046854  
2023-05-15 19:36:49.837: [iter 68 : loss : 0.1561 = 0.0638 + 0.0882 + 0.0041, time: 7.249647]
2023-05-15 19:36:49.993: epoch 68:	0.02528284  	0.18567295  	0.10082316  
2023-05-15 19:36:49.994: Find a better model.
2023-05-15 19:36:57.269: [iter 69 : loss : 0.1537 = 0.0615 + 0.0881 + 0.0041, time: 7.269563]
2023-05-15 19:36:57.422: epoch 69:	0.02538163  	0.18656451  	0.10112886  
2023-05-15 19:36:57.422: Find a better model.
2023-05-15 19:37:04.655: [iter 70 : loss : 0.1525 = 0.0603 + 0.0880 + 0.0042, time: 7.230509]
2023-05-15 19:37:04.814: epoch 70:	0.02540986  	0.18707052  	0.10139003  
2023-05-15 19:37:04.814: Find a better model.
2023-05-15 19:37:12.060: [iter 71 : loss : 0.1510 = 0.0589 + 0.0879 + 0.0042, time: 7.245615]
2023-05-15 19:37:12.217: epoch 71:	0.02548042  	0.18783873  	0.10168164  
2023-05-15 19:37:12.217: Find a better model.
2023-05-15 19:37:19.648: [iter 72 : loss : 0.1508 = 0.0588 + 0.0877 + 0.0042, time: 7.429106]
2023-05-15 19:37:19.791: epoch 72:	0.02560038  	0.18858717  	0.10198277  
2023-05-15 19:37:19.791: Find a better model.
2023-05-15 19:37:27.042: [iter 73 : loss : 0.1494 = 0.0575 + 0.0876 + 0.0043, time: 7.248903]
2023-05-15 19:37:27.195: epoch 73:	0.02555805  	0.18844876  	0.10211243  
2023-05-15 19:37:34.467: [iter 74 : loss : 0.1479 = 0.0560 + 0.0875 + 0.0043, time: 7.270308]
2023-05-15 19:37:34.624: epoch 74:	0.02562860  	0.18888818  	0.10241151  
2023-05-15 19:37:34.624: Find a better model.
2023-05-15 19:37:41.857: [iter 75 : loss : 0.1474 = 0.0557 + 0.0873 + 0.0044, time: 7.231308]
2023-05-15 19:37:42.015: epoch 75:	0.02567800  	0.18907145  	0.10254215  
2023-05-15 19:37:42.016: Find a better model.
2023-05-15 19:37:49.220: [iter 76 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 7.203381]
2023-05-15 19:37:49.365: epoch 76:	0.02571328  	0.18908811  	0.10275074  
2023-05-15 19:37:49.365: Find a better model.
2023-05-15 19:37:56.635: [iter 77 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0044, time: 7.269205]
2023-05-15 19:37:56.779: epoch 77:	0.02574857  	0.18961385  	0.10310885  
2023-05-15 19:37:56.779: Find a better model.
2023-05-15 19:38:04.022: [iter 78 : loss : 0.1447 = 0.0532 + 0.0871 + 0.0045, time: 7.241115]
2023-05-15 19:38:04.167: epoch 78:	0.02569212  	0.18878232  	0.10297603  
2023-05-15 19:38:11.393: [iter 79 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0045, time: 7.224747]
2023-05-15 19:38:11.552: epoch 79:	0.02571329  	0.18904173  	0.10303447  
2023-05-15 19:38:18.839: [iter 80 : loss : 0.1426 = 0.0513 + 0.0868 + 0.0046, time: 7.285773]
2023-05-15 19:38:18.999: epoch 80:	0.02577680  	0.18943578  	0.10325959  
2023-05-15 19:38:26.245: [iter 81 : loss : 0.1422 = 0.0510 + 0.0867 + 0.0046, time: 7.244747]
2023-05-15 19:38:26.399: epoch 81:	0.02579797  	0.18997176  	0.10342009  
2023-05-15 19:38:26.399: Find a better model.
2023-05-15 19:38:33.785: [iter 82 : loss : 0.1411 = 0.0499 + 0.0866 + 0.0046, time: 7.383765]
2023-05-15 19:38:33.943: epoch 82:	0.02585441  	0.19040945  	0.10381030  
2023-05-15 19:38:33.943: Find a better model.
2023-05-15 19:38:41.210: [iter 83 : loss : 0.1398 = 0.0486 + 0.0865 + 0.0047, time: 7.263542]
2023-05-15 19:38:41.365: epoch 83:	0.02591792  	0.19067018  	0.10417552  
2023-05-15 19:38:41.365: Find a better model.
2023-05-15 19:38:48.633: [iter 84 : loss : 0.1400 = 0.0489 + 0.0864 + 0.0047, time: 7.267147]
2023-05-15 19:38:48.779: epoch 84:	0.02596026  	0.19099939  	0.10445583  
2023-05-15 19:38:48.779: Find a better model.
2023-05-15 19:38:55.992: [iter 85 : loss : 0.1390 = 0.0479 + 0.0863 + 0.0048, time: 7.211560]
2023-05-15 19:38:56.147: epoch 85:	0.02608022  	0.19188111  	0.10491946  
2023-05-15 19:38:56.147: Find a better model.
2023-05-15 19:39:03.387: [iter 86 : loss : 0.1388 = 0.0478 + 0.0862 + 0.0048, time: 7.239676]
2023-05-15 19:39:03.541: epoch 86:	0.02604494  	0.19156711  	0.10490047  
2023-05-15 19:39:10.828: [iter 87 : loss : 0.1361 = 0.0452 + 0.0861 + 0.0048, time: 7.285641]
2023-05-15 19:39:10.989: epoch 87:	0.02614373  	0.19223714  	0.10536477  
2023-05-15 19:39:10.989: Find a better model.
2023-05-15 19:39:18.197: [iter 88 : loss : 0.1354 = 0.0445 + 0.0860 + 0.0049, time: 7.207113]
2023-05-15 19:39:18.351: epoch 88:	0.02615784  	0.19199626  	0.10552305  
2023-05-15 19:39:25.614: [iter 89 : loss : 0.1352 = 0.0444 + 0.0859 + 0.0049, time: 7.262282]
2023-05-15 19:39:25.768: epoch 89:	0.02608022  	0.19151770  	0.10532670  
2023-05-15 19:39:33.012: [iter 90 : loss : 0.1355 = 0.0447 + 0.0859 + 0.0050, time: 7.241018]
2023-05-15 19:39:33.167: epoch 90:	0.02617196  	0.19242179  	0.10572350  
2023-05-15 19:39:33.167: Find a better model.
2023-05-15 19:39:40.392: [iter 91 : loss : 0.1344 = 0.0437 + 0.0858 + 0.0050, time: 7.223844]
2023-05-15 19:39:40.545: epoch 91:	0.02615079  	0.19243023  	0.10568052  
2023-05-15 19:39:40.545: Find a better model.
2023-05-15 19:39:47.795: [iter 92 : loss : 0.1336 = 0.0429 + 0.0857 + 0.0050, time: 7.248596]
2023-05-15 19:39:47.939: epoch 92:	0.02612962  	0.19171387  	0.10571768  
2023-05-15 19:39:55.194: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 7.254307]
2023-05-15 19:39:55.351: epoch 93:	0.02616490  	0.19203459  	0.10582219  
2023-05-15 19:40:02.563: [iter 94 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 7.210847]
2023-05-15 19:40:02.705: epoch 94:	0.02630603  	0.19310001  	0.10605636  
2023-05-15 19:40:02.705: Find a better model.
2023-05-15 19:40:09.996: [iter 95 : loss : 0.1311 = 0.0405 + 0.0854 + 0.0051, time: 7.288903]
2023-05-15 19:40:10.152: epoch 95:	0.02629897  	0.19308099  	0.10623454  
2023-05-15 19:40:17.409: [iter 96 : loss : 0.1311 = 0.0406 + 0.0854 + 0.0052, time: 7.255519]
2023-05-15 19:40:17.565: epoch 96:	0.02633426  	0.19333197  	0.10614765  
2023-05-15 19:40:17.565: Find a better model.
2023-05-15 19:40:24.788: [iter 97 : loss : 0.1296 = 0.0391 + 0.0853 + 0.0052, time: 7.222180]
2023-05-15 19:40:24.943: epoch 97:	0.02638366  	0.19366612  	0.10639771  
2023-05-15 19:40:24.943: Find a better model.
2023-05-15 19:40:32.210: [iter 98 : loss : 0.1302 = 0.0397 + 0.0852 + 0.0052, time: 7.264938]
2023-05-15 19:40:32.363: epoch 98:	0.02644716  	0.19380239  	0.10666019  
2023-05-15 19:40:32.363: Find a better model.
2023-05-15 19:40:39.599: [iter 99 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 7.233801]
2023-05-15 19:40:39.753: epoch 99:	0.02648244  	0.19422789  	0.10688025  
2023-05-15 19:40:39.753: Find a better model.
2023-05-15 19:40:46.959: [iter 100 : loss : 0.1284 = 0.0380 + 0.0850 + 0.0053, time: 7.205830]
2023-05-15 19:40:47.103: epoch 100:	0.02644716  	0.19416620  	0.10690161  
2023-05-15 19:40:54.401: [iter 101 : loss : 0.1282 = 0.0378 + 0.0850 + 0.0054, time: 7.295232]
2023-05-15 19:40:54.553: epoch 101:	0.02656712  	0.19533932  	0.10734927  
2023-05-15 19:40:54.553: Find a better model.
2023-05-15 19:41:01.971: [iter 102 : loss : 0.1270 = 0.0367 + 0.0849 + 0.0054, time: 7.414663]
2023-05-15 19:41:02.113: epoch 102:	0.02658123  	0.19544348  	0.10743877  
2023-05-15 19:41:02.113: Find a better model.
2023-05-15 19:41:09.364: [iter 103 : loss : 0.1269 = 0.0367 + 0.0849 + 0.0054, time: 7.250310]
2023-05-15 19:41:09.520: epoch 103:	0.02658828  	0.19535576  	0.10737407  
2023-05-15 19:41:16.966: [iter 104 : loss : 0.1276 = 0.0373 + 0.0848 + 0.0055, time: 7.444658]
2023-05-15 19:41:17.123: epoch 104:	0.02657418  	0.19551483  	0.10754354  
2023-05-15 19:41:17.123: Find a better model.
2023-05-15 19:41:24.362: [iter 105 : loss : 0.1267 = 0.0365 + 0.0847 + 0.0055, time: 7.237352]
2023-05-15 19:41:24.507: epoch 105:	0.02658829  	0.19574703  	0.10771286  
2023-05-15 19:41:24.507: Find a better model.
2023-05-15 19:41:31.924: [iter 106 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 7.415839]
2023-05-15 19:41:32.082: epoch 106:	0.02662357  	0.19587320  	0.10788478  
2023-05-15 19:41:32.082: Find a better model.
2023-05-15 19:41:39.379: [iter 107 : loss : 0.1252 = 0.0351 + 0.0846 + 0.0056, time: 7.295851]
2023-05-15 19:41:39.521: epoch 107:	0.02666591  	0.19608268  	0.10797784  
2023-05-15 19:41:39.522: Find a better model.
2023-05-15 19:41:46.970: [iter 108 : loss : 0.1251 = 0.0350 + 0.0846 + 0.0056, time: 7.446920]
2023-05-15 19:41:47.127: epoch 108:	0.02672236  	0.19673735  	0.10823072  
2023-05-15 19:41:47.127: Find a better model.
2023-05-15 19:41:54.518: [iter 109 : loss : 0.1236 = 0.0336 + 0.0845 + 0.0056, time: 7.389585]
2023-05-15 19:41:54.675: epoch 109:	0.02672236  	0.19678439  	0.10838278  
2023-05-15 19:41:54.675: Find a better model.
2023-05-15 19:42:02.125: [iter 110 : loss : 0.1230 = 0.0329 + 0.0844 + 0.0057, time: 7.449013]
2023-05-15 19:42:02.271: epoch 110:	0.02675764  	0.19654581  	0.10835385  
2023-05-15 19:42:09.565: [iter 111 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.290759]
2023-05-15 19:42:09.719: epoch 111:	0.02669413  	0.19644621  	0.10830732  
2023-05-15 19:42:17.143: [iter 112 : loss : 0.1228 = 0.0328 + 0.0843 + 0.0057, time: 7.422877]
2023-05-15 19:42:17.298: epoch 112:	0.02665885  	0.19587669  	0.10823163  
2023-05-15 19:42:24.572: [iter 113 : loss : 0.1227 = 0.0327 + 0.0842 + 0.0058, time: 7.272950]
2023-05-15 19:42:24.718: epoch 113:	0.02665179  	0.19601643  	0.10840431  
2023-05-15 19:42:32.130: [iter 114 : loss : 0.1218 = 0.0319 + 0.0842 + 0.0058, time: 7.409883]
2023-05-15 19:42:32.290: epoch 114:	0.02663063  	0.19594227  	0.10831553  
2023-05-15 19:42:39.525: [iter 115 : loss : 0.1215 = 0.0316 + 0.0841 + 0.0058, time: 7.233247]
2023-05-15 19:42:39.680: epoch 115:	0.02656006  	0.19537477  	0.10825956  
2023-05-15 19:42:46.956: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 7.272804]
2023-05-15 19:42:47.109: epoch 116:	0.02651772  	0.19501168  	0.10812156  
2023-05-15 19:42:54.516: [iter 117 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.405272]
2023-05-15 19:42:54.660: epoch 117:	0.02666591  	0.19643356  	0.10847612  
2023-05-15 19:43:01.933: [iter 118 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.270666]
2023-05-15 19:43:02.080: epoch 118:	0.02663768  	0.19605196  	0.10853435  
2023-05-15 19:43:09.333: [iter 119 : loss : 0.1193 = 0.0294 + 0.0839 + 0.0060, time: 7.251001]
2023-05-15 19:43:09.476: epoch 119:	0.02669413  	0.19654521  	0.10863403  
2023-05-15 19:43:16.748: [iter 120 : loss : 0.1198 = 0.0299 + 0.0838 + 0.0060, time: 7.269379]
2023-05-15 19:43:16.901: epoch 120:	0.02669413  	0.19654424  	0.10871141  
2023-05-15 19:43:24.109: [iter 121 : loss : 0.1197 = 0.0298 + 0.0838 + 0.0060, time: 7.205962]
2023-05-15 19:43:24.261: epoch 121:	0.02671530  	0.19638333  	0.10875113  
2023-05-15 19:43:31.543: [iter 122 : loss : 0.1189 = 0.0291 + 0.0838 + 0.0060, time: 7.279385]
2023-05-15 19:43:31.700: epoch 122:	0.02667296  	0.19614181  	0.10870636  
2023-05-15 19:43:38.935: [iter 123 : loss : 0.1189 = 0.0291 + 0.0837 + 0.0061, time: 7.233959]
2023-05-15 19:43:39.080: epoch 123:	0.02676468  	0.19664581  	0.10888413  
2023-05-15 19:43:46.317: [iter 124 : loss : 0.1179 = 0.0281 + 0.0837 + 0.0061, time: 7.235768]
2023-05-15 19:43:46.476: epoch 124:	0.02676469  	0.19672933  	0.10874397  
2023-05-15 19:43:53.889: [iter 125 : loss : 0.1173 = 0.0275 + 0.0836 + 0.0061, time: 7.412574]
2023-05-15 19:43:54.046: epoch 125:	0.02689171  	0.19771942  	0.10890609  
2023-05-15 19:43:54.046: Find a better model.
2023-05-15 19:44:01.324: [iter 126 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0062, time: 7.276306]
2023-05-15 19:44:01.480: epoch 126:	0.02679997  	0.19687338  	0.10867511  
2023-05-15 19:44:08.925: [iter 127 : loss : 0.1166 = 0.0269 + 0.0835 + 0.0062, time: 7.444843]
2023-05-15 19:44:09.072: epoch 127:	0.02680703  	0.19692914  	0.10871927  
2023-05-15 19:44:16.315: [iter 128 : loss : 0.1173 = 0.0276 + 0.0835 + 0.0062, time: 7.242052]
2023-05-15 19:44:16.473: epoch 128:	0.02674352  	0.19619317  	0.10854049  
2023-05-15 19:44:23.902: [iter 129 : loss : 0.1166 = 0.0269 + 0.0834 + 0.0063, time: 7.427969]
2023-05-15 19:44:24.057: epoch 129:	0.02678586  	0.19642915  	0.10863220  
2023-05-15 19:44:31.466: [iter 130 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 7.408068]
2023-05-15 19:44:31.625: epoch 130:	0.02676469  	0.19654439  	0.10868100  
2023-05-15 19:44:38.917: [iter 131 : loss : 0.1159 = 0.0262 + 0.0834 + 0.0063, time: 7.290958]
2023-05-15 19:44:39.070: epoch 131:	0.02677880  	0.19675620  	0.10882752  
2023-05-15 19:44:46.512: [iter 132 : loss : 0.1160 = 0.0264 + 0.0833 + 0.0063, time: 7.439561]
2023-05-15 19:44:46.662: epoch 132:	0.02684936  	0.19692798  	0.10892661  
2023-05-15 19:44:54.061: [iter 133 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0064, time: 7.395805]
2023-05-15 19:44:54.203: epoch 133:	0.02680703  	0.19629204  	0.10885740  
2023-05-15 19:45:01.500: [iter 134 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 7.296597]
2023-05-15 19:45:01.657: epoch 134:	0.02684231  	0.19689474  	0.10930739  
2023-05-15 19:45:09.081: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 7.423074]
2023-05-15 19:45:09.238: epoch 135:	0.02689170  	0.19777423  	0.10940299  
2023-05-15 19:45:09.238: Find a better model.
2023-05-15 19:45:16.681: [iter 136 : loss : 0.1149 = 0.0254 + 0.0831 + 0.0065, time: 7.441618]
2023-05-15 19:45:16.826: epoch 136:	0.02693404  	0.19779654  	0.10951284  
2023-05-15 19:45:16.826: Find a better model.
2023-05-15 19:45:24.277: [iter 137 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 7.450384]
2023-05-15 19:45:24.436: epoch 137:	0.02691287  	0.19766395  	0.10948367  
2023-05-15 19:45:31.691: [iter 138 : loss : 0.1140 = 0.0244 + 0.0831 + 0.0065, time: 7.252713]
2023-05-15 19:45:31.837: epoch 138:	0.02687053  	0.19727331  	0.10933033  
2023-05-15 19:45:39.063: [iter 139 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 7.223555]
2023-05-15 19:45:39.207: epoch 139:	0.02681409  	0.19701752  	0.10923919  
2023-05-15 19:45:46.469: [iter 140 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0066, time: 7.261190]
2023-05-15 19:45:46.613: epoch 140:	0.02687054  	0.19718981  	0.10942257  
2023-05-15 19:45:53.863: [iter 141 : loss : 0.1142 = 0.0246 + 0.0829 + 0.0066, time: 7.249339]
2023-05-15 19:45:54.020: epoch 141:	0.02680704  	0.19660679  	0.10936260  
2023-05-15 19:46:01.249: [iter 142 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0066, time: 7.227839]
2023-05-15 19:46:01.392: epoch 142:	0.02682821  	0.19666904  	0.10932623  
2023-05-15 19:46:08.675: [iter 143 : loss : 0.1129 = 0.0234 + 0.0829 + 0.0067, time: 7.281679]
2023-05-15 19:46:08.832: epoch 143:	0.02689171  	0.19732657  	0.10958411  
2023-05-15 19:46:16.283: [iter 144 : loss : 0.1126 = 0.0231 + 0.0828 + 0.0067, time: 7.448541]
2023-05-15 19:46:16.441: epoch 144:	0.02687054  	0.19727273  	0.10948252  
2023-05-15 19:46:23.650: [iter 145 : loss : 0.1125 = 0.0229 + 0.0828 + 0.0067, time: 7.208381]
2023-05-15 19:46:23.806: epoch 145:	0.02677881  	0.19653325  	0.10924006  
2023-05-15 19:46:31.251: [iter 146 : loss : 0.1128 = 0.0232 + 0.0828 + 0.0067, time: 7.443571]
2023-05-15 19:46:31.396: epoch 146:	0.02687055  	0.19725491  	0.10947815  
2023-05-15 19:46:38.668: [iter 147 : loss : 0.1127 = 0.0232 + 0.0827 + 0.0068, time: 7.270276]
2023-05-15 19:46:38.827: epoch 147:	0.02691994  	0.19785343  	0.10956793  
2023-05-15 19:46:38.827: Find a better model.
2023-05-15 19:46:46.240: [iter 148 : loss : 0.1113 = 0.0218 + 0.0827 + 0.0068, time: 7.411168]
2023-05-15 19:46:46.395: epoch 148:	0.02691288  	0.19771525  	0.10958127  
2023-05-15 19:46:53.668: [iter 149 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 7.271501]
2023-05-15 19:46:53.823: epoch 149:	0.02688465  	0.19721918  	0.10955358  
2023-05-15 19:47:01.253: [iter 150 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0069, time: 7.428696]
2023-05-15 19:47:01.408: epoch 150:	0.02679998  	0.19656624  	0.10947400  
2023-05-15 19:47:08.842: [iter 151 : loss : 0.1111 = 0.0216 + 0.0826 + 0.0069, time: 7.431452]
2023-05-15 19:47:08.997: epoch 151:	0.02677175  	0.19645058  	0.10942937  
2023-05-15 19:47:16.255: [iter 152 : loss : 0.1105 = 0.0210 + 0.0826 + 0.0069, time: 7.256314]
2023-05-15 19:47:16.413: epoch 152:	0.02674353  	0.19613679  	0.10927656  
2023-05-15 19:47:23.827: [iter 153 : loss : 0.1097 = 0.0203 + 0.0825 + 0.0069, time: 7.412437]
2023-05-15 19:47:23.973: epoch 153:	0.02682115  	0.19655976  	0.10940447  
2023-05-15 19:47:31.407: [iter 154 : loss : 0.1102 = 0.0207 + 0.0825 + 0.0070, time: 7.432336]
2023-05-15 19:47:31.568: epoch 154:	0.02680704  	0.19656090  	0.10937201  
2023-05-15 19:47:38.851: [iter 155 : loss : 0.1110 = 0.0216 + 0.0825 + 0.0070, time: 7.281205]
2023-05-15 19:47:39.008: epoch 155:	0.02681410  	0.19653504  	0.10923894  
2023-05-15 19:47:46.444: [iter 156 : loss : 0.1104 = 0.0210 + 0.0825 + 0.0070, time: 7.435134]
2023-05-15 19:47:46.600: epoch 156:	0.02684232  	0.19683322  	0.10938913  
2023-05-15 19:47:53.827: [iter 157 : loss : 0.1102 = 0.0207 + 0.0824 + 0.0070, time: 7.225976]
2023-05-15 19:47:53.982: epoch 157:	0.02688466  	0.19717596  	0.10937798  
2023-05-15 19:48:01.247: [iter 158 : loss : 0.1093 = 0.0199 + 0.0824 + 0.0071, time: 7.263115]
2023-05-15 19:48:01.403: epoch 158:	0.02683526  	0.19690081  	0.10926387  
2023-05-15 19:48:08.648: [iter 159 : loss : 0.1098 = 0.0204 + 0.0823 + 0.0071, time: 7.243556]
2023-05-15 19:48:08.803: epoch 159:	0.02691994  	0.19739079  	0.10954303  
2023-05-15 19:48:16.017: [iter 160 : loss : 0.1093 = 0.0198 + 0.0823 + 0.0071, time: 7.212944]
2023-05-15 19:48:16.171: epoch 160:	0.02683526  	0.19679335  	0.10937526  
2023-05-15 19:48:23.437: [iter 161 : loss : 0.1090 = 0.0196 + 0.0823 + 0.0071, time: 7.265279]
2023-05-15 19:48:23.584: epoch 161:	0.02679292  	0.19629948  	0.10930465  
2023-05-15 19:48:30.831: [iter 162 : loss : 0.1081 = 0.0187 + 0.0823 + 0.0072, time: 7.245905]
2023-05-15 19:48:30.987: epoch 162:	0.02678587  	0.19603413  	0.10911700  
2023-05-15 19:48:38.385: [iter 163 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 7.397143]
2023-05-15 19:48:38.546: epoch 163:	0.02684937  	0.19706461  	0.10941359  
2023-05-15 19:48:45.813: [iter 164 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 7.266021]
2023-05-15 19:48:45.966: epoch 164:	0.02679998  	0.19665770  	0.10925519  
2023-05-15 19:48:53.391: [iter 165 : loss : 0.1083 = 0.0189 + 0.0822 + 0.0072, time: 7.421520]
2023-05-15 19:48:53.545: epoch 165:	0.02685643  	0.19676608  	0.10925294  
2023-05-15 19:49:00.801: [iter 166 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0073, time: 7.255146]
2023-05-15 19:49:00.958: epoch 166:	0.02687053  	0.19701016  	0.10915995  
2023-05-15 19:49:08.409: [iter 167 : loss : 0.1084 = 0.0190 + 0.0821 + 0.0073, time: 7.450400]
2023-05-15 19:49:08.564: epoch 167:	0.02687053  	0.19682375  	0.10907636  
2023-05-15 19:49:16.031: [iter 168 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 7.464692]
2023-05-15 19:49:16.184: epoch 168:	0.02692699  	0.19732471  	0.10934907  
2023-05-15 19:49:23.585: [iter 169 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 7.399977]
2023-05-15 19:49:23.741: epoch 169:	0.02685642  	0.19654068  	0.10903490  
2023-05-15 19:49:31.019: [iter 170 : loss : 0.1076 = 0.0182 + 0.0820 + 0.0073, time: 7.276322]
2023-05-15 19:49:31.177: epoch 170:	0.02682819  	0.19644719  	0.10903667  
2023-05-15 19:49:38.408: [iter 171 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0074, time: 7.229614]
2023-05-15 19:49:38.564: epoch 171:	0.02689170  	0.19679990  	0.10910316  
2023-05-15 19:49:45.956: [iter 172 : loss : 0.1070 = 0.0176 + 0.0820 + 0.0074, time: 7.390751]
2023-05-15 19:49:46.113: epoch 172:	0.02684936  	0.19647259  	0.10881869  
2023-05-15 19:49:46.113: Early stopping is trigger at epoch: 172
2023-05-15 19:49:46.113: best_result@epoch 147:

2023-05-15 19:49:46.113: 		0.0269      	0.1979      	0.1096      
2023-05-15 20:08:15.867: my pid: 6776
2023-05-15 20:08:15.868: model: model.general_recommender.SGL
2023-05-15 20:08:15.868: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 20:08:15.868: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 20:08:19.067: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 20:08:27.212: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.145013]
2023-05-15 20:08:27.367: epoch 1:	0.00145357  	0.01041888  	0.00485722  
2023-05-15 20:08:27.368: Find a better model.
2023-05-15 20:08:35.616: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.247004]
2023-05-15 20:08:35.799: epoch 2:	0.00271662  	0.01992618  	0.00985090  
2023-05-15 20:08:35.799: Find a better model.
2023-05-15 20:08:43.832: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 8.032089]
2023-05-15 20:08:43.995: epoch 3:	0.00529915  	0.03953585  	0.01914471  
2023-05-15 20:08:43.995: Find a better model.
2023-05-15 20:08:52.007: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.008492]
2023-05-15 20:08:52.164: epoch 4:	0.00815686  	0.05931814  	0.02900661  
2023-05-15 20:08:52.164: Find a better model.
2023-05-15 20:09:00.021: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 7.855056]
2023-05-15 20:09:00.174: epoch 5:	0.01174150  	0.08474755  	0.04066477  
2023-05-15 20:09:00.174: Find a better model.
2023-05-15 20:09:08.021: [iter 6 : loss : 0.7675 = 0.6882 + 0.0792 + 0.0000, time: 7.846641]
2023-05-15 20:09:08.174: epoch 6:	0.01514270  	0.10950386  	0.05336192  
2023-05-15 20:09:08.174: Find a better model.
2023-05-15 20:09:15.781: [iter 7 : loss : 0.7614 = 0.6814 + 0.0799 + 0.0000, time: 7.605290]
2023-05-15 20:09:15.922: epoch 7:	0.01779590  	0.12831484  	0.06386825  
2023-05-15 20:09:15.922: Find a better model.
2023-05-15 20:09:23.424: [iter 8 : loss : 0.7463 = 0.6645 + 0.0818 + 0.0001, time: 7.500978]
2023-05-15 20:09:23.579: epoch 8:	0.01852271  	0.13590264  	0.06909879  
2023-05-15 20:09:23.579: Find a better model.
2023-05-15 20:09:31.185: [iter 9 : loss : 0.7123 = 0.6267 + 0.0855 + 0.0001, time: 7.602274]
2023-05-15 20:09:31.338: epoch 9:	0.01898845  	0.13933572  	0.07014946  
2023-05-15 20:09:31.338: Find a better model.
2023-05-15 20:09:38.773: [iter 10 : loss : 0.6527 = 0.5616 + 0.0908 + 0.0002, time: 7.434506]
2023-05-15 20:09:38.928: epoch 10:	0.01879088  	0.13931277  	0.06944154  
2023-05-15 20:09:46.362: [iter 11 : loss : 0.5774 = 0.4813 + 0.0958 + 0.0004, time: 7.433114]
2023-05-15 20:09:46.516: epoch 11:	0.01855801  	0.13718130  	0.06874975  
2023-05-15 20:09:53.977: [iter 12 : loss : 0.5079 = 0.4082 + 0.0991 + 0.0005, time: 7.460080]
2023-05-15 20:09:54.125: epoch 12:	0.01852272  	0.13653274  	0.06885940  
2023-05-15 20:10:01.553: [iter 13 : loss : 0.4560 = 0.3542 + 0.1010 + 0.0007, time: 7.427075]
2023-05-15 20:10:01.698: epoch 13:	0.01866386  	0.13780023  	0.06940691  
2023-05-15 20:10:09.166: [iter 14 : loss : 0.4168 = 0.3139 + 0.1021 + 0.0008, time: 7.467082]
2023-05-15 20:10:09.321: epoch 14:	0.01880498  	0.13884446  	0.07008667  
2023-05-15 20:10:17.019: [iter 15 : loss : 0.3895 = 0.2860 + 0.1025 + 0.0010, time: 7.695825]
2023-05-15 20:10:17.176: epoch 15:	0.01898140  	0.14012238  	0.07104053  
2023-05-15 20:10:17.176: Find a better model.
2023-05-15 20:10:24.754: [iter 16 : loss : 0.3668 = 0.2631 + 0.1026 + 0.0011, time: 7.576616]
2023-05-15 20:10:24.909: epoch 16:	0.01909430  	0.14084564  	0.07156405  
2023-05-15 20:10:24.909: Find a better model.
2023-05-15 20:10:32.371: [iter 17 : loss : 0.3500 = 0.2465 + 0.1023 + 0.0012, time: 7.460641]
2023-05-15 20:10:32.528: epoch 17:	0.01939068  	0.14272845  	0.07264720  
2023-05-15 20:10:32.528: Find a better model.
2023-05-15 20:10:40.149: [iter 18 : loss : 0.3346 = 0.2312 + 0.1021 + 0.0013, time: 7.619878]
2023-05-15 20:10:40.304: epoch 18:	0.01950358  	0.14376393  	0.07315837  
2023-05-15 20:10:40.304: Find a better model.
2023-05-15 20:10:47.945: [iter 19 : loss : 0.3204 = 0.2172 + 0.1018 + 0.0014, time: 7.640063]
2023-05-15 20:10:48.104: epoch 19:	0.01975762  	0.14541569  	0.07414344  
2023-05-15 20:10:48.104: Find a better model.
2023-05-15 20:10:55.527: [iter 20 : loss : 0.3107 = 0.2078 + 0.1014 + 0.0015, time: 7.418759]
2023-05-15 20:10:55.681: epoch 20:	0.02001872  	0.14754422  	0.07513835  
2023-05-15 20:10:55.681: Find a better model.
2023-05-15 20:11:03.155: [iter 21 : loss : 0.3011 = 0.1985 + 0.1010 + 0.0016, time: 7.472691]
2023-05-15 20:11:03.311: epoch 21:	0.02022335  	0.14900647  	0.07597396  
2023-05-15 20:11:03.312: Find a better model.
2023-05-15 20:11:10.747: [iter 22 : loss : 0.2927 = 0.1904 + 0.1006 + 0.0017, time: 7.434323]
2023-05-15 20:11:10.904: epoch 22:	0.02037154  	0.15056351  	0.07666015  
2023-05-15 20:11:10.905: Find a better model.
2023-05-15 20:11:18.328: [iter 23 : loss : 0.2845 = 0.1826 + 0.1002 + 0.0017, time: 7.421577]
2023-05-15 20:11:18.483: epoch 23:	0.02066085  	0.15242842  	0.07764960  
2023-05-15 20:11:18.483: Find a better model.
2023-05-15 20:11:25.921: [iter 24 : loss : 0.2780 = 0.1764 + 0.0997 + 0.0018, time: 7.435309]
2023-05-15 20:11:26.077: epoch 24:	0.02080198  	0.15328617  	0.07821990  
2023-05-15 20:11:26.077: Find a better model.
2023-05-15 20:11:33.581: [iter 25 : loss : 0.2713 = 0.1701 + 0.0994 + 0.0019, time: 7.503287]
2023-05-15 20:11:33.736: epoch 25:	0.02104896  	0.15547831  	0.07902893  
2023-05-15 20:11:33.736: Find a better model.
2023-05-15 20:11:41.132: [iter 26 : loss : 0.2676 = 0.1667 + 0.0989 + 0.0019, time: 7.395038]
2023-05-15 20:11:41.289: epoch 26:	0.02123243  	0.15655784  	0.07967073  
2023-05-15 20:11:41.290: Find a better model.
2023-05-15 20:11:48.542: [iter 27 : loss : 0.2600 = 0.1594 + 0.0985 + 0.0020, time: 7.251144]
2023-05-15 20:11:48.687: epoch 27:	0.02147236  	0.15806991  	0.08066337  
2023-05-15 20:11:48.688: Find a better model.
2023-05-15 20:11:56.125: [iter 28 : loss : 0.2554 = 0.1551 + 0.0981 + 0.0021, time: 7.435919]
2023-05-15 20:11:56.282: epoch 28:	0.02157115  	0.15919456  	0.08156377  
2023-05-15 20:11:56.282: Find a better model.
2023-05-15 20:12:03.725: [iter 29 : loss : 0.2505 = 0.1507 + 0.0977 + 0.0021, time: 7.441507]
2023-05-15 20:12:03.883: epoch 29:	0.02173345  	0.16006115  	0.08214735  
2023-05-15 20:12:03.883: Find a better model.
2023-05-15 20:12:11.316: [iter 30 : loss : 0.2440 = 0.1445 + 0.0974 + 0.0022, time: 7.431076]
2023-05-15 20:12:11.459: epoch 30:	0.02194515  	0.16199236  	0.08294950  
2023-05-15 20:12:11.459: Find a better model.
2023-05-15 20:12:18.910: [iter 31 : loss : 0.2404 = 0.1413 + 0.0969 + 0.0023, time: 7.449501]
2023-05-15 20:12:19.053: epoch 31:	0.02208628  	0.16303200  	0.08361968  
2023-05-15 20:12:19.053: Find a better model.
2023-05-15 20:12:26.530: [iter 32 : loss : 0.2350 = 0.1361 + 0.0966 + 0.0023, time: 7.473843]
2023-05-15 20:12:26.672: epoch 32:	0.02224152  	0.16428921  	0.08445828  
2023-05-15 20:12:26.672: Find a better model.
2023-05-15 20:12:34.356: [iter 33 : loss : 0.2323 = 0.1338 + 0.0961 + 0.0024, time: 7.682902]
2023-05-15 20:12:34.510: epoch 33:	0.02233325  	0.16496450  	0.08492722  
2023-05-15 20:12:34.510: Find a better model.
2023-05-15 20:12:42.106: [iter 34 : loss : 0.2284 = 0.1302 + 0.0958 + 0.0024, time: 7.594781]
2023-05-15 20:12:42.263: epoch 34:	0.02250966  	0.16625027  	0.08567506  
2023-05-15 20:12:42.263: Find a better model.
2023-05-15 20:12:49.719: [iter 35 : loss : 0.2247 = 0.1267 + 0.0955 + 0.0025, time: 7.454453]
2023-05-15 20:12:49.873: epoch 35:	0.02263668  	0.16693440  	0.08630912  
2023-05-15 20:12:49.873: Find a better model.
2023-05-15 20:12:57.305: [iter 36 : loss : 0.2214 = 0.1236 + 0.0952 + 0.0026, time: 7.431638]
2023-05-15 20:12:57.459: epoch 36:	0.02273547  	0.16803224  	0.08694946  
2023-05-15 20:12:57.459: Find a better model.
2023-05-15 20:13:05.070: [iter 37 : loss : 0.2174 = 0.1199 + 0.0949 + 0.0026, time: 7.609743]
2023-05-15 20:13:05.224: epoch 37:	0.02278486  	0.16875792  	0.08737987  
2023-05-15 20:13:05.224: Find a better model.
2023-05-15 20:13:12.703: [iter 38 : loss : 0.2159 = 0.1187 + 0.0945 + 0.0027, time: 7.478320]
2023-05-15 20:13:12.860: epoch 38:	0.02289071  	0.16922379  	0.08810795  
2023-05-15 20:13:12.860: Find a better model.
2023-05-15 20:13:20.502: [iter 39 : loss : 0.2116 = 0.1146 + 0.0943 + 0.0027, time: 7.640618]
2023-05-15 20:13:20.656: epoch 39:	0.02301067  	0.16986184  	0.08891952  
2023-05-15 20:13:20.656: Find a better model.
2023-05-15 20:13:28.116: [iter 40 : loss : 0.2082 = 0.1114 + 0.0940 + 0.0028, time: 7.458943]
2023-05-15 20:13:28.274: epoch 40:	0.02306712  	0.17013077  	0.08920512  
2023-05-15 20:13:28.274: Find a better model.
2023-05-15 20:13:35.690: [iter 41 : loss : 0.2066 = 0.1100 + 0.0937 + 0.0028, time: 7.414238]
2023-05-15 20:13:35.844: epoch 41:	0.02310240  	0.17067529  	0.08972958  
2023-05-15 20:13:35.844: Find a better model.
2023-05-15 20:13:43.294: [iter 42 : loss : 0.2042 = 0.1080 + 0.0934 + 0.0029, time: 7.449647]
2023-05-15 20:13:43.448: epoch 42:	0.02320119  	0.17118639  	0.09025463  
2023-05-15 20:13:43.448: Find a better model.
2023-05-15 20:13:50.895: [iter 43 : loss : 0.2002 = 0.1042 + 0.0931 + 0.0029, time: 7.444813]
2023-05-15 20:13:51.048: epoch 43:	0.02334938  	0.17185679  	0.09089012  
2023-05-15 20:13:51.048: Find a better model.
2023-05-15 20:13:58.499: [iter 44 : loss : 0.1968 = 0.1011 + 0.0928 + 0.0030, time: 7.450226]
2023-05-15 20:13:58.651: epoch 44:	0.02356813  	0.17346302  	0.09154282  
2023-05-15 20:13:58.652: Find a better model.
2023-05-15 20:14:06.261: [iter 45 : loss : 0.1945 = 0.0989 + 0.0926 + 0.0030, time: 7.607408]
2023-05-15 20:14:06.420: epoch 45:	0.02365986  	0.17446432  	0.09189704  
2023-05-15 20:14:06.420: Find a better model.
2023-05-15 20:14:14.075: [iter 46 : loss : 0.1922 = 0.0968 + 0.0923 + 0.0031, time: 7.653944]
2023-05-15 20:14:14.229: epoch 46:	0.02373748  	0.17514467  	0.09233381  
2023-05-15 20:14:14.230: Find a better model.
2023-05-15 20:14:21.664: [iter 47 : loss : 0.1916 = 0.0964 + 0.0921 + 0.0031, time: 7.433882]
2023-05-15 20:14:21.818: epoch 47:	0.02385038  	0.17578293  	0.09289652  
2023-05-15 20:14:21.819: Find a better model.
2023-05-15 20:14:29.288: [iter 48 : loss : 0.1877 = 0.0926 + 0.0919 + 0.0032, time: 7.467193]
2023-05-15 20:14:29.445: epoch 48:	0.02382216  	0.17571701  	0.09313539  
2023-05-15 20:14:36.876: [iter 49 : loss : 0.1845 = 0.0896 + 0.0917 + 0.0032, time: 7.429791]
2023-05-15 20:14:37.021: epoch 49:	0.02391389  	0.17622717  	0.09358139  
2023-05-15 20:14:37.022: Find a better model.
2023-05-15 20:14:44.470: [iter 50 : loss : 0.1839 = 0.0892 + 0.0914 + 0.0033, time: 7.447316]
2023-05-15 20:14:44.624: epoch 50:	0.02399857  	0.17685811  	0.09424356  
2023-05-15 20:14:44.624: Find a better model.
2023-05-15 20:14:52.072: [iter 51 : loss : 0.1807 = 0.0861 + 0.0912 + 0.0033, time: 7.447100]
2023-05-15 20:14:52.226: epoch 51:	0.02408325  	0.17745532  	0.09456655  
2023-05-15 20:14:52.226: Find a better model.
2023-05-15 20:14:59.653: [iter 52 : loss : 0.1807 = 0.0863 + 0.0910 + 0.0034, time: 7.426077]
2023-05-15 20:14:59.809: epoch 52:	0.02412558  	0.17760314  	0.09492218  
2023-05-15 20:14:59.809: Find a better model.
2023-05-15 20:15:07.245: [iter 53 : loss : 0.1787 = 0.0844 + 0.0908 + 0.0034, time: 7.434528]
2023-05-15 20:15:07.403: epoch 53:	0.02421732  	0.17822838  	0.09543552  
2023-05-15 20:15:07.403: Find a better model.
2023-05-15 20:15:14.672: [iter 54 : loss : 0.1763 = 0.0822 + 0.0906 + 0.0035, time: 7.267296]
2023-05-15 20:15:14.826: epoch 54:	0.02442901  	0.17999013  	0.09618130  
2023-05-15 20:15:14.826: Find a better model.
2023-05-15 20:15:22.243: [iter 55 : loss : 0.1746 = 0.0806 + 0.0904 + 0.0035, time: 7.416450]
2023-05-15 20:15:22.403: epoch 55:	0.02445724  	0.18057200  	0.09636879  
2023-05-15 20:15:22.403: Find a better model.
2023-05-15 20:15:29.667: [iter 56 : loss : 0.1727 = 0.0789 + 0.0902 + 0.0035, time: 7.262934]
2023-05-15 20:15:29.820: epoch 56:	0.02456309  	0.18112721  	0.09679341  
2023-05-15 20:15:29.821: Find a better model.
2023-05-15 20:15:37.280: [iter 57 : loss : 0.1711 = 0.0775 + 0.0901 + 0.0036, time: 7.458203]
2023-05-15 20:15:37.431: epoch 57:	0.02459837  	0.18152110  	0.09709850  
2023-05-15 20:15:37.432: Find a better model.
2023-05-15 20:15:44.852: [iter 58 : loss : 0.1689 = 0.0754 + 0.0899 + 0.0036, time: 7.418689]
2023-05-15 20:15:45.007: epoch 58:	0.02461249  	0.18122472  	0.09714290  
2023-05-15 20:15:52.442: [iter 59 : loss : 0.1681 = 0.0748 + 0.0897 + 0.0037, time: 7.433386]
2023-05-15 20:15:52.597: epoch 59:	0.02470422  	0.18203828  	0.09772680  
2023-05-15 20:15:52.597: Find a better model.
2023-05-15 20:16:00.053: [iter 60 : loss : 0.1665 = 0.0733 + 0.0895 + 0.0037, time: 7.455574]
2023-05-15 20:16:00.209: epoch 60:	0.02477478  	0.18268128  	0.09810308  
2023-05-15 20:16:00.209: Find a better model.
2023-05-15 20:16:07.683: [iter 61 : loss : 0.1651 = 0.0720 + 0.0893 + 0.0038, time: 7.472444]
2023-05-15 20:16:07.837: epoch 61:	0.02476067  	0.18269342  	0.09832773  
2023-05-15 20:16:07.837: Find a better model.
2023-05-15 20:16:15.440: [iter 62 : loss : 0.1634 = 0.0704 + 0.0892 + 0.0038, time: 7.601049]
2023-05-15 20:16:15.593: epoch 62:	0.02488063  	0.18347616  	0.09885306  
2023-05-15 20:16:15.593: Find a better model.
2023-05-15 20:16:23.033: [iter 63 : loss : 0.1623 = 0.0694 + 0.0890 + 0.0039, time: 7.437541]
2023-05-15 20:16:23.185: epoch 63:	0.02493002  	0.18404602  	0.09923052  
2023-05-15 20:16:23.185: Find a better model.
2023-05-15 20:16:30.644: [iter 64 : loss : 0.1611 = 0.0683 + 0.0889 + 0.0039, time: 7.458892]
2023-05-15 20:16:30.799: epoch 64:	0.02498647  	0.18406765  	0.09944335  
2023-05-15 20:16:30.799: Find a better model.
2023-05-15 20:16:38.238: [iter 65 : loss : 0.1599 = 0.0672 + 0.0887 + 0.0040, time: 7.438048]
2023-05-15 20:16:38.390: epoch 65:	0.02497236  	0.18425208  	0.09971810  
2023-05-15 20:16:38.390: Find a better model.
2023-05-15 20:16:45.822: [iter 66 : loss : 0.1584 = 0.0658 + 0.0885 + 0.0040, time: 7.429499]
2023-05-15 20:16:45.976: epoch 66:	0.02502881  	0.18470666  	0.10005913  
2023-05-15 20:16:45.976: Find a better model.
2023-05-15 20:16:53.432: [iter 67 : loss : 0.1567 = 0.0642 + 0.0884 + 0.0040, time: 7.454695]
2023-05-15 20:16:53.587: epoch 67:	0.02514171  	0.18559267  	0.10050205  
2023-05-15 20:16:53.587: Find a better model.
2023-05-15 20:17:01.045: [iter 68 : loss : 0.1563 = 0.0639 + 0.0883 + 0.0041, time: 7.456476]
2023-05-15 20:17:01.198: epoch 68:	0.02518405  	0.18595617  	0.10076171  
2023-05-15 20:17:01.198: Find a better model.
2023-05-15 20:17:08.629: [iter 69 : loss : 0.1547 = 0.0624 + 0.0881 + 0.0041, time: 7.429343]
2023-05-15 20:17:08.786: epoch 69:	0.02521933  	0.18632060  	0.10097882  
2023-05-15 20:17:08.786: Find a better model.
2023-05-15 20:17:16.210: [iter 70 : loss : 0.1528 = 0.0606 + 0.0880 + 0.0042, time: 7.421968]
2023-05-15 20:17:16.354: epoch 70:	0.02531107  	0.18661143  	0.10121919  
2023-05-15 20:17:16.354: Find a better model.
2023-05-15 20:17:23.839: [iter 71 : loss : 0.1514 = 0.0592 + 0.0879 + 0.0042, time: 7.482495]
2023-05-15 20:17:23.992: epoch 71:	0.02536752  	0.18732090  	0.10167614  
2023-05-15 20:17:23.992: Find a better model.
2023-05-15 20:17:31.416: [iter 72 : loss : 0.1512 = 0.0592 + 0.0878 + 0.0042, time: 7.422835]
2023-05-15 20:17:31.574: epoch 72:	0.02549453  	0.18812796  	0.10205415  
2023-05-15 20:17:31.574: Find a better model.
2023-05-15 20:17:38.981: [iter 73 : loss : 0.1499 = 0.0579 + 0.0876 + 0.0043, time: 7.404847]
2023-05-15 20:17:39.125: epoch 73:	0.02548748  	0.18776250  	0.10203306  
2023-05-15 20:17:46.405: [iter 74 : loss : 0.1485 = 0.0566 + 0.0875 + 0.0043, time: 7.278800]
2023-05-15 20:17:46.561: epoch 74:	0.02557216  	0.18847129  	0.10224592  
2023-05-15 20:17:46.561: Find a better model.
2023-05-15 20:17:53.999: [iter 75 : loss : 0.1479 = 0.0561 + 0.0874 + 0.0044, time: 7.436013]
2023-05-15 20:17:54.152: epoch 75:	0.02560744  	0.18873325  	0.10252287  
2023-05-15 20:17:54.152: Find a better model.
2023-05-15 20:18:01.644: [iter 76 : loss : 0.1470 = 0.0553 + 0.0873 + 0.0044, time: 7.491033]
2023-05-15 20:18:01.797: epoch 76:	0.02561450  	0.18878785  	0.10269094  
2023-05-15 20:18:01.798: Find a better model.
2023-05-15 20:18:09.189: [iter 77 : loss : 0.1458 = 0.0542 + 0.0872 + 0.0044, time: 7.390851]
2023-05-15 20:18:09.332: epoch 77:	0.02570623  	0.18951045  	0.10308517  
2023-05-15 20:18:09.332: Find a better model.
2023-05-15 20:18:16.789: [iter 78 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 7.455793]
2023-05-15 20:18:16.944: epoch 78:	0.02572035  	0.18987413  	0.10329778  
2023-05-15 20:18:16.944: Find a better model.
2023-05-15 20:18:24.401: [iter 79 : loss : 0.1438 = 0.0523 + 0.0870 + 0.0045, time: 7.456704]
2023-05-15 20:18:24.555: epoch 79:	0.02576268  	0.19033498  	0.10371508  
2023-05-15 20:18:24.555: Find a better model.
2023-05-15 20:18:31.991: [iter 80 : loss : 0.1431 = 0.0517 + 0.0869 + 0.0046, time: 7.433471]
2023-05-15 20:18:32.146: epoch 80:	0.02572034  	0.19014877  	0.10375489  
2023-05-15 20:18:39.771: [iter 81 : loss : 0.1426 = 0.0512 + 0.0867 + 0.0046, time: 7.623301]
2023-05-15 20:18:39.924: epoch 81:	0.02579091  	0.19045436  	0.10397904  
2023-05-15 20:18:39.924: Find a better model.
2023-05-15 20:18:47.399: [iter 82 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0046, time: 7.472996]
2023-05-15 20:18:47.552: epoch 82:	0.02582619  	0.19087578  	0.10422824  
2023-05-15 20:18:47.552: Find a better model.
2023-05-15 20:18:54.988: [iter 83 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 7.435267]
2023-05-15 20:18:55.141: epoch 83:	0.02591086  	0.19134068  	0.10459387  
2023-05-15 20:18:55.141: Find a better model.
2023-05-15 20:19:02.567: [iter 84 : loss : 0.1402 = 0.0490 + 0.0864 + 0.0047, time: 7.425063]
2023-05-15 20:19:02.723: epoch 84:	0.02591792  	0.19115262  	0.10465469  
2023-05-15 20:19:09.987: [iter 85 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 7.262202]
2023-05-15 20:19:10.129: epoch 85:	0.02592498  	0.19162883  	0.10476699  
2023-05-15 20:19:10.129: Find a better model.
2023-05-15 20:19:17.582: [iter 86 : loss : 0.1394 = 0.0484 + 0.0862 + 0.0048, time: 7.451552]
2023-05-15 20:19:17.739: epoch 86:	0.02591086  	0.19150780  	0.10494916  
2023-05-15 20:19:25.171: [iter 87 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0048, time: 7.430742]
2023-05-15 20:19:25.327: epoch 87:	0.02588969  	0.19107150  	0.10506889  
2023-05-15 20:19:32.792: [iter 88 : loss : 0.1358 = 0.0448 + 0.0861 + 0.0049, time: 7.462923]
2023-05-15 20:19:32.944: epoch 88:	0.02597437  	0.19170782  	0.10530549  
2023-05-15 20:19:32.944: Find a better model.
2023-05-15 20:19:40.367: [iter 89 : loss : 0.1355 = 0.0446 + 0.0860 + 0.0049, time: 7.421290]
2023-05-15 20:19:40.520: epoch 89:	0.02596732  	0.19190247  	0.10534073  
2023-05-15 20:19:40.520: Find a better model.
2023-05-15 20:19:47.935: [iter 90 : loss : 0.1362 = 0.0453 + 0.0859 + 0.0050, time: 7.413992]
2023-05-15 20:19:48.091: epoch 90:	0.02593909  	0.19159931  	0.10530624  
2023-05-15 20:19:55.551: [iter 91 : loss : 0.1349 = 0.0441 + 0.0858 + 0.0050, time: 7.458695]
2023-05-15 20:19:55.707: epoch 91:	0.02599555  	0.19223855  	0.10551871  
2023-05-15 20:19:55.707: Find a better model.
2023-05-15 20:20:02.963: [iter 92 : loss : 0.1336 = 0.0429 + 0.0857 + 0.0050, time: 7.254106]
2023-05-15 20:20:03.114: epoch 92:	0.02596026  	0.19201128  	0.10555932  
2023-05-15 20:20:10.555: [iter 93 : loss : 0.1340 = 0.0433 + 0.0856 + 0.0051, time: 7.440484]
2023-05-15 20:20:10.711: epoch 93:	0.02595321  	0.19184892  	0.10556443  
2023-05-15 20:20:17.959: [iter 94 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.245100]
2023-05-15 20:20:18.101: epoch 94:	0.02599555  	0.19237179  	0.10573398  
2023-05-15 20:20:18.101: Find a better model.
2023-05-15 20:20:25.346: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.243319]
2023-05-15 20:20:25.490: epoch 95:	0.02598849  	0.19242060  	0.10568774  
2023-05-15 20:20:25.490: Find a better model.
2023-05-15 20:20:32.749: [iter 96 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0052, time: 7.257501]
2023-05-15 20:20:32.902: epoch 96:	0.02603788  	0.19280146  	0.10594314  
2023-05-15 20:20:32.903: Find a better model.
2023-05-15 20:20:40.325: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 7.421296]
2023-05-15 20:20:40.479: epoch 97:	0.02601671  	0.19301327  	0.10609036  
2023-05-15 20:20:40.480: Find a better model.
2023-05-15 20:20:47.914: [iter 98 : loss : 0.1306 = 0.0401 + 0.0852 + 0.0052, time: 7.432777]
2023-05-15 20:20:48.057: epoch 98:	0.02605905  	0.19329798  	0.10625609  
2023-05-15 20:20:48.057: Find a better model.
2023-05-15 20:20:55.342: [iter 99 : loss : 0.1296 = 0.0391 + 0.0852 + 0.0053, time: 7.284152]
2023-05-15 20:20:55.485: epoch 99:	0.02609433  	0.19375597  	0.10644328  
2023-05-15 20:20:55.485: Find a better model.
2023-05-15 20:21:02.926: [iter 100 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 7.438814]
2023-05-15 20:21:03.081: epoch 100:	0.02618607  	0.19408830  	0.10655309  
2023-05-15 20:21:03.081: Find a better model.
2023-05-15 20:21:10.347: [iter 101 : loss : 0.1284 = 0.0380 + 0.0851 + 0.0054, time: 7.264915]
2023-05-15 20:21:10.501: epoch 101:	0.02615078  	0.19406888  	0.10652483  
2023-05-15 20:21:17.926: [iter 102 : loss : 0.1274 = 0.0370 + 0.0850 + 0.0054, time: 7.424240]
2023-05-15 20:21:18.080: epoch 102:	0.02622134  	0.19440648  	0.10673270  
2023-05-15 20:21:18.080: Find a better model.
2023-05-15 20:21:25.343: [iter 103 : loss : 0.1272 = 0.0368 + 0.0849 + 0.0054, time: 7.262596]
2023-05-15 20:21:25.498: epoch 103:	0.02622135  	0.19412071  	0.10669312  
2023-05-15 20:21:32.905: [iter 104 : loss : 0.1276 = 0.0373 + 0.0848 + 0.0055, time: 7.406164]
2023-05-15 20:21:33.062: epoch 104:	0.02627780  	0.19446830  	0.10671673  
2023-05-15 20:21:33.062: Find a better model.
2023-05-15 20:21:40.333: [iter 105 : loss : 0.1269 = 0.0366 + 0.0848 + 0.0055, time: 7.269875]
2023-05-15 20:21:40.486: epoch 105:	0.02632719  	0.19473204  	0.10688385  
2023-05-15 20:21:40.487: Find a better model.
2023-05-15 20:21:47.742: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 7.253347]
2023-05-15 20:21:47.898: epoch 106:	0.02632013  	0.19438247  	0.10691851  
2023-05-15 20:21:55.316: [iter 107 : loss : 0.1254 = 0.0352 + 0.0847 + 0.0056, time: 7.415860]
2023-05-15 20:21:55.469: epoch 107:	0.02628485  	0.19418915  	0.10704108  
2023-05-15 20:22:02.719: [iter 108 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0056, time: 7.248024]
2023-05-15 20:22:02.875: epoch 108:	0.02634131  	0.19473061  	0.10721738  
2023-05-15 20:22:10.129: [iter 109 : loss : 0.1240 = 0.0339 + 0.0845 + 0.0056, time: 7.250516]
2023-05-15 20:22:10.282: epoch 109:	0.02634836  	0.19501922  	0.10713725  
2023-05-15 20:22:10.282: Find a better model.
2023-05-15 20:22:17.720: [iter 110 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 7.435963]
2023-05-15 20:22:17.875: epoch 110:	0.02634131  	0.19513522  	0.10706926  
2023-05-15 20:22:17.875: Find a better model.
2023-05-15 20:22:25.297: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 7.419946]
2023-05-15 20:22:25.448: epoch 111:	0.02634131  	0.19464158  	0.10709481  
2023-05-15 20:22:32.922: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.472361]
2023-05-15 20:22:33.074: epoch 112:	0.02641187  	0.19501215  	0.10716927  
2023-05-15 20:22:40.517: [iter 113 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0058, time: 7.442009]
2023-05-15 20:22:40.671: epoch 113:	0.02636247  	0.19473514  	0.10732674  
2023-05-15 20:22:48.096: [iter 114 : loss : 0.1221 = 0.0322 + 0.0842 + 0.0058, time: 7.423555]
2023-05-15 20:22:48.239: epoch 114:	0.02636248  	0.19467638  	0.10728583  
2023-05-15 20:22:55.678: [iter 115 : loss : 0.1219 = 0.0319 + 0.0842 + 0.0058, time: 7.438632]
2023-05-15 20:22:55.821: epoch 115:	0.02639776  	0.19481993  	0.10750642  
2023-05-15 20:23:03.302: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 7.480103]
2023-05-15 20:23:03.446: epoch 116:	0.02627780  	0.19369793  	0.10716636  
2023-05-15 20:23:10.898: [iter 117 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 7.450507]
2023-05-15 20:23:11.051: epoch 117:	0.02632013  	0.19396295  	0.10745975  
2023-05-15 20:23:18.482: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 7.428122]
2023-05-15 20:23:18.635: epoch 118:	0.02633425  	0.19421196  	0.10746197  
2023-05-15 20:23:26.109: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 7.472761]
2023-05-15 20:23:26.264: epoch 119:	0.02632719  	0.19429536  	0.10770989  
2023-05-15 20:23:33.688: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 7.421325]
2023-05-15 20:23:33.831: epoch 120:	0.02634836  	0.19473420  	0.10791136  
2023-05-15 20:23:41.262: [iter 121 : loss : 0.1198 = 0.0299 + 0.0838 + 0.0060, time: 7.429959]
2023-05-15 20:23:41.419: epoch 121:	0.02642599  	0.19517574  	0.10800012  
2023-05-15 20:23:41.419: Find a better model.
2023-05-15 20:23:48.681: [iter 122 : loss : 0.1192 = 0.0293 + 0.0838 + 0.0060, time: 7.261095]
2023-05-15 20:23:48.836: epoch 122:	0.02642599  	0.19522291  	0.10803075  
2023-05-15 20:23:48.836: Find a better model.
2023-05-15 20:23:56.258: [iter 123 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0061, time: 7.420913]
2023-05-15 20:23:56.413: epoch 123:	0.02637659  	0.19499688  	0.10796700  
2023-05-15 20:24:03.853: [iter 124 : loss : 0.1183 = 0.0285 + 0.0837 + 0.0061, time: 7.437655]
2023-05-15 20:24:04.008: epoch 124:	0.02640482  	0.19529311  	0.10788200  
2023-05-15 20:24:04.009: Find a better model.
2023-05-15 20:24:11.286: [iter 125 : loss : 0.1176 = 0.0278 + 0.0837 + 0.0061, time: 7.276238]
2023-05-15 20:24:11.438: epoch 125:	0.02646832  	0.19548279  	0.10809602  
2023-05-15 20:24:11.438: Find a better model.
2023-05-15 20:24:18.883: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 7.443446]
2023-05-15 20:24:19.035: epoch 126:	0.02639776  	0.19471253  	0.10787345  
2023-05-15 20:24:26.469: [iter 127 : loss : 0.1168 = 0.0270 + 0.0836 + 0.0062, time: 7.432933]
2023-05-15 20:24:26.621: epoch 127:	0.02640481  	0.19474305  	0.10806375  
2023-05-15 20:24:34.059: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 7.436090]
2023-05-15 20:24:34.212: epoch 128:	0.02641187  	0.19451460  	0.10800143  
2023-05-15 20:24:41.470: [iter 129 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0063, time: 7.254964]
2023-05-15 20:24:41.615: epoch 129:	0.02648243  	0.19507723  	0.10815894  
2023-05-15 20:24:49.041: [iter 130 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 7.425446]
2023-05-15 20:24:49.197: epoch 130:	0.02652477  	0.19555494  	0.10827976  
2023-05-15 20:24:49.197: Find a better model.
2023-05-15 20:24:56.483: [iter 131 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0063, time: 7.284886]
2023-05-15 20:24:56.639: epoch 131:	0.02650359  	0.19549431  	0.10834270  
2023-05-15 20:25:03.865: [iter 132 : loss : 0.1165 = 0.0267 + 0.0834 + 0.0064, time: 7.225457]
2023-05-15 20:25:04.022: epoch 132:	0.02650359  	0.19533582  	0.10831946  
2023-05-15 20:25:11.460: [iter 133 : loss : 0.1151 = 0.0254 + 0.0833 + 0.0064, time: 7.435746]
2023-05-15 20:25:11.616: epoch 133:	0.02649653  	0.19543083  	0.10829875  
2023-05-15 20:25:19.028: [iter 134 : loss : 0.1159 = 0.0262 + 0.0832 + 0.0064, time: 7.410096]
2023-05-15 20:25:19.180: epoch 134:	0.02650359  	0.19509536  	0.10841750  
2023-05-15 20:25:26.643: [iter 135 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0064, time: 7.461138]
2023-05-15 20:25:26.796: epoch 135:	0.02651770  	0.19550529  	0.10860310  
2023-05-15 20:25:34.232: [iter 136 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0065, time: 7.435010]
2023-05-15 20:25:34.376: epoch 136:	0.02654593  	0.19572112  	0.10863470  
2023-05-15 20:25:34.376: Find a better model.
2023-05-15 20:25:41.835: [iter 137 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.457903]
2023-05-15 20:25:41.979: epoch 137:	0.02655299  	0.19599585  	0.10874040  
2023-05-15 20:25:41.979: Find a better model.
2023-05-15 20:25:49.246: [iter 138 : loss : 0.1142 = 0.0246 + 0.0831 + 0.0065, time: 7.266131]
2023-05-15 20:25:49.400: epoch 138:	0.02649654  	0.19548519  	0.10850479  
2023-05-15 20:25:56.825: [iter 139 : loss : 0.1142 = 0.0246 + 0.0831 + 0.0066, time: 7.423257]
2023-05-15 20:25:56.977: epoch 139:	0.02655299  	0.19556117  	0.10867493  
2023-05-15 20:26:04.248: [iter 140 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 7.268656]
2023-05-15 20:26:04.403: epoch 140:	0.02658827  	0.19601029  	0.10873841  
2023-05-15 20:26:04.403: Find a better model.
2023-05-15 20:26:11.628: [iter 141 : loss : 0.1140 = 0.0244 + 0.0830 + 0.0066, time: 7.223981]
2023-05-15 20:26:11.782: epoch 141:	0.02656711  	0.19596499  	0.10885735  
2023-05-15 20:26:19.198: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 7.415475]
2023-05-15 20:26:19.343: epoch 142:	0.02659533  	0.19588360  	0.10877020  
2023-05-15 20:26:26.632: [iter 143 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0067, time: 7.286868]
2023-05-15 20:26:26.783: epoch 143:	0.02655299  	0.19589217  	0.10891698  
2023-05-15 20:26:34.026: [iter 144 : loss : 0.1128 = 0.0232 + 0.0829 + 0.0067, time: 7.241555]
2023-05-15 20:26:34.183: epoch 144:	0.02656711  	0.19617440  	0.10899882  
2023-05-15 20:26:34.184: Find a better model.
2023-05-15 20:26:41.662: [iter 145 : loss : 0.1126 = 0.0231 + 0.0828 + 0.0067, time: 7.476606]
2023-05-15 20:26:41.816: epoch 145:	0.02656711  	0.19584225  	0.10880278  
2023-05-15 20:26:49.193: [iter 146 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.376067]
2023-05-15 20:26:49.347: epoch 146:	0.02653887  	0.19543149  	0.10886116  
2023-05-15 20:26:56.615: [iter 147 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0068, time: 7.265709]
2023-05-15 20:26:56.769: epoch 147:	0.02650359  	0.19507124  	0.10858119  
2023-05-15 20:27:04.020: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.249320]
2023-05-15 20:27:04.175: epoch 148:	0.02654593  	0.19545358  	0.10890119  
2023-05-15 20:27:11.614: [iter 149 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 7.438107]
2023-05-15 20:27:11.769: epoch 149:	0.02656710  	0.19583622  	0.10902975  
2023-05-15 20:27:19.199: [iter 150 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0069, time: 7.428502]
2023-05-15 20:27:19.354: epoch 150:	0.02660944  	0.19670796  	0.10921149  
2023-05-15 20:27:19.354: Find a better model.
2023-05-15 20:27:26.605: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 7.249431]
2023-05-15 20:27:26.760: epoch 151:	0.02660238  	0.19673891  	0.10914344  
2023-05-15 20:27:26.760: Find a better model.
2023-05-15 20:27:34.187: [iter 152 : loss : 0.1110 = 0.0215 + 0.0826 + 0.0069, time: 7.426259]
2023-05-15 20:27:34.328: epoch 152:	0.02658826  	0.19651708  	0.10941090  
2023-05-15 20:27:41.603: [iter 153 : loss : 0.1099 = 0.0204 + 0.0826 + 0.0069, time: 7.273899]
2023-05-15 20:27:41.747: epoch 153:	0.02660944  	0.19695087  	0.10946871  
2023-05-15 20:27:41.748: Find a better model.
2023-05-15 20:27:49.176: [iter 154 : loss : 0.1103 = 0.0208 + 0.0825 + 0.0070, time: 7.427040]
2023-05-15 20:27:49.331: epoch 154:	0.02660239  	0.19693351  	0.10955860  
2023-05-15 20:27:56.775: [iter 155 : loss : 0.1111 = 0.0216 + 0.0825 + 0.0070, time: 7.442110]
2023-05-15 20:27:56.931: epoch 155:	0.02658121  	0.19700959  	0.10943522  
2023-05-15 20:27:56.931: Find a better model.
2023-05-15 20:28:04.374: [iter 156 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 7.440449]
2023-05-15 20:28:04.529: epoch 156:	0.02662356  	0.19710717  	0.10961851  
2023-05-15 20:28:04.529: Find a better model.
2023-05-15 20:28:12.010: [iter 157 : loss : 0.1104 = 0.0209 + 0.0824 + 0.0070, time: 7.479950]
2023-05-15 20:28:12.165: epoch 157:	0.02660944  	0.19673002  	0.10940153  
2023-05-15 20:28:19.394: [iter 158 : loss : 0.1096 = 0.0201 + 0.0824 + 0.0071, time: 7.226759]
2023-05-15 20:28:19.548: epoch 158:	0.02659533  	0.19649944  	0.10957186  
2023-05-15 20:28:26.982: [iter 159 : loss : 0.1100 = 0.0206 + 0.0824 + 0.0071, time: 7.431608]
2023-05-15 20:28:27.136: epoch 159:	0.02659533  	0.19623803  	0.10954729  
2023-05-15 20:28:34.397: [iter 160 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.260290]
2023-05-15 20:28:34.549: epoch 160:	0.02656711  	0.19576643  	0.10931947  
2023-05-15 20:28:41.970: [iter 161 : loss : 0.1093 = 0.0198 + 0.0823 + 0.0071, time: 7.418350]
2023-05-15 20:28:42.124: epoch 161:	0.02649654  	0.19496259  	0.10909974  
2023-05-15 20:28:49.389: [iter 162 : loss : 0.1085 = 0.0190 + 0.0823 + 0.0072, time: 7.264786]
2023-05-15 20:28:49.541: epoch 162:	0.02652477  	0.19523409  	0.10911970  
2023-05-15 20:28:56.960: [iter 163 : loss : 0.1088 = 0.0193 + 0.0823 + 0.0072, time: 7.417566]
2023-05-15 20:28:57.102: epoch 163:	0.02646126  	0.19486326  	0.10898367  
2023-05-15 20:29:04.388: [iter 164 : loss : 0.1085 = 0.0190 + 0.0822 + 0.0072, time: 7.285058]
2023-05-15 20:29:04.543: epoch 164:	0.02644715  	0.19454248  	0.10897729  
2023-05-15 20:29:11.949: [iter 165 : loss : 0.1085 = 0.0190 + 0.0822 + 0.0072, time: 7.405169]
2023-05-15 20:29:12.091: epoch 165:	0.02644715  	0.19468538  	0.10893644  
2023-05-15 20:29:19.380: [iter 166 : loss : 0.1082 = 0.0187 + 0.0822 + 0.0073, time: 7.286306]
2023-05-15 20:29:19.535: epoch 166:	0.02643303  	0.19455788  	0.10878211  
2023-05-15 20:29:26.956: [iter 167 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0073, time: 7.419471]
2023-05-15 20:29:27.097: epoch 167:	0.02639070  	0.19431765  	0.10882697  
2023-05-15 20:29:34.541: [iter 168 : loss : 0.1080 = 0.0186 + 0.0822 + 0.0073, time: 7.440864]
2023-05-15 20:29:34.694: epoch 168:	0.02640481  	0.19464372  	0.10888305  
2023-05-15 20:29:42.159: [iter 169 : loss : 0.1081 = 0.0186 + 0.0821 + 0.0073, time: 7.464479]
2023-05-15 20:29:42.316: epoch 169:	0.02648949  	0.19489565  	0.10914592  
2023-05-15 20:29:49.568: [iter 170 : loss : 0.1077 = 0.0182 + 0.0821 + 0.0073, time: 7.249696]
2023-05-15 20:29:49.721: epoch 170:	0.02650360  	0.19516166  	0.10912966  
2023-05-15 20:29:57.161: [iter 171 : loss : 0.1081 = 0.0187 + 0.0821 + 0.0074, time: 7.438639]
2023-05-15 20:29:57.317: epoch 171:	0.02660239  	0.19563697  	0.10941936  
2023-05-15 20:30:04.565: [iter 172 : loss : 0.1072 = 0.0177 + 0.0820 + 0.0074, time: 7.245933]
2023-05-15 20:30:04.718: epoch 172:	0.02653182  	0.19516107  	0.10937190  
2023-05-15 20:30:11.948: [iter 173 : loss : 0.1078 = 0.0183 + 0.0820 + 0.0074, time: 7.228597]
2023-05-15 20:30:12.090: epoch 173:	0.02644714  	0.19462503  	0.10925110  
2023-05-15 20:30:19.348: [iter 174 : loss : 0.1072 = 0.0178 + 0.0820 + 0.0074, time: 7.255530]
2023-05-15 20:30:19.501: epoch 174:	0.02645420  	0.19471894  	0.10908888  
2023-05-15 20:30:26.742: [iter 175 : loss : 0.1067 = 0.0172 + 0.0820 + 0.0075, time: 7.240079]
2023-05-15 20:30:26.896: epoch 175:	0.02645421  	0.19506727  	0.10917886  
2023-05-15 20:30:34.150: [iter 176 : loss : 0.1067 = 0.0173 + 0.0820 + 0.0075, time: 7.253456]
2023-05-15 20:30:34.307: epoch 176:	0.02639775  	0.19468373  	0.10898258  
2023-05-15 20:30:41.552: [iter 177 : loss : 0.1072 = 0.0177 + 0.0819 + 0.0075, time: 7.244548]
2023-05-15 20:30:41.706: epoch 177:	0.02645421  	0.19500636  	0.10922419  
2023-05-15 20:30:48.943: [iter 178 : loss : 0.1063 = 0.0168 + 0.0819 + 0.0075, time: 7.235594]
2023-05-15 20:30:49.096: epoch 178:	0.02641187  	0.19476141  	0.10905332  
2023-05-15 20:30:56.335: [iter 179 : loss : 0.1062 = 0.0167 + 0.0819 + 0.0076, time: 7.237323]
2023-05-15 20:30:56.490: epoch 179:	0.02644715  	0.19494364  	0.10903572  
2023-05-15 20:31:03.751: [iter 180 : loss : 0.1063 = 0.0168 + 0.0819 + 0.0076, time: 7.259974]
2023-05-15 20:31:03.906: epoch 180:	0.02651771  	0.19523951  	0.10913877  
2023-05-15 20:31:11.137: [iter 181 : loss : 0.1064 = 0.0170 + 0.0818 + 0.0076, time: 7.230184]
2023-05-15 20:31:11.294: epoch 181:	0.02649654  	0.19522996  	0.10931105  
2023-05-15 20:31:11.294: Early stopping is trigger at epoch: 181
2023-05-15 20:31:11.294: best_result@epoch 156:

2023-05-15 20:31:11.294: 		0.0266      	0.1971      	0.1096      
2023-05-15 20:46:35.816: my pid: 9432
2023-05-15 20:46:35.816: model: model.general_recommender.SGL
2023-05-15 20:46:35.816: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 20:46:35.816: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 20:46:38.898: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 20:46:47.135: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.236259]
2023-05-15 20:46:47.293: epoch 1:	0.00139712  	0.01064637  	0.00512284  
2023-05-15 20:46:47.293: Find a better model.
2023-05-15 20:46:55.727: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.433320]
2023-05-15 20:46:55.933: epoch 2:	0.00290008  	0.02124552  	0.01045007  
2023-05-15 20:46:55.933: Find a better model.
2023-05-15 20:47:04.112: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 8.176830]
2023-05-15 20:47:04.282: epoch 3:	0.00500279  	0.03714212  	0.01762649  
2023-05-15 20:47:04.282: Find a better model.
2023-05-15 20:47:12.520: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 8.236315]
2023-05-15 20:47:12.696: epoch 4:	0.00771939  	0.05660738  	0.02718809  
2023-05-15 20:47:12.696: Find a better model.
2023-05-15 20:47:20.718: [iter 5 : loss : 0.7698 = 0.6910 + 0.0788 + 0.0000, time: 8.020863]
2023-05-15 20:47:20.885: epoch 5:	0.01109230  	0.08082063  	0.03825901  
2023-05-15 20:47:20.885: Find a better model.
2023-05-15 20:47:28.962: [iter 6 : loss : 0.7677 = 0.6885 + 0.0792 + 0.0000, time: 8.075621]
2023-05-15 20:47:29.116: epoch 6:	0.01466286  	0.10622296  	0.05103185  
2023-05-15 20:47:29.116: Find a better model.
2023-05-15 20:47:37.097: [iter 7 : loss : 0.7621 = 0.6821 + 0.0799 + 0.0000, time: 7.979928]
2023-05-15 20:47:37.261: epoch 7:	0.01735135  	0.12675670  	0.06182015  
2023-05-15 20:47:37.261: Find a better model.
2023-05-15 20:47:45.106: [iter 8 : loss : 0.7481 = 0.6664 + 0.0816 + 0.0001, time: 7.844446]
2023-05-15 20:47:45.270: epoch 8:	0.01873442  	0.13720629  	0.06812342  
2023-05-15 20:47:45.270: Find a better model.
2023-05-15 20:47:53.099: [iter 9 : loss : 0.7158 = 0.6305 + 0.0852 + 0.0001, time: 7.827193]
2023-05-15 20:47:53.248: epoch 9:	0.01888967  	0.13967121  	0.06945480  
2023-05-15 20:47:53.248: Find a better model.
2023-05-15 20:48:01.102: [iter 10 : loss : 0.6580 = 0.5673 + 0.0905 + 0.0002, time: 7.852404]
2023-05-15 20:48:01.260: epoch 10:	0.01855094  	0.13752735  	0.06805793  
2023-05-15 20:48:09.147: [iter 11 : loss : 0.5831 = 0.4869 + 0.0957 + 0.0004, time: 7.885652]
2023-05-15 20:48:09.305: epoch 11:	0.01847333  	0.13665795  	0.06791363  
2023-05-15 20:48:17.116: [iter 12 : loss : 0.5126 = 0.4127 + 0.0993 + 0.0005, time: 7.809417]
2023-05-15 20:48:17.278: epoch 12:	0.01851567  	0.13678066  	0.06820800  
2023-05-15 20:48:25.081: [iter 13 : loss : 0.4597 = 0.3577 + 0.1013 + 0.0007, time: 7.802351]
2023-05-15 20:48:25.228: epoch 13:	0.01861446  	0.13753647  	0.06895677  
2023-05-15 20:48:32.895: [iter 14 : loss : 0.4198 = 0.3166 + 0.1023 + 0.0008, time: 7.665012]
2023-05-15 20:48:33.049: epoch 14:	0.01886144  	0.13977152  	0.07001299  
2023-05-15 20:48:33.049: Find a better model.
2023-05-15 20:48:40.884: [iter 15 : loss : 0.3920 = 0.2883 + 0.1027 + 0.0010, time: 7.831862]
2023-05-15 20:48:41.040: epoch 15:	0.01908019  	0.14135072  	0.07090973  
2023-05-15 20:48:41.040: Find a better model.
2023-05-15 20:48:48.689: [iter 16 : loss : 0.3690 = 0.2651 + 0.1029 + 0.0011, time: 7.648208]
2023-05-15 20:48:48.834: epoch 16:	0.01920720  	0.14271122  	0.07161926  
2023-05-15 20:48:48.835: Find a better model.
2023-05-15 20:48:56.464: [iter 17 : loss : 0.3519 = 0.2481 + 0.1027 + 0.0012, time: 7.627934]
2023-05-15 20:48:56.620: epoch 17:	0.01939067  	0.14360301  	0.07205790  
2023-05-15 20:48:56.620: Find a better model.
2023-05-15 20:49:04.343: [iter 18 : loss : 0.3363 = 0.2326 + 0.1024 + 0.0013, time: 7.722479]
2023-05-15 20:49:04.501: epoch 18:	0.01951770  	0.14464100  	0.07292221  
2023-05-15 20:49:04.501: Find a better model.
2023-05-15 20:49:12.051: [iter 19 : loss : 0.3220 = 0.2186 + 0.1021 + 0.0014, time: 7.548424]
2023-05-15 20:49:12.198: epoch 19:	0.01979290  	0.14637586  	0.07391120  
2023-05-15 20:49:12.198: Find a better model.
2023-05-15 20:49:19.718: [iter 20 : loss : 0.3123 = 0.2092 + 0.1016 + 0.0015, time: 7.519610]
2023-05-15 20:49:19.860: epoch 20:	0.01992698  	0.14712811  	0.07452204  
2023-05-15 20:49:19.860: Find a better model.
2023-05-15 20:49:27.244: [iter 21 : loss : 0.3022 = 0.1995 + 0.1012 + 0.0016, time: 7.381640]
2023-05-15 20:49:27.390: epoch 21:	0.02013162  	0.14860570  	0.07519632  
2023-05-15 20:49:27.390: Find a better model.
2023-05-15 20:49:34.840: [iter 22 : loss : 0.2939 = 0.1915 + 0.1008 + 0.0016, time: 7.448977]
2023-05-15 20:49:34.994: epoch 22:	0.02031508  	0.15001518  	0.07598364  
2023-05-15 20:49:34.994: Find a better model.
2023-05-15 20:49:42.456: [iter 23 : loss : 0.2858 = 0.1836 + 0.1004 + 0.0017, time: 7.460861]
2023-05-15 20:49:42.598: epoch 23:	0.02047738  	0.15113702  	0.07673635  
2023-05-15 20:49:42.598: Find a better model.
2023-05-15 20:49:50.063: [iter 24 : loss : 0.2790 = 0.1773 + 0.0999 + 0.0018, time: 7.463487]
2023-05-15 20:49:50.205: epoch 24:	0.02068907  	0.15264747  	0.07754871  
2023-05-15 20:49:50.206: Find a better model.
2023-05-15 20:49:57.635: [iter 25 : loss : 0.2723 = 0.1709 + 0.0995 + 0.0019, time: 7.427526]
2023-05-15 20:49:57.779: epoch 25:	0.02079492  	0.15360464  	0.07805569  
2023-05-15 20:49:57.779: Find a better model.
2023-05-15 20:50:05.275: [iter 26 : loss : 0.2687 = 0.1676 + 0.0991 + 0.0019, time: 7.495253]
2023-05-15 20:50:05.422: epoch 26:	0.02099955  	0.15480626  	0.07888783  
2023-05-15 20:50:05.422: Find a better model.
2023-05-15 20:50:12.855: [iter 27 : loss : 0.2610 = 0.1603 + 0.0987 + 0.0020, time: 7.431695]
2023-05-15 20:50:13.009: epoch 27:	0.02122536  	0.15646344  	0.07981767  
2023-05-15 20:50:13.009: Find a better model.
2023-05-15 20:50:20.606: [iter 28 : loss : 0.2560 = 0.1557 + 0.0982 + 0.0021, time: 7.596486]
2023-05-15 20:50:20.762: epoch 28:	0.02143706  	0.15800183  	0.08069836  
2023-05-15 20:50:20.763: Find a better model.
2023-05-15 20:50:28.431: [iter 29 : loss : 0.2515 = 0.1515 + 0.0978 + 0.0021, time: 7.666483]
2023-05-15 20:50:28.593: epoch 29:	0.02159936  	0.15933241  	0.08143754  
2023-05-15 20:50:28.593: Find a better model.
2023-05-15 20:50:36.218: [iter 30 : loss : 0.2450 = 0.1452 + 0.0975 + 0.0022, time: 7.624441]
2023-05-15 20:50:36.371: epoch 30:	0.02178283  	0.16018821  	0.08223974  
2023-05-15 20:50:36.371: Find a better model.
2023-05-15 20:50:43.831: [iter 31 : loss : 0.2411 = 0.1418 + 0.0970 + 0.0023, time: 7.458660]
2023-05-15 20:50:43.976: epoch 31:	0.02189574  	0.16120650  	0.08281671  
2023-05-15 20:50:43.977: Find a better model.
2023-05-15 20:50:51.648: [iter 32 : loss : 0.2356 = 0.1366 + 0.0967 + 0.0023, time: 7.670051]
2023-05-15 20:50:51.803: epoch 32:	0.02202981  	0.16208163  	0.08335197  
2023-05-15 20:50:51.803: Find a better model.
2023-05-15 20:50:59.257: [iter 33 : loss : 0.2330 = 0.1344 + 0.0963 + 0.0024, time: 7.451394]
2023-05-15 20:50:59.412: epoch 33:	0.02218505  	0.16361144  	0.08400836  
2023-05-15 20:50:59.412: Find a better model.
2023-05-15 20:51:06.816: [iter 34 : loss : 0.2290 = 0.1306 + 0.0960 + 0.0024, time: 7.402678]
2023-05-15 20:51:06.970: epoch 34:	0.02229089  	0.16420048  	0.08462173  
2023-05-15 20:51:06.971: Find a better model.
2023-05-15 20:51:14.596: [iter 35 : loss : 0.2254 = 0.1273 + 0.0957 + 0.0025, time: 7.624075]
2023-05-15 20:51:14.752: epoch 35:	0.02248848  	0.16559888  	0.08543865  
2023-05-15 20:51:14.752: Find a better model.
2023-05-15 20:51:22.434: [iter 36 : loss : 0.2220 = 0.1241 + 0.0954 + 0.0025, time: 7.681367]
2023-05-15 20:51:22.593: epoch 36:	0.02269312  	0.16699742  	0.08632956  
2023-05-15 20:51:22.593: Find a better model.
2023-05-15 20:51:30.197: [iter 37 : loss : 0.2183 = 0.1207 + 0.0950 + 0.0026, time: 7.603037]
2023-05-15 20:51:30.341: epoch 37:	0.02274957  	0.16751266  	0.08670580  
2023-05-15 20:51:30.341: Find a better model.
2023-05-15 20:51:37.814: [iter 38 : loss : 0.2166 = 0.1193 + 0.0947 + 0.0027, time: 7.471841]
2023-05-15 20:51:37.971: epoch 38:	0.02288365  	0.16895700  	0.08741747  
2023-05-15 20:51:37.971: Find a better model.
2023-05-15 20:51:45.418: [iter 39 : loss : 0.2121 = 0.1150 + 0.0944 + 0.0027, time: 7.445446]
2023-05-15 20:51:45.565: epoch 39:	0.02294010  	0.16965607  	0.08819154  
2023-05-15 20:51:45.565: Find a better model.
2023-05-15 20:51:53.021: [iter 40 : loss : 0.2087 = 0.1119 + 0.0941 + 0.0028, time: 7.454235]
2023-05-15 20:51:53.175: epoch 40:	0.02303183  	0.17030644  	0.08868867  
2023-05-15 20:51:53.175: Find a better model.
2023-05-15 20:52:00.620: [iter 41 : loss : 0.2072 = 0.1106 + 0.0938 + 0.0028, time: 7.442348]
2023-05-15 20:52:00.772: epoch 41:	0.02316590  	0.17093703  	0.08919692  
2023-05-15 20:52:00.773: Find a better model.
2023-05-15 20:52:08.232: [iter 42 : loss : 0.2051 = 0.1087 + 0.0935 + 0.0029, time: 7.458488]
2023-05-15 20:52:08.384: epoch 42:	0.02327881  	0.17185538  	0.08972466  
2023-05-15 20:52:08.385: Find a better model.
2023-05-15 20:52:15.816: [iter 43 : loss : 0.2011 = 0.1049 + 0.0932 + 0.0029, time: 7.429566]
2023-05-15 20:52:15.968: epoch 43:	0.02341288  	0.17306107  	0.09039411  
2023-05-15 20:52:15.969: Find a better model.
2023-05-15 20:52:23.401: [iter 44 : loss : 0.1977 = 0.1018 + 0.0929 + 0.0030, time: 7.431572]
2023-05-15 20:52:23.556: epoch 44:	0.02351873  	0.17377055  	0.09107868  
2023-05-15 20:52:23.556: Find a better model.
2023-05-15 20:52:31.048: [iter 45 : loss : 0.1956 = 0.0999 + 0.0927 + 0.0030, time: 7.489046]
2023-05-15 20:52:31.191: epoch 45:	0.02361046  	0.17435272  	0.09163210  
2023-05-15 20:52:31.191: Find a better model.
2023-05-15 20:52:38.594: [iter 46 : loss : 0.1928 = 0.0973 + 0.0925 + 0.0031, time: 7.402507]
2023-05-15 20:52:38.747: epoch 46:	0.02373043  	0.17547713  	0.09216293  
2023-05-15 20:52:38.747: Find a better model.
2023-05-15 20:52:46.197: [iter 47 : loss : 0.1923 = 0.0969 + 0.0922 + 0.0031, time: 7.448148]
2023-05-15 20:52:46.350: epoch 47:	0.02390684  	0.17691198  	0.09289034  
2023-05-15 20:52:46.350: Find a better model.
2023-05-15 20:52:53.821: [iter 48 : loss : 0.1883 = 0.0932 + 0.0919 + 0.0032, time: 7.470056]
2023-05-15 20:52:53.975: epoch 48:	0.02392095  	0.17671293  	0.09308804  
2023-05-15 20:53:01.583: [iter 49 : loss : 0.1853 = 0.0903 + 0.0918 + 0.0032, time: 7.606725]
2023-05-15 20:53:01.737: epoch 49:	0.02408325  	0.17802851  	0.09385768  
2023-05-15 20:53:01.737: Find a better model.
2023-05-15 20:53:09.175: [iter 50 : loss : 0.1843 = 0.0895 + 0.0915 + 0.0033, time: 7.437092]
2023-05-15 20:53:09.329: epoch 50:	0.02420321  	0.17876162  	0.09447531  
2023-05-15 20:53:09.329: Find a better model.
2023-05-15 20:53:16.773: [iter 51 : loss : 0.1812 = 0.0865 + 0.0913 + 0.0033, time: 7.442417]
2023-05-15 20:53:16.926: epoch 51:	0.02421732  	0.17858954  	0.09452567  
2023-05-15 20:53:24.411: [iter 52 : loss : 0.1814 = 0.0869 + 0.0912 + 0.0034, time: 7.484383]
2023-05-15 20:53:24.563: epoch 52:	0.02432316  	0.17963380  	0.09502362  
2023-05-15 20:53:24.563: Find a better model.
2023-05-15 20:53:31.977: [iter 53 : loss : 0.1791 = 0.0848 + 0.0909 + 0.0034, time: 7.412652]
2023-05-15 20:53:32.131: epoch 53:	0.02444312  	0.18055911  	0.09577537  
2023-05-15 20:53:32.131: Find a better model.
2023-05-15 20:53:39.592: [iter 54 : loss : 0.1771 = 0.0829 + 0.0907 + 0.0035, time: 7.460452]
2023-05-15 20:53:39.746: epoch 54:	0.02447841  	0.18072176  	0.09597135  
2023-05-15 20:53:39.747: Find a better model.
2023-05-15 20:53:47.186: [iter 55 : loss : 0.1752 = 0.0812 + 0.0905 + 0.0035, time: 7.437125]
2023-05-15 20:53:47.339: epoch 55:	0.02455603  	0.18145902  	0.09621515  
2023-05-15 20:53:47.339: Find a better model.
2023-05-15 20:53:54.962: [iter 56 : loss : 0.1734 = 0.0796 + 0.0903 + 0.0035, time: 7.620949]
2023-05-15 20:53:55.118: epoch 56:	0.02463366  	0.18190351  	0.09660967  
2023-05-15 20:53:55.118: Find a better model.
2023-05-15 20:54:02.552: [iter 57 : loss : 0.1718 = 0.0780 + 0.0902 + 0.0036, time: 7.432301]
2023-05-15 20:54:02.697: epoch 57:	0.02465481  	0.18214573  	0.09685838  
2023-05-15 20:54:02.697: Find a better model.
2023-05-15 20:54:10.167: [iter 58 : loss : 0.1696 = 0.0760 + 0.0900 + 0.0036, time: 7.468688]
2023-05-15 20:54:10.323: epoch 58:	0.02469010  	0.18227217  	0.09707057  
2023-05-15 20:54:10.323: Find a better model.
2023-05-15 20:54:17.786: [iter 59 : loss : 0.1686 = 0.0751 + 0.0898 + 0.0037, time: 7.461867]
2023-05-15 20:54:17.940: epoch 59:	0.02476066  	0.18293361  	0.09756676  
2023-05-15 20:54:17.940: Find a better model.
2023-05-15 20:54:25.370: [iter 60 : loss : 0.1671 = 0.0737 + 0.0896 + 0.0037, time: 7.429515]
2023-05-15 20:54:25.514: epoch 60:	0.02479594  	0.18331820  	0.09787403  
2023-05-15 20:54:25.514: Find a better model.
2023-05-15 20:54:32.948: [iter 61 : loss : 0.1659 = 0.0726 + 0.0895 + 0.0038, time: 7.432954]
2023-05-15 20:54:33.102: epoch 61:	0.02485239  	0.18376109  	0.09825821  
2023-05-15 20:54:33.102: Find a better model.
2023-05-15 20:54:40.768: [iter 62 : loss : 0.1641 = 0.0710 + 0.0893 + 0.0038, time: 7.659964]
2023-05-15 20:54:40.911: epoch 62:	0.02489473  	0.18401681  	0.09846184  
2023-05-15 20:54:40.911: Find a better model.
2023-05-15 20:54:48.372: [iter 63 : loss : 0.1629 = 0.0698 + 0.0892 + 0.0039, time: 7.459444]
2023-05-15 20:54:48.526: epoch 63:	0.02487356  	0.18386452  	0.09861626  
2023-05-15 20:54:55.968: [iter 64 : loss : 0.1617 = 0.0689 + 0.0889 + 0.0039, time: 7.440975]
2023-05-15 20:54:56.123: epoch 64:	0.02498646  	0.18477695  	0.09906613  
2023-05-15 20:54:56.123: Find a better model.
2023-05-15 20:55:03.752: [iter 65 : loss : 0.1604 = 0.0677 + 0.0888 + 0.0039, time: 7.628178]
2023-05-15 20:55:03.905: epoch 65:	0.02500057  	0.18446141  	0.09911881  
2023-05-15 20:55:11.363: [iter 66 : loss : 0.1590 = 0.0664 + 0.0886 + 0.0040, time: 7.456905]
2023-05-15 20:55:11.506: epoch 66:	0.02514876  	0.18554223  	0.09981380  
2023-05-15 20:55:11.506: Find a better model.
2023-05-15 20:55:18.953: [iter 67 : loss : 0.1573 = 0.0648 + 0.0885 + 0.0040, time: 7.446025]
2023-05-15 20:55:19.106: epoch 67:	0.02509231  	0.18501186  	0.09986170  
2023-05-15 20:55:26.705: [iter 68 : loss : 0.1572 = 0.0648 + 0.0884 + 0.0041, time: 7.597123]
2023-05-15 20:55:26.859: epoch 68:	0.02522638  	0.18591852  	0.10043156  
2023-05-15 20:55:26.859: Find a better model.
2023-05-15 20:55:34.345: [iter 69 : loss : 0.1552 = 0.0629 + 0.0882 + 0.0041, time: 7.484262]
2023-05-15 20:55:34.502: epoch 69:	0.02531106  	0.18676007  	0.10073603  
2023-05-15 20:55:34.503: Find a better model.
2023-05-15 20:55:41.934: [iter 70 : loss : 0.1533 = 0.0611 + 0.0881 + 0.0041, time: 7.429842]
2023-05-15 20:55:42.090: epoch 70:	0.02534634  	0.18691008  	0.10083483  
2023-05-15 20:55:42.091: Find a better model.
2023-05-15 20:55:49.733: [iter 71 : loss : 0.1520 = 0.0599 + 0.0880 + 0.0042, time: 7.641595]
2023-05-15 20:55:49.885: epoch 71:	0.02535340  	0.18699118  	0.10116521  
2023-05-15 20:55:49.885: Find a better model.
2023-05-15 20:55:57.371: [iter 72 : loss : 0.1518 = 0.0597 + 0.0878 + 0.0042, time: 7.484966]
2023-05-15 20:55:57.528: epoch 72:	0.02539573  	0.18718518  	0.10130591  
2023-05-15 20:55:57.528: Find a better model.
2023-05-15 20:56:05.138: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 7.608178]
2023-05-15 20:56:05.291: epoch 73:	0.02552275  	0.18838431  	0.10184173  
2023-05-15 20:56:05.291: Find a better model.
2023-05-15 20:56:12.908: [iter 74 : loss : 0.1492 = 0.0572 + 0.0877 + 0.0043, time: 7.616795]
2023-05-15 20:56:13.061: epoch 74:	0.02550864  	0.18807459  	0.10197104  
2023-05-15 20:56:20.510: [iter 75 : loss : 0.1486 = 0.0567 + 0.0875 + 0.0044, time: 7.447270]
2023-05-15 20:56:20.664: epoch 75:	0.02555803  	0.18836372  	0.10214783  
2023-05-15 20:56:28.100: [iter 76 : loss : 0.1473 = 0.0555 + 0.0874 + 0.0044, time: 7.434314]
2023-05-15 20:56:28.244: epoch 76:	0.02557920  	0.18853520  	0.10239559  
2023-05-15 20:56:28.244: Find a better model.
2023-05-15 20:56:35.723: [iter 77 : loss : 0.1466 = 0.0549 + 0.0872 + 0.0044, time: 7.478604]
2023-05-15 20:56:35.881: epoch 77:	0.02564271  	0.18878765  	0.10267823  
2023-05-15 20:56:35.881: Find a better model.
2023-05-15 20:56:43.523: [iter 78 : loss : 0.1454 = 0.0537 + 0.0872 + 0.0045, time: 7.641186]
2023-05-15 20:56:43.681: epoch 78:	0.02564976  	0.18910027  	0.10271413  
2023-05-15 20:56:43.681: Find a better model.
2023-05-15 20:56:51.303: [iter 79 : loss : 0.1443 = 0.0527 + 0.0870 + 0.0045, time: 7.619513]
2023-05-15 20:56:51.458: epoch 79:	0.02569210  	0.18914913  	0.10299361  
2023-05-15 20:56:51.458: Find a better model.
2023-05-15 20:56:59.111: [iter 80 : loss : 0.1434 = 0.0518 + 0.0870 + 0.0046, time: 7.650957]
2023-05-15 20:56:59.265: epoch 80:	0.02560037  	0.18833296  	0.10282558  
2023-05-15 20:57:06.693: [iter 81 : loss : 0.1434 = 0.0520 + 0.0868 + 0.0046, time: 7.427903]
2023-05-15 20:57:06.835: epoch 81:	0.02569916  	0.18906315  	0.10309117  
2023-05-15 20:57:14.278: [iter 82 : loss : 0.1419 = 0.0506 + 0.0867 + 0.0046, time: 7.440823]
2023-05-15 20:57:14.435: epoch 82:	0.02576973  	0.18953526  	0.10338745  
2023-05-15 20:57:14.435: Find a better model.
2023-05-15 20:57:21.912: [iter 83 : loss : 0.1409 = 0.0496 + 0.0866 + 0.0047, time: 7.475234]
2023-05-15 20:57:22.067: epoch 83:	0.02576973  	0.18957612  	0.10353216  
2023-05-15 20:57:22.068: Find a better model.
2023-05-15 20:57:29.512: [iter 84 : loss : 0.1408 = 0.0496 + 0.0865 + 0.0047, time: 7.443763]
2023-05-15 20:57:29.656: epoch 84:	0.02583323  	0.19013464  	0.10395689  
2023-05-15 20:57:29.657: Find a better model.
2023-05-15 20:57:37.260: [iter 85 : loss : 0.1398 = 0.0486 + 0.0864 + 0.0048, time: 7.601111]
2023-05-15 20:57:37.418: epoch 85:	0.02581206  	0.18961026  	0.10393079  
2023-05-15 20:57:44.877: [iter 86 : loss : 0.1397 = 0.0486 + 0.0863 + 0.0048, time: 7.458036]
2023-05-15 20:57:45.029: epoch 86:	0.02579089  	0.18940984  	0.10395438  
2023-05-15 20:57:52.718: [iter 87 : loss : 0.1370 = 0.0459 + 0.0862 + 0.0048, time: 7.687535]
2023-05-15 20:57:52.871: epoch 87:	0.02581206  	0.18945630  	0.10418312  
2023-05-15 20:58:00.285: [iter 88 : loss : 0.1362 = 0.0452 + 0.0861 + 0.0049, time: 7.411692]
2023-05-15 20:58:00.428: epoch 88:	0.02591085  	0.19015321  	0.10446671  
2023-05-15 20:58:00.428: Find a better model.
2023-05-15 20:58:08.059: [iter 89 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 7.630055]
2023-05-15 20:58:08.212: epoch 89:	0.02596024  	0.19071074  	0.10461067  
2023-05-15 20:58:08.212: Find a better model.
2023-05-15 20:58:15.900: [iter 90 : loss : 0.1364 = 0.0454 + 0.0860 + 0.0049, time: 7.686098]
2023-05-15 20:58:16.052: epoch 90:	0.02604492  	0.19152975  	0.10507262  
2023-05-15 20:58:16.053: Find a better model.
2023-05-15 20:58:23.662: [iter 91 : loss : 0.1353 = 0.0444 + 0.0859 + 0.0050, time: 7.608120]
2023-05-15 20:58:23.804: epoch 91:	0.02607314  	0.19182381  	0.10497576  
2023-05-15 20:58:23.804: Find a better model.
2023-05-15 20:58:31.266: [iter 92 : loss : 0.1345 = 0.0437 + 0.0858 + 0.0050, time: 7.460680]
2023-05-15 20:58:31.408: epoch 92:	0.02605903  	0.19176820  	0.10505360  
2023-05-15 20:58:39.048: [iter 93 : loss : 0.1347 = 0.0440 + 0.0857 + 0.0051, time: 7.638930]
2023-05-15 20:58:39.202: epoch 93:	0.02605197  	0.19186471  	0.10509325  
2023-05-15 20:58:39.202: Find a better model.
2023-05-15 20:58:46.851: [iter 94 : loss : 0.1323 = 0.0416 + 0.0856 + 0.0051, time: 7.646452]
2023-05-15 20:58:47.005: epoch 94:	0.02603081  	0.19195388  	0.10520576  
2023-05-15 20:58:47.006: Find a better model.
2023-05-15 20:58:54.656: [iter 95 : loss : 0.1319 = 0.0412 + 0.0856 + 0.0051, time: 7.649625]
2023-05-15 20:58:54.810: epoch 95:	0.02610842  	0.19247070  	0.10555144  
2023-05-15 20:58:54.811: Find a better model.
2023-05-15 20:59:02.282: [iter 96 : loss : 0.1318 = 0.0411 + 0.0855 + 0.0052, time: 7.469432]
2023-05-15 20:59:02.437: epoch 96:	0.02604492  	0.19198164  	0.10541730  
2023-05-15 20:59:10.096: [iter 97 : loss : 0.1303 = 0.0397 + 0.0854 + 0.0052, time: 7.658230]
2023-05-15 20:59:10.248: epoch 97:	0.02610843  	0.19254237  	0.10565093  
2023-05-15 20:59:10.248: Find a better model.
2023-05-15 20:59:17.827: [iter 98 : loss : 0.1311 = 0.0405 + 0.0853 + 0.0052, time: 7.576456]
2023-05-15 20:59:17.970: epoch 98:	0.02619311  	0.19306107  	0.10583191  
2023-05-15 20:59:17.970: Find a better model.
2023-05-15 20:59:25.444: [iter 99 : loss : 0.1300 = 0.0394 + 0.0853 + 0.0053, time: 7.472847]
2023-05-15 20:59:25.598: epoch 99:	0.02624956  	0.19375822  	0.10614328  
2023-05-15 20:59:25.598: Find a better model.
2023-05-15 20:59:33.038: [iter 100 : loss : 0.1292 = 0.0387 + 0.0851 + 0.0053, time: 7.438414]
2023-05-15 20:59:33.191: epoch 100:	0.02625662  	0.19367534  	0.10628467  
2023-05-15 20:59:40.843: [iter 101 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 7.650830]
2023-05-15 20:59:40.995: epoch 101:	0.02632718  	0.19391815  	0.10661644  
2023-05-15 20:59:40.995: Find a better model.
2023-05-15 20:59:48.659: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 7.662549]
2023-05-15 20:59:48.813: epoch 102:	0.02629190  	0.19378947  	0.10662622  
2023-05-15 20:59:56.433: [iter 103 : loss : 0.1275 = 0.0371 + 0.0849 + 0.0054, time: 7.619037]
2023-05-15 20:59:56.584: epoch 103:	0.02632013  	0.19397625  	0.10681825  
2023-05-15 20:59:56.584: Find a better model.
2023-05-15 21:00:04.210: [iter 104 : loss : 0.1281 = 0.0377 + 0.0849 + 0.0055, time: 7.624847]
2023-05-15 21:00:04.352: epoch 104:	0.02629190  	0.19416308  	0.10699639  
2023-05-15 21:00:04.352: Find a better model.
2023-05-15 21:00:12.012: [iter 105 : loss : 0.1274 = 0.0370 + 0.0848 + 0.0055, time: 7.659232]
2023-05-15 21:00:12.165: epoch 105:	0.02629895  	0.19404452  	0.10699219  
2023-05-15 21:00:19.810: [iter 106 : loss : 0.1267 = 0.0364 + 0.0848 + 0.0055, time: 7.644113]
2023-05-15 21:00:19.952: epoch 106:	0.02625661  	0.19357550  	0.10695959  
2023-05-15 21:00:27.421: [iter 107 : loss : 0.1259 = 0.0356 + 0.0847 + 0.0055, time: 7.466133]
2023-05-15 21:00:27.574: epoch 107:	0.02630601  	0.19393842  	0.10710174  
2023-05-15 21:00:35.277: [iter 108 : loss : 0.1255 = 0.0353 + 0.0847 + 0.0056, time: 7.702521]
2023-05-15 21:00:35.431: epoch 108:	0.02632718  	0.19425279  	0.10716477  
2023-05-15 21:00:35.431: Find a better model.
2023-05-15 21:00:43.024: [iter 109 : loss : 0.1242 = 0.0340 + 0.0846 + 0.0056, time: 7.590757]
2023-05-15 21:00:43.179: epoch 109:	0.02627073  	0.19389072  	0.10713153  
2023-05-15 21:00:50.652: [iter 110 : loss : 0.1235 = 0.0333 + 0.0845 + 0.0056, time: 7.472049]
2023-05-15 21:00:50.805: epoch 110:	0.02627073  	0.19382191  	0.10711882  
2023-05-15 21:00:58.421: [iter 111 : loss : 0.1237 = 0.0335 + 0.0845 + 0.0057, time: 7.615595]
2023-05-15 21:00:58.574: epoch 111:	0.02634835  	0.19441713  	0.10751635  
2023-05-15 21:00:58.574: Find a better model.
2023-05-15 21:01:06.267: [iter 112 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 7.691993]
2023-05-15 21:01:06.420: epoch 112:	0.02631307  	0.19475324  	0.10749448  
2023-05-15 21:01:06.420: Find a better model.
2023-05-15 21:01:14.019: [iter 113 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0058, time: 7.598053]
2023-05-15 21:01:14.176: epoch 113:	0.02635541  	0.19493467  	0.10769803  
2023-05-15 21:01:14.176: Find a better model.
2023-05-15 21:01:21.845: [iter 114 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0058, time: 7.668470]
2023-05-15 21:01:21.997: epoch 114:	0.02629896  	0.19446933  	0.10749623  
2023-05-15 21:01:29.629: [iter 115 : loss : 0.1221 = 0.0320 + 0.0842 + 0.0058, time: 7.629569]
2023-05-15 21:01:29.782: epoch 115:	0.02632013  	0.19459055  	0.10753879  
2023-05-15 21:01:37.428: [iter 116 : loss : 0.1211 = 0.0311 + 0.0842 + 0.0058, time: 7.645031]
2023-05-15 21:01:37.579: epoch 116:	0.02635541  	0.19502255  	0.10771566  
2023-05-15 21:01:37.579: Find a better model.
2023-05-15 21:01:45.214: [iter 117 : loss : 0.1214 = 0.0314 + 0.0841 + 0.0059, time: 7.634373]
2023-05-15 21:01:45.367: epoch 117:	0.02634836  	0.19480050  	0.10769751  
2023-05-15 21:01:52.792: [iter 118 : loss : 0.1210 = 0.0310 + 0.0840 + 0.0059, time: 7.424038]
2023-05-15 21:01:52.945: epoch 118:	0.02636953  	0.19525297  	0.10797144  
2023-05-15 21:01:52.945: Find a better model.
2023-05-15 21:02:00.383: [iter 119 : loss : 0.1202 = 0.0302 + 0.0840 + 0.0059, time: 7.435693]
2023-05-15 21:02:00.535: epoch 119:	0.02624956  	0.19407317  	0.10760687  
2023-05-15 21:02:08.030: [iter 120 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0060, time: 7.493305]
2023-05-15 21:02:08.183: epoch 120:	0.02622134  	0.19395092  	0.10753090  
2023-05-15 21:02:15.601: [iter 121 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 7.417152]
2023-05-15 21:02:15.755: epoch 121:	0.02624957  	0.19420750  	0.10761822  
2023-05-15 21:02:23.194: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 7.437159]
2023-05-15 21:02:23.350: epoch 122:	0.02632014  	0.19468978  	0.10774492  
2023-05-15 21:02:30.805: [iter 123 : loss : 0.1193 = 0.0294 + 0.0838 + 0.0061, time: 7.453208]
2023-05-15 21:02:30.960: epoch 123:	0.02620018  	0.19371112  	0.10741292  
2023-05-15 21:02:38.376: [iter 124 : loss : 0.1186 = 0.0287 + 0.0837 + 0.0061, time: 7.414519]
2023-05-15 21:02:38.518: epoch 124:	0.02621429  	0.19374755  	0.10758015  
2023-05-15 21:02:45.968: [iter 125 : loss : 0.1178 = 0.0280 + 0.0837 + 0.0061, time: 7.448844]
2023-05-15 21:02:46.111: epoch 125:	0.02624957  	0.19388007  	0.10768310  
2023-05-15 21:02:53.609: [iter 126 : loss : 0.1180 = 0.0282 + 0.0836 + 0.0062, time: 7.495810]
2023-05-15 21:02:53.761: epoch 126:	0.02626368  	0.19394414  	0.10765436  
2023-05-15 21:03:01.175: [iter 127 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 7.412822]
2023-05-15 21:03:01.332: epoch 127:	0.02624251  	0.19383503  	0.10783245  
2023-05-15 21:03:08.779: [iter 128 : loss : 0.1182 = 0.0284 + 0.0836 + 0.0062, time: 7.446261]
2023-05-15 21:03:08.931: epoch 128:	0.02632719  	0.19432954  	0.10804515  
2023-05-15 21:03:16.417: [iter 129 : loss : 0.1173 = 0.0275 + 0.0835 + 0.0063, time: 7.484259]
2023-05-15 21:03:16.574: epoch 129:	0.02641892  	0.19496445  	0.10818210  
2023-05-15 21:03:24.178: [iter 130 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 7.602072]
2023-05-15 21:03:24.336: epoch 130:	0.02645420  	0.19507381  	0.10822734  
2023-05-15 21:03:31.764: [iter 131 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 7.427269]
2023-05-15 21:03:31.918: epoch 131:	0.02648948  	0.19504096  	0.10810639  
2023-05-15 21:03:39.403: [iter 132 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 7.483289]
2023-05-15 21:03:39.556: epoch 132:	0.02639069  	0.19431826  	0.10811565  
2023-05-15 21:03:46.963: [iter 133 : loss : 0.1151 = 0.0254 + 0.0834 + 0.0064, time: 7.405362]
2023-05-15 21:03:47.115: epoch 133:	0.02639069  	0.19468795  	0.10809444  
2023-05-15 21:03:54.551: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 7.435174]
2023-05-15 21:03:54.704: epoch 134:	0.02645420  	0.19502684  	0.10837104  
2023-05-15 21:04:02.139: [iter 135 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 7.433846]
2023-05-15 21:04:02.279: epoch 135:	0.02646831  	0.19525394  	0.10839595  
2023-05-15 21:04:02.279: Find a better model.
2023-05-15 21:04:09.762: [iter 136 : loss : 0.1154 = 0.0257 + 0.0832 + 0.0065, time: 7.482056]
2023-05-15 21:04:09.914: epoch 136:	0.02652476  	0.19575897  	0.10862051  
2023-05-15 21:04:09.914: Find a better model.
2023-05-15 21:04:17.548: [iter 137 : loss : 0.1148 = 0.0252 + 0.0832 + 0.0065, time: 7.632919]
2023-05-15 21:04:17.701: epoch 137:	0.02648242  	0.19547611  	0.10837641  
2023-05-15 21:04:25.185: [iter 138 : loss : 0.1145 = 0.0248 + 0.0831 + 0.0065, time: 7.482981]
2023-05-15 21:04:25.340: epoch 138:	0.02653887  	0.19565056  	0.10847361  
2023-05-15 21:04:32.736: [iter 139 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.395089]
2023-05-15 21:04:32.889: epoch 139:	0.02650359  	0.19535214  	0.10841223  
2023-05-15 21:04:40.357: [iter 140 : loss : 0.1139 = 0.0243 + 0.0831 + 0.0066, time: 7.465704]
2023-05-15 21:04:40.512: epoch 140:	0.02657415  	0.19554815  	0.10841478  
2023-05-15 21:04:47.918: [iter 141 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 7.404970]
2023-05-15 21:04:48.071: epoch 141:	0.02651770  	0.19480097  	0.10852961  
2023-05-15 21:04:55.534: [iter 142 : loss : 0.1134 = 0.0238 + 0.0830 + 0.0066, time: 7.462040]
2023-05-15 21:04:55.688: epoch 142:	0.02651770  	0.19470626  	0.10838559  
2023-05-15 21:05:03.124: [iter 143 : loss : 0.1134 = 0.0238 + 0.0830 + 0.0067, time: 7.434810]
2023-05-15 21:05:03.265: epoch 143:	0.02649653  	0.19453427  	0.10847414  
2023-05-15 21:05:10.725: [iter 144 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 7.457802]
2023-05-15 21:05:10.877: epoch 144:	0.02648242  	0.19472741  	0.10833022  
2023-05-15 21:05:18.311: [iter 145 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0067, time: 7.431980]
2023-05-15 21:05:18.463: epoch 145:	0.02654592  	0.19514458  	0.10866255  
2023-05-15 21:05:25.722: [iter 146 : loss : 0.1132 = 0.0236 + 0.0828 + 0.0067, time: 7.257456]
2023-05-15 21:05:25.876: epoch 146:	0.02653181  	0.19493270  	0.10872191  
2023-05-15 21:05:33.297: [iter 147 : loss : 0.1128 = 0.0232 + 0.0828 + 0.0068, time: 7.419938]
2023-05-15 21:05:33.457: epoch 147:	0.02649653  	0.19480148  	0.10882688  
2023-05-15 21:05:40.920: [iter 148 : loss : 0.1118 = 0.0222 + 0.0828 + 0.0068, time: 7.462258]
2023-05-15 21:05:41.073: epoch 148:	0.02652476  	0.19490254  	0.10888492  
2023-05-15 21:05:48.320: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 7.245572]
2023-05-15 21:05:48.477: epoch 149:	0.02658121  	0.19555113  	0.10884487  
2023-05-15 21:05:55.916: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 7.437572]
2023-05-15 21:05:56.071: epoch 150:	0.02659531  	0.19526891  	0.10884312  
2023-05-15 21:06:03.316: [iter 151 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0069, time: 7.243758]
2023-05-15 21:06:03.472: epoch 151:	0.02654593  	0.19516999  	0.10889599  
2023-05-15 21:06:10.710: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.237120]
2023-05-15 21:06:10.849: epoch 152:	0.02653182  	0.19489980  	0.10871150  
2023-05-15 21:06:18.284: [iter 153 : loss : 0.1102 = 0.0207 + 0.0826 + 0.0069, time: 7.433139]
2023-05-15 21:06:18.439: epoch 153:	0.02650359  	0.19480465  	0.10865957  
2023-05-15 21:06:25.711: [iter 154 : loss : 0.1106 = 0.0211 + 0.0826 + 0.0070, time: 7.271209]
2023-05-15 21:06:25.854: epoch 154:	0.02648242  	0.19464265  	0.10855488  
2023-05-15 21:06:33.301: [iter 155 : loss : 0.1111 = 0.0216 + 0.0825 + 0.0070, time: 7.445966]
2023-05-15 21:06:33.458: epoch 155:	0.02652476  	0.19487558  	0.10873374  
2023-05-15 21:06:40.730: [iter 156 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 7.270538]
2023-05-15 21:06:40.884: epoch 156:	0.02652476  	0.19487353  	0.10854063  
2023-05-15 21:06:48.287: [iter 157 : loss : 0.1104 = 0.0208 + 0.0825 + 0.0070, time: 7.401938]
2023-05-15 21:06:48.440: epoch 157:	0.02646125  	0.19449115  	0.10842896  
2023-05-15 21:06:55.700: [iter 158 : loss : 0.1097 = 0.0202 + 0.0824 + 0.0071, time: 7.258362]
2023-05-15 21:06:55.851: epoch 158:	0.02648241  	0.19433001  	0.10840972  
2023-05-15 21:07:03.293: [iter 159 : loss : 0.1100 = 0.0205 + 0.0824 + 0.0071, time: 7.440831]
2023-05-15 21:07:03.444: epoch 159:	0.02648242  	0.19418350  	0.10835044  
2023-05-15 21:07:10.705: [iter 160 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.260397]
2023-05-15 21:07:10.857: epoch 160:	0.02644714  	0.19404446  	0.10814501  
2023-05-15 21:07:18.278: [iter 161 : loss : 0.1092 = 0.0197 + 0.0824 + 0.0071, time: 7.419425]
2023-05-15 21:07:18.420: epoch 161:	0.02641186  	0.19377966  	0.10822008  
2023-05-15 21:07:18.420: Early stopping is trigger at epoch: 161
2023-05-15 21:07:18.420: best_result@epoch 136:

2023-05-15 21:07:18.420: 		0.0265      	0.1958      	0.1086      
2023-05-15 21:21:21.814: my pid: 11444
2023-05-15 21:21:21.814: model: model.general_recommender.SGL
2023-05-15 21:21:21.814: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-15 21:21:21.814: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-15 21:21:24.901: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-15 21:21:33.007: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.106589]
2023-05-15 21:21:33.164: epoch 1:	0.00143240  	0.01080607  	0.00531954  
2023-05-15 21:21:33.164: Find a better model.
2023-05-15 21:21:41.427: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.262065]
2023-05-15 21:21:41.619: epoch 2:	0.00265312  	0.02000311  	0.00972350  
2023-05-15 21:21:41.619: Find a better model.
2023-05-15 21:21:49.811: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.190310]
2023-05-15 21:21:49.984: epoch 3:	0.00497457  	0.03749039  	0.01786458  
2023-05-15 21:21:49.984: Find a better model.
2023-05-15 21:21:58.002: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.017644]
2023-05-15 21:21:58.164: epoch 4:	0.00814980  	0.05918120  	0.02876288  
2023-05-15 21:21:58.164: Find a better model.
2023-05-15 21:22:06.014: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 7.849500]
2023-05-15 21:22:06.177: epoch 5:	0.01239070  	0.08989139  	0.04261075  
2023-05-15 21:22:06.177: Find a better model.
2023-05-15 21:22:13.784: [iter 6 : loss : 0.7671 = 0.6879 + 0.0792 + 0.0000, time: 7.604811]
2023-05-15 21:22:13.942: epoch 6:	0.01589773  	0.11451979  	0.05585687  
2023-05-15 21:22:13.942: Find a better model.
2023-05-15 21:22:21.597: [iter 7 : loss : 0.7604 = 0.6804 + 0.0800 + 0.0000, time: 7.654061]
2023-05-15 21:22:21.753: epoch 7:	0.01837452  	0.13332535  	0.06598708  
2023-05-15 21:22:21.754: Find a better model.
2023-05-15 21:22:29.588: [iter 8 : loss : 0.7439 = 0.6619 + 0.0820 + 0.0001, time: 7.832676]
2023-05-15 21:22:29.741: epoch 8:	0.01892494  	0.13910465  	0.06980155  
2023-05-15 21:22:29.742: Find a better model.
2023-05-15 21:22:37.362: [iter 9 : loss : 0.7072 = 0.6211 + 0.0859 + 0.0001, time: 7.618079]
2023-05-15 21:22:37.518: epoch 9:	0.01885438  	0.13938427  	0.07003670  
2023-05-15 21:22:37.518: Find a better model.
2023-05-15 21:22:44.960: [iter 10 : loss : 0.6451 = 0.5536 + 0.0913 + 0.0003, time: 7.440871]
2023-05-15 21:22:45.113: epoch 10:	0.01865680  	0.13807601  	0.06901202  
2023-05-15 21:22:52.584: [iter 11 : loss : 0.5698 = 0.4732 + 0.0962 + 0.0004, time: 7.470566]
2023-05-15 21:22:52.736: epoch 11:	0.01852978  	0.13728814  	0.06858353  
2023-05-15 21:23:00.170: [iter 12 : loss : 0.5021 = 0.4021 + 0.0994 + 0.0006, time: 7.433498]
2023-05-15 21:23:00.328: epoch 12:	0.01856506  	0.13744658  	0.06901094  
2023-05-15 21:23:07.776: [iter 13 : loss : 0.4521 = 0.3502 + 0.1012 + 0.0007, time: 7.445124]
2023-05-15 21:23:07.932: epoch 13:	0.01860741  	0.13785809  	0.06962857  
2023-05-15 21:23:15.380: [iter 14 : loss : 0.4141 = 0.3112 + 0.1020 + 0.0009, time: 7.447294]
2023-05-15 21:23:15.539: epoch 14:	0.01874148  	0.13868792  	0.06979138  
2023-05-15 21:23:22.943: [iter 15 : loss : 0.3877 = 0.2843 + 0.1024 + 0.0010, time: 7.400765]
2023-05-15 21:23:23.097: epoch 15:	0.01896728  	0.13979767  	0.07059398  
2023-05-15 21:23:23.098: Find a better model.
2023-05-15 21:23:30.552: [iter 16 : loss : 0.3654 = 0.2619 + 0.1024 + 0.0011, time: 7.453634]
2023-05-15 21:23:30.707: epoch 16:	0.01914370  	0.14123489  	0.07144646  
2023-05-15 21:23:30.707: Find a better model.
2023-05-15 21:23:38.160: [iter 17 : loss : 0.3491 = 0.2457 + 0.1022 + 0.0012, time: 7.451959]
2023-05-15 21:23:38.315: epoch 17:	0.01927072  	0.14259285  	0.07235906  
2023-05-15 21:23:38.315: Find a better model.
2023-05-15 21:23:45.730: [iter 18 : loss : 0.3338 = 0.2305 + 0.1020 + 0.0013, time: 7.414510]
2023-05-15 21:23:45.884: epoch 18:	0.01948241  	0.14381729  	0.07328003  
2023-05-15 21:23:45.885: Find a better model.
2023-05-15 21:23:53.337: [iter 19 : loss : 0.3195 = 0.2165 + 0.1016 + 0.0014, time: 7.451456]
2023-05-15 21:23:53.490: epoch 19:	0.01960943  	0.14503330  	0.07419096  
2023-05-15 21:23:53.491: Find a better model.
2023-05-15 21:24:00.960: [iter 20 : loss : 0.3099 = 0.2071 + 0.1012 + 0.0015, time: 7.466442]
2023-05-15 21:24:01.114: epoch 20:	0.01983523  	0.14652134  	0.07492934  
2023-05-15 21:24:01.115: Find a better model.
2023-05-15 21:24:08.542: [iter 21 : loss : 0.3002 = 0.1978 + 0.1008 + 0.0016, time: 7.426502]
2023-05-15 21:24:08.696: epoch 21:	0.02001871  	0.14787896  	0.07572124  
2023-05-15 21:24:08.696: Find a better model.
2023-05-15 21:24:16.129: [iter 22 : loss : 0.2919 = 0.1899 + 0.1004 + 0.0017, time: 7.432096]
2023-05-15 21:24:16.286: epoch 22:	0.02030802  	0.14967805  	0.07663371  
2023-05-15 21:24:16.286: Find a better model.
2023-05-15 21:24:23.746: [iter 23 : loss : 0.2837 = 0.1820 + 0.1000 + 0.0017, time: 7.458552]
2023-05-15 21:24:23.901: epoch 23:	0.02046327  	0.15117490  	0.07763571  
2023-05-15 21:24:23.901: Find a better model.
2023-05-15 21:24:31.345: [iter 24 : loss : 0.2772 = 0.1758 + 0.0995 + 0.0018, time: 7.442400]
2023-05-15 21:24:31.501: epoch 24:	0.02064673  	0.15234794  	0.07828386  
2023-05-15 21:24:31.502: Find a better model.
2023-05-15 21:24:38.916: [iter 25 : loss : 0.2707 = 0.1697 + 0.0992 + 0.0019, time: 7.412813]
2023-05-15 21:24:39.072: epoch 25:	0.02092194  	0.15437625  	0.07916505  
2023-05-15 21:24:39.072: Find a better model.
2023-05-15 21:24:46.524: [iter 26 : loss : 0.2670 = 0.1663 + 0.0987 + 0.0020, time: 7.451333]
2023-05-15 21:24:46.681: epoch 26:	0.02116186  	0.15599810  	0.08000991  
2023-05-15 21:24:46.681: Find a better model.
2023-05-15 21:24:54.081: [iter 27 : loss : 0.2592 = 0.1589 + 0.0983 + 0.0020, time: 7.398755]
2023-05-15 21:24:54.223: epoch 27:	0.02138062  	0.15747574  	0.08084572  
2023-05-15 21:24:54.223: Find a better model.
2023-05-15 21:25:01.533: [iter 28 : loss : 0.2544 = 0.1544 + 0.0979 + 0.0021, time: 7.308907]
2023-05-15 21:25:01.691: epoch 28:	0.02152881  	0.15846416  	0.08149239  
2023-05-15 21:25:01.691: Find a better model.
2023-05-15 21:25:08.922: [iter 29 : loss : 0.2495 = 0.1499 + 0.0974 + 0.0021, time: 7.229701]
2023-05-15 21:25:09.076: epoch 29:	0.02166289  	0.15984730  	0.08213085  
2023-05-15 21:25:09.076: Find a better model.
2023-05-15 21:25:16.525: [iter 30 : loss : 0.2432 = 0.1438 + 0.0972 + 0.0022, time: 7.446981]
2023-05-15 21:25:16.681: epoch 30:	0.02176167  	0.16027935  	0.08270543  
2023-05-15 21:25:16.681: Find a better model.
2023-05-15 21:25:23.916: [iter 31 : loss : 0.2397 = 0.1407 + 0.0967 + 0.0023, time: 7.233895]
2023-05-15 21:25:24.070: epoch 31:	0.02185340  	0.16062415  	0.08335659  
2023-05-15 21:25:24.071: Find a better model.
2023-05-15 21:25:31.517: [iter 32 : loss : 0.2343 = 0.1355 + 0.0964 + 0.0023, time: 7.445083]
2023-05-15 21:25:31.676: epoch 32:	0.02196631  	0.16196845  	0.08414432  
2023-05-15 21:25:31.677: Find a better model.
2023-05-15 21:25:39.112: [iter 33 : loss : 0.2317 = 0.1333 + 0.0960 + 0.0024, time: 7.434198]
2023-05-15 21:25:39.266: epoch 33:	0.02217095  	0.16327235  	0.08492725  
2023-05-15 21:25:39.267: Find a better model.
2023-05-15 21:25:46.691: [iter 34 : loss : 0.2275 = 0.1294 + 0.0957 + 0.0024, time: 7.420786]
2023-05-15 21:25:46.845: epoch 34:	0.02230502  	0.16452596  	0.08568838  
2023-05-15 21:25:46.845: Find a better model.
2023-05-15 21:25:54.308: [iter 35 : loss : 0.2240 = 0.1262 + 0.0953 + 0.0025, time: 7.461588]
2023-05-15 21:25:54.462: epoch 35:	0.02236853  	0.16495751  	0.08618890  
2023-05-15 21:25:54.462: Find a better model.
2023-05-15 21:26:01.906: [iter 36 : loss : 0.2205 = 0.1229 + 0.0951 + 0.0026, time: 7.442712]
2023-05-15 21:26:02.058: epoch 36:	0.02254494  	0.16584265  	0.08673305  
2023-05-15 21:26:02.058: Find a better model.
2023-05-15 21:26:09.473: [iter 37 : loss : 0.2167 = 0.1194 + 0.0947 + 0.0026, time: 7.412479]
2023-05-15 21:26:09.628: epoch 37:	0.02271429  	0.16729183  	0.08729852  
2023-05-15 21:26:09.628: Find a better model.
2023-05-15 21:26:16.893: [iter 38 : loss : 0.2150 = 0.1179 + 0.0944 + 0.0027, time: 7.264142]
2023-05-15 21:26:17.049: epoch 38:	0.02282015  	0.16797018  	0.08796468  
2023-05-15 21:26:17.050: Find a better model.
2023-05-15 21:26:24.472: [iter 39 : loss : 0.2107 = 0.1139 + 0.0941 + 0.0027, time: 7.420625]
2023-05-15 21:26:24.613: epoch 39:	0.02304596  	0.16962893  	0.08867587  
2023-05-15 21:26:24.613: Find a better model.
2023-05-15 21:26:31.906: [iter 40 : loss : 0.2074 = 0.1108 + 0.0938 + 0.0028, time: 7.291860]
2023-05-15 21:26:32.060: epoch 40:	0.02309535  	0.16993248  	0.08918390  
2023-05-15 21:26:32.061: Find a better model.
2023-05-15 21:26:39.486: [iter 41 : loss : 0.2059 = 0.1095 + 0.0935 + 0.0028, time: 7.424327]
2023-05-15 21:26:39.639: epoch 41:	0.02321531  	0.17044970  	0.08960159  
2023-05-15 21:26:39.639: Find a better model.
2023-05-15 21:26:46.895: [iter 42 : loss : 0.2034 = 0.1073 + 0.0932 + 0.0029, time: 7.253618]
2023-05-15 21:26:47.050: epoch 42:	0.02339171  	0.17200068  	0.09064266  
2023-05-15 21:26:47.050: Find a better model.
2023-05-15 21:26:54.280: [iter 43 : loss : 0.1998 = 0.1039 + 0.0930 + 0.0029, time: 7.229662]
2023-05-15 21:26:54.435: epoch 43:	0.02343406  	0.17207193  	0.09104466  
2023-05-15 21:26:54.435: Find a better model.
2023-05-15 21:27:01.676: [iter 44 : loss : 0.1960 = 0.1004 + 0.0927 + 0.0030, time: 7.239447]
2023-05-15 21:27:01.828: epoch 44:	0.02353990  	0.17309433  	0.09165561  
2023-05-15 21:27:01.828: Find a better model.
2023-05-15 21:27:09.094: [iter 45 : loss : 0.1938 = 0.0983 + 0.0925 + 0.0030, time: 7.264727]
2023-05-15 21:27:09.248: epoch 45:	0.02366692  	0.17392060  	0.09234166  
2023-05-15 21:27:09.248: Find a better model.
2023-05-15 21:27:16.646: [iter 46 : loss : 0.1915 = 0.0962 + 0.0922 + 0.0031, time: 7.396785]
2023-05-15 21:27:16.800: epoch 46:	0.02373043  	0.17437398  	0.09294739  
2023-05-15 21:27:16.800: Find a better model.
2023-05-15 21:27:24.073: [iter 47 : loss : 0.1910 = 0.0958 + 0.0920 + 0.0031, time: 7.271751]
2023-05-15 21:27:24.227: epoch 47:	0.02391390  	0.17582241  	0.09347732  
2023-05-15 21:27:24.227: Find a better model.
2023-05-15 21:27:31.465: [iter 48 : loss : 0.1870 = 0.0921 + 0.0918 + 0.0032, time: 7.237181]
2023-05-15 21:27:31.619: epoch 48:	0.02401269  	0.17652954  	0.09396978  
2023-05-15 21:27:31.619: Find a better model.
2023-05-15 21:27:38.872: [iter 49 : loss : 0.1840 = 0.0892 + 0.0915 + 0.0032, time: 7.251953]
2023-05-15 21:27:39.029: epoch 49:	0.02406913  	0.17712227  	0.09442919  
2023-05-15 21:27:39.030: Find a better model.
2023-05-15 21:27:46.265: [iter 50 : loss : 0.1829 = 0.0884 + 0.0913 + 0.0033, time: 7.233073]
2023-05-15 21:27:46.420: epoch 50:	0.02420321  	0.17838690  	0.09511657  
2023-05-15 21:27:46.420: Find a better model.
2023-05-15 21:27:53.664: [iter 51 : loss : 0.1800 = 0.0855 + 0.0911 + 0.0033, time: 7.242905]
2023-05-15 21:27:53.819: epoch 51:	0.02425966  	0.17889711  	0.09522731  
2023-05-15 21:27:53.819: Find a better model.
2023-05-15 21:28:01.056: [iter 52 : loss : 0.1799 = 0.0856 + 0.0909 + 0.0034, time: 7.236475]
2023-05-15 21:28:01.211: epoch 52:	0.02431612  	0.17945135  	0.09582900  
2023-05-15 21:28:01.211: Find a better model.
2023-05-15 21:28:08.448: [iter 53 : loss : 0.1779 = 0.0838 + 0.0907 + 0.0034, time: 7.236189]
2023-05-15 21:28:08.592: epoch 53:	0.02439374  	0.17994051  	0.09615836  
2023-05-15 21:28:08.592: Find a better model.
2023-05-15 21:28:15.840: [iter 54 : loss : 0.1758 = 0.0819 + 0.0905 + 0.0035, time: 7.245849]
2023-05-15 21:28:15.987: epoch 54:	0.02453487  	0.18081832  	0.09681753  
2023-05-15 21:28:15.987: Find a better model.
2023-05-15 21:28:23.238: [iter 55 : loss : 0.1740 = 0.0802 + 0.0903 + 0.0035, time: 7.248868]
2023-05-15 21:28:23.393: epoch 55:	0.02457015  	0.18091546  	0.09692591  
2023-05-15 21:28:23.393: Find a better model.
2023-05-15 21:28:30.661: [iter 56 : loss : 0.1719 = 0.0783 + 0.0901 + 0.0036, time: 7.267209]
2023-05-15 21:28:30.818: epoch 56:	0.02457721  	0.18114406  	0.09724688  
2023-05-15 21:28:30.818: Find a better model.
2023-05-15 21:28:38.085: [iter 57 : loss : 0.1706 = 0.0771 + 0.0899 + 0.0036, time: 7.266376]
2023-05-15 21:28:38.233: epoch 57:	0.02471129  	0.18247595  	0.09789167  
2023-05-15 21:28:38.233: Find a better model.
2023-05-15 21:28:45.456: [iter 58 : loss : 0.1685 = 0.0750 + 0.0898 + 0.0037, time: 7.221666]
2023-05-15 21:28:45.610: epoch 58:	0.02477480  	0.18303132  	0.09835811  
2023-05-15 21:28:45.610: Find a better model.
2023-05-15 21:28:53.017: [iter 59 : loss : 0.1674 = 0.0741 + 0.0896 + 0.0037, time: 7.405659]
2023-05-15 21:28:53.173: epoch 59:	0.02481714  	0.18325762  	0.09862298  
2023-05-15 21:28:53.173: Find a better model.
2023-05-15 21:29:00.441: [iter 60 : loss : 0.1661 = 0.0729 + 0.0894 + 0.0037, time: 7.265660]
2023-05-15 21:29:00.596: epoch 60:	0.02490887  	0.18394217  	0.09905130  
2023-05-15 21:29:00.596: Find a better model.
2023-05-15 21:29:08.066: [iter 61 : loss : 0.1645 = 0.0715 + 0.0892 + 0.0038, time: 7.468803]
2023-05-15 21:29:08.224: epoch 61:	0.02494415  	0.18428464  	0.09937046  
2023-05-15 21:29:08.225: Find a better model.
2023-05-15 21:29:15.611: [iter 62 : loss : 0.1630 = 0.0701 + 0.0891 + 0.0038, time: 7.385952]
2023-05-15 21:29:15.753: epoch 62:	0.02505705  	0.18512043  	0.09982267  
2023-05-15 21:29:15.753: Find a better model.
2023-05-15 21:29:23.022: [iter 63 : loss : 0.1617 = 0.0689 + 0.0889 + 0.0039, time: 7.266482]
2023-05-15 21:29:23.179: epoch 63:	0.02509233  	0.18548378  	0.10007735  
2023-05-15 21:29:23.180: Find a better model.
2023-05-15 21:29:30.433: [iter 64 : loss : 0.1606 = 0.0679 + 0.0888 + 0.0039, time: 7.252353]
2023-05-15 21:29:30.587: epoch 64:	0.02516289  	0.18620299  	0.10040482  
2023-05-15 21:29:30.587: Find a better model.
2023-05-15 21:29:38.058: [iter 65 : loss : 0.1593 = 0.0667 + 0.0886 + 0.0040, time: 7.470197]
2023-05-15 21:29:38.215: epoch 65:	0.02524757  	0.18681650  	0.10087377  
2023-05-15 21:29:38.215: Find a better model.
2023-05-15 21:29:45.602: [iter 66 : loss : 0.1579 = 0.0654 + 0.0885 + 0.0040, time: 7.384537]
2023-05-15 21:29:45.756: epoch 66:	0.02530402  	0.18704233  	0.10123992  
2023-05-15 21:29:45.756: Find a better model.
2023-05-15 21:29:53.030: [iter 67 : loss : 0.1562 = 0.0638 + 0.0883 + 0.0040, time: 7.271224]
2023-05-15 21:29:53.187: epoch 67:	0.02540281  	0.18789130  	0.10165498  
2023-05-15 21:29:53.188: Find a better model.
2023-05-15 21:30:00.611: [iter 68 : loss : 0.1560 = 0.0637 + 0.0882 + 0.0041, time: 7.421777]
2023-05-15 21:30:00.767: epoch 68:	0.02544515  	0.18827339  	0.10202510  
2023-05-15 21:30:00.767: Find a better model.
2023-05-15 21:30:08.009: [iter 69 : loss : 0.1541 = 0.0619 + 0.0880 + 0.0041, time: 7.240927]
2023-05-15 21:30:08.168: epoch 69:	0.02546632  	0.18816203  	0.10220641  
2023-05-15 21:30:15.415: [iter 70 : loss : 0.1524 = 0.0603 + 0.0880 + 0.0042, time: 7.246415]
2023-05-15 21:30:15.569: epoch 70:	0.02552982  	0.18890251  	0.10225991  
2023-05-15 21:30:15.569: Find a better model.
2023-05-15 21:30:23.032: [iter 71 : loss : 0.1507 = 0.0588 + 0.0878 + 0.0042, time: 7.461305]
2023-05-15 21:30:23.191: epoch 71:	0.02550865  	0.18890058  	0.10254751  
2023-05-15 21:30:30.578: [iter 72 : loss : 0.1509 = 0.0590 + 0.0877 + 0.0043, time: 7.386276]
2023-05-15 21:30:30.732: epoch 72:	0.02563567  	0.18947837  	0.10287783  
2023-05-15 21:30:30.732: Find a better model.
2023-05-15 21:30:38.003: [iter 73 : loss : 0.1493 = 0.0574 + 0.0876 + 0.0043, time: 7.269773]
2023-05-15 21:30:38.159: epoch 73:	0.02569918  	0.18971214  	0.10301413  
2023-05-15 21:30:38.159: Find a better model.
2023-05-15 21:30:45.400: [iter 74 : loss : 0.1482 = 0.0564 + 0.0875 + 0.0043, time: 7.239661]
2023-05-15 21:30:45.555: epoch 74:	0.02569212  	0.18973818  	0.10326559  
2023-05-15 21:30:45.555: Find a better model.
2023-05-15 21:30:52.804: [iter 75 : loss : 0.1474 = 0.0557 + 0.0873 + 0.0044, time: 7.247805]
2023-05-15 21:30:52.960: epoch 75:	0.02576268  	0.18986857  	0.10348918  
2023-05-15 21:30:52.960: Find a better model.
2023-05-15 21:31:00.200: [iter 76 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 7.239233]
2023-05-15 21:31:00.343: epoch 76:	0.02574857  	0.18954670  	0.10358511  
2023-05-15 21:31:07.591: [iter 77 : loss : 0.1455 = 0.0540 + 0.0871 + 0.0045, time: 7.246420]
2023-05-15 21:31:07.747: epoch 77:	0.02578386  	0.18976817  	0.10373630  
2023-05-15 21:31:14.994: [iter 78 : loss : 0.1445 = 0.0531 + 0.0870 + 0.0045, time: 7.245850]
2023-05-15 21:31:15.151: epoch 78:	0.02591087  	0.19079983  	0.10424711  
2023-05-15 21:31:15.151: Find a better model.
2023-05-15 21:31:22.394: [iter 79 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0045, time: 7.241625]
2023-05-15 21:31:22.538: epoch 79:	0.02593910  	0.19087674  	0.10431025  
2023-05-15 21:31:22.538: Find a better model.
2023-05-15 21:31:29.800: [iter 80 : loss : 0.1426 = 0.0513 + 0.0867 + 0.0046, time: 7.261721]
2023-05-15 21:31:29.953: epoch 80:	0.02599555  	0.19137612  	0.10460641  
2023-05-15 21:31:29.953: Find a better model.
2023-05-15 21:31:37.408: [iter 81 : loss : 0.1423 = 0.0511 + 0.0866 + 0.0046, time: 7.453135]
2023-05-15 21:31:37.560: epoch 81:	0.02606612  	0.19177920  	0.10498214  
2023-05-15 21:31:37.560: Find a better model.
2023-05-15 21:31:44.786: [iter 82 : loss : 0.1411 = 0.0499 + 0.0865 + 0.0047, time: 7.224359]
2023-05-15 21:31:44.941: epoch 82:	0.02617197  	0.19251548  	0.10529868  
2023-05-15 21:31:44.941: Find a better model.
2023-05-15 21:31:52.186: [iter 83 : loss : 0.1401 = 0.0489 + 0.0864 + 0.0047, time: 7.244052]
2023-05-15 21:31:52.342: epoch 83:	0.02620019  	0.19260994  	0.10558222  
2023-05-15 21:31:52.342: Find a better model.
2023-05-15 21:31:59.584: [iter 84 : loss : 0.1400 = 0.0490 + 0.0863 + 0.0047, time: 7.239845]
2023-05-15 21:31:59.737: epoch 84:	0.02617902  	0.19270121  	0.10577287  
2023-05-15 21:31:59.737: Find a better model.
2023-05-15 21:32:07.171: [iter 85 : loss : 0.1390 = 0.0480 + 0.0862 + 0.0048, time: 7.433434]
2023-05-15 21:32:07.331: epoch 85:	0.02620019  	0.19284779  	0.10592590  
2023-05-15 21:32:07.331: Find a better model.
2023-05-15 21:32:14.571: [iter 86 : loss : 0.1389 = 0.0480 + 0.0861 + 0.0048, time: 7.239117]
2023-05-15 21:32:14.726: epoch 86:	0.02616491  	0.19295239  	0.10593825  
2023-05-15 21:32:14.726: Find a better model.
2023-05-15 21:32:22.169: [iter 87 : loss : 0.1361 = 0.0452 + 0.0861 + 0.0049, time: 7.442089]
2023-05-15 21:32:22.327: epoch 87:	0.02617197  	0.19303294  	0.10623926  
2023-05-15 21:32:22.327: Find a better model.
2023-05-15 21:32:29.734: [iter 88 : loss : 0.1355 = 0.0446 + 0.0860 + 0.0049, time: 7.405860]
2023-05-15 21:32:29.888: epoch 88:	0.02620725  	0.19330439  	0.10638307  
2023-05-15 21:32:29.888: Find a better model.
2023-05-15 21:32:37.154: [iter 89 : loss : 0.1351 = 0.0443 + 0.0859 + 0.0049, time: 7.265296]
2023-05-15 21:32:37.295: epoch 89:	0.02622842  	0.19336756  	0.10660417  
2023-05-15 21:32:37.295: Find a better model.
2023-05-15 21:32:44.567: [iter 90 : loss : 0.1357 = 0.0449 + 0.0858 + 0.0050, time: 7.270148]
2023-05-15 21:32:44.722: epoch 90:	0.02632721  	0.19406463  	0.10695174  
2023-05-15 21:32:44.723: Find a better model.
2023-05-15 21:32:52.155: [iter 91 : loss : 0.1343 = 0.0436 + 0.0857 + 0.0050, time: 7.429897]
2023-05-15 21:32:52.312: epoch 91:	0.02635543  	0.19439627  	0.10707873  
2023-05-15 21:32:52.312: Find a better model.
2023-05-15 21:32:59.564: [iter 92 : loss : 0.1334 = 0.0427 + 0.0856 + 0.0050, time: 7.247840]
2023-05-15 21:32:59.718: epoch 92:	0.02631309  	0.19390404  	0.10709952  
2023-05-15 21:33:07.131: [iter 93 : loss : 0.1337 = 0.0432 + 0.0855 + 0.0051, time: 7.412146]
2023-05-15 21:33:07.287: epoch 93:	0.02626370  	0.19342408  	0.10713138  
2023-05-15 21:33:14.554: [iter 94 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.264594]
2023-05-15 21:33:14.707: epoch 94:	0.02629192  	0.19373704  	0.10737886  
2023-05-15 21:33:21.947: [iter 95 : loss : 0.1310 = 0.0405 + 0.0854 + 0.0051, time: 7.238176]
2023-05-15 21:33:22.104: epoch 95:	0.02638366  	0.19469047  	0.10769100  
2023-05-15 21:33:22.104: Find a better model.
2023-05-15 21:33:29.516: [iter 96 : loss : 0.1310 = 0.0405 + 0.0853 + 0.0052, time: 7.409805]
2023-05-15 21:33:29.669: epoch 96:	0.02644717  	0.19521716  	0.10790210  
2023-05-15 21:33:29.670: Find a better model.
2023-05-15 21:33:37.132: [iter 97 : loss : 0.1295 = 0.0390 + 0.0852 + 0.0052, time: 7.459696]
2023-05-15 21:33:37.286: epoch 97:	0.02656007  	0.19613804  	0.10813450  
2023-05-15 21:33:37.286: Find a better model.
2023-05-15 21:33:44.538: [iter 98 : loss : 0.1304 = 0.0400 + 0.0852 + 0.0053, time: 7.250718]
2023-05-15 21:33:44.690: epoch 98:	0.02658124  	0.19629152  	0.10833586  
2023-05-15 21:33:44.690: Find a better model.
2023-05-15 21:33:52.123: [iter 99 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 7.432125]
2023-05-15 21:33:52.278: epoch 99:	0.02661653  	0.19657941  	0.10839751  
2023-05-15 21:33:52.278: Find a better model.
2023-05-15 21:33:59.531: [iter 100 : loss : 0.1286 = 0.0382 + 0.0850 + 0.0053, time: 7.250886]
2023-05-15 21:33:59.672: epoch 100:	0.02661653  	0.19656792  	0.10840953  
2023-05-15 21:34:06.910: [iter 101 : loss : 0.1281 = 0.0378 + 0.0849 + 0.0054, time: 7.236448]
2023-05-15 21:34:07.063: epoch 101:	0.02661653  	0.19667253  	0.10850254  
2023-05-15 21:34:07.063: Find a better model.
2023-05-15 21:34:14.333: [iter 102 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 7.269030]
2023-05-15 21:34:14.491: epoch 102:	0.02658124  	0.19615790  	0.10833208  
2023-05-15 21:34:21.724: [iter 103 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0054, time: 7.231814]
2023-05-15 21:34:21.876: epoch 103:	0.02665886  	0.19661574  	0.10857560  
2023-05-15 21:34:29.108: [iter 104 : loss : 0.1272 = 0.0370 + 0.0847 + 0.0055, time: 7.230852]
2023-05-15 21:34:29.260: epoch 104:	0.02670121  	0.19715284  	0.10861760  
2023-05-15 21:34:29.261: Find a better model.
2023-05-15 21:34:36.509: [iter 105 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 7.246907]
2023-05-15 21:34:36.660: epoch 105:	0.02668003  	0.19686718  	0.10860069  
2023-05-15 21:34:43.895: [iter 106 : loss : 0.1260 = 0.0359 + 0.0846 + 0.0055, time: 7.233534]
2023-05-15 21:34:44.046: epoch 106:	0.02669415  	0.19675478  	0.10866272  
2023-05-15 21:34:51.311: [iter 107 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 7.261842]
2023-05-15 21:34:51.464: epoch 107:	0.02674354  	0.19735803  	0.10891163  
2023-05-15 21:34:51.464: Find a better model.
2023-05-15 21:34:58.716: [iter 108 : loss : 0.1250 = 0.0349 + 0.0845 + 0.0056, time: 7.251272]
2023-05-15 21:34:58.870: epoch 108:	0.02681411  	0.19793899  	0.10910897  
2023-05-15 21:34:58.870: Find a better model.
2023-05-15 21:35:06.097: [iter 109 : loss : 0.1235 = 0.0335 + 0.0844 + 0.0056, time: 7.226108]
2023-05-15 21:35:06.249: epoch 109:	0.02672238  	0.19716936  	0.10898978  
2023-05-15 21:35:13.483: [iter 110 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.232957]
2023-05-15 21:35:13.639: epoch 110:	0.02674355  	0.19748738  	0.10913762  
2023-05-15 21:35:20.890: [iter 111 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.250826]
2023-05-15 21:35:21.043: epoch 111:	0.02680000  	0.19776112  	0.10930574  
2023-05-15 21:35:28.292: [iter 112 : loss : 0.1229 = 0.0329 + 0.0843 + 0.0057, time: 7.248314]
2023-05-15 21:35:28.432: epoch 112:	0.02687057  	0.19835559  	0.10943747  
2023-05-15 21:35:28.432: Find a better model.
2023-05-15 21:35:35.697: [iter 113 : loss : 0.1227 = 0.0327 + 0.0842 + 0.0058, time: 7.263960]
2023-05-15 21:35:35.849: epoch 113:	0.02685645  	0.19813262  	0.10952556  
2023-05-15 21:35:43.086: [iter 114 : loss : 0.1219 = 0.0319 + 0.0841 + 0.0058, time: 7.235711]
2023-05-15 21:35:43.237: epoch 114:	0.02700464  	0.19904715  	0.10979560  
2023-05-15 21:35:43.237: Find a better model.
2023-05-15 21:35:50.477: [iter 115 : loss : 0.1215 = 0.0316 + 0.0841 + 0.0058, time: 7.237570]
2023-05-15 21:35:50.628: epoch 115:	0.02693407  	0.19870286  	0.10973988  
2023-05-15 21:35:57.881: [iter 116 : loss : 0.1205 = 0.0306 + 0.0840 + 0.0059, time: 7.251519]
2023-05-15 21:35:58.032: epoch 116:	0.02692701  	0.19864826  	0.10978238  
2023-05-15 21:36:05.269: [iter 117 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.236021]
2023-05-15 21:36:05.424: epoch 117:	0.02691290  	0.19846362  	0.10979835  
2023-05-15 21:36:12.673: [iter 118 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0059, time: 7.248261]
2023-05-15 21:36:12.827: epoch 118:	0.02696229  	0.19888890  	0.11002014  
2023-05-15 21:36:20.060: [iter 119 : loss : 0.1196 = 0.0298 + 0.0839 + 0.0060, time: 7.229547]
2023-05-15 21:36:20.211: epoch 119:	0.02691290  	0.19845167  	0.10996319  
2023-05-15 21:36:27.464: [iter 120 : loss : 0.1196 = 0.0297 + 0.0838 + 0.0060, time: 7.251105]
2023-05-15 21:36:27.616: epoch 120:	0.02691995  	0.19851826  	0.10995999  
2023-05-15 21:36:34.863: [iter 121 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0060, time: 7.245145]
2023-05-15 21:36:35.013: epoch 121:	0.02694818  	0.19891082  	0.11014625  
2023-05-15 21:36:42.239: [iter 122 : loss : 0.1189 = 0.0292 + 0.0837 + 0.0061, time: 7.222822]
2023-05-15 21:36:42.391: epoch 122:	0.02696229  	0.19918413  	0.11030310  
2023-05-15 21:36:42.391: Find a better model.
2023-05-15 21:36:49.658: [iter 123 : loss : 0.1189 = 0.0291 + 0.0837 + 0.0061, time: 7.266068]
2023-05-15 21:36:49.814: epoch 123:	0.02694112  	0.19882242  	0.11021448  
2023-05-15 21:36:56.854: [iter 124 : loss : 0.1181 = 0.0284 + 0.0836 + 0.0061, time: 7.039766]
2023-05-15 21:36:57.006: epoch 124:	0.02697641  	0.19887139  	0.11026698  
2023-05-15 21:37:04.065: [iter 125 : loss : 0.1173 = 0.0276 + 0.0836 + 0.0062, time: 7.056603]
2023-05-15 21:37:04.217: epoch 125:	0.02692701  	0.19867638  	0.11015816  
2023-05-15 21:37:11.438: [iter 126 : loss : 0.1174 = 0.0277 + 0.0835 + 0.0062, time: 7.220273]
2023-05-15 21:37:11.590: epoch 126:	0.02688468  	0.19841352  	0.11000399  
2023-05-15 21:37:18.841: [iter 127 : loss : 0.1166 = 0.0269 + 0.0835 + 0.0062, time: 7.250077]
2023-05-15 21:37:18.996: epoch 127:	0.02690584  	0.19870357  	0.11005124  
2023-05-15 21:37:26.235: [iter 128 : loss : 0.1176 = 0.0279 + 0.0834 + 0.0062, time: 7.237548]
2023-05-15 21:37:26.387: epoch 128:	0.02689173  	0.19876328  	0.11006222  
2023-05-15 21:37:33.639: [iter 129 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 7.250361]
2023-05-15 21:37:33.792: epoch 129:	0.02691290  	0.19886278  	0.11015603  
2023-05-15 21:37:41.049: [iter 130 : loss : 0.1165 = 0.0268 + 0.0834 + 0.0063, time: 7.256026]
2023-05-15 21:37:41.201: epoch 130:	0.02699757  	0.19963467  	0.11035436  
2023-05-15 21:37:41.201: Find a better model.
2023-05-15 21:37:48.251: [iter 131 : loss : 0.1158 = 0.0262 + 0.0833 + 0.0063, time: 7.048777]
2023-05-15 21:37:48.405: epoch 131:	0.02701169  	0.19957933  	0.11042501  
2023-05-15 21:37:55.634: [iter 132 : loss : 0.1160 = 0.0264 + 0.0833 + 0.0064, time: 7.228542]
2023-05-15 21:37:55.788: epoch 132:	0.02698346  	0.19936098  	0.11043129  
2023-05-15 21:38:03.035: [iter 133 : loss : 0.1147 = 0.0251 + 0.0832 + 0.0064, time: 7.246662]
2023-05-15 21:38:03.187: epoch 133:	0.02687762  	0.19832541  	0.11036643  
2023-05-15 21:38:10.413: [iter 134 : loss : 0.1155 = 0.0258 + 0.0832 + 0.0064, time: 7.223458]
2023-05-15 21:38:10.566: epoch 134:	0.02687762  	0.19836748  	0.11047474  
2023-05-15 21:38:17.826: [iter 135 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0065, time: 7.257988]
2023-05-15 21:38:17.979: epoch 135:	0.02689173  	0.19829141  	0.11022040  
2023-05-15 21:38:25.220: [iter 136 : loss : 0.1149 = 0.0253 + 0.0831 + 0.0065, time: 7.238758]
2023-05-15 21:38:25.372: epoch 136:	0.02693407  	0.19875212  	0.11036977  
2023-05-15 21:38:32.610: [iter 137 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 7.236430]
2023-05-15 21:38:32.762: epoch 137:	0.02689173  	0.19856809  	0.11022639  
2023-05-15 21:38:40.001: [iter 138 : loss : 0.1142 = 0.0246 + 0.0830 + 0.0065, time: 7.238941]
2023-05-15 21:38:40.153: epoch 138:	0.02693407  	0.19861098  	0.11032997  
2023-05-15 21:38:47.224: [iter 139 : loss : 0.1140 = 0.0245 + 0.0830 + 0.0066, time: 7.069820]
2023-05-15 21:38:47.376: epoch 139:	0.02694818  	0.19914304  	0.11042178  
2023-05-15 21:38:54.423: [iter 140 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0066, time: 7.044929]
2023-05-15 21:38:54.574: epoch 140:	0.02696230  	0.19934446  	0.11046848  
2023-05-15 21:39:01.790: [iter 141 : loss : 0.1139 = 0.0244 + 0.0829 + 0.0066, time: 7.213419]
2023-05-15 21:39:01.946: epoch 141:	0.02703286  	0.19998960  	0.11061479  
2023-05-15 21:39:01.946: Find a better model.
2023-05-15 21:39:09.204: [iter 142 : loss : 0.1129 = 0.0234 + 0.0829 + 0.0066, time: 7.257225]
2023-05-15 21:39:09.359: epoch 142:	0.02701169  	0.19941278  	0.11058579  
2023-05-15 21:39:16.589: [iter 143 : loss : 0.1132 = 0.0237 + 0.0828 + 0.0067, time: 7.228362]
2023-05-15 21:39:16.744: epoch 143:	0.02696935  	0.19906780  	0.11036411  
2023-05-15 21:39:24.183: [iter 144 : loss : 0.1125 = 0.0231 + 0.0828 + 0.0067, time: 7.437404]
2023-05-15 21:39:24.339: epoch 144:	0.02694112  	0.19901684  	0.11043151  
2023-05-15 21:39:31.595: [iter 145 : loss : 0.1126 = 0.0231 + 0.0828 + 0.0067, time: 7.255170]
2023-05-15 21:39:31.751: epoch 145:	0.02693407  	0.19888937  	0.11049134  
2023-05-15 21:39:38.988: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0068, time: 7.236000]
2023-05-15 21:39:39.140: epoch 146:	0.02695523  	0.19891950  	0.11067405  
2023-05-15 21:39:46.376: [iter 147 : loss : 0.1124 = 0.0229 + 0.0827 + 0.0068, time: 7.234894]
2023-05-15 21:39:46.530: epoch 147:	0.02699758  	0.19897214  	0.11068755  
2023-05-15 21:39:53.604: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.073627]
2023-05-15 21:39:53.756: epoch 148:	0.02695523  	0.19843899  	0.11063318  
2023-05-15 21:40:01.013: [iter 149 : loss : 0.1117 = 0.0223 + 0.0826 + 0.0068, time: 7.256410]
2023-05-15 21:40:01.163: epoch 149:	0.02696230  	0.19825163  	0.11043943  
2023-05-15 21:40:08.202: [iter 150 : loss : 0.1110 = 0.0215 + 0.0826 + 0.0069, time: 7.037503]
2023-05-15 21:40:08.362: epoch 150:	0.02701169  	0.19868688  	0.11055527  
2023-05-15 21:40:15.577: [iter 151 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0069, time: 7.213527]
2023-05-15 21:40:15.731: epoch 151:	0.02699052  	0.19856691  	0.11041286  
2023-05-15 21:40:22.977: [iter 152 : loss : 0.1108 = 0.0213 + 0.0825 + 0.0069, time: 7.244080]
2023-05-15 21:40:23.132: epoch 152:	0.02692702  	0.19830459  	0.11021136  
2023-05-15 21:40:30.384: [iter 153 : loss : 0.1098 = 0.0203 + 0.0825 + 0.0069, time: 7.250502]
2023-05-15 21:40:30.539: epoch 153:	0.02697641  	0.19839229  	0.11033110  
2023-05-15 21:40:37.773: [iter 154 : loss : 0.1102 = 0.0208 + 0.0825 + 0.0070, time: 7.231559]
2023-05-15 21:40:37.925: epoch 154:	0.02696935  	0.19831368  	0.11021732  
2023-05-15 21:40:45.158: [iter 155 : loss : 0.1112 = 0.0218 + 0.0824 + 0.0070, time: 7.231185]
2023-05-15 21:40:45.309: epoch 155:	0.02690584  	0.19810978  	0.11006004  
2023-05-15 21:40:52.579: [iter 156 : loss : 0.1103 = 0.0208 + 0.0824 + 0.0070, time: 7.268270]
2023-05-15 21:40:52.733: epoch 156:	0.02689879  	0.19759604  	0.10993318  
2023-05-15 21:40:59.785: [iter 157 : loss : 0.1101 = 0.0207 + 0.0824 + 0.0070, time: 7.051262]
2023-05-15 21:40:59.939: epoch 157:	0.02687762  	0.19775802  	0.10995335  
2023-05-15 21:41:07.173: [iter 158 : loss : 0.1093 = 0.0199 + 0.0824 + 0.0071, time: 7.231752]
2023-05-15 21:41:07.327: epoch 158:	0.02684940  	0.19744198  	0.10993860  
2023-05-15 21:41:14.572: [iter 159 : loss : 0.1099 = 0.0204 + 0.0823 + 0.0071, time: 7.244497]
2023-05-15 21:41:14.724: epoch 159:	0.02687762  	0.19761014  	0.10995579  
2023-05-15 21:41:21.956: [iter 160 : loss : 0.1095 = 0.0200 + 0.0823 + 0.0071, time: 7.231818]
2023-05-15 21:41:22.112: epoch 160:	0.02689879  	0.19763710  	0.11016177  
2023-05-15 21:41:29.364: [iter 161 : loss : 0.1088 = 0.0194 + 0.0823 + 0.0071, time: 7.251209]
2023-05-15 21:41:29.520: epoch 161:	0.02691291  	0.19768886  	0.11005975  
2023-05-15 21:41:36.739: [iter 162 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0072, time: 7.216973]
2023-05-15 21:41:36.895: epoch 162:	0.02684940  	0.19726014  	0.10999764  
2023-05-15 21:41:43.966: [iter 163 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 7.069391]
2023-05-15 21:41:44.117: epoch 163:	0.02684234  	0.19712152  	0.11024509  
2023-05-15 21:41:51.350: [iter 164 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.229448]
2023-05-15 21:41:51.502: epoch 164:	0.02690585  	0.19743206  	0.11033799  
2023-05-15 21:41:58.563: [iter 165 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0072, time: 7.059310]
2023-05-15 21:41:58.719: epoch 165:	0.02687762  	0.19693683  	0.11016173  
2023-05-15 21:42:05.762: [iter 166 : loss : 0.1080 = 0.0186 + 0.0822 + 0.0073, time: 7.041718]
2023-05-15 21:42:05.914: epoch 166:	0.02684939  	0.19658589  	0.10998435  
2023-05-15 21:42:05.914: Early stopping is trigger at epoch: 166
2023-05-15 21:42:05.914: best_result@epoch 141:

2023-05-15 21:42:05.914: 		0.0270      	0.2000      	0.1106      
2023-05-16 09:14:09.388: my pid: 3620
2023-05-16 09:14:09.388: model: model.general_recommender.SGL
2023-05-16 09:14:09.388: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 09:14:09.388: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 09:14:12.457: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 09:14:20.599: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.140246]
2023-05-16 09:14:20.754: epoch 1:	0.00156647  	0.01171466  	0.00580815  
2023-05-16 09:14:20.755: Find a better model.
2023-05-16 09:14:29.168: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.411215]
2023-05-16 09:14:29.371: epoch 2:	0.00292831  	0.02231355  	0.01077572  
2023-05-16 09:14:29.371: Find a better model.
2023-05-16 09:14:37.569: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.197109]
2023-05-16 09:14:37.740: epoch 3:	0.00508747  	0.03917150  	0.01863642  
2023-05-16 09:14:37.740: Find a better model.
2023-05-16 09:14:45.802: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.061360]
2023-05-16 09:14:45.964: epoch 4:	0.00821331  	0.06066947  	0.02949318  
2023-05-16 09:14:45.964: Find a better model.
2023-05-16 09:14:53.984: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 8.018955]
2023-05-16 09:14:54.145: epoch 5:	0.01175560  	0.08591533  	0.04142882  
2023-05-16 09:14:54.145: Find a better model.
2023-05-16 09:15:01.954: [iter 6 : loss : 0.7673 = 0.6880 + 0.0792 + 0.0000, time: 7.807735]
2023-05-16 09:15:02.111: epoch 6:	0.01555902  	0.11311486  	0.05467707  
2023-05-16 09:15:02.112: Find a better model.
2023-05-16 09:15:09.785: [iter 7 : loss : 0.7608 = 0.6808 + 0.0800 + 0.0000, time: 7.672433]
2023-05-16 09:15:09.939: epoch 7:	0.01805699  	0.13106143  	0.06440651  
2023-05-16 09:15:09.940: Find a better model.
2023-05-16 09:15:17.578: [iter 8 : loss : 0.7450 = 0.6630 + 0.0819 + 0.0001, time: 7.636669]
2023-05-16 09:15:17.738: epoch 8:	0.01906607  	0.13941690  	0.06928590  
2023-05-16 09:15:17.738: Find a better model.
2023-05-16 09:15:25.356: [iter 9 : loss : 0.7094 = 0.6236 + 0.0857 + 0.0001, time: 7.617311]
2023-05-16 09:15:25.510: epoch 9:	0.01894611  	0.13903846  	0.06977401  
2023-05-16 09:15:32.933: [iter 10 : loss : 0.6483 = 0.5570 + 0.0911 + 0.0002, time: 7.422135]
2023-05-16 09:15:33.085: epoch 10:	0.01879087  	0.13845405  	0.06886089  
2023-05-16 09:15:40.498: [iter 11 : loss : 0.5727 = 0.4763 + 0.0960 + 0.0004, time: 7.412098]
2023-05-16 09:15:40.657: epoch 11:	0.01855801  	0.13663562  	0.06826307  
2023-05-16 09:15:48.164: [iter 12 : loss : 0.5041 = 0.4042 + 0.0993 + 0.0006, time: 7.506222]
2023-05-16 09:15:48.318: epoch 12:	0.01860740  	0.13723880  	0.06864265  
2023-05-16 09:15:55.701: [iter 13 : loss : 0.4533 = 0.3514 + 0.1012 + 0.0007, time: 7.381634]
2023-05-16 09:15:55.857: epoch 13:	0.01874148  	0.13851438  	0.06911159  
2023-05-16 09:16:03.306: [iter 14 : loss : 0.4149 = 0.3120 + 0.1021 + 0.0008, time: 7.448681]
2023-05-16 09:16:03.462: epoch 14:	0.01883321  	0.13931243  	0.06980730  
2023-05-16 09:16:10.923: [iter 15 : loss : 0.3880 = 0.2846 + 0.1024 + 0.0010, time: 7.458607]
2023-05-16 09:16:11.078: epoch 15:	0.01905902  	0.14098047  	0.07071027  
2023-05-16 09:16:11.078: Find a better model.
2023-05-16 09:16:18.311: [iter 16 : loss : 0.3657 = 0.2621 + 0.1025 + 0.0011, time: 7.231928]
2023-05-16 09:16:18.466: epoch 16:	0.01927071  	0.14234026  	0.07161730  
2023-05-16 09:16:18.466: Find a better model.
2023-05-16 09:16:25.886: [iter 17 : loss : 0.3492 = 0.2457 + 0.1023 + 0.0012, time: 7.418731]
2023-05-16 09:16:26.040: epoch 17:	0.01942596  	0.14366136  	0.07247962  
2023-05-16 09:16:26.040: Find a better model.
2023-05-16 09:16:33.304: [iter 18 : loss : 0.3337 = 0.2304 + 0.1020 + 0.0013, time: 7.261499]
2023-05-16 09:16:33.461: epoch 18:	0.01965177  	0.14523041  	0.07356856  
2023-05-16 09:16:33.461: Find a better model.
2023-05-16 09:16:40.912: [iter 19 : loss : 0.3197 = 0.2165 + 0.1017 + 0.0014, time: 7.448934]
2023-05-16 09:16:41.069: epoch 19:	0.01991287  	0.14689185  	0.07446113  
2023-05-16 09:16:41.069: Find a better model.
2023-05-16 09:16:48.504: [iter 20 : loss : 0.3101 = 0.2073 + 0.1013 + 0.0015, time: 7.433004]
2023-05-16 09:16:48.658: epoch 20:	0.01999754  	0.14771725  	0.07502823  
2023-05-16 09:16:48.658: Find a better model.
2023-05-16 09:16:56.096: [iter 21 : loss : 0.3004 = 0.1979 + 0.1010 + 0.0016, time: 7.436779]
2023-05-16 09:16:56.253: epoch 21:	0.02021629  	0.14909098  	0.07581273  
2023-05-16 09:16:56.253: Find a better model.
2023-05-16 09:17:03.719: [iter 22 : loss : 0.2921 = 0.1900 + 0.1005 + 0.0017, time: 7.465120]
2023-05-16 09:17:03.877: epoch 22:	0.02035742  	0.15008770  	0.07641884  
2023-05-16 09:17:03.878: Find a better model.
2023-05-16 09:17:11.289: [iter 23 : loss : 0.2839 = 0.1821 + 0.1001 + 0.0017, time: 7.409712]
2023-05-16 09:17:11.445: epoch 23:	0.02059734  	0.15186732  	0.07732043  
2023-05-16 09:17:11.445: Find a better model.
2023-05-16 09:17:18.879: [iter 24 : loss : 0.2774 = 0.1759 + 0.0996 + 0.0018, time: 7.432555]
2023-05-16 09:17:19.035: epoch 24:	0.02080904  	0.15332657  	0.07830719  
2023-05-16 09:17:19.035: Find a better model.
2023-05-16 09:17:26.505: [iter 25 : loss : 0.2707 = 0.1696 + 0.0993 + 0.0019, time: 7.467577]
2023-05-16 09:17:26.649: epoch 25:	0.02090783  	0.15401866  	0.07878247  
2023-05-16 09:17:26.649: Find a better model.
2023-05-16 09:17:34.069: [iter 26 : loss : 0.2671 = 0.1663 + 0.0988 + 0.0019, time: 7.418762]
2023-05-16 09:17:34.226: epoch 26:	0.02107719  	0.15505925  	0.07936683  
2023-05-16 09:17:34.226: Find a better model.
2023-05-16 09:17:41.645: [iter 27 : loss : 0.2594 = 0.1590 + 0.0984 + 0.0020, time: 7.418679]
2023-05-16 09:17:41.804: epoch 27:	0.02128888  	0.15676486  	0.08016108  
2023-05-16 09:17:41.804: Find a better model.
2023-05-16 09:17:49.086: [iter 28 : loss : 0.2544 = 0.1544 + 0.0980 + 0.0021, time: 7.280750]
2023-05-16 09:17:49.243: epoch 28:	0.02147941  	0.15795879  	0.08119600  
2023-05-16 09:17:49.243: Find a better model.
2023-05-16 09:17:56.676: [iter 29 : loss : 0.2499 = 0.1502 + 0.0976 + 0.0021, time: 7.430529]
2023-05-16 09:17:56.819: epoch 29:	0.02161348  	0.15908027  	0.08178098  
2023-05-16 09:17:56.819: Find a better model.
2023-05-16 09:18:04.254: [iter 30 : loss : 0.2435 = 0.1440 + 0.0972 + 0.0022, time: 7.433374]
2023-05-16 09:18:04.410: epoch 30:	0.02168405  	0.15952547  	0.08213963  
2023-05-16 09:18:04.410: Find a better model.
2023-05-16 09:18:11.858: [iter 31 : loss : 0.2400 = 0.1409 + 0.0968 + 0.0023, time: 7.446020]
2023-05-16 09:18:12.016: epoch 31:	0.02177578  	0.16047744  	0.08253079  
2023-05-16 09:18:12.016: Find a better model.
2023-05-16 09:18:19.458: [iter 32 : loss : 0.2343 = 0.1356 + 0.0965 + 0.0023, time: 7.441657]
2023-05-16 09:18:19.613: epoch 32:	0.02196631  	0.16220053  	0.08362125  
2023-05-16 09:18:19.613: Find a better model.
2023-05-16 09:18:27.081: [iter 33 : loss : 0.2316 = 0.1331 + 0.0961 + 0.0024, time: 7.464650]
2023-05-16 09:18:27.238: epoch 33:	0.02214977  	0.16292085  	0.08427003  
2023-05-16 09:18:27.238: Find a better model.
2023-05-16 09:18:34.674: [iter 34 : loss : 0.2277 = 0.1294 + 0.0958 + 0.0024, time: 7.434189]
2023-05-16 09:18:34.830: epoch 34:	0.02237558  	0.16468279  	0.08518359  
2023-05-16 09:18:34.830: Find a better model.
2023-05-16 09:18:42.257: [iter 35 : loss : 0.2243 = 0.1263 + 0.0954 + 0.0025, time: 7.425090]
2023-05-16 09:18:42.411: epoch 35:	0.02246731  	0.16508709  	0.08562696  
2023-05-16 09:18:42.411: Find a better model.
2023-05-16 09:18:49.865: [iter 36 : loss : 0.2210 = 0.1233 + 0.0952 + 0.0026, time: 7.453408]
2023-05-16 09:18:50.022: epoch 36:	0.02255904  	0.16598366  	0.08618562  
2023-05-16 09:18:50.022: Find a better model.
2023-05-16 09:18:57.448: [iter 37 : loss : 0.2171 = 0.1197 + 0.0948 + 0.0026, time: 7.424751]
2023-05-16 09:18:57.603: epoch 37:	0.02268606  	0.16691162  	0.08682247  
2023-05-16 09:18:57.603: Find a better model.
2023-05-16 09:19:05.053: [iter 38 : loss : 0.2154 = 0.1182 + 0.0945 + 0.0027, time: 7.449259]
2023-05-16 09:19:05.210: epoch 38:	0.02287659  	0.16830502  	0.08777197  
2023-05-16 09:19:05.210: Find a better model.
2023-05-16 09:19:12.855: [iter 39 : loss : 0.2110 = 0.1141 + 0.0942 + 0.0027, time: 7.644148]
2023-05-16 09:19:13.013: epoch 39:	0.02294010  	0.16863768  	0.08837519  
2023-05-16 09:19:13.013: Find a better model.
2023-05-16 09:19:20.479: [iter 40 : loss : 0.2077 = 0.1110 + 0.0939 + 0.0028, time: 7.463254]
2023-05-16 09:19:20.635: epoch 40:	0.02305300  	0.16954422  	0.08889247  
2023-05-16 09:19:20.635: Find a better model.
2023-05-16 09:19:28.042: [iter 41 : loss : 0.2061 = 0.1096 + 0.0936 + 0.0028, time: 7.406175]
2023-05-16 09:19:28.198: epoch 41:	0.02316590  	0.17000861  	0.08945541  
2023-05-16 09:19:28.198: Find a better model.
2023-05-16 09:19:35.635: [iter 42 : loss : 0.2038 = 0.1076 + 0.0933 + 0.0029, time: 7.436785]
2023-05-16 09:19:35.790: epoch 42:	0.02326470  	0.17097919  	0.09009897  
2023-05-16 09:19:35.790: Find a better model.
2023-05-16 09:19:43.239: [iter 43 : loss : 0.2000 = 0.1040 + 0.0931 + 0.0029, time: 7.447863]
2023-05-16 09:19:43.393: epoch 43:	0.02338465  	0.17151380  	0.09066357  
2023-05-16 09:19:43.393: Find a better model.
2023-05-16 09:19:50.818: [iter 44 : loss : 0.1964 = 0.1007 + 0.0928 + 0.0030, time: 7.423208]
2023-05-16 09:19:50.974: epoch 44:	0.02348344  	0.17256720  	0.09115721  
2023-05-16 09:19:50.974: Find a better model.
2023-05-16 09:19:58.408: [iter 45 : loss : 0.1944 = 0.0988 + 0.0925 + 0.0030, time: 7.431710]
2023-05-16 09:19:58.550: epoch 45:	0.02360340  	0.17388335  	0.09163406  
2023-05-16 09:19:58.550: Find a better model.
2023-05-16 09:20:06.038: [iter 46 : loss : 0.1920 = 0.0967 + 0.0923 + 0.0031, time: 7.486839]
2023-05-16 09:20:06.195: epoch 46:	0.02368808  	0.17409419  	0.09191913  
2023-05-16 09:20:06.195: Find a better model.
2023-05-16 09:20:13.626: [iter 47 : loss : 0.1913 = 0.0961 + 0.0921 + 0.0031, time: 7.430568]
2023-05-16 09:20:13.782: epoch 47:	0.02377276  	0.17475525  	0.09249554  
2023-05-16 09:20:13.782: Find a better model.
2023-05-16 09:20:21.221: [iter 48 : loss : 0.1873 = 0.0923 + 0.0918 + 0.0032, time: 7.438144]
2023-05-16 09:20:21.377: epoch 48:	0.02391390  	0.17592160  	0.09321426  
2023-05-16 09:20:21.377: Find a better model.
2023-05-16 09:20:28.827: [iter 49 : loss : 0.1843 = 0.0895 + 0.0916 + 0.0032, time: 7.448756]
2023-05-16 09:20:28.983: epoch 49:	0.02393507  	0.17621391  	0.09368170  
2023-05-16 09:20:28.983: Find a better model.
2023-05-16 09:20:36.414: [iter 50 : loss : 0.1835 = 0.0888 + 0.0914 + 0.0033, time: 7.428284]
2023-05-16 09:20:36.557: epoch 50:	0.02407618  	0.17715897  	0.09419621  
2023-05-16 09:20:36.558: Find a better model.
2023-05-16 09:20:43.990: [iter 51 : loss : 0.1803 = 0.0858 + 0.0912 + 0.0033, time: 7.431284]
2023-05-16 09:20:44.147: epoch 51:	0.02413969  	0.17773224  	0.09446312  
2023-05-16 09:20:44.147: Find a better model.
2023-05-16 09:20:51.641: [iter 52 : loss : 0.1803 = 0.0860 + 0.0910 + 0.0034, time: 7.493568]
2023-05-16 09:20:51.795: epoch 52:	0.02417498  	0.17806581  	0.09489129  
2023-05-16 09:20:51.795: Find a better model.
2023-05-16 09:20:59.377: [iter 53 : loss : 0.1785 = 0.0843 + 0.0908 + 0.0034, time: 7.580182]
2023-05-16 09:20:59.520: epoch 53:	0.02420321  	0.17802545  	0.09528591  
2023-05-16 09:21:06.974: [iter 54 : loss : 0.1764 = 0.0823 + 0.0906 + 0.0035, time: 7.451958]
2023-05-16 09:21:07.116: epoch 54:	0.02430906  	0.17901386  	0.09571230  
2023-05-16 09:21:07.116: Find a better model.
2023-05-16 09:21:14.591: [iter 55 : loss : 0.1744 = 0.0805 + 0.0904 + 0.0035, time: 7.474678]
2023-05-16 09:21:14.734: epoch 55:	0.02440079  	0.17977081  	0.09627394  
2023-05-16 09:21:14.734: Find a better model.
2023-05-16 09:21:22.241: [iter 56 : loss : 0.1726 = 0.0788 + 0.0902 + 0.0036, time: 7.506156]
2023-05-16 09:21:22.397: epoch 56:	0.02439373  	0.17938125  	0.09640979  
2023-05-16 09:21:29.802: [iter 57 : loss : 0.1707 = 0.0771 + 0.0900 + 0.0036, time: 7.403785]
2023-05-16 09:21:29.957: epoch 57:	0.02449252  	0.18019441  	0.09697328  
2023-05-16 09:21:29.957: Find a better model.
2023-05-16 09:21:37.394: [iter 58 : loss : 0.1690 = 0.0755 + 0.0898 + 0.0036, time: 7.434360]
2023-05-16 09:21:37.549: epoch 58:	0.02446429  	0.17979531  	0.09711432  
2023-05-16 09:21:44.967: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 7.416226]
2023-05-16 09:21:45.123: epoch 59:	0.02455603  	0.18029302  	0.09752362  
2023-05-16 09:21:45.123: Find a better model.
2023-05-16 09:21:52.585: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 7.460936]
2023-05-16 09:21:52.739: epoch 60:	0.02471832  	0.18142875  	0.09806507  
2023-05-16 09:21:52.739: Find a better model.
2023-05-16 09:22:00.173: [iter 61 : loss : 0.1646 = 0.0716 + 0.0893 + 0.0038, time: 7.433025]
2023-05-16 09:22:00.325: epoch 61:	0.02474655  	0.18172421  	0.09810562  
2023-05-16 09:22:00.325: Find a better model.
2023-05-16 09:22:07.802: [iter 62 : loss : 0.1634 = 0.0704 + 0.0892 + 0.0038, time: 7.476536]
2023-05-16 09:22:07.958: epoch 62:	0.02485945  	0.18243219  	0.09893531  
2023-05-16 09:22:07.958: Find a better model.
2023-05-16 09:22:15.379: [iter 63 : loss : 0.1619 = 0.0690 + 0.0890 + 0.0039, time: 7.419996]
2023-05-16 09:22:15.533: epoch 63:	0.02495825  	0.18310665  	0.09916264  
2023-05-16 09:22:15.533: Find a better model.
2023-05-16 09:22:22.964: [iter 64 : loss : 0.1614 = 0.0686 + 0.0888 + 0.0039, time: 7.429240]
2023-05-16 09:22:23.121: epoch 64:	0.02512055  	0.18457274  	0.09988391  
2023-05-16 09:22:23.121: Find a better model.
2023-05-16 09:22:30.582: [iter 65 : loss : 0.1597 = 0.0671 + 0.0887 + 0.0040, time: 7.459862]
2023-05-16 09:22:30.737: epoch 65:	0.02514877  	0.18485706  	0.10015389  
2023-05-16 09:22:30.737: Find a better model.
2023-05-16 09:22:38.155: [iter 66 : loss : 0.1582 = 0.0657 + 0.0885 + 0.0040, time: 7.414765]
2023-05-16 09:22:38.308: epoch 66:	0.02526873  	0.18561950  	0.10055818  
2023-05-16 09:22:38.308: Find a better model.
2023-05-16 09:22:45.758: [iter 67 : loss : 0.1567 = 0.0643 + 0.0884 + 0.0040, time: 7.447012]
2023-05-16 09:22:45.901: epoch 67:	0.02534635  	0.18600315  	0.10093564  
2023-05-16 09:22:45.902: Find a better model.
2023-05-16 09:22:53.171: [iter 68 : loss : 0.1563 = 0.0640 + 0.0882 + 0.0041, time: 7.267671]
2023-05-16 09:22:53.323: epoch 68:	0.02547336  	0.18693806  	0.10130199  
2023-05-16 09:22:53.323: Find a better model.
2023-05-16 09:23:00.758: [iter 69 : loss : 0.1545 = 0.0622 + 0.0881 + 0.0041, time: 7.432674]
2023-05-16 09:23:00.900: epoch 69:	0.02544514  	0.18655315  	0.10143041  
2023-05-16 09:23:08.667: [iter 70 : loss : 0.1528 = 0.0606 + 0.0880 + 0.0042, time: 7.766212]
2023-05-16 09:23:08.829: epoch 70:	0.02547336  	0.18695818  	0.10170513  
2023-05-16 09:23:08.829: Find a better model.
2023-05-16 09:23:16.449: [iter 71 : loss : 0.1513 = 0.0592 + 0.0879 + 0.0042, time: 7.619576]
2023-05-16 09:23:16.604: epoch 71:	0.02548748  	0.18716837  	0.10195775  
2023-05-16 09:23:16.604: Find a better model.
2023-05-16 09:23:24.165: [iter 72 : loss : 0.1512 = 0.0592 + 0.0878 + 0.0042, time: 7.559130]
2023-05-16 09:23:24.309: epoch 72:	0.02559332  	0.18801701  	0.10236312  
2023-05-16 09:23:24.309: Find a better model.
2023-05-16 09:23:32.048: [iter 73 : loss : 0.1498 = 0.0579 + 0.0876 + 0.0043, time: 7.736990]
2023-05-16 09:23:32.228: epoch 73:	0.02560038  	0.18828681  	0.10243169  
2023-05-16 09:23:32.228: Find a better model.
2023-05-16 09:23:39.813: [iter 74 : loss : 0.1484 = 0.0565 + 0.0875 + 0.0043, time: 7.584558]
2023-05-16 09:23:39.974: epoch 74:	0.02562155  	0.18845934  	0.10258232  
2023-05-16 09:23:39.974: Find a better model.
2023-05-16 09:23:47.966: [iter 75 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0044, time: 7.989768]
2023-05-16 09:23:48.210: epoch 75:	0.02572034  	0.18897945  	0.10286748  
2023-05-16 09:23:48.210: Find a better model.
2023-05-16 09:23:56.683: [iter 76 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 8.470127]
2023-05-16 09:23:56.835: epoch 76:	0.02576268  	0.18895753  	0.10311943  
2023-05-16 09:24:04.626: [iter 77 : loss : 0.1460 = 0.0544 + 0.0872 + 0.0044, time: 7.789151]
2023-05-16 09:24:04.791: epoch 77:	0.02576974  	0.18926594  	0.10330349  
2023-05-16 09:24:04.791: Find a better model.
2023-05-16 09:24:12.367: [iter 78 : loss : 0.1451 = 0.0536 + 0.0871 + 0.0045, time: 7.573874]
2023-05-16 09:24:12.553: epoch 78:	0.02579091  	0.18972565  	0.10373917  
2023-05-16 09:24:12.553: Find a better model.
2023-05-16 09:24:20.127: [iter 79 : loss : 0.1436 = 0.0521 + 0.0869 + 0.0045, time: 7.571684]
2023-05-16 09:24:20.284: epoch 79:	0.02581913  	0.18963015  	0.10377549  
2023-05-16 09:24:27.733: [iter 80 : loss : 0.1430 = 0.0516 + 0.0869 + 0.0046, time: 7.447617]
2023-05-16 09:24:27.888: epoch 80:	0.02581208  	0.18940437  	0.10388680  
2023-05-16 09:24:35.341: [iter 81 : loss : 0.1427 = 0.0514 + 0.0867 + 0.0046, time: 7.451632]
2023-05-16 09:24:35.496: epoch 81:	0.02587559  	0.18997595  	0.10419679  
2023-05-16 09:24:35.497: Find a better model.
2023-05-16 09:24:42.925: [iter 82 : loss : 0.1413 = 0.0500 + 0.0866 + 0.0046, time: 7.427587]
2023-05-16 09:24:43.080: epoch 82:	0.02590381  	0.19022208  	0.10441851  
2023-05-16 09:24:43.080: Find a better model.
2023-05-16 09:24:50.336: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.254564]
2023-05-16 09:24:50.491: epoch 83:	0.02589676  	0.19033775  	0.10451437  
2023-05-16 09:24:50.491: Find a better model.
2023-05-16 09:24:57.739: [iter 84 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 7.247498]
2023-05-16 09:24:57.893: epoch 84:	0.02597438  	0.19074285  	0.10468348  
2023-05-16 09:24:57.894: Find a better model.
2023-05-16 09:25:05.340: [iter 85 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 7.443998]
2023-05-16 09:25:05.481: epoch 85:	0.02601672  	0.19107603  	0.10479328  
2023-05-16 09:25:05.481: Find a better model.
2023-05-16 09:25:12.927: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 7.444411]
2023-05-16 09:25:13.080: epoch 86:	0.02608728  	0.19166438  	0.10503832  
2023-05-16 09:25:13.080: Find a better model.
2023-05-16 09:25:20.503: [iter 87 : loss : 0.1365 = 0.0455 + 0.0861 + 0.0048, time: 7.421968]
2023-05-16 09:25:20.655: epoch 87:	0.02613668  	0.19215207  	0.10536303  
2023-05-16 09:25:20.655: Find a better model.
2023-05-16 09:25:28.130: [iter 88 : loss : 0.1358 = 0.0448 + 0.0861 + 0.0049, time: 7.474135]
2023-05-16 09:25:28.286: epoch 88:	0.02622841  	0.19275315  	0.10557026  
2023-05-16 09:25:28.286: Find a better model.
2023-05-16 09:25:35.709: [iter 89 : loss : 0.1353 = 0.0445 + 0.0860 + 0.0049, time: 7.420789]
2023-05-16 09:25:35.861: epoch 89:	0.02626369  	0.19269821  	0.10570841  
2023-05-16 09:25:43.313: [iter 90 : loss : 0.1363 = 0.0454 + 0.0859 + 0.0050, time: 7.450461]
2023-05-16 09:25:43.467: epoch 90:	0.02629192  	0.19270267  	0.10593433  
2023-05-16 09:25:50.715: [iter 91 : loss : 0.1350 = 0.0442 + 0.0858 + 0.0050, time: 7.247367]
2023-05-16 09:25:50.871: epoch 91:	0.02629191  	0.19254442  	0.10592765  
2023-05-16 09:25:58.305: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 7.433093]
2023-05-16 09:25:58.460: epoch 92:	0.02635542  	0.19318567  	0.10597685  
2023-05-16 09:25:58.460: Find a better model.
2023-05-16 09:26:05.711: [iter 93 : loss : 0.1343 = 0.0436 + 0.0856 + 0.0051, time: 7.248777]
2023-05-16 09:26:05.866: epoch 93:	0.02636953  	0.19340311  	0.10614359  
2023-05-16 09:26:05.866: Find a better model.
2023-05-16 09:26:13.285: [iter 94 : loss : 0.1323 = 0.0417 + 0.0855 + 0.0051, time: 7.418168]
2023-05-16 09:26:13.443: epoch 94:	0.02633425  	0.19314587  	0.10614621  
2023-05-16 09:26:20.705: [iter 95 : loss : 0.1316 = 0.0410 + 0.0855 + 0.0051, time: 7.260608]
2023-05-16 09:26:20.858: epoch 95:	0.02639071  	0.19389570  	0.10620549  
2023-05-16 09:26:20.858: Find a better model.
2023-05-16 09:26:28.276: [iter 96 : loss : 0.1315 = 0.0410 + 0.0854 + 0.0052, time: 7.416451]
2023-05-16 09:26:28.431: epoch 96:	0.02634836  	0.19308451  	0.10615332  
2023-05-16 09:26:35.695: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 7.262437]
2023-05-16 09:26:35.850: epoch 97:	0.02638365  	0.19360314  	0.10638224  
2023-05-16 09:26:43.267: [iter 98 : loss : 0.1307 = 0.0403 + 0.0852 + 0.0052, time: 7.416496]
2023-05-16 09:26:43.413: epoch 98:	0.02645421  	0.19420047  	0.10652313  
2023-05-16 09:26:43.413: Find a better model.
2023-05-16 09:26:50.890: [iter 99 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0053, time: 7.474660]
2023-05-16 09:26:51.044: epoch 99:	0.02646127  	0.19419320  	0.10657948  
2023-05-16 09:26:58.481: [iter 100 : loss : 0.1288 = 0.0384 + 0.0851 + 0.0053, time: 7.436373]
2023-05-16 09:26:58.637: epoch 100:	0.02655300  	0.19483307  	0.10683968  
2023-05-16 09:26:58.637: Find a better model.
2023-05-16 09:27:06.073: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0054, time: 7.435856]
2023-05-16 09:27:06.228: epoch 101:	0.02653889  	0.19474463  	0.10706483  
2023-05-16 09:27:13.711: [iter 102 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 7.480090]
2023-05-16 09:27:13.869: epoch 102:	0.02653183  	0.19489725  	0.10693090  
2023-05-16 09:27:13.869: Find a better model.
2023-05-16 09:27:21.509: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 7.639117]
2023-05-16 09:27:21.665: epoch 103:	0.02654594  	0.19509907  	0.10726868  
2023-05-16 09:27:21.665: Find a better model.
2023-05-16 09:27:29.077: [iter 104 : loss : 0.1277 = 0.0375 + 0.0848 + 0.0055, time: 7.409844]
2023-05-16 09:27:29.224: epoch 104:	0.02658123  	0.19555600  	0.10755403  
2023-05-16 09:27:29.224: Find a better model.
2023-05-16 09:27:36.488: [iter 105 : loss : 0.1270 = 0.0367 + 0.0848 + 0.0055, time: 7.262568]
2023-05-16 09:27:36.643: epoch 105:	0.02654594  	0.19528070  	0.10757226  
2023-05-16 09:27:44.113: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 7.468619]
2023-05-16 09:27:44.257: epoch 106:	0.02658122  	0.19554155  	0.10755814  
2023-05-16 09:27:51.667: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 7.407926]
2023-05-16 09:27:51.823: epoch 107:	0.02663768  	0.19578679  	0.10780515  
2023-05-16 09:27:51.823: Find a better model.
2023-05-16 09:27:59.276: [iter 108 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0056, time: 7.452218]
2023-05-16 09:27:59.422: epoch 108:	0.02667296  	0.19607611  	0.10791785  
2023-05-16 09:27:59.423: Find a better model.
2023-05-16 09:28:06.865: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 7.441470]
2023-05-16 09:28:07.023: epoch 109:	0.02666590  	0.19571270  	0.10798090  
2023-05-16 09:28:14.465: [iter 110 : loss : 0.1235 = 0.0334 + 0.0845 + 0.0057, time: 7.440999]
2023-05-16 09:28:14.621: epoch 110:	0.02670824  	0.19584012  	0.10811336  
2023-05-16 09:28:22.078: [iter 111 : loss : 0.1235 = 0.0335 + 0.0844 + 0.0057, time: 7.454429]
2023-05-16 09:28:22.222: epoch 111:	0.02666590  	0.19564076  	0.10811411  
2023-05-16 09:28:29.653: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.430442]
2023-05-16 09:28:29.808: epoch 112:	0.02659534  	0.19540137  	0.10792510  
2023-05-16 09:28:37.254: [iter 113 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0058, time: 7.443815]
2023-05-16 09:28:37.406: epoch 113:	0.02656005  	0.19504973  	0.10786539  
2023-05-16 09:28:44.648: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 7.240706]
2023-05-16 09:28:44.805: epoch 114:	0.02662356  	0.19556481  	0.10786119  
2023-05-16 09:28:52.245: [iter 115 : loss : 0.1216 = 0.0317 + 0.0841 + 0.0058, time: 7.437326]
2023-05-16 09:28:52.401: epoch 115:	0.02658828  	0.19521093  	0.10797080  
2023-05-16 09:28:59.879: [iter 116 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 7.476995]
2023-05-16 09:29:00.038: epoch 116:	0.02659533  	0.19538505  	0.10798340  
2023-05-16 09:29:07.640: [iter 117 : loss : 0.1209 = 0.0309 + 0.0840 + 0.0059, time: 7.600738]
2023-05-16 09:29:07.794: epoch 117:	0.02663768  	0.19554187  	0.10804913  
2023-05-16 09:29:15.229: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.433722]
2023-05-16 09:29:15.383: epoch 118:	0.02665179  	0.19577298  	0.10828511  
2023-05-16 09:29:22.815: [iter 119 : loss : 0.1195 = 0.0297 + 0.0839 + 0.0060, time: 7.430815]
2023-05-16 09:29:22.973: epoch 119:	0.02665179  	0.19580607  	0.10829663  
2023-05-16 09:29:30.239: [iter 120 : loss : 0.1200 = 0.0302 + 0.0839 + 0.0060, time: 7.263890]
2023-05-16 09:29:30.391: epoch 120:	0.02664473  	0.19566931  	0.10833117  
2023-05-16 09:29:37.507: [iter 121 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 7.114983]
2023-05-16 09:29:37.662: epoch 121:	0.02668707  	0.19565739  	0.10840032  
2023-05-16 09:29:45.017: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 7.353972]
2023-05-16 09:29:45.173: epoch 122:	0.02672235  	0.19590805  	0.10846458  
2023-05-16 09:29:52.598: [iter 123 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0061, time: 7.424099]
2023-05-16 09:29:52.752: epoch 123:	0.02675058  	0.19605254  	0.10861626  
2023-05-16 09:30:00.228: [iter 124 : loss : 0.1185 = 0.0287 + 0.0837 + 0.0061, time: 7.474647]
2023-05-16 09:30:00.383: epoch 124:	0.02677174  	0.19617736  	0.10874847  
2023-05-16 09:30:00.383: Find a better model.
2023-05-16 09:30:07.812: [iter 125 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0061, time: 7.427749]
2023-05-16 09:30:07.966: epoch 125:	0.02672235  	0.19580872  	0.10854507  
2023-05-16 09:30:15.442: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 7.474324]
2023-05-16 09:30:15.601: epoch 126:	0.02678586  	0.19618855  	0.10867431  
2023-05-16 09:30:15.601: Find a better model.
2023-05-16 09:30:23.025: [iter 127 : loss : 0.1169 = 0.0271 + 0.0835 + 0.0062, time: 7.423820]
2023-05-16 09:30:23.180: epoch 127:	0.02682820  	0.19662790  	0.10887562  
2023-05-16 09:30:23.180: Find a better model.
2023-05-16 09:30:30.634: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 7.452778]
2023-05-16 09:30:30.791: epoch 128:	0.02692699  	0.19728823  	0.10892077  
2023-05-16 09:30:30.791: Find a better model.
2023-05-16 09:30:38.424: [iter 129 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0063, time: 7.631818]
2023-05-16 09:30:38.581: epoch 129:	0.02686348  	0.19701327  	0.10889114  
2023-05-16 09:30:46.022: [iter 130 : loss : 0.1168 = 0.0272 + 0.0834 + 0.0063, time: 7.440398]
2023-05-16 09:30:46.176: epoch 130:	0.02680703  	0.19670191  	0.10877018  
2023-05-16 09:30:53.603: [iter 131 : loss : 0.1162 = 0.0266 + 0.0834 + 0.0063, time: 7.426395]
2023-05-16 09:30:53.758: epoch 131:	0.02680703  	0.19671275  	0.10891734  
2023-05-16 09:31:01.194: [iter 132 : loss : 0.1163 = 0.0267 + 0.0833 + 0.0063, time: 7.435030]
2023-05-16 09:31:01.348: epoch 132:	0.02674352  	0.19610971  	0.10866097  
2023-05-16 09:31:08.815: [iter 133 : loss : 0.1153 = 0.0257 + 0.0833 + 0.0064, time: 7.465506]
2023-05-16 09:31:08.970: epoch 133:	0.02665884  	0.19556414  	0.10845232  
2023-05-16 09:31:16.400: [iter 134 : loss : 0.1158 = 0.0262 + 0.0833 + 0.0064, time: 7.429157]
2023-05-16 09:31:16.542: epoch 134:	0.02672235  	0.19611871  	0.10875501  
2023-05-16 09:31:23.973: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 7.428813]
2023-05-16 09:31:24.126: epoch 135:	0.02673646  	0.19622210  	0.10871226  
2023-05-16 09:31:31.607: [iter 136 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0065, time: 7.480080]
2023-05-16 09:31:31.750: epoch 136:	0.02669413  	0.19589759  	0.10853515  
2023-05-16 09:31:39.188: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 7.437454]
2023-05-16 09:31:39.342: epoch 137:	0.02672941  	0.19607255  	0.10874871  
2023-05-16 09:31:46.783: [iter 138 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 7.439473]
2023-05-16 09:31:46.939: epoch 138:	0.02670119  	0.19604930  	0.10885186  
2023-05-16 09:31:54.414: [iter 139 : loss : 0.1142 = 0.0246 + 0.0831 + 0.0066, time: 7.473282]
2023-05-16 09:31:54.569: epoch 139:	0.02665885  	0.19551544  	0.10876499  
2023-05-16 09:32:01.970: [iter 140 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 7.399978]
2023-05-16 09:32:02.126: epoch 140:	0.02663063  	0.19519016  	0.10867646  
2023-05-16 09:32:09.580: [iter 141 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 7.452966]
2023-05-16 09:32:09.739: epoch 141:	0.02664473  	0.19519718  	0.10878325  
2023-05-16 09:32:17.189: [iter 142 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0066, time: 7.448953]
2023-05-16 09:32:17.344: epoch 142:	0.02662356  	0.19534561  	0.10889085  
2023-05-16 09:32:24.784: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 7.439105]
2023-05-16 09:32:24.937: epoch 143:	0.02665885  	0.19576374  	0.10898969  
2023-05-16 09:32:32.373: [iter 144 : loss : 0.1127 = 0.0232 + 0.0829 + 0.0067, time: 7.434203]
2023-05-16 09:32:32.526: epoch 144:	0.02663768  	0.19561930  	0.10902219  
2023-05-16 09:32:39.973: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 7.445557]
2023-05-16 09:32:40.126: epoch 145:	0.02664473  	0.19541705  	0.10895283  
2023-05-16 09:32:47.579: [iter 146 : loss : 0.1130 = 0.0234 + 0.0828 + 0.0067, time: 7.451928]
2023-05-16 09:32:47.738: epoch 146:	0.02660240  	0.19515772  	0.10892432  
2023-05-16 09:32:54.968: [iter 147 : loss : 0.1131 = 0.0235 + 0.0828 + 0.0068, time: 7.228901]
2023-05-16 09:32:55.123: epoch 147:	0.02658828  	0.19494018  	0.10884870  
2023-05-16 09:33:02.558: [iter 148 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.433872]
2023-05-16 09:33:02.717: epoch 148:	0.02666590  	0.19553299  	0.10906870  
2023-05-16 09:33:10.160: [iter 149 : loss : 0.1120 = 0.0225 + 0.0827 + 0.0068, time: 7.442000]
2023-05-16 09:33:10.303: epoch 149:	0.02665179  	0.19527245  	0.10911408  
2023-05-16 09:33:17.788: [iter 150 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.482427]
2023-05-16 09:33:17.941: epoch 150:	0.02663062  	0.19529594  	0.10896517  
2023-05-16 09:33:25.336: [iter 151 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0069, time: 7.392490]
2023-05-16 09:33:25.492: epoch 151:	0.02674352  	0.19622041  	0.10918213  
2023-05-16 09:33:32.941: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.448040]
2023-05-16 09:33:33.095: epoch 152:	0.02667296  	0.19579747  	0.10887191  
2023-05-16 09:33:40.553: [iter 153 : loss : 0.1101 = 0.0206 + 0.0825 + 0.0069, time: 7.455920]
2023-05-16 09:33:40.693: epoch 153:	0.02671530  	0.19586559  	0.10897657  
2023-05-16 09:33:40.693: Early stopping is trigger at epoch: 153
2023-05-16 09:33:40.693: best_result@epoch 128:

2023-05-16 09:33:40.693: 		0.0269      	0.1973      	0.1089      
2023-05-16 09:34:22.931: my pid: 5336
2023-05-16 09:34:22.931: model: model.general_recommender.SGL
2023-05-16 09:34:22.931: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 09:34:22.932: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 09:34:26.033: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 09:34:34.158: [iter 1 : loss : 0.7717 = 0.6930 + 0.0788 + 0.0000, time: 8.125928]
2023-05-16 09:34:34.315: epoch 1:	0.00134773  	0.01065345  	0.00468409  
2023-05-16 09:34:34.315: Find a better model.
2023-05-16 09:34:42.587: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.270418]
2023-05-16 09:34:42.786: epoch 2:	0.00268134  	0.01990482  	0.00940617  
2023-05-16 09:34:42.787: Find a better model.
2023-05-16 09:34:50.785: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 7.996216]
2023-05-16 09:34:50.969: epoch 3:	0.00467822  	0.03580035  	0.01669556  
2023-05-16 09:34:50.969: Find a better model.
2023-05-16 09:34:58.743: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 7.772055]
2023-05-16 09:34:58.890: epoch 4:	0.00810747  	0.05952318  	0.02790748  
2023-05-16 09:34:58.890: Find a better model.
2023-05-16 09:35:06.748: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 7.856887]
2023-05-16 09:35:06.903: epoch 5:	0.01169917  	0.08546852  	0.04038387  
2023-05-16 09:35:06.903: Find a better model.
2023-05-16 09:35:14.520: [iter 6 : loss : 0.7672 = 0.6880 + 0.0792 + 0.0000, time: 7.615204]
2023-05-16 09:35:14.676: epoch 6:	0.01534028  	0.11180835  	0.05316802  
2023-05-16 09:35:14.676: Find a better model.
2023-05-16 09:35:22.123: [iter 7 : loss : 0.7607 = 0.6806 + 0.0800 + 0.0000, time: 7.444705]
2023-05-16 09:35:22.279: epoch 7:	0.01773240  	0.12988032  	0.06330218  
2023-05-16 09:35:22.279: Find a better model.
2023-05-16 09:35:29.745: [iter 8 : loss : 0.7445 = 0.6625 + 0.0819 + 0.0001, time: 7.465302]
2023-05-16 09:35:29.899: epoch 8:	0.01872735  	0.13821344  	0.06831293  
2023-05-16 09:35:29.899: Find a better model.
2023-05-16 09:35:37.324: [iter 9 : loss : 0.7083 = 0.6223 + 0.0858 + 0.0001, time: 7.424397]
2023-05-16 09:35:37.476: epoch 9:	0.01874853  	0.13856411  	0.06882195  
2023-05-16 09:35:37.476: Find a better model.
2023-05-16 09:35:44.896: [iter 10 : loss : 0.6467 = 0.5552 + 0.0912 + 0.0003, time: 7.418476]
2023-05-16 09:35:45.049: epoch 10:	0.01840982  	0.13612968  	0.06780757  
2023-05-16 09:35:52.320: [iter 11 : loss : 0.5713 = 0.4748 + 0.0961 + 0.0004, time: 7.269018]
2023-05-16 09:35:52.473: epoch 11:	0.01838160  	0.13614184  	0.06764057  
2023-05-16 09:35:59.889: [iter 12 : loss : 0.5032 = 0.4033 + 0.0994 + 0.0006, time: 7.415109]
2023-05-16 09:36:00.045: epoch 12:	0.01835337  	0.13545156  	0.06784771  
2023-05-16 09:36:07.500: [iter 13 : loss : 0.4529 = 0.3509 + 0.1012 + 0.0007, time: 7.452254]
2023-05-16 09:36:07.652: epoch 13:	0.01846628  	0.13685153  	0.06875475  
2023-05-16 09:36:15.091: [iter 14 : loss : 0.4145 = 0.3116 + 0.1020 + 0.0008, time: 7.437948]
2023-05-16 09:36:15.234: epoch 14:	0.01881204  	0.13960667  	0.06996244  
2023-05-16 09:36:15.234: Find a better model.
2023-05-16 09:36:22.503: [iter 15 : loss : 0.3879 = 0.2845 + 0.1025 + 0.0010, time: 7.267454]
2023-05-16 09:36:22.656: epoch 15:	0.01891788  	0.14046204  	0.07054868  
2023-05-16 09:36:22.656: Find a better model.
2023-05-16 09:36:30.094: [iter 16 : loss : 0.3655 = 0.2620 + 0.1024 + 0.0011, time: 7.436576]
2023-05-16 09:36:30.250: epoch 16:	0.01908725  	0.14120264  	0.07100529  
2023-05-16 09:36:30.250: Find a better model.
2023-05-16 09:36:37.676: [iter 17 : loss : 0.3491 = 0.2456 + 0.1022 + 0.0012, time: 7.425268]
2023-05-16 09:36:37.829: epoch 17:	0.01939774  	0.14320301  	0.07196066  
2023-05-16 09:36:37.830: Find a better model.
2023-05-16 09:36:45.308: [iter 18 : loss : 0.3338 = 0.2306 + 0.1020 + 0.0013, time: 7.477722]
2023-05-16 09:36:45.461: epoch 18:	0.01960237  	0.14478475  	0.07290360  
2023-05-16 09:36:45.462: Find a better model.
2023-05-16 09:36:52.900: [iter 19 : loss : 0.3196 = 0.2165 + 0.1016 + 0.0014, time: 7.436985]
2023-05-16 09:36:53.053: epoch 19:	0.01989876  	0.14690126  	0.07405218  
2023-05-16 09:36:53.053: Find a better model.
2023-05-16 09:37:00.483: [iter 20 : loss : 0.3098 = 0.2070 + 0.1013 + 0.0015, time: 7.429304]
2023-05-16 09:37:00.626: epoch 20:	0.02013161  	0.14878473  	0.07509588  
2023-05-16 09:37:00.626: Find a better model.
2023-05-16 09:37:08.118: [iter 21 : loss : 0.3000 = 0.1976 + 0.1008 + 0.0016, time: 7.490528]
2023-05-16 09:37:08.273: epoch 21:	0.02023041  	0.14963426  	0.07564045  
2023-05-16 09:37:08.274: Find a better model.
2023-05-16 09:37:15.491: [iter 22 : loss : 0.2918 = 0.1897 + 0.1004 + 0.0017, time: 7.215264]
2023-05-16 09:37:15.644: epoch 22:	0.02030803  	0.15024199  	0.07605663  
2023-05-16 09:37:15.644: Find a better model.
2023-05-16 09:37:23.140: [iter 23 : loss : 0.2835 = 0.1818 + 0.1000 + 0.0017, time: 7.495081]
2023-05-16 09:37:23.286: epoch 23:	0.02068202  	0.15291786  	0.07738752  
2023-05-16 09:37:23.286: Find a better model.
2023-05-16 09:37:30.666: [iter 24 : loss : 0.2772 = 0.1758 + 0.0996 + 0.0018, time: 7.379682]
2023-05-16 09:37:30.818: epoch 24:	0.02086548  	0.15379347  	0.07806643  
2023-05-16 09:37:30.818: Find a better model.
2023-05-16 09:37:38.084: [iter 25 : loss : 0.2705 = 0.1695 + 0.0991 + 0.0019, time: 7.264437]
2023-05-16 09:37:38.239: epoch 25:	0.02113363  	0.15563656  	0.07891349  
2023-05-16 09:37:38.239: Find a better model.
2023-05-16 09:37:45.655: [iter 26 : loss : 0.2667 = 0.1660 + 0.0987 + 0.0019, time: 7.415129]
2023-05-16 09:37:45.806: epoch 26:	0.02121126  	0.15628770  	0.07957217  
2023-05-16 09:37:45.806: Find a better model.
2023-05-16 09:37:53.077: [iter 27 : loss : 0.2593 = 0.1590 + 0.0983 + 0.0020, time: 7.269770]
2023-05-16 09:37:53.229: epoch 27:	0.02138768  	0.15690912  	0.08019413  
2023-05-16 09:37:53.229: Find a better model.
2023-05-16 09:38:00.470: [iter 28 : loss : 0.2541 = 0.1541 + 0.0980 + 0.0021, time: 7.240003]
2023-05-16 09:38:00.623: epoch 28:	0.02162760  	0.15892228  	0.08129298  
2023-05-16 09:38:00.623: Find a better model.
2023-05-16 09:38:08.092: [iter 29 : loss : 0.2497 = 0.1501 + 0.0975 + 0.0021, time: 7.467783]
2023-05-16 09:38:08.245: epoch 29:	0.02178285  	0.16018891  	0.08212789  
2023-05-16 09:38:08.245: Find a better model.
2023-05-16 09:38:15.655: [iter 30 : loss : 0.2432 = 0.1438 + 0.0972 + 0.0022, time: 7.408802]
2023-05-16 09:38:15.809: epoch 30:	0.02196631  	0.16198808  	0.08300783  
2023-05-16 09:38:15.809: Find a better model.
2023-05-16 09:38:23.275: [iter 31 : loss : 0.2395 = 0.1405 + 0.0968 + 0.0023, time: 7.463854]
2023-05-16 09:38:23.425: epoch 31:	0.02212861  	0.16281319  	0.08359010  
2023-05-16 09:38:23.425: Find a better model.
2023-05-16 09:38:30.971: [iter 32 : loss : 0.2341 = 0.1353 + 0.0964 + 0.0023, time: 7.545099]
2023-05-16 09:38:31.112: epoch 32:	0.02224151  	0.16346933  	0.08399887  
2023-05-16 09:38:31.112: Find a better model.
2023-05-16 09:38:38.973: [iter 33 : loss : 0.2315 = 0.1330 + 0.0961 + 0.0024, time: 7.859242]
2023-05-16 09:38:39.139: epoch 33:	0.02226268  	0.16397004  	0.08442220  
2023-05-16 09:38:39.139: Find a better model.
2023-05-16 09:38:46.678: [iter 34 : loss : 0.2273 = 0.1291 + 0.0957 + 0.0024, time: 7.538164]
2023-05-16 09:38:46.821: epoch 34:	0.02241793  	0.16490221  	0.08511921  
2023-05-16 09:38:46.821: Find a better model.
2023-05-16 09:38:54.704: [iter 35 : loss : 0.2240 = 0.1261 + 0.0954 + 0.0025, time: 7.881655]
2023-05-16 09:38:54.846: epoch 35:	0.02253083  	0.16553389  	0.08572989  
2023-05-16 09:38:54.846: Find a better model.
2023-05-16 09:39:02.428: [iter 36 : loss : 0.2206 = 0.1230 + 0.0951 + 0.0026, time: 7.580832]
2023-05-16 09:39:02.581: epoch 36:	0.02259434  	0.16609848  	0.08607304  
2023-05-16 09:39:02.582: Find a better model.
2023-05-16 09:39:10.569: [iter 37 : loss : 0.2167 = 0.1194 + 0.0947 + 0.0026, time: 7.986038]
2023-05-16 09:39:10.712: epoch 37:	0.02260140  	0.16643246  	0.08654310  
2023-05-16 09:39:10.712: Find a better model.
2023-05-16 09:39:18.799: [iter 38 : loss : 0.2151 = 0.1180 + 0.0944 + 0.0027, time: 8.085188]
2023-05-16 09:39:18.964: epoch 38:	0.02277781  	0.16768134  	0.08733868  
2023-05-16 09:39:18.964: Find a better model.
2023-05-16 09:39:26.673: [iter 39 : loss : 0.2107 = 0.1138 + 0.0941 + 0.0027, time: 7.706960]
2023-05-16 09:39:26.819: epoch 39:	0.02292600  	0.16862258  	0.08794425  
2023-05-16 09:39:26.819: Find a better model.
2023-05-16 09:39:34.821: [iter 40 : loss : 0.2074 = 0.1107 + 0.0939 + 0.0028, time: 8.000815]
2023-05-16 09:39:34.969: epoch 40:	0.02306712  	0.16966751  	0.08850790  
2023-05-16 09:39:34.969: Find a better model.
2023-05-16 09:39:42.806: [iter 41 : loss : 0.2056 = 0.1093 + 0.0936 + 0.0028, time: 7.835443]
2023-05-16 09:39:42.952: epoch 41:	0.02314474  	0.17027473  	0.08908979  
2023-05-16 09:39:42.952: Find a better model.
2023-05-16 09:39:50.954: [iter 42 : loss : 0.2037 = 0.1075 + 0.0933 + 0.0029, time: 8.001076]
2023-05-16 09:39:51.124: epoch 42:	0.02320119  	0.17061390  	0.08948930  
2023-05-16 09:39:51.124: Find a better model.
2023-05-16 09:39:58.836: [iter 43 : loss : 0.2000 = 0.1040 + 0.0930 + 0.0029, time: 7.710824]
2023-05-16 09:39:59.049: epoch 43:	0.02340583  	0.17196314  	0.09021558  
2023-05-16 09:39:59.049: Find a better model.
2023-05-16 09:40:06.907: [iter 44 : loss : 0.1962 = 0.1005 + 0.0928 + 0.0030, time: 7.854724]
2023-05-16 09:40:07.065: epoch 44:	0.02338466  	0.17165121  	0.09042531  
2023-05-16 09:40:14.679: [iter 45 : loss : 0.1941 = 0.0986 + 0.0925 + 0.0030, time: 7.612738]
2023-05-16 09:40:14.833: epoch 45:	0.02349757  	0.17257793  	0.09104278  
2023-05-16 09:40:14.833: Find a better model.
2023-05-16 09:40:22.676: [iter 46 : loss : 0.1918 = 0.0964 + 0.0923 + 0.0031, time: 7.841971]
2023-05-16 09:40:22.826: epoch 46:	0.02360342  	0.17343253  	0.09156436  
2023-05-16 09:40:22.826: Find a better model.
2023-05-16 09:40:30.631: [iter 47 : loss : 0.1912 = 0.0961 + 0.0920 + 0.0031, time: 7.802963]
2023-05-16 09:40:30.785: epoch 47:	0.02370926  	0.17427681  	0.09201778  
2023-05-16 09:40:30.786: Find a better model.
2023-05-16 09:40:38.496: [iter 48 : loss : 0.1871 = 0.0921 + 0.0918 + 0.0032, time: 7.708586]
2023-05-16 09:40:38.642: epoch 48:	0.02382217  	0.17505479  	0.09244717  
2023-05-16 09:40:38.642: Find a better model.
2023-05-16 09:40:46.278: [iter 49 : loss : 0.1840 = 0.0892 + 0.0916 + 0.0032, time: 7.634548]
2023-05-16 09:40:46.443: epoch 49:	0.02392096  	0.17522612  	0.09286105  
2023-05-16 09:40:46.443: Find a better model.
2023-05-16 09:40:54.033: [iter 50 : loss : 0.1833 = 0.0886 + 0.0914 + 0.0033, time: 7.588172]
2023-05-16 09:40:54.178: epoch 50:	0.02390684  	0.17547759  	0.09321465  
2023-05-16 09:40:54.178: Find a better model.
2023-05-16 09:41:01.997: [iter 51 : loss : 0.1803 = 0.0858 + 0.0912 + 0.0033, time: 7.816646]
2023-05-16 09:41:02.150: epoch 51:	0.02400563  	0.17594618  	0.09374192  
2023-05-16 09:41:02.150: Find a better model.
2023-05-16 09:41:09.533: [iter 52 : loss : 0.1803 = 0.0859 + 0.0910 + 0.0034, time: 7.382387]
2023-05-16 09:41:09.685: epoch 52:	0.02401269  	0.17621975  	0.09409852  
2023-05-16 09:41:09.685: Find a better model.
2023-05-16 09:41:17.316: [iter 53 : loss : 0.1783 = 0.0841 + 0.0908 + 0.0034, time: 7.628772]
2023-05-16 09:41:17.478: epoch 53:	0.02411148  	0.17707334  	0.09460379  
2023-05-16 09:41:17.478: Find a better model.
2023-05-16 09:41:24.864: [iter 54 : loss : 0.1763 = 0.0822 + 0.0906 + 0.0035, time: 7.385291]
2023-05-16 09:41:25.008: epoch 54:	0.02419616  	0.17802894  	0.09525535  
2023-05-16 09:41:25.008: Find a better model.
2023-05-16 09:41:32.602: [iter 55 : loss : 0.1744 = 0.0805 + 0.0904 + 0.0035, time: 7.592749]
2023-05-16 09:41:32.748: epoch 55:	0.02420321  	0.17804398  	0.09527709  
2023-05-16 09:41:32.748: Find a better model.
2023-05-16 09:41:40.711: [iter 56 : loss : 0.1726 = 0.0788 + 0.0902 + 0.0036, time: 7.960744]
2023-05-16 09:41:40.869: epoch 56:	0.02435140  	0.17881615  	0.09592573  
2023-05-16 09:41:40.869: Find a better model.
2023-05-16 09:41:48.754: [iter 57 : loss : 0.1708 = 0.0771 + 0.0900 + 0.0036, time: 7.884035]
2023-05-16 09:41:48.897: epoch 57:	0.02443607  	0.17970072  	0.09623782  
2023-05-16 09:41:48.898: Find a better model.
2023-05-16 09:41:56.565: [iter 58 : loss : 0.1689 = 0.0754 + 0.0898 + 0.0036, time: 7.665733]
2023-05-16 09:41:56.705: epoch 58:	0.02452781  	0.18042998  	0.09671380  
2023-05-16 09:41:56.705: Find a better model.
2023-05-16 09:42:04.297: [iter 59 : loss : 0.1677 = 0.0743 + 0.0897 + 0.0037, time: 7.590234]
2023-05-16 09:42:04.450: epoch 59:	0.02471834  	0.18188204  	0.09736570  
2023-05-16 09:42:04.450: Find a better model.
2023-05-16 09:42:11.852: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 7.399594]
2023-05-16 09:42:12.000: epoch 60:	0.02476067  	0.18215539  	0.09761609  
2023-05-16 09:42:12.000: Find a better model.
2023-05-16 09:42:19.481: [iter 61 : loss : 0.1647 = 0.0716 + 0.0893 + 0.0038, time: 7.479446]
2023-05-16 09:42:19.627: epoch 61:	0.02478890  	0.18250744  	0.09801320  
2023-05-16 09:42:19.627: Find a better model.
2023-05-16 09:42:27.318: [iter 62 : loss : 0.1633 = 0.0703 + 0.0892 + 0.0038, time: 7.687162]
2023-05-16 09:42:27.487: epoch 62:	0.02492297  	0.18334062  	0.09849071  
2023-05-16 09:42:27.487: Find a better model.
2023-05-16 09:42:35.131: [iter 63 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 7.642878]
2023-05-16 09:42:35.312: epoch 63:	0.02496530  	0.18380943  	0.09872335  
2023-05-16 09:42:35.312: Find a better model.
2023-05-16 09:42:42.952: [iter 64 : loss : 0.1608 = 0.0681 + 0.0888 + 0.0039, time: 7.637382]
2023-05-16 09:42:43.098: epoch 64:	0.02503586  	0.18420564  	0.09902278  
2023-05-16 09:42:43.098: Find a better model.
2023-05-16 09:42:50.590: [iter 65 : loss : 0.1598 = 0.0672 + 0.0887 + 0.0040, time: 7.490078]
2023-05-16 09:42:50.745: epoch 65:	0.02498647  	0.18373634  	0.09906821  
2023-05-16 09:42:58.160: [iter 66 : loss : 0.1581 = 0.0656 + 0.0886 + 0.0040, time: 7.413300]
2023-05-16 09:42:58.301: epoch 66:	0.02500058  	0.18376242  	0.09941756  
2023-05-16 09:43:05.608: [iter 67 : loss : 0.1565 = 0.0640 + 0.0884 + 0.0040, time: 7.304437]
2023-05-16 09:43:05.762: epoch 67:	0.02514170  	0.18473832  	0.09981437  
2023-05-16 09:43:05.762: Find a better model.
2023-05-16 09:43:13.471: [iter 68 : loss : 0.1565 = 0.0642 + 0.0883 + 0.0041, time: 7.707130]
2023-05-16 09:43:13.611: epoch 68:	0.02508525  	0.18454213  	0.09996974  
2023-05-16 09:43:21.166: [iter 69 : loss : 0.1544 = 0.0622 + 0.0881 + 0.0041, time: 7.554891]
2023-05-16 09:43:21.320: epoch 69:	0.02512053  	0.18474567  	0.10022280  
2023-05-16 09:43:21.320: Find a better model.
2023-05-16 09:43:28.863: [iter 70 : loss : 0.1528 = 0.0606 + 0.0880 + 0.0042, time: 7.540924]
2023-05-16 09:43:29.006: epoch 70:	0.02519815  	0.18511446  	0.10045649  
2023-05-16 09:43:29.006: Find a better model.
2023-05-16 09:43:36.838: [iter 71 : loss : 0.1513 = 0.0592 + 0.0879 + 0.0042, time: 7.831132]
2023-05-16 09:43:36.992: epoch 71:	0.02526872  	0.18587872  	0.10089701  
2023-05-16 09:43:36.992: Find a better model.
2023-05-16 09:43:44.754: [iter 72 : loss : 0.1511 = 0.0591 + 0.0878 + 0.0042, time: 7.760763]
2023-05-16 09:43:44.927: epoch 72:	0.02530400  	0.18611422  	0.10115787  
2023-05-16 09:43:44.927: Find a better model.
2023-05-16 09:43:52.761: [iter 73 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 7.832823]
2023-05-16 09:43:52.915: epoch 73:	0.02533223  	0.18633477  	0.10125811  
2023-05-16 09:43:52.916: Find a better model.
2023-05-16 09:44:00.401: [iter 74 : loss : 0.1485 = 0.0566 + 0.0875 + 0.0043, time: 7.482742]
2023-05-16 09:44:00.545: epoch 74:	0.02543808  	0.18750799  	0.10165787  
2023-05-16 09:44:00.545: Find a better model.
2023-05-16 09:44:07.983: [iter 75 : loss : 0.1481 = 0.0563 + 0.0874 + 0.0044, time: 7.436145]
2023-05-16 09:44:08.125: epoch 75:	0.02541691  	0.18714465  	0.10169102  
2023-05-16 09:44:15.831: [iter 76 : loss : 0.1469 = 0.0552 + 0.0873 + 0.0044, time: 7.704114]
2023-05-16 09:44:15.982: epoch 76:	0.02554392  	0.18782283  	0.10215119  
2023-05-16 09:44:15.982: Find a better model.
2023-05-16 09:44:23.601: [iter 77 : loss : 0.1458 = 0.0542 + 0.0871 + 0.0044, time: 7.617443]
2023-05-16 09:44:23.761: epoch 77:	0.02555803  	0.18788847  	0.10225437  
2023-05-16 09:44:23.761: Find a better model.
2023-05-16 09:44:31.505: [iter 78 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 7.742073]
2023-05-16 09:44:31.673: epoch 78:	0.02559331  	0.18826808  	0.10247350  
2023-05-16 09:44:31.673: Find a better model.
2023-05-16 09:44:39.926: [iter 79 : loss : 0.1436 = 0.0521 + 0.0870 + 0.0045, time: 8.252029]
2023-05-16 09:44:40.142: epoch 79:	0.02564271  	0.18887606  	0.10278109  
2023-05-16 09:44:40.142: Find a better model.
2023-05-16 09:44:47.795: [iter 80 : loss : 0.1430 = 0.0516 + 0.0869 + 0.0046, time: 7.651461]
2023-05-16 09:44:47.955: epoch 80:	0.02561449  	0.18863940  	0.10286098  
2023-05-16 09:44:55.980: [iter 81 : loss : 0.1425 = 0.0512 + 0.0867 + 0.0046, time: 8.021972]
2023-05-16 09:44:56.135: epoch 81:	0.02569916  	0.18900785  	0.10323865  
2023-05-16 09:44:56.135: Find a better model.
2023-05-16 09:45:05.014: [iter 82 : loss : 0.1413 = 0.0500 + 0.0866 + 0.0046, time: 8.875844]
2023-05-16 09:45:05.296: epoch 82:	0.02573445  	0.18907104  	0.10342877  
2023-05-16 09:45:05.296: Find a better model.
2023-05-16 09:45:12.644: [iter 83 : loss : 0.1405 = 0.0493 + 0.0865 + 0.0047, time: 7.347132]
2023-05-16 09:45:12.801: epoch 83:	0.02576267  	0.18948393  	0.10368613  
2023-05-16 09:45:12.801: Find a better model.
2023-05-16 09:45:20.769: [iter 84 : loss : 0.1403 = 0.0491 + 0.0864 + 0.0047, time: 7.965011]
2023-05-16 09:45:20.925: epoch 84:	0.02583324  	0.19024380  	0.10399479  
2023-05-16 09:45:20.925: Find a better model.
2023-05-16 09:45:28.904: [iter 85 : loss : 0.1392 = 0.0481 + 0.0863 + 0.0048, time: 7.977003]
2023-05-16 09:45:29.071: epoch 85:	0.02581913  	0.18995705  	0.10407007  
2023-05-16 09:45:38.282: [iter 86 : loss : 0.1392 = 0.0481 + 0.0862 + 0.0048, time: 9.209023]
2023-05-16 09:45:38.535: epoch 86:	0.02581207  	0.18995146  	0.10412367  
2023-05-16 09:45:47.048: [iter 87 : loss : 0.1364 = 0.0454 + 0.0862 + 0.0048, time: 8.509093]
2023-05-16 09:45:47.225: epoch 87:	0.02592498  	0.19075303  	0.10451150  
2023-05-16 09:45:47.225: Find a better model.
2023-05-16 09:45:55.372: [iter 88 : loss : 0.1359 = 0.0450 + 0.0861 + 0.0049, time: 8.146011]
2023-05-16 09:45:55.527: epoch 88:	0.02591792  	0.19019368  	0.10450721  
2023-05-16 09:46:03.614: [iter 89 : loss : 0.1354 = 0.0446 + 0.0860 + 0.0049, time: 8.084992]
2023-05-16 09:46:03.797: epoch 89:	0.02586147  	0.19007671  	0.10449361  
2023-05-16 09:46:12.676: [iter 90 : loss : 0.1359 = 0.0451 + 0.0859 + 0.0049, time: 8.875337]
2023-05-16 09:46:12.981: epoch 90:	0.02590381  	0.19010499  	0.10452327  
2023-05-16 09:46:21.822: [iter 91 : loss : 0.1349 = 0.0441 + 0.0858 + 0.0050, time: 8.833002]
2023-05-16 09:46:22.115: epoch 91:	0.02592498  	0.19075921  	0.10479450  
2023-05-16 09:46:22.115: Find a better model.
2023-05-16 09:46:30.175: [iter 92 : loss : 0.1341 = 0.0434 + 0.0857 + 0.0050, time: 8.059008]
2023-05-16 09:46:30.343: epoch 92:	0.02593910  	0.19084649  	0.10490958  
2023-05-16 09:46:30.343: Find a better model.
2023-05-16 09:46:38.515: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 8.171012]
2023-05-16 09:46:38.671: epoch 93:	0.02601672  	0.19124334  	0.10522268  
2023-05-16 09:46:38.671: Find a better model.
2023-05-16 09:46:47.685: [iter 94 : loss : 0.1322 = 0.0415 + 0.0856 + 0.0051, time: 9.009027]
2023-05-16 09:46:47.976: epoch 94:	0.02610845  	0.19193517  	0.10542102  
2023-05-16 09:46:47.976: Find a better model.
2023-05-16 09:46:56.881: [iter 95 : loss : 0.1312 = 0.0406 + 0.0855 + 0.0051, time: 8.903018]
2023-05-16 09:46:57.167: epoch 95:	0.02620724  	0.19262020  	0.10566426  
2023-05-16 09:46:57.167: Find a better model.
2023-05-16 09:47:05.130: [iter 96 : loss : 0.1314 = 0.0409 + 0.0854 + 0.0052, time: 7.962003]
2023-05-16 09:47:05.292: epoch 96:	0.02611550  	0.19174075  	0.10573464  
2023-05-16 09:47:13.442: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 8.147084]
2023-05-16 09:47:13.601: epoch 97:	0.02620018  	0.19239450  	0.10576036  
2023-05-16 09:47:22.799: [iter 98 : loss : 0.1306 = 0.0401 + 0.0852 + 0.0052, time: 9.192089]
2023-05-16 09:47:23.077: epoch 98:	0.02617901  	0.19239113  	0.10583153  
2023-05-16 09:47:31.967: [iter 99 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0053, time: 8.886005]
2023-05-16 09:47:32.257: epoch 99:	0.02624958  	0.19284624  	0.10629581  
2023-05-16 09:47:32.257: Find a better model.
2023-05-16 09:47:40.333: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 8.075002]
2023-05-16 09:47:40.529: epoch 100:	0.02629897  	0.19330123  	0.10641672  
2023-05-16 09:47:40.530: Find a better model.
2023-05-16 09:47:48.576: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0053, time: 8.045189]
2023-05-16 09:47:48.726: epoch 101:	0.02632014  	0.19353463  	0.10641661  
2023-05-16 09:47:48.726: Find a better model.
2023-05-16 09:47:57.934: [iter 102 : loss : 0.1273 = 0.0369 + 0.0849 + 0.0054, time: 9.203024]
2023-05-16 09:47:58.216: epoch 102:	0.02629897  	0.19333810  	0.10654764  
2023-05-16 09:48:07.241: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 9.020014]
2023-05-16 09:48:07.528: epoch 103:	0.02635542  	0.19365993  	0.10669330  
2023-05-16 09:48:07.528: Find a better model.
2023-05-16 09:48:15.526: [iter 104 : loss : 0.1277 = 0.0374 + 0.0848 + 0.0055, time: 7.997008]
2023-05-16 09:48:15.693: epoch 104:	0.02632014  	0.19375397  	0.10681336  
2023-05-16 09:48:15.694: Find a better model.
2023-05-16 09:48:23.790: [iter 105 : loss : 0.1269 = 0.0367 + 0.0847 + 0.0055, time: 8.095135]
2023-05-16 09:48:23.950: epoch 105:	0.02641893  	0.19465846  	0.10718650  
2023-05-16 09:48:23.950: Find a better model.
2023-05-16 09:48:33.198: [iter 106 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 9.238358]
2023-05-16 09:48:33.493: epoch 106:	0.02636953  	0.19398238  	0.10705158  
2023-05-16 09:48:42.400: [iter 107 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0055, time: 8.906027]
2023-05-16 09:48:42.688: epoch 107:	0.02635542  	0.19386551  	0.10718260  
2023-05-16 09:48:50.701: [iter 108 : loss : 0.1253 = 0.0351 + 0.0846 + 0.0056, time: 8.012045]
2023-05-16 09:48:50.868: epoch 108:	0.02634131  	0.19406906  	0.10742354  
2023-05-16 09:48:59.022: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 8.152003]
2023-05-16 09:48:59.183: epoch 109:	0.02634837  	0.19358099  	0.10736860  
2023-05-16 09:49:07.969: [iter 110 : loss : 0.1235 = 0.0334 + 0.0845 + 0.0057, time: 8.784025]
2023-05-16 09:49:08.260: epoch 110:	0.02632719  	0.19350885  	0.10733320  
2023-05-16 09:49:17.183: [iter 111 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 8.920022]
2023-05-16 09:49:17.471: epoch 111:	0.02633426  	0.19376156  	0.10757680  
2023-05-16 09:49:25.545: [iter 112 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0057, time: 8.072002]
2023-05-16 09:49:25.698: epoch 112:	0.02635543  	0.19414034  	0.10768682  
2023-05-16 09:49:33.975: [iter 113 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0058, time: 8.275999]
2023-05-16 09:49:34.153: epoch 113:	0.02629192  	0.19379234  	0.10757497  
2023-05-16 09:49:43.483: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 9.327045]
2023-05-16 09:49:43.770: epoch 114:	0.02632720  	0.19355945  	0.10766497  
2023-05-16 09:49:52.819: [iter 115 : loss : 0.1220 = 0.0320 + 0.0842 + 0.0058, time: 9.046017]
2023-05-16 09:49:53.110: epoch 115:	0.02632720  	0.19369592  	0.10773234  
2023-05-16 09:50:01.071: [iter 116 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0058, time: 7.959127]
2023-05-16 09:50:01.227: epoch 116:	0.02631309  	0.19360936  	0.10764565  
2023-05-16 09:50:09.319: [iter 117 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 8.091047]
2023-05-16 09:50:09.484: epoch 117:	0.02639776  	0.19426107  	0.10791750  
2023-05-16 09:50:18.703: [iter 118 : loss : 0.1211 = 0.0311 + 0.0840 + 0.0059, time: 9.216467]
2023-05-16 09:50:18.989: epoch 118:	0.02643304  	0.19445758  	0.10812075  
2023-05-16 09:50:28.051: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0059, time: 9.052034]
2023-05-16 09:50:28.337: epoch 119:	0.02638366  	0.19392692  	0.10795860  
2023-05-16 09:50:36.458: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 8.120041]
2023-05-16 09:50:36.616: epoch 120:	0.02638365  	0.19373737  	0.10814377  
2023-05-16 09:50:44.760: [iter 121 : loss : 0.1198 = 0.0299 + 0.0838 + 0.0060, time: 8.143006]
2023-05-16 09:50:44.908: epoch 121:	0.02634837  	0.19367833  	0.10818265  
2023-05-16 09:50:54.077: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 9.165483]
2023-05-16 09:50:54.366: epoch 122:	0.02630603  	0.19330309  	0.10788292  
2023-05-16 09:51:03.324: [iter 123 : loss : 0.1190 = 0.0292 + 0.0838 + 0.0061, time: 8.953022]
2023-05-16 09:51:03.604: epoch 123:	0.02634837  	0.19364677  	0.10803695  
2023-05-16 09:51:11.672: [iter 124 : loss : 0.1183 = 0.0285 + 0.0837 + 0.0061, time: 8.067023]
2023-05-16 09:51:11.829: epoch 124:	0.02635543  	0.19366597  	0.10808571  
2023-05-16 09:51:19.983: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 8.151013]
2023-05-16 09:51:20.141: epoch 125:	0.02634132  	0.19325620  	0.10812962  
2023-05-16 09:51:29.490: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 9.346017]
2023-05-16 09:51:29.777: epoch 126:	0.02636954  	0.19353959  	0.10816125  
2023-05-16 09:51:38.703: [iter 127 : loss : 0.1169 = 0.0271 + 0.0835 + 0.0062, time: 8.924026]
2023-05-16 09:51:38.992: epoch 127:	0.02632015  	0.19341794  	0.10836266  
2023-05-16 09:51:46.879: [iter 128 : loss : 0.1178 = 0.0280 + 0.0835 + 0.0062, time: 7.885993]
2023-05-16 09:51:47.038: epoch 128:	0.02634132  	0.19333477  	0.10844268  
2023-05-16 09:51:55.115: [iter 129 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 8.075029]
2023-05-16 09:51:55.293: epoch 129:	0.02640482  	0.19391908  	0.10865904  
2023-05-16 09:52:04.095: [iter 130 : loss : 0.1172 = 0.0275 + 0.0834 + 0.0063, time: 8.800084]
2023-05-16 09:52:04.383: epoch 130:	0.02644716  	0.19406761  	0.10883062  
2023-05-16 09:52:04.383: Early stopping is trigger at epoch: 130
2023-05-16 09:52:04.383: best_result@epoch 105:

2023-05-16 09:52:04.383: 		0.0264      	0.1947      	0.1072      
2023-05-16 09:58:01.168: my pid: 11036
2023-05-16 09:58:01.168: model: model.general_recommender.SGL
2023-05-16 09:58:01.168: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 09:58:01.168: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 09:58:05.154: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 09:58:14.871: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.716559]
2023-05-16 09:58:15.046: epoch 1:	0.00154530  	0.01144892  	0.00525146  
2023-05-16 09:58:15.046: Find a better model.
2023-05-16 09:58:24.484: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 9.436898]
2023-05-16 09:58:24.692: epoch 2:	0.00258256  	0.01942644  	0.00943928  
2023-05-16 09:58:24.692: Find a better model.
2023-05-16 09:58:33.773: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 9.079019]
2023-05-16 09:58:33.937: epoch 3:	0.00469233  	0.03546405  	0.01690958  
2023-05-16 09:58:33.937: Find a better model.
2023-05-16 09:58:43.544: [iter 4 : loss : 0.7707 = 0.6920 + 0.0786 + 0.0000, time: 9.602178]
2023-05-16 09:58:43.857: epoch 4:	0.00745831  	0.05422639  	0.02596427  
2023-05-16 09:58:43.857: Find a better model.
2023-05-16 09:58:51.869: [iter 5 : loss : 0.7697 = 0.6908 + 0.0788 + 0.0000, time: 8.010891]
2023-05-16 09:58:52.034: epoch 5:	0.01135340  	0.08253442  	0.03846245  
2023-05-16 09:58:52.034: Find a better model.
2023-05-16 09:59:00.470: [iter 6 : loss : 0.7674 = 0.6882 + 0.0792 + 0.0000, time: 8.435045]
2023-05-16 09:59:00.632: epoch 6:	0.01478283  	0.10631796  	0.05161952  
2023-05-16 09:59:00.632: Find a better model.
2023-05-16 09:59:09.495: [iter 7 : loss : 0.7613 = 0.6814 + 0.0799 + 0.0000, time: 8.860651]
2023-05-16 09:59:09.652: epoch 7:	0.01747131  	0.12569301  	0.06245547  
2023-05-16 09:59:09.652: Find a better model.
2023-05-16 09:59:18.954: [iter 8 : loss : 0.7463 = 0.6644 + 0.0818 + 0.0001, time: 9.300481]
2023-05-16 09:59:19.252: epoch 8:	0.01888261  	0.13709834  	0.06847508  
2023-05-16 09:59:19.252: Find a better model.
2023-05-16 09:59:26.865: [iter 9 : loss : 0.7121 = 0.6265 + 0.0855 + 0.0001, time: 7.612580]
2023-05-16 09:59:27.026: epoch 9:	0.01876264  	0.13755369  	0.06910958  
2023-05-16 09:59:27.026: Find a better model.
2023-05-16 09:59:35.274: [iter 10 : loss : 0.6525 = 0.5614 + 0.0908 + 0.0002, time: 8.246974]
2023-05-16 09:59:35.431: epoch 10:	0.01857211  	0.13674825  	0.06860130  
2023-05-16 09:59:43.896: [iter 11 : loss : 0.5775 = 0.4813 + 0.0958 + 0.0004, time: 8.464000]
2023-05-16 09:59:44.052: epoch 11:	0.01850861  	0.13619803  	0.06829811  
2023-05-16 09:59:53.057: [iter 12 : loss : 0.5084 = 0.4086 + 0.0992 + 0.0005, time: 9.002145]
2023-05-16 09:59:53.348: epoch 12:	0.01845922  	0.13556856  	0.06820022  
2023-05-16 10:00:00.789: [iter 13 : loss : 0.4566 = 0.3548 + 0.1011 + 0.0007, time: 7.439833]
2023-05-16 10:00:00.951: epoch 13:	0.01856506  	0.13716491  	0.06932768  
2023-05-16 10:00:09.265: [iter 14 : loss : 0.4174 = 0.3145 + 0.1020 + 0.0008, time: 8.313028]
2023-05-16 10:00:09.424: epoch 14:	0.01867091  	0.13816378  	0.06990498  
2023-05-16 10:00:09.424: Find a better model.
2023-05-16 10:00:17.734: [iter 15 : loss : 0.3900 = 0.2865 + 0.1025 + 0.0010, time: 8.307365]
2023-05-16 10:00:17.889: epoch 15:	0.01889672  	0.13979313  	0.07077923  
2023-05-16 10:00:17.889: Find a better model.
2023-05-16 10:00:27.063: [iter 16 : loss : 0.3671 = 0.2635 + 0.1025 + 0.0011, time: 9.172772]
2023-05-16 10:00:27.351: epoch 16:	0.01908724  	0.14080344  	0.07152886  
2023-05-16 10:00:27.351: Find a better model.
2023-05-16 10:00:35.772: [iter 17 : loss : 0.3503 = 0.2468 + 0.1024 + 0.0012, time: 8.420027]
2023-05-16 10:00:35.933: epoch 17:	0.01929894  	0.14226092  	0.07234803  
2023-05-16 10:00:35.933: Find a better model.
2023-05-16 10:00:44.428: [iter 18 : loss : 0.3347 = 0.2314 + 0.1021 + 0.0013, time: 8.493068]
2023-05-16 10:00:44.582: epoch 18:	0.01964471  	0.14447598  	0.07335260  
2023-05-16 10:00:44.582: Find a better model.
2023-05-16 10:00:52.723: [iter 19 : loss : 0.3207 = 0.2175 + 0.1018 + 0.0014, time: 8.139016]
2023-05-16 10:00:52.877: epoch 19:	0.01979290  	0.14531790  	0.07409160  
2023-05-16 10:00:52.878: Find a better model.
2023-05-16 10:01:02.045: [iter 20 : loss : 0.3108 = 0.2080 + 0.1013 + 0.0015, time: 9.165241]
2023-05-16 10:01:02.330: epoch 20:	0.01996931  	0.14661974  	0.07485416  
2023-05-16 10:01:02.330: Find a better model.
2023-05-16 10:01:11.217: [iter 21 : loss : 0.3011 = 0.1985 + 0.1010 + 0.0016, time: 8.886290]
2023-05-16 10:01:11.396: epoch 21:	0.02020218  	0.14848432  	0.07568249  
2023-05-16 10:01:11.396: Find a better model.
2023-05-16 10:01:19.631: [iter 22 : loss : 0.2926 = 0.1903 + 0.1006 + 0.0017, time: 8.233014]
2023-05-16 10:01:19.785: epoch 22:	0.02032214  	0.14935520  	0.07612055  
2023-05-16 10:01:19.785: Find a better model.
2023-05-16 10:01:27.836: [iter 23 : loss : 0.2844 = 0.1824 + 0.1002 + 0.0017, time: 8.049992]
2023-05-16 10:01:27.995: epoch 23:	0.02056912  	0.15129834  	0.07710733  
2023-05-16 10:01:27.995: Find a better model.
2023-05-16 10:01:37.140: [iter 24 : loss : 0.2778 = 0.1763 + 0.0997 + 0.0018, time: 9.142021]
2023-05-16 10:01:37.425: epoch 24:	0.02078787  	0.15240449  	0.07774049  
2023-05-16 10:01:37.425: Find a better model.
2023-05-16 10:01:46.480: [iter 25 : loss : 0.2712 = 0.1701 + 0.0993 + 0.0019, time: 9.054347]
2023-05-16 10:01:46.760: epoch 25:	0.02107012  	0.15448351  	0.07878309  
2023-05-16 10:01:46.760: Find a better model.
2023-05-16 10:01:55.067: [iter 26 : loss : 0.2676 = 0.1668 + 0.0988 + 0.0019, time: 8.305995]
2023-05-16 10:01:55.234: epoch 26:	0.02121832  	0.15538156  	0.07938436  
2023-05-16 10:01:55.234: Find a better model.
2023-05-16 10:02:03.258: [iter 27 : loss : 0.2597 = 0.1592 + 0.0984 + 0.0020, time: 8.022043]
2023-05-16 10:02:03.420: epoch 27:	0.02139474  	0.15669535  	0.08013055  
2023-05-16 10:02:03.420: Find a better model.
2023-05-16 10:02:12.908: [iter 28 : loss : 0.2549 = 0.1548 + 0.0980 + 0.0021, time: 9.484016]
2023-05-16 10:02:13.200: epoch 28:	0.02158526  	0.15801789  	0.08088912  
2023-05-16 10:02:13.200: Find a better model.
2023-05-16 10:02:22.191: [iter 29 : loss : 0.2504 = 0.1506 + 0.0977 + 0.0021, time: 8.990012]
2023-05-16 10:02:22.481: epoch 29:	0.02181108  	0.16006619  	0.08197301  
2023-05-16 10:02:22.481: Find a better model.
2023-05-16 10:02:30.620: [iter 30 : loss : 0.2439 = 0.1444 + 0.0973 + 0.0022, time: 8.137362]
2023-05-16 10:02:30.815: epoch 30:	0.02207217  	0.16207939  	0.08311127  
2023-05-16 10:02:30.815: Find a better model.
2023-05-16 10:02:39.116: [iter 31 : loss : 0.2403 = 0.1412 + 0.0969 + 0.0023, time: 8.300013]
2023-05-16 10:02:39.292: epoch 31:	0.02214273  	0.16272551  	0.08353092  
2023-05-16 10:02:39.292: Find a better model.
2023-05-16 10:02:48.935: [iter 32 : loss : 0.2347 = 0.1358 + 0.0966 + 0.0023, time: 9.639014]
2023-05-16 10:02:49.225: epoch 32:	0.02226269  	0.16398808  	0.08409429  
2023-05-16 10:02:49.225: Find a better model.
2023-05-16 10:02:58.377: [iter 33 : loss : 0.2321 = 0.1336 + 0.0961 + 0.0024, time: 9.149030]
2023-05-16 10:02:58.663: epoch 33:	0.02243910  	0.16523254  	0.08481680  
2023-05-16 10:02:58.663: Find a better model.
2023-05-16 10:03:06.810: [iter 34 : loss : 0.2280 = 0.1297 + 0.0958 + 0.0024, time: 8.145023]
2023-05-16 10:03:06.963: epoch 34:	0.02260140  	0.16669828  	0.08576994  
2023-05-16 10:03:06.963: Find a better model.
2023-05-16 10:03:15.045: [iter 35 : loss : 0.2246 = 0.1266 + 0.0955 + 0.0025, time: 8.081515]
2023-05-16 10:03:15.194: epoch 35:	0.02265785  	0.16664748  	0.08618218  
2023-05-16 10:03:24.784: [iter 36 : loss : 0.2212 = 0.1235 + 0.0952 + 0.0026, time: 9.586604]
2023-05-16 10:03:25.074: epoch 36:	0.02282015  	0.16780254  	0.08677303  
2023-05-16 10:03:25.074: Find a better model.
2023-05-16 10:03:34.253: [iter 37 : loss : 0.2174 = 0.1199 + 0.0949 + 0.0026, time: 9.177045]
2023-05-16 10:03:34.539: epoch 37:	0.02288366  	0.16842075  	0.08714405  
2023-05-16 10:03:34.539: Find a better model.
2023-05-16 10:03:42.775: [iter 38 : loss : 0.2159 = 0.1186 + 0.0946 + 0.0027, time: 8.233992]
2023-05-16 10:03:42.942: epoch 38:	0.02304596  	0.16960262  	0.08790278  
2023-05-16 10:03:42.943: Find a better model.
2023-05-16 10:03:51.187: [iter 39 : loss : 0.2112 = 0.1143 + 0.0942 + 0.0027, time: 8.242014]
2023-05-16 10:03:51.347: epoch 39:	0.02306713  	0.16971695  	0.08821857  
2023-05-16 10:03:51.347: Find a better model.
2023-05-16 10:04:00.967: [iter 40 : loss : 0.2079 = 0.1112 + 0.0939 + 0.0028, time: 9.617011]
2023-05-16 10:04:01.252: epoch 40:	0.02318003  	0.17027108  	0.08861071  
2023-05-16 10:04:01.253: Find a better model.
2023-05-16 10:04:10.381: [iter 41 : loss : 0.2065 = 0.1099 + 0.0937 + 0.0028, time: 9.123849]
2023-05-16 10:04:10.677: epoch 41:	0.02329293  	0.17099066  	0.08909146  
2023-05-16 10:04:10.677: Find a better model.
2023-05-16 10:04:19.027: [iter 42 : loss : 0.2043 = 0.1080 + 0.0934 + 0.0029, time: 8.349190]
2023-05-16 10:04:19.199: epoch 42:	0.02339878  	0.17217995  	0.08962049  
2023-05-16 10:04:19.199: Find a better model.
2023-05-16 10:04:27.431: [iter 43 : loss : 0.2001 = 0.1041 + 0.0931 + 0.0029, time: 8.231004]
2023-05-16 10:04:27.595: epoch 43:	0.02353990  	0.17313831  	0.09042105  
2023-05-16 10:04:27.595: Find a better model.
2023-05-16 10:04:37.141: [iter 44 : loss : 0.1967 = 0.1010 + 0.0928 + 0.0030, time: 9.544015]
2023-05-16 10:04:37.435: epoch 44:	0.02361047  	0.17378043  	0.09079549  
2023-05-16 10:04:37.435: Find a better model.
2023-05-16 10:04:46.539: [iter 45 : loss : 0.1946 = 0.0990 + 0.0926 + 0.0030, time: 9.100026]
2023-05-16 10:04:46.838: epoch 45:	0.02370927  	0.17454964  	0.09139794  
2023-05-16 10:04:46.838: Find a better model.
2023-05-16 10:04:54.969: [iter 46 : loss : 0.1923 = 0.0969 + 0.0923 + 0.0031, time: 8.128369]
2023-05-16 10:04:55.132: epoch 46:	0.02382922  	0.17507264  	0.09176631  
2023-05-16 10:04:55.132: Find a better model.
2023-05-16 10:05:03.453: [iter 47 : loss : 0.1915 = 0.0962 + 0.0921 + 0.0031, time: 8.319071]
2023-05-16 10:05:03.615: epoch 47:	0.02401270  	0.17652975  	0.09246980  
2023-05-16 10:05:03.615: Find a better model.
2023-05-16 10:05:13.265: [iter 48 : loss : 0.1874 = 0.0924 + 0.0919 + 0.0032, time: 9.644991]
2023-05-16 10:05:13.558: epoch 48:	0.02410443  	0.17722692  	0.09279174  
2023-05-16 10:05:13.558: Find a better model.
2023-05-16 10:05:22.707: [iter 49 : loss : 0.1842 = 0.0893 + 0.0917 + 0.0032, time: 9.144213]
2023-05-16 10:05:22.998: epoch 49:	0.02411853  	0.17680030  	0.09272318  
2023-05-16 10:05:31.157: [iter 50 : loss : 0.1838 = 0.0891 + 0.0914 + 0.0033, time: 8.155993]
2023-05-16 10:05:31.317: epoch 50:	0.02416087  	0.17722987  	0.09323262  
2023-05-16 10:05:31.317: Find a better model.
2023-05-16 10:05:39.615: [iter 51 : loss : 0.1806 = 0.0861 + 0.0913 + 0.0033, time: 8.296992]
2023-05-16 10:05:39.773: epoch 51:	0.02427377  	0.17826706  	0.09387761  
2023-05-16 10:05:39.774: Find a better model.
2023-05-16 10:05:49.503: [iter 52 : loss : 0.1806 = 0.0861 + 0.0911 + 0.0034, time: 9.725991]
2023-05-16 10:05:49.790: epoch 52:	0.02422438  	0.17794113  	0.09395175  
2023-05-16 10:05:59.007: [iter 53 : loss : 0.1786 = 0.0843 + 0.0908 + 0.0034, time: 9.214992]
2023-05-16 10:05:59.294: epoch 53:	0.02438668  	0.17892393  	0.09450379  
2023-05-16 10:05:59.294: Find a better model.
2023-05-16 10:06:07.525: [iter 54 : loss : 0.1766 = 0.0824 + 0.0907 + 0.0035, time: 8.228997]
2023-05-16 10:06:07.729: epoch 54:	0.02459131  	0.18015015  	0.09518514  
2023-05-16 10:06:07.729: Find a better model.
2023-05-16 10:06:15.984: [iter 55 : loss : 0.1746 = 0.0807 + 0.0904 + 0.0035, time: 8.249990]
2023-05-16 10:06:16.146: epoch 55:	0.02459131  	0.18037906  	0.09545229  
2023-05-16 10:06:16.146: Find a better model.
2023-05-16 10:06:25.726: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0036, time: 9.577300]
2023-05-16 10:06:26.010: epoch 56:	0.02458426  	0.18039855  	0.09548703  
2023-05-16 10:06:26.010: Find a better model.
2023-05-16 10:06:35.222: [iter 57 : loss : 0.1709 = 0.0772 + 0.0901 + 0.0036, time: 9.209991]
2023-05-16 10:06:35.503: epoch 57:	0.02471128  	0.18142153  	0.09600355  
2023-05-16 10:06:35.504: Find a better model.
2023-05-16 10:06:43.935: [iter 58 : loss : 0.1692 = 0.0756 + 0.0899 + 0.0037, time: 8.429993]
2023-05-16 10:06:44.108: epoch 58:	0.02478183  	0.18215194  	0.09644983  
2023-05-16 10:06:44.109: Find a better model.
2023-05-16 10:06:52.388: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 8.277992]
2023-05-16 10:06:52.550: epoch 59:	0.02487357  	0.18249442  	0.09699537  
2023-05-16 10:06:52.550: Find a better model.
2023-05-16 10:07:02.236: [iter 60 : loss : 0.1668 = 0.0735 + 0.0896 + 0.0037, time: 9.682497]
2023-05-16 10:07:02.519: epoch 60:	0.02495825  	0.18299982  	0.09728161  
2023-05-16 10:07:02.519: Find a better model.
2023-05-16 10:07:11.657: [iter 61 : loss : 0.1651 = 0.0719 + 0.0894 + 0.0038, time: 9.136334]
2023-05-16 10:07:11.944: epoch 61:	0.02502881  	0.18374875  	0.09781639  
2023-05-16 10:07:11.945: Find a better model.
2023-05-16 10:07:20.305: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 8.358963]
2023-05-16 10:07:20.466: epoch 62:	0.02507115  	0.18426825  	0.09804277  
2023-05-16 10:07:20.466: Find a better model.
2023-05-16 10:07:28.958: [iter 63 : loss : 0.1623 = 0.0693 + 0.0891 + 0.0039, time: 8.490992]
2023-05-16 10:07:29.122: epoch 63:	0.02509231  	0.18445335  	0.09836359  
2023-05-16 10:07:29.122: Find a better model.
2023-05-16 10:07:38.656: [iter 64 : loss : 0.1614 = 0.0686 + 0.0889 + 0.0039, time: 9.531201]
2023-05-16 10:07:38.941: epoch 64:	0.02510643  	0.18455508  	0.09869758  
2023-05-16 10:07:38.941: Find a better model.
2023-05-16 10:07:48.007: [iter 65 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0040, time: 9.062951]
2023-05-16 10:07:48.297: epoch 65:	0.02513465  	0.18480317  	0.09906382  
2023-05-16 10:07:48.297: Find a better model.
2023-05-16 10:07:56.724: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 8.424717]
2023-05-16 10:07:56.882: epoch 66:	0.02521227  	0.18561973  	0.09950911  
2023-05-16 10:07:56.882: Find a better model.
2023-05-16 10:08:05.258: [iter 67 : loss : 0.1569 = 0.0644 + 0.0885 + 0.0040, time: 8.374203]
2023-05-16 10:08:05.435: epoch 67:	0.02526166  	0.18604170  	0.09985889  
2023-05-16 10:08:05.435: Find a better model.
2023-05-16 10:08:14.863: [iter 68 : loss : 0.1569 = 0.0644 + 0.0883 + 0.0041, time: 9.425992]
2023-05-16 10:08:15.145: epoch 68:	0.02524050  	0.18587366  	0.10002085  
2023-05-16 10:08:24.352: [iter 69 : loss : 0.1546 = 0.0624 + 0.0881 + 0.0041, time: 9.200994]
2023-05-16 10:08:24.637: epoch 69:	0.02528284  	0.18629685  	0.10014416  
2023-05-16 10:08:24.638: Find a better model.
2023-05-16 10:08:32.957: [iter 70 : loss : 0.1531 = 0.0609 + 0.0881 + 0.0042, time: 8.317451]
2023-05-16 10:08:33.118: epoch 70:	0.02530400  	0.18599948  	0.10032904  
2023-05-16 10:08:41.412: [iter 71 : loss : 0.1514 = 0.0593 + 0.0879 + 0.0042, time: 8.292794]
2023-05-16 10:08:41.563: epoch 71:	0.02534634  	0.18618511  	0.10067679  
2023-05-16 10:08:50.124: [iter 72 : loss : 0.1515 = 0.0594 + 0.0878 + 0.0042, time: 8.560028]
2023-05-16 10:08:50.412: epoch 72:	0.02546630  	0.18707407  	0.10096853  
2023-05-16 10:08:50.412: Find a better model.
2023-05-16 10:08:59.567: [iter 73 : loss : 0.1502 = 0.0582 + 0.0877 + 0.0043, time: 9.151176]
2023-05-16 10:08:59.852: epoch 73:	0.02555098  	0.18754722  	0.10120232  
2023-05-16 10:08:59.853: Find a better model.
2023-05-16 10:09:08.320: [iter 74 : loss : 0.1487 = 0.0568 + 0.0876 + 0.0043, time: 8.466066]
2023-05-16 10:09:08.492: epoch 74:	0.02562154  	0.18816976  	0.10151921  
2023-05-16 10:09:08.492: Find a better model.
2023-05-16 10:09:17.104: [iter 75 : loss : 0.1482 = 0.0563 + 0.0875 + 0.0044, time: 8.610353]
2023-05-16 10:09:17.251: epoch 75:	0.02561448  	0.18818352  	0.10166364  
2023-05-16 10:09:17.251: Find a better model.
2023-05-16 10:09:25.315: [iter 76 : loss : 0.1470 = 0.0553 + 0.0873 + 0.0044, time: 8.055992]
2023-05-16 10:09:25.483: epoch 76:	0.02563565  	0.18855163  	0.10188965  
2023-05-16 10:09:25.483: Find a better model.
2023-05-16 10:09:34.743: [iter 77 : loss : 0.1460 = 0.0543 + 0.0872 + 0.0045, time: 9.257991]
2023-05-16 10:09:35.053: epoch 77:	0.02569211  	0.18877456  	0.10204340  
2023-05-16 10:09:35.053: Find a better model.
2023-05-16 10:09:43.127: [iter 78 : loss : 0.1452 = 0.0537 + 0.0871 + 0.0045, time: 8.072331]
2023-05-16 10:09:43.308: epoch 78:	0.02576972  	0.18947218  	0.10224102  
2023-05-16 10:09:43.308: Find a better model.
2023-05-16 10:09:51.047: [iter 79 : loss : 0.1439 = 0.0524 + 0.0870 + 0.0045, time: 7.736993]
2023-05-16 10:09:51.210: epoch 79:	0.02584029  	0.18963878  	0.10254524  
2023-05-16 10:09:51.210: Find a better model.
2023-05-16 10:09:59.446: [iter 80 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 8.234981]
2023-05-16 10:09:59.601: epoch 80:	0.02576267  	0.18925619  	0.10243684  
2023-05-16 10:10:08.831: [iter 81 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 9.227947]
2023-05-16 10:10:09.148: epoch 81:	0.02585441  	0.19008824  	0.10294530  
2023-05-16 10:10:09.148: Find a better model.
2023-05-16 10:10:16.728: [iter 82 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0047, time: 7.578137]
2023-05-16 10:10:16.891: epoch 82:	0.02586852  	0.19032751  	0.10300279  
2023-05-16 10:10:16.891: Find a better model.
2023-05-16 10:10:25.256: [iter 83 : loss : 0.1405 = 0.0492 + 0.0866 + 0.0047, time: 8.363992]
2023-05-16 10:10:25.427: epoch 83:	0.02593908  	0.19093283  	0.10348739  
2023-05-16 10:10:25.427: Find a better model.
2023-05-16 10:10:33.755: [iter 84 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 8.325996]
2023-05-16 10:10:33.987: epoch 84:	0.02605904  	0.19179899  	0.10358100  
2023-05-16 10:10:33.987: Find a better model.
2023-05-16 10:10:43.630: [iter 85 : loss : 0.1395 = 0.0483 + 0.0864 + 0.0048, time: 9.638513]
2023-05-16 10:10:43.928: epoch 85:	0.02608727  	0.19217020  	0.10394448  
2023-05-16 10:10:43.928: Find a better model.
2023-05-16 10:10:53.155: [iter 86 : loss : 0.1396 = 0.0486 + 0.0863 + 0.0048, time: 9.225026]
2023-05-16 10:10:53.404: epoch 86:	0.02607316  	0.19209594  	0.10399497  
2023-05-16 10:11:02.105: [iter 87 : loss : 0.1367 = 0.0457 + 0.0862 + 0.0048, time: 8.699574]
2023-05-16 10:11:02.273: epoch 87:	0.02616489  	0.19276693  	0.10433078  
2023-05-16 10:11:02.273: Find a better model.
2023-05-16 10:11:10.637: [iter 88 : loss : 0.1360 = 0.0450 + 0.0861 + 0.0049, time: 8.361992]
2023-05-16 10:11:10.810: epoch 88:	0.02615783  	0.19281942  	0.10456925  
2023-05-16 10:11:10.810: Find a better model.
2023-05-16 10:11:19.670: [iter 89 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 8.855252]
2023-05-16 10:11:19.964: epoch 89:	0.02621429  	0.19320667  	0.10470878  
2023-05-16 10:11:19.964: Find a better model.
2023-05-16 10:11:27.629: [iter 90 : loss : 0.1363 = 0.0454 + 0.0859 + 0.0050, time: 7.664181]
2023-05-16 10:11:27.813: epoch 90:	0.02625663  	0.19339904  	0.10503085  
2023-05-16 10:11:27.813: Find a better model.
2023-05-16 10:11:35.454: [iter 91 : loss : 0.1350 = 0.0443 + 0.0858 + 0.0050, time: 7.640322]
2023-05-16 10:11:35.605: epoch 91:	0.02630603  	0.19376425  	0.10515483  
2023-05-16 10:11:35.605: Find a better model.
2023-05-16 10:11:43.292: [iter 92 : loss : 0.1341 = 0.0433 + 0.0857 + 0.0050, time: 7.686050]
2023-05-16 10:11:43.436: epoch 92:	0.02631308  	0.19387402  	0.10533450  
2023-05-16 10:11:43.436: Find a better model.
2023-05-16 10:11:51.532: [iter 93 : loss : 0.1345 = 0.0438 + 0.0856 + 0.0051, time: 8.093387]
2023-05-16 10:11:51.730: epoch 93:	0.02632014  	0.19391032  	0.10554650  
2023-05-16 10:11:51.731: Find a better model.
2023-05-16 10:12:00.060: [iter 94 : loss : 0.1323 = 0.0416 + 0.0856 + 0.0051, time: 8.327734]
2023-05-16 10:12:00.209: epoch 94:	0.02629191  	0.19382483  	0.10547342  
2023-05-16 10:12:09.017: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 8.806096]
2023-05-16 10:12:09.200: epoch 95:	0.02632014  	0.19409840  	0.10565081  
2023-05-16 10:12:09.200: Find a better model.
2023-05-16 10:12:18.984: [iter 96 : loss : 0.1318 = 0.0412 + 0.0854 + 0.0052, time: 9.779979]
2023-05-16 10:12:19.260: epoch 96:	0.02627780  	0.19374932  	0.10557368  
2023-05-16 10:12:28.563: [iter 97 : loss : 0.1301 = 0.0396 + 0.0853 + 0.0052, time: 9.300766]
2023-05-16 10:12:28.818: epoch 97:	0.02628485  	0.19369036  	0.10565577  
2023-05-16 10:12:37.032: [iter 98 : loss : 0.1308 = 0.0403 + 0.0853 + 0.0052, time: 8.212015]
2023-05-16 10:12:37.191: epoch 98:	0.02634131  	0.19415368  	0.10584269  
2023-05-16 10:12:37.191: Find a better model.
2023-05-16 10:12:45.202: [iter 99 : loss : 0.1299 = 0.0394 + 0.0852 + 0.0053, time: 8.009257]
2023-05-16 10:12:45.360: epoch 99:	0.02639071  	0.19452074  	0.10599759  
2023-05-16 10:12:45.360: Find a better model.
2023-05-16 10:12:54.666: [iter 100 : loss : 0.1292 = 0.0387 + 0.0851 + 0.0053, time: 9.302199]
2023-05-16 10:12:54.962: epoch 100:	0.02642599  	0.19480415  	0.10627995  
2023-05-16 10:12:54.963: Find a better model.
2023-05-16 10:13:04.126: [iter 101 : loss : 0.1288 = 0.0383 + 0.0851 + 0.0054, time: 9.162031]
2023-05-16 10:13:04.421: epoch 101:	0.02635543  	0.19417603  	0.10617752  
2023-05-16 10:13:12.858: [iter 102 : loss : 0.1276 = 0.0372 + 0.0850 + 0.0054, time: 8.436004]
2023-05-16 10:13:13.016: epoch 102:	0.02640482  	0.19452356  	0.10633386  
2023-05-16 10:13:21.339: [iter 103 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 8.321001]
2023-05-16 10:13:21.519: epoch 103:	0.02646833  	0.19465211  	0.10666659  
2023-05-16 10:13:29.869: [iter 104 : loss : 0.1279 = 0.0376 + 0.0849 + 0.0055, time: 8.346611]
2023-05-16 10:13:30.161: epoch 104:	0.02658829  	0.19560507  	0.10695378  
2023-05-16 10:13:30.161: Find a better model.
2023-05-16 10:13:39.269: [iter 105 : loss : 0.1272 = 0.0369 + 0.0848 + 0.0055, time: 9.106043]
2023-05-16 10:13:39.566: epoch 105:	0.02653183  	0.19509405  	0.10694562  
2023-05-16 10:13:47.695: [iter 106 : loss : 0.1265 = 0.0362 + 0.0847 + 0.0055, time: 8.128009]
2023-05-16 10:13:47.854: epoch 106:	0.02651772  	0.19501233  	0.10695665  
2023-05-16 10:13:55.569: [iter 107 : loss : 0.1256 = 0.0354 + 0.0847 + 0.0056, time: 7.713361]
2023-05-16 10:13:55.731: epoch 107:	0.02648950  	0.19452529  	0.10676656  
2023-05-16 10:14:03.947: [iter 108 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 8.214012]
2023-05-16 10:14:04.102: epoch 108:	0.02645421  	0.19449687  	0.10693412  
2023-05-16 10:14:13.165: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 9.058028]
2023-05-16 10:14:13.455: epoch 109:	0.02646832  	0.19487576  	0.10684910  
2023-05-16 10:14:20.842: [iter 110 : loss : 0.1236 = 0.0334 + 0.0845 + 0.0057, time: 7.386128]
2023-05-16 10:14:20.995: epoch 110:	0.02647538  	0.19484979  	0.10685452  
2023-05-16 10:14:28.968: [iter 111 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 7.971870]
2023-05-16 10:14:29.111: epoch 111:	0.02641187  	0.19450109  	0.10684664  
2023-05-16 10:14:37.197: [iter 112 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 8.084009]
2023-05-16 10:14:37.361: epoch 112:	0.02637659  	0.19444031  	0.10690679  
2023-05-16 10:14:46.537: [iter 113 : loss : 0.1234 = 0.0333 + 0.0843 + 0.0058, time: 9.174114]
2023-05-16 10:14:46.837: epoch 113:	0.02646126  	0.19478583  	0.10717165  
2023-05-16 10:14:55.541: [iter 114 : loss : 0.1223 = 0.0322 + 0.0842 + 0.0058, time: 8.702030]
2023-05-16 10:14:55.738: epoch 114:	0.02646832  	0.19499773  	0.10717423  
2023-05-16 10:15:04.180: [iter 115 : loss : 0.1220 = 0.0320 + 0.0842 + 0.0058, time: 8.441003]
2023-05-16 10:15:04.336: epoch 115:	0.02650360  	0.19495775  	0.10730907  
2023-05-16 10:15:12.373: [iter 116 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 8.035006]
2023-05-16 10:15:12.531: epoch 116:	0.02649654  	0.19470702  	0.10732234  
2023-05-16 10:15:21.750: [iter 117 : loss : 0.1212 = 0.0312 + 0.0841 + 0.0059, time: 9.216395]
2023-05-16 10:15:22.048: epoch 117:	0.02644715  	0.19481525  	0.10722797  
2023-05-16 10:15:31.274: [iter 118 : loss : 0.1211 = 0.0311 + 0.0840 + 0.0059, time: 9.222039]
2023-05-16 10:15:31.562: epoch 118:	0.02644715  	0.19481526  	0.10727099  
2023-05-16 10:15:39.976: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 8.413033]
2023-05-16 10:15:40.141: epoch 119:	0.02646832  	0.19520320  	0.10732396  
2023-05-16 10:15:48.424: [iter 120 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0060, time: 8.282037]
2023-05-16 10:15:48.605: epoch 120:	0.02650360  	0.19524272  	0.10750111  
2023-05-16 10:15:57.372: [iter 121 : loss : 0.1202 = 0.0303 + 0.0838 + 0.0060, time: 8.761058]
2023-05-16 10:15:57.660: epoch 121:	0.02648948  	0.19496043  	0.10744163  
2023-05-16 10:16:06.755: [iter 122 : loss : 0.1193 = 0.0294 + 0.0838 + 0.0060, time: 9.089345]
2023-05-16 10:16:07.056: epoch 122:	0.02648243  	0.19492359  	0.10756397  
2023-05-16 10:16:15.323: [iter 123 : loss : 0.1194 = 0.0295 + 0.0837 + 0.0061, time: 8.265016]
2023-05-16 10:16:15.508: epoch 123:	0.02646831  	0.19488172  	0.10746651  
2023-05-16 10:16:23.327: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 7.817207]
2023-05-16 10:16:23.482: epoch 124:	0.02651771  	0.19510874  	0.10751672  
2023-05-16 10:16:31.541: [iter 125 : loss : 0.1178 = 0.0280 + 0.0837 + 0.0061, time: 8.055612]
2023-05-16 10:16:31.720: epoch 125:	0.02653182  	0.19536024  	0.10767850  
2023-05-16 10:16:40.791: [iter 126 : loss : 0.1180 = 0.0282 + 0.0836 + 0.0062, time: 9.066236]
2023-05-16 10:16:41.086: epoch 126:	0.02654593  	0.19521739  	0.10792574  
2023-05-16 10:16:49.378: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 8.291213]
2023-05-16 10:16:49.557: epoch 127:	0.02646832  	0.19491568  	0.10770825  
2023-05-16 10:16:57.328: [iter 128 : loss : 0.1179 = 0.0281 + 0.0835 + 0.0062, time: 7.770003]
2023-05-16 10:16:57.484: epoch 128:	0.02651066  	0.19517672  	0.10777966  
2023-05-16 10:17:05.684: [iter 129 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 8.199535]
2023-05-16 10:17:05.839: epoch 129:	0.02656005  	0.19556338  	0.10774165  
2023-05-16 10:17:05.839: Early stopping is trigger at epoch: 129
2023-05-16 10:17:05.839: best_result@epoch 104:

2023-05-16 10:17:05.839: 		0.0266      	0.1956      	0.1070      
2023-05-16 10:19:28.195: my pid: 14084
2023-05-16 10:19:28.195: model: model.general_recommender.SGL
2023-05-16 10:19:28.195: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 10:19:28.195: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 10:19:32.403: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 10:19:41.605: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.202322]
2023-05-16 10:19:41.773: epoch 1:	0.00153825  	0.01150909  	0.00535319  
2023-05-16 10:19:41.773: Find a better model.
2023-05-16 10:19:50.680: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.906440]
2023-05-16 10:19:50.910: epoch 2:	0.00264606  	0.01985535  	0.00954827  
2023-05-16 10:19:50.911: Find a better model.
2023-05-16 10:19:59.455: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.542042]
2023-05-16 10:19:59.640: epoch 3:	0.00508041  	0.03774312  	0.01771704  
2023-05-16 10:19:59.640: Find a better model.
2023-05-16 10:20:09.397: [iter 4 : loss : 0.7706 = 0.6920 + 0.0787 + 0.0000, time: 9.749056]
2023-05-16 10:20:09.705: epoch 4:	0.00817097  	0.06061530  	0.02898171  
2023-05-16 10:20:09.705: Find a better model.
2023-05-16 10:20:18.312: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 8.606003]
2023-05-16 10:20:18.485: epoch 5:	0.01196731  	0.08654277  	0.04159146  
2023-05-16 10:20:18.485: Find a better model.
2023-05-16 10:20:26.625: [iter 6 : loss : 0.7671 = 0.6878 + 0.0792 + 0.0000, time: 8.137021]
2023-05-16 10:20:26.789: epoch 6:	0.01540378  	0.11063903  	0.05453398  
2023-05-16 10:20:26.789: Find a better model.
2023-05-16 10:20:35.219: [iter 7 : loss : 0.7604 = 0.6803 + 0.0800 + 0.0000, time: 8.428048]
2023-05-16 10:20:35.391: epoch 7:	0.01808521  	0.13097700  	0.06493009  
2023-05-16 10:20:35.391: Find a better model.
2023-05-16 10:20:44.698: [iter 8 : loss : 0.7439 = 0.6618 + 0.0820 + 0.0001, time: 9.305029]
2023-05-16 10:20:45.000: epoch 8:	0.01928482  	0.14038235  	0.07008537  
2023-05-16 10:20:45.000: Find a better model.
2023-05-16 10:20:53.456: [iter 9 : loss : 0.7070 = 0.6209 + 0.0860 + 0.0001, time: 8.455014]
2023-05-16 10:20:53.625: epoch 9:	0.01899551  	0.14030920  	0.07012942  
2023-05-16 10:21:01.436: [iter 10 : loss : 0.6445 = 0.5527 + 0.0915 + 0.0003, time: 7.810011]
2023-05-16 10:21:01.598: epoch 10:	0.01858623  	0.13726777  	0.06862034  
2023-05-16 10:21:09.634: [iter 11 : loss : 0.5686 = 0.4718 + 0.0964 + 0.0004, time: 8.034014]
2023-05-16 10:21:09.797: epoch 11:	0.01869914  	0.13819031  	0.06884494  
2023-05-16 10:21:18.858: [iter 12 : loss : 0.5008 = 0.4006 + 0.0996 + 0.0006, time: 9.059001]
2023-05-16 10:21:19.157: epoch 12:	0.01850861  	0.13678889  	0.06878385  
2023-05-16 10:21:26.536: [iter 13 : loss : 0.4511 = 0.3490 + 0.1014 + 0.0007, time: 7.377997]
2023-05-16 10:21:26.697: epoch 13:	0.01860740  	0.13757615  	0.06898793  
2023-05-16 10:21:34.804: [iter 14 : loss : 0.4135 = 0.3103 + 0.1023 + 0.0009, time: 8.105472]
2023-05-16 10:21:34.950: epoch 14:	0.01888967  	0.13932811  	0.07003061  
2023-05-16 10:21:43.100: [iter 15 : loss : 0.3871 = 0.2835 + 0.1026 + 0.0010, time: 8.148012]
2023-05-16 10:21:43.265: epoch 15:	0.01893200  	0.14008819  	0.07059569  
2023-05-16 10:21:52.314: [iter 16 : loss : 0.3650 = 0.2614 + 0.1025 + 0.0011, time: 9.047020]
2023-05-16 10:21:52.613: epoch 16:	0.01908019  	0.14103960  	0.07143188  
2023-05-16 10:21:52.613: Find a better model.
2023-05-16 10:22:01.846: [iter 17 : loss : 0.3488 = 0.2452 + 0.1024 + 0.0012, time: 9.225044]
2023-05-16 10:22:02.136: epoch 17:	0.01932717  	0.14315151  	0.07239703  
2023-05-16 10:22:02.136: Find a better model.
2023-05-16 10:22:10.211: [iter 18 : loss : 0.3335 = 0.2301 + 0.1021 + 0.0013, time: 8.072996]
2023-05-16 10:22:10.390: epoch 18:	0.01951065  	0.14459299  	0.07316074  
2023-05-16 10:22:10.390: Find a better model.
2023-05-16 10:22:18.696: [iter 19 : loss : 0.3194 = 0.2162 + 0.1018 + 0.0014, time: 8.305071]
2023-05-16 10:22:18.857: epoch 19:	0.01971529  	0.14596926  	0.07391544  
2023-05-16 10:22:18.857: Find a better model.
2023-05-16 10:22:27.984: [iter 20 : loss : 0.3099 = 0.2071 + 0.1014 + 0.0015, time: 9.126494]
2023-05-16 10:22:28.281: epoch 20:	0.01989171  	0.14697377  	0.07479025  
2023-05-16 10:22:28.281: Find a better model.
2023-05-16 10:22:37.422: [iter 21 : loss : 0.3003 = 0.1978 + 0.1010 + 0.0016, time: 9.137341]
2023-05-16 10:22:37.721: epoch 21:	0.02008223  	0.14823759  	0.07535561  
2023-05-16 10:22:37.721: Find a better model.
2023-05-16 10:22:45.955: [iter 22 : loss : 0.2919 = 0.1897 + 0.1006 + 0.0017, time: 8.230996]
2023-05-16 10:22:46.129: epoch 22:	0.02027981  	0.14945002  	0.07588626  
2023-05-16 10:22:46.129: Find a better model.
2023-05-16 10:22:54.025: [iter 23 : loss : 0.2838 = 0.1819 + 0.1001 + 0.0017, time: 7.894198]
2023-05-16 10:22:54.184: epoch 23:	0.02054089  	0.15116958  	0.07678205  
2023-05-16 10:22:54.184: Find a better model.
2023-05-16 10:23:02.175: [iter 24 : loss : 0.2773 = 0.1758 + 0.0997 + 0.0018, time: 7.990013]
2023-05-16 10:23:02.338: epoch 24:	0.02073847  	0.15256856  	0.07759245  
2023-05-16 10:23:02.338: Find a better model.
2023-05-16 10:23:11.468: [iter 25 : loss : 0.2707 = 0.1696 + 0.0993 + 0.0019, time: 9.126024]
2023-05-16 10:23:11.774: epoch 25:	0.02096428  	0.15381338  	0.07842650  
2023-05-16 10:23:11.774: Find a better model.
2023-05-16 10:23:20.041: [iter 26 : loss : 0.2672 = 0.1664 + 0.0989 + 0.0019, time: 8.266048]
2023-05-16 10:23:20.201: epoch 26:	0.02116186  	0.15556343  	0.07904311  
2023-05-16 10:23:20.201: Find a better model.
2023-05-16 10:23:27.985: [iter 27 : loss : 0.2593 = 0.1589 + 0.0984 + 0.0020, time: 7.781940]
2023-05-16 10:23:28.148: epoch 27:	0.02135239  	0.15664686  	0.08001290  
2023-05-16 10:23:28.148: Find a better model.
2023-05-16 10:23:36.348: [iter 28 : loss : 0.2543 = 0.1542 + 0.0980 + 0.0021, time: 8.198784]
2023-05-16 10:23:36.507: epoch 28:	0.02159232  	0.15858398  	0.08101299  
2023-05-16 10:23:36.508: Find a better model.
2023-05-16 10:23:45.665: [iter 29 : loss : 0.2500 = 0.1502 + 0.0976 + 0.0021, time: 9.151044]
2023-05-16 10:23:45.934: epoch 29:	0.02170522  	0.15964071  	0.08160793  
2023-05-16 10:23:45.934: Find a better model.
2023-05-16 10:23:53.422: [iter 30 : loss : 0.2437 = 0.1442 + 0.0973 + 0.0022, time: 7.487601]
2023-05-16 10:23:53.585: epoch 30:	0.02195220  	0.16158693  	0.08228212  
2023-05-16 10:23:53.585: Find a better model.
2023-05-16 10:24:01.755: [iter 31 : loss : 0.2399 = 0.1408 + 0.0968 + 0.0023, time: 8.169019]
2023-05-16 10:24:01.907: epoch 31:	0.02210038  	0.16295666  	0.08331046  
2023-05-16 10:24:01.908: Find a better model.
2023-05-16 10:24:10.016: [iter 32 : loss : 0.2342 = 0.1353 + 0.0965 + 0.0023, time: 8.107000]
2023-05-16 10:24:10.187: epoch 32:	0.02219917  	0.16347018  	0.08374934  
2023-05-16 10:24:10.187: Find a better model.
2023-05-16 10:24:19.416: [iter 33 : loss : 0.2320 = 0.1335 + 0.0962 + 0.0024, time: 9.225024]
2023-05-16 10:24:19.716: epoch 33:	0.02230502  	0.16421871  	0.08420511  
2023-05-16 10:24:19.716: Find a better model.
2023-05-16 10:24:28.767: [iter 34 : loss : 0.2278 = 0.1295 + 0.0958 + 0.0024, time: 9.049002]
2023-05-16 10:24:29.067: epoch 34:	0.02246732  	0.16542031  	0.08509774  
2023-05-16 10:24:29.067: Find a better model.
2023-05-16 10:24:37.207: [iter 35 : loss : 0.2243 = 0.1262 + 0.0955 + 0.0025, time: 8.138996]
2023-05-16 10:24:37.368: epoch 35:	0.02253788  	0.16608039  	0.08568347  
2023-05-16 10:24:37.368: Find a better model.
2023-05-16 10:24:45.470: [iter 36 : loss : 0.2209 = 0.1232 + 0.0951 + 0.0025, time: 8.101013]
2023-05-16 10:24:45.655: epoch 36:	0.02270018  	0.16702384  	0.08626072  
2023-05-16 10:24:45.655: Find a better model.
2023-05-16 10:24:54.350: [iter 37 : loss : 0.2168 = 0.1194 + 0.0949 + 0.0026, time: 8.691046]
2023-05-16 10:24:54.653: epoch 37:	0.02274252  	0.16753352  	0.08659543  
2023-05-16 10:24:54.653: Find a better model.
2023-05-16 10:25:03.606: [iter 38 : loss : 0.2152 = 0.1180 + 0.0946 + 0.0027, time: 8.949031]
2023-05-16 10:25:03.909: epoch 38:	0.02286953  	0.16825712  	0.08719020  
2023-05-16 10:25:03.909: Find a better model.
2023-05-16 10:25:11.889: [iter 39 : loss : 0.2108 = 0.1139 + 0.0942 + 0.0027, time: 7.978993]
2023-05-16 10:25:12.049: epoch 39:	0.02302478  	0.16959113  	0.08813147  
2023-05-16 10:25:12.050: Find a better model.
2023-05-16 10:25:19.762: [iter 40 : loss : 0.2074 = 0.1107 + 0.0940 + 0.0028, time: 7.711206]
2023-05-16 10:25:19.925: epoch 40:	0.02315885  	0.17055346  	0.08862399  
2023-05-16 10:25:19.925: Find a better model.
2023-05-16 10:25:27.954: [iter 41 : loss : 0.2059 = 0.1094 + 0.0937 + 0.0028, time: 8.028039]
2023-05-16 10:25:28.112: epoch 41:	0.02332821  	0.17222899  	0.08947472  
2023-05-16 10:25:28.113: Find a better model.
2023-05-16 10:25:37.014: [iter 42 : loss : 0.2036 = 0.1074 + 0.0934 + 0.0029, time: 8.898798]
2023-05-16 10:25:37.310: epoch 42:	0.02337054  	0.17266385  	0.08994823  
2023-05-16 10:25:37.310: Find a better model.
2023-05-16 10:25:44.601: [iter 43 : loss : 0.1996 = 0.1036 + 0.0931 + 0.0029, time: 7.289013]
2023-05-16 10:25:44.770: epoch 43:	0.02351872  	0.17370878  	0.09057804  
2023-05-16 10:25:44.770: Find a better model.
2023-05-16 10:25:52.949: [iter 44 : loss : 0.1967 = 0.1009 + 0.0928 + 0.0030, time: 8.178042]
2023-05-16 10:25:53.106: epoch 44:	0.02364575  	0.17475407  	0.09126047  
2023-05-16 10:25:53.106: Find a better model.
2023-05-16 10:26:01.193: [iter 45 : loss : 0.1943 = 0.0986 + 0.0926 + 0.0030, time: 8.086173]
2023-05-16 10:26:01.361: epoch 45:	0.02375865  	0.17545226  	0.09186501  
2023-05-16 10:26:01.361: Find a better model.
2023-05-16 10:26:10.320: [iter 46 : loss : 0.1917 = 0.0963 + 0.0923 + 0.0031, time: 8.950521]
2023-05-16 10:26:10.609: epoch 46:	0.02383627  	0.17628121  	0.09236135  
2023-05-16 10:26:10.609: Find a better model.
2023-05-16 10:26:19.687: [iter 47 : loss : 0.1913 = 0.0960 + 0.0921 + 0.0031, time: 9.074065]
2023-05-16 10:26:19.955: epoch 47:	0.02392801  	0.17672502  	0.09277073  
2023-05-16 10:26:19.955: Find a better model.
2023-05-16 10:26:28.284: [iter 48 : loss : 0.1872 = 0.0921 + 0.0919 + 0.0032, time: 8.328545]
2023-05-16 10:26:28.447: epoch 48:	0.02392801  	0.17658557  	0.09303986  
2023-05-16 10:26:36.426: [iter 49 : loss : 0.1842 = 0.0892 + 0.0917 + 0.0032, time: 7.976000]
2023-05-16 10:26:36.588: epoch 49:	0.02401974  	0.17714128  	0.09368071  
2023-05-16 10:26:36.588: Find a better model.
2023-05-16 10:26:44.229: [iter 50 : loss : 0.1833 = 0.0886 + 0.0914 + 0.0033, time: 7.637105]
2023-05-16 10:26:44.527: epoch 50:	0.02408325  	0.17780608  	0.09407365  
2023-05-16 10:26:44.527: Find a better model.
2023-05-16 10:26:53.473: [iter 51 : loss : 0.1804 = 0.0858 + 0.0912 + 0.0033, time: 8.942015]
2023-05-16 10:26:53.776: epoch 51:	0.02409030  	0.17837429  	0.09443801  
2023-05-16 10:26:53.776: Find a better model.
2023-05-16 10:27:01.906: [iter 52 : loss : 0.1803 = 0.0859 + 0.0911 + 0.0034, time: 8.128867]
2023-05-16 10:27:02.056: epoch 52:	0.02425965  	0.17973901  	0.09497969  
2023-05-16 10:27:02.056: Find a better model.
2023-05-16 10:27:09.723: [iter 53 : loss : 0.1783 = 0.0840 + 0.0909 + 0.0034, time: 7.665010]
2023-05-16 10:27:09.891: epoch 53:	0.02436550  	0.17998391  	0.09533782  
2023-05-16 10:27:09.891: Find a better model.
2023-05-16 10:27:18.088: [iter 54 : loss : 0.1762 = 0.0821 + 0.0906 + 0.0035, time: 8.195457]
2023-05-16 10:27:18.247: epoch 54:	0.02442901  	0.18057834  	0.09572399  
2023-05-16 10:27:18.247: Find a better model.
2023-05-16 10:27:27.414: [iter 55 : loss : 0.1743 = 0.0804 + 0.0904 + 0.0035, time: 9.165039]
2023-05-16 10:27:27.694: epoch 55:	0.02445018  	0.18043464  	0.09587794  
2023-05-16 10:27:35.037: [iter 56 : loss : 0.1723 = 0.0786 + 0.0902 + 0.0035, time: 7.342471]
2023-05-16 10:27:35.199: epoch 56:	0.02451368  	0.18119808  	0.09642946  
2023-05-16 10:27:35.199: Find a better model.
2023-05-16 10:27:43.518: [iter 57 : loss : 0.1708 = 0.0771 + 0.0901 + 0.0036, time: 8.316468]
2023-05-16 10:27:43.676: epoch 57:	0.02471127  	0.18247202  	0.09698590  
2023-05-16 10:27:43.677: Find a better model.
2023-05-16 10:27:51.948: [iter 58 : loss : 0.1688 = 0.0753 + 0.0899 + 0.0036, time: 8.270179]
2023-05-16 10:27:52.121: epoch 58:	0.02464071  	0.18202108  	0.09716940  
2023-05-16 10:28:01.245: [iter 59 : loss : 0.1678 = 0.0744 + 0.0897 + 0.0037, time: 9.121197]
2023-05-16 10:28:01.540: epoch 59:	0.02473949  	0.18269537  	0.09750569  
2023-05-16 10:28:01.541: Find a better model.
2023-05-16 10:28:10.679: [iter 60 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 9.137021]
2023-05-16 10:28:10.979: epoch 60:	0.02476772  	0.18288927  	0.09775067  
2023-05-16 10:28:10.979: Find a better model.
2023-05-16 10:28:19.281: [iter 61 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 8.299992]
2023-05-16 10:28:19.459: epoch 61:	0.02476066  	0.18313707  	0.09794196  
2023-05-16 10:28:19.459: Find a better model.
2023-05-16 10:28:27.923: [iter 62 : loss : 0.1634 = 0.0704 + 0.0892 + 0.0038, time: 8.462028]
2023-05-16 10:28:28.085: epoch 62:	0.02484534  	0.18376824  	0.09828060  
2023-05-16 10:28:28.085: Find a better model.
2023-05-16 10:28:37.429: [iter 63 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 9.340035]
2023-05-16 10:28:37.731: epoch 63:	0.02488768  	0.18346915  	0.09838255  
2023-05-16 10:28:46.857: [iter 64 : loss : 0.1611 = 0.0683 + 0.0889 + 0.0039, time: 9.123006]
2023-05-16 10:28:47.152: epoch 64:	0.02493002  	0.18393351  	0.09889553  
2023-05-16 10:28:47.152: Find a better model.
2023-05-16 10:28:55.480: [iter 65 : loss : 0.1598 = 0.0671 + 0.0887 + 0.0039, time: 8.325992]
2023-05-16 10:28:55.651: epoch 65:	0.02499352  	0.18407810  	0.09916350  
2023-05-16 10:28:55.651: Find a better model.
2023-05-16 10:29:03.453: [iter 66 : loss : 0.1581 = 0.0655 + 0.0886 + 0.0040, time: 7.800001]
2023-05-16 10:29:03.607: epoch 66:	0.02502881  	0.18467157  	0.09965815  
2023-05-16 10:29:03.607: Find a better model.
2023-05-16 10:29:11.495: [iter 67 : loss : 0.1566 = 0.0641 + 0.0884 + 0.0040, time: 7.886346]
2023-05-16 10:29:11.656: epoch 67:	0.02518405  	0.18589924  	0.10013723  
2023-05-16 10:29:11.656: Find a better model.
2023-05-16 10:29:20.772: [iter 68 : loss : 0.1561 = 0.0637 + 0.0883 + 0.0041, time: 9.110162]
2023-05-16 10:29:21.076: epoch 68:	0.02518405  	0.18563613  	0.10029184  
2023-05-16 10:29:29.302: [iter 69 : loss : 0.1544 = 0.0621 + 0.0882 + 0.0041, time: 8.224014]
2023-05-16 10:29:29.468: epoch 69:	0.02521933  	0.18594557  	0.10051232  
2023-05-16 10:29:29.468: Find a better model.
2023-05-16 10:29:37.249: [iter 70 : loss : 0.1529 = 0.0607 + 0.0881 + 0.0042, time: 7.779109]
2023-05-16 10:29:37.414: epoch 70:	0.02528990  	0.18641347  	0.10071544  
2023-05-16 10:29:37.414: Find a better model.
2023-05-16 10:29:45.659: [iter 71 : loss : 0.1510 = 0.0589 + 0.0879 + 0.0042, time: 8.244002]
2023-05-16 10:29:45.822: epoch 71:	0.02534635  	0.18685639  	0.10103522  
2023-05-16 10:29:45.822: Find a better model.
2023-05-16 10:29:54.780: [iter 72 : loss : 0.1511 = 0.0591 + 0.0878 + 0.0042, time: 8.956051]
2023-05-16 10:29:55.077: epoch 72:	0.02536752  	0.18715973  	0.10139547  
2023-05-16 10:29:55.078: Find a better model.
2023-05-16 10:30:02.564: [iter 73 : loss : 0.1494 = 0.0574 + 0.0877 + 0.0043, time: 7.484020]
2023-05-16 10:30:02.730: epoch 73:	0.02535341  	0.18694444  	0.10141356  
2023-05-16 10:30:11.048: [iter 74 : loss : 0.1483 = 0.0564 + 0.0875 + 0.0043, time: 8.316209]
2023-05-16 10:30:11.205: epoch 74:	0.02545219  	0.18750265  	0.10178762  
2023-05-16 10:30:11.205: Find a better model.
2023-05-16 10:30:19.232: [iter 75 : loss : 0.1479 = 0.0561 + 0.0874 + 0.0044, time: 8.026002]
2023-05-16 10:30:19.396: epoch 75:	0.02548042  	0.18770917  	0.10212107  
2023-05-16 10:30:19.396: Find a better model.
2023-05-16 10:30:28.630: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 9.233387]
2023-05-16 10:30:28.928: epoch 76:	0.02556510  	0.18826984  	0.10247561  
2023-05-16 10:30:28.928: Find a better model.
2023-05-16 10:30:38.121: [iter 77 : loss : 0.1459 = 0.0543 + 0.0872 + 0.0044, time: 9.189006]
2023-05-16 10:30:38.390: epoch 77:	0.02558627  	0.18841913  	0.10258549  
2023-05-16 10:30:38.390: Find a better model.
2023-05-16 10:30:46.668: [iter 78 : loss : 0.1448 = 0.0532 + 0.0871 + 0.0045, time: 8.275332]
2023-05-16 10:30:46.869: epoch 78:	0.02564978  	0.18898235  	0.10293009  
2023-05-16 10:30:46.869: Find a better model.
2023-05-16 10:30:55.075: [iter 79 : loss : 0.1436 = 0.0521 + 0.0870 + 0.0045, time: 8.203363]
2023-05-16 10:30:55.296: epoch 79:	0.02567800  	0.18879697  	0.10301579  
2023-05-16 10:31:03.114: [iter 80 : loss : 0.1427 = 0.0513 + 0.0869 + 0.0046, time: 7.817008]
2023-05-16 10:31:03.413: epoch 80:	0.02577679  	0.18964460  	0.10328052  
2023-05-16 10:31:03.413: Find a better model.
2023-05-16 10:31:12.632: [iter 81 : loss : 0.1426 = 0.0512 + 0.0868 + 0.0046, time: 9.212024]
2023-05-16 10:31:12.931: epoch 81:	0.02569211  	0.18914565  	0.10338007  
2023-05-16 10:31:21.294: [iter 82 : loss : 0.1413 = 0.0500 + 0.0866 + 0.0046, time: 8.360992]
2023-05-16 10:31:21.457: epoch 82:	0.02577679  	0.18965247  	0.10384527  
2023-05-16 10:31:21.457: Find a better model.
2023-05-16 10:31:29.228: [iter 83 : loss : 0.1403 = 0.0491 + 0.0866 + 0.0047, time: 7.770008]
2023-05-16 10:31:29.388: epoch 83:	0.02586147  	0.19019011  	0.10436732  
2023-05-16 10:31:29.388: Find a better model.
2023-05-16 10:31:37.413: [iter 84 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 8.023213]
2023-05-16 10:31:37.571: epoch 84:	0.02584030  	0.19011529  	0.10449911  
2023-05-16 10:31:46.577: [iter 85 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 9.003033]
2023-05-16 10:31:46.874: epoch 85:	0.02589675  	0.19034281  	0.10465495  
2023-05-16 10:31:46.874: Find a better model.
2023-05-16 10:31:54.445: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 7.569128]
2023-05-16 10:31:54.609: epoch 86:	0.02593203  	0.19088459  	0.10479787  
2023-05-16 10:31:54.609: Find a better model.
2023-05-16 10:32:02.807: [iter 87 : loss : 0.1364 = 0.0454 + 0.0862 + 0.0048, time: 8.196008]
2023-05-16 10:32:02.954: epoch 87:	0.02593909  	0.19114575  	0.10518728  
2023-05-16 10:32:02.955: Find a better model.
2023-05-16 10:32:11.261: [iter 88 : loss : 0.1357 = 0.0448 + 0.0861 + 0.0049, time: 8.304191]
2023-05-16 10:32:11.444: epoch 88:	0.02589675  	0.19086379  	0.10516165  
2023-05-16 10:32:20.502: [iter 89 : loss : 0.1354 = 0.0445 + 0.0860 + 0.0049, time: 9.055024]
2023-05-16 10:32:20.774: epoch 89:	0.02597437  	0.19143561  	0.10545852  
2023-05-16 10:32:20.774: Find a better model.
2023-05-16 10:32:29.998: [iter 90 : loss : 0.1360 = 0.0451 + 0.0859 + 0.0049, time: 9.222012]
2023-05-16 10:32:30.301: epoch 90:	0.02605199  	0.19197540  	0.10562872  
2023-05-16 10:32:30.302: Find a better model.
2023-05-16 10:32:38.393: [iter 91 : loss : 0.1346 = 0.0438 + 0.0858 + 0.0050, time: 8.090436]
2023-05-16 10:32:38.552: epoch 91:	0.02604493  	0.19151241  	0.10556313  
2023-05-16 10:32:46.870: [iter 92 : loss : 0.1337 = 0.0430 + 0.0857 + 0.0050, time: 8.315632]
2023-05-16 10:32:47.048: epoch 92:	0.02604493  	0.19164227  	0.10568156  
2023-05-16 10:32:55.702: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 8.652021]
2023-05-16 10:32:56.001: epoch 93:	0.02614372  	0.19212411  	0.10599937  
2023-05-16 10:32:56.001: Find a better model.
2023-05-16 10:33:05.090: [iter 94 : loss : 0.1318 = 0.0411 + 0.0856 + 0.0051, time: 9.087023]
2023-05-16 10:33:05.388: epoch 94:	0.02613666  	0.19216664  	0.10605321  
2023-05-16 10:33:05.388: Find a better model.
2023-05-16 10:33:13.354: [iter 95 : loss : 0.1313 = 0.0406 + 0.0855 + 0.0051, time: 7.963995]
2023-05-16 10:33:13.517: epoch 95:	0.02612961  	0.19201815  	0.10623186  
2023-05-16 10:33:21.152: [iter 96 : loss : 0.1316 = 0.0411 + 0.0854 + 0.0052, time: 7.634002]
2023-05-16 10:33:21.314: epoch 96:	0.02612255  	0.19169080  	0.10628234  
2023-05-16 10:33:29.381: [iter 97 : loss : 0.1297 = 0.0392 + 0.0853 + 0.0052, time: 8.065481]
2023-05-16 10:33:29.539: epoch 97:	0.02617900  	0.19225551  	0.10662774  
2023-05-16 10:33:29.539: Find a better model.
2023-05-16 10:33:38.534: [iter 98 : loss : 0.1306 = 0.0401 + 0.0853 + 0.0052, time: 8.994040]
2023-05-16 10:33:38.829: epoch 98:	0.02622839  	0.19247299  	0.10666519  
2023-05-16 10:33:38.829: Find a better model.
2023-05-16 10:33:46.198: [iter 99 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0053, time: 7.367638]
2023-05-16 10:33:46.362: epoch 99:	0.02630601  	0.19338500  	0.10715086  
2023-05-16 10:33:46.362: Find a better model.
2023-05-16 10:33:54.579: [iter 100 : loss : 0.1289 = 0.0384 + 0.0851 + 0.0053, time: 8.216131]
2023-05-16 10:33:54.740: epoch 100:	0.02629896  	0.19316162  	0.10707328  
2023-05-16 10:34:02.977: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0053, time: 8.235002]
2023-05-16 10:34:03.156: epoch 101:	0.02631307  	0.19336291  	0.10731261  
2023-05-16 10:34:12.340: [iter 102 : loss : 0.1274 = 0.0370 + 0.0850 + 0.0054, time: 9.182523]
2023-05-16 10:34:12.639: epoch 102:	0.02635541  	0.19353330  	0.10724019  
2023-05-16 10:34:12.639: Find a better model.
2023-05-16 10:34:21.728: [iter 103 : loss : 0.1271 = 0.0367 + 0.0849 + 0.0054, time: 9.083025]
2023-05-16 10:34:21.994: epoch 103:	0.02639775  	0.19361369  	0.10729726  
2023-05-16 10:34:21.994: Find a better model.
2023-05-16 10:34:30.334: [iter 104 : loss : 0.1277 = 0.0374 + 0.0848 + 0.0055, time: 8.338079]
2023-05-16 10:34:30.505: epoch 104:	0.02638363  	0.19395275  	0.10746518  
2023-05-16 10:34:30.505: Find a better model.
2023-05-16 10:34:38.350: [iter 105 : loss : 0.1267 = 0.0365 + 0.0847 + 0.0055, time: 7.843993]
2023-05-16 10:34:38.815: epoch 105:	0.02648242  	0.19459201  	0.10783086  
2023-05-16 10:34:38.816: Find a better model.
2023-05-16 10:34:46.332: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 7.502434]
2023-05-16 10:34:46.495: epoch 106:	0.02652476  	0.19508775  	0.10788796  
2023-05-16 10:34:46.495: Find a better model.
2023-05-16 10:34:55.697: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0055, time: 9.199092]
2023-05-16 10:34:55.986: epoch 107:	0.02656710  	0.19514440  	0.10803784  
2023-05-16 10:34:55.986: Find a better model.
2023-05-16 10:35:04.154: [iter 108 : loss : 0.1252 = 0.0350 + 0.0846 + 0.0056, time: 8.166047]
2023-05-16 10:35:04.307: epoch 108:	0.02656005  	0.19524351  	0.10809442  
2023-05-16 10:35:04.307: Find a better model.
2023-05-16 10:35:11.983: [iter 109 : loss : 0.1240 = 0.0339 + 0.0845 + 0.0056, time: 7.674386]
2023-05-16 10:35:12.148: epoch 109:	0.02655298  	0.19488712  	0.10800986  
2023-05-16 10:35:20.537: [iter 110 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 8.387511]
2023-05-16 10:35:20.694: epoch 110:	0.02658121  	0.19493890  	0.10807263  
2023-05-16 10:35:29.749: [iter 111 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 9.053434]
2023-05-16 10:35:30.046: epoch 111:	0.02664472  	0.19530310  	0.10840088  
2023-05-16 10:35:30.046: Find a better model.
2023-05-16 10:35:37.569: [iter 112 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0057, time: 7.521938]
2023-05-16 10:35:37.738: epoch 112:	0.02670117  	0.19584236  	0.10849241  
2023-05-16 10:35:37.738: Find a better model.
2023-05-16 10:35:46.030: [iter 113 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0058, time: 8.282993]
2023-05-16 10:35:46.188: epoch 113:	0.02672940  	0.19608435  	0.10868976  
2023-05-16 10:35:46.189: Find a better model.
2023-05-16 10:35:54.303: [iter 114 : loss : 0.1220 = 0.0320 + 0.0842 + 0.0058, time: 8.112778]
2023-05-16 10:35:54.466: epoch 114:	0.02679290  	0.19656020  	0.10888809  
2023-05-16 10:35:54.466: Find a better model.
2023-05-16 10:36:03.661: [iter 115 : loss : 0.1217 = 0.0317 + 0.0842 + 0.0058, time: 9.193011]
2023-05-16 10:36:03.974: epoch 115:	0.02672234  	0.19624655  	0.10873878  
2023-05-16 10:36:13.111: [iter 116 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0058, time: 9.128278]
2023-05-16 10:36:13.402: epoch 116:	0.02671529  	0.19605955  	0.10875950  
2023-05-16 10:36:21.548: [iter 117 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.143996]
2023-05-16 10:36:21.727: epoch 117:	0.02675763  	0.19637415  	0.10897721  
2023-05-16 10:36:29.330: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 7.600013]
2023-05-16 10:36:29.485: epoch 118:	0.02681408  	0.19691831  	0.10935136  
2023-05-16 10:36:29.486: Find a better model.
2023-05-16 10:36:37.508: [iter 119 : loss : 0.1198 = 0.0299 + 0.0840 + 0.0059, time: 8.021003]
2023-05-16 10:36:37.667: epoch 119:	0.02684231  	0.19716394  	0.10926104  
2023-05-16 10:36:37.667: Find a better model.
2023-05-16 10:36:46.672: [iter 120 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 9.002028]
2023-05-16 10:36:46.969: epoch 120:	0.02678585  	0.19677025  	0.10933898  
2023-05-16 10:36:54.473: [iter 121 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0060, time: 7.501993]
2023-05-16 10:36:54.631: epoch 121:	0.02678585  	0.19666556  	0.10920872  
2023-05-16 10:37:02.493: [iter 122 : loss : 0.1191 = 0.0292 + 0.0838 + 0.0060, time: 7.861402]
2023-05-16 10:37:02.653: epoch 122:	0.02687759  	0.19749078  	0.10955561  
2023-05-16 10:37:02.653: Find a better model.
2023-05-16 10:37:10.713: [iter 123 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 8.058088]
2023-05-16 10:37:10.875: epoch 123:	0.02677879  	0.19692890  	0.10933533  
2023-05-16 10:37:20.088: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 9.209023]
2023-05-16 10:37:20.385: epoch 124:	0.02680702  	0.19708581  	0.10958272  
2023-05-16 10:37:29.387: [iter 125 : loss : 0.1174 = 0.0276 + 0.0837 + 0.0061, time: 8.993013]
2023-05-16 10:37:29.685: epoch 125:	0.02686347  	0.19732004  	0.10966700  
2023-05-16 10:37:37.697: [iter 126 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0062, time: 8.009998]
2023-05-16 10:37:37.893: epoch 126:	0.02689875  	0.19746158  	0.10975477  
2023-05-16 10:37:45.507: [iter 127 : loss : 0.1168 = 0.0270 + 0.0836 + 0.0062, time: 7.611993]
2023-05-16 10:37:45.666: epoch 127:	0.02694815  	0.19774158  	0.10992185  
2023-05-16 10:37:45.666: Find a better model.
2023-05-16 10:37:53.449: [iter 128 : loss : 0.1178 = 0.0280 + 0.0835 + 0.0062, time: 7.781018]
2023-05-16 10:37:53.610: epoch 128:	0.02694109  	0.19780707  	0.10985719  
2023-05-16 10:37:53.610: Find a better model.
2023-05-16 10:38:02.563: [iter 129 : loss : 0.1168 = 0.0271 + 0.0835 + 0.0063, time: 8.951013]
2023-05-16 10:38:02.863: epoch 129:	0.02696227  	0.19789448  	0.11012846  
2023-05-16 10:38:02.863: Find a better model.
2023-05-16 10:38:10.195: [iter 130 : loss : 0.1169 = 0.0273 + 0.0834 + 0.0063, time: 7.330023]
2023-05-16 10:38:10.360: epoch 130:	0.02698344  	0.19818608  	0.11035116  
2023-05-16 10:38:10.360: Find a better model.
2023-05-16 10:38:18.544: [iter 131 : loss : 0.1161 = 0.0264 + 0.0834 + 0.0063, time: 8.182007]
2023-05-16 10:38:18.701: epoch 131:	0.02695521  	0.19764994  	0.11013283  
2023-05-16 10:38:26.650: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 7.946002]
2023-05-16 10:38:26.812: epoch 132:	0.02688465  	0.19746234  	0.11008377  
2023-05-16 10:38:35.945: [iter 133 : loss : 0.1151 = 0.0254 + 0.0833 + 0.0064, time: 9.129600]
2023-05-16 10:38:36.244: epoch 133:	0.02689170  	0.19745709  	0.11006095  
2023-05-16 10:38:45.252: [iter 134 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 8.997018]
2023-05-16 10:38:45.557: epoch 134:	0.02690581  	0.19738843  	0.10994010  
2023-05-16 10:38:53.549: [iter 135 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0064, time: 7.989966]
2023-05-16 10:38:53.712: epoch 135:	0.02694109  	0.19780248  	0.11001726  
2023-05-16 10:39:01.441: [iter 136 : loss : 0.1152 = 0.0256 + 0.0831 + 0.0065, time: 7.728013]
2023-05-16 10:39:01.604: epoch 136:	0.02696227  	0.19795708  	0.11026962  
2023-05-16 10:39:09.472: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 7.866994]
2023-05-16 10:39:09.628: epoch 137:	0.02694109  	0.19766054  	0.11025669  
2023-05-16 10:39:18.694: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 9.062024]
2023-05-16 10:39:18.956: epoch 138:	0.02694109  	0.19794422  	0.11034454  
2023-05-16 10:39:26.410: [iter 139 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0065, time: 7.452015]
2023-05-16 10:39:26.582: epoch 139:	0.02694109  	0.19786848  	0.11034162  
2023-05-16 10:39:34.854: [iter 140 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 8.269521]
2023-05-16 10:39:35.013: epoch 140:	0.02693404  	0.19788344  	0.11049037  
2023-05-16 10:39:43.066: [iter 141 : loss : 0.1142 = 0.0247 + 0.0830 + 0.0066, time: 8.052003]
2023-05-16 10:39:43.228: epoch 141:	0.02693404  	0.19760133  	0.11050086  
2023-05-16 10:39:52.660: [iter 142 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 9.428568]
2023-05-16 10:39:52.960: epoch 142:	0.02693404  	0.19736762  	0.11044205  
2023-05-16 10:40:02.000: [iter 143 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0067, time: 9.038040]
2023-05-16 10:40:02.299: epoch 143:	0.02694109  	0.19725031  	0.11043377  
2023-05-16 10:40:10.418: [iter 144 : loss : 0.1127 = 0.0231 + 0.0829 + 0.0067, time: 8.118041]
2023-05-16 10:40:10.661: epoch 144:	0.02702576  	0.19772387  	0.11072344  
2023-05-16 10:40:18.226: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.562994]
2023-05-16 10:40:18.380: epoch 145:	0.02693403  	0.19713971  	0.11067041  
2023-05-16 10:40:26.213: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.832007]
2023-05-16 10:40:26.371: epoch 146:	0.02693403  	0.19733267  	0.11071567  
2023-05-16 10:40:35.318: [iter 147 : loss : 0.1128 = 0.0233 + 0.0827 + 0.0068, time: 8.944043]
2023-05-16 10:40:35.619: epoch 147:	0.02685641  	0.19661565  	0.11055160  
2023-05-16 10:40:42.918: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.298013]
2023-05-16 10:40:43.082: epoch 148:	0.02692698  	0.19716914  	0.11076599  
2023-05-16 10:40:51.257: [iter 149 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 8.174009]
2023-05-16 10:40:51.416: epoch 149:	0.02690581  	0.19709784  	0.11074208  
2023-05-16 10:40:59.412: [iter 150 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.993996]
2023-05-16 10:40:59.573: epoch 150:	0.02689170  	0.19702652  	0.11074060  
2023-05-16 10:41:08.900: [iter 151 : loss : 0.1117 = 0.0222 + 0.0826 + 0.0069, time: 9.325121]
2023-05-16 10:41:09.195: epoch 151:	0.02692698  	0.19731790  	0.11086707  
2023-05-16 10:41:18.223: [iter 152 : loss : 0.1108 = 0.0213 + 0.0826 + 0.0069, time: 9.025026]
2023-05-16 10:41:18.515: epoch 152:	0.02689170  	0.19718696  	0.11060955  
2023-05-16 10:41:26.366: [iter 153 : loss : 0.1101 = 0.0206 + 0.0826 + 0.0069, time: 7.850017]
2023-05-16 10:41:26.529: epoch 153:	0.02684936  	0.19671911  	0.11056758  
2023-05-16 10:41:34.160: [iter 154 : loss : 0.1102 = 0.0207 + 0.0826 + 0.0069, time: 7.630027]
2023-05-16 10:41:34.320: epoch 154:	0.02691992  	0.19706166  	0.11074122  
2023-05-16 10:41:42.398: [iter 155 : loss : 0.1112 = 0.0218 + 0.0825 + 0.0070, time: 8.077009]
2023-05-16 10:41:42.558: epoch 155:	0.02699049  	0.19761521  	0.11099707  
2023-05-16 10:41:42.558: Early stopping is trigger at epoch: 155
2023-05-16 10:41:42.558: best_result@epoch 130:

2023-05-16 10:41:42.558: 		0.0270      	0.1982      	0.1104      
2023-05-16 11:04:07.118: my pid: 10864
2023-05-16 11:04:07.118: model: model.general_recommender.SGL
2023-05-16 11:04:07.118: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 11:04:07.118: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 11:04:10.292: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 11:04:18.732: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.439874]
2023-05-16 11:04:18.881: epoch 1:	0.00143946  	0.01106034  	0.00528109  
2023-05-16 11:04:18.882: Find a better model.
2023-05-16 11:04:27.353: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.469568]
2023-05-16 11:04:27.556: epoch 2:	0.00254728  	0.01927543  	0.00935553  
2023-05-16 11:04:27.556: Find a better model.
2023-05-16 11:04:35.827: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.269734]
2023-05-16 11:04:36.002: epoch 3:	0.00496046  	0.03746357  	0.01778348  
2023-05-16 11:04:36.002: Find a better model.
2023-05-16 11:04:44.384: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.379668]
2023-05-16 11:04:44.633: epoch 4:	0.00813569  	0.06009244  	0.02909447  
2023-05-16 11:04:44.633: Find a better model.
2023-05-16 11:04:52.802: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 8.168287]
2023-05-16 11:04:52.951: epoch 5:	0.01203082  	0.08811507  	0.04176414  
2023-05-16 11:04:52.951: Find a better model.
2023-05-16 11:05:01.042: [iter 6 : loss : 0.7671 = 0.6878 + 0.0792 + 0.0000, time: 8.087282]
2023-05-16 11:05:01.219: epoch 6:	0.01560136  	0.11283182  	0.05519778  
2023-05-16 11:05:01.219: Find a better model.
2023-05-16 11:05:09.196: [iter 7 : loss : 0.7603 = 0.6803 + 0.0800 + 0.0000, time: 7.974801]
2023-05-16 11:05:09.352: epoch 7:	0.01784530  	0.12934938  	0.06399599  
2023-05-16 11:05:09.352: Find a better model.
2023-05-16 11:05:17.115: [iter 8 : loss : 0.7437 = 0.6617 + 0.0820 + 0.0001, time: 7.761903]
2023-05-16 11:05:17.288: epoch 8:	0.01874147  	0.13678324  	0.06857765  
2023-05-16 11:05:17.288: Find a better model.
2023-05-16 11:05:24.917: [iter 9 : loss : 0.7069 = 0.6208 + 0.0859 + 0.0001, time: 7.627599]
2023-05-16 11:05:25.061: epoch 9:	0.01850156  	0.13668850  	0.06852255  
2023-05-16 11:05:32.812: [iter 10 : loss : 0.6446 = 0.5530 + 0.0913 + 0.0003, time: 7.749387]
2023-05-16 11:05:32.980: epoch 10:	0.01849449  	0.13652429  	0.06819370  
2023-05-16 11:05:40.811: [iter 11 : loss : 0.5693 = 0.4727 + 0.0962 + 0.0004, time: 7.830041]
2023-05-16 11:05:40.987: epoch 11:	0.01843804  	0.13624902  	0.06815002  
2023-05-16 11:05:49.596: [iter 12 : loss : 0.5013 = 0.4014 + 0.0994 + 0.0006, time: 8.605664]
2023-05-16 11:05:49.744: epoch 12:	0.01833220  	0.13544881  	0.06798587  
2023-05-16 11:05:57.961: [iter 13 : loss : 0.4514 = 0.3495 + 0.1012 + 0.0007, time: 8.216004]
2023-05-16 11:05:58.120: epoch 13:	0.01835336  	0.13561790  	0.06840353  
2023-05-16 11:06:05.935: [iter 14 : loss : 0.4135 = 0.3106 + 0.1021 + 0.0009, time: 7.813132]
2023-05-16 11:06:06.109: epoch 14:	0.01862857  	0.13770774  	0.06961946  
2023-05-16 11:06:06.109: Find a better model.
2023-05-16 11:06:15.203: [iter 15 : loss : 0.3870 = 0.2835 + 0.1025 + 0.0010, time: 9.081017]
2023-05-16 11:06:15.481: epoch 15:	0.01890377  	0.13935338  	0.07061194  
2023-05-16 11:06:15.481: Find a better model.
2023-05-16 11:06:23.644: [iter 16 : loss : 0.3647 = 0.2613 + 0.1024 + 0.0011, time: 8.162057]
2023-05-16 11:06:23.802: epoch 16:	0.01901668  	0.14035125  	0.07130843  
2023-05-16 11:06:23.802: Find a better model.
2023-05-16 11:06:31.516: [iter 17 : loss : 0.3486 = 0.2451 + 0.1023 + 0.0012, time: 7.712032]
2023-05-16 11:06:31.679: epoch 17:	0.01915076  	0.14145745  	0.07210180  
2023-05-16 11:06:31.679: Find a better model.
2023-05-16 11:06:40.154: [iter 18 : loss : 0.3334 = 0.2301 + 0.1020 + 0.0013, time: 8.474091]
2023-05-16 11:06:40.314: epoch 18:	0.01949653  	0.14390180  	0.07309942  
2023-05-16 11:06:40.314: Find a better model.
2023-05-16 11:06:49.308: [iter 19 : loss : 0.3193 = 0.2162 + 0.1017 + 0.0014, time: 8.993038]
2023-05-16 11:06:49.595: epoch 19:	0.01973645  	0.14515245  	0.07392430  
2023-05-16 11:06:49.595: Find a better model.
2023-05-16 11:06:57.039: [iter 20 : loss : 0.3097 = 0.2069 + 0.1013 + 0.0015, time: 7.443017]
2023-05-16 11:06:57.202: epoch 20:	0.01988463  	0.14658231  	0.07461047  
2023-05-16 11:06:57.202: Find a better model.
2023-05-16 11:07:05.290: [iter 21 : loss : 0.3000 = 0.1976 + 0.1009 + 0.0016, time: 8.086030]
2023-05-16 11:07:05.448: epoch 21:	0.02011750  	0.14851302  	0.07529961  
2023-05-16 11:07:05.449: Find a better model.
2023-05-16 11:07:13.889: [iter 22 : loss : 0.2919 = 0.1897 + 0.1005 + 0.0017, time: 8.438549]
2023-05-16 11:07:14.052: epoch 22:	0.02037859  	0.15062059  	0.07621717  
2023-05-16 11:07:14.053: Find a better model.
2023-05-16 11:07:23.569: [iter 23 : loss : 0.2838 = 0.1820 + 0.1001 + 0.0017, time: 9.515058]
2023-05-16 11:07:23.861: epoch 23:	0.02059028  	0.15226322  	0.07698024  
2023-05-16 11:07:23.861: Find a better model.
2023-05-16 11:07:33.028: [iter 24 : loss : 0.2772 = 0.1758 + 0.0996 + 0.0018, time: 9.162030]
2023-05-16 11:07:33.319: epoch 24:	0.02075964  	0.15325706  	0.07767717  
2023-05-16 11:07:33.319: Find a better model.
2023-05-16 11:07:41.675: [iter 25 : loss : 0.2706 = 0.1695 + 0.0993 + 0.0019, time: 8.354060]
2023-05-16 11:07:41.852: epoch 25:	0.02087961  	0.15420306  	0.07821865  
2023-05-16 11:07:41.852: Find a better model.
2023-05-16 11:07:50.395: [iter 26 : loss : 0.2671 = 0.1663 + 0.0989 + 0.0019, time: 8.540102]
2023-05-16 11:07:50.574: epoch 26:	0.02107013  	0.15533312  	0.07891222  
2023-05-16 11:07:50.574: Find a better model.
2023-05-16 11:07:58.260: [iter 27 : loss : 0.2595 = 0.1591 + 0.0984 + 0.0020, time: 7.684993]
2023-05-16 11:07:58.422: epoch 27:	0.02124655  	0.15667397  	0.07967354  
2023-05-16 11:07:58.422: Find a better model.
2023-05-16 11:08:07.502: [iter 28 : loss : 0.2544 = 0.1544 + 0.0979 + 0.0021, time: 9.076990]
2023-05-16 11:08:07.768: epoch 28:	0.02148648  	0.15875703  	0.08100219  
2023-05-16 11:08:07.768: Find a better model.
2023-05-16 11:08:16.048: [iter 29 : loss : 0.2499 = 0.1503 + 0.0975 + 0.0021, time: 8.278992]
2023-05-16 11:08:16.210: epoch 29:	0.02170523  	0.16011451  	0.08202478  
2023-05-16 11:08:16.210: Find a better model.
2023-05-16 11:08:23.850: [iter 30 : loss : 0.2436 = 0.1442 + 0.0972 + 0.0022, time: 7.638992]
2023-05-16 11:08:24.012: epoch 30:	0.02177579  	0.16107279  	0.08259613  
2023-05-16 11:08:24.012: Find a better model.
2023-05-16 11:08:32.468: [iter 31 : loss : 0.2398 = 0.1407 + 0.0969 + 0.0023, time: 8.455003]
2023-05-16 11:08:32.706: epoch 31:	0.02195926  	0.16215779  	0.08354873  
2023-05-16 11:08:32.707: Find a better model.
2023-05-16 11:08:41.617: [iter 32 : loss : 0.2345 = 0.1357 + 0.0965 + 0.0023, time: 8.907108]
2023-05-16 11:08:41.879: epoch 32:	0.02215684  	0.16365930  	0.08437766  
2023-05-16 11:08:41.880: Find a better model.
2023-05-16 11:08:49.406: [iter 33 : loss : 0.2318 = 0.1333 + 0.0961 + 0.0024, time: 7.525138]
2023-05-16 11:08:49.589: epoch 33:	0.02224857  	0.16451333  	0.08493549  
2023-05-16 11:08:49.589: Find a better model.
2023-05-16 11:08:57.814: [iter 34 : loss : 0.2277 = 0.1296 + 0.0957 + 0.0024, time: 8.224380]
2023-05-16 11:08:57.973: epoch 34:	0.02228384  	0.16418125  	0.08520062  
2023-05-16 11:09:06.440: [iter 35 : loss : 0.2244 = 0.1264 + 0.0954 + 0.0025, time: 8.466003]
2023-05-16 11:09:06.600: epoch 35:	0.02237558  	0.16514157  	0.08584113  
2023-05-16 11:09:06.600: Find a better model.
2023-05-16 11:09:15.761: [iter 36 : loss : 0.2209 = 0.1232 + 0.0952 + 0.0025, time: 9.157066]
2023-05-16 11:09:16.054: epoch 36:	0.02250965  	0.16612394  	0.08635043  
2023-05-16 11:09:16.054: Find a better model.
2023-05-16 11:09:25.040: [iter 37 : loss : 0.2172 = 0.1198 + 0.0948 + 0.0026, time: 8.985655]
2023-05-16 11:09:25.325: epoch 37:	0.02263667  	0.16737315  	0.08705588  
2023-05-16 11:09:25.325: Find a better model.
2023-05-16 11:09:33.627: [iter 38 : loss : 0.2153 = 0.1181 + 0.0945 + 0.0027, time: 8.299992]
2023-05-16 11:09:33.778: epoch 38:	0.02282014  	0.16899739  	0.08791208  
2023-05-16 11:09:33.778: Find a better model.
2023-05-16 11:09:42.041: [iter 39 : loss : 0.2108 = 0.1139 + 0.0942 + 0.0027, time: 8.260002]
2023-05-16 11:09:42.394: epoch 39:	0.02289776  	0.16891436  	0.08850136  
2023-05-16 11:09:50.252: [iter 40 : loss : 0.2076 = 0.1110 + 0.0939 + 0.0028, time: 7.856996]
2023-05-16 11:09:50.423: epoch 40:	0.02291893  	0.16862203  	0.08866494  
2023-05-16 11:09:59.439: [iter 41 : loss : 0.2061 = 0.1097 + 0.0936 + 0.0028, time: 9.006302]
2023-05-16 11:09:59.695: epoch 41:	0.02306712  	0.16995201  	0.08938101  
2023-05-16 11:09:59.695: Find a better model.
2023-05-16 11:10:07.885: [iter 42 : loss : 0.2038 = 0.1076 + 0.0934 + 0.0029, time: 8.187993]
2023-05-16 11:10:08.043: epoch 42:	0.02317296  	0.17071676  	0.09008077  
2023-05-16 11:10:08.044: Find a better model.
2023-05-16 11:10:15.817: [iter 43 : loss : 0.1998 = 0.1038 + 0.0930 + 0.0029, time: 7.761189]
2023-05-16 11:10:15.980: epoch 43:	0.02327881  	0.17163067  	0.09059415  
2023-05-16 11:10:15.980: Find a better model.
2023-05-16 11:10:24.266: [iter 44 : loss : 0.1964 = 0.1007 + 0.0928 + 0.0030, time: 8.283993]
2023-05-16 11:10:24.443: epoch 44:	0.02335643  	0.17175403  	0.09105831  
2023-05-16 11:10:24.443: Find a better model.
2023-05-16 11:10:33.433: [iter 45 : loss : 0.1943 = 0.0986 + 0.0926 + 0.0030, time: 8.987740]
2023-05-16 11:10:33.704: epoch 45:	0.02353990  	0.17314993  	0.09175929  
2023-05-16 11:10:33.704: Find a better model.
2023-05-16 11:10:41.543: [iter 46 : loss : 0.1920 = 0.0966 + 0.0923 + 0.0031, time: 7.837628]
2023-05-16 11:10:41.704: epoch 46:	0.02366692  	0.17395741  	0.09249970  
2023-05-16 11:10:41.704: Find a better model.
2023-05-16 11:10:50.009: [iter 47 : loss : 0.1913 = 0.0961 + 0.0921 + 0.0031, time: 8.303992]
2023-05-16 11:10:50.166: epoch 47:	0.02374454  	0.17429905  	0.09282030  
2023-05-16 11:10:50.166: Find a better model.
2023-05-16 11:10:58.371: [iter 48 : loss : 0.1873 = 0.0923 + 0.0918 + 0.0032, time: 8.203278]
2023-05-16 11:10:58.535: epoch 48:	0.02387861  	0.17543636  	0.09314799  
2023-05-16 11:10:58.535: Find a better model.
2023-05-16 11:11:07.303: [iter 49 : loss : 0.1845 = 0.0896 + 0.0916 + 0.0032, time: 8.765998]
2023-05-16 11:11:07.593: epoch 49:	0.02387156  	0.17557928  	0.09366330  
2023-05-16 11:11:07.593: Find a better model.
2023-05-16 11:11:16.438: [iter 50 : loss : 0.1835 = 0.0888 + 0.0914 + 0.0033, time: 8.842992]
2023-05-16 11:11:16.729: epoch 50:	0.02396329  	0.17621917  	0.09417824  
2023-05-16 11:11:16.729: Find a better model.
2023-05-16 11:11:24.953: [iter 51 : loss : 0.1805 = 0.0860 + 0.0912 + 0.0033, time: 8.221995]
2023-05-16 11:11:25.123: epoch 51:	0.02409736  	0.17708795  	0.09459247  
2023-05-16 11:11:25.123: Find a better model.
2023-05-16 11:11:32.832: [iter 52 : loss : 0.1802 = 0.0859 + 0.0910 + 0.0034, time: 7.706993]
2023-05-16 11:11:32.996: epoch 52:	0.02412559  	0.17748517  	0.09498670  
2023-05-16 11:11:32.996: Find a better model.
2023-05-16 11:11:41.161: [iter 53 : loss : 0.1782 = 0.0840 + 0.0908 + 0.0034, time: 8.163512]
2023-05-16 11:11:41.321: epoch 53:	0.02411853  	0.17735679  	0.09530396  
2023-05-16 11:11:50.263: [iter 54 : loss : 0.1765 = 0.0824 + 0.0906 + 0.0035, time: 8.939992]
2023-05-16 11:11:50.567: epoch 54:	0.02437962  	0.17937458  	0.09609652  
2023-05-16 11:11:50.568: Find a better model.
2023-05-16 11:11:57.949: [iter 55 : loss : 0.1745 = 0.0806 + 0.0904 + 0.0035, time: 7.379992]
2023-05-16 11:11:58.111: epoch 55:	0.02436550  	0.17901586  	0.09613255  
2023-05-16 11:12:06.148: [iter 56 : loss : 0.1726 = 0.0788 + 0.0903 + 0.0035, time: 8.035497]
2023-05-16 11:12:06.301: epoch 56:	0.02447135  	0.17965476  	0.09651271  
2023-05-16 11:12:06.301: Find a better model.
2023-05-16 11:12:14.562: [iter 57 : loss : 0.1708 = 0.0771 + 0.0901 + 0.0036, time: 8.259995]
2023-05-16 11:12:14.720: epoch 57:	0.02441490  	0.17936558  	0.09665394  
2023-05-16 11:12:23.954: [iter 58 : loss : 0.1689 = 0.0754 + 0.0898 + 0.0036, time: 9.230463]
2023-05-16 11:12:24.205: epoch 58:	0.02447841  	0.17953628  	0.09693501  
2023-05-16 11:12:33.287: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 9.077991]
2023-05-16 11:12:33.574: epoch 59:	0.02457720  	0.18054080  	0.09757243  
2023-05-16 11:12:33.574: Find a better model.
2023-05-16 11:12:41.782: [iter 60 : loss : 0.1664 = 0.0731 + 0.0895 + 0.0037, time: 8.207332]
2023-05-16 11:12:41.953: epoch 60:	0.02471833  	0.18166229  	0.09793583  
2023-05-16 11:12:41.953: Find a better model.
2023-05-16 11:12:50.449: [iter 61 : loss : 0.1650 = 0.0719 + 0.0893 + 0.0038, time: 8.495121]
2023-05-16 11:12:50.621: epoch 61:	0.02476067  	0.18233529  	0.09838977  
2023-05-16 11:12:50.621: Find a better model.
2023-05-16 11:12:58.363: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 7.739312]
2023-05-16 11:12:58.548: epoch 62:	0.02471833  	0.18244477  	0.09860212  
2023-05-16 11:12:58.548: Find a better model.
2023-05-16 11:13:07.506: [iter 63 : loss : 0.1621 = 0.0693 + 0.0890 + 0.0039, time: 8.955992]
2023-05-16 11:13:07.792: epoch 63:	0.02478889  	0.18318380  	0.09902136  
2023-05-16 11:13:07.792: Find a better model.
2023-05-16 11:13:16.022: [iter 64 : loss : 0.1609 = 0.0682 + 0.0888 + 0.0039, time: 8.227992]
2023-05-16 11:13:16.171: epoch 64:	0.02492296  	0.18408734  	0.09921338  
2023-05-16 11:13:16.171: Find a better model.
2023-05-16 11:13:23.775: [iter 65 : loss : 0.1599 = 0.0672 + 0.0887 + 0.0039, time: 7.603063]
2023-05-16 11:13:23.944: epoch 65:	0.02495824  	0.18437244  	0.09953304  
2023-05-16 11:13:23.944: Find a better model.
2023-05-16 11:13:32.363: [iter 66 : loss : 0.1579 = 0.0654 + 0.0886 + 0.0040, time: 8.417269]
2023-05-16 11:13:32.591: epoch 66:	0.02500764  	0.18461214  	0.09988498  
2023-05-16 11:13:32.591: Find a better model.
2023-05-16 11:13:41.537: [iter 67 : loss : 0.1566 = 0.0642 + 0.0884 + 0.0040, time: 8.941952]
2023-05-16 11:13:41.824: epoch 67:	0.02501470  	0.18483424  	0.10014335  
2023-05-16 11:13:41.824: Find a better model.
2023-05-16 11:13:49.375: [iter 68 : loss : 0.1564 = 0.0640 + 0.0883 + 0.0041, time: 7.549993]
2023-05-16 11:13:49.571: epoch 68:	0.02519110  	0.18612221  	0.10062301  
2023-05-16 11:13:49.571: Find a better model.
2023-05-16 11:13:57.951: [iter 69 : loss : 0.1546 = 0.0623 + 0.0881 + 0.0041, time: 8.379001]
2023-05-16 11:13:58.104: epoch 69:	0.02519110  	0.18584336  	0.10075780  
2023-05-16 11:14:06.367: [iter 70 : loss : 0.1529 = 0.0607 + 0.0880 + 0.0042, time: 8.262141]
2023-05-16 11:14:06.533: epoch 70:	0.02530401  	0.18668815  	0.10124199  
2023-05-16 11:14:06.533: Find a better model.
2023-05-16 11:14:15.511: [iter 71 : loss : 0.1513 = 0.0592 + 0.0879 + 0.0042, time: 8.970128]
2023-05-16 11:14:15.799: epoch 71:	0.02533929  	0.18690287  	0.10118145  
2023-05-16 11:14:15.799: Find a better model.
2023-05-16 11:14:24.827: [iter 72 : loss : 0.1511 = 0.0591 + 0.0878 + 0.0042, time: 9.021022]
2023-05-16 11:14:25.124: epoch 72:	0.02535340  	0.18701661  	0.10132627  
2023-05-16 11:14:25.124: Find a better model.
2023-05-16 11:14:33.372: [iter 73 : loss : 0.1499 = 0.0579 + 0.0876 + 0.0043, time: 8.246992]
2023-05-16 11:14:33.584: epoch 73:	0.02545219  	0.18773790  	0.10171910  
2023-05-16 11:14:33.584: Find a better model.
2023-05-16 11:14:41.815: [iter 74 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 8.228359]
2023-05-16 11:14:42.202: epoch 74:	0.02549453  	0.18809256  	0.10199831  
2023-05-16 11:14:42.203: Find a better model.
2023-05-16 11:14:50.324: [iter 75 : loss : 0.1479 = 0.0562 + 0.0874 + 0.0044, time: 8.110958]
2023-05-16 11:14:50.480: epoch 75:	0.02545925  	0.18772216  	0.10207181  
2023-05-16 11:14:59.583: [iter 76 : loss : 0.1470 = 0.0553 + 0.0873 + 0.0044, time: 9.100419]
2023-05-16 11:14:59.842: epoch 76:	0.02548041  	0.18776602  	0.10213339  
2023-05-16 11:15:08.136: [iter 77 : loss : 0.1461 = 0.0544 + 0.0872 + 0.0044, time: 8.292993]
2023-05-16 11:15:08.309: epoch 77:	0.02559332  	0.18843938  	0.10253751  
2023-05-16 11:15:08.309: Find a better model.
2023-05-16 11:15:15.919: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 7.608924]
2023-05-16 11:15:16.080: epoch 78:	0.02557920  	0.18812510  	0.10257691  
2023-05-16 11:15:25.094: [iter 79 : loss : 0.1439 = 0.0524 + 0.0870 + 0.0045, time: 9.012305]
2023-05-16 11:15:25.264: epoch 79:	0.02569917  	0.18903251  	0.10302188  
2023-05-16 11:15:25.264: Find a better model.
2023-05-16 11:15:34.404: [iter 80 : loss : 0.1428 = 0.0514 + 0.0869 + 0.0046, time: 9.137992]
2023-05-16 11:15:34.744: epoch 80:	0.02575562  	0.18943544  	0.10320055  
2023-05-16 11:15:34.744: Find a better model.
2023-05-16 11:15:42.327: [iter 81 : loss : 0.1428 = 0.0515 + 0.0867 + 0.0046, time: 7.580473]
2023-05-16 11:15:42.509: epoch 81:	0.02584030  	0.18945223  	0.10362384  
2023-05-16 11:15:42.510: Find a better model.
2023-05-16 11:15:50.878: [iter 82 : loss : 0.1413 = 0.0501 + 0.0866 + 0.0046, time: 8.364868]
2023-05-16 11:15:51.035: epoch 82:	0.02583324  	0.18945223  	0.10345946  
2023-05-16 11:15:59.542: [iter 83 : loss : 0.1405 = 0.0493 + 0.0865 + 0.0047, time: 8.505243]
2023-05-16 11:15:59.703: epoch 83:	0.02591086  	0.18978108  	0.10375095  
2023-05-16 11:15:59.703: Find a better model.
2023-05-16 11:16:09.253: [iter 84 : loss : 0.1405 = 0.0493 + 0.0864 + 0.0047, time: 9.549036]
2023-05-16 11:16:09.546: epoch 84:	0.02593908  	0.19021626  	0.10400882  
2023-05-16 11:16:09.546: Find a better model.
2023-05-16 11:16:18.597: [iter 85 : loss : 0.1394 = 0.0483 + 0.0863 + 0.0048, time: 9.043964]
2023-05-16 11:16:18.848: epoch 85:	0.02603081  	0.19101773  	0.10429119  
2023-05-16 11:16:18.849: Find a better model.
2023-05-16 11:16:26.914: [iter 86 : loss : 0.1394 = 0.0483 + 0.0862 + 0.0048, time: 8.064163]
2023-05-16 11:16:27.073: epoch 86:	0.02586145  	0.18949032  	0.10402745  
2023-05-16 11:16:35.127: [iter 87 : loss : 0.1368 = 0.0458 + 0.0862 + 0.0048, time: 8.053115]
2023-05-16 11:16:35.684: epoch 87:	0.02605198  	0.19080615  	0.10442726  
2023-05-16 11:16:43.468: [iter 88 : loss : 0.1357 = 0.0447 + 0.0861 + 0.0049, time: 7.782594]
2023-05-16 11:16:43.629: epoch 88:	0.02604492  	0.19091733  	0.10446646  
2023-05-16 11:16:52.634: [iter 89 : loss : 0.1356 = 0.0448 + 0.0859 + 0.0049, time: 9.001012]
2023-05-16 11:16:52.917: epoch 89:	0.02604492  	0.19105393  	0.10471800  
2023-05-16 11:16:52.917: Find a better model.
2023-05-16 11:17:01.118: [iter 90 : loss : 0.1363 = 0.0455 + 0.0859 + 0.0049, time: 8.200049]
2023-05-16 11:17:01.282: epoch 90:	0.02606609  	0.19097957  	0.10472114  
2023-05-16 11:17:08.894: [iter 91 : loss : 0.1348 = 0.0440 + 0.0858 + 0.0050, time: 7.610992]
2023-05-16 11:17:09.054: epoch 91:	0.02616488  	0.19164388  	0.10488947  
2023-05-16 11:17:09.054: Find a better model.
2023-05-16 11:17:17.794: [iter 92 : loss : 0.1341 = 0.0433 + 0.0857 + 0.0050, time: 8.737080]
2023-05-16 11:17:17.959: epoch 92:	0.02617193  	0.19160280  	0.10514196  
2023-05-16 11:17:27.058: [iter 93 : loss : 0.1342 = 0.0436 + 0.0856 + 0.0051, time: 9.089036]
2023-05-16 11:17:27.350: epoch 93:	0.02619311  	0.19176595  	0.10530809  
2023-05-16 11:17:27.350: Find a better model.
2023-05-16 11:17:34.765: [iter 94 : loss : 0.1319 = 0.0412 + 0.0856 + 0.0051, time: 7.412420]
2023-05-16 11:17:34.925: epoch 94:	0.02617194  	0.19155312  	0.10526307  
2023-05-16 11:17:43.298: [iter 95 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 8.370133]
2023-05-16 11:17:43.454: epoch 95:	0.02624956  	0.19226903  	0.10552394  
2023-05-16 11:17:43.454: Find a better model.
2023-05-16 11:17:51.861: [iter 96 : loss : 0.1315 = 0.0410 + 0.0854 + 0.0052, time: 8.406155]
2023-05-16 11:17:52.022: epoch 96:	0.02632718  	0.19283772  	0.10569467  
2023-05-16 11:17:52.022: Find a better model.
2023-05-16 11:18:01.324: [iter 97 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0052, time: 9.301017]
2023-05-16 11:18:01.612: epoch 97:	0.02636952  	0.19339259  	0.10592923  
2023-05-16 11:18:01.613: Find a better model.
2023-05-16 11:18:10.724: [iter 98 : loss : 0.1307 = 0.0402 + 0.0853 + 0.0052, time: 9.110651]
2023-05-16 11:18:11.014: epoch 98:	0.02633423  	0.19311444  	0.10601437  
2023-05-16 11:18:19.234: [iter 99 : loss : 0.1296 = 0.0392 + 0.0851 + 0.0053, time: 8.219016]
2023-05-16 11:18:19.406: epoch 99:	0.02636952  	0.19325675  	0.10604715  
2023-05-16 11:18:28.065: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 8.657011]
2023-05-16 11:18:28.230: epoch 100:	0.02636952  	0.19335152  	0.10615428  
2023-05-16 11:18:36.031: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0053, time: 7.800028]
2023-05-16 11:18:36.189: epoch 101:	0.02641186  	0.19392534  	0.10647395  
2023-05-16 11:18:36.190: Find a better model.
2023-05-16 11:18:45.303: [iter 102 : loss : 0.1276 = 0.0373 + 0.0849 + 0.0054, time: 9.110012]
2023-05-16 11:18:45.557: epoch 102:	0.02644715  	0.19427979  	0.10677042  
2023-05-16 11:18:45.557: Find a better model.
2023-05-16 11:18:53.987: [iter 103 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 8.428992]
2023-05-16 11:18:54.145: epoch 103:	0.02644009  	0.19430453  	0.10686866  
2023-05-16 11:18:54.145: Find a better model.
2023-05-16 11:19:02.023: [iter 104 : loss : 0.1278 = 0.0376 + 0.0848 + 0.0055, time: 7.876010]
2023-05-16 11:19:02.185: epoch 104:	0.02640481  	0.19418989  	0.10692879  
2023-05-16 11:19:10.727: [iter 105 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0055, time: 8.539932]
2023-05-16 11:19:10.891: epoch 105:	0.02646127  	0.19482850  	0.10717698  
2023-05-16 11:19:10.891: Find a better model.
2023-05-16 11:19:19.938: [iter 106 : loss : 0.1265 = 0.0362 + 0.0847 + 0.0055, time: 9.041062]
2023-05-16 11:19:20.226: epoch 106:	0.02648949  	0.19501761  	0.10725997  
2023-05-16 11:19:20.227: Find a better model.
2023-05-16 11:19:27.729: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0055, time: 7.500129]
2023-05-16 11:19:27.888: epoch 107:	0.02645421  	0.19470768  	0.10719065  
2023-05-16 11:19:36.032: [iter 108 : loss : 0.1253 = 0.0352 + 0.0846 + 0.0056, time: 8.143006]
2023-05-16 11:19:36.193: epoch 108:	0.02649655  	0.19511077  	0.10743242  
2023-05-16 11:19:36.193: Find a better model.
2023-05-16 11:19:44.596: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 8.401019]
2023-05-16 11:19:44.761: epoch 109:	0.02654594  	0.19528700  	0.10762315  
2023-05-16 11:19:44.761: Find a better model.
2023-05-16 11:19:53.822: [iter 110 : loss : 0.1233 = 0.0332 + 0.0845 + 0.0057, time: 9.057839]
2023-05-16 11:19:54.076: epoch 110:	0.02652477  	0.19498119  	0.10759401  
2023-05-16 11:20:03.179: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 9.099115]
2023-05-16 11:20:03.472: epoch 111:	0.02654594  	0.19531518  	0.10765724  
2023-05-16 11:20:03.472: Find a better model.
2023-05-16 11:20:12.240: [iter 112 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0057, time: 8.767317]
2023-05-16 11:20:12.411: epoch 112:	0.02655300  	0.19539222  	0.10776601  
2023-05-16 11:20:12.411: Find a better model.
2023-05-16 11:20:20.994: [iter 113 : loss : 0.1232 = 0.0331 + 0.0843 + 0.0058, time: 8.582208]
2023-05-16 11:20:21.164: epoch 113:	0.02658829  	0.19579379  	0.10780212  
2023-05-16 11:20:21.164: Find a better model.
2023-05-16 11:20:29.033: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 7.867066]
2023-05-16 11:20:29.195: epoch 114:	0.02660240  	0.19591217  	0.10790759  
2023-05-16 11:20:29.195: Find a better model.
2023-05-16 11:20:38.333: [iter 115 : loss : 0.1218 = 0.0318 + 0.0841 + 0.0058, time: 9.135079]
2023-05-16 11:20:38.627: epoch 115:	0.02653889  	0.19541411  	0.10771227  
2023-05-16 11:20:46.984: [iter 116 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0058, time: 8.354471]
2023-05-16 11:20:47.131: epoch 116:	0.02655300  	0.19549163  	0.10772058  
2023-05-16 11:20:54.798: [iter 117 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 7.666127]
2023-05-16 11:20:54.966: epoch 117:	0.02659534  	0.19573256  	0.10787973  
2023-05-16 11:21:03.239: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 8.271032]
2023-05-16 11:21:03.418: epoch 118:	0.02661651  	0.19589604  	0.10792342  
2023-05-16 11:21:12.508: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0059, time: 9.088016]
2023-05-16 11:21:12.800: epoch 119:	0.02658123  	0.19548127  	0.10789055  
2023-05-16 11:21:20.342: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 7.540996]
2023-05-16 11:21:20.518: epoch 120:	0.02660240  	0.19551705  	0.10802139  
2023-05-16 11:21:28.775: [iter 121 : loss : 0.1201 = 0.0303 + 0.0838 + 0.0060, time: 8.254030]
2023-05-16 11:21:28.930: epoch 121:	0.02655300  	0.19506557  	0.10797057  
2023-05-16 11:21:37.178: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 8.245992]
2023-05-16 11:21:37.340: epoch 122:	0.02658123  	0.19524814  	0.10781363  
2023-05-16 11:21:45.754: [iter 123 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0061, time: 8.407064]
2023-05-16 11:21:46.052: epoch 123:	0.02665178  	0.19557902  	0.10813053  
2023-05-16 11:21:55.083: [iter 124 : loss : 0.1185 = 0.0287 + 0.0837 + 0.0061, time: 9.030034]
2023-05-16 11:21:55.367: epoch 124:	0.02667296  	0.19584359  	0.10817689  
2023-05-16 11:22:03.721: [iter 125 : loss : 0.1176 = 0.0278 + 0.0837 + 0.0061, time: 8.351031]
2023-05-16 11:22:03.887: epoch 125:	0.02665179  	0.19570574  	0.10823179  
2023-05-16 11:22:11.765: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 7.877007]
2023-05-16 11:22:11.926: epoch 126:	0.02668002  	0.19600487  	0.10833298  
2023-05-16 11:22:11.927: Find a better model.
2023-05-16 11:22:20.176: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 8.248024]
2023-05-16 11:22:20.330: epoch 127:	0.02666591  	0.19584523  	0.10837752  
2023-05-16 11:22:29.373: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 9.040968]
2023-05-16 11:22:29.660: epoch 128:	0.02671530  	0.19617465  	0.10864125  
2023-05-16 11:22:29.660: Find a better model.
2023-05-16 11:22:37.183: [iter 129 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0063, time: 7.520204]
2023-05-16 11:22:37.345: epoch 129:	0.02673647  	0.19664350  	0.10870425  
2023-05-16 11:22:37.345: Find a better model.
2023-05-16 11:22:45.340: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.994015]
2023-05-16 11:22:45.498: epoch 130:	0.02676470  	0.19669697  	0.10866962  
2023-05-16 11:22:45.499: Find a better model.
2023-05-16 11:22:53.964: [iter 131 : loss : 0.1162 = 0.0265 + 0.0834 + 0.0063, time: 8.462001]
2023-05-16 11:22:54.127: epoch 131:	0.02674353  	0.19655527  	0.10867505  
2023-05-16 11:23:03.369: [iter 132 : loss : 0.1164 = 0.0267 + 0.0833 + 0.0063, time: 9.239018]
2023-05-16 11:23:03.652: epoch 132:	0.02683527  	0.19698906  	0.10892975  
2023-05-16 11:23:03.652: Find a better model.
2023-05-16 11:23:12.874: [iter 133 : loss : 0.1150 = 0.0254 + 0.0833 + 0.0064, time: 9.221025]
2023-05-16 11:23:13.157: epoch 133:	0.02684232  	0.19703586  	0.10905802  
2023-05-16 11:23:13.157: Find a better model.
2023-05-16 11:23:21.529: [iter 134 : loss : 0.1159 = 0.0262 + 0.0832 + 0.0064, time: 8.370004]
2023-05-16 11:23:21.711: epoch 134:	0.02675764  	0.19641219  	0.10893214  
2023-05-16 11:23:29.914: [iter 135 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 8.201003]
2023-05-16 11:23:30.099: epoch 135:	0.02679997  	0.19650626  	0.10895471  
2023-05-16 11:23:38.141: [iter 136 : loss : 0.1152 = 0.0255 + 0.0832 + 0.0065, time: 8.040013]
2023-05-16 11:23:38.430: epoch 136:	0.02679997  	0.19678868  	0.10902164  
2023-05-16 11:23:47.506: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 9.074109]
2023-05-16 11:23:47.790: epoch 137:	0.02683526  	0.19692978  	0.10907536  
2023-05-16 11:23:56.011: [iter 138 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 8.218995]
2023-05-16 11:23:56.177: epoch 138:	0.02679292  	0.19648439  	0.10897218  
2023-05-16 11:24:03.914: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 7.736039]
2023-05-16 11:24:04.071: epoch 139:	0.02679292  	0.19633313  	0.10895433  
2023-05-16 11:24:12.380: [iter 140 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 8.308030]
2023-05-16 11:24:12.550: epoch 140:	0.02677175  	0.19625099  	0.10890657  
2023-05-16 11:24:21.452: [iter 141 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0066, time: 8.898022]
2023-05-16 11:24:21.737: epoch 141:	0.02679997  	0.19642434  	0.10905980  
2023-05-16 11:24:29.110: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 7.371001]
2023-05-16 11:24:29.269: epoch 142:	0.02677175  	0.19616927  	0.10900658  
2023-05-16 11:24:37.543: [iter 143 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0067, time: 8.273001]
2023-05-16 11:24:37.698: epoch 143:	0.02681408  	0.19657002  	0.10905353  
2023-05-16 11:24:46.102: [iter 144 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 8.403003]
2023-05-16 11:24:46.263: epoch 144:	0.02688466  	0.19730169  	0.10927504  
2023-05-16 11:24:46.263: Find a better model.
2023-05-16 11:24:55.769: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 9.505018]
2023-05-16 11:24:56.053: epoch 145:	0.02686348  	0.19686946  	0.10923544  
2023-05-16 11:25:05.226: [iter 146 : loss : 0.1132 = 0.0237 + 0.0828 + 0.0067, time: 9.169087]
2023-05-16 11:25:05.526: epoch 146:	0.02686348  	0.19694643  	0.10934521  
2023-05-16 11:25:13.996: [iter 147 : loss : 0.1130 = 0.0234 + 0.0828 + 0.0068, time: 8.468012]
2023-05-16 11:25:14.161: epoch 147:	0.02681409  	0.19634594  	0.10916038  
2023-05-16 11:25:23.239: [iter 148 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 9.075751]
2023-05-16 11:25:23.444: epoch 148:	0.02682114  	0.19673045  	0.10927076  
2023-05-16 11:25:31.363: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 7.916641]
2023-05-16 11:25:31.543: epoch 149:	0.02682820  	0.19626202  	0.10922604  
2023-05-16 11:25:40.624: [iter 150 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 9.077171]
2023-05-16 11:25:40.906: epoch 150:	0.02681408  	0.19664276  	0.10936005  
2023-05-16 11:25:49.340: [iter 151 : loss : 0.1118 = 0.0223 + 0.0826 + 0.0069, time: 8.432013]
2023-05-16 11:25:49.505: epoch 151:	0.02684231  	0.19661146  	0.10922124  
2023-05-16 11:25:57.521: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 8.013153]
2023-05-16 11:25:57.685: epoch 152:	0.02684936  	0.19682072  	0.10925405  
2023-05-16 11:26:06.124: [iter 153 : loss : 0.1100 = 0.0205 + 0.0826 + 0.0069, time: 8.435870]
2023-05-16 11:26:06.300: epoch 153:	0.02684937  	0.19696881  	0.10930225  
2023-05-16 11:26:15.360: [iter 154 : loss : 0.1107 = 0.0212 + 0.0826 + 0.0069, time: 9.058022]
2023-05-16 11:26:15.608: epoch 154:	0.02684936  	0.19684416  	0.10951723  
2023-05-16 11:26:23.381: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 7.772460]
2023-05-16 11:26:23.573: epoch 155:	0.02672940  	0.19594900  	0.10924555  
2023-05-16 11:26:32.048: [iter 156 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 8.474021]
2023-05-16 11:26:32.204: epoch 156:	0.02672940  	0.19576705  	0.10924508  
2023-05-16 11:26:40.859: [iter 157 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 8.654067]
2023-05-16 11:26:41.019: epoch 157:	0.02679291  	0.19644190  	0.10942844  
2023-05-16 11:26:50.591: [iter 158 : loss : 0.1099 = 0.0205 + 0.0824 + 0.0070, time: 9.563083]
2023-05-16 11:26:50.877: epoch 158:	0.02677174  	0.19606084  	0.10953461  
2023-05-16 11:27:00.086: [iter 159 : loss : 0.1100 = 0.0206 + 0.0824 + 0.0071, time: 9.205271]
2023-05-16 11:27:00.370: epoch 159:	0.02679291  	0.19630308  	0.10958982  
2023-05-16 11:27:08.656: [iter 160 : loss : 0.1096 = 0.0201 + 0.0823 + 0.0071, time: 8.284997]
2023-05-16 11:27:08.818: epoch 160:	0.02673646  	0.19569689  	0.10939292  
2023-05-16 11:27:17.221: [iter 161 : loss : 0.1091 = 0.0197 + 0.0823 + 0.0071, time: 8.402002]
2023-05-16 11:27:17.373: epoch 161:	0.02672940  	0.19557779  	0.10941040  
2023-05-16 11:27:25.267: [iter 162 : loss : 0.1084 = 0.0190 + 0.0823 + 0.0071, time: 7.892013]
2023-05-16 11:27:25.427: epoch 162:	0.02675762  	0.19580361  	0.10936954  
2023-05-16 11:27:34.421: [iter 163 : loss : 0.1089 = 0.0195 + 0.0823 + 0.0072, time: 8.993042]
2023-05-16 11:27:34.685: epoch 163:	0.02679291  	0.19619372  	0.10959630  
2023-05-16 11:27:43.046: [iter 164 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 8.358987]
2023-05-16 11:27:43.229: epoch 164:	0.02677880  	0.19612090  	0.10948776  
2023-05-16 11:27:51.034: [iter 165 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0072, time: 7.804352]
2023-05-16 11:27:51.200: epoch 165:	0.02674351  	0.19563010  	0.10934833  
2023-05-16 11:27:59.686: [iter 166 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0072, time: 8.484008]
2023-05-16 11:27:59.853: epoch 166:	0.02671529  	0.19549116  	0.10916487  
2023-05-16 11:28:08.874: [iter 167 : loss : 0.1087 = 0.0192 + 0.0822 + 0.0073, time: 9.019021]
2023-05-16 11:28:09.155: epoch 167:	0.02675762  	0.19581433  	0.10931233  
2023-05-16 11:28:16.731: [iter 168 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 7.574013]
2023-05-16 11:28:16.899: epoch 168:	0.02675763  	0.19556592  	0.10939668  
2023-05-16 11:28:25.446: [iter 169 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 8.545009]
2023-05-16 11:28:25.604: epoch 169:	0.02673646  	0.19517694  	0.10925261  
2023-05-16 11:28:25.604: Early stopping is trigger at epoch: 169
2023-05-16 11:28:25.604: best_result@epoch 144:

2023-05-16 11:28:25.604: 		0.0269      	0.1973      	0.1093      
2023-05-16 11:30:55.676: my pid: 4464
2023-05-16 11:30:55.676: model: model.general_recommender.SGL
2023-05-16 11:30:55.676: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 11:30:55.676: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 11:30:58.935: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 11:31:07.603: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.667779]
2023-05-16 11:31:07.765: epoch 1:	0.00127717  	0.00954077  	0.00461937  
2023-05-16 11:31:07.765: Find a better model.
2023-05-16 11:31:17.275: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 9.508032]
2023-05-16 11:31:17.460: epoch 2:	0.00273779  	0.02062503  	0.01006951  
2023-05-16 11:31:17.460: Find a better model.
2023-05-16 11:31:27.226: [iter 3 : loss : 0.7710 = 0.6925 + 0.0785 + 0.0000, time: 9.763144]
2023-05-16 11:31:27.551: epoch 3:	0.00487579  	0.03689504  	0.01791989  
2023-05-16 11:31:27.551: Find a better model.
2023-05-16 11:31:35.620: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.068023]
2023-05-16 11:31:35.798: epoch 4:	0.00804396  	0.05853401  	0.02820212  
2023-05-16 11:31:35.798: Find a better model.
2023-05-16 11:31:44.390: [iter 5 : loss : 0.7695 = 0.6907 + 0.0788 + 0.0000, time: 8.590021]
2023-05-16 11:31:44.555: epoch 5:	0.01164976  	0.08497637  	0.04043231  
2023-05-16 11:31:44.556: Find a better model.
2023-05-16 11:31:53.367: [iter 6 : loss : 0.7670 = 0.6877 + 0.0792 + 0.0000, time: 8.810014]
2023-05-16 11:31:53.534: epoch 6:	0.01502980  	0.10890941  	0.05374001  
2023-05-16 11:31:53.534: Find a better model.
2023-05-16 11:32:03.021: [iter 7 : loss : 0.7601 = 0.6800 + 0.0800 + 0.0000, time: 9.483143]
2023-05-16 11:32:03.289: epoch 7:	0.01787353  	0.12936577  	0.06437853  
2023-05-16 11:32:03.289: Find a better model.
2023-05-16 11:32:12.695: [iter 8 : loss : 0.7431 = 0.6610 + 0.0821 + 0.0001, time: 9.403014]
2023-05-16 11:32:12.989: epoch 8:	0.01881910  	0.13764884  	0.06946768  
2023-05-16 11:32:12.989: Find a better model.
2023-05-16 11:32:21.174: [iter 9 : loss : 0.7054 = 0.6191 + 0.0861 + 0.0001, time: 8.184014]
2023-05-16 11:32:21.361: epoch 9:	0.01857213  	0.13762817  	0.06885132  
2023-05-16 11:32:29.908: [iter 10 : loss : 0.6423 = 0.5504 + 0.0916 + 0.0003, time: 8.545004]
2023-05-16 11:32:30.064: epoch 10:	0.01853684  	0.13719694  	0.06838197  
2023-05-16 11:32:37.953: [iter 11 : loss : 0.5665 = 0.4696 + 0.0965 + 0.0004, time: 7.886642]
2023-05-16 11:32:38.112: epoch 11:	0.01843100  	0.13622586  	0.06805568  
2023-05-16 11:32:47.289: [iter 12 : loss : 0.4992 = 0.3989 + 0.0997 + 0.0006, time: 9.175180]
2023-05-16 11:32:47.587: epoch 12:	0.01848745  	0.13673185  	0.06841151  
2023-05-16 11:32:55.451: [iter 13 : loss : 0.4498 = 0.3476 + 0.1014 + 0.0007, time: 7.862603]
2023-05-16 11:32:55.816: epoch 13:	0.01859329  	0.13749787  	0.06903808  
2023-05-16 11:33:03.587: [iter 14 : loss : 0.4128 = 0.3096 + 0.1024 + 0.0009, time: 7.748919]
2023-05-16 11:33:03.754: epoch 14:	0.01867797  	0.13835913  	0.06959397  
2023-05-16 11:33:03.754: Find a better model.
2023-05-16 11:33:12.066: [iter 15 : loss : 0.3867 = 0.2831 + 0.1026 + 0.0010, time: 8.310138]
2023-05-16 11:33:12.307: epoch 15:	0.01886849  	0.13960044  	0.07035436  
2023-05-16 11:33:12.307: Find a better model.
2023-05-16 11:33:21.480: [iter 16 : loss : 0.3646 = 0.2609 + 0.1026 + 0.0011, time: 9.171041]
2023-05-16 11:33:21.784: epoch 16:	0.01908724  	0.14071964  	0.07104429  
2023-05-16 11:33:21.784: Find a better model.
2023-05-16 11:33:30.946: [iter 17 : loss : 0.3486 = 0.2449 + 0.1024 + 0.0012, time: 9.158449]
2023-05-16 11:33:31.255: epoch 17:	0.01941185  	0.14292327  	0.07226305  
2023-05-16 11:33:31.255: Find a better model.
2023-05-16 11:33:39.550: [iter 18 : loss : 0.3336 = 0.2300 + 0.1022 + 0.0013, time: 8.294214]
2023-05-16 11:33:39.725: epoch 18:	0.01953887  	0.14370102  	0.07280055  
2023-05-16 11:33:39.725: Find a better model.
2023-05-16 11:33:48.177: [iter 19 : loss : 0.3198 = 0.2165 + 0.1019 + 0.0014, time: 8.450004]
2023-05-16 11:33:48.332: epoch 19:	0.01974351  	0.14529097  	0.07380370  
2023-05-16 11:33:48.332: Find a better model.
2023-05-16 11:33:56.124: [iter 20 : loss : 0.3100 = 0.2071 + 0.1014 + 0.0015, time: 7.790470]
2023-05-16 11:33:56.285: epoch 20:	0.01992697  	0.14682606  	0.07468480  
2023-05-16 11:33:56.285: Find a better model.
2023-05-16 11:34:05.549: [iter 21 : loss : 0.3007 = 0.1981 + 0.1010 + 0.0016, time: 9.260278]
2023-05-16 11:34:05.847: epoch 21:	0.02001871  	0.14766759  	0.07528350  
2023-05-16 11:34:05.847: Find a better model.
2023-05-16 11:34:14.106: [iter 22 : loss : 0.2924 = 0.1901 + 0.1007 + 0.0017, time: 8.257004]
2023-05-16 11:34:14.390: epoch 22:	0.02018807  	0.14875008  	0.07611424  
2023-05-16 11:34:14.390: Find a better model.
2023-05-16 11:34:22.142: [iter 23 : loss : 0.2841 = 0.1821 + 0.1003 + 0.0017, time: 7.749763]
2023-05-16 11:34:22.331: epoch 23:	0.02041389  	0.15107016  	0.07700378  
2023-05-16 11:34:22.331: Find a better model.
2023-05-16 11:34:31.167: [iter 24 : loss : 0.2778 = 0.1762 + 0.0998 + 0.0018, time: 8.834006]
2023-05-16 11:34:31.330: epoch 24:	0.02059735  	0.15224406  	0.07785226  
2023-05-16 11:34:31.331: Find a better model.
2023-05-16 11:34:40.478: [iter 25 : loss : 0.2711 = 0.1698 + 0.0994 + 0.0019, time: 9.145035]
2023-05-16 11:34:40.776: epoch 25:	0.02073848  	0.15346225  	0.07860651  
2023-05-16 11:34:40.776: Find a better model.
2023-05-16 11:34:49.524: [iter 26 : loss : 0.2674 = 0.1666 + 0.0989 + 0.0019, time: 8.746323]
2023-05-16 11:34:49.700: epoch 26:	0.02092194  	0.15458338  	0.07951023  
2023-05-16 11:34:49.700: Find a better model.
2023-05-16 11:34:58.387: [iter 27 : loss : 0.2599 = 0.1595 + 0.0984 + 0.0020, time: 8.686253]
2023-05-16 11:34:58.580: epoch 27:	0.02117598  	0.15653221  	0.08058622  
2023-05-16 11:34:58.581: Find a better model.
2023-05-16 11:35:07.278: [iter 28 : loss : 0.2549 = 0.1547 + 0.0981 + 0.0021, time: 8.696026]
2023-05-16 11:35:07.439: epoch 28:	0.02143002  	0.15818848  	0.08139013  
2023-05-16 11:35:07.439: Find a better model.
2023-05-16 11:35:16.480: [iter 29 : loss : 0.2503 = 0.1506 + 0.0976 + 0.0021, time: 9.039558]
2023-05-16 11:35:16.722: epoch 29:	0.02159938  	0.15929450  	0.08199137  
2023-05-16 11:35:16.722: Find a better model.
2023-05-16 11:35:25.871: [iter 30 : loss : 0.2440 = 0.1445 + 0.0973 + 0.0022, time: 9.146426]
2023-05-16 11:35:26.180: epoch 30:	0.02170523  	0.16005193  	0.08257525  
2023-05-16 11:35:26.180: Find a better model.
2023-05-16 11:35:34.447: [iter 31 : loss : 0.2404 = 0.1412 + 0.0969 + 0.0023, time: 8.265550]
2023-05-16 11:35:34.595: epoch 31:	0.02187458  	0.16108887  	0.08328205  
2023-05-16 11:35:34.595: Find a better model.
2023-05-16 11:35:42.459: [iter 32 : loss : 0.2349 = 0.1359 + 0.0966 + 0.0023, time: 7.863107]
2023-05-16 11:35:42.622: epoch 32:	0.02202276  	0.16231938  	0.08389468  
2023-05-16 11:35:42.622: Find a better model.
2023-05-16 11:35:51.259: [iter 33 : loss : 0.2324 = 0.1338 + 0.0962 + 0.0024, time: 8.636229]
2023-05-16 11:35:51.499: epoch 33:	0.02214979  	0.16334903  	0.08439088  
2023-05-16 11:35:51.499: Find a better model.
2023-05-16 11:36:00.541: [iter 34 : loss : 0.2281 = 0.1298 + 0.0959 + 0.0024, time: 9.038891]
2023-05-16 11:36:00.799: epoch 34:	0.02234736  	0.16498123  	0.08515818  
2023-05-16 11:36:00.799: Find a better model.
2023-05-16 11:36:09.352: [iter 35 : loss : 0.2246 = 0.1266 + 0.0955 + 0.0025, time: 8.552040]
2023-05-16 11:36:09.522: epoch 35:	0.02259434  	0.16647933  	0.08600692  
2023-05-16 11:36:09.522: Find a better model.
2023-05-16 11:36:18.106: [iter 36 : loss : 0.2212 = 0.1235 + 0.0952 + 0.0025, time: 8.581378]
2023-05-16 11:36:18.261: epoch 36:	0.02270018  	0.16729864  	0.08662314  
2023-05-16 11:36:18.261: Find a better model.
2023-05-16 11:36:26.858: [iter 37 : loss : 0.2174 = 0.1200 + 0.0948 + 0.0026, time: 8.595147]
2023-05-16 11:36:27.019: epoch 37:	0.02284131  	0.16836388  	0.08718579  
2023-05-16 11:36:27.019: Find a better model.
2023-05-16 11:36:34.899: [iter 38 : loss : 0.2158 = 0.1186 + 0.0945 + 0.0027, time: 7.879019]
2023-05-16 11:36:35.158: epoch 38:	0.02290482  	0.16860795  	0.08767341  
2023-05-16 11:36:35.158: Find a better model.
2023-05-16 11:36:44.291: [iter 39 : loss : 0.2113 = 0.1144 + 0.0942 + 0.0027, time: 9.130270]
2023-05-16 11:36:44.580: epoch 39:	0.02303183  	0.16923437  	0.08822159  
2023-05-16 11:36:44.580: Find a better model.
2023-05-16 11:36:52.826: [iter 40 : loss : 0.2083 = 0.1116 + 0.0940 + 0.0028, time: 8.243692]
2023-05-16 11:36:52.970: epoch 40:	0.02309534  	0.16931684  	0.08854221  
2023-05-16 11:36:52.970: Find a better model.
2023-05-16 11:37:00.803: [iter 41 : loss : 0.2064 = 0.1099 + 0.0937 + 0.0028, time: 7.831012]
2023-05-16 11:37:00.963: epoch 41:	0.02325059  	0.17026512  	0.08918738  
2023-05-16 11:37:00.963: Find a better model.
2023-05-16 11:37:09.701: [iter 42 : loss : 0.2040 = 0.1078 + 0.0934 + 0.0029, time: 8.736003]
2023-05-16 11:37:09.879: epoch 42:	0.02337760  	0.17123283  	0.08985480  
2023-05-16 11:37:09.879: Find a better model.
2023-05-16 11:37:19.061: [iter 43 : loss : 0.2002 = 0.1042 + 0.0931 + 0.0029, time: 9.181036]
2023-05-16 11:37:19.365: epoch 43:	0.02349050  	0.17207575  	0.09050467  
2023-05-16 11:37:19.365: Find a better model.
2023-05-16 11:37:27.535: [iter 44 : loss : 0.1970 = 0.1012 + 0.0928 + 0.0030, time: 8.169003]
2023-05-16 11:37:27.704: epoch 44:	0.02363163  	0.17359504  	0.09122589  
2023-05-16 11:37:27.704: Find a better model.
2023-05-16 11:37:36.405: [iter 45 : loss : 0.1947 = 0.0991 + 0.0926 + 0.0030, time: 8.698012]
2023-05-16 11:37:36.548: epoch 45:	0.02376571  	0.17486577  	0.09210110  
2023-05-16 11:37:36.549: Find a better model.
2023-05-16 11:37:44.820: [iter 46 : loss : 0.1924 = 0.0970 + 0.0923 + 0.0031, time: 8.268014]
2023-05-16 11:37:44.978: epoch 46:	0.02374454  	0.17459765  	0.09234387  
2023-05-16 11:37:53.179: [iter 47 : loss : 0.1917 = 0.0964 + 0.0921 + 0.0031, time: 8.194303]
2023-05-16 11:37:53.474: epoch 47:	0.02375865  	0.17485912  	0.09257325  
2023-05-16 11:38:02.670: [iter 48 : loss : 0.1876 = 0.0926 + 0.0919 + 0.0032, time: 9.189022]
2023-05-16 11:38:02.955: epoch 48:	0.02389979  	0.17604287  	0.09327812  
2023-05-16 11:38:02.956: Find a better model.
2023-05-16 11:38:11.488: [iter 49 : loss : 0.1846 = 0.0898 + 0.0916 + 0.0032, time: 8.531014]
2023-05-16 11:38:11.637: epoch 49:	0.02405503  	0.17737046  	0.09382758  
2023-05-16 11:38:11.637: Find a better model.
2023-05-16 11:38:19.396: [iter 50 : loss : 0.1835 = 0.0888 + 0.0914 + 0.0033, time: 7.757312]
2023-05-16 11:38:19.557: epoch 50:	0.02409736  	0.17780365  	0.09415667  
2023-05-16 11:38:19.557: Find a better model.
2023-05-16 11:38:28.057: [iter 51 : loss : 0.1805 = 0.0860 + 0.0912 + 0.0033, time: 8.497216]
2023-05-16 11:38:28.236: epoch 51:	0.02417498  	0.17829658  	0.09474595  
2023-05-16 11:38:28.236: Find a better model.
2023-05-16 11:38:37.380: [iter 52 : loss : 0.1809 = 0.0864 + 0.0911 + 0.0034, time: 9.140011]
2023-05-16 11:38:37.671: epoch 52:	0.02422437  	0.17858522  	0.09513245  
2023-05-16 11:38:37.671: Find a better model.
2023-05-16 11:38:45.973: [iter 53 : loss : 0.1788 = 0.0845 + 0.0909 + 0.0034, time: 8.301040]
2023-05-16 11:38:46.146: epoch 53:	0.02428788  	0.17860606  	0.09538843  
2023-05-16 11:38:46.147: Find a better model.
2023-05-16 11:38:54.626: [iter 54 : loss : 0.1767 = 0.0827 + 0.0906 + 0.0035, time: 8.478008]
2023-05-16 11:38:54.782: epoch 54:	0.02442195  	0.17979375  	0.09609097  
2023-05-16 11:38:54.782: Find a better model.
2023-05-16 11:39:03.366: [iter 55 : loss : 0.1745 = 0.0806 + 0.0904 + 0.0035, time: 8.582997]
2023-05-16 11:39:03.528: epoch 55:	0.02435139  	0.17906155  	0.09596781  
2023-05-16 11:39:11.422: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 7.892248]
2023-05-16 11:39:11.659: epoch 56:	0.02442196  	0.17969942  	0.09629890  
2023-05-16 11:39:20.850: [iter 57 : loss : 0.1711 = 0.0774 + 0.0901 + 0.0036, time: 9.186016]
2023-05-16 11:39:21.147: epoch 57:	0.02451369  	0.18024391  	0.09669095  
2023-05-16 11:39:21.148: Find a better model.
2023-05-16 11:39:29.371: [iter 58 : loss : 0.1691 = 0.0755 + 0.0899 + 0.0036, time: 8.221992]
2023-05-16 11:39:29.517: epoch 58:	0.02457720  	0.18081468  	0.09717251  
2023-05-16 11:39:29.517: Find a better model.
2023-05-16 11:39:37.360: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 7.842429]
2023-05-16 11:39:37.518: epoch 59:	0.02470422  	0.18175396  	0.09768361  
2023-05-16 11:39:37.518: Find a better model.
2023-05-16 11:39:46.189: [iter 60 : loss : 0.1664 = 0.0731 + 0.0895 + 0.0037, time: 8.668257]
2023-05-16 11:39:46.438: epoch 60:	0.02470422  	0.18171892  	0.09776188  
2023-05-16 11:39:55.482: [iter 61 : loss : 0.1650 = 0.0719 + 0.0893 + 0.0038, time: 9.035025]
2023-05-16 11:39:55.737: epoch 61:	0.02475361  	0.18215373  	0.09809637  
2023-05-16 11:39:55.737: Find a better model.
2023-05-16 11:40:04.311: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 8.573102]
2023-05-16 11:40:04.490: epoch 62:	0.02476067  	0.18217182  	0.09834065  
2023-05-16 11:40:04.490: Find a better model.
2023-05-16 11:40:13.002: [iter 63 : loss : 0.1624 = 0.0695 + 0.0890 + 0.0039, time: 8.509224]
2023-05-16 11:40:13.158: epoch 63:	0.02482417  	0.18250448  	0.09865326  
2023-05-16 11:40:13.158: Find a better model.
2023-05-16 11:40:21.426: [iter 64 : loss : 0.1612 = 0.0684 + 0.0889 + 0.0039, time: 8.265958]
2023-05-16 11:40:21.604: epoch 64:	0.02495825  	0.18360989  	0.09921134  
2023-05-16 11:40:21.604: Find a better model.
2023-05-16 11:40:29.340: [iter 65 : loss : 0.1598 = 0.0671 + 0.0887 + 0.0039, time: 7.735064]
2023-05-16 11:40:29.487: epoch 65:	0.02499353  	0.18332158  	0.09948803  
2023-05-16 11:40:38.653: [iter 66 : loss : 0.1586 = 0.0660 + 0.0886 + 0.0040, time: 9.164016]
2023-05-16 11:40:38.919: epoch 66:	0.02503587  	0.18377163  	0.09989109  
2023-05-16 11:40:38.919: Find a better model.
2023-05-16 11:40:47.322: [iter 67 : loss : 0.1567 = 0.0642 + 0.0884 + 0.0040, time: 8.400999]
2023-05-16 11:40:47.498: epoch 67:	0.02506409  	0.18425304  	0.10008156  
2023-05-16 11:40:47.498: Find a better model.
2023-05-16 11:40:55.327: [iter 68 : loss : 0.1564 = 0.0641 + 0.0883 + 0.0041, time: 7.828147]
2023-05-16 11:40:55.488: epoch 68:	0.02512055  	0.18464833  	0.10035005  
2023-05-16 11:40:55.488: Find a better model.
2023-05-16 11:41:04.149: [iter 69 : loss : 0.1546 = 0.0624 + 0.0881 + 0.0041, time: 8.659003]
2023-05-16 11:41:04.341: epoch 69:	0.02514878  	0.18464817  	0.10037027  
2023-05-16 11:41:13.408: [iter 70 : loss : 0.1529 = 0.0608 + 0.0880 + 0.0042, time: 9.062042]
2023-05-16 11:41:13.667: epoch 70:	0.02523346  	0.18537591  	0.10085989  
2023-05-16 11:41:13.667: Find a better model.
2023-05-16 11:41:22.158: [iter 71 : loss : 0.1514 = 0.0593 + 0.0879 + 0.0042, time: 8.488846]
2023-05-16 11:41:22.365: epoch 71:	0.02526874  	0.18569522  	0.10110296  
2023-05-16 11:41:22.365: Find a better model.
2023-05-16 11:41:30.984: [iter 72 : loss : 0.1513 = 0.0593 + 0.0878 + 0.0042, time: 8.615996]
2023-05-16 11:41:31.138: epoch 72:	0.02531108  	0.18624583  	0.10137312  
2023-05-16 11:41:31.138: Find a better model.
2023-05-16 11:41:39.728: [iter 73 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 8.589026]
2023-05-16 11:41:39.889: epoch 73:	0.02532519  	0.18601274  	0.10143608  
2023-05-16 11:41:47.968: [iter 74 : loss : 0.1485 = 0.0566 + 0.0875 + 0.0043, time: 8.076301]
2023-05-16 11:41:48.263: epoch 74:	0.02541693  	0.18678570  	0.10182153  
2023-05-16 11:41:48.264: Find a better model.
2023-05-16 11:41:57.293: [iter 75 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0044, time: 9.027002]
2023-05-16 11:41:57.589: epoch 75:	0.02540987  	0.18662703  	0.10202098  
2023-05-16 11:42:05.900: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 8.309509]
2023-05-16 11:42:06.056: epoch 76:	0.02545926  	0.18691850  	0.10236123  
2023-05-16 11:42:06.056: Find a better model.
2023-05-16 11:42:13.716: [iter 77 : loss : 0.1458 = 0.0542 + 0.0871 + 0.0044, time: 7.658162]
2023-05-16 11:42:13.878: epoch 77:	0.02551571  	0.18738300  	0.10253999  
2023-05-16 11:42:13.878: Find a better model.
2023-05-16 11:42:22.561: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 8.682173]
2023-05-16 11:42:22.731: epoch 78:	0.02558628  	0.18785132  	0.10273804  
2023-05-16 11:42:22.731: Find a better model.
2023-05-16 11:42:31.803: [iter 79 : loss : 0.1437 = 0.0522 + 0.0869 + 0.0045, time: 9.069149]
2023-05-16 11:42:32.102: epoch 79:	0.02565684  	0.18833187  	0.10274065  
2023-05-16 11:42:32.102: Find a better model.
2023-05-16 11:42:40.692: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 8.587932]
2023-05-16 11:42:40.866: epoch 80:	0.02570624  	0.18883909  	0.10302297  
2023-05-16 11:42:40.866: Find a better model.
2023-05-16 11:42:49.519: [iter 81 : loss : 0.1428 = 0.0514 + 0.0867 + 0.0046, time: 8.651005]
2023-05-16 11:42:49.666: epoch 81:	0.02579091  	0.18928581  	0.10326294  
2023-05-16 11:42:49.666: Find a better model.
2023-05-16 11:42:57.865: [iter 82 : loss : 0.1415 = 0.0503 + 0.0866 + 0.0046, time: 8.197868]
2023-05-16 11:42:58.044: epoch 82:	0.02582619  	0.18982676  	0.10343178  
2023-05-16 11:42:58.045: Find a better model.
2023-05-16 11:43:05.881: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.835479]
2023-05-16 11:43:06.042: epoch 83:	0.02582619  	0.18969293  	0.10385089  
2023-05-16 11:43:15.206: [iter 84 : loss : 0.1403 = 0.0491 + 0.0864 + 0.0047, time: 9.159435]
2023-05-16 11:43:15.486: epoch 84:	0.02584031  	0.18986118  	0.10374746  
2023-05-16 11:43:15.486: Find a better model.
2023-05-16 11:43:23.681: [iter 85 : loss : 0.1392 = 0.0481 + 0.0863 + 0.0048, time: 8.192992]
2023-05-16 11:43:23.845: epoch 85:	0.02589676  	0.19003884  	0.10409524  
2023-05-16 11:43:23.845: Find a better model.
2023-05-16 11:43:31.498: [iter 86 : loss : 0.1392 = 0.0482 + 0.0862 + 0.0048, time: 7.652004]
2023-05-16 11:43:31.657: epoch 86:	0.02591792  	0.19020608  	0.10422067  
2023-05-16 11:43:31.658: Find a better model.
2023-05-16 11:43:40.358: [iter 87 : loss : 0.1365 = 0.0455 + 0.0861 + 0.0048, time: 8.698732]
2023-05-16 11:43:40.535: epoch 87:	0.02600260  	0.19089633  	0.10457656  
2023-05-16 11:43:40.535: Find a better model.
2023-05-16 11:43:49.721: [iter 88 : loss : 0.1358 = 0.0448 + 0.0860 + 0.0049, time: 9.181015]
2023-05-16 11:43:50.014: epoch 88:	0.02604494  	0.19116314  	0.10472650  
2023-05-16 11:43:50.014: Find a better model.
2023-05-16 11:43:59.004: [iter 89 : loss : 0.1354 = 0.0446 + 0.0859 + 0.0049, time: 8.989358]
2023-05-16 11:43:59.182: epoch 89:	0.02605906  	0.19117914  	0.10478480  
2023-05-16 11:43:59.182: Find a better model.
2023-05-16 11:44:07.547: [iter 90 : loss : 0.1362 = 0.0454 + 0.0858 + 0.0049, time: 8.362996]
2023-05-16 11:44:07.708: epoch 90:	0.02600261  	0.19075383  	0.10475465  
2023-05-16 11:44:16.165: [iter 91 : loss : 0.1348 = 0.0441 + 0.0858 + 0.0050, time: 8.455992]
2023-05-16 11:44:16.333: epoch 91:	0.02606612  	0.19118978  	0.10497107  
2023-05-16 11:44:16.333: Find a better model.
2023-05-16 11:44:24.055: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 7.720168]
2023-05-16 11:44:24.221: epoch 92:	0.02612256  	0.19148730  	0.10502862  
2023-05-16 11:44:24.222: Find a better model.
2023-05-16 11:44:33.309: [iter 93 : loss : 0.1343 = 0.0437 + 0.0856 + 0.0051, time: 9.084528]
2023-05-16 11:44:33.608: epoch 93:	0.02612962  	0.19141959  	0.10513567  
2023-05-16 11:44:41.411: [iter 94 : loss : 0.1320 = 0.0414 + 0.0855 + 0.0051, time: 7.800692]
2023-05-16 11:44:41.708: epoch 94:	0.02620724  	0.19239399  	0.10545164  
2023-05-16 11:44:41.708: Find a better model.
2023-05-16 11:44:49.483: [iter 95 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0051, time: 7.773028]
2023-05-16 11:44:49.643: epoch 95:	0.02614373  	0.19166179  	0.10543076  
2023-05-16 11:44:58.165: [iter 96 : loss : 0.1314 = 0.0409 + 0.0854 + 0.0052, time: 8.520002]
2023-05-16 11:44:58.399: epoch 96:	0.02617196  	0.19171742  	0.10552555  
2023-05-16 11:45:07.462: [iter 97 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0052, time: 9.056587]
2023-05-16 11:45:07.771: epoch 97:	0.02616491  	0.19204022  	0.10559975  
2023-05-16 11:45:16.943: [iter 98 : loss : 0.1306 = 0.0401 + 0.0852 + 0.0052, time: 9.168570]
2023-05-16 11:45:17.233: epoch 98:	0.02615079  	0.19168657  	0.10583679  
2023-05-16 11:45:25.651: [iter 99 : loss : 0.1294 = 0.0390 + 0.0851 + 0.0053, time: 8.414992]
2023-05-16 11:45:25.822: epoch 99:	0.02615785  	0.19163485  	0.10587725  
2023-05-16 11:45:34.321: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 8.497541]
2023-05-16 11:45:34.474: epoch 100:	0.02616490  	0.19168539  	0.10591251  
2023-05-16 11:45:42.263: [iter 101 : loss : 0.1287 = 0.0384 + 0.0850 + 0.0053, time: 7.786007]
2023-05-16 11:45:42.430: epoch 101:	0.02621430  	0.19232668  	0.10626441  
2023-05-16 11:45:51.521: [iter 102 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 9.089714]
2023-05-16 11:45:51.819: epoch 102:	0.02621430  	0.19219740  	0.10630093  
2023-05-16 11:45:59.746: [iter 103 : loss : 0.1271 = 0.0369 + 0.0848 + 0.0054, time: 7.924129]
2023-05-16 11:45:59.980: epoch 103:	0.02624252  	0.19230935  	0.10628124  
2023-05-16 11:46:07.853: [iter 104 : loss : 0.1279 = 0.0377 + 0.0848 + 0.0055, time: 7.872054]
2023-05-16 11:46:08.020: epoch 104:	0.02629192  	0.19249620  	0.10657467  
2023-05-16 11:46:08.020: Find a better model.
2023-05-16 11:46:16.581: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 8.560005]
2023-05-16 11:46:16.738: epoch 105:	0.02628486  	0.19262597  	0.10642992  
2023-05-16 11:46:16.738: Find a better model.
2023-05-16 11:46:25.750: [iter 106 : loss : 0.1263 = 0.0361 + 0.0846 + 0.0055, time: 9.010017]
2023-05-16 11:46:26.011: epoch 106:	0.02633426  	0.19257654  	0.10649211  
2023-05-16 11:46:35.126: [iter 107 : loss : 0.1254 = 0.0352 + 0.0846 + 0.0055, time: 9.114455]
2023-05-16 11:46:35.424: epoch 107:	0.02631309  	0.19241166  	0.10664718  
2023-05-16 11:46:43.640: [iter 108 : loss : 0.1254 = 0.0352 + 0.0845 + 0.0056, time: 8.215002]
2023-05-16 11:46:43.818: epoch 108:	0.02631309  	0.19259414  	0.10688792  
2023-05-16 11:46:52.323: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 8.504119]
2023-05-16 11:46:52.474: epoch 109:	0.02639776  	0.19336668  	0.10707065  
2023-05-16 11:46:52.474: Find a better model.
2023-05-16 11:47:00.441: [iter 110 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 7.966042]
2023-05-16 11:47:00.598: epoch 110:	0.02634131  	0.19291912  	0.10688988  
2023-05-16 11:47:09.790: [iter 111 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 9.190055]
2023-05-16 11:47:10.086: epoch 111:	0.02632720  	0.19289495  	0.10691871  
2023-05-16 11:47:17.948: [iter 112 : loss : 0.1230 = 0.0331 + 0.0843 + 0.0057, time: 7.861028]
2023-05-16 11:47:18.103: epoch 112:	0.02640482  	0.19360206  	0.10718457  
2023-05-16 11:47:18.103: Find a better model.
2023-05-16 11:47:26.013: [iter 113 : loss : 0.1232 = 0.0332 + 0.0842 + 0.0058, time: 7.907015]
2023-05-16 11:47:26.179: epoch 113:	0.02639776  	0.19388545  	0.10737740  
2023-05-16 11:47:26.179: Find a better model.
2023-05-16 11:47:34.743: [iter 114 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 8.563012]
2023-05-16 11:47:34.910: epoch 114:	0.02642599  	0.19391282  	0.10742586  
2023-05-16 11:47:34.910: Find a better model.
2023-05-16 11:47:44.140: [iter 115 : loss : 0.1217 = 0.0317 + 0.0841 + 0.0058, time: 9.227020]
2023-05-16 11:47:44.437: epoch 115:	0.02640482  	0.19369756  	0.10732128  
2023-05-16 11:47:53.668: [iter 116 : loss : 0.1207 = 0.0308 + 0.0841 + 0.0059, time: 9.228013]
2023-05-16 11:47:53.964: epoch 116:	0.02642599  	0.19384030  	0.10747309  
2023-05-16 11:48:02.186: [iter 117 : loss : 0.1208 = 0.0310 + 0.0840 + 0.0059, time: 8.220007]
2023-05-16 11:48:02.389: epoch 117:	0.02651067  	0.19469869  	0.10783266  
2023-05-16 11:48:02.389: Find a better model.
2023-05-16 11:48:10.544: [iter 118 : loss : 0.1209 = 0.0310 + 0.0839 + 0.0059, time: 8.150030]
2023-05-16 11:48:11.117: epoch 118:	0.02644717  	0.19417630  	0.10758249  
2023-05-16 11:48:19.155: [iter 119 : loss : 0.1198 = 0.0300 + 0.0839 + 0.0060, time: 8.037377]
2023-05-16 11:48:19.316: epoch 119:	0.02643305  	0.19396034  	0.10747975  
2023-05-16 11:48:28.391: [iter 120 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 9.072006]
2023-05-16 11:48:28.685: epoch 120:	0.02642599  	0.19394691  	0.10750529  
2023-05-16 11:48:36.467: [iter 121 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0060, time: 7.781010]
2023-05-16 11:48:36.623: epoch 121:	0.02638366  	0.19351648  	0.10755012  
2023-05-16 11:48:44.581: [iter 122 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0060, time: 7.957194]
2023-05-16 11:48:44.749: epoch 122:	0.02644716  	0.19414599  	0.10762016  
2023-05-16 11:48:53.223: [iter 123 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 8.471065]
2023-05-16 11:48:53.439: epoch 123:	0.02637660  	0.19360472  	0.10749082  
2023-05-16 11:49:02.724: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 9.283064]
2023-05-16 11:49:03.005: epoch 124:	0.02634132  	0.19312289  	0.10748076  
2023-05-16 11:49:12.102: [iter 125 : loss : 0.1174 = 0.0277 + 0.0836 + 0.0061, time: 9.094028]
2023-05-16 11:49:12.396: epoch 125:	0.02626370  	0.19262119  	0.10725228  
2023-05-16 11:49:20.585: [iter 126 : loss : 0.1177 = 0.0280 + 0.0836 + 0.0062, time: 8.187017]
2023-05-16 11:49:20.753: epoch 126:	0.02634837  	0.19350809  	0.10758238  
2023-05-16 11:49:28.782: [iter 127 : loss : 0.1166 = 0.0269 + 0.0835 + 0.0062, time: 8.027008]
2023-05-16 11:49:28.943: epoch 127:	0.02639777  	0.19368534  	0.10771743  
2023-05-16 11:49:37.335: [iter 128 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 8.389498]
2023-05-16 11:49:37.492: epoch 128:	0.02631309  	0.19351710  	0.10779322  
2023-05-16 11:49:46.598: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 9.102016]
2023-05-16 11:49:46.858: epoch 129:	0.02629899  	0.19361931  	0.10799309  
2023-05-16 11:49:54.221: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.361034]
2023-05-16 11:49:54.382: epoch 130:	0.02634132  	0.19382192  	0.10802336  
2023-05-16 11:50:02.533: [iter 131 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0063, time: 8.150053]
2023-05-16 11:50:02.691: epoch 131:	0.02629898  	0.19323343  	0.10787772  
2023-05-16 11:50:11.153: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 8.460017]
2023-05-16 11:50:11.315: epoch 132:	0.02634131  	0.19323587  	0.10771643  
2023-05-16 11:50:20.442: [iter 133 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0064, time: 9.125543]
2023-05-16 11:50:20.738: epoch 133:	0.02634837  	0.19344826  	0.10775807  
2023-05-16 11:50:29.810: [iter 134 : loss : 0.1158 = 0.0261 + 0.0832 + 0.0064, time: 9.071007]
2023-05-16 11:50:30.110: epoch 134:	0.02634837  	0.19322240  	0.10796241  
2023-05-16 11:50:38.308: [iter 135 : loss : 0.1154 = 0.0258 + 0.0832 + 0.0064, time: 8.197043]
2023-05-16 11:50:38.540: epoch 135:	0.02633426  	0.19343224  	0.10800737  
2023-05-16 11:50:46.353: [iter 136 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 7.812009]
2023-05-16 11:50:46.512: epoch 136:	0.02624253  	0.19284911  	0.10783709  
2023-05-16 11:50:54.804: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 8.290129]
2023-05-16 11:50:54.961: epoch 137:	0.02627780  	0.19296288  	0.10782628  
2023-05-16 11:51:03.908: [iter 138 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0065, time: 8.943024]
2023-05-16 11:51:04.204: epoch 138:	0.02623546  	0.19276957  	0.10777283  
2023-05-16 11:51:12.282: [iter 139 : loss : 0.1140 = 0.0244 + 0.0830 + 0.0066, time: 8.077045]
2023-05-16 11:51:12.474: epoch 139:	0.02629898  	0.19332466  	0.10810842  
2023-05-16 11:51:20.768: [iter 140 : loss : 0.1136 = 0.0241 + 0.0830 + 0.0066, time: 8.292053]
2023-05-16 11:51:20.932: epoch 140:	0.02631308  	0.19354735  	0.10815495  
2023-05-16 11:51:29.413: [iter 141 : loss : 0.1139 = 0.0244 + 0.0829 + 0.0066, time: 8.480025]
2023-05-16 11:51:29.577: epoch 141:	0.02628486  	0.19329794  	0.10817461  
2023-05-16 11:51:37.332: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 7.754021]
2023-05-16 11:51:37.489: epoch 142:	0.02626370  	0.19326985  	0.10808558  
2023-05-16 11:51:37.489: Early stopping is trigger at epoch: 142
2023-05-16 11:51:37.489: best_result@epoch 117:

2023-05-16 11:51:37.489: 		0.0265      	0.1947      	0.1078      
2023-05-16 14:32:21.727: my pid: 10644
2023-05-16 14:32:21.727: model: model.general_recommender.SGL
2023-05-16 14:32:21.727: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 14:32:21.727: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 14:32:24.763: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 14:32:32.968: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.205096]
2023-05-16 14:32:33.125: epoch 1:	0.00155236  	0.01105782  	0.00554478  
2023-05-16 14:32:33.126: Find a better model.
2023-05-16 14:32:41.947: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.820693]
2023-05-16 14:32:42.167: epoch 2:	0.00271662  	0.02009726  	0.01031822  
2023-05-16 14:32:42.167: Find a better model.
2023-05-16 14:32:50.467: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.298898]
2023-05-16 14:32:50.641: epoch 3:	0.00510158  	0.03808971  	0.01862350  
2023-05-16 14:32:50.641: Find a better model.
2023-05-16 14:32:58.821: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.178087]
2023-05-16 14:32:58.988: epoch 4:	0.00805102  	0.05915865  	0.02905325  
2023-05-16 14:32:58.988: Find a better model.
2023-05-16 14:33:07.010: [iter 5 : loss : 0.7695 = 0.6907 + 0.0788 + 0.0000, time: 8.021717]
2023-05-16 14:33:07.172: epoch 5:	0.01195319  	0.08686140  	0.04200723  
2023-05-16 14:33:07.172: Find a better model.
2023-05-16 14:33:14.909: [iter 6 : loss : 0.7671 = 0.6878 + 0.0792 + 0.0000, time: 7.735243]
2023-05-16 14:33:15.076: epoch 6:	0.01536143  	0.11073162  	0.05472922  
2023-05-16 14:33:15.076: Find a better model.
2023-05-16 14:33:22.993: [iter 7 : loss : 0.7603 = 0.6802 + 0.0800 + 0.0000, time: 7.915296]
2023-05-16 14:33:23.152: epoch 7:	0.01785234  	0.13049310  	0.06508181  
2023-05-16 14:33:23.152: Find a better model.
2023-05-16 14:33:30.858: [iter 8 : loss : 0.7435 = 0.6614 + 0.0820 + 0.0001, time: 7.705003]
2023-05-16 14:33:31.044: epoch 8:	0.01886849  	0.13830085  	0.06947340  
2023-05-16 14:33:31.044: Find a better model.
2023-05-16 14:33:38.437: [iter 9 : loss : 0.7062 = 0.6200 + 0.0861 + 0.0001, time: 7.390994]
2023-05-16 14:33:38.599: epoch 9:	0.01870619  	0.13801283  	0.06895508  
2023-05-16 14:33:46.485: [iter 10 : loss : 0.6433 = 0.5514 + 0.0916 + 0.0003, time: 7.883968]
2023-05-16 14:33:46.721: epoch 10:	0.01850861  	0.13723436  	0.06813453  
2023-05-16 14:33:54.675: [iter 11 : loss : 0.5675 = 0.4706 + 0.0965 + 0.0004, time: 7.952650]
2023-05-16 14:33:54.865: epoch 11:	0.01825458  	0.13503817  	0.06723113  
2023-05-16 14:34:03.292: [iter 12 : loss : 0.4998 = 0.3994 + 0.0998 + 0.0006, time: 8.424130]
2023-05-16 14:34:03.459: epoch 12:	0.01825458  	0.13492244  	0.06756811  
2023-05-16 14:34:12.431: [iter 13 : loss : 0.4504 = 0.3481 + 0.1016 + 0.0007, time: 8.969094]
2023-05-16 14:34:12.729: epoch 13:	0.01831809  	0.13583836  	0.06817719  
2023-05-16 14:34:21.822: [iter 14 : loss : 0.4131 = 0.3097 + 0.1025 + 0.0009, time: 9.091520]
2023-05-16 14:34:22.083: epoch 14:	0.01860740  	0.13823487  	0.06931999  
2023-05-16 14:34:30.164: [iter 15 : loss : 0.3871 = 0.2832 + 0.1029 + 0.0010, time: 8.078498]
2023-05-16 14:34:30.343: epoch 15:	0.01892494  	0.14065365  	0.07027322  
2023-05-16 14:34:30.343: Find a better model.
2023-05-16 14:34:37.626: [iter 16 : loss : 0.3652 = 0.2613 + 0.1028 + 0.0011, time: 7.281204]
2023-05-16 14:34:37.786: epoch 16:	0.01913663  	0.14180750  	0.07116394  
2023-05-16 14:34:37.786: Find a better model.
2023-05-16 14:34:46.158: [iter 17 : loss : 0.3491 = 0.2452 + 0.1026 + 0.0012, time: 8.369993]
2023-05-16 14:34:46.322: epoch 17:	0.01934833  	0.14353098  	0.07216974  
2023-05-16 14:34:46.322: Find a better model.
2023-05-16 14:34:55.432: [iter 18 : loss : 0.3340 = 0.2304 + 0.1023 + 0.0013, time: 9.106027]
2023-05-16 14:34:55.748: epoch 18:	0.01948947  	0.14396520  	0.07283923  
2023-05-16 14:34:55.748: Find a better model.
2023-05-16 14:35:04.983: [iter 19 : loss : 0.3201 = 0.2168 + 0.1020 + 0.0014, time: 9.233020]
2023-05-16 14:35:05.189: epoch 19:	0.01975057  	0.14620003  	0.07370418  
2023-05-16 14:35:05.189: Find a better model.
2023-05-16 14:35:13.403: [iter 20 : loss : 0.3106 = 0.2075 + 0.1016 + 0.0015, time: 8.213235]
2023-05-16 14:35:13.578: epoch 20:	0.01991286  	0.14688246  	0.07436961  
2023-05-16 14:35:13.579: Find a better model.
2023-05-16 14:35:22.138: [iter 21 : loss : 0.3012 = 0.1984 + 0.1012 + 0.0016, time: 8.558338]
2023-05-16 14:35:22.302: epoch 21:	0.02005400  	0.14819343  	0.07489042  
2023-05-16 14:35:22.302: Find a better model.
2023-05-16 14:35:30.134: [iter 22 : loss : 0.2930 = 0.1906 + 0.1008 + 0.0017, time: 7.831041]
2023-05-16 14:35:30.291: epoch 22:	0.02028686  	0.14986491  	0.07570914  
2023-05-16 14:35:30.292: Find a better model.
2023-05-16 14:35:39.402: [iter 23 : loss : 0.2850 = 0.1830 + 0.1004 + 0.0017, time: 9.108431]
2023-05-16 14:35:39.669: epoch 23:	0.02047033  	0.15119535  	0.07644786  
2023-05-16 14:35:39.669: Find a better model.
2023-05-16 14:35:47.173: [iter 24 : loss : 0.2783 = 0.1766 + 0.0999 + 0.0018, time: 7.503006]
2023-05-16 14:35:47.333: epoch 24:	0.02058323  	0.15242667  	0.07716630  
2023-05-16 14:35:47.334: Find a better model.
2023-05-16 14:35:55.338: [iter 25 : loss : 0.2720 = 0.1706 + 0.0995 + 0.0019, time: 8.002258]
2023-05-16 14:35:55.496: epoch 25:	0.02086549  	0.15454966  	0.07813593  
2023-05-16 14:35:55.496: Find a better model.
2023-05-16 14:36:03.953: [iter 26 : loss : 0.2682 = 0.1672 + 0.0991 + 0.0019, time: 8.456003]
2023-05-16 14:36:04.116: epoch 26:	0.02098545  	0.15487394  	0.07870042  
2023-05-16 14:36:04.116: Find a better model.
2023-05-16 14:36:12.621: [iter 27 : loss : 0.2605 = 0.1599 + 0.0986 + 0.0020, time: 8.503205]
2023-05-16 14:36:12.903: epoch 27:	0.02125360  	0.15675196  	0.07962054  
2023-05-16 14:36:12.903: Find a better model.
2023-05-16 14:36:22.001: [iter 28 : loss : 0.2556 = 0.1553 + 0.0982 + 0.0021, time: 9.095349]
2023-05-16 14:36:22.297: epoch 28:	0.02138768  	0.15779294  	0.08062198  
2023-05-16 14:36:22.297: Find a better model.
2023-05-16 14:36:30.471: [iter 29 : loss : 0.2510 = 0.1511 + 0.0977 + 0.0021, time: 8.172376]
2023-05-16 14:36:30.630: epoch 29:	0.02154292  	0.15860233  	0.08114690  
2023-05-16 14:36:30.630: Find a better model.
2023-05-16 14:36:38.303: [iter 30 : loss : 0.2448 = 0.1451 + 0.0974 + 0.0022, time: 7.671007]
2023-05-16 14:36:38.464: epoch 30:	0.02171934  	0.16044602  	0.08211055  
2023-05-16 14:36:38.464: Find a better model.
2023-05-16 14:36:46.974: [iter 31 : loss : 0.2412 = 0.1419 + 0.0970 + 0.0023, time: 8.509165]
2023-05-16 14:36:47.131: epoch 31:	0.02187458  	0.16166323  	0.08286785  
2023-05-16 14:36:47.131: Find a better model.
2023-05-16 14:36:56.061: [iter 32 : loss : 0.2354 = 0.1364 + 0.0967 + 0.0023, time: 8.927100]
2023-05-16 14:36:56.373: epoch 32:	0.02209333  	0.16332342  	0.08353073  
2023-05-16 14:36:56.373: Find a better model.
2023-05-16 14:37:05.419: [iter 33 : loss : 0.2328 = 0.1342 + 0.0963 + 0.0024, time: 9.041510]
2023-05-16 14:37:05.672: epoch 33:	0.02216390  	0.16394575  	0.08408707  
2023-05-16 14:37:05.672: Find a better model.
2023-05-16 14:37:13.714: [iter 34 : loss : 0.2285 = 0.1302 + 0.0959 + 0.0024, time: 8.040089]
2023-05-16 14:37:13.869: epoch 34:	0.02230502  	0.16512690  	0.08484646  
2023-05-16 14:37:13.869: Find a better model.
2023-05-16 14:37:21.715: [iter 35 : loss : 0.2253 = 0.1271 + 0.0957 + 0.0025, time: 7.844059]
2023-05-16 14:37:21.868: epoch 35:	0.02247437  	0.16661856  	0.08557335  
2023-05-16 14:37:21.868: Find a better model.
2023-05-16 14:37:29.895: [iter 36 : loss : 0.2218 = 0.1240 + 0.0953 + 0.0025, time: 8.024996]
2023-05-16 14:37:30.048: epoch 36:	0.02250966  	0.16680411  	0.08587540  
2023-05-16 14:37:30.049: Find a better model.
2023-05-16 14:37:38.958: [iter 37 : loss : 0.2179 = 0.1204 + 0.0950 + 0.0026, time: 8.906015]
2023-05-16 14:37:39.250: epoch 37:	0.02262962  	0.16770840  	0.08644962  
2023-05-16 14:37:39.250: Find a better model.
2023-05-16 14:37:46.791: [iter 38 : loss : 0.2161 = 0.1187 + 0.0947 + 0.0026, time: 7.540003]
2023-05-16 14:37:46.979: epoch 38:	0.02282720  	0.16895600  	0.08724716  
2023-05-16 14:37:46.980: Find a better model.
2023-05-16 14:37:55.328: [iter 39 : loss : 0.2118 = 0.1148 + 0.0943 + 0.0027, time: 8.346992]
2023-05-16 14:37:55.482: epoch 39:	0.02296833  	0.16995452  	0.08800859  
2023-05-16 14:37:55.482: Find a better model.
2023-05-16 14:38:03.778: [iter 40 : loss : 0.2086 = 0.1118 + 0.0940 + 0.0028, time: 8.294730]
2023-05-16 14:38:03.951: epoch 40:	0.02306006  	0.17093763  	0.08865346  
2023-05-16 14:38:03.952: Find a better model.
2023-05-16 14:38:11.680: [iter 41 : loss : 0.2069 = 0.1103 + 0.0937 + 0.0028, time: 7.727008]
2023-05-16 14:38:11.837: epoch 41:	0.02309535  	0.17075996  	0.08906352  
2023-05-16 14:38:20.932: [iter 42 : loss : 0.2045 = 0.1082 + 0.0935 + 0.0029, time: 9.093273]
2023-05-16 14:38:21.236: epoch 42:	0.02327176  	0.17213430  	0.08991109  
2023-05-16 14:38:21.237: Find a better model.
2023-05-16 14:38:28.691: [iter 43 : loss : 0.2006 = 0.1045 + 0.0932 + 0.0029, time: 7.453304]
2023-05-16 14:38:28.848: epoch 43:	0.02344111  	0.17344441  	0.09068588  
2023-05-16 14:38:28.848: Find a better model.
2023-05-16 14:38:36.871: [iter 44 : loss : 0.1972 = 0.1014 + 0.0929 + 0.0030, time: 8.022016]
2023-05-16 14:38:37.031: epoch 44:	0.02353284  	0.17427225  	0.09123982  
2023-05-16 14:38:37.031: Find a better model.
2023-05-16 14:38:45.505: [iter 45 : loss : 0.1950 = 0.0993 + 0.0927 + 0.0030, time: 8.472999]
2023-05-16 14:38:45.664: epoch 45:	0.02368103  	0.17502166  	0.09187266  
2023-05-16 14:38:45.664: Find a better model.
2023-05-16 14:38:54.058: [iter 46 : loss : 0.1926 = 0.0971 + 0.0924 + 0.0031, time: 8.391025]
2023-05-16 14:38:54.355: epoch 46:	0.02372338  	0.17519052  	0.09224373  
2023-05-16 14:38:54.355: Find a better model.
2023-05-16 14:39:03.497: [iter 47 : loss : 0.1919 = 0.0966 + 0.0922 + 0.0031, time: 9.140018]
2023-05-16 14:39:03.800: epoch 47:	0.02380806  	0.17582743  	0.09261023  
2023-05-16 14:39:03.800: Find a better model.
2023-05-16 14:39:11.975: [iter 48 : loss : 0.1879 = 0.0928 + 0.0920 + 0.0032, time: 8.173992]
2023-05-16 14:39:12.120: epoch 48:	0.02387157  	0.17643337  	0.09322570  
2023-05-16 14:39:12.120: Find a better model.
2023-05-16 14:39:19.879: [iter 49 : loss : 0.1846 = 0.0897 + 0.0917 + 0.0032, time: 7.758173]
2023-05-16 14:39:20.051: epoch 49:	0.02404797  	0.17773721  	0.09380814  
2023-05-16 14:39:20.051: Find a better model.
2023-05-16 14:39:28.763: [iter 50 : loss : 0.1840 = 0.0892 + 0.0915 + 0.0033, time: 8.710005]
2023-05-16 14:39:28.936: epoch 50:	0.02413971  	0.17847693  	0.09424412  
2023-05-16 14:39:28.937: Find a better model.
2023-05-16 14:39:37.960: [iter 51 : loss : 0.1808 = 0.0862 + 0.0913 + 0.0033, time: 9.014822]
2023-05-16 14:39:38.250: epoch 51:	0.02423850  	0.17923164  	0.09472980  
2023-05-16 14:39:38.251: Find a better model.
2023-05-16 14:39:47.407: [iter 52 : loss : 0.1810 = 0.0865 + 0.0911 + 0.0034, time: 9.153011]
2023-05-16 14:39:47.694: epoch 52:	0.02430907  	0.17980507  	0.09499290  
2023-05-16 14:39:47.694: Find a better model.
2023-05-16 14:39:55.672: [iter 53 : loss : 0.1789 = 0.0847 + 0.0908 + 0.0034, time: 7.976991]
2023-05-16 14:39:55.831: epoch 53:	0.02435141  	0.18033823  	0.09555607  
2023-05-16 14:39:55.831: Find a better model.
2023-05-16 14:40:03.777: [iter 54 : loss : 0.1766 = 0.0825 + 0.0906 + 0.0034, time: 7.944012]
2023-05-16 14:40:04.379: epoch 54:	0.02442903  	0.18063161  	0.09588926  
2023-05-16 14:40:04.379: Find a better model.
2023-05-16 14:40:12.234: [iter 55 : loss : 0.1750 = 0.0810 + 0.0905 + 0.0035, time: 7.854018]
2023-05-16 14:40:12.391: epoch 55:	0.02457015  	0.18166995  	0.09632728  
2023-05-16 14:40:12.391: Find a better model.
2023-05-16 14:40:21.481: [iter 56 : loss : 0.1731 = 0.0793 + 0.0903 + 0.0035, time: 9.087022]
2023-05-16 14:40:21.768: epoch 56:	0.02466894  	0.18228024  	0.09672178  
2023-05-16 14:40:21.768: Find a better model.
2023-05-16 14:40:29.196: [iter 57 : loss : 0.1710 = 0.0774 + 0.0901 + 0.0036, time: 7.426807]
2023-05-16 14:40:29.362: epoch 57:	0.02473245  	0.18277828  	0.09722952  
2023-05-16 14:40:29.362: Find a better model.
2023-05-16 14:40:37.456: [iter 58 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 8.093013]
2023-05-16 14:40:37.613: epoch 58:	0.02473951  	0.18308431  	0.09757569  
2023-05-16 14:40:37.613: Find a better model.
2023-05-16 14:40:45.863: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 8.248992]
2023-05-16 14:40:46.022: epoch 59:	0.02483829  	0.18363930  	0.09791737  
2023-05-16 14:40:46.022: Find a better model.
2023-05-16 14:40:53.622: [iter 60 : loss : 0.1666 = 0.0733 + 0.0896 + 0.0037, time: 7.598016]
2023-05-16 14:40:53.781: epoch 60:	0.02487358  	0.18399990  	0.09840579  
2023-05-16 14:40:53.782: Find a better model.
2023-05-16 14:41:02.849: [iter 61 : loss : 0.1654 = 0.0722 + 0.0894 + 0.0038, time: 9.065022]
2023-05-16 14:41:03.136: epoch 61:	0.02487358  	0.18390250  	0.09867216  
2023-05-16 14:41:11.034: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 7.897012]
2023-05-16 14:41:11.477: epoch 62:	0.02493002  	0.18449816  	0.09887980  
2023-05-16 14:41:11.477: Find a better model.
2023-05-16 14:41:19.229: [iter 63 : loss : 0.1624 = 0.0695 + 0.0891 + 0.0039, time: 7.751033]
2023-05-16 14:41:19.391: epoch 63:	0.02503587  	0.18511911  	0.09931038  
2023-05-16 14:41:19.391: Find a better model.
2023-05-16 14:41:27.891: [iter 64 : loss : 0.1615 = 0.0687 + 0.0889 + 0.0039, time: 8.498026]
2023-05-16 14:41:28.104: epoch 64:	0.02513467  	0.18589939  	0.09975716  
2023-05-16 14:41:28.105: Find a better model.
2023-05-16 14:41:37.229: [iter 65 : loss : 0.1600 = 0.0673 + 0.0888 + 0.0039, time: 9.122003]
2023-05-16 14:41:37.493: epoch 65:	0.02516995  	0.18625376  	0.10002001  
2023-05-16 14:41:37.493: Find a better model.
2023-05-16 14:41:46.641: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 9.144013]
2023-05-16 14:41:46.938: epoch 66:	0.02531108  	0.18726245  	0.10051402  
2023-05-16 14:41:46.938: Find a better model.
2023-05-16 14:41:55.047: [iter 67 : loss : 0.1569 = 0.0645 + 0.0885 + 0.0040, time: 8.107001]
2023-05-16 14:41:55.196: epoch 67:	0.02525463  	0.18687744  	0.10038962  
2023-05-16 14:42:02.994: [iter 68 : loss : 0.1565 = 0.0641 + 0.0883 + 0.0041, time: 7.797022]
2023-05-16 14:42:03.155: epoch 68:	0.02531108  	0.18747111  	0.10061781  
2023-05-16 14:42:03.156: Find a better model.
2023-05-16 14:42:11.386: [iter 69 : loss : 0.1546 = 0.0623 + 0.0882 + 0.0041, time: 8.229002]
2023-05-16 14:42:11.544: epoch 69:	0.02537459  	0.18775363  	0.10074855  
2023-05-16 14:42:11.544: Find a better model.
2023-05-16 14:42:20.504: [iter 70 : loss : 0.1531 = 0.0609 + 0.0881 + 0.0041, time: 8.958033]
2023-05-16 14:42:20.764: epoch 70:	0.02542398  	0.18804115  	0.10104381  
2023-05-16 14:42:20.764: Find a better model.
2023-05-16 14:42:28.640: [iter 71 : loss : 0.1514 = 0.0593 + 0.0879 + 0.0042, time: 7.873017]
2023-05-16 14:42:28.805: epoch 71:	0.02540987  	0.18786608  	0.10135590  
2023-05-16 14:42:37.035: [iter 72 : loss : 0.1514 = 0.0593 + 0.0878 + 0.0042, time: 8.227037]
2023-05-16 14:42:37.184: epoch 72:	0.02546633  	0.18860182  	0.10166645  
2023-05-16 14:42:37.184: Find a better model.
2023-05-16 14:42:45.515: [iter 73 : loss : 0.1500 = 0.0581 + 0.0877 + 0.0043, time: 8.329992]
2023-05-16 14:42:45.681: epoch 73:	0.02551572  	0.18879788  	0.10183049  
2023-05-16 14:42:45.681: Find a better model.
2023-05-16 14:42:53.387: [iter 74 : loss : 0.1485 = 0.0566 + 0.0876 + 0.0043, time: 7.705503]
2023-05-16 14:42:53.545: epoch 74:	0.02552983  	0.18909173  	0.10210646  
2023-05-16 14:42:53.545: Find a better model.
2023-05-16 14:43:02.642: [iter 75 : loss : 0.1481 = 0.0563 + 0.0875 + 0.0044, time: 9.093463]
2023-05-16 14:43:02.940: epoch 75:	0.02560038  	0.18945055  	0.10241532  
2023-05-16 14:43:02.940: Find a better model.
2023-05-16 14:43:10.309: [iter 76 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 7.366015]
2023-05-16 14:43:10.470: epoch 76:	0.02565684  	0.18967286  	0.10280402  
2023-05-16 14:43:10.470: Find a better model.
2023-05-16 14:43:18.548: [iter 77 : loss : 0.1460 = 0.0543 + 0.0872 + 0.0044, time: 8.076023]
2023-05-16 14:43:18.708: epoch 77:	0.02568507  	0.18968555  	0.10287043  
2023-05-16 14:43:18.709: Find a better model.
2023-05-16 14:43:27.132: [iter 78 : loss : 0.1451 = 0.0535 + 0.0871 + 0.0045, time: 8.422008]
2023-05-16 14:43:27.293: epoch 78:	0.02572740  	0.19016813  	0.10304198  
2023-05-16 14:43:27.293: Find a better model.
2023-05-16 14:43:35.397: [iter 79 : loss : 0.1436 = 0.0521 + 0.0870 + 0.0045, time: 8.101021]
2023-05-16 14:43:35.696: epoch 79:	0.02575563  	0.19000733  	0.10305345  
2023-05-16 14:43:44.789: [iter 80 : loss : 0.1431 = 0.0517 + 0.0869 + 0.0046, time: 9.090034]
2023-05-16 14:43:45.060: epoch 80:	0.02577680  	0.19015093  	0.10343772  
2023-05-16 14:43:53.447: [iter 81 : loss : 0.1428 = 0.0514 + 0.0868 + 0.0046, time: 8.385992]
2023-05-16 14:43:53.607: epoch 81:	0.02576974  	0.19036219  	0.10353670  
2023-05-16 14:43:53.607: Find a better model.
2023-05-16 14:44:01.378: [iter 82 : loss : 0.1413 = 0.0500 + 0.0867 + 0.0046, time: 7.770474]
2023-05-16 14:44:01.542: epoch 82:	0.02579796  	0.19035614  	0.10355474  
2023-05-16 14:44:10.207: [iter 83 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 8.664023]
2023-05-16 14:44:10.373: epoch 83:	0.02578385  	0.19027527  	0.10369740  
2023-05-16 14:44:19.561: [iter 84 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 9.178007]
2023-05-16 14:44:19.855: epoch 84:	0.02584736  	0.19099875  	0.10402210  
2023-05-16 14:44:19.855: Find a better model.
2023-05-16 14:44:28.976: [iter 85 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 9.118320]
2023-05-16 14:44:29.271: epoch 85:	0.02588971  	0.19123307  	0.10440072  
2023-05-16 14:44:29.271: Find a better model.
2023-05-16 14:44:37.355: [iter 86 : loss : 0.1393 = 0.0482 + 0.0862 + 0.0048, time: 8.082992]
2023-05-16 14:44:37.519: epoch 86:	0.02579797  	0.19059660  	0.10430142  
2023-05-16 14:44:45.627: [iter 87 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0048, time: 8.106992]
2023-05-16 14:44:46.201: epoch 87:	0.02584031  	0.19102362  	0.10447767  
2023-05-16 14:44:54.119: [iter 88 : loss : 0.1357 = 0.0448 + 0.0860 + 0.0049, time: 7.916534]
2023-05-16 14:44:54.278: epoch 88:	0.02587559  	0.19141106  	0.10477483  
2023-05-16 14:44:54.278: Find a better model.
2023-05-16 14:45:03.300: [iter 89 : loss : 0.1358 = 0.0450 + 0.0860 + 0.0049, time: 9.018013]
2023-05-16 14:45:03.588: epoch 89:	0.02588264  	0.19116594  	0.10490281  
2023-05-16 14:45:10.982: [iter 90 : loss : 0.1362 = 0.0453 + 0.0859 + 0.0049, time: 7.392016]
2023-05-16 14:45:11.143: epoch 90:	0.02588970  	0.19138521  	0.10503148  
2023-05-16 14:45:19.127: [iter 91 : loss : 0.1347 = 0.0440 + 0.0858 + 0.0050, time: 7.982526]
2023-05-16 14:45:19.284: epoch 91:	0.02591792  	0.19126689  	0.10516423  
2023-05-16 14:45:27.728: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 8.443002]
2023-05-16 14:45:27.889: epoch 92:	0.02602377  	0.19172986  	0.10547995  
2023-05-16 14:45:27.889: Find a better model.
2023-05-16 14:45:35.525: [iter 93 : loss : 0.1343 = 0.0437 + 0.0856 + 0.0051, time: 7.632017]
2023-05-16 14:45:35.723: epoch 93:	0.02604494  	0.19206163  	0.10561842  
2023-05-16 14:45:35.723: Find a better model.
2023-05-16 14:45:44.836: [iter 94 : loss : 0.1322 = 0.0415 + 0.0856 + 0.0051, time: 9.109431]
2023-05-16 14:45:45.135: epoch 94:	0.02605905  	0.19206369  	0.10574976  
2023-05-16 14:45:45.136: Find a better model.
2023-05-16 14:45:53.309: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 8.171993]
2023-05-16 14:45:53.463: epoch 95:	0.02605199  	0.19208393  	0.10587865  
2023-05-16 14:45:53.464: Find a better model.
2023-05-16 14:46:00.955: [iter 96 : loss : 0.1316 = 0.0411 + 0.0854 + 0.0052, time: 7.490003]
2023-05-16 14:46:01.124: epoch 96:	0.02612256  	0.19265662  	0.10615300  
2023-05-16 14:46:01.125: Find a better model.
2023-05-16 14:46:09.472: [iter 97 : loss : 0.1297 = 0.0392 + 0.0853 + 0.0052, time: 8.346369]
2023-05-16 14:46:09.645: epoch 97:	0.02613667  	0.19288553  	0.10618537  
2023-05-16 14:46:09.645: Find a better model.
2023-05-16 14:46:18.879: [iter 98 : loss : 0.1308 = 0.0403 + 0.0853 + 0.0052, time: 9.223022]
2023-05-16 14:46:19.134: epoch 98:	0.02611550  	0.19288026  	0.10627632  
2023-05-16 14:46:28.211: [iter 99 : loss : 0.1296 = 0.0391 + 0.0852 + 0.0053, time: 9.074538]
2023-05-16 14:46:28.498: epoch 99:	0.02614373  	0.19299351  	0.10653127  
2023-05-16 14:46:28.498: Find a better model.
2023-05-16 14:46:36.576: [iter 100 : loss : 0.1288 = 0.0384 + 0.0851 + 0.0053, time: 8.076993]
2023-05-16 14:46:36.744: epoch 100:	0.02613668  	0.19305661  	0.10648080  
2023-05-16 14:46:36.744: Find a better model.
2023-05-16 14:46:44.544: [iter 101 : loss : 0.1283 = 0.0379 + 0.0850 + 0.0053, time: 7.798992]
2023-05-16 14:46:44.705: epoch 101:	0.02621430  	0.19336520  	0.10664547  
2023-05-16 14:46:44.705: Find a better model.
2023-05-16 14:46:52.921: [iter 102 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 8.214085]
2023-05-16 14:46:53.077: epoch 102:	0.02617196  	0.19296469  	0.10654672  
2023-05-16 14:47:02.057: [iter 103 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 8.978275]
2023-05-16 14:47:02.319: epoch 103:	0.02615079  	0.19292194  	0.10659687  
2023-05-16 14:47:10.140: [iter 104 : loss : 0.1278 = 0.0376 + 0.0848 + 0.0055, time: 7.818003]
2023-05-16 14:47:10.306: epoch 104:	0.02624958  	0.19375052  	0.10696715  
2023-05-16 14:47:10.306: Find a better model.
2023-05-16 14:47:18.536: [iter 105 : loss : 0.1272 = 0.0370 + 0.0847 + 0.0055, time: 8.229027]
2023-05-16 14:47:18.697: epoch 105:	0.02627780  	0.19379416  	0.10712244  
2023-05-16 14:47:18.697: Find a better model.
2023-05-16 14:47:27.003: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 8.304992]
2023-05-16 14:47:27.153: epoch 106:	0.02627780  	0.19400366  	0.10726966  
2023-05-16 14:47:27.153: Find a better model.
2023-05-16 14:47:34.884: [iter 107 : loss : 0.1254 = 0.0352 + 0.0847 + 0.0055, time: 7.730033]
2023-05-16 14:47:35.041: epoch 107:	0.02622841  	0.19363220  	0.10716081  
2023-05-16 14:47:44.027: [iter 108 : loss : 0.1254 = 0.0353 + 0.0845 + 0.0056, time: 8.983012]
2023-05-16 14:47:44.277: epoch 108:	0.02628487  	0.19401008  	0.10742276  
2023-05-16 14:47:44.277: Find a better model.
2023-05-16 14:47:51.691: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 7.412271]
2023-05-16 14:47:51.853: epoch 109:	0.02625664  	0.19376048  	0.10745306  
2023-05-16 14:47:59.848: [iter 110 : loss : 0.1233 = 0.0332 + 0.0845 + 0.0056, time: 7.994016]
2023-05-16 14:48:00.009: epoch 110:	0.02630603  	0.19419327  	0.10761405  
2023-05-16 14:48:00.010: Find a better model.
2023-05-16 14:48:08.253: [iter 111 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 8.241995]
2023-05-16 14:48:08.414: epoch 111:	0.02632720  	0.19446872  	0.10768353  
2023-05-16 14:48:08.414: Find a better model.
2023-05-16 14:48:16.089: [iter 112 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0057, time: 7.674410]
2023-05-16 14:48:16.270: epoch 112:	0.02634837  	0.19463745  	0.10782010  
2023-05-16 14:48:16.270: Find a better model.
2023-05-16 14:48:25.410: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0058, time: 9.139162]
2023-05-16 14:48:25.703: epoch 113:	0.02632721  	0.19464132  	0.10774158  
2023-05-16 14:48:25.703: Find a better model.
2023-05-16 14:48:33.500: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 7.795003]
2023-05-16 14:48:33.951: epoch 114:	0.02634838  	0.19458301  	0.10777881  
2023-05-16 14:48:41.498: [iter 115 : loss : 0.1219 = 0.0320 + 0.0841 + 0.0058, time: 7.545018]
2023-05-16 14:48:41.666: epoch 115:	0.02634837  	0.19480798  	0.10796131  
2023-05-16 14:48:41.666: Find a better model.
2023-05-16 14:48:50.041: [iter 116 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0058, time: 8.374008]
2023-05-16 14:48:50.195: epoch 116:	0.02634132  	0.19500948  	0.10800300  
2023-05-16 14:48:50.195: Find a better model.
2023-05-16 14:48:59.097: [iter 117 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.894013]
2023-05-16 14:48:59.383: epoch 117:	0.02635544  	0.19494818  	0.10803477  
2023-05-16 14:49:08.428: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 9.036023]
2023-05-16 14:49:08.719: epoch 118:	0.02638366  	0.19522589  	0.10830722  
2023-05-16 14:49:08.720: Find a better model.
2023-05-16 14:49:16.865: [iter 119 : loss : 0.1197 = 0.0299 + 0.0839 + 0.0059, time: 8.144112]
2023-05-16 14:49:17.066: epoch 119:	0.02649657  	0.19576171  	0.10867475  
2023-05-16 14:49:17.067: Find a better model.
2023-05-16 14:49:24.489: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 7.421001]
2023-05-16 14:49:24.649: epoch 120:	0.02644717  	0.19539607  	0.10854638  
2023-05-16 14:49:32.873: [iter 121 : loss : 0.1199 = 0.0300 + 0.0838 + 0.0060, time: 8.222005]
2023-05-16 14:49:33.104: epoch 121:	0.02644717  	0.19525848  	0.10865786  
2023-05-16 14:49:42.002: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 8.895052]
2023-05-16 14:49:42.309: epoch 122:	0.02646833  	0.19555452  	0.10865299  
2023-05-16 14:49:51.002: [iter 123 : loss : 0.1189 = 0.0292 + 0.0837 + 0.0061, time: 8.692265]
2023-05-16 14:49:51.181: epoch 123:	0.02645423  	0.19507313  	0.10865335  
2023-05-16 14:49:59.275: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 8.092241]
2023-05-16 14:49:59.452: epoch 124:	0.02649656  	0.19552241  	0.10894422  
2023-05-16 14:50:07.287: [iter 125 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0061, time: 7.832000]
2023-05-16 14:50:07.864: epoch 125:	0.02638366  	0.19487610  	0.10863299  
2023-05-16 14:50:15.422: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 7.556569]
2023-05-16 14:50:15.578: epoch 126:	0.02641189  	0.19482081  	0.10881466  
2023-05-16 14:50:24.414: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 8.831232]
2023-05-16 14:50:24.706: epoch 127:	0.02649657  	0.19519167  	0.10896850  
2023-05-16 14:50:32.020: [iter 128 : loss : 0.1179 = 0.0281 + 0.0835 + 0.0062, time: 7.313018]
2023-05-16 14:50:32.182: epoch 128:	0.02652480  	0.19544387  	0.10902409  
2023-05-16 14:50:40.333: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 8.150002]
2023-05-16 14:50:40.490: epoch 129:	0.02651774  	0.19548731  	0.10913593  
2023-05-16 14:50:48.754: [iter 130 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 8.263002]
2023-05-16 14:50:48.921: epoch 130:	0.02651068  	0.19527574  	0.10926827  
2023-05-16 14:50:56.407: [iter 131 : loss : 0.1161 = 0.0265 + 0.0834 + 0.0063, time: 7.484622]
2023-05-16 14:50:56.561: epoch 131:	0.02650362  	0.19510433  	0.10915409  
2023-05-16 14:51:05.398: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 8.835036]
2023-05-16 14:51:05.694: epoch 132:	0.02655302  	0.19551271  	0.10921936  
2023-05-16 14:51:12.907: [iter 133 : loss : 0.1151 = 0.0254 + 0.0833 + 0.0064, time: 7.212125]
2023-05-16 14:51:13.074: epoch 133:	0.02656008  	0.19562398  	0.10920826  
2023-05-16 14:51:21.029: [iter 134 : loss : 0.1158 = 0.0261 + 0.0832 + 0.0064, time: 7.953487]
2023-05-16 14:51:21.175: epoch 134:	0.02658830  	0.19583564  	0.10943455  
2023-05-16 14:51:21.175: Find a better model.
2023-05-16 14:51:29.119: [iter 135 : loss : 0.1154 = 0.0258 + 0.0832 + 0.0064, time: 7.941992]
2023-05-16 14:51:29.302: epoch 135:	0.02658125  	0.19615337  	0.10951759  
2023-05-16 14:51:29.302: Find a better model.
2023-05-16 14:51:36.812: [iter 136 : loss : 0.1152 = 0.0256 + 0.0831 + 0.0065, time: 7.508026]
2023-05-16 14:51:36.970: epoch 136:	0.02664476  	0.19683896  	0.10977539  
2023-05-16 14:51:36.970: Find a better model.
2023-05-16 14:51:45.926: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 8.954306]
2023-05-16 14:51:46.226: epoch 137:	0.02662359  	0.19652756  	0.10975997  
2023-05-16 14:51:53.473: [iter 138 : loss : 0.1143 = 0.0248 + 0.0831 + 0.0065, time: 7.246003]
2023-05-16 14:51:53.631: epoch 138:	0.02661653  	0.19659947  	0.10972569  
2023-05-16 14:52:01.373: [iter 139 : loss : 0.1140 = 0.0244 + 0.0830 + 0.0065, time: 7.740016]
2023-05-16 14:52:01.530: epoch 139:	0.02659536  	0.19649972  	0.10965817  
2023-05-16 14:52:09.774: [iter 140 : loss : 0.1136 = 0.0241 + 0.0830 + 0.0066, time: 8.241981]
2023-05-16 14:52:09.938: epoch 140:	0.02656008  	0.19569910  	0.10945787  
2023-05-16 14:52:17.580: [iter 141 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0066, time: 7.641289]
2023-05-16 14:52:17.728: epoch 141:	0.02653891  	0.19572464  	0.10953947  
2023-05-16 14:52:26.766: [iter 142 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0066, time: 9.031023]
2023-05-16 14:52:27.052: epoch 142:	0.02654596  	0.19530188  	0.10935955  
2023-05-16 14:52:34.472: [iter 143 : loss : 0.1135 = 0.0239 + 0.0828 + 0.0067, time: 7.419014]
2023-05-16 14:52:34.628: epoch 143:	0.02654596  	0.19582739  	0.10955444  
2023-05-16 14:52:42.396: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.766025]
2023-05-16 14:52:42.554: epoch 144:	0.02658124  	0.19598685  	0.10963609  
2023-05-16 14:52:50.553: [iter 145 : loss : 0.1124 = 0.0229 + 0.0828 + 0.0067, time: 7.998002]
2023-05-16 14:52:50.714: epoch 145:	0.02650362  	0.19497374  	0.10932152  
2023-05-16 14:52:58.605: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 7.890003]
2023-05-16 14:52:58.866: epoch 146:	0.02660241  	0.19582894  	0.10970887  
2023-05-16 14:53:07.799: [iter 147 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0068, time: 8.930584]
2023-05-16 14:53:08.108: epoch 147:	0.02654596  	0.19494389  	0.10942632  
2023-05-16 14:53:15.807: [iter 148 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.697992]
2023-05-16 14:53:16.291: epoch 148:	0.02655302  	0.19521616  	0.10949337  
2023-05-16 14:53:23.802: [iter 149 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.508031]
2023-05-16 14:53:23.997: epoch 149:	0.02658830  	0.19517612  	0.10948662  
2023-05-16 14:53:32.236: [iter 150 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0068, time: 8.236993]
2023-05-16 14:53:32.428: epoch 150:	0.02660241  	0.19510989  	0.10945352  
2023-05-16 14:53:41.282: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 8.851123]
2023-05-16 14:53:41.543: epoch 151:	0.02658829  	0.19502737  	0.10926381  
2023-05-16 14:53:50.551: [iter 152 : loss : 0.1108 = 0.0213 + 0.0826 + 0.0069, time: 9.005027]
2023-05-16 14:53:50.847: epoch 152:	0.02652478  	0.19464807  	0.10911702  
2023-05-16 14:53:58.677: [iter 153 : loss : 0.1099 = 0.0205 + 0.0825 + 0.0069, time: 7.829027]
2023-05-16 14:53:58.836: epoch 153:	0.02650362  	0.19475710  	0.10923642  
2023-05-16 14:54:06.376: [iter 154 : loss : 0.1103 = 0.0209 + 0.0825 + 0.0069, time: 7.538006]
2023-05-16 14:54:06.541: epoch 154:	0.02654596  	0.19510891  	0.10934908  
2023-05-16 14:54:14.781: [iter 155 : loss : 0.1110 = 0.0215 + 0.0825 + 0.0070, time: 8.238992]
2023-05-16 14:54:14.952: epoch 155:	0.02648245  	0.19444436  	0.10930437  
2023-05-16 14:54:23.818: [iter 156 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 8.862012]
2023-05-16 14:54:24.115: epoch 156:	0.02653890  	0.19485041  	0.10920746  
2023-05-16 14:54:33.029: [iter 157 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 8.911066]
2023-05-16 14:54:33.312: epoch 157:	0.02648245  	0.19448970  	0.10906811  
2023-05-16 14:54:40.962: [iter 158 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 7.649013]
2023-05-16 14:54:41.130: epoch 158:	0.02653890  	0.19457191  	0.10918427  
2023-05-16 14:54:48.525: [iter 159 : loss : 0.1097 = 0.0203 + 0.0823 + 0.0071, time: 7.394003]
2023-05-16 14:54:48.681: epoch 159:	0.02647539  	0.19419914  	0.10899738  
2023-05-16 14:54:56.793: [iter 160 : loss : 0.1095 = 0.0200 + 0.0823 + 0.0071, time: 8.111225]
2023-05-16 14:54:57.029: epoch 160:	0.02646834  	0.19405688  	0.10888329  
2023-05-16 14:55:05.905: [iter 161 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0071, time: 8.870006]
2023-05-16 14:55:06.205: epoch 161:	0.02648244  	0.19448347  	0.10900684  
2023-05-16 14:55:06.205: Early stopping is trigger at epoch: 161
2023-05-16 14:55:06.205: best_result@epoch 136:

2023-05-16 14:55:06.205: 		0.0266      	0.1968      	0.1098      
2023-05-16 15:01:54.238: my pid: 8840
2023-05-16 15:01:54.238: model: model.general_recommender.SGL
2023-05-16 15:01:54.238: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 15:01:54.238: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 15:01:57.546: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 15:02:07.575: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.027059]
2023-05-16 15:02:07.883: epoch 1:	0.00152413  	0.01089091  	0.00515900  
2023-05-16 15:02:07.883: Find a better model.
2023-05-16 15:02:16.300: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.416050]
2023-05-16 15:02:16.514: epoch 2:	0.00306943  	0.02216921  	0.01090340  
2023-05-16 15:02:16.514: Find a better model.
2023-05-16 15:02:25.427: [iter 3 : loss : 0.7711 = 0.6925 + 0.0785 + 0.0000, time: 8.911080]
2023-05-16 15:02:25.593: epoch 3:	0.00524270  	0.03911415  	0.01918012  
2023-05-16 15:02:25.593: Find a better model.
2023-05-16 15:02:34.394: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.799741]
2023-05-16 15:02:34.557: epoch 4:	0.00829093  	0.06203620  	0.03015362  
2023-05-16 15:02:34.557: Find a better model.
2023-05-16 15:02:44.441: [iter 5 : loss : 0.7696 = 0.6907 + 0.0788 + 0.0000, time: 9.882048]
2023-05-16 15:02:44.706: epoch 5:	0.01208021  	0.08973588  	0.04298770  
2023-05-16 15:02:44.706: Find a better model.
2023-05-16 15:02:54.320: [iter 6 : loss : 0.7671 = 0.6879 + 0.0792 + 0.0000, time: 9.612023]
2023-05-16 15:02:54.602: epoch 6:	0.01538967  	0.11207932  	0.05474056  
2023-05-16 15:02:54.602: Find a better model.
2023-05-16 15:03:03.222: [iter 7 : loss : 0.7604 = 0.6803 + 0.0800 + 0.0000, time: 8.618015]
2023-05-16 15:03:03.380: epoch 7:	0.01778885  	0.13088758  	0.06447298  
2023-05-16 15:03:03.380: Find a better model.
2023-05-16 15:03:11.387: [iter 8 : loss : 0.7437 = 0.6616 + 0.0820 + 0.0001, time: 8.006027]
2023-05-16 15:03:11.547: epoch 8:	0.01869914  	0.13762948  	0.06841833  
2023-05-16 15:03:11.547: Find a better model.
2023-05-16 15:03:20.233: [iter 9 : loss : 0.7069 = 0.6208 + 0.0860 + 0.0001, time: 8.684007]
2023-05-16 15:03:20.382: epoch 9:	0.01851567  	0.13696985  	0.06863004  
2023-05-16 15:03:29.735: [iter 10 : loss : 0.6449 = 0.5533 + 0.0913 + 0.0003, time: 9.350006]
2023-05-16 15:03:30.044: epoch 10:	0.01840277  	0.13564989  	0.06812256  
2023-05-16 15:03:38.925: [iter 11 : loss : 0.5697 = 0.4731 + 0.0962 + 0.0004, time: 8.880030]
2023-05-16 15:03:39.104: epoch 11:	0.01852272  	0.13693595  	0.06860943  
2023-05-16 15:03:47.810: [iter 12 : loss : 0.5019 = 0.4018 + 0.0995 + 0.0006, time: 8.703799]
2023-05-16 15:03:47.972: epoch 12:	0.01838866  	0.13627328  	0.06836423  
2023-05-16 15:03:56.695: [iter 13 : loss : 0.4519 = 0.3498 + 0.1013 + 0.0007, time: 8.721003]
2023-05-16 15:03:56.860: epoch 13:	0.01844511  	0.13698971  	0.06876718  
2023-05-16 15:04:04.953: [iter 14 : loss : 0.4139 = 0.3109 + 0.1022 + 0.0009, time: 8.092528]
2023-05-16 15:04:05.109: epoch 14:	0.01863563  	0.13828348  	0.06963033  
2023-05-16 15:04:05.109: Find a better model.
2023-05-16 15:04:14.449: [iter 15 : loss : 0.3875 = 0.2840 + 0.1025 + 0.0010, time: 9.337016]
2023-05-16 15:04:14.721: epoch 15:	0.01898140  	0.14053369  	0.07071979  
2023-05-16 15:04:14.721: Find a better model.
2023-05-16 15:04:22.398: [iter 16 : loss : 0.3653 = 0.2617 + 0.1025 + 0.0011, time: 7.676050]
2023-05-16 15:04:22.561: epoch 16:	0.01920720  	0.14210725  	0.07175062  
2023-05-16 15:04:22.561: Find a better model.
2023-05-16 15:04:30.778: [iter 17 : loss : 0.3488 = 0.2453 + 0.1023 + 0.0012, time: 8.215090]
2023-05-16 15:04:30.931: epoch 17:	0.01939067  	0.14314573  	0.07247929  
2023-05-16 15:04:30.931: Find a better model.
2023-05-16 15:04:39.516: [iter 18 : loss : 0.3337 = 0.2303 + 0.1021 + 0.0013, time: 8.583992]
2023-05-16 15:04:39.677: epoch 18:	0.01965176  	0.14469585  	0.07335626  
2023-05-16 15:04:39.677: Find a better model.
2023-05-16 15:04:47.749: [iter 19 : loss : 0.3197 = 0.2166 + 0.1017 + 0.0014, time: 8.071073]
2023-05-16 15:04:47.973: epoch 19:	0.01972939  	0.14524028  	0.07394823  
2023-05-16 15:04:47.974: Find a better model.
2023-05-16 15:04:57.312: [iter 20 : loss : 0.3100 = 0.2073 + 0.1013 + 0.0015, time: 9.330022]
2023-05-16 15:04:57.614: epoch 20:	0.01987052  	0.14603126  	0.07451192  
2023-05-16 15:04:57.614: Find a better model.
2023-05-16 15:05:05.500: [iter 21 : loss : 0.3003 = 0.1978 + 0.1009 + 0.0016, time: 7.884031]
2023-05-16 15:05:05.945: epoch 21:	0.02004693  	0.14767766  	0.07519654  
2023-05-16 15:05:05.946: Find a better model.
2023-05-16 15:05:13.764: [iter 22 : loss : 0.2922 = 0.1900 + 0.1005 + 0.0017, time: 7.808231]
2023-05-16 15:05:13.931: epoch 22:	0.02030802  	0.14955644  	0.07592841  
2023-05-16 15:05:13.931: Find a better model.
2023-05-16 15:05:22.464: [iter 23 : loss : 0.2838 = 0.1820 + 0.1001 + 0.0017, time: 8.531416]
2023-05-16 15:05:22.630: epoch 23:	0.02042798  	0.15079264  	0.07668840  
2023-05-16 15:05:22.631: Find a better model.
2023-05-16 15:05:31.819: [iter 24 : loss : 0.2774 = 0.1760 + 0.0996 + 0.0018, time: 9.186999]
2023-05-16 15:05:32.127: epoch 24:	0.02058322  	0.15185490  	0.07748817  
2023-05-16 15:05:32.127: Find a better model.
2023-05-16 15:05:41.356: [iter 25 : loss : 0.2709 = 0.1698 + 0.0992 + 0.0019, time: 9.226019]
2023-05-16 15:05:41.665: epoch 25:	0.02083726  	0.15393457  	0.07850469  
2023-05-16 15:05:41.666: Find a better model.
2023-05-16 15:05:49.817: [iter 26 : loss : 0.2671 = 0.1664 + 0.0988 + 0.0019, time: 8.150026]
2023-05-16 15:05:49.974: epoch 26:	0.02104896  	0.15529671  	0.07943551  
2023-05-16 15:05:49.974: Find a better model.
2023-05-16 15:05:57.913: [iter 27 : loss : 0.2596 = 0.1593 + 0.0983 + 0.0020, time: 7.937047]
2023-05-16 15:05:58.073: epoch 27:	0.02126065  	0.15665828  	0.08020760  
2023-05-16 15:05:58.073: Find a better model.
2023-05-16 15:06:06.525: [iter 28 : loss : 0.2544 = 0.1544 + 0.0979 + 0.0021, time: 8.450001]
2023-05-16 15:06:06.688: epoch 28:	0.02140885  	0.15750293  	0.08088490  
2023-05-16 15:06:06.688: Find a better model.
2023-05-16 15:06:15.853: [iter 29 : loss : 0.2501 = 0.1504 + 0.0975 + 0.0021, time: 9.162031]
2023-05-16 15:06:16.151: epoch 29:	0.02157821  	0.15880907  	0.08150139  
2023-05-16 15:06:16.151: Find a better model.
2023-05-16 15:06:25.426: [iter 30 : loss : 0.2438 = 0.1444 + 0.0972 + 0.0022, time: 9.272028]
2023-05-16 15:06:25.727: epoch 30:	0.02179696  	0.16011597  	0.08225866  
2023-05-16 15:06:25.727: Find a better model.
2023-05-16 15:06:33.937: [iter 31 : loss : 0.2398 = 0.1408 + 0.0968 + 0.0023, time: 8.209054]
2023-05-16 15:06:34.103: epoch 31:	0.02181813  	0.16019292  	0.08273137  
2023-05-16 15:06:34.103: Find a better model.
2023-05-16 15:06:41.915: [iter 32 : loss : 0.2345 = 0.1357 + 0.0964 + 0.0023, time: 7.811000]
2023-05-16 15:06:42.077: epoch 32:	0.02209333  	0.16224052  	0.08364388  
2023-05-16 15:06:42.077: Find a better model.
2023-05-16 15:06:50.558: [iter 33 : loss : 0.2319 = 0.1335 + 0.0960 + 0.0024, time: 8.479341]
2023-05-16 15:06:50.712: epoch 33:	0.02227680  	0.16312365  	0.08424062  
2023-05-16 15:06:50.712: Find a better model.
2023-05-16 15:06:59.903: [iter 34 : loss : 0.2277 = 0.1295 + 0.0957 + 0.0024, time: 9.189335]
2023-05-16 15:07:00.195: epoch 34:	0.02238264  	0.16389598  	0.08484482  
2023-05-16 15:07:00.195: Find a better model.
2023-05-16 15:07:08.855: [iter 35 : loss : 0.2243 = 0.1263 + 0.0954 + 0.0025, time: 8.658020]
2023-05-16 15:07:09.029: epoch 35:	0.02251672  	0.16478649  	0.08548128  
2023-05-16 15:07:09.029: Find a better model.
2023-05-16 15:07:17.560: [iter 36 : loss : 0.2207 = 0.1231 + 0.0951 + 0.0026, time: 8.529034]
2023-05-16 15:07:17.717: epoch 36:	0.02277780  	0.16676663  	0.08650140  
2023-05-16 15:07:17.717: Find a better model.
2023-05-16 15:07:26.037: [iter 37 : loss : 0.2171 = 0.1197 + 0.0948 + 0.0026, time: 8.319023]
2023-05-16 15:07:26.203: epoch 37:	0.02284131  	0.16686086  	0.08683850  
2023-05-16 15:07:26.203: Find a better model.
2023-05-16 15:07:34.061: [iter 38 : loss : 0.2156 = 0.1185 + 0.0945 + 0.0027, time: 7.857024]
2023-05-16 15:07:34.220: epoch 38:	0.02289071  	0.16773170  	0.08757133  
2023-05-16 15:07:34.220: Find a better model.
2023-05-16 15:07:43.273: [iter 39 : loss : 0.2109 = 0.1141 + 0.0941 + 0.0027, time: 9.049556]
2023-05-16 15:07:43.576: epoch 39:	0.02301772  	0.16880205  	0.08817764  
2023-05-16 15:07:43.576: Find a better model.
2023-05-16 15:07:50.958: [iter 40 : loss : 0.2075 = 0.1108 + 0.0939 + 0.0028, time: 7.381015]
2023-05-16 15:07:51.122: epoch 40:	0.02312357  	0.16968307  	0.08862668  
2023-05-16 15:07:51.122: Find a better model.
2023-05-16 15:07:59.495: [iter 41 : loss : 0.2061 = 0.1097 + 0.0936 + 0.0028, time: 8.372632]
2023-05-16 15:07:59.650: epoch 41:	0.02327176  	0.17113036  	0.08932667  
2023-05-16 15:07:59.650: Find a better model.
2023-05-16 15:08:07.981: [iter 42 : loss : 0.2035 = 0.1074 + 0.0933 + 0.0029, time: 8.329090]
2023-05-16 15:08:08.141: epoch 42:	0.02334937  	0.17141180  	0.08970695  
2023-05-16 15:08:08.141: Find a better model.
2023-05-16 15:08:16.045: [iter 43 : loss : 0.1999 = 0.1040 + 0.0930 + 0.0029, time: 7.903020]
2023-05-16 15:08:16.206: epoch 43:	0.02339877  	0.17203441  	0.09027221  
2023-05-16 15:08:16.206: Find a better model.
2023-05-16 15:08:25.263: [iter 44 : loss : 0.1963 = 0.1005 + 0.0927 + 0.0030, time: 9.053083]
2023-05-16 15:08:25.556: epoch 44:	0.02350462  	0.17269468  	0.09084163  
2023-05-16 15:08:25.556: Find a better model.
2023-05-16 15:08:32.919: [iter 45 : loss : 0.1943 = 0.0988 + 0.0925 + 0.0030, time: 7.362194]
2023-05-16 15:08:33.081: epoch 45:	0.02361046  	0.17344810  	0.09145045  
2023-05-16 15:08:33.081: Find a better model.
2023-05-16 15:08:41.109: [iter 46 : loss : 0.1919 = 0.0965 + 0.0923 + 0.0031, time: 8.027531]
2023-05-16 15:08:41.273: epoch 46:	0.02363163  	0.17333806  	0.09169353  
2023-05-16 15:08:49.764: [iter 47 : loss : 0.1912 = 0.0960 + 0.0921 + 0.0031, time: 8.489992]
2023-05-16 15:08:49.929: epoch 47:	0.02374453  	0.17464431  	0.09242782  
2023-05-16 15:08:49.929: Find a better model.
2023-05-16 15:08:57.640: [iter 48 : loss : 0.1871 = 0.0921 + 0.0918 + 0.0032, time: 7.709020]
2023-05-16 15:08:57.795: epoch 48:	0.02383627  	0.17487752  	0.09280384  
2023-05-16 15:08:57.795: Find a better model.
2023-05-16 15:09:06.855: [iter 49 : loss : 0.1843 = 0.0895 + 0.0916 + 0.0032, time: 9.057013]
2023-05-16 15:09:07.160: epoch 49:	0.02392800  	0.17557345  	0.09340282  
2023-05-16 15:09:07.160: Find a better model.
2023-05-16 15:09:14.548: [iter 50 : loss : 0.1833 = 0.0887 + 0.0914 + 0.0033, time: 7.384525]
2023-05-16 15:09:14.713: epoch 50:	0.02392801  	0.17552258  	0.09361973  
2023-05-16 15:09:22.912: [iter 51 : loss : 0.1804 = 0.0860 + 0.0911 + 0.0033, time: 8.197023]
2023-05-16 15:09:23.073: epoch 51:	0.02396329  	0.17587522  	0.09385644  
2023-05-16 15:09:23.073: Find a better model.
2023-05-16 15:09:31.342: [iter 52 : loss : 0.1804 = 0.0861 + 0.0910 + 0.0034, time: 8.268218]
2023-05-16 15:09:31.503: epoch 52:	0.02411148  	0.17668484  	0.09434313  
2023-05-16 15:09:31.503: Find a better model.
2023-05-16 15:09:39.252: [iter 53 : loss : 0.1783 = 0.0841 + 0.0907 + 0.0034, time: 7.747999]
2023-05-16 15:09:39.408: epoch 53:	0.02413970  	0.17703466  	0.09481005  
2023-05-16 15:09:39.408: Find a better model.
2023-05-16 15:09:48.437: [iter 54 : loss : 0.1762 = 0.0822 + 0.0906 + 0.0035, time: 9.023864]
2023-05-16 15:09:48.740: epoch 54:	0.02425966  	0.17773257  	0.09523408  
2023-05-16 15:09:48.740: Find a better model.
2023-05-16 15:09:56.062: [iter 55 : loss : 0.1741 = 0.0802 + 0.0904 + 0.0035, time: 7.321486]
2023-05-16 15:09:56.238: epoch 55:	0.02430200  	0.17807285  	0.09551851  
2023-05-16 15:09:56.238: Find a better model.
2023-05-16 15:10:04.483: [iter 56 : loss : 0.1726 = 0.0789 + 0.0902 + 0.0036, time: 8.242993]
2023-05-16 15:10:04.638: epoch 56:	0.02436551  	0.17885199  	0.09591173  
2023-05-16 15:10:04.638: Find a better model.
2023-05-16 15:10:13.144: [iter 57 : loss : 0.1704 = 0.0768 + 0.0900 + 0.0036, time: 8.505002]
2023-05-16 15:10:13.310: epoch 57:	0.02447136  	0.17966580  	0.09648666  
2023-05-16 15:10:13.310: Find a better model.
2023-05-16 15:10:21.030: [iter 58 : loss : 0.1686 = 0.0751 + 0.0898 + 0.0036, time: 7.718318]
2023-05-16 15:10:21.190: epoch 58:	0.02453486  	0.18031271  	0.09687757  
2023-05-16 15:10:21.190: Find a better model.
2023-05-16 15:10:30.324: [iter 59 : loss : 0.1677 = 0.0744 + 0.0896 + 0.0037, time: 9.131398]
2023-05-16 15:10:30.637: epoch 59:	0.02459837  	0.18097249  	0.09734588  
2023-05-16 15:10:30.637: Find a better model.
2023-05-16 15:10:37.982: [iter 60 : loss : 0.1661 = 0.0729 + 0.0895 + 0.0037, time: 7.344002]
2023-05-16 15:10:38.140: epoch 60:	0.02475361  	0.18191335  	0.09783919  
2023-05-16 15:10:38.141: Find a better model.
2023-05-16 15:10:46.419: [iter 61 : loss : 0.1647 = 0.0717 + 0.0893 + 0.0038, time: 8.276009]
2023-05-16 15:10:46.572: epoch 61:	0.02469716  	0.18154220  	0.09776205  
2023-05-16 15:10:54.630: [iter 62 : loss : 0.1634 = 0.0705 + 0.0891 + 0.0038, time: 8.056018]
2023-05-16 15:10:54.790: epoch 62:	0.02468304  	0.18149166  	0.09797803  
2023-05-16 15:11:02.395: [iter 63 : loss : 0.1619 = 0.0691 + 0.0890 + 0.0039, time: 7.603008]
2023-05-16 15:11:02.548: epoch 63:	0.02476772  	0.18182115  	0.09845085  
2023-05-16 15:11:11.790: [iter 64 : loss : 0.1607 = 0.0680 + 0.0888 + 0.0039, time: 9.231900]
2023-05-16 15:11:12.092: epoch 64:	0.02488768  	0.18269412  	0.09905493  
2023-05-16 15:11:12.092: Find a better model.
2023-05-16 15:11:19.441: [iter 65 : loss : 0.1594 = 0.0668 + 0.0886 + 0.0040, time: 7.348103]
2023-05-16 15:11:19.601: epoch 65:	0.02486651  	0.18269703  	0.09915633  
2023-05-16 15:11:19.601: Find a better model.
2023-05-16 15:11:27.810: [iter 66 : loss : 0.1580 = 0.0655 + 0.0885 + 0.0040, time: 8.206950]
2023-05-16 15:11:27.963: epoch 66:	0.02488062  	0.18257447  	0.09927049  
2023-05-16 15:11:36.232: [iter 67 : loss : 0.1565 = 0.0641 + 0.0884 + 0.0040, time: 8.268100]
2023-05-16 15:11:36.381: epoch 67:	0.02496530  	0.18322636  	0.09986825  
2023-05-16 15:11:36.381: Find a better model.
2023-05-16 15:11:44.148: [iter 68 : loss : 0.1560 = 0.0637 + 0.0882 + 0.0041, time: 7.766146]
2023-05-16 15:11:44.302: epoch 68:	0.02500764  	0.18350855  	0.10015155  
2023-05-16 15:11:44.302: Find a better model.
2023-05-16 15:11:53.615: [iter 69 : loss : 0.1542 = 0.0620 + 0.0881 + 0.0041, time: 9.307428]
2023-05-16 15:11:53.917: epoch 69:	0.02507114  	0.18392952  	0.10048786  
2023-05-16 15:11:53.917: Find a better model.
2023-05-16 15:12:01.346: [iter 70 : loss : 0.1526 = 0.0604 + 0.0880 + 0.0042, time: 7.428003]
2023-05-16 15:12:01.507: epoch 70:	0.02516288  	0.18447511  	0.10086223  
2023-05-16 15:12:01.507: Find a better model.
2023-05-16 15:12:09.592: [iter 71 : loss : 0.1510 = 0.0590 + 0.0878 + 0.0042, time: 8.084010]
2023-05-16 15:12:09.747: epoch 71:	0.02514876  	0.18401606  	0.10092027  
2023-05-16 15:12:17.981: [iter 72 : loss : 0.1510 = 0.0591 + 0.0877 + 0.0042, time: 8.232992]
2023-05-16 15:12:18.142: epoch 72:	0.02521228  	0.18473211  	0.10125265  
2023-05-16 15:12:18.142: Find a better model.
2023-05-16 15:12:25.965: [iter 73 : loss : 0.1497 = 0.0578 + 0.0876 + 0.0043, time: 7.821995]
2023-05-16 15:12:26.124: epoch 73:	0.02519110  	0.18436261  	0.10147695  
2023-05-16 15:12:35.258: [iter 74 : loss : 0.1484 = 0.0565 + 0.0875 + 0.0043, time: 9.133391]
2023-05-16 15:12:35.565: epoch 74:	0.02516288  	0.18423526  	0.10171983  
2023-05-16 15:12:42.999: [iter 75 : loss : 0.1477 = 0.0560 + 0.0873 + 0.0044, time: 7.431993]
2023-05-16 15:12:43.157: epoch 75:	0.02525462  	0.18464687  	0.10196923  
2023-05-16 15:12:51.181: [iter 76 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 8.021919]
2023-05-16 15:12:51.330: epoch 76:	0.02539575  	0.18564133  	0.10235245  
2023-05-16 15:12:51.330: Find a better model.
2023-05-16 15:12:59.553: [iter 77 : loss : 0.1456 = 0.0541 + 0.0871 + 0.0044, time: 8.222181]
2023-05-16 15:12:59.714: epoch 77:	0.02545925  	0.18638988  	0.10242894  
2023-05-16 15:12:59.714: Find a better model.
2023-05-16 15:13:07.360: [iter 78 : loss : 0.1448 = 0.0533 + 0.0870 + 0.0045, time: 7.644819]
2023-05-16 15:13:07.520: epoch 78:	0.02562155  	0.18740201  	0.10273888  
2023-05-16 15:13:07.521: Find a better model.
2023-05-16 15:13:16.669: [iter 79 : loss : 0.1434 = 0.0520 + 0.0869 + 0.0045, time: 9.140008]
2023-05-16 15:13:16.965: epoch 79:	0.02560744  	0.18746138  	0.10295269  
2023-05-16 15:13:16.965: Find a better model.
2023-05-16 15:13:24.344: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 7.377484]
2023-05-16 15:13:24.500: epoch 80:	0.02565684  	0.18801491  	0.10312646  
2023-05-16 15:13:24.500: Find a better model.
2023-05-16 15:13:32.538: [iter 81 : loss : 0.1425 = 0.0512 + 0.0867 + 0.0046, time: 8.036027]
2023-05-16 15:13:32.692: epoch 81:	0.02571329  	0.18846463  	0.10333749  
2023-05-16 15:13:32.692: Find a better model.
2023-05-16 15:13:40.923: [iter 82 : loss : 0.1412 = 0.0500 + 0.0866 + 0.0046, time: 8.229998]
2023-05-16 15:13:41.083: epoch 82:	0.02583325  	0.18937208  	0.10364481  
2023-05-16 15:13:41.083: Find a better model.
2023-05-16 15:13:48.743: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 7.657993]
2023-05-16 15:13:48.905: epoch 83:	0.02583325  	0.18930218  	0.10386120  
2023-05-16 15:13:58.068: [iter 84 : loss : 0.1402 = 0.0491 + 0.0864 + 0.0047, time: 9.161132]
2023-05-16 15:13:58.378: epoch 84:	0.02589676  	0.19000906  	0.10410497  
2023-05-16 15:13:58.378: Find a better model.
2023-05-16 15:14:05.739: [iter 85 : loss : 0.1390 = 0.0479 + 0.0863 + 0.0048, time: 7.360007]
2023-05-16 15:14:05.897: epoch 85:	0.02593910  	0.19014432  	0.10431468  
2023-05-16 15:14:05.897: Find a better model.
2023-05-16 15:14:13.947: [iter 86 : loss : 0.1393 = 0.0483 + 0.0862 + 0.0048, time: 8.048997]
2023-05-16 15:14:14.101: epoch 86:	0.02589677  	0.18981357  	0.10428017  
2023-05-16 15:14:22.314: [iter 87 : loss : 0.1365 = 0.0456 + 0.0861 + 0.0048, time: 8.211349]
2023-05-16 15:14:22.473: epoch 87:	0.02593910  	0.19023348  	0.10451718  
2023-05-16 15:14:22.473: Find a better model.
2023-05-16 15:14:30.121: [iter 88 : loss : 0.1354 = 0.0445 + 0.0860 + 0.0049, time: 7.646134]
2023-05-16 15:14:30.303: epoch 88:	0.02592499  	0.19011222  	0.10457089  
2023-05-16 15:14:39.408: [iter 89 : loss : 0.1352 = 0.0444 + 0.0859 + 0.0049, time: 9.103002]
2023-05-16 15:14:39.701: epoch 89:	0.02602378  	0.19065934  	0.10497632  
2023-05-16 15:14:39.701: Find a better model.
2023-05-16 15:14:47.128: [iter 90 : loss : 0.1358 = 0.0450 + 0.0858 + 0.0050, time: 7.424447]
2023-05-16 15:14:47.286: epoch 90:	0.02597438  	0.19038424  	0.10505600  
2023-05-16 15:14:55.330: [iter 91 : loss : 0.1346 = 0.0438 + 0.0857 + 0.0050, time: 8.043006]
2023-05-16 15:14:55.486: epoch 91:	0.02599555  	0.19066547  	0.10537275  
2023-05-16 15:14:55.486: Find a better model.
2023-05-16 15:15:03.702: [iter 92 : loss : 0.1338 = 0.0432 + 0.0856 + 0.0050, time: 8.213993]
2023-05-16 15:15:03.863: epoch 92:	0.02606612  	0.19095741  	0.10551225  
2023-05-16 15:15:03.863: Find a better model.
2023-05-16 15:15:11.562: [iter 93 : loss : 0.1340 = 0.0434 + 0.0855 + 0.0051, time: 7.698482]
2023-05-16 15:15:11.719: epoch 93:	0.02615079  	0.19168758  	0.10571053  
2023-05-16 15:15:11.719: Find a better model.
2023-05-16 15:15:20.832: [iter 94 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 9.111035]
2023-05-16 15:15:21.130: epoch 94:	0.02617902  	0.19163734  	0.10568212  
2023-05-16 15:15:28.484: [iter 95 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0051, time: 7.353011]
2023-05-16 15:15:28.642: epoch 95:	0.02623547  	0.19217888  	0.10602634  
2023-05-16 15:15:28.642: Find a better model.
2023-05-16 15:15:36.692: [iter 96 : loss : 0.1312 = 0.0407 + 0.0853 + 0.0052, time: 8.047020]
2023-05-16 15:15:36.847: epoch 96:	0.02621430  	0.19198544  	0.10603560  
2023-05-16 15:15:45.112: [iter 97 : loss : 0.1295 = 0.0390 + 0.0853 + 0.0052, time: 8.264060]
2023-05-16 15:15:45.274: epoch 97:	0.02634132  	0.19286045  	0.10649601  
2023-05-16 15:15:45.274: Find a better model.
2023-05-16 15:15:52.926: [iter 98 : loss : 0.1306 = 0.0401 + 0.0852 + 0.0052, time: 7.650043]
2023-05-16 15:15:53.095: epoch 98:	0.02638365  	0.19340670  	0.10671657  
2023-05-16 15:15:53.096: Find a better model.
2023-05-16 15:16:02.183: [iter 99 : loss : 0.1295 = 0.0391 + 0.0851 + 0.0053, time: 9.084031]
2023-05-16 15:16:02.491: epoch 99:	0.02636248  	0.19323103  	0.10669773  
2023-05-16 15:16:09.960: [iter 100 : loss : 0.1284 = 0.0381 + 0.0850 + 0.0053, time: 7.466636]
2023-05-16 15:16:10.117: epoch 100:	0.02633426  	0.19307326  	0.10662439  
2023-05-16 15:16:18.105: [iter 101 : loss : 0.1283 = 0.0380 + 0.0850 + 0.0054, time: 7.986520]
2023-05-16 15:16:18.261: epoch 101:	0.02636248  	0.19331689  	0.10686476  
2023-05-16 15:16:26.520: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 8.258454]
2023-05-16 15:16:26.682: epoch 102:	0.02645422  	0.19434910  	0.10716439  
2023-05-16 15:16:26.682: Find a better model.
2023-05-16 15:16:34.257: [iter 103 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0054, time: 7.573996]
2023-05-16 15:16:34.413: epoch 103:	0.02652479  	0.19476521  	0.10737986  
2023-05-16 15:16:34.413: Find a better model.
2023-05-16 15:16:43.551: [iter 104 : loss : 0.1276 = 0.0374 + 0.0848 + 0.0055, time: 9.136095]
2023-05-16 15:16:43.819: epoch 104:	0.02647539  	0.19453724  	0.10734213  
2023-05-16 15:16:51.164: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 7.344001]
2023-05-16 15:16:51.325: epoch 105:	0.02647539  	0.19439216  	0.10740942  
2023-05-16 15:16:59.315: [iter 106 : loss : 0.1260 = 0.0359 + 0.0847 + 0.0055, time: 7.989008]
2023-05-16 15:16:59.471: epoch 106:	0.02651772  	0.19452214  	0.10735614  
2023-05-16 15:17:07.566: [iter 107 : loss : 0.1252 = 0.0351 + 0.0846 + 0.0056, time: 8.094001]
2023-05-16 15:17:07.744: epoch 107:	0.02651773  	0.19464903  	0.10751309  
2023-05-16 15:17:15.472: [iter 108 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 7.725429]
2023-05-16 15:17:15.626: epoch 108:	0.02654596  	0.19479544  	0.10746100  
2023-05-16 15:17:15.626: Find a better model.
2023-05-16 15:17:24.721: [iter 109 : loss : 0.1238 = 0.0338 + 0.0844 + 0.0056, time: 9.093055]
2023-05-16 15:17:25.031: epoch 109:	0.02653890  	0.19487092  	0.10760637  
2023-05-16 15:17:25.031: Find a better model.
2023-05-16 15:17:32.280: [iter 110 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 7.247713]
2023-05-16 15:17:32.443: epoch 110:	0.02652478  	0.19455256  	0.10768016  
2023-05-16 15:17:40.561: [iter 111 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0057, time: 8.116077]
2023-05-16 15:17:40.715: epoch 111:	0.02651772  	0.19446906  	0.10784365  
2023-05-16 15:17:49.160: [iter 112 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0057, time: 8.443411]
2023-05-16 15:17:49.323: epoch 112:	0.02648244  	0.19417083  	0.10778233  
2023-05-16 15:17:57.260: [iter 113 : loss : 0.1230 = 0.0330 + 0.0842 + 0.0058, time: 7.935558]
2023-05-16 15:17:57.415: epoch 113:	0.02655301  	0.19485590  	0.10808256  
2023-05-16 15:18:06.565: [iter 114 : loss : 0.1222 = 0.0323 + 0.0842 + 0.0058, time: 9.145197]
2023-05-16 15:18:06.879: epoch 114:	0.02659534  	0.19519205  	0.10829256  
2023-05-16 15:18:06.879: Find a better model.
2023-05-16 15:18:14.411: [iter 115 : loss : 0.1218 = 0.0318 + 0.0841 + 0.0058, time: 7.529995]
2023-05-16 15:18:14.576: epoch 115:	0.02658829  	0.19502875  	0.10818401  
2023-05-16 15:18:22.922: [iter 116 : loss : 0.1206 = 0.0307 + 0.0841 + 0.0059, time: 8.344992]
2023-05-16 15:18:23.084: epoch 116:	0.02663063  	0.19529694  	0.10818020  
2023-05-16 15:18:23.084: Find a better model.
2023-05-16 15:18:31.423: [iter 117 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 8.336992]
2023-05-16 15:18:31.585: epoch 117:	0.02663768  	0.19549084  	0.10812293  
2023-05-16 15:18:31.585: Find a better model.
2023-05-16 15:18:39.238: [iter 118 : loss : 0.1206 = 0.0307 + 0.0839 + 0.0059, time: 7.652690]
2023-05-16 15:18:39.393: epoch 118:	0.02658829  	0.19516447  	0.10830639  
2023-05-16 15:18:48.522: [iter 119 : loss : 0.1195 = 0.0297 + 0.0839 + 0.0060, time: 9.124991]
2023-05-16 15:18:48.829: epoch 119:	0.02666591  	0.19540800  	0.10840552  
2023-05-16 15:18:56.334: [iter 120 : loss : 0.1201 = 0.0303 + 0.0839 + 0.0060, time: 7.503917]
2023-05-16 15:18:56.490: epoch 120:	0.02661652  	0.19510564  	0.10842276  
2023-05-16 15:19:04.888: [iter 121 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 8.396992]
2023-05-16 15:19:05.052: epoch 121:	0.02660947  	0.19544774  	0.10841664  
2023-05-16 15:19:13.434: [iter 122 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0060, time: 8.379219]
2023-05-16 15:19:13.597: epoch 122:	0.02656713  	0.19517848  	0.10825017  
2023-05-16 15:19:21.258: [iter 123 : loss : 0.1189 = 0.0292 + 0.0837 + 0.0061, time: 7.659208]
2023-05-16 15:19:21.414: epoch 123:	0.02660947  	0.19525588  	0.10837204  
2023-05-16 15:19:30.570: [iter 124 : loss : 0.1181 = 0.0284 + 0.0836 + 0.0061, time: 9.152104]
2023-05-16 15:19:30.880: epoch 124:	0.02657418  	0.19462214  	0.10835737  
2023-05-16 15:19:38.290: [iter 125 : loss : 0.1174 = 0.0277 + 0.0836 + 0.0061, time: 7.408993]
2023-05-16 15:19:38.452: epoch 125:	0.02667297  	0.19547157  	0.10858560  
2023-05-16 15:19:46.876: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 8.423451]
2023-05-16 15:19:47.040: epoch 126:	0.02664475  	0.19537693  	0.10857577  
2023-05-16 15:19:55.702: [iter 127 : loss : 0.1166 = 0.0269 + 0.0835 + 0.0062, time: 8.660999]
2023-05-16 15:19:55.865: epoch 127:	0.02658124  	0.19515322  	0.10841842  
2023-05-16 15:20:03.635: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 7.769113]
2023-05-16 15:20:03.791: epoch 128:	0.02656007  	0.19459546  	0.10854764  
2023-05-16 15:20:12.856: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 9.062037]
2023-05-16 15:20:13.168: epoch 129:	0.02661653  	0.19507687  	0.10869157  
2023-05-16 15:20:20.525: [iter 130 : loss : 0.1167 = 0.0271 + 0.0834 + 0.0063, time: 7.354029]
2023-05-16 15:20:20.690: epoch 130:	0.02661652  	0.19528593  	0.10873341  
2023-05-16 15:20:28.885: [iter 131 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0063, time: 8.194001]
2023-05-16 15:20:29.046: epoch 131:	0.02659535  	0.19494554  	0.10861114  
2023-05-16 15:20:37.422: [iter 132 : loss : 0.1162 = 0.0266 + 0.0833 + 0.0064, time: 8.373496]
2023-05-16 15:20:37.586: epoch 132:	0.02658830  	0.19495112  	0.10860566  
2023-05-16 15:20:45.195: [iter 133 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0064, time: 7.607925]
2023-05-16 15:20:45.350: epoch 133:	0.02660242  	0.19543786  	0.10883779  
2023-05-16 15:20:54.401: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 9.041376]
2023-05-16 15:20:54.703: epoch 134:	0.02658124  	0.19516848  	0.10897757  
2023-05-16 15:21:02.053: [iter 135 : loss : 0.1154 = 0.0258 + 0.0832 + 0.0064, time: 7.348501]
2023-05-16 15:21:02.236: epoch 135:	0.02660241  	0.19551969  	0.10902828  
2023-05-16 15:21:02.236: Find a better model.
2023-05-16 15:21:10.451: [iter 136 : loss : 0.1148 = 0.0253 + 0.0831 + 0.0065, time: 8.212988]
2023-05-16 15:21:10.611: epoch 136:	0.02660947  	0.19552870  	0.10914107  
2023-05-16 15:21:10.612: Find a better model.
2023-05-16 15:21:18.927: [iter 137 : loss : 0.1145 = 0.0250 + 0.0831 + 0.0065, time: 8.314002]
2023-05-16 15:21:19.087: epoch 137:	0.02662358  	0.19572660  	0.10921301  
2023-05-16 15:21:19.088: Find a better model.
2023-05-16 15:21:26.803: [iter 138 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 7.714003]
2023-05-16 15:21:26.959: epoch 138:	0.02651773  	0.19512828  	0.10913066  
2023-05-16 15:21:36.002: [iter 139 : loss : 0.1142 = 0.0247 + 0.0830 + 0.0066, time: 9.040105]
2023-05-16 15:21:36.305: epoch 139:	0.02663769  	0.19612336  	0.10933048  
2023-05-16 15:21:36.305: Find a better model.
2023-05-16 15:21:43.649: [iter 140 : loss : 0.1136 = 0.0241 + 0.0830 + 0.0066, time: 7.341736]
2023-05-16 15:21:43.807: epoch 140:	0.02652479  	0.19516309  	0.10916357  
2023-05-16 15:21:52.026: [iter 141 : loss : 0.1143 = 0.0248 + 0.0829 + 0.0066, time: 8.216993]
2023-05-16 15:21:52.190: epoch 141:	0.02654595  	0.19507492  	0.10922119  
2023-05-16 15:22:00.507: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 8.316412]
2023-05-16 15:22:00.670: epoch 142:	0.02658123  	0.19495958  	0.10924223  
2023-05-16 15:22:08.352: [iter 143 : loss : 0.1134 = 0.0239 + 0.0828 + 0.0067, time: 7.681016]
2023-05-16 15:22:08.508: epoch 143:	0.02656712  	0.19485424  	0.10927055  
2023-05-16 15:22:17.561: [iter 144 : loss : 0.1126 = 0.0231 + 0.0828 + 0.0067, time: 9.049920]
2023-05-16 15:22:17.859: epoch 144:	0.02659535  	0.19513670  	0.10929444  
2023-05-16 15:22:25.205: [iter 145 : loss : 0.1125 = 0.0230 + 0.0827 + 0.0067, time: 7.343814]
2023-05-16 15:22:25.368: epoch 145:	0.02653184  	0.19475648  	0.10916619  
2023-05-16 15:22:33.656: [iter 146 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0067, time: 8.287018]
2023-05-16 15:22:33.818: epoch 146:	0.02651773  	0.19451956  	0.10899280  
2023-05-16 15:22:42.183: [iter 147 : loss : 0.1126 = 0.0232 + 0.0827 + 0.0068, time: 8.364004]
2023-05-16 15:22:42.344: epoch 147:	0.02653184  	0.19435969  	0.10892005  
2023-05-16 15:22:49.980: [iter 148 : loss : 0.1114 = 0.0220 + 0.0827 + 0.0068, time: 7.633351]
2023-05-16 15:22:50.135: epoch 148:	0.02650362  	0.19412667  	0.10890922  
2023-05-16 15:22:59.072: [iter 149 : loss : 0.1117 = 0.0223 + 0.0826 + 0.0068, time: 8.936266]
2023-05-16 15:22:59.386: epoch 149:	0.02651067  	0.19393595  	0.10892104  
2023-05-16 15:23:06.725: [iter 150 : loss : 0.1112 = 0.0218 + 0.0826 + 0.0069, time: 7.336396]
2023-05-16 15:23:06.889: epoch 150:	0.02652478  	0.19405092  	0.10898659  
2023-05-16 15:23:15.215: [iter 151 : loss : 0.1113 = 0.0219 + 0.0826 + 0.0069, time: 8.324013]
2023-05-16 15:23:15.384: epoch 151:	0.02651067  	0.19439188  	0.10892986  
2023-05-16 15:23:23.743: [iter 152 : loss : 0.1108 = 0.0213 + 0.0825 + 0.0069, time: 8.357993]
2023-05-16 15:23:23.897: epoch 152:	0.02648244  	0.19390677  	0.10885952  
2023-05-16 15:23:31.568: [iter 153 : loss : 0.1099 = 0.0205 + 0.0825 + 0.0069, time: 7.670157]
2023-05-16 15:23:31.723: epoch 153:	0.02646833  	0.19359310  	0.10888330  
2023-05-16 15:23:40.745: [iter 154 : loss : 0.1101 = 0.0207 + 0.0825 + 0.0070, time: 9.020356]
2023-05-16 15:23:41.043: epoch 154:	0.02649656  	0.19348828  	0.10895252  
2023-05-16 15:23:48.694: [iter 155 : loss : 0.1109 = 0.0214 + 0.0825 + 0.0070, time: 7.650003]
2023-05-16 15:23:48.856: epoch 155:	0.02653890  	0.19372754  	0.10893140  
2023-05-16 15:23:57.188: [iter 156 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 8.331011]
2023-05-16 15:23:57.371: epoch 156:	0.02657418  	0.19423503  	0.10907508  
2023-05-16 15:24:05.722: [iter 157 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 8.350013]
2023-05-16 15:24:05.886: epoch 157:	0.02646833  	0.19349344  	0.10884223  
2023-05-16 15:24:13.521: [iter 158 : loss : 0.1095 = 0.0201 + 0.0824 + 0.0071, time: 7.634003]
2023-05-16 15:24:13.677: epoch 158:	0.02650362  	0.19391054  	0.10891216  
2023-05-16 15:24:22.816: [iter 159 : loss : 0.1098 = 0.0204 + 0.0823 + 0.0071, time: 9.137069]
2023-05-16 15:24:23.117: epoch 159:	0.02652478  	0.19377273  	0.10899892  
2023-05-16 15:24:30.535: [iter 160 : loss : 0.1094 = 0.0200 + 0.0823 + 0.0071, time: 7.416003]
2023-05-16 15:24:30.700: epoch 160:	0.02649656  	0.19359556  	0.10896559  
2023-05-16 15:24:39.175: [iter 161 : loss : 0.1088 = 0.0194 + 0.0823 + 0.0071, time: 8.474013]
2023-05-16 15:24:39.338: epoch 161:	0.02653890  	0.19382668  	0.10907210  
2023-05-16 15:24:47.721: [iter 162 : loss : 0.1084 = 0.0189 + 0.0822 + 0.0072, time: 8.382003]
2023-05-16 15:24:47.885: epoch 162:	0.02658830  	0.19421868  	0.10907961  
2023-05-16 15:24:55.524: [iter 163 : loss : 0.1088 = 0.0193 + 0.0822 + 0.0072, time: 7.637962]
2023-05-16 15:24:55.679: epoch 163:	0.02653891  	0.19378136  	0.10903885  
2023-05-16 15:25:04.706: [iter 164 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 9.024870]
2023-05-16 15:25:05.002: epoch 164:	0.02656007  	0.19370441  	0.10913483  
2023-05-16 15:25:05.003: Early stopping is trigger at epoch: 164
2023-05-16 15:25:05.003: best_result@epoch 139:

2023-05-16 15:25:05.003: 		0.0266      	0.1961      	0.1093      
2023-05-16 15:26:26.998: my pid: 2428
2023-05-16 15:26:26.998: model: model.general_recommender.SGL
2023-05-16 15:26:26.998: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 15:26:26.998: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 15:26:31.323: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 15:26:40.298: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.974509]
2023-05-16 15:26:40.455: epoch 1:	0.00142535  	0.01026722  	0.00504134  
2023-05-16 15:26:40.455: Find a better model.
2023-05-16 15:26:49.882: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 9.426031]
2023-05-16 15:26:50.097: epoch 2:	0.00264606  	0.01981615  	0.00965487  
2023-05-16 15:26:50.097: Find a better model.
2023-05-16 15:26:58.693: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.595041]
2023-05-16 15:26:58.867: epoch 3:	0.00463588  	0.03505517  	0.01677997  
2023-05-16 15:26:58.867: Find a better model.
2023-05-16 15:27:08.722: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 9.852776]
2023-05-16 15:27:09.041: epoch 4:	0.00788167  	0.05869089  	0.02842203  
2023-05-16 15:27:09.041: Find a better model.
2023-05-16 15:27:17.501: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 8.459014]
2023-05-16 15:27:17.946: epoch 5:	0.01196730  	0.08707643  	0.04202853  
2023-05-16 15:27:17.946: Find a better model.
2023-05-16 15:27:26.137: [iter 6 : loss : 0.7672 = 0.6880 + 0.0792 + 0.0000, time: 8.190057]
2023-05-16 15:27:26.364: epoch 6:	0.01565781  	0.11332510  	0.05520381  
2023-05-16 15:27:26.364: Find a better model.
2023-05-16 15:27:35.695: [iter 7 : loss : 0.7606 = 0.6806 + 0.0800 + 0.0000, time: 9.330302]
2023-05-16 15:27:35.848: epoch 7:	0.01793703  	0.13014849  	0.06464057  
2023-05-16 15:27:35.848: Find a better model.
2023-05-16 15:27:45.533: [iter 8 : loss : 0.7443 = 0.6623 + 0.0819 + 0.0001, time: 9.681369]
2023-05-16 15:27:45.838: epoch 8:	0.01887554  	0.13722047  	0.06920075  
2023-05-16 15:27:45.838: Find a better model.
2023-05-16 15:27:55.593: [iter 9 : loss : 0.7079 = 0.6219 + 0.0859 + 0.0001, time: 9.749551]
2023-05-16 15:27:55.857: epoch 9:	0.01873442  	0.13780306  	0.06905267  
2023-05-16 15:27:55.857: Find a better model.
2023-05-16 15:28:03.949: [iter 10 : loss : 0.6459 = 0.5545 + 0.0912 + 0.0003, time: 8.089767]
2023-05-16 15:28:04.113: epoch 10:	0.01852272  	0.13641284  	0.06860507  
2023-05-16 15:28:12.635: [iter 11 : loss : 0.5704 = 0.4738 + 0.0962 + 0.0004, time: 8.520209]
2023-05-16 15:28:12.829: epoch 11:	0.01846627  	0.13646494  	0.06808060  
2023-05-16 15:28:21.384: [iter 12 : loss : 0.5021 = 0.4020 + 0.0995 + 0.0006, time: 8.552527]
2023-05-16 15:28:21.529: epoch 12:	0.01842394  	0.13610099  	0.06818745  
2023-05-16 15:28:30.136: [iter 13 : loss : 0.4521 = 0.3501 + 0.1013 + 0.0007, time: 8.605762]
2023-05-16 15:28:30.310: epoch 13:	0.01850155  	0.13699491  	0.06877011  
2023-05-16 15:28:38.621: [iter 14 : loss : 0.4141 = 0.3111 + 0.1022 + 0.0009, time: 8.310152]
2023-05-16 15:28:38.789: epoch 14:	0.01881204  	0.13957226  	0.07001352  
2023-05-16 15:28:38.789: Find a better model.
2023-05-16 15:28:48.298: [iter 15 : loss : 0.3878 = 0.2842 + 0.1026 + 0.0010, time: 9.502537]
2023-05-16 15:28:48.612: epoch 15:	0.01894611  	0.14040507  	0.07055978  
2023-05-16 15:28:48.612: Find a better model.
2023-05-16 15:28:56.377: [iter 16 : loss : 0.3655 = 0.2618 + 0.1026 + 0.0011, time: 7.763040]
2023-05-16 15:28:56.588: epoch 16:	0.01903079  	0.14083512  	0.07116284  
2023-05-16 15:28:56.588: Find a better model.
2023-05-16 15:29:04.867: [iter 17 : loss : 0.3492 = 0.2456 + 0.1024 + 0.0012, time: 8.275165]
2023-05-16 15:29:05.024: epoch 17:	0.01932716  	0.14277855  	0.07234072  
2023-05-16 15:29:05.024: Find a better model.
2023-05-16 15:29:13.333: [iter 18 : loss : 0.3340 = 0.2305 + 0.1021 + 0.0013, time: 8.308378]
2023-05-16 15:29:13.514: epoch 18:	0.01953886  	0.14392127  	0.07319109  
2023-05-16 15:29:13.514: Find a better model.
2023-05-16 15:29:21.233: [iter 19 : loss : 0.3200 = 0.2168 + 0.1018 + 0.0014, time: 7.717018]
2023-05-16 15:29:21.391: epoch 19:	0.01978584  	0.14590961  	0.07413173  
2023-05-16 15:29:21.391: Find a better model.
2023-05-16 15:29:30.694: [iter 20 : loss : 0.3103 = 0.2074 + 0.1014 + 0.0015, time: 9.291044]
2023-05-16 15:29:31.005: epoch 20:	0.02005400  	0.14774038  	0.07483389  
2023-05-16 15:29:31.005: Find a better model.
2023-05-16 15:29:38.888: [iter 21 : loss : 0.3007 = 0.1981 + 0.1010 + 0.0016, time: 7.882026]
2023-05-16 15:29:39.051: epoch 21:	0.02029392  	0.14941160  	0.07581161  
2023-05-16 15:29:39.051: Find a better model.
2023-05-16 15:29:47.483: [iter 22 : loss : 0.2923 = 0.1901 + 0.1006 + 0.0017, time: 8.430067]
2023-05-16 15:29:47.648: epoch 22:	0.02045622  	0.15084627  	0.07658699  
2023-05-16 15:29:47.648: Find a better model.
2023-05-16 15:29:56.237: [iter 23 : loss : 0.2843 = 0.1823 + 0.1002 + 0.0017, time: 8.587035]
2023-05-16 15:29:56.389: epoch 23:	0.02068202  	0.15228701  	0.07726151  
2023-05-16 15:29:56.390: Find a better model.
2023-05-16 15:30:04.402: [iter 24 : loss : 0.2777 = 0.1762 + 0.0997 + 0.0018, time: 8.011029]
2023-05-16 15:30:04.558: epoch 24:	0.02085844  	0.15341868  	0.07808919  
2023-05-16 15:30:04.558: Find a better model.
2023-05-16 15:30:13.836: [iter 25 : loss : 0.2713 = 0.1701 + 0.0993 + 0.0019, time: 9.277053]
2023-05-16 15:30:14.115: epoch 25:	0.02096429  	0.15456820  	0.07892542  
2023-05-16 15:30:14.115: Find a better model.
2023-05-16 15:30:22.410: [iter 26 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 8.293048]
2023-05-16 15:30:22.579: epoch 26:	0.02118305  	0.15588960  	0.07990561  
2023-05-16 15:30:22.579: Find a better model.
2023-05-16 15:30:31.073: [iter 27 : loss : 0.2599 = 0.1595 + 0.0984 + 0.0020, time: 8.490776]
2023-05-16 15:30:31.275: epoch 27:	0.02141591  	0.15787821  	0.08049881  
2023-05-16 15:30:31.276: Find a better model.
2023-05-16 15:30:39.795: [iter 28 : loss : 0.2548 = 0.1547 + 0.0981 + 0.0021, time: 8.515521]
2023-05-16 15:30:39.958: epoch 28:	0.02147942  	0.15829261  	0.08107565  
2023-05-16 15:30:39.958: Find a better model.
2023-05-16 15:30:47.824: [iter 29 : loss : 0.2502 = 0.1505 + 0.0976 + 0.0021, time: 7.865029]
2023-05-16 15:30:47.980: epoch 29:	0.02164171  	0.15913150  	0.08156366  
2023-05-16 15:30:47.980: Find a better model.
2023-05-16 15:30:57.279: [iter 30 : loss : 0.2441 = 0.1446 + 0.0973 + 0.0022, time: 9.296030]
2023-05-16 15:30:57.585: epoch 30:	0.02186046  	0.16075183  	0.08259691  
2023-05-16 15:30:57.585: Find a better model.
2023-05-16 15:31:05.905: [iter 31 : loss : 0.2401 = 0.1410 + 0.0969 + 0.0023, time: 8.319049]
2023-05-16 15:31:06.081: epoch 31:	0.02194514  	0.16145959  	0.08326212  
2023-05-16 15:31:06.082: Find a better model.
2023-05-16 15:31:14.477: [iter 32 : loss : 0.2348 = 0.1360 + 0.0965 + 0.0023, time: 8.394265]
2023-05-16 15:31:14.649: epoch 32:	0.02201570  	0.16220467  	0.08370502  
2023-05-16 15:31:14.649: Find a better model.
2023-05-16 15:31:23.171: [iter 33 : loss : 0.2320 = 0.1335 + 0.0961 + 0.0024, time: 8.519997]
2023-05-16 15:31:23.378: epoch 33:	0.02230502  	0.16422994  	0.08466215  
2023-05-16 15:31:23.378: Find a better model.
2023-05-16 15:31:31.185: [iter 34 : loss : 0.2281 = 0.1299 + 0.0958 + 0.0024, time: 7.805048]
2023-05-16 15:31:31.343: epoch 34:	0.02241087  	0.16516730  	0.08523627  
2023-05-16 15:31:31.343: Find a better model.
2023-05-16 15:31:40.510: [iter 35 : loss : 0.2245 = 0.1265 + 0.0955 + 0.0025, time: 9.164020]
2023-05-16 15:31:40.813: epoch 35:	0.02262257  	0.16687563  	0.08614984  
2023-05-16 15:31:40.813: Find a better model.
2023-05-16 15:31:49.337: [iter 36 : loss : 0.2214 = 0.1236 + 0.0952 + 0.0025, time: 8.522006]
2023-05-16 15:31:49.511: epoch 36:	0.02263668  	0.16681728  	0.08645532  
2023-05-16 15:31:57.810: [iter 37 : loss : 0.2173 = 0.1199 + 0.0948 + 0.0026, time: 8.298269]
2023-05-16 15:31:57.988: epoch 37:	0.02281309  	0.16812184  	0.08707836  
2023-05-16 15:31:57.988: Find a better model.
2023-05-16 15:32:06.405: [iter 38 : loss : 0.2158 = 0.1185 + 0.0946 + 0.0027, time: 8.415018]
2023-05-16 15:32:06.799: epoch 38:	0.02293305  	0.16910610  	0.08777557  
2023-05-16 15:32:06.800: Find a better model.
2023-05-16 15:32:14.596: [iter 39 : loss : 0.2113 = 0.1144 + 0.0942 + 0.0027, time: 7.795019]
2023-05-16 15:32:14.752: epoch 39:	0.02317298  	0.17075691  	0.08884676  
2023-05-16 15:32:14.753: Find a better model.
2023-05-16 15:32:23.892: [iter 40 : loss : 0.2080 = 0.1113 + 0.0939 + 0.0028, time: 9.136009]
2023-05-16 15:32:24.170: epoch 40:	0.02325766  	0.17152612  	0.08922867  
2023-05-16 15:32:24.170: Find a better model.
2023-05-16 15:32:32.857: [iter 41 : loss : 0.2062 = 0.1097 + 0.0936 + 0.0028, time: 8.685034]
2023-05-16 15:32:33.032: epoch 41:	0.02325060  	0.17161950  	0.08969447  
2023-05-16 15:32:33.032: Find a better model.
2023-05-16 15:32:41.240: [iter 42 : loss : 0.2041 = 0.1079 + 0.0934 + 0.0029, time: 8.206016]
2023-05-16 15:32:41.415: epoch 42:	0.02333527  	0.17233358  	0.09020544  
2023-05-16 15:32:41.415: Find a better model.
2023-05-16 15:32:49.503: [iter 43 : loss : 0.2003 = 0.1044 + 0.0931 + 0.0029, time: 8.087006]
2023-05-16 15:32:50.089: epoch 43:	0.02338467  	0.17266327  	0.09063278  
2023-05-16 15:32:50.089: Find a better model.
2023-05-16 15:32:57.955: [iter 44 : loss : 0.1968 = 0.1010 + 0.0928 + 0.0030, time: 7.863993]
2023-05-16 15:32:58.111: epoch 44:	0.02347640  	0.17311744  	0.09100088  
2023-05-16 15:32:58.111: Find a better model.
2023-05-16 15:33:07.383: [iter 45 : loss : 0.1947 = 0.0991 + 0.0925 + 0.0030, time: 9.266068]
2023-05-16 15:33:07.700: epoch 45:	0.02350462  	0.17341018  	0.09147041  
2023-05-16 15:33:07.700: Find a better model.
2023-05-16 15:33:16.064: [iter 46 : loss : 0.1924 = 0.0970 + 0.0923 + 0.0031, time: 8.361026]
2023-05-16 15:33:16.263: epoch 46:	0.02366692  	0.17461294  	0.09217574  
2023-05-16 15:33:16.263: Find a better model.
2023-05-16 15:33:24.634: [iter 47 : loss : 0.1915 = 0.0962 + 0.0921 + 0.0031, time: 8.368004]
2023-05-16 15:33:24.812: epoch 47:	0.02373043  	0.17487155  	0.09243582  
2023-05-16 15:33:24.812: Find a better model.
2023-05-16 15:33:33.132: [iter 48 : loss : 0.1876 = 0.0926 + 0.0918 + 0.0032, time: 8.318291]
2023-05-16 15:33:33.520: epoch 48:	0.02386451  	0.17562461  	0.09306887  
2023-05-16 15:33:33.520: Find a better model.
2023-05-16 15:33:41.530: [iter 49 : loss : 0.1842 = 0.0893 + 0.0916 + 0.0032, time: 8.009125]
2023-05-16 15:33:41.690: epoch 49:	0.02390684  	0.17599908  	0.09343331  
2023-05-16 15:33:41.690: Find a better model.
2023-05-16 15:33:50.875: [iter 50 : loss : 0.1839 = 0.0892 + 0.0914 + 0.0033, time: 9.182033]
2023-05-16 15:33:51.188: epoch 50:	0.02394918  	0.17628917  	0.09382365  
2023-05-16 15:33:51.188: Find a better model.
2023-05-16 15:33:59.549: [iter 51 : loss : 0.1806 = 0.0861 + 0.0912 + 0.0033, time: 8.360031]
2023-05-16 15:33:59.714: epoch 51:	0.02402680  	0.17686665  	0.09414261  
2023-05-16 15:33:59.714: Find a better model.
2023-05-16 15:34:08.388: [iter 52 : loss : 0.1805 = 0.0861 + 0.0910 + 0.0034, time: 8.672015]
2023-05-16 15:34:08.563: epoch 52:	0.02411147  	0.17765357  	0.09468469  
2023-05-16 15:34:08.563: Find a better model.
2023-05-16 15:34:17.114: [iter 53 : loss : 0.1785 = 0.0843 + 0.0908 + 0.0034, time: 8.549063]
2023-05-16 15:34:17.278: epoch 53:	0.02424554  	0.17884374  	0.09527928  
2023-05-16 15:34:17.278: Find a better model.
2023-05-16 15:34:25.152: [iter 54 : loss : 0.1765 = 0.0825 + 0.0906 + 0.0035, time: 7.872002]
2023-05-16 15:34:25.310: epoch 54:	0.02428083  	0.17919792  	0.09567080  
2023-05-16 15:34:25.310: Find a better model.
2023-05-16 15:34:34.510: [iter 55 : loss : 0.1746 = 0.0807 + 0.0904 + 0.0035, time: 9.193012]
2023-05-16 15:34:34.819: epoch 55:	0.02433728  	0.17962524  	0.09621666  
2023-05-16 15:34:34.819: Find a better model.
2023-05-16 15:34:43.136: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 8.314013]
2023-05-16 15:34:43.331: epoch 56:	0.02440785  	0.18020500  	0.09647487  
2023-05-16 15:34:43.332: Find a better model.
2023-05-16 15:34:51.784: [iter 57 : loss : 0.1708 = 0.0772 + 0.0900 + 0.0036, time: 8.451017]
2023-05-16 15:34:51.952: epoch 57:	0.02456308  	0.18108843  	0.09691887  
2023-05-16 15:34:51.952: Find a better model.
2023-05-16 15:35:00.476: [iter 58 : loss : 0.1691 = 0.0756 + 0.0899 + 0.0036, time: 8.523026]
2023-05-16 15:35:00.629: epoch 58:	0.02465483  	0.18179753  	0.09722175  
2023-05-16 15:35:00.629: Find a better model.
2023-05-16 15:35:08.531: [iter 59 : loss : 0.1681 = 0.0748 + 0.0897 + 0.0037, time: 7.900025]
2023-05-16 15:35:08.687: epoch 59:	0.02471128  	0.18200158  	0.09748562  
2023-05-16 15:35:08.687: Find a better model.
2023-05-16 15:35:17.995: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 9.305055]
2023-05-16 15:35:18.288: epoch 60:	0.02478185  	0.18234213  	0.09798060  
2023-05-16 15:35:18.288: Find a better model.
2023-05-16 15:35:26.643: [iter 61 : loss : 0.1649 = 0.0718 + 0.0893 + 0.0038, time: 8.353039]
2023-05-16 15:35:26.819: epoch 61:	0.02492297  	0.18356311  	0.09853236  
2023-05-16 15:35:26.819: Find a better model.
2023-05-16 15:35:35.359: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 8.539057]
2023-05-16 15:35:35.528: epoch 62:	0.02501470  	0.18375631  	0.09880628  
2023-05-16 15:35:35.528: Find a better model.
2023-05-16 15:35:43.586: [iter 63 : loss : 0.1623 = 0.0694 + 0.0890 + 0.0039, time: 8.055330]
2023-05-16 15:35:44.111: epoch 63:	0.02497236  	0.18364212  	0.09900793  
2023-05-16 15:35:52.105: [iter 64 : loss : 0.1611 = 0.0683 + 0.0888 + 0.0039, time: 7.993045]
2023-05-16 15:35:52.267: epoch 64:	0.02502881  	0.18393014  	0.09930518  
2023-05-16 15:35:52.268: Find a better model.
2023-05-16 15:36:01.508: [iter 65 : loss : 0.1598 = 0.0672 + 0.0887 + 0.0039, time: 9.238019]
2023-05-16 15:36:01.772: epoch 65:	0.02508526  	0.18439014  	0.09949239  
2023-05-16 15:36:01.772: Find a better model.
2023-05-16 15:36:10.247: [iter 66 : loss : 0.1583 = 0.0658 + 0.0885 + 0.0040, time: 8.474023]
2023-05-16 15:36:10.410: epoch 66:	0.02516994  	0.18530454  	0.10015549  
2023-05-16 15:36:10.410: Find a better model.
2023-05-16 15:36:18.730: [iter 67 : loss : 0.1566 = 0.0642 + 0.0884 + 0.0040, time: 8.318027]
2023-05-16 15:36:18.907: epoch 67:	0.02524756  	0.18562907  	0.10037307  
2023-05-16 15:36:18.907: Find a better model.
2023-05-16 15:36:26.969: [iter 68 : loss : 0.1564 = 0.0641 + 0.0883 + 0.0041, time: 8.061041]
2023-05-16 15:36:27.545: epoch 68:	0.02524756  	0.18576196  	0.10043280  
2023-05-16 15:36:27.545: Find a better model.
2023-05-16 15:36:35.285: [iter 69 : loss : 0.1543 = 0.0621 + 0.0881 + 0.0041, time: 7.738016]
2023-05-16 15:36:35.431: epoch 69:	0.02537458  	0.18691270  	0.10106761  
2023-05-16 15:36:35.431: Find a better model.
2023-05-16 15:36:44.791: [iter 70 : loss : 0.1529 = 0.0607 + 0.0880 + 0.0042, time: 9.352036]
2023-05-16 15:36:45.105: epoch 70:	0.02546631  	0.18722184  	0.10144673  
2023-05-16 15:36:45.105: Find a better model.
2023-05-16 15:36:53.727: [iter 71 : loss : 0.1511 = 0.0590 + 0.0879 + 0.0042, time: 8.621038]
2023-05-16 15:36:53.903: epoch 71:	0.02552982  	0.18792163  	0.10161564  
2023-05-16 15:36:53.903: Find a better model.
2023-05-16 15:37:02.364: [iter 72 : loss : 0.1512 = 0.0592 + 0.0878 + 0.0042, time: 8.458610]
2023-05-16 15:37:02.530: epoch 72:	0.02551571  	0.18777798  	0.10194121  
2023-05-16 15:37:10.891: [iter 73 : loss : 0.1497 = 0.0578 + 0.0876 + 0.0043, time: 8.360035]
2023-05-16 15:37:11.290: epoch 73:	0.02564978  	0.18889114  	0.10225125  
2023-05-16 15:37:11.290: Find a better model.
2023-05-16 15:37:19.249: [iter 74 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0043, time: 7.958030]
2023-05-16 15:37:19.405: epoch 74:	0.02563567  	0.18885472  	0.10235017  
2023-05-16 15:37:28.752: [iter 75 : loss : 0.1477 = 0.0559 + 0.0874 + 0.0044, time: 9.345025]
2023-05-16 15:37:29.062: epoch 75:	0.02572035  	0.18943326  	0.10286935  
2023-05-16 15:37:29.062: Find a better model.
2023-05-16 15:37:37.350: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 8.287001]
2023-05-16 15:37:37.518: epoch 76:	0.02574152  	0.18948355  	0.10295109  
2023-05-16 15:37:37.518: Find a better model.
2023-05-16 15:37:45.921: [iter 77 : loss : 0.1459 = 0.0543 + 0.0872 + 0.0044, time: 8.402545]
2023-05-16 15:37:46.099: epoch 77:	0.02583325  	0.18998584  	0.10321829  
2023-05-16 15:37:46.099: Find a better model.
2023-05-16 15:37:54.516: [iter 78 : loss : 0.1450 = 0.0535 + 0.0870 + 0.0045, time: 8.414274]
2023-05-16 15:37:54.898: epoch 78:	0.02581209  	0.18991862  	0.10322616  
2023-05-16 15:38:02.845: [iter 79 : loss : 0.1437 = 0.0523 + 0.0869 + 0.0045, time: 7.945028]
2023-05-16 15:38:03.001: epoch 79:	0.02577680  	0.18935443  	0.10309155  
2023-05-16 15:38:12.229: [iter 80 : loss : 0.1431 = 0.0517 + 0.0868 + 0.0046, time: 9.218006]
2023-05-16 15:38:12.501: epoch 80:	0.02577680  	0.18910570  	0.10330389  
2023-05-16 15:38:20.998: [iter 81 : loss : 0.1427 = 0.0514 + 0.0867 + 0.0046, time: 8.496015]
2023-05-16 15:38:21.177: epoch 81:	0.02576975  	0.18905735  	0.10334282  
2023-05-16 15:38:29.716: [iter 82 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 8.536042]
2023-05-16 15:38:29.898: epoch 82:	0.02590382  	0.18999678  	0.10377419  
2023-05-16 15:38:29.898: Find a better model.
2023-05-16 15:38:38.316: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 8.417037]
2023-05-16 15:38:38.604: epoch 83:	0.02583326  	0.18937899  	0.10396642  
2023-05-16 15:38:46.623: [iter 84 : loss : 0.1403 = 0.0492 + 0.0864 + 0.0047, time: 8.018039]
2023-05-16 15:38:46.779: epoch 84:	0.02584031  	0.18931302  	0.10407167  
2023-05-16 15:38:56.092: [iter 85 : loss : 0.1392 = 0.0481 + 0.0863 + 0.0048, time: 9.310021]
2023-05-16 15:38:56.408: epoch 85:	0.02593910  	0.18977882  	0.10420143  
2023-05-16 15:39:04.713: [iter 86 : loss : 0.1393 = 0.0483 + 0.0862 + 0.0048, time: 8.303016]
2023-05-16 15:39:04.882: epoch 86:	0.02594616  	0.18975413  	0.10431901  
2023-05-16 15:39:13.286: [iter 87 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0048, time: 8.403019]
2023-05-16 15:39:13.451: epoch 87:	0.02586148  	0.18927057  	0.10433227  
2023-05-16 15:39:21.861: [iter 88 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 8.408029]
2023-05-16 15:39:22.229: epoch 88:	0.02588971  	0.18955213  	0.10444316  
2023-05-16 15:39:30.209: [iter 89 : loss : 0.1356 = 0.0448 + 0.0859 + 0.0049, time: 7.979073]
2023-05-16 15:39:30.365: epoch 89:	0.02594616  	0.18944193  	0.10464317  
2023-05-16 15:39:39.716: [iter 90 : loss : 0.1360 = 0.0453 + 0.0858 + 0.0050, time: 9.349071]
2023-05-16 15:39:39.980: epoch 90:	0.02607318  	0.19041862  	0.10525195  
2023-05-16 15:39:39.980: Find a better model.
2023-05-16 15:39:48.421: [iter 91 : loss : 0.1347 = 0.0440 + 0.0858 + 0.0050, time: 8.440036]
2023-05-16 15:39:48.598: epoch 91:	0.02601673  	0.19005193  	0.10503335  
2023-05-16 15:39:57.052: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 8.453043]
2023-05-16 15:39:57.273: epoch 92:	0.02606612  	0.19076717  	0.10526460  
2023-05-16 15:39:57.274: Find a better model.
2023-05-16 15:40:05.730: [iter 93 : loss : 0.1342 = 0.0436 + 0.0856 + 0.0051, time: 8.450022]
2023-05-16 15:40:05.968: epoch 93:	0.02614374  	0.19140938  	0.10560355  
2023-05-16 15:40:05.968: Find a better model.
2023-05-16 15:40:13.835: [iter 94 : loss : 0.1320 = 0.0413 + 0.0855 + 0.0051, time: 7.865013]
2023-05-16 15:40:13.993: epoch 94:	0.02616491  	0.19146289  	0.10557026  
2023-05-16 15:40:13.993: Find a better model.
2023-05-16 15:40:23.162: [iter 95 : loss : 0.1312 = 0.0407 + 0.0854 + 0.0051, time: 9.163047]
2023-05-16 15:40:23.477: epoch 95:	0.02617197  	0.19158012  	0.10574400  
2023-05-16 15:40:23.477: Find a better model.
2023-05-16 15:40:31.897: [iter 96 : loss : 0.1314 = 0.0409 + 0.0854 + 0.0052, time: 8.417065]
2023-05-16 15:40:32.073: epoch 96:	0.02624253  	0.19186102  	0.10585103  
2023-05-16 15:40:32.073: Find a better model.
2023-05-16 15:40:40.467: [iter 97 : loss : 0.1295 = 0.0390 + 0.0853 + 0.0052, time: 8.393029]
2023-05-16 15:40:40.644: epoch 97:	0.02622841  	0.19192095  	0.10589816  
2023-05-16 15:40:40.645: Find a better model.
2023-05-16 15:40:48.850: [iter 98 : loss : 0.1307 = 0.0402 + 0.0852 + 0.0052, time: 8.204017]
2023-05-16 15:40:49.400: epoch 98:	0.02627075  	0.19220397  	0.10603276  
2023-05-16 15:40:49.400: Find a better model.
2023-05-16 15:40:57.217: [iter 99 : loss : 0.1294 = 0.0390 + 0.0852 + 0.0053, time: 7.815014]
2023-05-16 15:40:57.374: epoch 99:	0.02635543  	0.19268580  	0.10612174  
2023-05-16 15:40:57.374: Find a better model.
2023-05-16 15:41:06.515: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 9.133013]
2023-05-16 15:41:06.824: epoch 100:	0.02634132  	0.19234395  	0.10615198  
2023-05-16 15:41:15.291: [iter 101 : loss : 0.1285 = 0.0382 + 0.0850 + 0.0054, time: 8.465999]
2023-05-16 15:41:15.455: epoch 101:	0.02636955  	0.19263029  	0.10639825  
2023-05-16 15:41:23.847: [iter 102 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 8.390544]
2023-05-16 15:41:24.022: epoch 102:	0.02644012  	0.19319314  	0.10677243  
2023-05-16 15:41:24.022: Find a better model.
2023-05-16 15:41:31.883: [iter 103 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0054, time: 7.860019]
2023-05-16 15:41:32.323: epoch 103:	0.02641189  	0.19283929  	0.10669530  
2023-05-16 15:41:40.364: [iter 104 : loss : 0.1276 = 0.0374 + 0.0848 + 0.0055, time: 8.030008]
2023-05-16 15:41:40.522: epoch 104:	0.02646128  	0.19323578  	0.10681797  
2023-05-16 15:41:40.522: Find a better model.
2023-05-16 15:41:49.707: [iter 105 : loss : 0.1268 = 0.0366 + 0.0847 + 0.0055, time: 9.183017]
2023-05-16 15:41:50.031: epoch 105:	0.02646834  	0.19326994  	0.10691962  
2023-05-16 15:41:50.031: Find a better model.
2023-05-16 15:41:58.890: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 8.857013]
2023-05-16 15:41:59.068: epoch 106:	0.02644717  	0.19298282  	0.10705530  
2023-05-16 15:42:07.188: [iter 107 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 8.118219]
2023-05-16 15:42:07.400: epoch 107:	0.02649656  	0.19358310  	0.10723434  
2023-05-16 15:42:07.400: Find a better model.
2023-05-16 15:42:15.214: [iter 108 : loss : 0.1252 = 0.0350 + 0.0845 + 0.0056, time: 7.812103]
2023-05-16 15:42:15.372: epoch 108:	0.02653184  	0.19380116  	0.10745799  
2023-05-16 15:42:15.372: Find a better model.
2023-05-16 15:42:23.390: [iter 109 : loss : 0.1238 = 0.0337 + 0.0844 + 0.0056, time: 8.017016]
2023-05-16 15:42:23.546: epoch 109:	0.02648950  	0.19352861  	0.10749257  
2023-05-16 15:42:32.733: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 9.185012]
2023-05-16 15:42:33.040: epoch 110:	0.02655301  	0.19386001  	0.10748866  
2023-05-16 15:42:33.041: Find a better model.
2023-05-16 15:42:42.224: [iter 111 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 9.180022]
2023-05-16 15:42:42.492: epoch 111:	0.02660240  	0.19427550  	0.10758197  
2023-05-16 15:42:42.492: Find a better model.
2023-05-16 15:42:50.572: [iter 112 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0057, time: 8.079038]
2023-05-16 15:42:50.732: epoch 112:	0.02653890  	0.19421391  	0.10764961  
2023-05-16 15:42:58.384: [iter 113 : loss : 0.1230 = 0.0330 + 0.0842 + 0.0058, time: 7.650029]
2023-05-16 15:42:58.546: epoch 113:	0.02648244  	0.19383901  	0.10758664  
2023-05-16 15:43:06.829: [iter 114 : loss : 0.1222 = 0.0323 + 0.0842 + 0.0058, time: 8.281001]
2023-05-16 15:43:06.992: epoch 114:	0.02636955  	0.19276926  	0.10731784  
2023-05-16 15:43:16.262: [iter 115 : loss : 0.1217 = 0.0317 + 0.0841 + 0.0058, time: 9.268020]
2023-05-16 15:43:16.526: epoch 115:	0.02643305  	0.19288857  	0.10759103  
2023-05-16 15:43:25.787: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 9.258036]
2023-05-16 15:43:26.107: epoch 116:	0.02642599  	0.19309837  	0.10755420  
2023-05-16 15:43:34.129: [iter 117 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 8.020972]
2023-05-16 15:43:34.290: epoch 117:	0.02653184  	0.19392572  	0.10792591  
2023-05-16 15:43:41.940: [iter 118 : loss : 0.1208 = 0.0309 + 0.0839 + 0.0059, time: 7.649054]
2023-05-16 15:43:42.101: epoch 118:	0.02643305  	0.19295093  	0.10763104  
2023-05-16 15:43:50.411: [iter 119 : loss : 0.1198 = 0.0299 + 0.0839 + 0.0060, time: 8.309061]
2023-05-16 15:43:50.575: epoch 119:	0.02648244  	0.19350564  	0.10775741  
2023-05-16 15:43:59.754: [iter 120 : loss : 0.1200 = 0.0302 + 0.0839 + 0.0060, time: 9.177020]
2023-05-16 15:44:00.074: epoch 120:	0.02651772  	0.19347782  	0.10803179  
2023-05-16 15:44:09.259: [iter 121 : loss : 0.1200 = 0.0301 + 0.0838 + 0.0060, time: 9.181007]
2023-05-16 15:44:09.572: epoch 121:	0.02646833  	0.19305874  	0.10794780  
2023-05-16 15:44:17.524: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 7.951017]
2023-05-16 15:44:17.693: epoch 122:	0.02641188  	0.19264774  	0.10796545  
2023-05-16 15:44:25.324: [iter 123 : loss : 0.1189 = 0.0291 + 0.0837 + 0.0061, time: 7.629000]
2023-05-16 15:44:25.480: epoch 123:	0.02642599  	0.19255367  	0.10775100  
2023-05-16 15:44:33.746: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 8.265020]
2023-05-16 15:44:33.908: epoch 124:	0.02639777  	0.19264129  	0.10782622  
2023-05-16 15:44:43.023: [iter 125 : loss : 0.1174 = 0.0277 + 0.0836 + 0.0061, time: 9.110015]
2023-05-16 15:44:43.335: epoch 125:	0.02644011  	0.19298002  	0.10787389  
2023-05-16 15:44:52.427: [iter 126 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0062, time: 9.091013]
2023-05-16 15:44:52.738: epoch 126:	0.02640483  	0.19312692  	0.10794678  
2023-05-16 15:45:00.798: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 8.058003]
2023-05-16 15:45:01.037: epoch 127:	0.02642600  	0.19306053  	0.10805596  
2023-05-16 15:45:08.498: [iter 128 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 7.457428]
2023-05-16 15:45:08.660: epoch 128:	0.02650362  	0.19353744  	0.10830169  
2023-05-16 15:45:17.154: [iter 129 : loss : 0.1170 = 0.0274 + 0.0834 + 0.0063, time: 8.493425]
2023-05-16 15:45:17.389: epoch 129:	0.02653184  	0.19394144  	0.10830517  
2023-05-16 15:45:26.492: [iter 130 : loss : 0.1169 = 0.0273 + 0.0834 + 0.0063, time: 9.099015]
2023-05-16 15:45:26.754: epoch 130:	0.02650362  	0.19351871  	0.10827958  
2023-05-16 15:45:35.888: [iter 131 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 9.130007]
2023-05-16 15:45:36.211: epoch 131:	0.02653184  	0.19382812  	0.10840036  
2023-05-16 15:45:44.287: [iter 132 : loss : 0.1163 = 0.0267 + 0.0833 + 0.0064, time: 8.075086]
2023-05-16 15:45:44.434: epoch 132:	0.02656007  	0.19398393  	0.10846408  
2023-05-16 15:45:51.906: [iter 133 : loss : 0.1151 = 0.0254 + 0.0833 + 0.0064, time: 7.471009]
2023-05-16 15:45:52.083: epoch 133:	0.02648245  	0.19364443  	0.10834205  
2023-05-16 15:46:00.086: [iter 134 : loss : 0.1159 = 0.0262 + 0.0832 + 0.0064, time: 8.001439]
2023-05-16 15:46:00.372: epoch 134:	0.02656713  	0.19404492  	0.10857542  
2023-05-16 15:46:08.900: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 8.526015]
2023-05-16 15:46:09.211: epoch 135:	0.02652479  	0.19389358  	0.10865533  
2023-05-16 15:46:18.353: [iter 136 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 9.135036]
2023-05-16 15:46:18.666: epoch 136:	0.02648245  	0.19359887  	0.10830075  
2023-05-16 15:46:18.666: Early stopping is trigger at epoch: 136
2023-05-16 15:46:18.666: best_result@epoch 111:

2023-05-16 15:46:18.666: 		0.0266      	0.1943      	0.1076      
2023-05-16 15:55:03.786: my pid: 14244
2023-05-16 15:55:03.786: model: model.general_recommender.SGL
2023-05-16 15:55:03.786: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 15:55:03.786: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 15:55:07.085: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 15:55:15.561: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.475614]
2023-05-16 15:55:15.729: epoch 1:	0.00137595  	0.00980986  	0.00516534  
2023-05-16 15:55:15.729: Find a better model.
2023-05-16 15:55:25.623: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 9.892065]
2023-05-16 15:55:25.879: epoch 2:	0.00276602  	0.02047260  	0.01047762  
2023-05-16 15:55:25.879: Find a better model.
2023-05-16 15:55:38.055: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 12.173221]
2023-05-16 15:55:38.274: epoch 3:	0.00494634  	0.03644122  	0.01739454  
2023-05-16 15:55:38.274: Find a better model.
2023-05-16 15:55:50.651: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 12.374760]
2023-05-16 15:55:50.887: epoch 4:	0.00780406  	0.05724849  	0.02702915  
2023-05-16 15:55:50.887: Find a better model.
2023-05-16 15:56:02.719: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 11.829855]
2023-05-16 15:56:03.157: epoch 5:	0.01148041  	0.08433701  	0.04032828  
2023-05-16 15:56:03.157: Find a better model.
2023-05-16 15:56:11.166: [iter 6 : loss : 0.7673 = 0.6881 + 0.0792 + 0.0000, time: 8.007348]
2023-05-16 15:56:11.325: epoch 6:	0.01510742  	0.10851147  	0.05322086  
2023-05-16 15:56:11.325: Find a better model.
2023-05-16 15:56:20.172: [iter 7 : loss : 0.7609 = 0.6809 + 0.0799 + 0.0000, time: 8.845416]
2023-05-16 15:56:20.331: epoch 7:	0.01764066  	0.12671110  	0.06345960  
2023-05-16 15:56:20.331: Find a better model.
2023-05-16 15:56:28.758: [iter 8 : loss : 0.7451 = 0.6632 + 0.0818 + 0.0001, time: 8.426391]
2023-05-16 15:56:28.916: epoch 8:	0.01877675  	0.13672711  	0.06845886  
2023-05-16 15:56:28.916: Find a better model.
2023-05-16 15:56:36.836: [iter 9 : loss : 0.7096 = 0.6237 + 0.0857 + 0.0001, time: 7.919315]
2023-05-16 15:56:36.977: epoch 9:	0.01857917  	0.13633461  	0.06868273  
2023-05-16 15:56:44.766: [iter 10 : loss : 0.6485 = 0.5572 + 0.0911 + 0.0002, time: 7.787872]
2023-05-16 15:56:44.923: epoch 10:	0.01845216  	0.13614884  	0.06822598  
2023-05-16 15:56:52.974: [iter 11 : loss : 0.5730 = 0.4765 + 0.0960 + 0.0004, time: 8.050200]
2023-05-16 15:56:53.116: epoch 11:	0.01833220  	0.13518956  	0.06774931  
2023-05-16 15:57:01.001: [iter 12 : loss : 0.5043 = 0.4044 + 0.0994 + 0.0006, time: 7.882048]
2023-05-16 15:57:01.166: epoch 12:	0.01837455  	0.13584633  	0.06811771  
2023-05-16 15:57:09.163: [iter 13 : loss : 0.4534 = 0.3515 + 0.1012 + 0.0007, time: 7.995468]
2023-05-16 15:57:09.317: epoch 13:	0.01849450  	0.13662463  	0.06855366  
2023-05-16 15:57:17.186: [iter 14 : loss : 0.4149 = 0.3119 + 0.1022 + 0.0008, time: 7.867642]
2023-05-16 15:57:17.335: epoch 14:	0.01865680  	0.13776013  	0.06922902  
2023-05-16 15:57:17.335: Find a better model.
2023-05-16 15:57:25.004: [iter 15 : loss : 0.3882 = 0.2847 + 0.1025 + 0.0010, time: 7.668398]
2023-05-16 15:57:25.177: epoch 15:	0.01881204  	0.13864733  	0.06993185  
2023-05-16 15:57:25.178: Find a better model.
2023-05-16 15:57:32.896: [iter 16 : loss : 0.3656 = 0.2619 + 0.1025 + 0.0011, time: 7.716058]
2023-05-16 15:57:33.053: epoch 16:	0.01902374  	0.14007869  	0.07079644  
2023-05-16 15:57:33.053: Find a better model.
2023-05-16 15:57:40.661: [iter 17 : loss : 0.3492 = 0.2456 + 0.1024 + 0.0012, time: 7.605410]
2023-05-16 15:57:40.817: epoch 17:	0.01922132  	0.14137396  	0.07177345  
2023-05-16 15:57:40.817: Find a better model.
2023-05-16 15:57:48.440: [iter 18 : loss : 0.3340 = 0.2305 + 0.1021 + 0.0013, time: 7.622765]
2023-05-16 15:57:48.606: epoch 18:	0.01942597  	0.14285584  	0.07255458  
2023-05-16 15:57:48.606: Find a better model.
2023-05-16 15:57:56.024: [iter 19 : loss : 0.3199 = 0.2167 + 0.1018 + 0.0014, time: 7.416260]
2023-05-16 15:57:56.176: epoch 19:	0.01969412  	0.14499779  	0.07369068  
2023-05-16 15:57:56.176: Find a better model.
2023-05-16 15:58:03.524: [iter 20 : loss : 0.3102 = 0.2073 + 0.1014 + 0.0015, time: 7.347349]
2023-05-16 15:58:03.671: epoch 20:	0.01986348  	0.14648378  	0.07429649  
2023-05-16 15:58:03.671: Find a better model.
2023-05-16 15:58:11.399: [iter 21 : loss : 0.3007 = 0.1981 + 0.1010 + 0.0016, time: 7.725171]
2023-05-16 15:58:11.555: epoch 21:	0.02010340  	0.14807679  	0.07508535  
2023-05-16 15:58:11.555: Find a better model.
2023-05-16 15:58:18.972: [iter 22 : loss : 0.2924 = 0.1901 + 0.1007 + 0.0017, time: 7.415599]
2023-05-16 15:58:19.126: epoch 22:	0.02032214  	0.14967696  	0.07576636  
2023-05-16 15:58:19.126: Find a better model.
2023-05-16 15:58:27.254: [iter 23 : loss : 0.2841 = 0.1821 + 0.1002 + 0.0017, time: 8.127277]
2023-05-16 15:58:27.414: epoch 23:	0.02055501  	0.15155801  	0.07685193  
2023-05-16 15:58:27.414: Find a better model.
2023-05-16 15:58:35.645: [iter 24 : loss : 0.2777 = 0.1762 + 0.0997 + 0.0018, time: 8.229154]
2023-05-16 15:58:35.802: epoch 24:	0.02074553  	0.15297411  	0.07781315  
2023-05-16 15:58:35.802: Find a better model.
2023-05-16 15:58:44.179: [iter 25 : loss : 0.2710 = 0.1699 + 0.0993 + 0.0019, time: 8.374546]
2023-05-16 15:58:44.339: epoch 25:	0.02087961  	0.15388325  	0.07847970  
2023-05-16 15:58:44.339: Find a better model.
2023-05-16 15:58:53.109: [iter 26 : loss : 0.2675 = 0.1667 + 0.0989 + 0.0019, time: 8.768214]
2023-05-16 15:58:53.409: epoch 26:	0.02101368  	0.15442902  	0.07907406  
2023-05-16 15:58:53.409: Find a better model.
2023-05-16 15:59:02.375: [iter 27 : loss : 0.2599 = 0.1594 + 0.0985 + 0.0020, time: 8.961101]
2023-05-16 15:59:02.661: epoch 27:	0.02123244  	0.15581782  	0.07984951  
2023-05-16 15:59:02.661: Find a better model.
2023-05-16 15:59:11.067: [iter 28 : loss : 0.2549 = 0.1547 + 0.0981 + 0.0021, time: 8.403999]
2023-05-16 15:59:11.240: epoch 28:	0.02148647  	0.15781993  	0.08080871  
2023-05-16 15:59:11.240: Find a better model.
2023-05-16 15:59:18.863: [iter 29 : loss : 0.2505 = 0.1507 + 0.0977 + 0.0021, time: 7.622098]
2023-05-16 15:59:19.025: epoch 29:	0.02163467  	0.15906470  	0.08158755  
2023-05-16 15:59:19.025: Find a better model.
2023-05-16 15:59:27.447: [iter 30 : loss : 0.2441 = 0.1446 + 0.0973 + 0.0022, time: 8.420995]
2023-05-16 15:59:27.677: epoch 30:	0.02180403  	0.16038185  	0.08219512  
2023-05-16 15:59:27.678: Find a better model.
2023-05-16 15:59:36.750: [iter 31 : loss : 0.2404 = 0.1413 + 0.0969 + 0.0023, time: 9.068006]
2023-05-16 15:59:37.047: epoch 31:	0.02199455  	0.16183369  	0.08299716  
2023-05-16 15:59:37.048: Find a better model.
2023-05-16 15:59:46.077: [iter 32 : loss : 0.2348 = 0.1359 + 0.0965 + 0.0023, time: 9.025608]
2023-05-16 15:59:46.370: epoch 32:	0.02217096  	0.16332288  	0.08381287  
2023-05-16 15:59:46.371: Find a better model.
2023-05-16 15:59:54.852: [iter 33 : loss : 0.2322 = 0.1336 + 0.0962 + 0.0024, time: 8.480159]
2023-05-16 15:59:55.007: epoch 33:	0.02230503  	0.16448435  	0.08452139  
2023-05-16 15:59:55.007: Find a better model.
2023-05-16 16:00:02.592: [iter 34 : loss : 0.2282 = 0.1300 + 0.0958 + 0.0024, time: 7.584001]
2023-05-16 16:00:02.752: epoch 34:	0.02248849  	0.16576478  	0.08539618  
2023-05-16 16:00:02.752: Find a better model.
2023-05-16 16:00:11.055: [iter 35 : loss : 0.2247 = 0.1267 + 0.0955 + 0.0025, time: 8.301483]
2023-05-16 16:00:11.232: epoch 35:	0.02259434  	0.16641875  	0.08604497  
2023-05-16 16:00:11.232: Find a better model.
2023-05-16 16:00:20.226: [iter 36 : loss : 0.2213 = 0.1236 + 0.0952 + 0.0025, time: 8.986026]
2023-05-16 16:00:20.523: epoch 36:	0.02270724  	0.16753443  	0.08667390  
2023-05-16 16:00:20.523: Find a better model.
2023-05-16 16:00:29.519: [iter 37 : loss : 0.2177 = 0.1202 + 0.0949 + 0.0026, time: 8.993008]
2023-05-16 16:00:29.735: epoch 37:	0.02280604  	0.16851385  	0.08734812  
2023-05-16 16:00:29.735: Find a better model.
2023-05-16 16:00:38.029: [iter 38 : loss : 0.2159 = 0.1186 + 0.0946 + 0.0027, time: 8.292307]
2023-05-16 16:00:38.191: epoch 38:	0.02289071  	0.16901654  	0.08777723  
2023-05-16 16:00:38.191: Find a better model.
2023-05-16 16:00:46.035: [iter 39 : loss : 0.2114 = 0.1144 + 0.0943 + 0.0027, time: 7.842010]
2023-05-16 16:00:46.195: epoch 39:	0.02306712  	0.17025673  	0.08861204  
2023-05-16 16:00:46.195: Find a better model.
2023-05-16 16:00:54.164: [iter 40 : loss : 0.2082 = 0.1115 + 0.0939 + 0.0028, time: 7.968015]
2023-05-16 16:00:54.319: epoch 40:	0.02318708  	0.17095944  	0.08908722  
2023-05-16 16:00:54.319: Find a better model.
2023-05-16 16:01:03.273: [iter 41 : loss : 0.2066 = 0.1101 + 0.0937 + 0.0028, time: 8.950438]
2023-05-16 16:01:03.573: epoch 41:	0.02331410  	0.17206109  	0.08950501  
2023-05-16 16:01:03.573: Find a better model.
2023-05-16 16:01:11.219: [iter 42 : loss : 0.2043 = 0.1080 + 0.0934 + 0.0029, time: 7.644799]
2023-05-16 16:01:11.452: epoch 42:	0.02334938  	0.17214283  	0.08987020  
2023-05-16 16:01:11.454: Find a better model.
2023-05-16 16:01:19.606: [iter 43 : loss : 0.2006 = 0.1045 + 0.0931 + 0.0029, time: 8.137089]
2023-05-16 16:01:19.768: epoch 43:	0.02343406  	0.17283978  	0.09050809  
2023-05-16 16:01:19.768: Find a better model.
2023-05-16 16:01:27.939: [iter 44 : loss : 0.1968 = 0.1010 + 0.0928 + 0.0030, time: 8.168009]
2023-05-16 16:01:28.380: epoch 44:	0.02347640  	0.17345996  	0.09108910  
2023-05-16 16:01:28.380: Find a better model.
2023-05-16 16:01:36.176: [iter 45 : loss : 0.1948 = 0.0992 + 0.0926 + 0.0030, time: 7.795004]
2023-05-16 16:01:36.331: epoch 45:	0.02365281  	0.17415072  	0.09172948  
2023-05-16 16:01:36.331: Find a better model.
2023-05-16 16:01:45.382: [iter 46 : loss : 0.1925 = 0.0971 + 0.0924 + 0.0031, time: 9.047008]
2023-05-16 16:01:45.685: epoch 46:	0.02370221  	0.17488371  	0.09219529  
2023-05-16 16:01:45.685: Find a better model.
2023-05-16 16:01:53.574: [iter 47 : loss : 0.1917 = 0.0964 + 0.0921 + 0.0031, time: 7.888031]
2023-05-16 16:01:53.752: epoch 47:	0.02387862  	0.17592107  	0.09279999  
2023-05-16 16:01:53.752: Find a better model.
2023-05-16 16:02:01.958: [iter 48 : loss : 0.1876 = 0.0926 + 0.0918 + 0.0032, time: 8.204999]
2023-05-16 16:02:02.114: epoch 48:	0.02388568  	0.17590532  	0.09308286  
2023-05-16 16:02:10.353: [iter 49 : loss : 0.1847 = 0.0899 + 0.0917 + 0.0032, time: 8.236533]
2023-05-16 16:02:10.529: epoch 49:	0.02391391  	0.17611282  	0.09323761  
2023-05-16 16:02:10.529: Find a better model.
2023-05-16 16:02:18.152: [iter 50 : loss : 0.1840 = 0.0893 + 0.0915 + 0.0033, time: 7.621068]
2023-05-16 16:02:18.310: epoch 50:	0.02394213  	0.17636909  	0.09349667  
2023-05-16 16:02:18.310: Find a better model.
2023-05-16 16:02:27.412: [iter 51 : loss : 0.1807 = 0.0861 + 0.0912 + 0.0033, time: 9.098024]
2023-05-16 16:02:27.705: epoch 51:	0.02408326  	0.17711726  	0.09397639  
2023-05-16 16:02:27.706: Find a better model.
2023-05-16 16:02:35.657: [iter 52 : loss : 0.1808 = 0.0864 + 0.0910 + 0.0034, time: 7.950618]
2023-05-16 16:02:35.814: epoch 52:	0.02414677  	0.17735121  	0.09452495  
2023-05-16 16:02:35.814: Find a better model.
2023-05-16 16:02:43.952: [iter 53 : loss : 0.1788 = 0.0845 + 0.0908 + 0.0034, time: 8.136053]
2023-05-16 16:02:44.107: epoch 53:	0.02415382  	0.17744827  	0.09470985  
2023-05-16 16:02:44.108: Find a better model.
2023-05-16 16:02:52.570: [iter 54 : loss : 0.1766 = 0.0825 + 0.0906 + 0.0035, time: 8.460987]
2023-05-16 16:02:52.729: epoch 54:	0.02428084  	0.17850955  	0.09532463  
2023-05-16 16:02:52.729: Find a better model.
2023-05-16 16:03:01.076: [iter 55 : loss : 0.1746 = 0.0807 + 0.0904 + 0.0035, time: 8.342027]
2023-05-16 16:03:01.361: epoch 55:	0.02435140  	0.17877223  	0.09569923  
2023-05-16 16:03:01.361: Find a better model.
2023-05-16 16:03:10.426: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 9.063009]
2023-05-16 16:03:10.714: epoch 56:	0.02445724  	0.17962128  	0.09604465  
2023-05-16 16:03:10.714: Find a better model.
2023-05-16 16:03:19.150: [iter 57 : loss : 0.1712 = 0.0776 + 0.0901 + 0.0036, time: 8.435031]
2023-05-16 16:03:19.316: epoch 57:	0.02449958  	0.17981346  	0.09637342  
2023-05-16 16:03:19.317: Find a better model.
2023-05-16 16:03:26.981: [iter 58 : loss : 0.1691 = 0.0757 + 0.0899 + 0.0036, time: 7.663000]
2023-05-16 16:03:27.145: epoch 58:	0.02453486  	0.17997327  	0.09667964  
2023-05-16 16:03:27.145: Find a better model.
2023-05-16 16:03:35.524: [iter 59 : loss : 0.1683 = 0.0748 + 0.0897 + 0.0037, time: 8.376501]
2023-05-16 16:03:35.705: epoch 59:	0.02454898  	0.18031940  	0.09697969  
2023-05-16 16:03:35.705: Find a better model.
2023-05-16 16:03:44.947: [iter 60 : loss : 0.1666 = 0.0734 + 0.0895 + 0.0037, time: 9.239410]
2023-05-16 16:03:45.232: epoch 60:	0.02461954  	0.18105038  	0.09738383  
2023-05-16 16:03:45.232: Find a better model.
2023-05-16 16:03:54.348: [iter 61 : loss : 0.1653 = 0.0722 + 0.0894 + 0.0038, time: 9.113361]
2023-05-16 16:03:54.642: epoch 61:	0.02476067  	0.18237871  	0.09794046  
2023-05-16 16:03:54.642: Find a better model.
2023-05-16 16:04:03.094: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 8.451057]
2023-05-16 16:04:03.357: epoch 62:	0.02481007  	0.18276960  	0.09825426  
2023-05-16 16:04:03.357: Find a better model.
2023-05-16 16:04:10.921: [iter 63 : loss : 0.1625 = 0.0696 + 0.0890 + 0.0039, time: 7.563227]
2023-05-16 16:04:11.077: epoch 63:	0.02491592  	0.18368590  	0.09862787  
2023-05-16 16:04:11.077: Find a better model.
2023-05-16 16:04:19.565: [iter 64 : loss : 0.1613 = 0.0685 + 0.0889 + 0.0039, time: 8.486251]
2023-05-16 16:04:19.739: epoch 64:	0.02495826  	0.18402036  	0.09885023  
2023-05-16 16:04:19.739: Find a better model.
2023-05-16 16:04:28.759: [iter 65 : loss : 0.1601 = 0.0675 + 0.0887 + 0.0039, time: 9.019022]
2023-05-16 16:04:29.061: epoch 65:	0.02505704  	0.18455552  	0.09943378  
2023-05-16 16:04:29.062: Find a better model.
2023-05-16 16:04:38.030: [iter 66 : loss : 0.1585 = 0.0660 + 0.0885 + 0.0040, time: 8.966588]
2023-05-16 16:04:38.207: epoch 66:	0.02514172  	0.18529379  	0.09992677  
2023-05-16 16:04:38.207: Find a better model.
2023-05-16 16:04:46.514: [iter 67 : loss : 0.1568 = 0.0643 + 0.0884 + 0.0040, time: 8.306045]
2023-05-16 16:04:46.677: epoch 67:	0.02515583  	0.18505345  	0.09986027  
2023-05-16 16:04:54.631: [iter 68 : loss : 0.1564 = 0.0640 + 0.0883 + 0.0041, time: 7.953014]
2023-05-16 16:04:55.123: epoch 68:	0.02528990  	0.18639058  	0.10032421  
2023-05-16 16:04:55.123: Find a better model.
2023-05-16 16:05:03.071: [iter 69 : loss : 0.1547 = 0.0624 + 0.0882 + 0.0041, time: 7.946043]
2023-05-16 16:05:03.226: epoch 69:	0.02528284  	0.18640427  	0.10048999  
2023-05-16 16:05:03.226: Find a better model.
2023-05-16 16:05:12.281: [iter 70 : loss : 0.1531 = 0.0609 + 0.0880 + 0.0042, time: 9.050035]
2023-05-16 16:05:12.577: epoch 70:	0.02536046  	0.18668400  	0.10069201  
2023-05-16 16:05:12.577: Find a better model.
2023-05-16 16:05:20.275: [iter 71 : loss : 0.1515 = 0.0594 + 0.0879 + 0.0042, time: 7.696002]
2023-05-16 16:05:20.444: epoch 71:	0.02538868  	0.18664064  	0.10102996  
2023-05-16 16:05:28.720: [iter 72 : loss : 0.1513 = 0.0593 + 0.0878 + 0.0042, time: 8.274012]
2023-05-16 16:05:28.875: epoch 72:	0.02544513  	0.18709673  	0.10119995  
2023-05-16 16:05:28.875: Find a better model.
2023-05-16 16:05:37.280: [iter 73 : loss : 0.1500 = 0.0581 + 0.0876 + 0.0043, time: 8.404002]
2023-05-16 16:05:37.437: epoch 73:	0.02549453  	0.18734136  	0.10128421  
2023-05-16 16:05:37.437: Find a better model.
2023-05-16 16:05:45.288: [iter 74 : loss : 0.1485 = 0.0567 + 0.0876 + 0.0043, time: 7.850009]
2023-05-16 16:05:45.446: epoch 74:	0.02552276  	0.18776940  	0.10152850  
2023-05-16 16:05:45.446: Find a better model.
2023-05-16 16:05:54.603: [iter 75 : loss : 0.1480 = 0.0563 + 0.0874 + 0.0044, time: 9.155022]
2023-05-16 16:05:54.891: epoch 75:	0.02548748  	0.18746515  	0.10157880  
2023-05-16 16:06:03.035: [iter 76 : loss : 0.1470 = 0.0553 + 0.0873 + 0.0044, time: 8.140069]
2023-05-16 16:06:03.193: epoch 76:	0.02556510  	0.18824014  	0.10186619  
2023-05-16 16:06:03.193: Find a better model.
2023-05-16 16:06:11.047: [iter 77 : loss : 0.1462 = 0.0546 + 0.0872 + 0.0044, time: 7.852021]
2023-05-16 16:06:11.212: epoch 77:	0.02562155  	0.18850453  	0.10214272  
2023-05-16 16:06:11.212: Find a better model.
2023-05-16 16:06:19.290: [iter 78 : loss : 0.1452 = 0.0536 + 0.0871 + 0.0045, time: 8.073007]
2023-05-16 16:06:19.551: epoch 78:	0.02565683  	0.18880549  	0.10235644  
2023-05-16 16:06:19.552: Find a better model.
2023-05-16 16:06:28.800: [iter 79 : loss : 0.1438 = 0.0523 + 0.0869 + 0.0045, time: 9.244019]
2023-05-16 16:06:29.101: epoch 79:	0.02573446  	0.18936993  	0.10246146  
2023-05-16 16:06:29.101: Find a better model.
2023-05-16 16:06:38.253: [iter 80 : loss : 0.1431 = 0.0517 + 0.0869 + 0.0046, time: 9.149037]
2023-05-16 16:06:38.549: epoch 80:	0.02576268  	0.18935223  	0.10255114  
2023-05-16 16:06:47.031: [iter 81 : loss : 0.1428 = 0.0515 + 0.0867 + 0.0046, time: 8.480013]
2023-05-16 16:06:47.186: epoch 81:	0.02584030  	0.18994263  	0.10290496  
2023-05-16 16:06:47.186: Find a better model.
2023-05-16 16:06:54.853: [iter 82 : loss : 0.1415 = 0.0502 + 0.0867 + 0.0046, time: 7.665027]
2023-05-16 16:06:55.013: epoch 82:	0.02588264  	0.19049616  	0.10322683  
2023-05-16 16:06:55.013: Find a better model.
2023-05-16 16:07:03.320: [iter 83 : loss : 0.1404 = 0.0492 + 0.0866 + 0.0047, time: 8.304996]
2023-05-16 16:07:03.497: epoch 83:	0.02584736  	0.19045417  	0.10333275  
2023-05-16 16:07:12.504: [iter 84 : loss : 0.1403 = 0.0491 + 0.0864 + 0.0047, time: 8.999033]
2023-05-16 16:07:12.785: epoch 84:	0.02588970  	0.19062276  	0.10360160  
2023-05-16 16:07:12.785: Find a better model.
2023-05-16 16:07:21.961: [iter 85 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 9.174421]
2023-05-16 16:07:22.221: epoch 85:	0.02588264  	0.19054554  	0.10369118  
2023-05-16 16:07:30.680: [iter 86 : loss : 0.1396 = 0.0485 + 0.0863 + 0.0048, time: 8.458010]
2023-05-16 16:07:30.848: epoch 86:	0.02591087  	0.19052373  	0.10382479  
2023-05-16 16:07:38.910: [iter 87 : loss : 0.1365 = 0.0455 + 0.0862 + 0.0048, time: 8.060997]
2023-05-16 16:07:39.230: epoch 87:	0.02596027  	0.19069414  	0.10407677  
2023-05-16 16:07:39.231: Find a better model.
2023-05-16 16:07:47.249: [iter 88 : loss : 0.1360 = 0.0451 + 0.0861 + 0.0049, time: 8.006998]
2023-05-16 16:07:47.404: epoch 88:	0.02591087  	0.19042863  	0.10401743  
2023-05-16 16:07:56.382: [iter 89 : loss : 0.1356 = 0.0447 + 0.0859 + 0.0049, time: 8.976023]
2023-05-16 16:07:56.669: epoch 89:	0.02593205  	0.19089174  	0.10429296  
2023-05-16 16:07:56.669: Find a better model.
2023-05-16 16:08:04.420: [iter 90 : loss : 0.1361 = 0.0453 + 0.0859 + 0.0049, time: 7.749171]
2023-05-16 16:08:04.659: epoch 90:	0.02584736  	0.19013797  	0.10412958  
2023-05-16 16:08:13.066: [iter 91 : loss : 0.1346 = 0.0439 + 0.0858 + 0.0050, time: 8.406008]
2023-05-16 16:08:13.222: epoch 91:	0.02590381  	0.19055471  	0.10437199  
2023-05-16 16:08:21.328: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 8.105128]
2023-05-16 16:08:21.514: epoch 92:	0.02594615  	0.19096519  	0.10460616  
2023-05-16 16:08:21.514: Find a better model.
2023-05-16 16:08:29.187: [iter 93 : loss : 0.1342 = 0.0436 + 0.0856 + 0.0051, time: 7.672018]
2023-05-16 16:08:29.354: epoch 93:	0.02598143  	0.19096187  	0.10480646  
2023-05-16 16:08:38.465: [iter 94 : loss : 0.1319 = 0.0413 + 0.0855 + 0.0051, time: 9.104006]
2023-05-16 16:08:38.755: epoch 94:	0.02606611  	0.19175395  	0.10492606  
2023-05-16 16:08:38.755: Find a better model.
2023-05-16 16:08:46.739: [iter 95 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 7.982992]
2023-05-16 16:08:46.899: epoch 95:	0.02605905  	0.19191474  	0.10507118  
2023-05-16 16:08:46.899: Find a better model.
2023-05-16 16:08:54.993: [iter 96 : loss : 0.1317 = 0.0411 + 0.0854 + 0.0052, time: 8.091624]
2023-05-16 16:08:55.148: epoch 96:	0.02612962  	0.19224915  	0.10522164  
2023-05-16 16:08:55.148: Find a better model.
2023-05-16 16:09:03.595: [iter 97 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0052, time: 8.445996]
2023-05-16 16:09:03.754: epoch 97:	0.02610844  	0.19218008  	0.10536427  
2023-05-16 16:09:12.331: [iter 98 : loss : 0.1309 = 0.0404 + 0.0852 + 0.0052, time: 8.574213]
2023-05-16 16:09:12.627: epoch 98:	0.02624252  	0.19298309  	0.10580108  
2023-05-16 16:09:12.627: Find a better model.
2023-05-16 16:09:21.832: [iter 99 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0053, time: 9.204024]
2023-05-16 16:09:22.126: epoch 99:	0.02625663  	0.19312513  	0.10587205  
2023-05-16 16:09:22.126: Find a better model.
2023-05-16 16:09:31.608: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 9.479245]
2023-05-16 16:09:31.753: epoch 100:	0.02637659  	0.19423744  	0.10628583  
2023-05-16 16:09:31.753: Find a better model.
2023-05-16 16:09:39.610: [iter 101 : loss : 0.1285 = 0.0381 + 0.0850 + 0.0053, time: 7.855006]
2023-05-16 16:09:39.772: epoch 101:	0.02637659  	0.19431332  	0.10639562  
2023-05-16 16:09:39.772: Find a better model.
2023-05-16 16:09:48.700: [iter 102 : loss : 0.1277 = 0.0374 + 0.0849 + 0.0054, time: 8.927021]
2023-05-16 16:09:48.867: epoch 102:	0.02637659  	0.19429404  	0.10646864  
2023-05-16 16:09:58.365: [iter 103 : loss : 0.1270 = 0.0367 + 0.0849 + 0.0054, time: 9.495059]
2023-05-16 16:09:58.664: epoch 103:	0.02636248  	0.19426650  	0.10651175  
2023-05-16 16:10:08.368: [iter 104 : loss : 0.1277 = 0.0375 + 0.0848 + 0.0055, time: 9.700420]
2023-05-16 16:10:08.686: epoch 104:	0.02632014  	0.19376346  	0.10667314  
2023-05-16 16:10:19.114: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 10.426037]
2023-05-16 16:10:19.285: epoch 105:	0.02640481  	0.19461507  	0.10717306  
2023-05-16 16:10:19.285: Find a better model.
2023-05-16 16:10:28.109: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 8.821672]
2023-05-16 16:10:28.314: epoch 106:	0.02648244  	0.19487092  	0.10730109  
2023-05-16 16:10:28.314: Find a better model.
2023-05-16 16:10:37.465: [iter 107 : loss : 0.1253 = 0.0352 + 0.0846 + 0.0055, time: 9.148035]
2023-05-16 16:10:37.753: epoch 107:	0.02646833  	0.19458795  	0.10718760  
2023-05-16 16:10:48.096: [iter 108 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 10.338316]
2023-05-16 16:10:48.441: epoch 108:	0.02648244  	0.19450237  	0.10724609  
2023-05-16 16:10:58.725: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 10.281084]
2023-05-16 16:10:59.065: epoch 109:	0.02646127  	0.19441019  	0.10716458  
2023-05-16 16:11:08.832: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 9.763257]
2023-05-16 16:11:09.232: epoch 110:	0.02648949  	0.19436030  	0.10722194  
2023-05-16 16:11:19.130: [iter 111 : loss : 0.1232 = 0.0332 + 0.0844 + 0.0057, time: 9.897672]
2023-05-16 16:11:19.293: epoch 111:	0.02652477  	0.19471270  	0.10720918  
2023-05-16 16:11:29.125: [iter 112 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0057, time: 9.831001]
2023-05-16 16:11:29.281: epoch 112:	0.02649655  	0.19452913  	0.10731395  
2023-05-16 16:11:37.361: [iter 113 : loss : 0.1231 = 0.0331 + 0.0842 + 0.0058, time: 8.078004]
2023-05-16 16:11:37.571: epoch 113:	0.02648243  	0.19449148  	0.10730187  
2023-05-16 16:11:47.737: [iter 114 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.163183]
2023-05-16 16:11:48.083: epoch 114:	0.02657417  	0.19527742  	0.10752566  
2023-05-16 16:11:48.083: Find a better model.
2023-05-16 16:11:58.391: [iter 115 : loss : 0.1217 = 0.0317 + 0.0841 + 0.0058, time: 10.302369]
2023-05-16 16:11:58.738: epoch 115:	0.02656006  	0.19488765  	0.10765323  
2023-05-16 16:12:06.580: [iter 116 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0058, time: 7.840223]
2023-05-16 16:12:06.831: epoch 116:	0.02651066  	0.19472440  	0.10736890  
2023-05-16 16:12:16.432: [iter 117 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 9.600423]
2023-05-16 16:12:16.606: epoch 117:	0.02656711  	0.19511369  	0.10769146  
2023-05-16 16:12:26.395: [iter 118 : loss : 0.1207 = 0.0308 + 0.0840 + 0.0059, time: 9.788004]
2023-05-16 16:12:26.565: epoch 118:	0.02653183  	0.19458368  	0.10774779  
2023-05-16 16:12:34.780: [iter 119 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 8.214289]
2023-05-16 16:12:34.943: epoch 119:	0.02656006  	0.19504632  	0.10787235  
2023-05-16 16:12:45.154: [iter 120 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 10.209127]
2023-05-16 16:12:45.521: epoch 120:	0.02660240  	0.19536871  	0.10807277  
2023-05-16 16:12:45.521: Find a better model.
2023-05-16 16:12:55.783: [iter 121 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 10.255645]
2023-05-16 16:12:56.127: epoch 121:	0.02665180  	0.19581912  	0.10828225  
2023-05-16 16:12:56.127: Find a better model.
2023-05-16 16:13:04.110: [iter 122 : loss : 0.1193 = 0.0295 + 0.0837 + 0.0060, time: 7.981992]
2023-05-16 16:13:04.321: epoch 122:	0.02658829  	0.19563465  	0.10813491  
2023-05-16 16:13:13.816: [iter 123 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 9.493015]
2023-05-16 16:13:13.964: epoch 123:	0.02655301  	0.19534548  	0.10816869  
2023-05-16 16:13:24.023: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 10.058060]
2023-05-16 16:13:24.206: epoch 124:	0.02653890  	0.19514288  	0.10803544  
2023-05-16 16:13:32.305: [iter 125 : loss : 0.1174 = 0.0277 + 0.0836 + 0.0061, time: 8.097993]
2023-05-16 16:13:32.499: epoch 125:	0.02665180  	0.19606355  	0.10834457  
2023-05-16 16:13:32.499: Find a better model.
2023-05-16 16:13:42.781: [iter 126 : loss : 0.1177 = 0.0279 + 0.0836 + 0.0062, time: 10.276708]
2023-05-16 16:13:43.131: epoch 126:	0.02669414  	0.19628736  	0.10851084  
2023-05-16 16:13:43.131: Find a better model.
2023-05-16 16:13:53.371: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 10.236019]
2023-05-16 16:13:53.728: epoch 127:	0.02668003  	0.19630416  	0.10856982  
2023-05-16 16:13:53.728: Find a better model.
2023-05-16 16:14:01.625: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 7.896123]
2023-05-16 16:14:01.828: epoch 128:	0.02673648  	0.19681379  	0.10882133  
2023-05-16 16:14:01.829: Find a better model.
2023-05-16 16:14:11.415: [iter 129 : loss : 0.1168 = 0.0271 + 0.0835 + 0.0063, time: 9.584007]
2023-05-16 16:14:11.584: epoch 129:	0.02672236  	0.19665384  	0.10873615  
2023-05-16 16:14:21.549: [iter 130 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 9.963012]
2023-05-16 16:14:21.707: epoch 130:	0.02669414  	0.19656026  	0.10880873  
2023-05-16 16:14:29.902: [iter 131 : loss : 0.1161 = 0.0265 + 0.0834 + 0.0063, time: 8.193012]
2023-05-16 16:14:30.062: epoch 131:	0.02665179  	0.19595796  	0.10865754  
2023-05-16 16:14:40.247: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 10.181834]
2023-05-16 16:14:40.587: epoch 132:	0.02660239  	0.19535264  	0.10861895  
2023-05-16 16:14:50.899: [iter 133 : loss : 0.1151 = 0.0255 + 0.0833 + 0.0064, time: 10.306711]
2023-05-16 16:14:51.234: epoch 133:	0.02663063  	0.19542211  	0.10874780  
2023-05-16 16:14:59.389: [iter 134 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 8.152266]
2023-05-16 16:15:00.003: epoch 134:	0.02667296  	0.19563873  	0.10890163  
2023-05-16 16:15:09.768: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 9.752074]
2023-05-16 16:15:09.949: epoch 135:	0.02665885  	0.19568039  	0.10888425  
2023-05-16 16:15:19.917: [iter 136 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0065, time: 9.966996]
2023-05-16 16:15:20.086: epoch 136:	0.02662357  	0.19537100  	0.10873343  
2023-05-16 16:15:28.509: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 8.420265]
2023-05-16 16:15:28.672: epoch 137:	0.02658829  	0.19523193  	0.10874686  
2023-05-16 16:15:38.826: [iter 138 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 10.151368]
2023-05-16 16:15:39.186: epoch 138:	0.02654595  	0.19456516  	0.10862800  
2023-05-16 16:15:49.537: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0065, time: 10.348080]
2023-05-16 16:15:49.905: epoch 139:	0.02656712  	0.19485238  	0.10868531  
2023-05-16 16:15:58.042: [iter 140 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 8.136156]
2023-05-16 16:15:58.244: epoch 140:	0.02647538  	0.19427788  	0.10856020  
2023-05-16 16:16:08.039: [iter 141 : loss : 0.1141 = 0.0245 + 0.0829 + 0.0066, time: 9.792192]
2023-05-16 16:16:08.208: epoch 141:	0.02648949  	0.19450955  	0.10857392  
2023-05-16 16:16:18.541: [iter 142 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 10.331105]
2023-05-16 16:16:18.696: epoch 142:	0.02650361  	0.19446790  	0.10849749  
2023-05-16 16:16:26.876: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 8.178257]
2023-05-16 16:16:27.041: epoch 143:	0.02654595  	0.19472216  	0.10862863  
2023-05-16 16:16:37.286: [iter 144 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0067, time: 10.243355]
2023-05-16 16:16:37.639: epoch 144:	0.02659534  	0.19498827  	0.10872222  
2023-05-16 16:16:47.889: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 10.248023]
2023-05-16 16:16:48.241: epoch 145:	0.02654595  	0.19472829  	0.10872581  
2023-05-16 16:16:56.015: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.771494]
2023-05-16 16:16:56.470: epoch 146:	0.02662357  	0.19521961  	0.10884321  
2023-05-16 16:17:06.163: [iter 147 : loss : 0.1128 = 0.0233 + 0.0827 + 0.0068, time: 9.691124]
2023-05-16 16:17:06.331: epoch 147:	0.02659534  	0.19509691  	0.10895006  
2023-05-16 16:17:16.252: [iter 148 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0068, time: 9.919020]
2023-05-16 16:17:16.421: epoch 148:	0.02653889  	0.19464354  	0.10881806  
2023-05-16 16:17:24.444: [iter 149 : loss : 0.1120 = 0.0225 + 0.0827 + 0.0068, time: 8.022005]
2023-05-16 16:17:24.618: epoch 149:	0.02653889  	0.19470733  	0.10876360  
2023-05-16 16:17:34.755: [iter 150 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0068, time: 10.130060]
2023-05-16 16:17:35.110: epoch 150:	0.02660240  	0.19525355  	0.10875946  
2023-05-16 16:17:45.363: [iter 151 : loss : 0.1114 = 0.0220 + 0.0826 + 0.0069, time: 10.252483]
2023-05-16 16:17:45.729: epoch 151:	0.02662357  	0.19518644  	0.10870207  
2023-05-16 16:17:53.406: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.675004]
2023-05-16 16:17:53.828: epoch 152:	0.02657418  	0.19502422  	0.10864009  
2023-05-16 16:18:03.277: [iter 153 : loss : 0.1097 = 0.0203 + 0.0825 + 0.0069, time: 9.446721]
2023-05-16 16:18:03.434: epoch 153:	0.02652478  	0.19469471  	0.10863031  
2023-05-16 16:18:03.435: Early stopping is trigger at epoch: 153
2023-05-16 16:18:03.435: best_result@epoch 128:

2023-05-16 16:18:03.435: 		0.0267      	0.1968      	0.1088      
2023-05-16 16:22:46.149: my pid: 10932
2023-05-16 16:22:46.149: model: model.general_recommender.SGL
2023-05-16 16:22:46.149: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 16:22:46.149: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 16:22:49.483: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 16:23:00.971: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 11.484049]
2023-05-16 16:23:01.328: epoch 1:	0.00154530  	0.01151896  	0.00531719  
2023-05-16 16:23:01.328: Find a better model.
2023-05-16 16:23:12.663: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 11.322361]
2023-05-16 16:23:13.061: epoch 2:	0.00288597  	0.02124803  	0.01045880  
2023-05-16 16:23:13.061: Find a better model.
2023-05-16 16:23:23.339: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.275068]
2023-05-16 16:23:23.689: epoch 3:	0.00473466  	0.03487536  	0.01673315  
2023-05-16 16:23:23.689: Find a better model.
2023-05-16 16:23:32.627: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.936053]
2023-05-16 16:23:32.867: epoch 4:	0.00767705  	0.05549804  	0.02693598  
2023-05-16 16:23:32.867: Find a better model.
2023-05-16 16:23:43.397: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 10.528038]
2023-05-16 16:23:43.744: epoch 5:	0.01178384  	0.08441582  	0.04073336  
2023-05-16 16:23:43.745: Find a better model.
2023-05-16 16:23:54.465: [iter 6 : loss : 0.7674 = 0.6882 + 0.0792 + 0.0000, time: 10.718240]
2023-05-16 16:23:54.809: epoch 6:	0.01506508  	0.10845289  	0.05251918  
2023-05-16 16:23:54.809: Find a better model.
2023-05-16 16:24:05.483: [iter 7 : loss : 0.7613 = 0.6814 + 0.0799 + 0.0000, time: 10.673273]
2023-05-16 16:24:05.847: epoch 7:	0.01796525  	0.13063246  	0.06423113  
2023-05-16 16:24:05.847: Find a better model.
2023-05-16 16:24:15.553: [iter 8 : loss : 0.7462 = 0.6644 + 0.0817 + 0.0001, time: 9.705026]
2023-05-16 16:24:15.745: epoch 8:	0.01891083  	0.13760923  	0.06888023  
2023-05-16 16:24:15.745: Find a better model.
2023-05-16 16:24:25.963: [iter 9 : loss : 0.7119 = 0.6263 + 0.0855 + 0.0001, time: 10.217041]
2023-05-16 16:24:26.128: epoch 9:	0.01876971  	0.13822007  	0.06931883  
2023-05-16 16:24:26.128: Find a better model.
2023-05-16 16:24:36.301: [iter 10 : loss : 0.6523 = 0.5612 + 0.0909 + 0.0002, time: 10.170630]
2023-05-16 16:24:36.461: epoch 10:	0.01869914  	0.13840817  	0.06912586  
2023-05-16 16:24:36.461: Find a better model.
2023-05-16 16:24:45.437: [iter 11 : loss : 0.5770 = 0.4806 + 0.0959 + 0.0004, time: 8.974035]
2023-05-16 16:24:45.764: epoch 11:	0.01840277  	0.13567342  	0.06809355  
2023-05-16 16:24:56.285: [iter 12 : loss : 0.5075 = 0.4076 + 0.0993 + 0.0005, time: 10.519035]
2023-05-16 16:24:56.639: epoch 12:	0.01831809  	0.13506645  	0.06828063  
2023-05-16 16:25:07.206: [iter 13 : loss : 0.4558 = 0.3539 + 0.1012 + 0.0007, time: 10.564253]
2023-05-16 16:25:07.575: epoch 13:	0.01848744  	0.13667931  	0.06899439  
2023-05-16 16:25:17.097: [iter 14 : loss : 0.4169 = 0.3138 + 0.1022 + 0.0008, time: 9.519632]
2023-05-16 16:25:17.260: epoch 14:	0.01862857  	0.13779306  	0.06961588  
2023-05-16 16:25:25.515: [iter 15 : loss : 0.3898 = 0.2862 + 0.1026 + 0.0010, time: 8.253046]
2023-05-16 16:25:25.681: epoch 15:	0.01881204  	0.13890752  	0.07034051  
2023-05-16 16:25:25.682: Find a better model.
2023-05-16 16:25:36.044: [iter 16 : loss : 0.3670 = 0.2633 + 0.1026 + 0.0011, time: 10.361028]
2023-05-16 16:25:36.222: epoch 16:	0.01906608  	0.14031228  	0.07115061  
2023-05-16 16:25:36.222: Find a better model.
2023-05-16 16:25:46.815: [iter 17 : loss : 0.3504 = 0.2467 + 0.1025 + 0.0012, time: 10.587323]
2023-05-16 16:25:47.169: epoch 17:	0.01932717  	0.14225885  	0.07226148  
2023-05-16 16:25:47.169: Find a better model.
2023-05-16 16:25:57.775: [iter 18 : loss : 0.3350 = 0.2315 + 0.1022 + 0.0013, time: 10.603482]
2023-05-16 16:25:58.144: epoch 18:	0.01946124  	0.14317758  	0.07271708  
2023-05-16 16:25:58.144: Find a better model.
2023-05-16 16:26:08.431: [iter 19 : loss : 0.3208 = 0.2175 + 0.1019 + 0.0014, time: 10.282963]
2023-05-16 16:26:08.762: epoch 19:	0.01970117  	0.14492442  	0.07371007  
2023-05-16 16:26:08.762: Find a better model.
2023-05-16 16:26:18.909: [iter 20 : loss : 0.3112 = 0.2082 + 0.1015 + 0.0015, time: 10.146001]
2023-05-16 16:26:19.067: epoch 20:	0.01995521  	0.14686313  	0.07469551  
2023-05-16 16:26:19.067: Find a better model.
2023-05-16 16:26:29.630: [iter 21 : loss : 0.3015 = 0.1988 + 0.1011 + 0.0016, time: 10.562021]
2023-05-16 16:26:29.788: epoch 21:	0.02014574  	0.14851774  	0.07542529  
2023-05-16 16:26:29.788: Find a better model.
2023-05-16 16:26:39.884: [iter 22 : loss : 0.2929 = 0.1907 + 0.1006 + 0.0017, time: 10.094030]
2023-05-16 16:26:40.246: epoch 22:	0.02037154  	0.15005341  	0.07600911  
2023-05-16 16:26:40.246: Find a better model.
2023-05-16 16:26:50.687: [iter 23 : loss : 0.2848 = 0.1828 + 0.1003 + 0.0017, time: 10.436604]
2023-05-16 16:26:51.019: epoch 23:	0.02066085  	0.15247519  	0.07719207  
2023-05-16 16:26:51.019: Find a better model.
2023-05-16 16:27:01.676: [iter 24 : loss : 0.2782 = 0.1767 + 0.0998 + 0.0018, time: 10.654058]
2023-05-16 16:27:02.044: epoch 24:	0.02078787  	0.15342574  	0.07780128  
2023-05-16 16:27:02.044: Find a better model.
2023-05-16 16:27:12.154: [iter 25 : loss : 0.2718 = 0.1705 + 0.0994 + 0.0019, time: 10.109742]
2023-05-16 16:27:12.319: epoch 25:	0.02102073  	0.15469100  	0.07875057  
2023-05-16 16:27:12.319: Find a better model.
2023-05-16 16:27:20.973: [iter 26 : loss : 0.2679 = 0.1670 + 0.0989 + 0.0019, time: 8.652016]
2023-05-16 16:27:21.181: epoch 26:	0.02116893  	0.15596978  	0.07963825  
2023-05-16 16:27:21.181: Find a better model.
2023-05-16 16:27:30.903: [iter 27 : loss : 0.2603 = 0.1598 + 0.0985 + 0.0020, time: 9.720003]
2023-05-16 16:27:31.071: epoch 27:	0.02134534  	0.15728173  	0.08035449  
2023-05-16 16:27:31.071: Find a better model.
2023-05-16 16:27:41.438: [iter 28 : loss : 0.2554 = 0.1552 + 0.0981 + 0.0021, time: 10.364033]
2023-05-16 16:27:41.782: epoch 28:	0.02154998  	0.15879209  	0.08126963  
2023-05-16 16:27:41.782: Find a better model.
2023-05-16 16:27:52.231: [iter 29 : loss : 0.2508 = 0.1510 + 0.0977 + 0.0021, time: 10.447066]
2023-05-16 16:27:52.579: epoch 29:	0.02166994  	0.15953849  	0.08181074  
2023-05-16 16:27:52.579: Find a better model.
2023-05-16 16:28:01.447: [iter 30 : loss : 0.2444 = 0.1449 + 0.0973 + 0.0022, time: 8.865004]
2023-05-16 16:28:01.651: epoch 30:	0.02175462  	0.16001828  	0.08243150  
2023-05-16 16:28:01.651: Find a better model.
2023-05-16 16:28:11.037: [iter 31 : loss : 0.2409 = 0.1417 + 0.0970 + 0.0023, time: 9.385024]
2023-05-16 16:28:11.224: epoch 31:	0.02192397  	0.16129018  	0.08312880  
2023-05-16 16:28:11.224: Find a better model.
2023-05-16 16:28:21.356: [iter 32 : loss : 0.2350 = 0.1361 + 0.0966 + 0.0023, time: 10.130502]
2023-05-16 16:28:21.532: epoch 32:	0.02205805  	0.16260949  	0.08397693  
2023-05-16 16:28:21.532: Find a better model.
2023-05-16 16:28:31.675: [iter 33 : loss : 0.2325 = 0.1339 + 0.0962 + 0.0024, time: 10.139514]
2023-05-16 16:28:32.028: epoch 33:	0.02221329  	0.16350757  	0.08455229  
2023-05-16 16:28:32.029: Find a better model.
2023-05-16 16:28:42.446: [iter 34 : loss : 0.2283 = 0.1301 + 0.0958 + 0.0024, time: 10.412032]
2023-05-16 16:28:42.793: epoch 34:	0.02242499  	0.16536047  	0.08558354  
2023-05-16 16:28:42.793: Find a better model.
2023-05-16 16:28:53.160: [iter 35 : loss : 0.2250 = 0.1269 + 0.0956 + 0.0025, time: 10.364001]
2023-05-16 16:28:53.514: epoch 35:	0.02258023  	0.16615562  	0.08635374  
2023-05-16 16:28:53.514: Find a better model.
2023-05-16 16:29:03.273: [iter 36 : loss : 0.2216 = 0.1238 + 0.0952 + 0.0025, time: 9.758051]
2023-05-16 16:29:03.452: epoch 36:	0.02268608  	0.16678107  	0.08692604  
2023-05-16 16:29:03.452: Find a better model.
2023-05-16 16:29:11.766: [iter 37 : loss : 0.2177 = 0.1202 + 0.0949 + 0.0026, time: 8.312040]
2023-05-16 16:29:11.977: epoch 37:	0.02284133  	0.16839695  	0.08760092  
2023-05-16 16:29:11.977: Find a better model.
2023-05-16 16:29:22.058: [iter 38 : loss : 0.2158 = 0.1185 + 0.0946 + 0.0027, time: 10.079117]
2023-05-16 16:29:22.225: epoch 38:	0.02302479  	0.17008995  	0.08848829  
2023-05-16 16:29:22.225: Find a better model.
2023-05-16 16:29:32.286: [iter 39 : loss : 0.2115 = 0.1145 + 0.0943 + 0.0027, time: 10.057025]
2023-05-16 16:29:32.630: epoch 39:	0.02318004  	0.17150415  	0.08927700  
2023-05-16 16:29:32.630: Find a better model.
2023-05-16 16:29:43.010: [iter 40 : loss : 0.2083 = 0.1115 + 0.0940 + 0.0028, time: 10.375165]
2023-05-16 16:29:43.348: epoch 40:	0.02332117  	0.17251533  	0.08989440  
2023-05-16 16:29:43.348: Find a better model.
2023-05-16 16:29:52.867: [iter 41 : loss : 0.2066 = 0.1101 + 0.0937 + 0.0028, time: 9.515288]
2023-05-16 16:29:53.120: epoch 41:	0.02342701  	0.17303753  	0.09038144  
2023-05-16 16:29:53.120: Find a better model.
2023-05-16 16:30:02.600: [iter 42 : loss : 0.2042 = 0.1079 + 0.0934 + 0.0029, time: 9.479018]
2023-05-16 16:30:02.754: epoch 42:	0.02354697  	0.17346798  	0.09090393  
2023-05-16 16:30:02.754: Find a better model.
2023-05-16 16:30:12.723: [iter 43 : loss : 0.2003 = 0.1043 + 0.0931 + 0.0029, time: 9.965774]
2023-05-16 16:30:13.210: epoch 43:	0.02362459  	0.17398396  	0.09162926  
2023-05-16 16:30:13.210: Find a better model.
2023-05-16 16:30:23.594: [iter 44 : loss : 0.1968 = 0.1010 + 0.0928 + 0.0030, time: 10.382090]
2023-05-16 16:30:23.946: epoch 44:	0.02387862  	0.17640075  	0.09235382  
2023-05-16 16:30:23.947: Find a better model.
2023-05-16 16:30:34.275: [iter 45 : loss : 0.1949 = 0.0992 + 0.0926 + 0.0030, time: 10.326013]
2023-05-16 16:30:34.625: epoch 45:	0.02396330  	0.17680140  	0.09290878  
2023-05-16 16:30:34.625: Find a better model.
2023-05-16 16:30:45.262: [iter 46 : loss : 0.1924 = 0.0970 + 0.0924 + 0.0031, time: 10.632575]
2023-05-16 16:30:45.650: epoch 46:	0.02397036  	0.17664616  	0.09320500  
2023-05-16 16:30:55.377: [iter 47 : loss : 0.1917 = 0.0965 + 0.0921 + 0.0031, time: 9.725007]
2023-05-16 16:30:55.625: epoch 47:	0.02403386  	0.17703982  	0.09354895  
2023-05-16 16:30:55.626: Find a better model.
2023-05-16 16:31:03.720: [iter 48 : loss : 0.1877 = 0.0926 + 0.0919 + 0.0032, time: 8.092486]
2023-05-16 16:31:03.929: epoch 48:	0.02410443  	0.17744552  	0.09379265  
2023-05-16 16:31:03.930: Find a better model.
2023-05-16 16:31:13.850: [iter 49 : loss : 0.1847 = 0.0898 + 0.0917 + 0.0032, time: 9.917810]
2023-05-16 16:31:14.045: epoch 49:	0.02421732  	0.17834415  	0.09435678  
2023-05-16 16:31:14.046: Find a better model.
2023-05-16 16:31:24.385: [iter 50 : loss : 0.1835 = 0.0888 + 0.0914 + 0.0033, time: 10.337011]
2023-05-16 16:31:24.730: epoch 50:	0.02422438  	0.17833410  	0.09446026  
2023-05-16 16:31:35.271: [iter 51 : loss : 0.1806 = 0.0861 + 0.0912 + 0.0033, time: 10.538025]
2023-05-16 16:31:35.662: epoch 51:	0.02433022  	0.17907627  	0.09492256  
2023-05-16 16:31:35.663: Find a better model.
2023-05-16 16:31:45.611: [iter 52 : loss : 0.1807 = 0.0863 + 0.0910 + 0.0034, time: 9.945044]
2023-05-16 16:31:45.923: epoch 52:	0.02437962  	0.17977305  	0.09536455  
2023-05-16 16:31:45.923: Find a better model.
2023-05-16 16:31:55.848: [iter 53 : loss : 0.1783 = 0.0841 + 0.0908 + 0.0034, time: 9.923307]
2023-05-16 16:31:56.014: epoch 53:	0.02449252  	0.18024303  	0.09590632  
2023-05-16 16:31:56.014: Find a better model.
2023-05-16 16:32:05.114: [iter 54 : loss : 0.1766 = 0.0825 + 0.0906 + 0.0035, time: 9.097208]
2023-05-16 16:32:05.277: epoch 54:	0.02464071  	0.18165146  	0.09674359  
2023-05-16 16:32:05.277: Find a better model.
2023-05-16 16:32:13.951: [iter 55 : loss : 0.1744 = 0.0806 + 0.0904 + 0.0035, time: 8.673029]
2023-05-16 16:32:14.106: epoch 55:	0.02466893  	0.18171604  	0.09700053  
2023-05-16 16:32:14.106: Find a better model.
2023-05-16 16:32:24.459: [iter 56 : loss : 0.1728 = 0.0790 + 0.0903 + 0.0035, time: 10.350340]
2023-05-16 16:32:24.811: epoch 56:	0.02476773  	0.18232092  	0.09743931  
2023-05-16 16:32:24.811: Find a better model.
2023-05-16 16:32:35.116: [iter 57 : loss : 0.1706 = 0.0770 + 0.0900 + 0.0036, time: 10.303024]
2023-05-16 16:32:35.472: epoch 57:	0.02490886  	0.18380162  	0.09805754  
2023-05-16 16:32:35.472: Find a better model.
2023-05-16 16:32:43.466: [iter 58 : loss : 0.1692 = 0.0757 + 0.0899 + 0.0036, time: 7.991048]
2023-05-16 16:32:43.780: epoch 58:	0.02488769  	0.18323351  	0.09795532  
2023-05-16 16:32:53.016: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 9.235020]
2023-05-16 16:32:53.167: epoch 59:	0.02490886  	0.18324527  	0.09800167  
2023-05-16 16:33:03.034: [iter 60 : loss : 0.1666 = 0.0733 + 0.0895 + 0.0037, time: 9.864991]
2023-05-16 16:33:03.192: epoch 60:	0.02503587  	0.18409948  	0.09861024  
2023-05-16 16:33:03.192: Find a better model.
2023-05-16 16:33:13.371: [iter 61 : loss : 0.1654 = 0.0723 + 0.0893 + 0.0038, time: 10.174037]
2023-05-16 16:33:13.719: epoch 61:	0.02510644  	0.18446153  	0.09899638  
2023-05-16 16:33:13.719: Find a better model.
2023-05-16 16:33:24.141: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 10.420305]
2023-05-16 16:33:24.491: epoch 62:	0.02511350  	0.18450013  	0.09916964  
2023-05-16 16:33:24.491: Find a better model.
2023-05-16 16:33:34.797: [iter 63 : loss : 0.1622 = 0.0693 + 0.0890 + 0.0039, time: 10.305017]
2023-05-16 16:33:35.149: epoch 63:	0.02516290  	0.18469536  	0.09960410  
2023-05-16 16:33:35.149: Find a better model.
2023-05-16 16:33:44.829: [iter 64 : loss : 0.1613 = 0.0685 + 0.0888 + 0.0039, time: 9.678846]
2023-05-16 16:33:45.108: epoch 64:	0.02515583  	0.18494423  	0.09983118  
2023-05-16 16:33:45.108: Find a better model.
2023-05-16 16:33:53.203: [iter 65 : loss : 0.1597 = 0.0671 + 0.0887 + 0.0040, time: 8.093935]
2023-05-16 16:33:53.413: epoch 65:	0.02528991  	0.18592277  	0.10042219  
2023-05-16 16:33:53.413: Find a better model.
2023-05-16 16:34:03.255: [iter 66 : loss : 0.1582 = 0.0657 + 0.0885 + 0.0040, time: 9.840087]
2023-05-16 16:34:03.416: epoch 66:	0.02528991  	0.18578669  	0.10050730  
2023-05-16 16:34:13.839: [iter 67 : loss : 0.1567 = 0.0643 + 0.0884 + 0.0040, time: 10.422085]
2023-05-16 16:34:14.178: epoch 67:	0.02531813  	0.18613258  	0.10078799  
2023-05-16 16:34:14.178: Find a better model.
2023-05-16 16:34:24.577: [iter 68 : loss : 0.1566 = 0.0643 + 0.0883 + 0.0041, time: 10.396024]
2023-05-16 16:34:24.915: epoch 68:	0.02529696  	0.18595454  	0.10077309  
2023-05-16 16:34:34.418: [iter 69 : loss : 0.1546 = 0.0623 + 0.0881 + 0.0041, time: 9.498218]
2023-05-16 16:34:34.729: epoch 69:	0.02538870  	0.18670094  	0.10100732  
2023-05-16 16:34:34.729: Find a better model.
2023-05-16 16:34:44.141: [iter 70 : loss : 0.1530 = 0.0608 + 0.0880 + 0.0042, time: 9.410002]
2023-05-16 16:34:44.304: epoch 70:	0.02543809  	0.18709552  	0.10133951  
2023-05-16 16:34:44.304: Find a better model.
2023-05-16 16:34:53.919: [iter 71 : loss : 0.1514 = 0.0593 + 0.0879 + 0.0042, time: 9.613122]
2023-05-16 16:34:54.084: epoch 71:	0.02546632  	0.18724114  	0.10144531  
2023-05-16 16:34:54.084: Find a better model.
2023-05-16 16:35:03.465: [iter 72 : loss : 0.1513 = 0.0593 + 0.0878 + 0.0042, time: 9.377175]
2023-05-16 16:35:03.745: epoch 72:	0.02550160  	0.18733236  	0.10181496  
2023-05-16 16:35:03.745: Find a better model.
2023-05-16 16:35:14.111: [iter 73 : loss : 0.1501 = 0.0582 + 0.0876 + 0.0043, time: 10.364037]
2023-05-16 16:35:14.469: epoch 73:	0.02553688  	0.18759300  	0.10200126  
2023-05-16 16:35:14.469: Find a better model.
2023-05-16 16:35:24.942: [iter 74 : loss : 0.1487 = 0.0568 + 0.0875 + 0.0043, time: 10.469035]
2023-05-16 16:35:25.305: epoch 74:	0.02550865  	0.18742515  	0.10238890  
2023-05-16 16:35:34.585: [iter 75 : loss : 0.1478 = 0.0561 + 0.0874 + 0.0044, time: 9.278407]
2023-05-16 16:35:34.747: epoch 75:	0.02566389  	0.18837975  	0.10266639  
2023-05-16 16:35:34.747: Find a better model.
2023-05-16 16:35:43.078: [iter 76 : loss : 0.1469 = 0.0553 + 0.0873 + 0.0044, time: 8.328217]
2023-05-16 16:35:43.250: epoch 76:	0.02576268  	0.18944450  	0.10314488  
2023-05-16 16:35:43.250: Find a better model.
2023-05-16 16:35:53.088: [iter 77 : loss : 0.1459 = 0.0542 + 0.0872 + 0.0045, time: 9.835007]
2023-05-16 16:35:53.281: epoch 77:	0.02584030  	0.19020586  	0.10340410  
2023-05-16 16:35:53.281: Find a better model.
2023-05-16 16:36:03.687: [iter 78 : loss : 0.1448 = 0.0533 + 0.0871 + 0.0045, time: 10.401739]
2023-05-16 16:36:04.041: epoch 78:	0.02583324  	0.19023426  	0.10353985  
2023-05-16 16:36:04.041: Find a better model.
2023-05-16 16:36:14.458: [iter 79 : loss : 0.1435 = 0.0520 + 0.0869 + 0.0045, time: 10.407046]
2023-05-16 16:36:14.804: epoch 79:	0.02586853  	0.19021957  	0.10375126  
2023-05-16 16:36:24.441: [iter 80 : loss : 0.1431 = 0.0516 + 0.0869 + 0.0046, time: 9.626242]
2023-05-16 16:36:24.745: epoch 80:	0.02587558  	0.19035056  	0.10379052  
2023-05-16 16:36:24.745: Find a better model.
2023-05-16 16:36:34.492: [iter 81 : loss : 0.1428 = 0.0515 + 0.0867 + 0.0046, time: 9.745001]
2023-05-16 16:36:34.694: epoch 81:	0.02591792  	0.19068377  	0.10414888  
2023-05-16 16:36:34.694: Find a better model.
2023-05-16 16:36:44.034: [iter 82 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0046, time: 9.339008]
2023-05-16 16:36:44.202: epoch 82:	0.02603082  	0.19125180  	0.10441774  
2023-05-16 16:36:44.202: Find a better model.
2023-05-16 16:36:52.999: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 8.794071]
2023-05-16 16:36:53.247: epoch 83:	0.02609433  	0.19173259  	0.10472930  
2023-05-16 16:36:53.247: Find a better model.
2023-05-16 16:37:03.665: [iter 84 : loss : 0.1404 = 0.0492 + 0.0864 + 0.0047, time: 10.413401]
2023-05-16 16:37:04.032: epoch 84:	0.02617195  	0.19242716  	0.10492913  
2023-05-16 16:37:04.032: Find a better model.
2023-05-16 16:37:14.530: [iter 85 : loss : 0.1394 = 0.0483 + 0.0863 + 0.0048, time: 10.487112]
2023-05-16 16:37:14.876: epoch 85:	0.02614373  	0.19242495  	0.10504217  
2023-05-16 16:37:24.147: [iter 86 : loss : 0.1392 = 0.0482 + 0.0862 + 0.0048, time: 9.269197]
2023-05-16 16:37:24.310: epoch 86:	0.02616489  	0.19277179  	0.10529768  
2023-05-16 16:37:24.310: Find a better model.
2023-05-16 16:37:32.871: [iter 87 : loss : 0.1366 = 0.0457 + 0.0861 + 0.0048, time: 8.559266]
2023-05-16 16:37:33.034: epoch 87:	0.02622135  	0.19299503  	0.10527161  
2023-05-16 16:37:33.034: Find a better model.
2023-05-16 16:37:43.079: [iter 88 : loss : 0.1357 = 0.0448 + 0.0860 + 0.0049, time: 10.042017]
2023-05-16 16:37:43.347: epoch 88:	0.02629897  	0.19362096  	0.10546511  
2023-05-16 16:37:43.348: Find a better model.
2023-05-16 16:37:54.041: [iter 89 : loss : 0.1356 = 0.0448 + 0.0860 + 0.0049, time: 10.689693]
2023-05-16 16:37:54.393: epoch 89:	0.02631307  	0.19367151  	0.10571223  
2023-05-16 16:37:54.393: Find a better model.
2023-05-16 16:38:04.849: [iter 90 : loss : 0.1362 = 0.0454 + 0.0859 + 0.0050, time: 10.453011]
2023-05-16 16:38:05.209: epoch 90:	0.02632719  	0.19387014  	0.10578649  
2023-05-16 16:38:05.209: Find a better model.
2023-05-16 16:38:14.648: [iter 91 : loss : 0.1346 = 0.0439 + 0.0858 + 0.0050, time: 9.436724]
2023-05-16 16:38:14.966: epoch 91:	0.02629191  	0.19372295  	0.10580208  
2023-05-16 16:38:24.658: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 9.691019]
2023-05-16 16:38:24.814: epoch 92:	0.02636248  	0.19445109  	0.10602377  
2023-05-16 16:38:24.814: Find a better model.
2023-05-16 16:38:34.471: [iter 93 : loss : 0.1342 = 0.0435 + 0.0856 + 0.0051, time: 9.653959]
2023-05-16 16:38:34.637: epoch 93:	0.02640481  	0.19444619  	0.10634010  
2023-05-16 16:38:44.558: [iter 94 : loss : 0.1319 = 0.0413 + 0.0855 + 0.0051, time: 9.919017]
2023-05-16 16:38:44.878: epoch 94:	0.02639776  	0.19429138  	0.10639180  
2023-05-16 16:38:55.360: [iter 95 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 10.479100]
2023-05-16 16:38:55.728: epoch 95:	0.02644010  	0.19459964  	0.10671768  
2023-05-16 16:38:55.728: Find a better model.
2023-05-16 16:39:06.117: [iter 96 : loss : 0.1317 = 0.0412 + 0.0854 + 0.0052, time: 10.385626]
2023-05-16 16:39:06.464: epoch 96:	0.02650360  	0.19493066  	0.10685321  
2023-05-16 16:39:06.464: Find a better model.
2023-05-16 16:39:15.831: [iter 97 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0052, time: 9.366105]
2023-05-16 16:39:16.360: epoch 97:	0.02648243  	0.19485062  	0.10674594  
2023-05-16 16:39:24.639: [iter 98 : loss : 0.1306 = 0.0401 + 0.0852 + 0.0052, time: 8.276005]
2023-05-16 16:39:24.845: epoch 98:	0.02653183  	0.19500820  	0.10699899  
2023-05-16 16:39:24.845: Find a better model.
2023-05-16 16:39:34.879: [iter 99 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0053, time: 10.032009]
2023-05-16 16:39:35.053: epoch 99:	0.02657417  	0.19552124  	0.10720504  
2023-05-16 16:39:35.053: Find a better model.
2023-05-16 16:39:45.521: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 10.462364]
2023-05-16 16:39:45.886: epoch 100:	0.02663063  	0.19590685  	0.10727741  
2023-05-16 16:39:45.886: Find a better model.
2023-05-16 16:39:56.294: [iter 101 : loss : 0.1285 = 0.0382 + 0.0850 + 0.0054, time: 10.406171]
2023-05-16 16:39:56.643: epoch 101:	0.02659534  	0.19574232  	0.10737409  
2023-05-16 16:40:05.979: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 9.333001]
2023-05-16 16:40:06.216: epoch 102:	0.02659534  	0.19554852  	0.10750240  
2023-05-16 16:40:15.591: [iter 103 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 9.374009]
2023-05-16 16:40:15.752: epoch 103:	0.02657416  	0.19534212  	0.10762083  
2023-05-16 16:40:25.634: [iter 104 : loss : 0.1277 = 0.0374 + 0.0848 + 0.0055, time: 9.879001]
2023-05-16 16:40:26.210: epoch 104:	0.02656005  	0.19557011  	0.10780630  
2023-05-16 16:40:36.193: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 9.979152]
2023-05-16 16:40:36.542: epoch 105:	0.02660945  	0.19570461  	0.10773897  
2023-05-16 16:40:46.954: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 10.410024]
2023-05-16 16:40:47.296: epoch 106:	0.02663767  	0.19588658  	0.10793054  
2023-05-16 16:40:57.764: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 10.466028]
2023-05-16 16:40:58.120: epoch 107:	0.02665884  	0.19578648  	0.10783175  
2023-05-16 16:41:07.901: [iter 108 : loss : 0.1254 = 0.0352 + 0.0845 + 0.0056, time: 9.779116]
2023-05-16 16:41:08.078: epoch 108:	0.02661650  	0.19550169  	0.10802428  
2023-05-16 16:41:16.416: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 8.335007]
2023-05-16 16:41:16.647: epoch 109:	0.02665883  	0.19577454  	0.10801920  
2023-05-16 16:41:26.564: [iter 110 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 9.914006]
2023-05-16 16:41:26.752: epoch 110:	0.02671529  	0.19616140  	0.10813680  
2023-05-16 16:41:26.752: Find a better model.
2023-05-16 16:41:37.175: [iter 111 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 10.420027]
2023-05-16 16:41:37.522: epoch 111:	0.02670117  	0.19600773  	0.10811769  
2023-05-16 16:41:48.043: [iter 112 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0057, time: 10.519069]
2023-05-16 16:41:48.407: epoch 112:	0.02670823  	0.19598839  	0.10811105  
2023-05-16 16:41:57.770: [iter 113 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0058, time: 9.362030]
2023-05-16 16:41:57.953: epoch 113:	0.02665883  	0.19551235  	0.10792664  
2023-05-16 16:42:07.561: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 9.607006]
2023-05-16 16:42:07.729: epoch 114:	0.02669412  	0.19591019  	0.10802577  
2023-05-16 16:42:17.340: [iter 115 : loss : 0.1217 = 0.0318 + 0.0841 + 0.0058, time: 9.609991]
2023-05-16 16:42:17.502: epoch 115:	0.02671529  	0.19597450  	0.10818251  
2023-05-16 16:42:27.651: [iter 116 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0059, time: 10.146027]
2023-05-16 16:42:27.896: epoch 116:	0.02669412  	0.19610728  	0.10833319  
2023-05-16 16:42:38.260: [iter 117 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 10.355016]
2023-05-16 16:42:38.622: epoch 117:	0.02675058  	0.19660911  	0.10852687  
2023-05-16 16:42:38.622: Find a better model.
2023-05-16 16:42:48.870: [iter 118 : loss : 0.1208 = 0.0309 + 0.0839 + 0.0059, time: 10.245512]
2023-05-16 16:42:49.225: epoch 118:	0.02669412  	0.19594584  	0.10843817  
2023-05-16 16:42:58.550: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 9.323992]
2023-05-16 16:42:58.805: epoch 119:	0.02670118  	0.19615085  	0.10852836  
2023-05-16 16:43:06.739: [iter 120 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 7.931096]
2023-05-16 16:43:06.926: epoch 120:	0.02677175  	0.19663042  	0.10867082  
2023-05-16 16:43:06.927: Find a better model.
2023-05-16 16:43:16.787: [iter 121 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0060, time: 9.859000]
2023-05-16 16:43:16.976: epoch 121:	0.02679997  	0.19715986  	0.10883982  
2023-05-16 16:43:16.976: Find a better model.
2023-05-16 16:43:27.273: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0061, time: 10.294083]
2023-05-16 16:43:27.629: epoch 122:	0.02681408  	0.19702324  	0.10870865  
2023-05-16 16:43:38.052: [iter 123 : loss : 0.1194 = 0.0296 + 0.0837 + 0.0061, time: 10.418028]
2023-05-16 16:43:38.412: epoch 123:	0.02679997  	0.19716461  	0.10887136  
2023-05-16 16:43:38.412: Find a better model.
2023-05-16 16:43:48.089: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 9.674013]
2023-05-16 16:43:48.383: epoch 124:	0.02683526  	0.19728646  	0.10895730  
2023-05-16 16:43:48.384: Find a better model.
2023-05-16 16:43:56.695: [iter 125 : loss : 0.1176 = 0.0278 + 0.0836 + 0.0061, time: 8.310545]
2023-05-16 16:43:56.855: epoch 125:	0.02678586  	0.19681904  	0.10879615  
2023-05-16 16:44:05.327: [iter 126 : loss : 0.1177 = 0.0280 + 0.0836 + 0.0062, time: 8.470041]
2023-05-16 16:44:05.490: epoch 126:	0.02688466  	0.19734102  	0.10902141  
2023-05-16 16:44:05.490: Find a better model.
2023-05-16 16:44:13.290: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 7.797365]
2023-05-16 16:44:13.452: epoch 127:	0.02677881  	0.19657283  	0.10882677  
2023-05-16 16:44:22.690: [iter 128 : loss : 0.1181 = 0.0284 + 0.0835 + 0.0062, time: 9.235044]
2023-05-16 16:44:23.004: epoch 128:	0.02687760  	0.19701259  	0.10914004  
2023-05-16 16:44:31.063: [iter 129 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 8.025176]
2023-05-16 16:44:31.317: epoch 129:	0.02688465  	0.19716120  	0.10909044  
2023-05-16 16:44:39.296: [iter 130 : loss : 0.1172 = 0.0275 + 0.0834 + 0.0063, time: 7.978677]
2023-05-16 16:44:39.461: epoch 130:	0.02684231  	0.19674984  	0.10911275  
2023-05-16 16:44:48.012: [iter 131 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0063, time: 8.549079]
2023-05-16 16:44:48.178: epoch 131:	0.02691288  	0.19718024  	0.10928339  
2023-05-16 16:44:57.411: [iter 132 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0064, time: 9.229053]
2023-05-16 16:44:57.717: epoch 132:	0.02684937  	0.19673565  	0.10919178  
2023-05-16 16:45:07.013: [iter 133 : loss : 0.1152 = 0.0256 + 0.0833 + 0.0064, time: 9.294078]
2023-05-16 16:45:07.312: epoch 133:	0.02684937  	0.19668540  	0.10922555  
2023-05-16 16:45:15.674: [iter 134 : loss : 0.1159 = 0.0263 + 0.0832 + 0.0064, time: 8.359025]
2023-05-16 16:45:15.837: epoch 134:	0.02682114  	0.19639035  	0.10935563  
2023-05-16 16:45:23.681: [iter 135 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 7.842006]
2023-05-16 16:45:23.840: epoch 135:	0.02691994  	0.19717939  	0.10980772  
2023-05-16 16:45:32.093: [iter 136 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0065, time: 8.252215]
2023-05-16 16:45:32.251: epoch 136:	0.02685643  	0.19642517  	0.10965504  
2023-05-16 16:45:41.393: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 9.138043]
2023-05-16 16:45:41.672: epoch 137:	0.02679997  	0.19633068  	0.10969321  
2023-05-16 16:45:49.600: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 7.925280]
2023-05-16 16:45:49.762: epoch 138:	0.02680703  	0.19641326  	0.10961342  
2023-05-16 16:45:58.288: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 8.525007]
2023-05-16 16:45:58.452: epoch 139:	0.02687760  	0.19684912  	0.10975623  
2023-05-16 16:46:07.052: [iter 140 : loss : 0.1138 = 0.0243 + 0.0830 + 0.0066, time: 8.598001]
2023-05-16 16:46:07.211: epoch 140:	0.02689877  	0.19688781  	0.10978611  
2023-05-16 16:46:15.267: [iter 141 : loss : 0.1143 = 0.0248 + 0.0829 + 0.0066, time: 8.055027]
2023-05-16 16:46:15.423: epoch 141:	0.02687054  	0.19683300  	0.10974221  
2023-05-16 16:46:24.564: [iter 142 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 9.139119]
2023-05-16 16:46:24.859: epoch 142:	0.02687760  	0.19697924  	0.10979673  
2023-05-16 16:46:32.787: [iter 143 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0067, time: 7.924993]
2023-05-16 16:46:32.943: epoch 143:	0.02693405  	0.19735162  	0.10991619  
2023-05-16 16:46:32.943: Find a better model.
2023-05-16 16:46:41.028: [iter 144 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0067, time: 8.083992]
2023-05-16 16:46:41.184: epoch 144:	0.02689171  	0.19704270  	0.10985193  
2023-05-16 16:46:49.615: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 8.428908]
2023-05-16 16:46:49.773: epoch 145:	0.02685643  	0.19667803  	0.10978498  
2023-05-16 16:46:59.345: [iter 146 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0067, time: 9.569243]
2023-05-16 16:46:59.643: epoch 146:	0.02684937  	0.19642086  	0.10965338  
2023-05-16 16:47:08.857: [iter 147 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0068, time: 9.210271]
2023-05-16 16:47:09.172: epoch 147:	0.02684232  	0.19661698  	0.10988542  
2023-05-16 16:47:17.365: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 8.190995]
2023-05-16 16:47:17.528: epoch 148:	0.02680703  	0.19640720  	0.10985131  
2023-05-16 16:47:25.231: [iter 149 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.701993]
2023-05-16 16:47:25.394: epoch 149:	0.02684231  	0.19632140  	0.10982140  
2023-05-16 16:47:33.858: [iter 150 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0069, time: 8.461306]
2023-05-16 16:47:34.011: epoch 150:	0.02687054  	0.19660273  	0.10982376  
2023-05-16 16:47:43.071: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 9.056992]
2023-05-16 16:47:43.335: epoch 151:	0.02684937  	0.19620086  	0.10971460  
2023-05-16 16:47:52.465: [iter 152 : loss : 0.1108 = 0.0213 + 0.0826 + 0.0069, time: 9.127991]
2023-05-16 16:47:52.778: epoch 152:	0.02682821  	0.19628069  	0.10961394  
2023-05-16 16:48:01.085: [iter 153 : loss : 0.1100 = 0.0205 + 0.0826 + 0.0069, time: 8.305993]
2023-05-16 16:48:01.245: epoch 153:	0.02681409  	0.19601630  	0.10966242  
2023-05-16 16:48:09.269: [iter 154 : loss : 0.1104 = 0.0209 + 0.0825 + 0.0070, time: 8.021992]
2023-05-16 16:48:09.524: epoch 154:	0.02670824  	0.19550204  	0.10960176  
2023-05-16 16:48:17.789: [iter 155 : loss : 0.1111 = 0.0216 + 0.0825 + 0.0070, time: 8.262992]
2023-05-16 16:48:17.945: epoch 155:	0.02664473  	0.19533844  	0.10961806  
2023-05-16 16:48:27.104: [iter 156 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 9.155999]
2023-05-16 16:48:27.403: epoch 156:	0.02669413  	0.19546777  	0.10960308  
2023-05-16 16:48:34.831: [iter 157 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 7.425993]
2023-05-16 16:48:34.998: epoch 157:	0.02670825  	0.19544517  	0.10967956  
2023-05-16 16:48:43.444: [iter 158 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 8.443520]
2023-05-16 16:48:43.599: epoch 158:	0.02677176  	0.19627170  	0.10968896  
2023-05-16 16:48:52.178: [iter 159 : loss : 0.1099 = 0.0205 + 0.0823 + 0.0071, time: 8.577006]
2023-05-16 16:48:52.335: epoch 159:	0.02672236  	0.19593699  	0.10957798  
2023-05-16 16:49:00.193: [iter 160 : loss : 0.1095 = 0.0201 + 0.0823 + 0.0071, time: 7.856498]
2023-05-16 16:49:00.352: epoch 160:	0.02666591  	0.19540058  	0.10947223  
2023-05-16 16:49:09.600: [iter 161 : loss : 0.1090 = 0.0196 + 0.0823 + 0.0071, time: 9.247201]
2023-05-16 16:49:09.906: epoch 161:	0.02664475  	0.19570398  	0.10956746  
2023-05-16 16:49:17.669: [iter 162 : loss : 0.1085 = 0.0191 + 0.0823 + 0.0072, time: 7.761003]
2023-05-16 16:49:17.827: epoch 162:	0.02664474  	0.19529165  	0.10934094  
2023-05-16 16:49:25.777: [iter 163 : loss : 0.1087 = 0.0192 + 0.0822 + 0.0072, time: 7.949038]
2023-05-16 16:49:25.937: epoch 163:	0.02660946  	0.19516414  	0.10914503  
2023-05-16 16:49:34.391: [iter 164 : loss : 0.1088 = 0.0193 + 0.0822 + 0.0072, time: 8.453139]
2023-05-16 16:49:34.553: epoch 164:	0.02670120  	0.19598037  	0.10949884  
2023-05-16 16:49:43.166: [iter 165 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 8.611019]
2023-05-16 16:49:43.456: epoch 165:	0.02670119  	0.19596225  	0.10944925  
2023-05-16 16:49:52.703: [iter 166 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 9.239022]
2023-05-16 16:49:53.000: epoch 166:	0.02670120  	0.19594739  	0.10960186  
2023-05-16 16:50:01.823: [iter 167 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0073, time: 8.821554]
2023-05-16 16:50:01.985: epoch 167:	0.02665886  	0.19544636  	0.10941357  
2023-05-16 16:50:09.789: [iter 168 : loss : 0.1079 = 0.0184 + 0.0821 + 0.0073, time: 7.803378]
2023-05-16 16:50:09.956: epoch 168:	0.02663769  	0.19507916  	0.10923912  
2023-05-16 16:50:09.956: Early stopping is trigger at epoch: 168
2023-05-16 16:50:09.956: best_result@epoch 143:

2023-05-16 16:50:09.956: 		0.0269      	0.1974      	0.1099      
2023-05-16 17:16:51.443: my pid: 11228
2023-05-16 17:16:51.444: model: model.general_recommender.SGL
2023-05-16 17:16:51.444: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 17:16:51.444: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 17:16:54.600: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 17:17:03.238: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.636702]
2023-05-16 17:17:03.384: epoch 1:	0.00156647  	0.01121095  	0.00533219  
2023-05-16 17:17:03.384: Find a better model.
2023-05-16 17:17:12.240: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 8.853884]
2023-05-16 17:17:12.429: epoch 2:	0.00272368  	0.02101265  	0.01006706  
2023-05-16 17:17:12.429: Find a better model.
2023-05-16 17:17:20.846: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.416587]
2023-05-16 17:17:21.013: epoch 3:	0.00464294  	0.03552489  	0.01704598  
2023-05-16 17:17:21.013: Find a better model.
2023-05-16 17:17:29.536: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 8.521302]
2023-05-16 17:17:29.708: epoch 4:	0.00773349  	0.05719993  	0.02771139  
2023-05-16 17:17:29.708: Find a better model.
2023-05-16 17:17:38.495: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 8.786447]
2023-05-16 17:17:38.646: epoch 5:	0.01133223  	0.08301944  	0.03898768  
2023-05-16 17:17:38.646: Find a better model.
2023-05-16 17:17:47.732: [iter 6 : loss : 0.7677 = 0.6885 + 0.0792 + 0.0000, time: 9.084422]
2023-05-16 17:17:47.896: epoch 6:	0.01471225  	0.10672856  	0.05182076  
2023-05-16 17:17:47.897: Find a better model.
2023-05-16 17:17:56.661: [iter 7 : loss : 0.7619 = 0.6820 + 0.0798 + 0.0000, time: 8.763303]
2023-05-16 17:17:56.825: epoch 7:	0.01769711  	0.12804700  	0.06257070  
2023-05-16 17:17:56.825: Find a better model.
2023-05-16 17:18:05.819: [iter 8 : loss : 0.7476 = 0.6659 + 0.0816 + 0.0001, time: 8.990405]
2023-05-16 17:18:05.982: epoch 8:	0.01862856  	0.13671081  	0.06753570  
2023-05-16 17:18:05.982: Find a better model.
2023-05-16 17:18:15.425: [iter 9 : loss : 0.7148 = 0.6293 + 0.0853 + 0.0001, time: 9.436752]
2023-05-16 17:18:15.734: epoch 9:	0.01865678  	0.13772602  	0.06890146  
2023-05-16 17:18:15.734: Find a better model.
2023-05-16 17:18:23.682: [iter 10 : loss : 0.6559 = 0.5649 + 0.0908 + 0.0002, time: 7.944540]
2023-05-16 17:18:24.132: epoch 10:	0.01832514  	0.13540347  	0.06790298  
2023-05-16 17:18:32.834: [iter 11 : loss : 0.5804 = 0.4840 + 0.0960 + 0.0004, time: 8.700114]
2023-05-16 17:18:32.996: epoch 11:	0.01834631  	0.13552369  	0.06773955  
2023-05-16 17:18:41.477: [iter 12 : loss : 0.5100 = 0.4099 + 0.0996 + 0.0005, time: 8.479872]
2023-05-16 17:18:41.633: epoch 12:	0.01831809  	0.13552725  	0.06798892  
2023-05-16 17:18:49.788: [iter 13 : loss : 0.4578 = 0.3556 + 0.1015 + 0.0007, time: 8.152829]
2023-05-16 17:18:49.976: epoch 13:	0.01836748  	0.13618170  	0.06825061  
2023-05-16 17:18:59.395: [iter 14 : loss : 0.4184 = 0.3150 + 0.1025 + 0.0008, time: 9.415919]
2023-05-16 17:18:59.701: epoch 14:	0.01857211  	0.13776730  	0.06927674  
2023-05-16 17:18:59.701: Find a better model.
2023-05-16 17:19:08.706: [iter 15 : loss : 0.3910 = 0.2871 + 0.1029 + 0.0010, time: 9.004693]
2023-05-16 17:19:09.019: epoch 15:	0.01876970  	0.13906585  	0.07027056  
2023-05-16 17:19:09.019: Find a better model.
2023-05-16 17:19:17.650: [iter 16 : loss : 0.3683 = 0.2643 + 0.1029 + 0.0011, time: 8.629008]
2023-05-16 17:19:17.824: epoch 16:	0.01896023  	0.14009814  	0.07098649  
2023-05-16 17:19:17.824: Find a better model.
2023-05-16 17:19:27.032: [iter 17 : loss : 0.3516 = 0.2477 + 0.1027 + 0.0012, time: 9.207094]
2023-05-16 17:19:27.187: epoch 17:	0.01923543  	0.14240916  	0.07217602  
2023-05-16 17:19:27.188: Find a better model.
2023-05-16 17:19:37.432: [iter 18 : loss : 0.3361 = 0.2323 + 0.1025 + 0.0013, time: 10.241599]
2023-05-16 17:19:37.784: epoch 18:	0.01952475  	0.14458160  	0.07322066  
2023-05-16 17:19:37.784: Find a better model.
2023-05-16 17:19:48.137: [iter 19 : loss : 0.3219 = 0.2185 + 0.1021 + 0.0014, time: 10.341247]
2023-05-16 17:19:48.475: epoch 19:	0.01967294  	0.14527044  	0.07388958  
2023-05-16 17:19:48.475: Find a better model.
2023-05-16 17:19:57.442: [iter 20 : loss : 0.3122 = 0.2090 + 0.1017 + 0.0015, time: 8.965253]
2023-05-16 17:19:57.615: epoch 20:	0.01987053  	0.14648682  	0.07434353  
2023-05-16 17:19:57.615: Find a better model.
2023-05-16 17:20:06.182: [iter 21 : loss : 0.3026 = 0.1997 + 0.1013 + 0.0016, time: 8.565363]
2023-05-16 17:20:06.345: epoch 21:	0.02008927  	0.14849631  	0.07517970  
2023-05-16 17:20:06.345: Find a better model.
2023-05-16 17:20:16.395: [iter 22 : loss : 0.2942 = 0.1916 + 0.1009 + 0.0016, time: 10.048059]
2023-05-16 17:20:16.557: epoch 22:	0.02030097  	0.14975812  	0.07572698  
2023-05-16 17:20:16.557: Find a better model.
2023-05-16 17:20:27.559: [iter 23 : loss : 0.2859 = 0.1837 + 0.1005 + 0.0017, time: 10.994513]
2023-05-16 17:20:27.978: epoch 23:	0.02047032  	0.15056762  	0.07666776  
2023-05-16 17:20:27.978: Find a better model.
2023-05-16 17:20:38.558: [iter 24 : loss : 0.2792 = 0.1775 + 0.1000 + 0.0018, time: 10.575270]
2023-05-16 17:20:38.911: epoch 24:	0.02066084  	0.15195878  	0.07736260  
2023-05-16 17:20:38.911: Find a better model.
2023-05-16 17:20:48.976: [iter 25 : loss : 0.2728 = 0.1713 + 0.0996 + 0.0019, time: 10.057017]
2023-05-16 17:20:49.285: epoch 25:	0.02084432  	0.15341157  	0.07817982  
2023-05-16 17:20:49.285: Find a better model.
2023-05-16 17:20:59.213: [iter 26 : loss : 0.2689 = 0.1678 + 0.0991 + 0.0019, time: 9.927705]
2023-05-16 17:20:59.387: epoch 26:	0.02104896  	0.15509638  	0.07913688  
2023-05-16 17:20:59.387: Find a better model.
2023-05-16 17:21:09.343: [iter 27 : loss : 0.2613 = 0.1606 + 0.0987 + 0.0020, time: 9.953129]
2023-05-16 17:21:09.513: epoch 27:	0.02130299  	0.15698123  	0.08005847  
2023-05-16 17:21:09.514: Find a better model.
2023-05-16 17:21:17.936: [iter 28 : loss : 0.2564 = 0.1560 + 0.0983 + 0.0021, time: 8.420156]
2023-05-16 17:21:18.240: epoch 28:	0.02134534  	0.15693142  	0.08053483  
2023-05-16 17:21:28.331: [iter 29 : loss : 0.2518 = 0.1518 + 0.0979 + 0.0021, time: 10.090765]
2023-05-16 17:21:28.678: epoch 29:	0.02147941  	0.15821782  	0.08132946  
2023-05-16 17:21:28.678: Find a better model.
2023-05-16 17:21:38.876: [iter 30 : loss : 0.2454 = 0.1456 + 0.0976 + 0.0022, time: 10.194136]
2023-05-16 17:21:39.195: epoch 30:	0.02169111  	0.15982226  	0.08216834  
2023-05-16 17:21:39.195: Find a better model.
2023-05-16 17:21:48.079: [iter 31 : loss : 0.2417 = 0.1423 + 0.0971 + 0.0023, time: 8.882986]
2023-05-16 17:21:48.307: epoch 31:	0.02188163  	0.16102475  	0.08277372  
2023-05-16 17:21:48.308: Find a better model.
2023-05-16 17:21:56.719: [iter 32 : loss : 0.2360 = 0.1369 + 0.0968 + 0.0023, time: 8.404425]
2023-05-16 17:21:56.902: epoch 32:	0.02205099  	0.16255137  	0.08348689  
2023-05-16 17:21:56.902: Find a better model.
2023-05-16 17:22:07.165: [iter 33 : loss : 0.2334 = 0.1346 + 0.0964 + 0.0024, time: 10.260993]
2023-05-16 17:22:07.395: epoch 33:	0.02218506  	0.16344169  	0.08393096  
2023-05-16 17:22:07.395: Find a better model.
2023-05-16 17:22:17.724: [iter 34 : loss : 0.2292 = 0.1307 + 0.0960 + 0.0024, time: 10.327017]
2023-05-16 17:22:18.070: epoch 34:	0.02229091  	0.16415058  	0.08468229  
2023-05-16 17:22:18.070: Find a better model.
2023-05-16 17:22:28.288: [iter 35 : loss : 0.2258 = 0.1276 + 0.0957 + 0.0025, time: 10.210137]
2023-05-16 17:22:28.637: epoch 35:	0.02238264  	0.16514400  	0.08535691  
2023-05-16 17:22:28.637: Find a better model.
2023-05-16 17:22:38.837: [iter 36 : loss : 0.2222 = 0.1243 + 0.0953 + 0.0025, time: 10.197372]
2023-05-16 17:22:39.182: epoch 36:	0.02260139  	0.16657837  	0.08625164  
2023-05-16 17:22:39.182: Find a better model.
2023-05-16 17:22:49.274: [iter 37 : loss : 0.2186 = 0.1210 + 0.0950 + 0.0026, time: 10.090992]
2023-05-16 17:22:49.456: epoch 37:	0.02273547  	0.16722764  	0.08683878  
2023-05-16 17:22:49.456: Find a better model.
2023-05-16 17:22:58.011: [iter 38 : loss : 0.2168 = 0.1194 + 0.0947 + 0.0026, time: 8.554018]
2023-05-16 17:22:58.219: epoch 38:	0.02277781  	0.16776483  	0.08729464  
2023-05-16 17:22:58.219: Find a better model.
2023-05-16 17:23:07.787: [iter 39 : loss : 0.2124 = 0.1153 + 0.0944 + 0.0027, time: 9.566230]
2023-05-16 17:23:08.007: epoch 39:	0.02292599  	0.16901290  	0.08802111  
2023-05-16 17:23:08.008: Find a better model.
2023-05-16 17:23:18.242: [iter 40 : loss : 0.2092 = 0.1123 + 0.0941 + 0.0028, time: 10.231636]
2023-05-16 17:23:18.606: epoch 40:	0.02304595  	0.16953127  	0.08830316  
2023-05-16 17:23:18.606: Find a better model.
2023-05-16 17:23:28.980: [iter 41 : loss : 0.2074 = 0.1107 + 0.0939 + 0.0028, time: 10.370769]
2023-05-16 17:23:29.319: epoch 41:	0.02317297  	0.17051256  	0.08899919  
2023-05-16 17:23:29.319: Find a better model.
2023-05-16 17:23:38.556: [iter 42 : loss : 0.2051 = 0.1086 + 0.0936 + 0.0029, time: 9.235166]
2023-05-16 17:23:39.126: epoch 42:	0.02327881  	0.17154123  	0.08962531  
2023-05-16 17:23:39.126: Find a better model.
2023-05-16 17:23:49.152: [iter 43 : loss : 0.2013 = 0.1052 + 0.0932 + 0.0029, time: 10.021033]
2023-05-16 17:23:49.309: epoch 43:	0.02346934  	0.17267135  	0.09037059  
2023-05-16 17:23:49.310: Find a better model.
2023-05-16 17:23:59.382: [iter 44 : loss : 0.1978 = 0.1018 + 0.0930 + 0.0030, time: 10.071218]
2023-05-16 17:23:59.546: epoch 44:	0.02354696  	0.17329055  	0.09097906  
2023-05-16 17:23:59.546: Find a better model.
2023-05-16 17:24:08.631: [iter 45 : loss : 0.1956 = 0.0999 + 0.0928 + 0.0030, time: 9.082435]
2023-05-16 17:24:08.987: epoch 45:	0.02366692  	0.17410772  	0.09154814  
2023-05-16 17:24:08.987: Find a better model.
2023-05-16 17:24:19.349: [iter 46 : loss : 0.1933 = 0.0977 + 0.0925 + 0.0031, time: 10.358722]
2023-05-16 17:24:19.705: epoch 46:	0.02380099  	0.17485404  	0.09207601  
2023-05-16 17:24:19.706: Find a better model.
2023-05-16 17:24:29.975: [iter 47 : loss : 0.1924 = 0.0971 + 0.0923 + 0.0031, time: 10.262110]
2023-05-16 17:24:30.331: epoch 47:	0.02380805  	0.17518981  	0.09248412  
2023-05-16 17:24:30.331: Find a better model.
2023-05-16 17:24:39.948: [iter 48 : loss : 0.1885 = 0.0933 + 0.0920 + 0.0032, time: 9.614759]
2023-05-16 17:24:40.355: epoch 48:	0.02394212  	0.17625371  	0.09296536  
2023-05-16 17:24:40.355: Find a better model.
2023-05-16 17:24:48.558: [iter 49 : loss : 0.1854 = 0.0904 + 0.0918 + 0.0032, time: 8.202024]
2023-05-16 17:24:48.767: epoch 49:	0.02400563  	0.17649367  	0.09332213  
2023-05-16 17:24:48.767: Find a better model.
2023-05-16 17:24:58.590: [iter 50 : loss : 0.1845 = 0.0897 + 0.0916 + 0.0033, time: 9.820674]
2023-05-16 17:24:58.786: epoch 50:	0.02409030  	0.17720096  	0.09392986  
2023-05-16 17:24:58.786: Find a better model.
2023-05-16 17:25:09.208: [iter 51 : loss : 0.1814 = 0.0867 + 0.0914 + 0.0033, time: 10.418743]
2023-05-16 17:25:09.558: epoch 51:	0.02416087  	0.17768994  	0.09416942  
2023-05-16 17:25:09.558: Find a better model.
2023-05-16 17:25:19.915: [iter 52 : loss : 0.1813 = 0.0867 + 0.0912 + 0.0034, time: 10.353579]
2023-05-16 17:25:20.269: epoch 52:	0.02421026  	0.17802759  	0.09448169  
2023-05-16 17:25:20.269: Find a better model.
2023-05-16 17:25:30.251: [iter 53 : loss : 0.1793 = 0.0849 + 0.0910 + 0.0034, time: 9.974758]
2023-05-16 17:25:30.543: epoch 53:	0.02430905  	0.17855403  	0.09493709  
2023-05-16 17:25:30.543: Find a better model.
2023-05-16 17:25:40.274: [iter 54 : loss : 0.1773 = 0.0831 + 0.0907 + 0.0034, time: 9.729420]
2023-05-16 17:25:40.437: epoch 54:	0.02435844  	0.17875986  	0.09528986  
2023-05-16 17:25:40.437: Find a better model.
2023-05-16 17:25:50.592: [iter 55 : loss : 0.1752 = 0.0812 + 0.0905 + 0.0035, time: 10.153355]
2023-05-16 17:25:50.748: epoch 55:	0.02446429  	0.17923313  	0.09571906  
2023-05-16 17:25:50.748: Find a better model.
2023-05-16 17:26:00.960: [iter 56 : loss : 0.1735 = 0.0796 + 0.0903 + 0.0035, time: 10.207145]
2023-05-16 17:26:01.312: epoch 56:	0.02454191  	0.17990011  	0.09618897  
2023-05-16 17:26:01.312: Find a better model.
2023-05-16 17:26:11.570: [iter 57 : loss : 0.1715 = 0.0778 + 0.0902 + 0.0036, time: 10.255944]
2023-05-16 17:26:11.926: epoch 57:	0.02458425  	0.17995536  	0.09657458  
2023-05-16 17:26:11.926: Find a better model.
2023-05-16 17:26:22.236: [iter 58 : loss : 0.1698 = 0.0762 + 0.0900 + 0.0036, time: 10.307078]
2023-05-16 17:26:22.591: epoch 58:	0.02461953  	0.18051620  	0.09702938  
2023-05-16 17:26:22.591: Find a better model.
2023-05-16 17:26:32.307: [iter 59 : loss : 0.1687 = 0.0753 + 0.0898 + 0.0037, time: 9.714816]
2023-05-16 17:26:32.462: epoch 59:	0.02465481  	0.18057162  	0.09726116  
2023-05-16 17:26:32.462: Find a better model.
2023-05-16 17:26:40.569: [iter 60 : loss : 0.1670 = 0.0736 + 0.0897 + 0.0037, time: 8.106005]
2023-05-16 17:26:40.780: epoch 60:	0.02469010  	0.18089166  	0.09766904  
2023-05-16 17:26:40.780: Find a better model.
2023-05-16 17:26:50.735: [iter 61 : loss : 0.1659 = 0.0727 + 0.0894 + 0.0038, time: 9.952998]
2023-05-16 17:26:50.929: epoch 61:	0.02471126  	0.18075895  	0.09774179  
2023-05-16 17:27:01.295: [iter 62 : loss : 0.1640 = 0.0709 + 0.0893 + 0.0038, time: 10.359126]
2023-05-16 17:27:01.640: epoch 62:	0.02477477  	0.18144327  	0.09813765  
2023-05-16 17:27:01.640: Find a better model.
2023-05-16 17:27:11.849: [iter 63 : loss : 0.1628 = 0.0698 + 0.0891 + 0.0039, time: 10.199273]
2023-05-16 17:27:12.221: epoch 63:	0.02486651  	0.18198171  	0.09857256  
2023-05-16 17:27:12.221: Find a better model.
2023-05-16 17:27:21.602: [iter 64 : loss : 0.1618 = 0.0689 + 0.0890 + 0.0039, time: 9.380046]
2023-05-16 17:27:21.793: epoch 64:	0.02492296  	0.18244651  	0.09893253  
2023-05-16 17:27:21.793: Find a better model.
2023-05-16 17:27:31.258: [iter 65 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 9.463013]
2023-05-16 17:27:31.423: epoch 65:	0.02497941  	0.18261929  	0.09923688  
2023-05-16 17:27:31.423: Find a better model.
2023-05-16 17:27:41.300: [iter 66 : loss : 0.1589 = 0.0663 + 0.0886 + 0.0040, time: 9.875541]
2023-05-16 17:27:41.457: epoch 66:	0.02503586  	0.18362065  	0.09980445  
2023-05-16 17:27:41.457: Find a better model.
2023-05-16 17:27:51.409: [iter 67 : loss : 0.1572 = 0.0647 + 0.0885 + 0.0040, time: 9.948462]
2023-05-16 17:27:51.760: epoch 67:	0.02512054  	0.18387568  	0.10021830  
2023-05-16 17:27:51.760: Find a better model.
2023-05-16 17:28:02.085: [iter 68 : loss : 0.1569 = 0.0645 + 0.0884 + 0.0041, time: 10.322381]
2023-05-16 17:28:02.428: epoch 68:	0.02516993  	0.18444505  	0.10039695  
2023-05-16 17:28:02.429: Find a better model.
2023-05-16 17:28:12.731: [iter 69 : loss : 0.1552 = 0.0628 + 0.0882 + 0.0041, time: 10.298573]
2023-05-16 17:28:13.058: epoch 69:	0.02522638  	0.18485881  	0.10063980  
2023-05-16 17:28:13.058: Find a better model.
2023-05-16 17:28:22.825: [iter 70 : loss : 0.1535 = 0.0612 + 0.0881 + 0.0041, time: 9.766009]
2023-05-16 17:28:23.020: epoch 70:	0.02533223  	0.18579608  	0.10109648  
2023-05-16 17:28:23.020: Find a better model.
2023-05-16 17:28:31.514: [iter 71 : loss : 0.1520 = 0.0598 + 0.0880 + 0.0042, time: 8.493001]
2023-05-16 17:28:31.724: epoch 71:	0.02536046  	0.18618639  	0.10140146  
2023-05-16 17:28:31.724: Find a better model.
2023-05-16 17:28:41.041: [iter 72 : loss : 0.1516 = 0.0595 + 0.0878 + 0.0042, time: 9.315024]
2023-05-16 17:28:41.202: epoch 72:	0.02535340  	0.18606040  	0.10156959  
2023-05-16 17:28:51.381: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 10.172625]
2023-05-16 17:28:51.727: epoch 73:	0.02535340  	0.18612419  	0.10163915  
2023-05-16 17:29:02.043: [iter 74 : loss : 0.1490 = 0.0571 + 0.0876 + 0.0043, time: 10.312194]
2023-05-16 17:29:02.386: epoch 74:	0.02548748  	0.18697311  	0.10222536  
2023-05-16 17:29:02.386: Find a better model.
2023-05-16 17:29:11.034: [iter 75 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0044, time: 8.646176]
2023-05-16 17:29:11.226: epoch 75:	0.02553687  	0.18715902  	0.10240892  
2023-05-16 17:29:11.227: Find a better model.
2023-05-16 17:29:20.771: [iter 76 : loss : 0.1471 = 0.0554 + 0.0873 + 0.0044, time: 9.543010]
2023-05-16 17:29:20.931: epoch 76:	0.02550864  	0.18694642  	0.10251287  
2023-05-16 17:29:30.625: [iter 77 : loss : 0.1463 = 0.0546 + 0.0872 + 0.0044, time: 9.690606]
2023-05-16 17:29:30.911: epoch 77:	0.02550159  	0.18716231  	0.10282235  
2023-05-16 17:29:30.911: Find a better model.
2023-05-16 17:29:40.851: [iter 78 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0045, time: 9.935058]
2023-05-16 17:29:41.190: epoch 78:	0.02556509  	0.18761000  	0.10312415  
2023-05-16 17:29:41.190: Find a better model.
2023-05-16 17:29:51.435: [iter 79 : loss : 0.1442 = 0.0526 + 0.0870 + 0.0045, time: 10.240255]
2023-05-16 17:29:51.784: epoch 79:	0.02552275  	0.18726411  	0.10321852  
2023-05-16 17:30:02.033: [iter 80 : loss : 0.1433 = 0.0518 + 0.0869 + 0.0046, time: 10.246094]
2023-05-16 17:30:02.390: epoch 80:	0.02567094  	0.18844816  	0.10364060  
2023-05-16 17:30:02.390: Find a better model.
2023-05-16 17:30:12.422: [iter 81 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 10.029565]
2023-05-16 17:30:12.605: epoch 81:	0.02575562  	0.18907392  	0.10409214  
2023-05-16 17:30:12.605: Find a better model.
2023-05-16 17:30:21.284: [iter 82 : loss : 0.1419 = 0.0505 + 0.0867 + 0.0046, time: 8.678349]
2023-05-16 17:30:21.489: epoch 82:	0.02579796  	0.18921496  	0.10411536  
2023-05-16 17:30:21.489: Find a better model.
2023-05-16 17:30:31.020: [iter 83 : loss : 0.1407 = 0.0494 + 0.0866 + 0.0047, time: 9.529030]
2023-05-16 17:30:31.192: epoch 83:	0.02585441  	0.18962111  	0.10436395  
2023-05-16 17:30:31.192: Find a better model.
2023-05-16 17:30:41.321: [iter 84 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 10.126745]
2023-05-16 17:30:41.685: epoch 84:	0.02584030  	0.18976004  	0.10468209  
2023-05-16 17:30:41.686: Find a better model.
2023-05-16 17:30:51.852: [iter 85 : loss : 0.1397 = 0.0485 + 0.0864 + 0.0047, time: 10.163383]
2023-05-16 17:30:52.214: epoch 85:	0.02594615  	0.19037174  	0.10487634  
2023-05-16 17:30:52.214: Find a better model.
2023-05-16 17:31:00.886: [iter 86 : loss : 0.1395 = 0.0484 + 0.0863 + 0.0048, time: 8.669250]
2023-05-16 17:31:01.070: epoch 86:	0.02585441  	0.19004560  	0.10481870  
2023-05-16 17:31:10.387: [iter 87 : loss : 0.1370 = 0.0459 + 0.0862 + 0.0048, time: 9.316815]
2023-05-16 17:31:10.543: epoch 87:	0.02593204  	0.19075119  	0.10509221  
2023-05-16 17:31:10.543: Find a better model.
2023-05-16 17:31:20.444: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 9.900095]
2023-05-16 17:31:20.602: epoch 88:	0.02599554  	0.19120219  	0.10524157  
2023-05-16 17:31:20.602: Find a better model.
2023-05-16 17:31:30.671: [iter 89 : loss : 0.1360 = 0.0451 + 0.0860 + 0.0049, time: 10.066524]
2023-05-16 17:31:31.026: epoch 89:	0.02594615  	0.19073147  	0.10516610  
2023-05-16 17:31:41.387: [iter 90 : loss : 0.1365 = 0.0457 + 0.0859 + 0.0049, time: 10.359277]
2023-05-16 17:31:41.751: epoch 90:	0.02600260  	0.19134744  	0.10555352  
2023-05-16 17:31:41.751: Find a better model.
2023-05-16 17:31:51.932: [iter 91 : loss : 0.1353 = 0.0444 + 0.0858 + 0.0050, time: 10.176278]
2023-05-16 17:31:52.275: epoch 91:	0.02606611  	0.19166145  	0.10577614  
2023-05-16 17:31:52.275: Find a better model.
2023-05-16 17:32:02.119: [iter 92 : loss : 0.1342 = 0.0434 + 0.0858 + 0.0050, time: 9.843251]
2023-05-16 17:32:02.369: epoch 92:	0.02602377  	0.19117835  	0.10566286  
2023-05-16 17:32:10.645: [iter 93 : loss : 0.1345 = 0.0438 + 0.0857 + 0.0051, time: 8.274010]
2023-05-16 17:32:10.861: epoch 93:	0.02601671  	0.19139875  	0.10576901  
2023-05-16 17:32:20.725: [iter 94 : loss : 0.1322 = 0.0415 + 0.0856 + 0.0051, time: 9.862051]
2023-05-16 17:32:20.956: epoch 94:	0.02600966  	0.19149528  	0.10576390  
2023-05-16 17:32:31.211: [iter 95 : loss : 0.1317 = 0.0410 + 0.0855 + 0.0051, time: 10.251048]
2023-05-16 17:32:31.573: epoch 95:	0.02600966  	0.19176756  	0.10595791  
2023-05-16 17:32:31.573: Find a better model.
2023-05-16 17:32:41.835: [iter 96 : loss : 0.1319 = 0.0413 + 0.0854 + 0.0052, time: 10.259736]
2023-05-16 17:32:42.178: epoch 96:	0.02609433  	0.19233249  	0.10615417  
2023-05-16 17:32:42.178: Find a better model.
2023-05-16 17:32:50.936: [iter 97 : loss : 0.1302 = 0.0397 + 0.0853 + 0.0052, time: 8.757519]
2023-05-16 17:32:51.134: epoch 97:	0.02615784  	0.19241762  	0.10644941  
2023-05-16 17:32:51.134: Find a better model.
2023-05-16 17:33:00.556: [iter 98 : loss : 0.1310 = 0.0404 + 0.0853 + 0.0052, time: 9.419310]
2023-05-16 17:33:00.719: epoch 98:	0.02615078  	0.19273487  	0.10656764  
2023-05-16 17:33:00.720: Find a better model.
2023-05-16 17:33:10.632: [iter 99 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0053, time: 9.910299]
2023-05-16 17:33:10.849: epoch 99:	0.02615784  	0.19297455  	0.10675341  
2023-05-16 17:33:10.849: Find a better model.
2023-05-16 17:33:20.631: [iter 100 : loss : 0.1290 = 0.0385 + 0.0851 + 0.0053, time: 9.766934]
2023-05-16 17:33:20.970: epoch 100:	0.02620724  	0.19310710  	0.10676906  
2023-05-16 17:33:20.970: Find a better model.
2023-05-16 17:33:31.275: [iter 101 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 10.303210]
2023-05-16 17:33:31.610: epoch 101:	0.02624252  	0.19334260  	0.10703637  
2023-05-16 17:33:31.610: Find a better model.
2023-05-16 17:33:41.951: [iter 102 : loss : 0.1277 = 0.0373 + 0.0850 + 0.0054, time: 10.337879]
2023-05-16 17:33:42.301: epoch 102:	0.02622841  	0.19333543  	0.10695475  
2023-05-16 17:33:52.348: [iter 103 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 10.045077]
2023-05-16 17:33:52.510: epoch 103:	0.02631309  	0.19368634  	0.10729541  
2023-05-16 17:33:52.511: Find a better model.
2023-05-16 17:34:01.811: [iter 104 : loss : 0.1279 = 0.0376 + 0.0849 + 0.0055, time: 9.299006]
2023-05-16 17:34:02.021: epoch 104:	0.02635542  	0.19383192  	0.10738356  
2023-05-16 17:34:02.022: Find a better model.
2023-05-16 17:34:10.929: [iter 105 : loss : 0.1274 = 0.0371 + 0.0848 + 0.0055, time: 8.905930]
2023-05-16 17:34:11.086: epoch 105:	0.02636954  	0.19392465  	0.10747252  
2023-05-16 17:34:11.086: Find a better model.
2023-05-16 17:34:21.326: [iter 106 : loss : 0.1267 = 0.0364 + 0.0847 + 0.0055, time: 10.236628]
2023-05-16 17:34:21.652: epoch 106:	0.02636955  	0.19385824  	0.10753588  
2023-05-16 17:34:31.959: [iter 107 : loss : 0.1257 = 0.0355 + 0.0847 + 0.0055, time: 10.305734]
2023-05-16 17:34:32.320: epoch 107:	0.02638366  	0.19377309  	0.10764780  
2023-05-16 17:34:40.872: [iter 108 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0056, time: 8.549013]
2023-05-16 17:34:41.054: epoch 108:	0.02643305  	0.19386035  	0.10774820  
2023-05-16 17:34:49.458: [iter 109 : loss : 0.1243 = 0.0341 + 0.0845 + 0.0056, time: 8.402010]
2023-05-16 17:34:49.629: epoch 109:	0.02641894  	0.19420648  	0.10793779  
2023-05-16 17:34:49.629: Find a better model.
2023-05-16 17:34:59.486: [iter 110 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0056, time: 9.853992]
2023-05-16 17:34:59.663: epoch 110:	0.02636955  	0.19392313  	0.10800844  
2023-05-16 17:35:09.757: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 10.092304]
2023-05-16 17:35:10.117: epoch 111:	0.02644011  	0.19454400  	0.10836856  
2023-05-16 17:35:10.118: Find a better model.
2023-05-16 17:35:20.325: [iter 112 : loss : 0.1232 = 0.0332 + 0.0844 + 0.0057, time: 10.204554]
2023-05-16 17:35:20.658: epoch 112:	0.02646127  	0.19447401  	0.10821100  
2023-05-16 17:35:30.675: [iter 113 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0058, time: 10.013086]
2023-05-16 17:35:31.260: epoch 113:	0.02641894  	0.19444665  	0.10812576  
2023-05-16 17:35:41.271: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 10.005991]
2023-05-16 17:35:41.435: epoch 114:	0.02650362  	0.19498837  	0.10844857  
2023-05-16 17:35:41.435: Find a better model.
2023-05-16 17:35:51.338: [iter 115 : loss : 0.1219 = 0.0319 + 0.0842 + 0.0058, time: 9.901261]
2023-05-16 17:35:51.860: epoch 115:	0.02650362  	0.19492191  	0.10843752  
2023-05-16 17:36:01.778: [iter 116 : loss : 0.1212 = 0.0312 + 0.0842 + 0.0058, time: 9.898038]
2023-05-16 17:36:02.130: epoch 116:	0.02650362  	0.19465765  	0.10828391  
2023-05-16 17:36:12.524: [iter 117 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 10.387565]
2023-05-16 17:36:12.872: epoch 117:	0.02660240  	0.19539610  	0.10860419  
2023-05-16 17:36:12.872: Find a better model.
2023-05-16 17:36:23.148: [iter 118 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 10.270658]
2023-05-16 17:36:23.501: epoch 118:	0.02665886  	0.19592889  	0.10874877  
2023-05-16 17:36:23.502: Find a better model.
2023-05-16 17:36:33.198: [iter 119 : loss : 0.1201 = 0.0302 + 0.0840 + 0.0059, time: 9.694999]
2023-05-16 17:36:33.461: epoch 119:	0.02656712  	0.19537272  	0.10867923  
2023-05-16 17:36:41.747: [iter 120 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0060, time: 8.283006]
2023-05-16 17:36:41.959: epoch 120:	0.02659535  	0.19556713  	0.10884417  
2023-05-16 17:36:51.668: [iter 121 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 9.707027]
2023-05-16 17:36:51.845: epoch 121:	0.02656006  	0.19542031  	0.10878462  
2023-05-16 17:37:02.193: [iter 122 : loss : 0.1196 = 0.0297 + 0.0838 + 0.0060, time: 10.336155]
2023-05-16 17:37:02.540: epoch 122:	0.02654595  	0.19535910  	0.10879020  
2023-05-16 17:37:12.719: [iter 123 : loss : 0.1194 = 0.0295 + 0.0838 + 0.0061, time: 10.170832]
2023-05-16 17:37:13.076: epoch 123:	0.02652478  	0.19496046  	0.10858493  
2023-05-16 17:37:21.973: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 8.896648]
2023-05-16 17:37:22.161: epoch 124:	0.02653184  	0.19472983  	0.10847574  
2023-05-16 17:37:31.439: [iter 125 : loss : 0.1178 = 0.0280 + 0.0837 + 0.0061, time: 9.275187]
2023-05-16 17:37:31.593: epoch 125:	0.02665886  	0.19573411  	0.10899096  
2023-05-16 17:37:41.526: [iter 126 : loss : 0.1180 = 0.0282 + 0.0836 + 0.0062, time: 9.932647]
2023-05-16 17:37:41.694: epoch 126:	0.02661652  	0.19559862  	0.10895202  
2023-05-16 17:37:51.640: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 9.939760]
2023-05-16 17:37:51.969: epoch 127:	0.02663768  	0.19518091  	0.10885479  
2023-05-16 17:38:02.257: [iter 128 : loss : 0.1182 = 0.0284 + 0.0835 + 0.0062, time: 10.287442]
2023-05-16 17:38:02.616: epoch 128:	0.02669413  	0.19535886  	0.10895074  
2023-05-16 17:38:12.813: [iter 129 : loss : 0.1172 = 0.0275 + 0.0835 + 0.0063, time: 10.194839]
2023-05-16 17:38:13.172: epoch 129:	0.02670825  	0.19549847  	0.10909219  
2023-05-16 17:38:23.086: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 9.912956]
2023-05-16 17:38:23.251: epoch 130:	0.02672942  	0.19578162  	0.10905114  
2023-05-16 17:38:31.695: [iter 131 : loss : 0.1161 = 0.0264 + 0.0834 + 0.0063, time: 8.441992]
2023-05-16 17:38:31.909: epoch 131:	0.02673647  	0.19588244  	0.10913666  
2023-05-16 17:38:41.397: [iter 132 : loss : 0.1165 = 0.0268 + 0.0834 + 0.0063, time: 9.485215]
2023-05-16 17:38:41.566: epoch 132:	0.02676470  	0.19602099  	0.10914925  
2023-05-16 17:38:41.567: Find a better model.
2023-05-16 17:38:51.815: [iter 133 : loss : 0.1152 = 0.0256 + 0.0833 + 0.0064, time: 10.244047]
2023-05-16 17:38:52.169: epoch 133:	0.02676471  	0.19583228  	0.10921024  
2023-05-16 17:39:02.390: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 10.220875]
2023-05-16 17:39:02.749: epoch 134:	0.02677176  	0.19593264  	0.10931086  
2023-05-16 17:39:11.370: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 8.619162]
2023-05-16 17:39:11.553: epoch 135:	0.02670120  	0.19529429  	0.10892890  
2023-05-16 17:39:21.002: [iter 136 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0065, time: 9.446999]
2023-05-16 17:39:21.169: epoch 136:	0.02665180  	0.19526561  	0.10903178  
2023-05-16 17:39:30.866: [iter 137 : loss : 0.1149 = 0.0252 + 0.0832 + 0.0065, time: 9.695457]
2023-05-16 17:39:31.021: epoch 137:	0.02663063  	0.19479427  	0.10883345  
2023-05-16 17:39:41.024: [iter 138 : loss : 0.1146 = 0.0249 + 0.0831 + 0.0065, time: 9.999911]
2023-05-16 17:39:41.381: epoch 138:	0.02669414  	0.19528404  	0.10896034  
2023-05-16 17:39:51.522: [iter 139 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0066, time: 10.140144]
2023-05-16 17:39:51.874: epoch 139:	0.02668708  	0.19543555  	0.10915547  
2023-05-16 17:40:02.026: [iter 140 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 10.143686]
2023-05-16 17:40:02.358: epoch 140:	0.02665179  	0.19512130  	0.10907806  
2023-05-16 17:40:11.988: [iter 141 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0066, time: 9.629238]
2023-05-16 17:40:12.146: epoch 141:	0.02664474  	0.19519635  	0.10909745  
2023-05-16 17:40:20.040: [iter 142 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0066, time: 7.893035]
2023-05-16 17:40:20.251: epoch 142:	0.02661652  	0.19507208  	0.10918073  
2023-05-16 17:40:29.938: [iter 143 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0067, time: 9.685158]
2023-05-16 17:40:30.205: epoch 143:	0.02664474  	0.19495477  	0.10915035  
2023-05-16 17:40:40.388: [iter 144 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 10.177910]
2023-05-16 17:40:40.721: epoch 144:	0.02663063  	0.19490544  	0.10908276  
2023-05-16 17:40:50.908: [iter 145 : loss : 0.1127 = 0.0231 + 0.0829 + 0.0067, time: 10.184908]
2023-05-16 17:40:51.251: epoch 145:	0.02660946  	0.19496441  	0.10932384  
2023-05-16 17:41:01.051: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 9.796007]
2023-05-16 17:41:01.406: epoch 146:	0.02667297  	0.19526085  	0.10939289  
2023-05-16 17:41:10.967: [iter 147 : loss : 0.1128 = 0.0232 + 0.0828 + 0.0068, time: 9.559002]
2023-05-16 17:41:11.122: epoch 147:	0.02668709  	0.19567627  	0.10957261  
2023-05-16 17:41:20.072: [iter 148 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 8.949126]
2023-05-16 17:41:20.240: epoch 148:	0.02671531  	0.19558342  	0.10961617  
2023-05-16 17:41:28.948: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 8.707007]
2023-05-16 17:41:29.115: epoch 149:	0.02672943  	0.19575301  	0.10959695  
2023-05-16 17:41:39.224: [iter 150 : loss : 0.1113 = 0.0218 + 0.0827 + 0.0069, time: 10.106161]
2023-05-16 17:41:39.577: epoch 150:	0.02670826  	0.19567771  	0.10951650  
2023-05-16 17:41:49.520: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 9.940278]
2023-05-16 17:41:49.853: epoch 151:	0.02665181  	0.19523631  	0.10934737  
2023-05-16 17:41:58.444: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 8.590369]
2023-05-16 17:41:58.910: epoch 152:	0.02670826  	0.19575529  	0.10922831  
2023-05-16 17:42:07.531: [iter 153 : loss : 0.1102 = 0.0206 + 0.0826 + 0.0069, time: 8.599944]
2023-05-16 17:42:07.697: epoch 153:	0.02667297  	0.19510446  	0.10912810  
2023-05-16 17:42:17.957: [iter 154 : loss : 0.1105 = 0.0210 + 0.0826 + 0.0070, time: 10.259510]
2023-05-16 17:42:18.110: epoch 154:	0.02668709  	0.19533196  	0.10919055  
2023-05-16 17:42:28.395: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 10.280101]
2023-05-16 17:42:28.752: epoch 155:	0.02664475  	0.19507447  	0.10896934  
2023-05-16 17:42:38.945: [iter 156 : loss : 0.1107 = 0.0212 + 0.0825 + 0.0070, time: 10.189116]
2023-05-16 17:42:39.292: epoch 156:	0.02663769  	0.19500084  	0.10893173  
2023-05-16 17:42:49.073: [iter 157 : loss : 0.1104 = 0.0209 + 0.0824 + 0.0070, time: 9.773437]
2023-05-16 17:42:49.376: epoch 157:	0.02666592  	0.19500977  	0.10904825  
2023-05-16 17:42:49.376: Early stopping is trigger at epoch: 157
2023-05-16 17:42:49.376: best_result@epoch 132:

2023-05-16 17:42:49.376: 		0.0268      	0.1960      	0.1091      
2023-05-16 20:05:08.596: my pid: 5592
2023-05-16 20:05:08.596: model: model.general_recommender.SGL
2023-05-16 20:05:08.596: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 20:05:08.596: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 20:05:13.037: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 20:05:23.339: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.300138]
2023-05-16 20:05:23.624: epoch 1:	0.00148180  	0.01001598  	0.00493434  
2023-05-16 20:05:23.624: Find a better model.
2023-05-16 20:05:33.592: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.964412]
2023-05-16 20:05:33.827: epoch 2:	0.00267429  	0.01982772  	0.00966074  
2023-05-16 20:05:33.827: Find a better model.
2023-05-16 20:05:45.272: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 11.442471]
2023-05-16 20:05:45.674: epoch 3:	0.00459354  	0.03394277  	0.01645423  
2023-05-16 20:05:45.674: Find a better model.
2023-05-16 20:05:56.805: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 11.129410]
2023-05-16 20:05:57.155: epoch 4:	0.00767705  	0.05626488  	0.02689254  
2023-05-16 20:05:57.155: Find a better model.
2023-05-16 20:06:08.095: [iter 5 : loss : 0.7698 = 0.6911 + 0.0787 + 0.0000, time: 10.938192]
2023-05-16 20:06:08.300: epoch 5:	0.01102879  	0.08073992  	0.03866838  
2023-05-16 20:06:08.301: Find a better model.
2023-05-16 20:06:17.904: [iter 6 : loss : 0.7679 = 0.6888 + 0.0791 + 0.0000, time: 9.602029]
2023-05-16 20:06:18.215: epoch 6:	0.01436650  	0.10389126  	0.05076177  
2023-05-16 20:06:18.215: Find a better model.
2023-05-16 20:06:27.550: [iter 7 : loss : 0.7627 = 0.6829 + 0.0798 + 0.0000, time: 9.332321]
2023-05-16 20:06:27.703: epoch 7:	0.01737252  	0.12532000  	0.06209661  
2023-05-16 20:06:27.703: Find a better model.
2023-05-16 20:06:38.171: [iter 8 : loss : 0.7498 = 0.6683 + 0.0814 + 0.0001, time: 10.462429]
2023-05-16 20:06:38.508: epoch 8:	0.01879087  	0.13747172  	0.06876895  
2023-05-16 20:06:38.508: Find a better model.
2023-05-16 20:06:49.080: [iter 9 : loss : 0.7194 = 0.6345 + 0.0848 + 0.0001, time: 10.569617]
2023-05-16 20:06:49.367: epoch 9:	0.01887555  	0.13819470  	0.06908761  
2023-05-16 20:06:49.367: Find a better model.
2023-05-16 20:06:58.528: [iter 10 : loss : 0.6633 = 0.5730 + 0.0901 + 0.0002, time: 9.158966]
2023-05-16 20:06:58.775: epoch 10:	0.01853684  	0.13712089  	0.06834024  
2023-05-16 20:07:07.340: [iter 11 : loss : 0.5880 = 0.4920 + 0.0956 + 0.0004, time: 8.562022]
2023-05-16 20:07:07.501: epoch 11:	0.01841687  	0.13583219  	0.06754433  
2023-05-16 20:07:17.735: [iter 12 : loss : 0.5160 = 0.4160 + 0.0995 + 0.0005, time: 10.231700]
2023-05-16 20:07:17.922: epoch 12:	0.01841688  	0.13597949  	0.06803489  
2023-05-16 20:07:28.150: [iter 13 : loss : 0.4619 = 0.3596 + 0.1016 + 0.0007, time: 10.224407]
2023-05-16 20:07:28.472: epoch 13:	0.01840982  	0.13620913  	0.06836917  
2023-05-16 20:07:38.671: [iter 14 : loss : 0.4213 = 0.3179 + 0.1026 + 0.0008, time: 10.196039]
2023-05-16 20:07:39.026: epoch 14:	0.01861445  	0.13754790  	0.06925863  
2023-05-16 20:07:48.622: [iter 15 : loss : 0.3934 = 0.2894 + 0.1031 + 0.0010, time: 9.593002]
2023-05-16 20:07:48.808: epoch 15:	0.01875558  	0.13894476  	0.06995910  
2023-05-16 20:07:48.808: Find a better model.
2023-05-16 20:07:57.962: [iter 16 : loss : 0.3701 = 0.2660 + 0.1031 + 0.0011, time: 9.152256]
2023-05-16 20:07:58.177: epoch 16:	0.01891083  	0.13991596  	0.07068432  
2023-05-16 20:07:58.177: Find a better model.
2023-05-16 20:08:08.258: [iter 17 : loss : 0.3532 = 0.2492 + 0.1029 + 0.0012, time: 10.078991]
2023-05-16 20:08:08.418: epoch 17:	0.01926366  	0.14210857  	0.07183787  
2023-05-16 20:08:08.418: Find a better model.
2023-05-16 20:08:18.231: [iter 18 : loss : 0.3377 = 0.2337 + 0.1027 + 0.0013, time: 9.809494]
2023-05-16 20:08:18.579: epoch 18:	0.01947536  	0.14339522  	0.07259482  
2023-05-16 20:08:18.579: Find a better model.
2023-05-16 20:08:28.934: [iter 19 : loss : 0.3233 = 0.2196 + 0.1023 + 0.0014, time: 10.345312]
2023-05-16 20:08:29.267: epoch 19:	0.01962355  	0.14419946  	0.07328554  
2023-05-16 20:08:29.267: Find a better model.
2023-05-16 20:08:38.836: [iter 20 : loss : 0.3135 = 0.2101 + 0.1019 + 0.0015, time: 9.563000]
2023-05-16 20:08:39.147: epoch 20:	0.01991992  	0.14639582  	0.07425461  
2023-05-16 20:08:39.147: Find a better model.
2023-05-16 20:08:48.530: [iter 21 : loss : 0.3036 = 0.2006 + 0.1015 + 0.0016, time: 9.382441]
2023-05-16 20:08:48.701: epoch 21:	0.02011045  	0.14764240  	0.07499592  
2023-05-16 20:08:48.701: Find a better model.
2023-05-16 20:08:58.342: [iter 22 : loss : 0.2954 = 0.1927 + 0.1011 + 0.0016, time: 9.638117]
2023-05-16 20:08:58.500: epoch 22:	0.02030098  	0.14856574  	0.07567047  
2023-05-16 20:08:58.500: Find a better model.
2023-05-16 20:09:08.603: [iter 23 : loss : 0.2869 = 0.1845 + 0.1007 + 0.0017, time: 10.096022]
2023-05-16 20:09:08.907: epoch 23:	0.02045621  	0.14970204  	0.07651100  
2023-05-16 20:09:08.907: Find a better model.
2023-05-16 20:09:19.177: [iter 24 : loss : 0.2803 = 0.1784 + 0.1001 + 0.0018, time: 10.268113]
2023-05-16 20:09:19.514: epoch 24:	0.02070319  	0.15150437  	0.07734372  
2023-05-16 20:09:19.515: Find a better model.
2023-05-16 20:09:29.475: [iter 25 : loss : 0.2736 = 0.1720 + 0.0997 + 0.0019, time: 9.956009]
2023-05-16 20:09:30.147: epoch 25:	0.02087255  	0.15314277  	0.07797252  
2023-05-16 20:09:30.147: Find a better model.
2023-05-16 20:09:39.923: [iter 26 : loss : 0.2698 = 0.1685 + 0.0993 + 0.0019, time: 9.772504]
2023-05-16 20:09:40.132: epoch 26:	0.02109835  	0.15462612  	0.07900006  
2023-05-16 20:09:40.132: Find a better model.
2023-05-16 20:09:49.699: [iter 27 : loss : 0.2621 = 0.1612 + 0.0989 + 0.0020, time: 9.565017]
2023-05-16 20:09:49.866: epoch 27:	0.02126772  	0.15584095  	0.07973134  
2023-05-16 20:09:49.866: Find a better model.
2023-05-16 20:09:59.942: [iter 28 : loss : 0.2570 = 0.1565 + 0.0984 + 0.0021, time: 10.074169]
2023-05-16 20:10:00.250: epoch 28:	0.02137357  	0.15666929  	0.08032143  
2023-05-16 20:10:00.250: Find a better model.
2023-05-16 20:10:10.546: [iter 29 : loss : 0.2526 = 0.1525 + 0.0981 + 0.0021, time: 10.292395]
2023-05-16 20:10:10.897: epoch 29:	0.02147942  	0.15727787  	0.08094110  
2023-05-16 20:10:10.897: Find a better model.
2023-05-16 20:10:20.935: [iter 30 : loss : 0.2462 = 0.1464 + 0.0976 + 0.0022, time: 10.026991]
2023-05-16 20:10:21.412: epoch 30:	0.02162761  	0.15871702  	0.08170622  
2023-05-16 20:10:21.413: Find a better model.
2023-05-16 20:10:31.379: [iter 31 : loss : 0.2424 = 0.1429 + 0.0973 + 0.0022, time: 9.925505]
2023-05-16 20:10:31.529: epoch 31:	0.02182519  	0.16031143  	0.08244866  
2023-05-16 20:10:31.529: Find a better model.
2023-05-16 20:10:40.452: [iter 32 : loss : 0.2367 = 0.1375 + 0.0968 + 0.0023, time: 8.921992]
2023-05-16 20:10:40.620: epoch 32:	0.02207217  	0.16268332  	0.08341004  
2023-05-16 20:10:40.620: Find a better model.
2023-05-16 20:10:49.822: [iter 33 : loss : 0.2340 = 0.1352 + 0.0964 + 0.0024, time: 9.198214]
2023-05-16 20:10:50.208: epoch 33:	0.02225563  	0.16370362  	0.08417200  
2023-05-16 20:10:50.208: Find a better model.
2023-05-16 20:11:00.543: [iter 34 : loss : 0.2298 = 0.1313 + 0.0961 + 0.0024, time: 10.332024]
2023-05-16 20:11:00.869: epoch 34:	0.02246732  	0.16516306  	0.08500803  
2023-05-16 20:11:00.869: Find a better model.
2023-05-16 20:11:10.988: [iter 35 : loss : 0.2264 = 0.1281 + 0.0958 + 0.0025, time: 10.116563]
2023-05-16 20:11:11.294: epoch 35:	0.02254494  	0.16587810  	0.08564103  
2023-05-16 20:11:11.294: Find a better model.
2023-05-16 20:11:20.833: [iter 36 : loss : 0.2229 = 0.1249 + 0.0954 + 0.0025, time: 9.536103]
2023-05-16 20:11:21.236: epoch 36:	0.02267902  	0.16707028  	0.08623792  
2023-05-16 20:11:21.236: Find a better model.
2023-05-16 20:11:30.053: [iter 37 : loss : 0.2189 = 0.1212 + 0.0951 + 0.0026, time: 8.816182]
2023-05-16 20:11:30.220: epoch 37:	0.02265079  	0.16688402  	0.08653890  
2023-05-16 20:11:39.781: [iter 38 : loss : 0.2172 = 0.1198 + 0.0948 + 0.0026, time: 9.558025]
2023-05-16 20:11:40.140: epoch 38:	0.02284131  	0.16805448  	0.08721561  
2023-05-16 20:11:40.140: Find a better model.
2023-05-16 20:11:50.458: [iter 39 : loss : 0.2130 = 0.1158 + 0.0945 + 0.0027, time: 10.315016]
2023-05-16 20:11:50.798: epoch 39:	0.02296833  	0.16927822  	0.08782256  
2023-05-16 20:11:50.798: Find a better model.
2023-05-16 20:12:00.865: [iter 40 : loss : 0.2096 = 0.1126 + 0.0942 + 0.0028, time: 10.058354]
2023-05-16 20:12:01.492: epoch 40:	0.02306712  	0.17001189  	0.08827823  
2023-05-16 20:12:01.492: Find a better model.
2023-05-16 20:12:11.126: [iter 41 : loss : 0.2078 = 0.1111 + 0.0939 + 0.0028, time: 9.633004]
2023-05-16 20:12:11.286: epoch 41:	0.02325764  	0.17116114  	0.08904269  
2023-05-16 20:12:11.286: Find a better model.
2023-05-16 20:12:20.303: [iter 42 : loss : 0.2054 = 0.1090 + 0.0936 + 0.0029, time: 9.014003]
2023-05-16 20:12:20.467: epoch 42:	0.02334938  	0.17210035  	0.08964065  
2023-05-16 20:12:20.467: Find a better model.
2023-05-16 20:12:31.520: [iter 43 : loss : 0.2017 = 0.1055 + 0.0933 + 0.0029, time: 11.051547]
2023-05-16 20:12:31.773: epoch 43:	0.02358931  	0.17415948  	0.09061866  
2023-05-16 20:12:31.773: Find a better model.
2023-05-16 20:12:42.079: [iter 44 : loss : 0.1981 = 0.1022 + 0.0930 + 0.0030, time: 10.304044]
2023-05-16 20:12:42.417: epoch 44:	0.02372338  	0.17507689  	0.09137529  
2023-05-16 20:12:42.417: Find a better model.
2023-05-16 20:12:51.943: [iter 45 : loss : 0.1960 = 0.1002 + 0.0928 + 0.0030, time: 9.516000]
2023-05-16 20:12:52.204: epoch 45:	0.02377277  	0.17553230  	0.09186433  
2023-05-16 20:12:52.204: Find a better model.
2023-05-16 20:13:01.505: [iter 46 : loss : 0.1935 = 0.0980 + 0.0925 + 0.0031, time: 9.299011]
2023-05-16 20:13:01.667: epoch 46:	0.02387156  	0.17575829  	0.09216487  
2023-05-16 20:13:01.668: Find a better model.
2023-05-16 20:13:10.818: [iter 47 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 9.148003]
2023-05-16 20:13:10.982: epoch 47:	0.02389979  	0.17577726  	0.09250545  
2023-05-16 20:13:10.982: Find a better model.
2023-05-16 20:13:21.375: [iter 48 : loss : 0.1888 = 0.0936 + 0.0920 + 0.0032, time: 10.386945]
2023-05-16 20:13:21.666: epoch 48:	0.02400563  	0.17625709  	0.09284484  
2023-05-16 20:13:21.666: Find a better model.
2023-05-16 20:13:32.090: [iter 49 : loss : 0.1857 = 0.0907 + 0.0918 + 0.0032, time: 10.420011]
2023-05-16 20:13:32.442: epoch 49:	0.02403386  	0.17644912  	0.09332883  
2023-05-16 20:13:32.442: Find a better model.
2023-05-16 20:13:42.114: [iter 50 : loss : 0.1848 = 0.0900 + 0.0916 + 0.0033, time: 9.668011]
2023-05-16 20:13:42.420: epoch 50:	0.02417498  	0.17717314  	0.09372301  
2023-05-16 20:13:42.421: Find a better model.
2023-05-16 20:13:51.331: [iter 51 : loss : 0.1815 = 0.0869 + 0.0914 + 0.0033, time: 8.907196]
2023-05-16 20:13:51.497: epoch 51:	0.02423143  	0.17793119  	0.09410822  
2023-05-16 20:13:51.497: Find a better model.
2023-05-16 20:14:00.556: [iter 52 : loss : 0.1816 = 0.0870 + 0.0912 + 0.0034, time: 9.057002]
2023-05-16 20:14:00.733: epoch 52:	0.02431611  	0.17891167  	0.09467860  
2023-05-16 20:14:00.734: Find a better model.
2023-05-16 20:14:10.845: [iter 53 : loss : 0.1799 = 0.0856 + 0.0909 + 0.0034, time: 10.108023]
2023-05-16 20:14:11.151: epoch 53:	0.02447841  	0.17989895  	0.09539387  
2023-05-16 20:14:11.151: Find a better model.
2023-05-16 20:14:21.339: [iter 54 : loss : 0.1775 = 0.0833 + 0.0907 + 0.0034, time: 10.185026]
2023-05-16 20:14:21.691: epoch 54:	0.02452780  	0.18016860  	0.09566268  
2023-05-16 20:14:21.691: Find a better model.
2023-05-16 20:14:31.810: [iter 55 : loss : 0.1755 = 0.0814 + 0.0906 + 0.0035, time: 10.117124]
2023-05-16 20:14:32.124: epoch 55:	0.02465482  	0.18103980  	0.09620140  
2023-05-16 20:14:32.124: Find a better model.
2023-05-16 20:14:41.431: [iter 56 : loss : 0.1739 = 0.0800 + 0.0904 + 0.0035, time: 9.306049]
2023-05-16 20:14:41.608: epoch 56:	0.02481712  	0.18226950  	0.09680215  
2023-05-16 20:14:41.608: Find a better model.
2023-05-16 20:14:50.190: [iter 57 : loss : 0.1719 = 0.0781 + 0.0902 + 0.0036, time: 8.581003]
2023-05-16 20:14:50.352: epoch 57:	0.02495119  	0.18319190  	0.09720770  
2023-05-16 20:14:50.352: Find a better model.
2023-05-16 20:15:00.453: [iter 58 : loss : 0.1700 = 0.0764 + 0.0900 + 0.0036, time: 10.099040]
2023-05-16 20:15:00.739: epoch 58:	0.02499353  	0.18342189  	0.09757623  
2023-05-16 20:15:00.739: Find a better model.
2023-05-16 20:15:11.015: [iter 59 : loss : 0.1687 = 0.0753 + 0.0898 + 0.0037, time: 10.273473]
2023-05-16 20:15:11.309: epoch 59:	0.02497941  	0.18319954  	0.09793723  
2023-05-16 20:15:21.441: [iter 60 : loss : 0.1674 = 0.0740 + 0.0896 + 0.0037, time: 10.130059]
2023-05-16 20:15:21.623: epoch 60:	0.02500764  	0.18337083  	0.09820099  
2023-05-16 20:15:31.652: [iter 61 : loss : 0.1660 = 0.0727 + 0.0895 + 0.0038, time: 10.027014]
2023-05-16 20:15:31.821: epoch 61:	0.02502176  	0.18336663  	0.09833062  
2023-05-16 20:15:42.098: [iter 62 : loss : 0.1645 = 0.0714 + 0.0893 + 0.0038, time: 10.274255]
2023-05-16 20:15:42.394: epoch 62:	0.02498647  	0.18289828  	0.09836259  
2023-05-16 20:15:52.702: [iter 63 : loss : 0.1630 = 0.0701 + 0.0891 + 0.0038, time: 10.306294]
2023-05-16 20:15:53.060: epoch 63:	0.02504998  	0.18355171  	0.09862389  
2023-05-16 20:15:53.060: Find a better model.
2023-05-16 20:16:03.797: [iter 64 : loss : 0.1620 = 0.0692 + 0.0890 + 0.0039, time: 10.733528]
2023-05-16 20:16:04.134: epoch 64:	0.02520522  	0.18434656  	0.09914103  
2023-05-16 20:16:04.134: Find a better model.
2023-05-16 20:16:14.019: [iter 65 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 9.884018]
2023-05-16 20:16:14.187: epoch 65:	0.02527578  	0.18499340  	0.09947336  
2023-05-16 20:16:14.187: Find a better model.
2023-05-16 20:16:22.385: [iter 66 : loss : 0.1592 = 0.0666 + 0.0887 + 0.0040, time: 8.197001]
2023-05-16 20:16:22.551: epoch 66:	0.02529695  	0.18504433  	0.09956615  
2023-05-16 20:16:22.551: Find a better model.
2023-05-16 20:16:32.713: [iter 67 : loss : 0.1575 = 0.0650 + 0.0885 + 0.0040, time: 10.161026]
2023-05-16 20:16:33.025: epoch 67:	0.02540279  	0.18573777  	0.09973954  
2023-05-16 20:16:33.025: Find a better model.
2023-05-16 20:16:43.036: [iter 68 : loss : 0.1573 = 0.0649 + 0.0883 + 0.0041, time: 10.010007]
2023-05-16 20:16:43.352: epoch 68:	0.02536046  	0.18580593  	0.10001236  
2023-05-16 20:16:43.352: Find a better model.
2023-05-16 20:16:51.398: [iter 69 : loss : 0.1552 = 0.0628 + 0.0883 + 0.0041, time: 8.044162]
2023-05-16 20:16:51.608: epoch 69:	0.02546630  	0.18682677  	0.10041051  
2023-05-16 20:16:51.608: Find a better model.
2023-05-16 20:17:01.343: [iter 70 : loss : 0.1536 = 0.0613 + 0.0881 + 0.0041, time: 9.732325]
2023-05-16 20:17:01.505: epoch 70:	0.02545924  	0.18655890  	0.10038097  
2023-05-16 20:17:11.876: [iter 71 : loss : 0.1521 = 0.0599 + 0.0880 + 0.0042, time: 10.367504]
2023-05-16 20:17:12.255: epoch 71:	0.02549453  	0.18714395  	0.10069103  
2023-05-16 20:17:12.255: Find a better model.
2023-05-16 20:17:22.266: [iter 72 : loss : 0.1521 = 0.0600 + 0.0879 + 0.0042, time: 10.008031]
2023-05-16 20:17:22.751: epoch 72:	0.02552981  	0.18757460  	0.10098371  
2023-05-16 20:17:22.751: Find a better model.
2023-05-16 20:17:32.266: [iter 73 : loss : 0.1503 = 0.0584 + 0.0877 + 0.0043, time: 9.513017]
2023-05-16 20:17:32.568: epoch 73:	0.02564271  	0.18826306  	0.10129761  
2023-05-16 20:17:32.568: Find a better model.
2023-05-16 20:17:42.208: [iter 74 : loss : 0.1493 = 0.0574 + 0.0876 + 0.0043, time: 9.638298]
2023-05-16 20:17:42.368: epoch 74:	0.02565683  	0.18873808  	0.10161415  
2023-05-16 20:17:42.368: Find a better model.
2023-05-16 20:17:51.808: [iter 75 : loss : 0.1488 = 0.0569 + 0.0875 + 0.0044, time: 9.437851]
2023-05-16 20:17:52.260: epoch 75:	0.02560038  	0.18788025  	0.10150595  
2023-05-16 20:18:00.902: [iter 76 : loss : 0.1473 = 0.0556 + 0.0874 + 0.0044, time: 8.633992]
2023-05-16 20:18:01.073: epoch 76:	0.02562155  	0.18809567  	0.10168420  
2023-05-16 20:18:10.932: [iter 77 : loss : 0.1464 = 0.0548 + 0.0872 + 0.0044, time: 9.853374]
2023-05-16 20:18:11.258: epoch 77:	0.02570623  	0.18883105  	0.10200966  
2023-05-16 20:18:11.258: Find a better model.
2023-05-16 20:18:20.229: [iter 78 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0045, time: 8.970010]
2023-05-16 20:18:20.409: epoch 78:	0.02563565  	0.18864694  	0.10205562  
2023-05-16 20:18:30.093: [iter 79 : loss : 0.1443 = 0.0527 + 0.0870 + 0.0045, time: 9.678010]
2023-05-16 20:18:30.372: epoch 79:	0.02569211  	0.18882255  	0.10223835  
2023-05-16 20:18:40.299: [iter 80 : loss : 0.1438 = 0.0523 + 0.0869 + 0.0046, time: 9.925353]
2023-05-16 20:18:40.477: epoch 80:	0.02567799  	0.18879800  	0.10241517  
2023-05-16 20:18:50.952: [iter 81 : loss : 0.1433 = 0.0519 + 0.0868 + 0.0046, time: 10.472933]
2023-05-16 20:18:51.260: epoch 81:	0.02577678  	0.18943480  	0.10265672  
2023-05-16 20:18:51.260: Find a better model.
2023-05-16 20:19:01.864: [iter 82 : loss : 0.1418 = 0.0505 + 0.0867 + 0.0046, time: 10.602004]
2023-05-16 20:19:02.152: epoch 82:	0.02579795  	0.18999733  	0.10304522  
2023-05-16 20:19:02.152: Find a better model.
2023-05-16 20:19:12.438: [iter 83 : loss : 0.1408 = 0.0495 + 0.0866 + 0.0047, time: 10.285152]
2023-05-16 20:19:12.702: epoch 83:	0.02588969  	0.19075458  	0.10353978  
2023-05-16 20:19:12.702: Find a better model.
2023-05-16 20:19:21.905: [iter 84 : loss : 0.1407 = 0.0495 + 0.0864 + 0.0047, time: 9.200008]
2023-05-16 20:19:22.147: epoch 84:	0.02584735  	0.19032899  	0.10352375  
2023-05-16 20:19:32.488: [iter 85 : loss : 0.1397 = 0.0486 + 0.0864 + 0.0047, time: 10.335379]
2023-05-16 20:19:32.797: epoch 85:	0.02591791  	0.19060378  	0.10383691  
2023-05-16 20:19:43.277: [iter 86 : loss : 0.1398 = 0.0487 + 0.0863 + 0.0048, time: 10.478002]
2023-05-16 20:19:43.552: epoch 86:	0.02599553  	0.19090749  	0.10399225  
2023-05-16 20:19:43.552: Find a better model.
2023-05-16 20:19:53.772: [iter 87 : loss : 0.1370 = 0.0459 + 0.0862 + 0.0048, time: 10.218024]
2023-05-16 20:19:54.123: epoch 87:	0.02607315  	0.19147883  	0.10419272  
2023-05-16 20:19:54.123: Find a better model.
2023-05-16 20:20:03.396: [iter 88 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0049, time: 9.271004]
2023-05-16 20:20:03.571: epoch 88:	0.02610843  	0.19191884  	0.10435291  
2023-05-16 20:20:03.571: Find a better model.
2023-05-16 20:20:12.271: [iter 89 : loss : 0.1361 = 0.0452 + 0.0860 + 0.0049, time: 8.699628]
2023-05-16 20:20:12.436: epoch 89:	0.02606609  	0.19122754  	0.10429293  
2023-05-16 20:20:22.790: [iter 90 : loss : 0.1367 = 0.0458 + 0.0859 + 0.0049, time: 10.349013]
2023-05-16 20:20:23.165: epoch 90:	0.02603081  	0.19101660  	0.10439972  
2023-05-16 20:20:32.574: [iter 91 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 9.406005]
2023-05-16 20:20:32.965: epoch 91:	0.02610843  	0.19183302  	0.10471405  
2023-05-16 20:20:41.375: [iter 92 : loss : 0.1344 = 0.0436 + 0.0858 + 0.0050, time: 8.408374]
2023-05-16 20:20:41.597: epoch 92:	0.02615077  	0.19198610  	0.10496893  
2023-05-16 20:20:41.597: Find a better model.
2023-05-16 20:20:51.957: [iter 93 : loss : 0.1347 = 0.0439 + 0.0857 + 0.0051, time: 10.359019]
2023-05-16 20:20:52.133: epoch 93:	0.02605198  	0.19139950  	0.10487413  
2023-05-16 20:21:02.774: [iter 94 : loss : 0.1324 = 0.0418 + 0.0856 + 0.0051, time: 10.637413]
2023-05-16 20:21:03.171: epoch 94:	0.02610137  	0.19161318  	0.10499302  
2023-05-16 20:21:13.721: [iter 95 : loss : 0.1318 = 0.0411 + 0.0855 + 0.0051, time: 10.545625]
2023-05-16 20:21:14.073: epoch 95:	0.02608020  	0.19181098  	0.10503113  
2023-05-16 20:21:24.503: [iter 96 : loss : 0.1319 = 0.0413 + 0.0854 + 0.0052, time: 10.424404]
2023-05-16 20:21:24.814: epoch 96:	0.02614372  	0.19233271  	0.10543481  
2023-05-16 20:21:24.814: Find a better model.
2023-05-16 20:21:35.176: [iter 97 : loss : 0.1301 = 0.0396 + 0.0854 + 0.0052, time: 10.360991]
2023-05-16 20:21:35.346: epoch 97:	0.02619311  	0.19260561  	0.10570080  
2023-05-16 20:21:35.346: Find a better model.
2023-05-16 20:21:44.802: [iter 98 : loss : 0.1310 = 0.0405 + 0.0853 + 0.0052, time: 9.455003]
2023-05-16 20:21:44.973: epoch 98:	0.02627073  	0.19343384  	0.10610949  
2023-05-16 20:21:44.974: Find a better model.
2023-05-16 20:21:54.983: [iter 99 : loss : 0.1299 = 0.0394 + 0.0852 + 0.0053, time: 10.001033]
2023-05-16 20:21:55.332: epoch 99:	0.02624251  	0.19287521  	0.10616622  
2023-05-16 20:22:05.533: [iter 100 : loss : 0.1290 = 0.0385 + 0.0851 + 0.0053, time: 10.199023]
2023-05-16 20:22:05.841: epoch 100:	0.02623546  	0.19308905  	0.10612683  
2023-05-16 20:22:15.370: [iter 101 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 9.526997]
2023-05-16 20:22:15.537: epoch 101:	0.02630602  	0.19369984  	0.10650898  
2023-05-16 20:22:15.537: Find a better model.
2023-05-16 20:22:24.746: [iter 102 : loss : 0.1278 = 0.0374 + 0.0850 + 0.0054, time: 9.207154]
2023-05-16 20:22:24.911: epoch 102:	0.02629896  	0.19379479  	0.10657228  
2023-05-16 20:22:24.911: Find a better model.
2023-05-16 20:22:34.300: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 9.388343]
2023-05-16 20:22:34.516: epoch 103:	0.02635541  	0.19413216  	0.10669061  
2023-05-16 20:22:34.517: Find a better model.
2023-05-16 20:22:44.850: [iter 104 : loss : 0.1280 = 0.0377 + 0.0848 + 0.0055, time: 10.330887]
2023-05-16 20:22:45.205: epoch 104:	0.02628485  	0.19343540  	0.10644681  
2023-05-16 20:22:55.520: [iter 105 : loss : 0.1273 = 0.0370 + 0.0848 + 0.0055, time: 10.310000]
2023-05-16 20:22:55.868: epoch 105:	0.02626368  	0.19337276  	0.10652385  
2023-05-16 20:23:04.809: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 8.939573]
2023-05-16 20:23:04.980: epoch 106:	0.02624956  	0.19337898  	0.10655551  
2023-05-16 20:23:13.613: [iter 107 : loss : 0.1258 = 0.0356 + 0.0847 + 0.0055, time: 8.631016]
2023-05-16 20:23:13.776: epoch 107:	0.02622839  	0.19318995  	0.10661744  
2023-05-16 20:23:24.368: [iter 108 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0056, time: 10.590436]
2023-05-16 20:23:24.582: epoch 108:	0.02624957  	0.19334294  	0.10664312  
2023-05-16 20:23:34.895: [iter 109 : loss : 0.1242 = 0.0341 + 0.0845 + 0.0056, time: 10.309369]
2023-05-16 20:23:35.231: epoch 109:	0.02629896  	0.19358929  	0.10682622  
2023-05-16 20:23:45.613: [iter 110 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0057, time: 10.367332]
2023-05-16 20:23:45.956: epoch 110:	0.02629190  	0.19362886  	0.10681421  
2023-05-16 20:23:55.854: [iter 111 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 9.897635]
2023-05-16 20:23:56.072: epoch 111:	0.02627779  	0.19360206  	0.10688929  
2023-05-16 20:24:06.079: [iter 112 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0057, time: 10.004947]
2023-05-16 20:24:06.242: epoch 112:	0.02626368  	0.19336750  	0.10663431  
2023-05-16 20:24:16.409: [iter 113 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0058, time: 10.164269]
2023-05-16 20:24:16.565: epoch 113:	0.02623546  	0.19330874  	0.10661420  
2023-05-16 20:24:25.033: [iter 114 : loss : 0.1226 = 0.0326 + 0.0842 + 0.0058, time: 8.466006]
2023-05-16 20:24:25.196: epoch 114:	0.02634130  	0.19387925  	0.10676815  
2023-05-16 20:24:35.414: [iter 115 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.214433]
2023-05-16 20:24:35.754: epoch 115:	0.02633424  	0.19398162  	0.10682102  
2023-05-16 20:24:45.953: [iter 116 : loss : 0.1214 = 0.0314 + 0.0842 + 0.0059, time: 10.193003]
2023-05-16 20:24:46.289: epoch 116:	0.02632719  	0.19402687  	0.10673178  
2023-05-16 20:24:55.498: [iter 117 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 9.207984]
2023-05-16 20:24:55.671: epoch 117:	0.02634836  	0.19387621  	0.10690784  
2023-05-16 20:25:04.211: [iter 118 : loss : 0.1212 = 0.0312 + 0.0840 + 0.0059, time: 8.539046]
2023-05-16 20:25:04.376: epoch 118:	0.02627780  	0.19360071  	0.10705175  
2023-05-16 20:25:14.805: [iter 119 : loss : 0.1200 = 0.0301 + 0.0840 + 0.0060, time: 10.428004]
2023-05-16 20:25:14.973: epoch 119:	0.02632719  	0.19384465  	0.10705374  
2023-05-16 20:25:25.628: [iter 120 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0060, time: 10.653049]
2023-05-16 20:25:25.966: epoch 120:	0.02632013  	0.19387691  	0.10696511  
2023-05-16 20:25:36.362: [iter 121 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 10.393026]
2023-05-16 20:25:36.720: epoch 121:	0.02634835  	0.19382395  	0.10705739  
2023-05-16 20:25:46.313: [iter 122 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0060, time: 9.592037]
2023-05-16 20:25:46.499: epoch 122:	0.02636953  	0.19426993  	0.10714845  
2023-05-16 20:25:46.499: Find a better model.
2023-05-16 20:25:56.029: [iter 123 : loss : 0.1193 = 0.0295 + 0.0837 + 0.0061, time: 9.528017]
2023-05-16 20:25:56.207: epoch 123:	0.02638364  	0.19439098  	0.10731028  
2023-05-16 20:25:56.207: Find a better model.
2023-05-16 20:26:06.165: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 9.956991]
2023-05-16 20:26:06.328: epoch 124:	0.02634131  	0.19386387  	0.10721373  
2023-05-16 20:26:15.836: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 9.494016]
2023-05-16 20:26:16.165: epoch 125:	0.02627074  	0.19361714  	0.10715825  
2023-05-16 20:26:26.517: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 10.350038]
2023-05-16 20:26:26.869: epoch 126:	0.02624957  	0.19339809  	0.10721530  
2023-05-16 20:26:36.444: [iter 127 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0062, time: 9.572429]
2023-05-16 20:26:36.704: epoch 127:	0.02624252  	0.19351071  	0.10720741  
2023-05-16 20:26:46.363: [iter 128 : loss : 0.1182 = 0.0284 + 0.0835 + 0.0062, time: 9.658014]
2023-05-16 20:26:46.522: epoch 128:	0.02624251  	0.19352216  	0.10735928  
2023-05-16 20:26:55.573: [iter 129 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 9.048991]
2023-05-16 20:26:55.744: epoch 129:	0.02627780  	0.19398141  	0.10747118  
2023-05-16 20:27:05.478: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 9.727234]
2023-05-16 20:27:05.775: epoch 130:	0.02634836  	0.19426516  	0.10762472  
2023-05-16 20:27:16.178: [iter 131 : loss : 0.1164 = 0.0266 + 0.0834 + 0.0063, time: 10.395021]
2023-05-16 20:27:16.532: epoch 131:	0.02627780  	0.19391927  	0.10740796  
2023-05-16 20:27:26.436: [iter 132 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 9.900036]
2023-05-16 20:27:26.859: epoch 132:	0.02632719  	0.19422999  	0.10762069  
2023-05-16 20:27:36.718: [iter 133 : loss : 0.1154 = 0.0257 + 0.0833 + 0.0064, time: 9.857028]
2023-05-16 20:27:36.871: epoch 133:	0.02634131  	0.19429980  	0.10767988  
2023-05-16 20:27:46.070: [iter 134 : loss : 0.1160 = 0.0264 + 0.0832 + 0.0064, time: 9.197991]
2023-05-16 20:27:46.230: epoch 134:	0.02629897  	0.19389690  	0.10778080  
2023-05-16 20:27:57.107: [iter 135 : loss : 0.1156 = 0.0259 + 0.0832 + 0.0064, time: 10.868030]
2023-05-16 20:27:57.383: epoch 135:	0.02624957  	0.19356333  	0.10760821  
2023-05-16 20:28:07.744: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 10.359022]
2023-05-16 20:28:08.100: epoch 136:	0.02628485  	0.19394051  	0.10778173  
2023-05-16 20:28:17.717: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 9.610520]
2023-05-16 20:28:17.982: epoch 137:	0.02627074  	0.19388217  	0.10780972  
2023-05-16 20:28:27.466: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 9.482005]
2023-05-16 20:28:27.635: epoch 138:	0.02630602  	0.19409014  	0.10775667  
2023-05-16 20:28:36.740: [iter 139 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0066, time: 9.102991]
2023-05-16 20:28:36.906: epoch 139:	0.02624251  	0.19339746  	0.10746069  
2023-05-16 20:28:47.568: [iter 140 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 10.660290]
2023-05-16 20:28:47.855: epoch 140:	0.02621428  	0.19263901  	0.10729978  
2023-05-16 20:28:58.156: [iter 141 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 10.296090]
2023-05-16 20:28:58.505: epoch 141:	0.02622840  	0.19273736  	0.10742151  
2023-05-16 20:29:07.872: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 9.361160]
2023-05-16 20:29:08.170: epoch 142:	0.02631308  	0.19321610  	0.10760729  
2023-05-16 20:29:17.425: [iter 143 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0067, time: 9.254163]
2023-05-16 20:29:17.590: epoch 143:	0.02625662  	0.19287077  	0.10760487  
2023-05-16 20:29:26.851: [iter 144 : loss : 0.1128 = 0.0232 + 0.0829 + 0.0067, time: 9.259261]
2023-05-16 20:29:27.116: epoch 144:	0.02627073  	0.19291569  	0.10773723  
2023-05-16 20:29:37.435: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 10.314511]
2023-05-16 20:29:37.729: epoch 145:	0.02622134  	0.19249028  	0.10760113  
2023-05-16 20:29:48.190: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 10.456099]
2023-05-16 20:29:48.533: epoch 146:	0.02624251  	0.19260275  	0.10755503  
2023-05-16 20:29:58.787: [iter 147 : loss : 0.1130 = 0.0234 + 0.0828 + 0.0068, time: 10.251013]
2023-05-16 20:29:59.060: epoch 147:	0.02625663  	0.19262695  	0.10757867  
2023-05-16 20:30:08.501: [iter 148 : loss : 0.1116 = 0.0220 + 0.0827 + 0.0068, time: 9.439991]
2023-05-16 20:30:08.737: epoch 148:	0.02630602  	0.19296929  	0.10771590  
2023-05-16 20:30:08.737: Early stopping is trigger at epoch: 148
2023-05-16 20:30:08.737: best_result@epoch 123:

2023-05-16 20:30:08.737: 		0.0264      	0.1944      	0.1073      
2023-05-16 20:48:22.939: my pid: 1276
2023-05-16 20:48:22.939: model: model.general_recommender.SGL
2023-05-16 20:48:22.939: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 20:48:22.939: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 20:48:26.570: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 20:48:37.877: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 11.299672]
2023-05-16 20:48:38.195: epoch 1:	0.00160175  	0.01160001  	0.00568006  
2023-05-16 20:48:38.195: Find a better model.
2023-05-16 20:48:49.532: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 11.332593]
2023-05-16 20:48:49.917: epoch 2:	0.00274485  	0.02103400  	0.01050852  
2023-05-16 20:48:49.917: Find a better model.
2023-05-16 20:49:00.889: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.967822]
2023-05-16 20:49:01.294: epoch 3:	0.00493223  	0.03769996  	0.01803392  
2023-05-16 20:49:01.295: Find a better model.
2023-05-16 20:49:11.122: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 9.824965]
2023-05-16 20:49:11.352: epoch 4:	0.00798046  	0.05971793  	0.02881260  
2023-05-16 20:49:11.353: Find a better model.
2023-05-16 20:49:21.177: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 9.821063]
2023-05-16 20:49:21.371: epoch 5:	0.01164976  	0.08556163  	0.04076066  
2023-05-16 20:49:21.371: Find a better model.
2023-05-16 20:49:31.314: [iter 6 : loss : 0.7674 = 0.6882 + 0.0791 + 0.0000, time: 9.939823]
2023-05-16 20:49:31.674: epoch 6:	0.01523444  	0.11082208  	0.05380110  
2023-05-16 20:49:31.675: Find a better model.
2023-05-16 20:49:42.405: [iter 7 : loss : 0.7613 = 0.6813 + 0.0799 + 0.0000, time: 10.725652]
2023-05-16 20:49:42.754: epoch 7:	0.01771123  	0.12881458  	0.06390847  
2023-05-16 20:49:42.755: Find a better model.
2023-05-16 20:49:52.625: [iter 8 : loss : 0.7460 = 0.6643 + 0.0817 + 0.0001, time: 9.864419]
2023-05-16 20:49:52.912: epoch 8:	0.01879792  	0.13778093  	0.06872436  
2023-05-16 20:49:52.912: Find a better model.
2023-05-16 20:50:02.109: [iter 9 : loss : 0.7117 = 0.6261 + 0.0855 + 0.0001, time: 9.196026]
2023-05-16 20:50:02.260: epoch 9:	0.01876264  	0.13837910  	0.06970381  
2023-05-16 20:50:02.261: Find a better model.
2023-05-16 20:50:11.683: [iter 10 : loss : 0.6516 = 0.5605 + 0.0909 + 0.0002, time: 9.420996]
2023-05-16 20:50:11.853: epoch 10:	0.01871325  	0.13863185  	0.06921180  
2023-05-16 20:50:11.853: Find a better model.
2023-05-16 20:50:21.451: [iter 11 : loss : 0.5762 = 0.4799 + 0.0959 + 0.0004, time: 9.594709]
2023-05-16 20:50:21.743: epoch 11:	0.01857917  	0.13795729  	0.06884554  
2023-05-16 20:50:32.112: [iter 12 : loss : 0.5068 = 0.4070 + 0.0993 + 0.0005, time: 10.366316]
2023-05-16 20:50:32.486: epoch 12:	0.01857918  	0.13756399  	0.06877550  
2023-05-16 20:50:42.830: [iter 13 : loss : 0.4555 = 0.3536 + 0.1012 + 0.0007, time: 10.341007]
2023-05-16 20:50:43.185: epoch 13:	0.01872030  	0.13858455  	0.06947152  
2023-05-16 20:50:52.649: [iter 14 : loss : 0.4168 = 0.3138 + 0.1022 + 0.0008, time: 9.463001]
2023-05-16 20:50:52.832: epoch 14:	0.01873442  	0.13867593  	0.07006221  
2023-05-16 20:50:52.832: Find a better model.
2023-05-16 20:51:01.234: [iter 15 : loss : 0.3896 = 0.2860 + 0.1026 + 0.0010, time: 8.400015]
2023-05-16 20:51:01.424: epoch 15:	0.01896729  	0.14021230  	0.07088740  
2023-05-16 20:51:01.424: Find a better model.
2023-05-16 20:51:11.885: [iter 16 : loss : 0.3669 = 0.2633 + 0.1026 + 0.0011, time: 10.459125]
2023-05-16 20:51:12.057: epoch 16:	0.01914369  	0.14139654  	0.07154466  
2023-05-16 20:51:12.057: Find a better model.
2023-05-16 20:51:22.451: [iter 17 : loss : 0.3503 = 0.2467 + 0.1024 + 0.0012, time: 10.391975]
2023-05-16 20:51:22.768: epoch 17:	0.01932716  	0.14228582  	0.07202464  
2023-05-16 20:51:22.769: Find a better model.
2023-05-16 20:51:33.193: [iter 18 : loss : 0.3349 = 0.2315 + 0.1021 + 0.0013, time: 10.409079]
2023-05-16 20:51:33.535: epoch 18:	0.01949652  	0.14362217  	0.07292111  
2023-05-16 20:51:33.535: Find a better model.
2023-05-16 20:51:43.706: [iter 19 : loss : 0.3208 = 0.2176 + 0.1019 + 0.0014, time: 10.169060]
2023-05-16 20:51:44.070: epoch 19:	0.01965882  	0.14497031  	0.07364339  
2023-05-16 20:51:44.070: Find a better model.
2023-05-16 20:51:54.010: [iter 20 : loss : 0.3109 = 0.2080 + 0.1014 + 0.0015, time: 9.938507]
2023-05-16 20:51:54.173: epoch 20:	0.01992697  	0.14683303  	0.07468765  
2023-05-16 20:51:54.173: Find a better model.
2023-05-16 20:52:02.362: [iter 21 : loss : 0.3014 = 0.1989 + 0.1010 + 0.0016, time: 8.188027]
2023-05-16 20:52:02.572: epoch 21:	0.02011750  	0.14824338  	0.07555486  
2023-05-16 20:52:02.572: Find a better model.
2023-05-16 20:52:12.820: [iter 22 : loss : 0.2930 = 0.1907 + 0.1006 + 0.0017, time: 10.246057]
2023-05-16 20:52:13.006: epoch 22:	0.02028685  	0.14988565  	0.07630024  
2023-05-16 20:52:13.006: Find a better model.
2023-05-16 20:52:23.424: [iter 23 : loss : 0.2848 = 0.1829 + 0.1002 + 0.0017, time: 10.408334]
2023-05-16 20:52:23.783: epoch 23:	0.02053383  	0.15150900  	0.07714289  
2023-05-16 20:52:23.783: Find a better model.
2023-05-16 20:52:34.237: [iter 24 : loss : 0.2781 = 0.1766 + 0.0997 + 0.0018, time: 10.441601]
2023-05-16 20:52:34.569: epoch 24:	0.02072435  	0.15299821  	0.07784593  
2023-05-16 20:52:34.569: Find a better model.
2023-05-16 20:52:44.776: [iter 25 : loss : 0.2714 = 0.1702 + 0.0993 + 0.0019, time: 10.205472]
2023-05-16 20:52:45.080: epoch 25:	0.02085843  	0.15369903  	0.07844404  
2023-05-16 20:52:45.080: Find a better model.
2023-05-16 20:52:54.937: [iter 26 : loss : 0.2677 = 0.1669 + 0.0989 + 0.0019, time: 9.855998]
2023-05-16 20:52:55.109: epoch 26:	0.02102778  	0.15505810  	0.07913052  
2023-05-16 20:52:55.109: Find a better model.
2023-05-16 20:53:04.344: [iter 27 : loss : 0.2600 = 0.1596 + 0.0985 + 0.0020, time: 9.231653]
2023-05-16 20:53:04.514: epoch 27:	0.02131005  	0.15667585  	0.08003727  
2023-05-16 20:53:04.514: Find a better model.
2023-05-16 20:53:13.421: [iter 28 : loss : 0.2551 = 0.1549 + 0.0981 + 0.0021, time: 8.903731]
2023-05-16 20:53:13.570: epoch 28:	0.02149352  	0.15778261  	0.08072560  
2023-05-16 20:53:13.570: Find a better model.
2023-05-16 20:53:23.728: [iter 29 : loss : 0.2505 = 0.1507 + 0.0976 + 0.0021, time: 10.152996]
2023-05-16 20:53:24.082: epoch 29:	0.02168405  	0.15925525  	0.08153348  
2023-05-16 20:53:24.083: Find a better model.
2023-05-16 20:53:34.171: [iter 30 : loss : 0.2441 = 0.1446 + 0.0973 + 0.0022, time: 10.083035]
2023-05-16 20:53:34.523: epoch 30:	0.02179695  	0.16055354  	0.08239579  
2023-05-16 20:53:34.524: Find a better model.
2023-05-16 20:53:43.265: [iter 31 : loss : 0.2406 = 0.1415 + 0.0968 + 0.0023, time: 8.738995]
2023-05-16 20:53:43.462: epoch 31:	0.02199453  	0.16177790  	0.08302515  
2023-05-16 20:53:43.462: Find a better model.
2023-05-16 20:53:52.589: [iter 32 : loss : 0.2349 = 0.1360 + 0.0965 + 0.0023, time: 9.126317]
2023-05-16 20:53:52.759: epoch 32:	0.02217095  	0.16328353  	0.08396383  
2023-05-16 20:53:52.759: Find a better model.
2023-05-16 20:54:02.086: [iter 33 : loss : 0.2323 = 0.1338 + 0.0961 + 0.0024, time: 9.325991]
2023-05-16 20:54:02.257: epoch 33:	0.02229091  	0.16430004  	0.08464937  
2023-05-16 20:54:02.257: Find a better model.
2023-05-16 20:54:10.812: [iter 34 : loss : 0.2283 = 0.1301 + 0.0958 + 0.0024, time: 8.539838]
2023-05-16 20:54:11.102: epoch 34:	0.02241087  	0.16508634  	0.08507629  
2023-05-16 20:54:11.102: Find a better model.
2023-05-16 20:54:21.287: [iter 35 : loss : 0.2247 = 0.1267 + 0.0955 + 0.0025, time: 10.179320]
2023-05-16 20:54:21.654: epoch 35:	0.02255905  	0.16618417  	0.08571526  
2023-05-16 20:54:21.655: Find a better model.
2023-05-16 20:54:31.942: [iter 36 : loss : 0.2212 = 0.1235 + 0.0952 + 0.0025, time: 10.281183]
2023-05-16 20:54:32.302: epoch 36:	0.02270724  	0.16746224  	0.08662091  
2023-05-16 20:54:32.302: Find a better model.
2023-05-16 20:54:41.017: [iter 37 : loss : 0.2173 = 0.1199 + 0.0948 + 0.0026, time: 8.714183]
2023-05-16 20:54:41.189: epoch 37:	0.02282014  	0.16822578  	0.08707442  
2023-05-16 20:54:41.189: Find a better model.
2023-05-16 20:54:49.786: [iter 38 : loss : 0.2159 = 0.1188 + 0.0945 + 0.0027, time: 8.595042]
2023-05-16 20:54:49.950: epoch 38:	0.02303184  	0.17023642  	0.08814222  
2023-05-16 20:54:49.950: Find a better model.
2023-05-16 20:54:59.983: [iter 39 : loss : 0.2113 = 0.1143 + 0.0942 + 0.0027, time: 10.031244]
2023-05-16 20:55:00.159: epoch 39:	0.02315180  	0.17083314  	0.08879347  
2023-05-16 20:55:00.159: Find a better model.
2023-05-16 20:55:10.094: [iter 40 : loss : 0.2080 = 0.1113 + 0.0939 + 0.0028, time: 9.932242]
2023-05-16 20:55:10.458: epoch 40:	0.02324354  	0.17152384  	0.08947048  
2023-05-16 20:55:10.458: Find a better model.
2023-05-16 20:55:20.745: [iter 41 : loss : 0.2064 = 0.1099 + 0.0936 + 0.0028, time: 10.285212]
2023-05-16 20:55:21.101: epoch 41:	0.02333527  	0.17189290  	0.09012675  
2023-05-16 20:55:21.101: Find a better model.
2023-05-16 20:55:31.453: [iter 42 : loss : 0.2039 = 0.1077 + 0.0934 + 0.0029, time: 10.347162]
2023-05-16 20:55:31.801: epoch 42:	0.02347639  	0.17306380  	0.09085076  
2023-05-16 20:55:31.801: Find a better model.
2023-05-16 20:55:41.751: [iter 43 : loss : 0.2000 = 0.1040 + 0.0931 + 0.0029, time: 9.948991]
2023-05-16 20:55:41.927: epoch 43:	0.02351873  	0.17338203  	0.09114038  
2023-05-16 20:55:41.927: Find a better model.
2023-05-16 20:55:51.146: [iter 44 : loss : 0.1968 = 0.1010 + 0.0928 + 0.0030, time: 9.216998]
2023-05-16 20:55:51.365: epoch 44:	0.02360340  	0.17402709  	0.09155043  
2023-05-16 20:55:51.365: Find a better model.
2023-05-16 20:56:00.564: [iter 45 : loss : 0.1945 = 0.0989 + 0.0925 + 0.0030, time: 9.198373]
2023-05-16 20:56:00.733: epoch 45:	0.02373748  	0.17503804  	0.09214336  
2023-05-16 20:56:00.733: Find a better model.
2023-05-16 20:56:11.051: [iter 46 : loss : 0.1922 = 0.0968 + 0.0923 + 0.0031, time: 10.313953]
2023-05-16 20:56:11.426: epoch 46:	0.02380099  	0.17532501  	0.09255696  
2023-05-16 20:56:11.426: Find a better model.
2023-05-16 20:56:21.753: [iter 47 : loss : 0.1914 = 0.0962 + 0.0921 + 0.0031, time: 10.323877]
2023-05-16 20:56:22.124: epoch 47:	0.02394211  	0.17647330  	0.09313309  
2023-05-16 20:56:22.124: Find a better model.
2023-05-16 20:56:30.737: [iter 48 : loss : 0.1878 = 0.0928 + 0.0918 + 0.0032, time: 8.611896]
2023-05-16 20:56:31.385: epoch 48:	0.02394917  	0.17627800  	0.09332214  
2023-05-16 20:56:40.389: [iter 49 : loss : 0.1845 = 0.0897 + 0.0916 + 0.0032, time: 8.988519]
2023-05-16 20:56:40.583: epoch 49:	0.02401973  	0.17676033  	0.09373956  
2023-05-16 20:56:40.583: Find a better model.
2023-05-16 20:56:50.740: [iter 50 : loss : 0.1835 = 0.0889 + 0.0914 + 0.0033, time: 10.155520]
2023-05-16 20:56:50.908: epoch 50:	0.02411853  	0.17741174  	0.09427376  
2023-05-16 20:56:50.908: Find a better model.
2023-05-16 20:57:00.455: [iter 51 : loss : 0.1804 = 0.0859 + 0.0912 + 0.0033, time: 9.544517]
2023-05-16 20:57:00.768: epoch 51:	0.02421732  	0.17825022  	0.09464886  
2023-05-16 20:57:00.768: Find a better model.
2023-05-16 20:57:11.235: [iter 52 : loss : 0.1804 = 0.0861 + 0.0910 + 0.0034, time: 10.463820]
2023-05-16 20:57:11.607: epoch 52:	0.02435139  	0.17906697  	0.09532721  
2023-05-16 20:57:11.607: Find a better model.
2023-05-16 20:57:21.862: [iter 53 : loss : 0.1784 = 0.0842 + 0.0907 + 0.0034, time: 10.252346]
2023-05-16 20:57:22.221: epoch 53:	0.02442195  	0.18012168  	0.09599152  
2023-05-16 20:57:22.221: Find a better model.
2023-05-16 20:57:32.035: [iter 54 : loss : 0.1763 = 0.0823 + 0.0906 + 0.0035, time: 9.812964]
2023-05-16 20:57:32.214: epoch 54:	0.02454897  	0.18085478  	0.09645953  
2023-05-16 20:57:32.214: Find a better model.
2023-05-16 20:57:40.724: [iter 55 : loss : 0.1745 = 0.0806 + 0.0904 + 0.0035, time: 8.506995]
2023-05-16 20:57:40.907: epoch 55:	0.02465481  	0.18142278  	0.09689112  
2023-05-16 20:57:40.907: Find a better model.
2023-05-16 20:57:50.411: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 9.502969]
2023-05-16 20:57:50.565: epoch 56:	0.02478183  	0.18221982  	0.09746057  
2023-05-16 20:57:50.565: Find a better model.
2023-05-16 20:58:01.177: [iter 57 : loss : 0.1709 = 0.0773 + 0.0900 + 0.0036, time: 10.609314]
2023-05-16 20:58:01.524: epoch 57:	0.02476772  	0.18203811  	0.09750153  
2023-05-16 20:58:11.943: [iter 58 : loss : 0.1689 = 0.0754 + 0.0899 + 0.0036, time: 10.414709]
2023-05-16 20:58:12.314: epoch 58:	0.02488062  	0.18291047  	0.09804978  
2023-05-16 20:58:12.314: Find a better model.
2023-05-16 20:58:21.795: [iter 59 : loss : 0.1677 = 0.0744 + 0.0897 + 0.0037, time: 9.480005]
2023-05-16 20:58:22.009: epoch 59:	0.02483122  	0.18269962  	0.09815272  
2023-05-16 20:58:31.583: [iter 60 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 9.572549]
2023-05-16 20:58:31.746: epoch 60:	0.02490884  	0.18294923  	0.09859349  
2023-05-16 20:58:31.747: Find a better model.
2023-05-16 20:58:42.182: [iter 61 : loss : 0.1649 = 0.0718 + 0.0893 + 0.0038, time: 10.434549]
2023-05-16 20:58:42.357: epoch 61:	0.02502880  	0.18398428  	0.09907494  
2023-05-16 20:58:42.357: Find a better model.
2023-05-16 20:58:51.967: [iter 62 : loss : 0.1633 = 0.0704 + 0.0891 + 0.0038, time: 9.605318]
2023-05-16 20:58:52.311: epoch 62:	0.02504291  	0.18435881  	0.09944544  
2023-05-16 20:58:52.311: Find a better model.
2023-05-16 20:59:02.606: [iter 63 : loss : 0.1622 = 0.0693 + 0.0890 + 0.0039, time: 10.289622]
2023-05-16 20:59:02.945: epoch 63:	0.02508525  	0.18459658  	0.09965673  
2023-05-16 20:59:02.945: Find a better model.
2023-05-16 20:59:13.349: [iter 64 : loss : 0.1609 = 0.0682 + 0.0888 + 0.0039, time: 10.401247]
2023-05-16 20:59:13.788: epoch 64:	0.02514876  	0.18509217  	0.10006841  
2023-05-16 20:59:13.788: Find a better model.
2023-05-16 20:59:23.996: [iter 65 : loss : 0.1597 = 0.0671 + 0.0887 + 0.0040, time: 10.205973]
2023-05-16 20:59:24.170: epoch 65:	0.02509231  	0.18447728  	0.10001813  
2023-05-16 20:59:33.546: [iter 66 : loss : 0.1582 = 0.0656 + 0.0885 + 0.0040, time: 9.374343]
2023-05-16 20:59:33.812: epoch 66:	0.02522638  	0.18513267  	0.10052060  
2023-05-16 20:59:33.812: Find a better model.
2023-05-16 20:59:43.088: [iter 67 : loss : 0.1566 = 0.0642 + 0.0884 + 0.0040, time: 9.275169]
2023-05-16 20:59:43.264: epoch 67:	0.02516288  	0.18523675  	0.10072497  
2023-05-16 20:59:43.265: Find a better model.
2023-05-16 20:59:53.807: [iter 68 : loss : 0.1564 = 0.0641 + 0.0882 + 0.0041, time: 10.539002]
2023-05-16 20:59:54.174: epoch 68:	0.02525461  	0.18594685  	0.10110765  
2023-05-16 20:59:54.175: Find a better model.
2023-05-16 21:00:04.681: [iter 69 : loss : 0.1548 = 0.0626 + 0.0881 + 0.0041, time: 10.503488]
2023-05-16 21:00:05.020: epoch 69:	0.02526167  	0.18579660  	0.10124835  
2023-05-16 21:00:13.654: [iter 70 : loss : 0.1529 = 0.0607 + 0.0880 + 0.0042, time: 8.630223]
2023-05-16 21:00:13.914: epoch 70:	0.02543102  	0.18696474  	0.10149574  
2023-05-16 21:00:13.914: Find a better model.
2023-05-16 21:00:23.286: [iter 71 : loss : 0.1514 = 0.0594 + 0.0878 + 0.0042, time: 9.369671]
2023-05-16 21:00:23.541: epoch 71:	0.02549453  	0.18725137  	0.10181391  
2023-05-16 21:00:23.541: Find a better model.
2023-05-16 21:00:33.837: [iter 72 : loss : 0.1511 = 0.0592 + 0.0877 + 0.0042, time: 10.293090]
2023-05-16 21:00:34.002: epoch 72:	0.02555098  	0.18781355  	0.10213378  
2023-05-16 21:00:34.002: Find a better model.
2023-05-16 21:00:43.635: [iter 73 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 9.631028]
2023-05-16 21:00:43.994: epoch 73:	0.02569917  	0.18886334  	0.10258598  
2023-05-16 21:00:43.994: Find a better model.
2023-05-16 21:00:54.264: [iter 74 : loss : 0.1483 = 0.0565 + 0.0875 + 0.0043, time: 10.267144]
2023-05-16 21:00:54.613: epoch 74:	0.02569211  	0.18854627  	0.10277504  
2023-05-16 21:01:04.964: [iter 75 : loss : 0.1479 = 0.0562 + 0.0874 + 0.0044, time: 10.349340]
2023-05-16 21:01:05.276: epoch 75:	0.02571328  	0.18878308  	0.10287474  
2023-05-16 21:01:15.435: [iter 76 : loss : 0.1467 = 0.0551 + 0.0872 + 0.0044, time: 10.155133]
2023-05-16 21:01:15.604: epoch 76:	0.02577679  	0.18952236  	0.10317598  
2023-05-16 21:01:15.604: Find a better model.
2023-05-16 21:01:24.846: [iter 77 : loss : 0.1457 = 0.0541 + 0.0871 + 0.0045, time: 9.241268]
2023-05-16 21:01:25.017: epoch 77:	0.02581912  	0.18981394  	0.10346819  
2023-05-16 21:01:25.017: Find a better model.
2023-05-16 21:01:34.256: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 9.236356]
2023-05-16 21:01:34.490: epoch 78:	0.02583324  	0.18979473  	0.10343008  
2023-05-16 21:01:44.814: [iter 79 : loss : 0.1437 = 0.0523 + 0.0869 + 0.0045, time: 10.320724]
2023-05-16 21:01:45.187: epoch 79:	0.02584735  	0.18985572  	0.10376598  
2023-05-16 21:01:45.187: Find a better model.
2023-05-16 21:01:55.640: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 10.451070]
2023-05-16 21:01:55.981: epoch 80:	0.02586146  	0.19023921  	0.10396682  
2023-05-16 21:01:55.982: Find a better model.
2023-05-16 21:02:04.590: [iter 81 : loss : 0.1424 = 0.0512 + 0.0867 + 0.0046, time: 8.606470]
2023-05-16 21:02:05.449: epoch 81:	0.02586146  	0.19037865  	0.10410079  
2023-05-16 21:02:05.449: Find a better model.
2023-05-16 21:02:14.247: [iter 82 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0047, time: 8.795001]
2023-05-16 21:02:14.507: epoch 82:	0.02597436  	0.19076455  	0.10429385  
2023-05-16 21:02:14.507: Find a better model.
2023-05-16 21:02:24.828: [iter 83 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 10.318998]
2023-05-16 21:02:24.983: epoch 83:	0.02596731  	0.19080260  	0.10463390  
2023-05-16 21:02:24.983: Find a better model.
2023-05-16 21:02:34.709: [iter 84 : loss : 0.1402 = 0.0491 + 0.0864 + 0.0047, time: 9.722732]
2023-05-16 21:02:35.052: epoch 84:	0.02598847  	0.19101001  	0.10481685  
2023-05-16 21:02:35.052: Find a better model.
2023-05-16 21:02:45.349: [iter 85 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 10.290949]
2023-05-16 21:02:45.718: epoch 85:	0.02598142  	0.19061235  	0.10484780  
2023-05-16 21:02:56.098: [iter 86 : loss : 0.1391 = 0.0481 + 0.0862 + 0.0048, time: 10.375458]
2023-05-16 21:02:56.430: epoch 86:	0.02608020  	0.19144540  	0.10508803  
2023-05-16 21:02:56.431: Find a better model.
2023-05-16 21:03:06.410: [iter 87 : loss : 0.1362 = 0.0453 + 0.0861 + 0.0048, time: 9.977999]
2023-05-16 21:03:06.563: epoch 87:	0.02619311  	0.19228171  	0.10553013  
2023-05-16 21:03:06.563: Find a better model.
2023-05-16 21:03:15.818: [iter 88 : loss : 0.1356 = 0.0448 + 0.0860 + 0.0049, time: 9.253999]
2023-05-16 21:03:15.988: epoch 88:	0.02623545  	0.19277029  	0.10569097  
2023-05-16 21:03:15.988: Find a better model.
2023-05-16 21:03:25.399: [iter 89 : loss : 0.1353 = 0.0445 + 0.0859 + 0.0049, time: 9.410886]
2023-05-16 21:03:25.555: epoch 89:	0.02627778  	0.19296464  	0.10583722  
2023-05-16 21:03:25.555: Find a better model.
2023-05-16 21:03:35.952: [iter 90 : loss : 0.1361 = 0.0453 + 0.0858 + 0.0050, time: 10.393002]
2023-05-16 21:03:36.307: epoch 90:	0.02630601  	0.19296560  	0.10585713  
2023-05-16 21:03:36.308: Find a better model.
2023-05-16 21:03:46.641: [iter 91 : loss : 0.1347 = 0.0440 + 0.0858 + 0.0050, time: 10.328560]
2023-05-16 21:03:47.001: epoch 91:	0.02627074  	0.19263774  	0.10587040  
2023-05-16 21:03:55.994: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 8.991457]
2023-05-16 21:03:56.185: epoch 92:	0.02627779  	0.19249009  	0.10579681  
2023-05-16 21:04:05.238: [iter 93 : loss : 0.1342 = 0.0435 + 0.0856 + 0.0051, time: 9.051303]
2023-05-16 21:04:05.465: epoch 93:	0.02628485  	0.19246987  	0.10607282  
2023-05-16 21:04:15.523: [iter 94 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 10.056994]
2023-05-16 21:04:15.874: epoch 94:	0.02624957  	0.19255346  	0.10615182  
2023-05-16 21:04:25.691: [iter 95 : loss : 0.1315 = 0.0409 + 0.0854 + 0.0051, time: 9.814723]
2023-05-16 21:04:26.031: epoch 95:	0.02628485  	0.19321324  	0.10654317  
2023-05-16 21:04:26.031: Find a better model.
2023-05-16 21:04:36.351: [iter 96 : loss : 0.1311 = 0.0406 + 0.0854 + 0.0052, time: 10.318319]
2023-05-16 21:04:36.704: epoch 96:	0.02631307  	0.19315788  	0.10629725  
2023-05-16 21:04:46.995: [iter 97 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0052, time: 10.288633]
2023-05-16 21:04:47.305: epoch 97:	0.02634129  	0.19331273  	0.10651844  
2023-05-16 21:04:47.306: Find a better model.
2023-05-16 21:04:57.570: [iter 98 : loss : 0.1304 = 0.0400 + 0.0852 + 0.0053, time: 10.261753]
2023-05-16 21:04:57.728: epoch 98:	0.02627779  	0.19322337  	0.10655007  
2023-05-16 21:05:06.907: [iter 99 : loss : 0.1294 = 0.0390 + 0.0851 + 0.0053, time: 9.177312]
2023-05-16 21:05:07.076: epoch 99:	0.02636247  	0.19376276  	0.10678034  
2023-05-16 21:05:07.076: Find a better model.
2023-05-16 21:05:16.169: [iter 100 : loss : 0.1288 = 0.0384 + 0.0851 + 0.0053, time: 9.091865]
2023-05-16 21:05:16.335: epoch 100:	0.02636247  	0.19369785  	0.10682826  
2023-05-16 21:05:26.803: [iter 101 : loss : 0.1282 = 0.0379 + 0.0850 + 0.0054, time: 10.464917]
2023-05-16 21:05:27.178: epoch 101:	0.02632718  	0.19363278  	0.10716023  
2023-05-16 21:05:37.508: [iter 102 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 10.327384]
2023-05-16 21:05:37.869: epoch 102:	0.02631307  	0.19364882  	0.10723440  
2023-05-16 21:05:46.531: [iter 103 : loss : 0.1273 = 0.0370 + 0.0848 + 0.0054, time: 8.660191]
2023-05-16 21:05:47.196: epoch 103:	0.02624251  	0.19323222  	0.10704190  
2023-05-16 21:05:56.409: [iter 104 : loss : 0.1275 = 0.0373 + 0.0848 + 0.0055, time: 9.198649]
2023-05-16 21:05:56.580: epoch 104:	0.02633424  	0.19322962  	0.10717043  
2023-05-16 21:06:06.620: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 10.039001]
2023-05-16 21:06:06.783: epoch 105:	0.02630601  	0.19312385  	0.10704937  
2023-05-16 21:06:16.463: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 9.675448]
2023-05-16 21:06:16.813: epoch 106:	0.02640481  	0.19390991  	0.10752866  
2023-05-16 21:06:16.813: Find a better model.
2023-05-16 21:06:27.210: [iter 107 : loss : 0.1254 = 0.0353 + 0.0846 + 0.0056, time: 10.389087]
2023-05-16 21:06:27.576: epoch 107:	0.02645421  	0.19461669  	0.10787147  
2023-05-16 21:06:27.577: Find a better model.
2023-05-16 21:06:37.884: [iter 108 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 10.302426]
2023-05-16 21:06:38.258: epoch 108:	0.02652477  	0.19477816  	0.10789207  
2023-05-16 21:06:38.258: Find a better model.
2023-05-16 21:06:48.125: [iter 109 : loss : 0.1236 = 0.0336 + 0.0845 + 0.0056, time: 9.865991]
2023-05-16 21:06:48.308: epoch 109:	0.02659534  	0.19544397  	0.10810631  
2023-05-16 21:06:48.308: Find a better model.
2023-05-16 21:06:56.776: [iter 110 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 8.463997]
2023-05-16 21:06:56.954: epoch 110:	0.02656006  	0.19520223  	0.10811743  
2023-05-16 21:07:06.411: [iter 111 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0057, time: 9.454992]
2023-05-16 21:07:06.569: epoch 111:	0.02659534  	0.19551347  	0.10846056  
2023-05-16 21:07:06.569: Find a better model.
2023-05-16 21:07:17.038: [iter 112 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0057, time: 10.467767]
2023-05-16 21:07:17.413: epoch 112:	0.02670824  	0.19654457  	0.10863847  
2023-05-16 21:07:17.413: Find a better model.
2023-05-16 21:07:27.730: [iter 113 : loss : 0.1230 = 0.0330 + 0.0842 + 0.0058, time: 10.312845]
2023-05-16 21:07:28.087: epoch 113:	0.02665885  	0.19608733  	0.10857064  
2023-05-16 21:07:37.492: [iter 114 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 9.396408]
2023-05-16 21:07:37.761: epoch 114:	0.02668707  	0.19636993  	0.10860766  
2023-05-16 21:07:47.512: [iter 115 : loss : 0.1216 = 0.0317 + 0.0841 + 0.0058, time: 9.749822]
2023-05-16 21:07:47.674: epoch 115:	0.02668707  	0.19639789  	0.10893898  
2023-05-16 21:07:56.897: [iter 116 : loss : 0.1210 = 0.0311 + 0.0841 + 0.0059, time: 9.220991]
2023-05-16 21:07:57.066: epoch 116:	0.02675764  	0.19689181  	0.10910443  
2023-05-16 21:07:57.066: Find a better model.
2023-05-16 21:08:07.113: [iter 117 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 10.035906]
2023-05-16 21:08:07.399: epoch 117:	0.02675764  	0.19694711  	0.10899809  
2023-05-16 21:08:07.399: Find a better model.
2023-05-16 21:08:17.666: [iter 118 : loss : 0.1206 = 0.0308 + 0.0840 + 0.0059, time: 10.265325]
2023-05-16 21:08:18.012: epoch 118:	0.02679998  	0.19726180  	0.10923970  
2023-05-16 21:08:18.013: Find a better model.
2023-05-16 21:08:28.310: [iter 119 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 10.293148]
2023-05-16 21:08:28.666: epoch 119:	0.02680703  	0.19701771  	0.10926522  
2023-05-16 21:08:37.820: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 9.152934]
2023-05-16 21:08:37.986: epoch 120:	0.02678586  	0.19703794  	0.10924147  
2023-05-16 21:08:46.654: [iter 121 : loss : 0.1197 = 0.0298 + 0.0838 + 0.0060, time: 8.667222]
2023-05-16 21:08:46.816: epoch 121:	0.02675058  	0.19687565  	0.10925014  
2023-05-16 21:08:56.879: [iter 122 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 10.061010]
2023-05-16 21:08:57.060: epoch 122:	0.02677880  	0.19722603  	0.10949576  
2023-05-16 21:09:07.631: [iter 123 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0061, time: 10.568720]
2023-05-16 21:09:07.978: epoch 123:	0.02680703  	0.19716832  	0.10965742  
2023-05-16 21:09:18.223: [iter 124 : loss : 0.1181 = 0.0283 + 0.0836 + 0.0061, time: 10.244055]
2023-05-16 21:09:18.583: epoch 124:	0.02675058  	0.19678935  	0.10954557  
2023-05-16 21:09:28.323: [iter 125 : loss : 0.1175 = 0.0277 + 0.0836 + 0.0061, time: 9.738296]
2023-05-16 21:09:28.640: epoch 125:	0.02677175  	0.19689503  	0.10973550  
2023-05-16 21:09:38.601: [iter 126 : loss : 0.1178 = 0.0281 + 0.0836 + 0.0062, time: 9.959032]
2023-05-16 21:09:38.765: epoch 126:	0.02672941  	0.19683151  	0.10988168  
2023-05-16 21:09:47.559: [iter 127 : loss : 0.1168 = 0.0270 + 0.0835 + 0.0062, time: 8.792211]
2023-05-16 21:09:47.731: epoch 127:	0.02675763  	0.19704702  	0.10999931  
2023-05-16 21:09:56.477: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 8.743014]
2023-05-16 21:09:56.633: epoch 128:	0.02678586  	0.19691287  	0.10996848  
2023-05-16 21:10:06.893: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 10.256661]
2023-05-16 21:10:07.254: epoch 129:	0.02676469  	0.19670402  	0.10992653  
2023-05-16 21:10:17.537: [iter 130 : loss : 0.1168 = 0.0271 + 0.0834 + 0.0063, time: 10.278756]
2023-05-16 21:10:17.923: epoch 130:	0.02670118  	0.19625135  	0.10972743  
2023-05-16 21:10:26.626: [iter 131 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0063, time: 8.701406]
2023-05-16 21:10:26.878: epoch 131:	0.02671529  	0.19636817  	0.10992653  
2023-05-16 21:10:36.087: [iter 132 : loss : 0.1164 = 0.0268 + 0.0833 + 0.0064, time: 9.206000]
2023-05-16 21:10:36.255: epoch 132:	0.02670822  	0.19637376  	0.10977156  
2023-05-16 21:10:45.641: [iter 133 : loss : 0.1150 = 0.0254 + 0.0833 + 0.0064, time: 9.383996]
2023-05-16 21:10:45.980: epoch 133:	0.02669412  	0.19611405  	0.10969370  
2023-05-16 21:10:56.181: [iter 134 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 10.197816]
2023-05-16 21:10:56.460: epoch 134:	0.02668000  	0.19593753  	0.10974567  
2023-05-16 21:11:06.844: [iter 135 : loss : 0.1153 = 0.0257 + 0.0831 + 0.0064, time: 10.380193]
2023-05-16 21:11:07.221: epoch 135:	0.02670822  	0.19621474  	0.10993392  
2023-05-16 21:11:17.487: [iter 136 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 10.261043]
2023-05-16 21:11:17.855: epoch 136:	0.02668705  	0.19617373  	0.10994974  
2023-05-16 21:11:26.994: [iter 137 : loss : 0.1146 = 0.0251 + 0.0831 + 0.0065, time: 9.136992]
2023-05-16 21:11:27.208: epoch 137:	0.02656710  	0.19521469  	0.10968248  
2023-05-16 21:11:35.433: [iter 138 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 8.222091]
2023-05-16 21:11:35.594: epoch 138:	0.02653182  	0.19498859  	0.10970015  
2023-05-16 21:11:45.641: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 10.043992]
2023-05-16 21:11:45.809: epoch 139:	0.02655299  	0.19501182  	0.10972031  
2023-05-16 21:11:56.224: [iter 140 : loss : 0.1134 = 0.0239 + 0.0830 + 0.0066, time: 10.401593]
2023-05-16 21:11:56.563: epoch 140:	0.02660944  	0.19562761  	0.10990747  
2023-05-16 21:12:06.683: [iter 141 : loss : 0.1141 = 0.0245 + 0.0829 + 0.0066, time: 10.115080]
2023-05-16 21:12:07.042: epoch 141:	0.02653887  	0.19497082  	0.10966321  
2023-05-16 21:12:16.932: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 9.887321]
2023-05-16 21:12:17.213: epoch 142:	0.02659533  	0.19564112  	0.10998964  
2023-05-16 21:12:26.850: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 9.634801]
2023-05-16 21:12:27.005: epoch 143:	0.02669412  	0.19648732  	0.11036766  
2023-05-16 21:12:27.005: Early stopping is trigger at epoch: 143
2023-05-16 21:12:27.005: best_result@epoch 118:

2023-05-16 21:12:27.005: 		0.0268      	0.1973      	0.1092      
2023-05-16 21:15:41.440: my pid: 2960
2023-05-16 21:15:41.440: model: model.general_recommender.SGL
2023-05-16 21:15:41.440: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 21:15:41.440: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 21:15:46.259: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 21:15:55.107: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.846361]
2023-05-16 21:15:55.409: epoch 1:	0.00159470  	0.01140640  	0.00568407  
2023-05-16 21:15:55.409: Find a better model.
2023-05-16 21:16:05.987: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 10.569550]
2023-05-16 21:16:06.178: epoch 2:	0.00263901  	0.01931091  	0.01005184  
2023-05-16 21:16:06.178: Find a better model.
2023-05-16 21:16:16.943: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.764199]
2023-05-16 21:16:17.129: epoch 3:	0.00496046  	0.03700948  	0.01832520  
2023-05-16 21:16:17.129: Find a better model.
2023-05-16 21:16:28.403: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 11.270638]
2023-05-16 21:16:28.768: epoch 4:	0.00823448  	0.06050033  	0.02950674  
2023-05-16 21:16:28.768: Find a better model.
2023-05-16 21:16:39.677: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 10.904996]
2023-05-16 21:16:40.028: epoch 5:	0.01186146  	0.08677948  	0.04195474  
2023-05-16 21:16:40.028: Find a better model.
2023-05-16 21:16:50.515: [iter 6 : loss : 0.7673 = 0.6881 + 0.0792 + 0.0000, time: 10.480791]
2023-05-16 21:16:50.836: epoch 6:	0.01562960  	0.11285821  	0.05554429  
2023-05-16 21:16:50.836: Find a better model.
2023-05-16 21:17:01.051: [iter 7 : loss : 0.7610 = 0.6810 + 0.0799 + 0.0000, time: 10.213568]
2023-05-16 21:17:01.220: epoch 7:	0.01788764  	0.13004290  	0.06471623  
2023-05-16 21:17:01.220: Find a better model.
2023-05-16 21:17:10.488: [iter 8 : loss : 0.7453 = 0.6634 + 0.0818 + 0.0001, time: 9.267054]
2023-05-16 21:17:10.662: epoch 8:	0.01872736  	0.13728800  	0.06926963  
2023-05-16 21:17:10.663: Find a better model.
2023-05-16 21:17:19.592: [iter 9 : loss : 0.7097 = 0.6238 + 0.0857 + 0.0001, time: 8.928122]
2023-05-16 21:17:19.755: epoch 9:	0.01887555  	0.13922836  	0.06968481  
2023-05-16 21:17:19.755: Find a better model.
2023-05-16 21:17:30.127: [iter 10 : loss : 0.6482 = 0.5567 + 0.0912 + 0.0002, time: 10.368450]
2023-05-16 21:17:30.476: epoch 10:	0.01867092  	0.13869685  	0.06904592  
2023-05-16 21:17:40.862: [iter 11 : loss : 0.5721 = 0.4754 + 0.0963 + 0.0004, time: 10.382095]
2023-05-16 21:17:41.231: epoch 11:	0.01841688  	0.13597959  	0.06806304  
2023-05-16 21:17:49.829: [iter 12 : loss : 0.5035 = 0.4033 + 0.0996 + 0.0006, time: 8.596755]
2023-05-16 21:17:50.053: epoch 12:	0.01841688  	0.13658458  	0.06838490  
2023-05-16 21:17:59.120: [iter 13 : loss : 0.4532 = 0.3510 + 0.1015 + 0.0007, time: 9.066405]
2023-05-16 21:17:59.306: epoch 13:	0.01850156  	0.13754936  	0.06906591  
2023-05-16 21:18:09.123: [iter 14 : loss : 0.4151 = 0.3120 + 0.1023 + 0.0008, time: 9.813003]
2023-05-16 21:18:09.324: epoch 14:	0.01865680  	0.13909613  	0.06992140  
2023-05-16 21:18:19.134: [iter 15 : loss : 0.3887 = 0.2851 + 0.1027 + 0.0010, time: 9.805400]
2023-05-16 21:18:19.505: epoch 15:	0.01890378  	0.14078826  	0.07095958  
2023-05-16 21:18:19.505: Find a better model.
2023-05-16 21:18:30.044: [iter 16 : loss : 0.3666 = 0.2629 + 0.1027 + 0.0011, time: 10.536737]
2023-05-16 21:18:30.421: epoch 16:	0.01902374  	0.14124230  	0.07138074  
2023-05-16 21:18:30.421: Find a better model.
2023-05-16 21:18:40.932: [iter 17 : loss : 0.3502 = 0.2465 + 0.1025 + 0.0012, time: 10.508254]
2023-05-16 21:18:41.297: epoch 17:	0.01927072  	0.14253569  	0.07234767  
2023-05-16 21:18:41.298: Find a better model.
2023-05-16 21:18:51.071: [iter 18 : loss : 0.3351 = 0.2316 + 0.1022 + 0.0013, time: 9.772419]
2023-05-16 21:18:51.232: epoch 18:	0.01950358  	0.14448519  	0.07338819  
2023-05-16 21:18:51.232: Find a better model.
2023-05-16 21:18:59.936: [iter 19 : loss : 0.3208 = 0.2176 + 0.1019 + 0.0014, time: 8.701383]
2023-05-16 21:19:00.150: epoch 19:	0.01963766  	0.14521758  	0.07397157  
2023-05-16 21:19:00.151: Find a better model.
2023-05-16 21:19:10.193: [iter 20 : loss : 0.3113 = 0.2083 + 0.1015 + 0.0015, time: 10.040710]
2023-05-16 21:19:10.364: epoch 20:	0.01989875  	0.14678895  	0.07494048  
2023-05-16 21:19:10.364: Find a better model.
2023-05-16 21:19:20.973: [iter 21 : loss : 0.3015 = 0.1989 + 0.1011 + 0.0016, time: 10.607134]
2023-05-16 21:19:21.341: epoch 21:	0.02001872  	0.14793757  	0.07565682  
2023-05-16 21:19:21.341: Find a better model.
2023-05-16 21:19:31.959: [iter 22 : loss : 0.2933 = 0.1910 + 0.1006 + 0.0016, time: 10.614789]
2023-05-16 21:19:32.336: epoch 22:	0.02025864  	0.14964437  	0.07621656  
2023-05-16 21:19:32.336: Find a better model.
2023-05-16 21:19:41.161: [iter 23 : loss : 0.2850 = 0.1830 + 0.1002 + 0.0017, time: 8.822992]
2023-05-16 21:19:41.485: epoch 23:	0.02043505  	0.15077624  	0.07715318  
2023-05-16 21:19:41.486: Find a better model.
2023-05-16 21:19:50.891: [iter 24 : loss : 0.2785 = 0.1769 + 0.0997 + 0.0018, time: 9.402107]
2023-05-16 21:19:51.062: epoch 24:	0.02072436  	0.15280628  	0.07808647  
2023-05-16 21:19:51.062: Find a better model.
2023-05-16 21:20:01.336: [iter 25 : loss : 0.2719 = 0.1706 + 0.0994 + 0.0019, time: 10.272385]
2023-05-16 21:20:01.573: epoch 25:	0.02090783  	0.15432875  	0.07898116  
2023-05-16 21:20:01.573: Find a better model.
2023-05-16 21:20:11.254: [iter 26 : loss : 0.2681 = 0.1673 + 0.0989 + 0.0019, time: 9.676417]
2023-05-16 21:20:11.576: epoch 26:	0.02115481  	0.15628907  	0.07977518  
2023-05-16 21:20:11.576: Find a better model.
2023-05-16 21:20:21.917: [iter 27 : loss : 0.2605 = 0.1600 + 0.0985 + 0.0020, time: 10.337079]
2023-05-16 21:20:22.274: epoch 27:	0.02121831  	0.15660006  	0.08025952  
2023-05-16 21:20:22.274: Find a better model.
2023-05-16 21:20:32.832: [iter 28 : loss : 0.2554 = 0.1553 + 0.0981 + 0.0021, time: 10.550090]
2023-05-16 21:20:33.189: epoch 28:	0.02143001  	0.15801781  	0.08107191  
2023-05-16 21:20:33.189: Find a better model.
2023-05-16 21:20:43.003: [iter 29 : loss : 0.2509 = 0.1511 + 0.0977 + 0.0021, time: 9.811463]
2023-05-16 21:20:43.193: epoch 29:	0.02159232  	0.15903711  	0.08182280  
2023-05-16 21:20:43.193: Find a better model.
2023-05-16 21:20:51.887: [iter 30 : loss : 0.2444 = 0.1449 + 0.0973 + 0.0022, time: 8.692002]
2023-05-16 21:20:52.093: epoch 30:	0.02189575  	0.16178679  	0.08292409  
2023-05-16 21:20:52.093: Find a better model.
2023-05-16 21:21:01.902: [iter 31 : loss : 0.2408 = 0.1416 + 0.0969 + 0.0023, time: 9.806798]
2023-05-16 21:21:02.066: epoch 31:	0.02199453  	0.16214240  	0.08342759  
2023-05-16 21:21:02.066: Find a better model.
2023-05-16 21:21:12.682: [iter 32 : loss : 0.2350 = 0.1361 + 0.0966 + 0.0023, time: 10.614000]
2023-05-16 21:21:13.049: epoch 32:	0.02216389  	0.16383637  	0.08425727  
2023-05-16 21:21:13.049: Find a better model.
2023-05-16 21:21:23.671: [iter 33 : loss : 0.2325 = 0.1340 + 0.0961 + 0.0024, time: 10.619863]
2023-05-16 21:21:24.036: epoch 33:	0.02223445  	0.16430180  	0.08475239  
2023-05-16 21:21:24.036: Find a better model.
2023-05-16 21:21:33.373: [iter 34 : loss : 0.2285 = 0.1303 + 0.0958 + 0.0024, time: 9.334687]
2023-05-16 21:21:33.622: epoch 34:	0.02245320  	0.16624849  	0.08570186  
2023-05-16 21:21:33.622: Find a better model.
2023-05-16 21:21:43.253: [iter 35 : loss : 0.2250 = 0.1270 + 0.0955 + 0.0025, time: 9.629753]
2023-05-16 21:21:43.521: epoch 35:	0.02255199  	0.16693200  	0.08621023  
2023-05-16 21:21:43.521: Find a better model.
2023-05-16 21:21:53.925: [iter 36 : loss : 0.2214 = 0.1237 + 0.0952 + 0.0025, time: 10.401185]
2023-05-16 21:21:54.118: epoch 36:	0.02271429  	0.16784048  	0.08694634  
2023-05-16 21:21:54.118: Find a better model.
2023-05-16 21:22:03.860: [iter 37 : loss : 0.2176 = 0.1201 + 0.0948 + 0.0026, time: 9.740018]
2023-05-16 21:22:04.210: epoch 37:	0.02279897  	0.16894627  	0.08743131  
2023-05-16 21:22:04.210: Find a better model.
2023-05-16 21:22:14.617: [iter 38 : loss : 0.2158 = 0.1187 + 0.0945 + 0.0027, time: 10.404404]
2023-05-16 21:22:14.966: epoch 38:	0.02290482  	0.16916902  	0.08801193  
2023-05-16 21:22:14.966: Find a better model.
2023-05-16 21:22:25.302: [iter 39 : loss : 0.2116 = 0.1147 + 0.0942 + 0.0027, time: 10.332195]
2023-05-16 21:22:25.663: epoch 39:	0.02304594  	0.17035246  	0.08867157  
2023-05-16 21:22:25.664: Find a better model.
2023-05-16 21:22:35.543: [iter 40 : loss : 0.2083 = 0.1116 + 0.0939 + 0.0028, time: 9.877991]
2023-05-16 21:22:35.725: epoch 40:	0.02318707  	0.17109303  	0.08916143  
2023-05-16 21:22:35.725: Find a better model.
2023-05-16 21:22:44.008: [iter 41 : loss : 0.2065 = 0.1100 + 0.0937 + 0.0028, time: 8.282083]
2023-05-16 21:22:44.207: epoch 41:	0.02340582  	0.17283846  	0.09004788  
2023-05-16 21:22:44.207: Find a better model.
2023-05-16 21:22:53.950: [iter 42 : loss : 0.2041 = 0.1079 + 0.0934 + 0.0029, time: 9.742043]
2023-05-16 21:22:54.123: epoch 42:	0.02347639  	0.17341839  	0.09061197  
2023-05-16 21:22:54.124: Find a better model.
2023-05-16 21:23:04.631: [iter 43 : loss : 0.2003 = 0.1043 + 0.0931 + 0.0029, time: 10.501881]
2023-05-16 21:23:04.992: epoch 43:	0.02358223  	0.17392525  	0.09107249  
2023-05-16 21:23:04.992: Find a better model.
2023-05-16 21:23:15.381: [iter 44 : loss : 0.1968 = 0.1011 + 0.0928 + 0.0030, time: 10.384883]
2023-05-16 21:23:15.745: epoch 44:	0.02369513  	0.17477876  	0.09171380  
2023-05-16 21:23:15.745: Find a better model.
2023-05-16 21:23:25.180: [iter 45 : loss : 0.1947 = 0.0991 + 0.0926 + 0.0030, time: 9.433303]
2023-05-16 21:23:25.492: epoch 45:	0.02378687  	0.17544325  	0.09272000  
2023-05-16 21:23:25.492: Find a better model.
2023-05-16 21:23:35.031: [iter 46 : loss : 0.1922 = 0.0968 + 0.0923 + 0.0031, time: 9.538029]
2023-05-16 21:23:35.190: epoch 46:	0.02379393  	0.17564386  	0.09298179  
2023-05-16 21:23:35.190: Find a better model.
2023-05-16 21:23:44.588: [iter 47 : loss : 0.1916 = 0.0964 + 0.0921 + 0.0031, time: 9.396994]
2023-05-16 21:23:44.761: epoch 47:	0.02399857  	0.17702752  	0.09387354  
2023-05-16 21:23:44.761: Find a better model.
2023-05-16 21:23:53.701: [iter 48 : loss : 0.1876 = 0.0926 + 0.0918 + 0.0032, time: 8.930496]
2023-05-16 21:23:53.967: epoch 48:	0.02412558  	0.17798384  	0.09431011  
2023-05-16 21:23:53.967: Find a better model.
2023-05-16 21:24:04.328: [iter 49 : loss : 0.1847 = 0.0898 + 0.0916 + 0.0032, time: 10.356319]
2023-05-16 21:24:04.667: epoch 49:	0.02416086  	0.17798311  	0.09466492  
2023-05-16 21:24:14.924: [iter 50 : loss : 0.1837 = 0.0890 + 0.0914 + 0.0033, time: 10.251806]
2023-05-16 21:24:15.278: epoch 50:	0.02425260  	0.17876904  	0.09515965  
2023-05-16 21:24:15.279: Find a better model.
2023-05-16 21:24:23.980: [iter 51 : loss : 0.1808 = 0.0863 + 0.0912 + 0.0033, time: 8.700059]
2023-05-16 21:24:24.147: epoch 51:	0.02429494  	0.17900768  	0.09556880  
2023-05-16 21:24:24.147: Find a better model.
2023-05-16 21:24:33.193: [iter 52 : loss : 0.1808 = 0.0864 + 0.0910 + 0.0034, time: 9.043009]
2023-05-16 21:24:33.372: epoch 52:	0.02435845  	0.17945336  	0.09601267  
2023-05-16 21:24:33.373: Find a better model.
2023-05-16 21:24:43.563: [iter 53 : loss : 0.1786 = 0.0844 + 0.0908 + 0.0034, time: 10.188991]
2023-05-16 21:24:43.721: epoch 53:	0.02449252  	0.18060355  	0.09671086  
2023-05-16 21:24:43.721: Find a better model.
2023-05-16 21:24:53.662: [iter 54 : loss : 0.1764 = 0.0824 + 0.0906 + 0.0035, time: 9.935102]
2023-05-16 21:24:54.035: epoch 54:	0.02456308  	0.18102682  	0.09692027  
2023-05-16 21:24:54.035: Find a better model.
2023-05-16 21:25:04.261: [iter 55 : loss : 0.1744 = 0.0806 + 0.0904 + 0.0035, time: 10.224448]
2023-05-16 21:25:04.644: epoch 55:	0.02459837  	0.18172225  	0.09731505  
2023-05-16 21:25:04.645: Find a better model.
2023-05-16 21:25:14.843: [iter 56 : loss : 0.1727 = 0.0789 + 0.0902 + 0.0035, time: 10.190885]
2023-05-16 21:25:15.161: epoch 56:	0.02469010  	0.18209936  	0.09781393  
2023-05-16 21:25:15.162: Find a better model.
2023-05-16 21:25:25.131: [iter 57 : loss : 0.1710 = 0.0774 + 0.0900 + 0.0036, time: 9.967150]
2023-05-16 21:25:25.332: epoch 57:	0.02476066  	0.18255240  	0.09813916  
2023-05-16 21:25:25.332: Find a better model.
2023-05-16 21:25:34.549: [iter 58 : loss : 0.1689 = 0.0754 + 0.0899 + 0.0036, time: 9.211465]
2023-05-16 21:25:34.723: epoch 58:	0.02475360  	0.18228218  	0.09822429  
2023-05-16 21:25:43.955: [iter 59 : loss : 0.1680 = 0.0747 + 0.0896 + 0.0037, time: 9.230510]
2023-05-16 21:25:44.112: epoch 59:	0.02482416  	0.18274555  	0.09858508  
2023-05-16 21:25:44.112: Find a better model.
2023-05-16 21:25:54.529: [iter 60 : loss : 0.1667 = 0.0734 + 0.0895 + 0.0037, time: 10.408181]
2023-05-16 21:25:54.878: epoch 60:	0.02497235  	0.18393996  	0.09898043  
2023-05-16 21:25:54.878: Find a better model.
2023-05-16 21:26:05.372: [iter 61 : loss : 0.1651 = 0.0720 + 0.0893 + 0.0038, time: 10.492564]
2023-05-16 21:26:05.729: epoch 61:	0.02500058  	0.18437983  	0.09928892  
2023-05-16 21:26:05.729: Find a better model.
2023-05-16 21:26:14.706: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 8.975523]
2023-05-16 21:26:14.888: epoch 62:	0.02495824  	0.18408239  	0.09941351  
2023-05-16 21:26:24.218: [iter 63 : loss : 0.1622 = 0.0694 + 0.0890 + 0.0039, time: 9.326717]
2023-05-16 21:26:24.488: epoch 63:	0.02516288  	0.18541099  	0.10001576  
2023-05-16 21:26:24.488: Find a better model.
2023-05-16 21:26:34.829: [iter 64 : loss : 0.1611 = 0.0683 + 0.0889 + 0.0039, time: 10.337941]
2023-05-16 21:26:35.590: epoch 64:	0.02526872  	0.18615621  	0.10053728  
2023-05-16 21:26:35.590: Find a better model.
2023-05-16 21:26:45.636: [iter 65 : loss : 0.1597 = 0.0671 + 0.0887 + 0.0039, time: 10.042843]
2023-05-16 21:26:45.979: epoch 65:	0.02528283  	0.18644585  	0.10091602  
2023-05-16 21:26:45.979: Find a better model.
2023-05-16 21:26:57.200: [iter 66 : loss : 0.1582 = 0.0657 + 0.0886 + 0.0040, time: 11.218608]
2023-05-16 21:26:57.583: epoch 66:	0.02536046  	0.18703714  	0.10124744  
2023-05-16 21:26:57.583: Find a better model.
2023-05-16 21:27:08.905: [iter 67 : loss : 0.1565 = 0.0641 + 0.0884 + 0.0040, time: 11.320315]
2023-05-16 21:27:09.254: epoch 67:	0.02538868  	0.18738572  	0.10154953  
2023-05-16 21:27:09.254: Find a better model.
2023-05-16 21:27:20.109: [iter 68 : loss : 0.1565 = 0.0642 + 0.0883 + 0.0041, time: 10.852609]
2023-05-16 21:27:20.396: epoch 68:	0.02548042  	0.18819818  	0.10206824  
2023-05-16 21:27:20.396: Find a better model.
2023-05-16 21:27:29.568: [iter 69 : loss : 0.1545 = 0.0623 + 0.0881 + 0.0041, time: 9.167481]
2023-05-16 21:27:30.149: epoch 69:	0.02547337  	0.18800692  	0.10230242  
2023-05-16 21:27:40.207: [iter 70 : loss : 0.1530 = 0.0608 + 0.0880 + 0.0042, time: 10.051090]
2023-05-16 21:27:40.412: epoch 70:	0.02551570  	0.18822418  	0.10239895  
2023-05-16 21:27:40.412: Find a better model.
2023-05-16 21:27:51.622: [iter 71 : loss : 0.1515 = 0.0595 + 0.0878 + 0.0042, time: 11.206593]
2023-05-16 21:27:52.009: epoch 71:	0.02560038  	0.18889429  	0.10268695  
2023-05-16 21:27:52.009: Find a better model.
2023-05-16 21:28:00.434: [iter 72 : loss : 0.1513 = 0.0593 + 0.0878 + 0.0042, time: 8.423512]
2023-05-16 21:28:00.621: epoch 72:	0.02567094  	0.18930764  	0.10294475  
2023-05-16 21:28:00.622: Find a better model.
2023-05-16 21:28:10.655: [iter 73 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 10.032427]
2023-05-16 21:28:10.821: epoch 73:	0.02568505  	0.18959527  	0.10306432  
2023-05-16 21:28:10.821: Find a better model.
2023-05-16 21:28:20.000: [iter 74 : loss : 0.1484 = 0.0565 + 0.0875 + 0.0043, time: 9.176889]
2023-05-16 21:28:20.176: epoch 74:	0.02568506  	0.18954834  	0.10305665  
2023-05-16 21:28:29.313: [iter 75 : loss : 0.1478 = 0.0560 + 0.0874 + 0.0044, time: 9.133876]
2023-05-16 21:28:29.521: epoch 75:	0.02579795  	0.19044924  	0.10350795  
2023-05-16 21:28:29.521: Find a better model.
2023-05-16 21:28:39.958: [iter 76 : loss : 0.1469 = 0.0552 + 0.0873 + 0.0044, time: 10.431591]
2023-05-16 21:28:40.321: epoch 76:	0.02588263  	0.19088979  	0.10378624  
2023-05-16 21:28:40.321: Find a better model.
2023-05-16 21:28:50.807: [iter 77 : loss : 0.1458 = 0.0542 + 0.0872 + 0.0044, time: 10.482503]
2023-05-16 21:28:51.169: epoch 77:	0.02579090  	0.19012511  	0.10368521  
2023-05-16 21:29:00.162: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 8.990156]
2023-05-16 21:29:00.590: epoch 78:	0.02577679  	0.19013265  	0.10391127  
2023-05-16 21:29:09.663: [iter 79 : loss : 0.1435 = 0.0521 + 0.0869 + 0.0045, time: 9.070540]
2023-05-16 21:29:09.837: epoch 79:	0.02585441  	0.19087327  	0.10422189  
2023-05-16 21:29:19.720: [iter 80 : loss : 0.1431 = 0.0517 + 0.0868 + 0.0046, time: 9.881999]
2023-05-16 21:29:20.432: epoch 80:	0.02578384  	0.19018035  	0.10428534  
2023-05-16 21:29:30.158: [iter 81 : loss : 0.1424 = 0.0511 + 0.0867 + 0.0046, time: 9.714477]
2023-05-16 21:29:30.471: epoch 81:	0.02584030  	0.19048955  	0.10446532  
2023-05-16 21:29:41.010: [iter 82 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0046, time: 10.534532]
2023-05-16 21:29:41.378: epoch 82:	0.02594614  	0.19148552  	0.10481508  
2023-05-16 21:29:41.378: Find a better model.
2023-05-16 21:29:51.926: [iter 83 : loss : 0.1401 = 0.0489 + 0.0865 + 0.0047, time: 10.545213]
2023-05-16 21:29:52.276: epoch 83:	0.02598142  	0.19171053  	0.10522451  
2023-05-16 21:29:52.276: Find a better model.
2023-05-16 21:30:02.251: [iter 84 : loss : 0.1403 = 0.0492 + 0.0864 + 0.0047, time: 9.971057]
2023-05-16 21:30:02.471: epoch 84:	0.02599554  	0.19153008  	0.10511414  
2023-05-16 21:30:10.860: [iter 85 : loss : 0.1391 = 0.0481 + 0.0863 + 0.0048, time: 8.386051]
2023-05-16 21:30:11.031: epoch 85:	0.02596025  	0.19149308  	0.10548022  
2023-05-16 21:30:20.655: [iter 86 : loss : 0.1392 = 0.0482 + 0.0862 + 0.0048, time: 9.622285]
2023-05-16 21:30:20.944: epoch 86:	0.02596025  	0.19144668  	0.10550458  
2023-05-16 21:30:31.116: [iter 87 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0048, time: 10.168867]
2023-05-16 21:30:31.488: epoch 87:	0.02604493  	0.19206008  	0.10581885  
2023-05-16 21:30:31.488: Find a better model.
2023-05-16 21:30:41.939: [iter 88 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 10.443268]
2023-05-16 21:30:42.303: epoch 88:	0.02603082  	0.19195212  	0.10579202  
2023-05-16 21:30:51.709: [iter 89 : loss : 0.1356 = 0.0447 + 0.0859 + 0.0049, time: 9.394746]
2023-05-16 21:30:52.022: epoch 89:	0.02608022  	0.19230132  	0.10612656  
2023-05-16 21:30:52.022: Find a better model.
2023-05-16 21:31:00.615: [iter 90 : loss : 0.1361 = 0.0452 + 0.0859 + 0.0049, time: 8.591470]
2023-05-16 21:31:00.815: epoch 90:	0.02603788  	0.19175433  	0.10602398  
2023-05-16 21:31:08.594: [iter 91 : loss : 0.1346 = 0.0438 + 0.0858 + 0.0050, time: 7.778045]
2023-05-16 21:31:08.757: epoch 91:	0.02611550  	0.19220659  	0.10648261  
2023-05-16 21:31:17.245: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 8.486984]
2023-05-16 21:31:17.411: epoch 92:	0.02610845  	0.19217414  	0.10639292  
2023-05-16 21:31:26.809: [iter 93 : loss : 0.1340 = 0.0433 + 0.0856 + 0.0051, time: 9.394969]
2023-05-16 21:31:27.123: epoch 93:	0.02613667  	0.19242647  	0.10655865  
2023-05-16 21:31:27.123: Find a better model.
2023-05-16 21:31:36.932: [iter 94 : loss : 0.1319 = 0.0413 + 0.0855 + 0.0051, time: 9.806624]
2023-05-16 21:31:37.249: epoch 94:	0.02610139  	0.19213270  	0.10648305  
2023-05-16 21:31:46.604: [iter 95 : loss : 0.1313 = 0.0407 + 0.0855 + 0.0051, time: 9.354026]
2023-05-16 21:31:46.771: epoch 95:	0.02615078  	0.19246615  	0.10667357  
2023-05-16 21:31:46.772: Find a better model.
2023-05-16 21:31:54.753: [iter 96 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0052, time: 7.979851]
2023-05-16 21:31:54.930: epoch 96:	0.02613667  	0.19215873  	0.10660774  
2023-05-16 21:32:04.281: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 9.349359]
2023-05-16 21:32:04.451: epoch 97:	0.02623546  	0.19282366  	0.10685410  
2023-05-16 21:32:04.451: Find a better model.
2023-05-16 21:32:14.365: [iter 98 : loss : 0.1305 = 0.0401 + 0.0852 + 0.0052, time: 9.905854]
2023-05-16 21:32:14.689: epoch 98:	0.02627780  	0.19315475  	0.10715839  
2023-05-16 21:32:14.689: Find a better model.
2023-05-16 21:32:25.129: [iter 99 : loss : 0.1293 = 0.0389 + 0.0851 + 0.0053, time: 10.435506]
2023-05-16 21:32:25.479: epoch 99:	0.02636247  	0.19373371  	0.10741834  
2023-05-16 21:32:25.479: Find a better model.
2023-05-16 21:32:35.586: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 10.104725]
2023-05-16 21:32:35.753: epoch 100:	0.02635542  	0.19381554  	0.10751022  
2023-05-16 21:32:35.753: Find a better model.
2023-05-16 21:32:44.006: [iter 101 : loss : 0.1284 = 0.0380 + 0.0850 + 0.0053, time: 8.251053]
2023-05-16 21:32:44.171: epoch 101:	0.02638364  	0.19391976  	0.10772488  
2023-05-16 21:32:44.171: Find a better model.
2023-05-16 21:32:54.605: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 10.430001]
2023-05-16 21:32:54.931: epoch 102:	0.02642598  	0.19412789  	0.10791401  
2023-05-16 21:32:54.931: Find a better model.
2023-05-16 21:33:04.431: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 9.496121]
2023-05-16 21:33:04.745: epoch 103:	0.02643304  	0.19450678  	0.10797974  
2023-05-16 21:33:04.745: Find a better model.
2023-05-16 21:33:14.844: [iter 104 : loss : 0.1277 = 0.0375 + 0.0848 + 0.0055, time: 10.096344]
2023-05-16 21:33:15.163: epoch 104:	0.02647538  	0.19454418  	0.10800412  
2023-05-16 21:33:15.163: Find a better model.
2023-05-16 21:33:25.433: [iter 105 : loss : 0.1269 = 0.0367 + 0.0847 + 0.0055, time: 10.269072]
2023-05-16 21:33:25.591: epoch 105:	0.02651066  	0.19484256  	0.10816295  
2023-05-16 21:33:25.591: Find a better model.
2023-05-16 21:33:35.538: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 9.942007]
2023-05-16 21:33:36.084: epoch 106:	0.02656711  	0.19541425  	0.10857388  
2023-05-16 21:33:36.084: Find a better model.
2023-05-16 21:33:45.203: [iter 107 : loss : 0.1254 = 0.0353 + 0.0846 + 0.0055, time: 9.117527]
2023-05-16 21:33:45.404: epoch 107:	0.02666590  	0.19591239  	0.10873788  
2023-05-16 21:33:45.404: Find a better model.
2023-05-16 21:33:55.784: [iter 108 : loss : 0.1254 = 0.0353 + 0.0845 + 0.0056, time: 10.369408]
2023-05-16 21:33:56.110: epoch 108:	0.02670118  	0.19612442  	0.10893550  
2023-05-16 21:33:56.110: Find a better model.
2023-05-16 21:34:05.048: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 8.936373]
2023-05-16 21:34:05.210: epoch 109:	0.02664473  	0.19565229  	0.10882351  
2023-05-16 21:34:14.442: [iter 110 : loss : 0.1231 = 0.0331 + 0.0844 + 0.0057, time: 9.223092]
2023-05-16 21:34:14.743: epoch 110:	0.02668001  	0.19611572  	0.10878428  
2023-05-16 21:34:24.781: [iter 111 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 10.025939]
2023-05-16 21:34:25.194: epoch 111:	0.02663767  	0.19581202  	0.10881936  
2023-05-16 21:34:35.722: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 10.525927]
2023-05-16 21:34:36.066: epoch 112:	0.02668707  	0.19614437  	0.10893049  
2023-05-16 21:34:36.066: Find a better model.
2023-05-16 21:34:46.365: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0058, time: 10.297661]
2023-05-16 21:34:46.720: epoch 113:	0.02670824  	0.19623975  	0.10888418  
2023-05-16 21:34:46.720: Find a better model.
2023-05-16 21:34:56.078: [iter 114 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 9.357318]
2023-05-16 21:34:56.238: epoch 114:	0.02667295  	0.19595441  	0.10896002  
2023-05-16 21:35:05.769: [iter 115 : loss : 0.1216 = 0.0316 + 0.0841 + 0.0058, time: 9.526941]
2023-05-16 21:35:06.085: epoch 115:	0.02668001  	0.19617823  	0.10898728  
2023-05-16 21:35:15.479: [iter 116 : loss : 0.1208 = 0.0309 + 0.0841 + 0.0059, time: 9.392652]
2023-05-16 21:35:15.668: epoch 116:	0.02658828  	0.19547991  	0.10879079  
2023-05-16 21:35:25.593: [iter 117 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 9.921001]
2023-05-16 21:35:25.918: epoch 117:	0.02667295  	0.19575605  	0.10891072  
2023-05-16 21:35:36.275: [iter 118 : loss : 0.1206 = 0.0308 + 0.0840 + 0.0059, time: 10.354968]
2023-05-16 21:35:36.617: epoch 118:	0.02674352  	0.19673938  	0.10941064  
2023-05-16 21:35:36.617: Find a better model.
2023-05-16 21:35:46.969: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 10.348795]
2023-05-16 21:35:47.295: epoch 119:	0.02677175  	0.19703342  	0.10940701  
2023-05-16 21:35:47.295: Find a better model.
2023-05-16 21:35:56.075: [iter 120 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 8.776525]
2023-05-16 21:35:56.680: epoch 120:	0.02676469  	0.19700168  	0.10946476  
2023-05-16 21:36:05.504: [iter 121 : loss : 0.1199 = 0.0300 + 0.0838 + 0.0060, time: 8.821820]
2023-05-16 21:36:05.658: epoch 121:	0.02678586  	0.19724828  	0.10971360  
2023-05-16 21:36:05.658: Find a better model.
2023-05-16 21:36:16.197: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 10.537002]
2023-05-16 21:36:16.530: epoch 122:	0.02671530  	0.19646223  	0.10944065  
2023-05-16 21:36:26.947: [iter 123 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 10.414925]
2023-05-16 21:36:27.263: epoch 123:	0.02665885  	0.19595408  	0.10948931  
2023-05-16 21:36:37.684: [iter 124 : loss : 0.1180 = 0.0283 + 0.0837 + 0.0061, time: 10.418330]
2023-05-16 21:36:37.991: epoch 124:	0.02662357  	0.19593412  	0.10924624  
2023-05-16 21:36:47.683: [iter 125 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0061, time: 9.689961]
2023-05-16 21:36:47.849: epoch 125:	0.02674353  	0.19667196  	0.10960590  
2023-05-16 21:36:56.301: [iter 126 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0062, time: 8.451108]
2023-05-16 21:36:56.465: epoch 126:	0.02673647  	0.19665337  	0.10966471  
2023-05-16 21:37:06.305: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 9.836862]
2023-05-16 21:37:06.625: epoch 127:	0.02677175  	0.19672662  	0.10971037  
2023-05-16 21:37:17.099: [iter 128 : loss : 0.1179 = 0.0281 + 0.0835 + 0.0062, time: 10.472307]
2023-05-16 21:37:17.467: epoch 128:	0.02674353  	0.19628644  	0.10971507  
2023-05-16 21:37:27.600: [iter 129 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 10.127173]
2023-05-16 21:37:27.915: epoch 129:	0.02683526  	0.19731089  	0.10989251  
2023-05-16 21:37:27.915: Find a better model.
2023-05-16 21:37:36.714: [iter 130 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 8.797348]
2023-05-16 21:37:36.902: epoch 130:	0.02684937  	0.19721481  	0.11001609  
2023-05-16 21:37:46.317: [iter 131 : loss : 0.1161 = 0.0265 + 0.0833 + 0.0063, time: 9.414004]
2023-05-16 21:37:46.545: epoch 131:	0.02689171  	0.19758245  	0.11006802  
2023-05-16 21:37:46.545: Find a better model.
2023-05-16 21:37:56.617: [iter 132 : loss : 0.1164 = 0.0267 + 0.0833 + 0.0063, time: 10.057624]
2023-05-16 21:37:56.954: epoch 132:	0.02684231  	0.19758166  	0.11012327  
2023-05-16 21:38:07.348: [iter 133 : loss : 0.1151 = 0.0255 + 0.0833 + 0.0064, time: 10.386844]
2023-05-16 21:38:07.724: epoch 133:	0.02683526  	0.19744495  	0.11001191  
2023-05-16 21:38:18.868: [iter 134 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 11.140532]
2023-05-16 21:38:19.262: epoch 134:	0.02688465  	0.19753660  	0.11021902  
2023-05-16 21:38:28.806: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 9.542233]
2023-05-16 21:38:29.121: epoch 135:	0.02687760  	0.19777800  	0.11025931  
2023-05-16 21:38:29.121: Find a better model.
2023-05-16 21:38:37.314: [iter 136 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 8.190098]
2023-05-16 21:38:37.530: epoch 136:	0.02693405  	0.19786264  	0.11043885  
2023-05-16 21:38:37.531: Find a better model.
2023-05-16 21:38:47.817: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 10.283257]
2023-05-16 21:38:47.986: epoch 137:	0.02699050  	0.19788346  	0.11057173  
2023-05-16 21:38:47.986: Find a better model.
2023-05-16 21:38:58.498: [iter 138 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0065, time: 10.498303]
2023-05-16 21:38:58.860: epoch 138:	0.02698345  	0.19794084  	0.11046589  
2023-05-16 21:38:58.860: Find a better model.
2023-05-16 21:39:09.138: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 10.274714]
2023-05-16 21:39:09.499: epoch 139:	0.02699756  	0.19818084  	0.11060678  
2023-05-16 21:39:09.499: Find a better model.
2023-05-16 21:39:19.857: [iter 140 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 10.352288]
2023-05-16 21:39:20.215: epoch 140:	0.02696228  	0.19787955  	0.11065013  
2023-05-16 21:39:30.013: [iter 141 : loss : 0.1143 = 0.0247 + 0.0829 + 0.0066, time: 9.796513]
2023-05-16 21:39:30.177: epoch 141:	0.02696228  	0.19789110  	0.11058727  
2023-05-16 21:39:38.236: [iter 142 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0066, time: 8.056003]
2023-05-16 21:39:38.410: epoch 142:	0.02701873  	0.19856459  	0.11093438  
2023-05-16 21:39:38.410: Find a better model.
2023-05-16 21:39:48.513: [iter 143 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0067, time: 10.101455]
2023-05-16 21:39:48.718: epoch 143:	0.02705401  	0.19914661  	0.11123867  
2023-05-16 21:39:48.718: Find a better model.
2023-05-16 21:39:59.063: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 10.335741]
2023-05-16 21:39:59.427: epoch 144:	0.02703283  	0.19884245  	0.11125096  
2023-05-16 21:40:09.823: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 10.395483]
2023-05-16 21:40:10.200: epoch 145:	0.02705400  	0.19914241  	0.11147162  
2023-05-16 21:40:20.440: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 10.237889]
2023-05-16 21:40:20.800: epoch 146:	0.02709634  	0.19947185  	0.11162124  
2023-05-16 21:40:20.801: Find a better model.
2023-05-16 21:40:30.410: [iter 147 : loss : 0.1128 = 0.0233 + 0.0827 + 0.0068, time: 9.607995]
2023-05-16 21:40:30.565: epoch 147:	0.02701166  	0.19859818  	0.11130112  
2023-05-16 21:40:39.302: [iter 148 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 8.733410]
2023-05-16 21:40:39.779: epoch 148:	0.02701872  	0.19877928  	0.11116512  
2023-05-16 21:40:49.034: [iter 149 : loss : 0.1118 = 0.0223 + 0.0826 + 0.0068, time: 9.239002]
2023-05-16 21:40:49.189: epoch 149:	0.02703284  	0.19870681  	0.11118221  
2023-05-16 21:40:59.580: [iter 150 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0068, time: 10.388701]
2023-05-16 21:40:59.952: epoch 150:	0.02703284  	0.19872160  	0.11131927  
2023-05-16 21:41:10.377: [iter 151 : loss : 0.1114 = 0.0219 + 0.0826 + 0.0069, time: 10.411009]
2023-05-16 21:41:10.738: epoch 151:	0.02703284  	0.19890620  	0.11144449  
2023-05-16 21:41:20.213: [iter 152 : loss : 0.1108 = 0.0213 + 0.0826 + 0.0069, time: 9.468751]
2023-05-16 21:41:20.576: epoch 152:	0.02699050  	0.19854805  	0.11123236  
2023-05-16 21:41:29.657: [iter 153 : loss : 0.1098 = 0.0203 + 0.0825 + 0.0069, time: 9.079981]
2023-05-16 21:41:29.829: epoch 153:	0.02696933  	0.19831835  	0.11119188  
2023-05-16 21:41:39.410: [iter 154 : loss : 0.1104 = 0.0210 + 0.0825 + 0.0070, time: 9.578994]
2023-05-16 21:41:39.582: epoch 154:	0.02692699  	0.19802615  	0.11104134  
2023-05-16 21:41:49.351: [iter 155 : loss : 0.1111 = 0.0217 + 0.0825 + 0.0070, time: 9.768380]
2023-05-16 21:41:49.646: epoch 155:	0.02694110  	0.19784908  	0.11095384  
2023-05-16 21:41:59.922: [iter 156 : loss : 0.1104 = 0.0209 + 0.0824 + 0.0070, time: 10.272303]
2023-05-16 21:42:00.288: epoch 156:	0.02694110  	0.19791472  	0.11106771  
2023-05-16 21:42:10.715: [iter 157 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 10.423658]
2023-05-16 21:42:11.033: epoch 157:	0.02696932  	0.19782342  	0.11100765  
2023-05-16 21:42:20.267: [iter 158 : loss : 0.1096 = 0.0202 + 0.0824 + 0.0071, time: 9.231997]
2023-05-16 21:42:20.502: epoch 158:	0.02693404  	0.19751652  	0.11113454  
2023-05-16 21:42:29.702: [iter 159 : loss : 0.1097 = 0.0203 + 0.0824 + 0.0071, time: 9.197003]
2023-05-16 21:42:29.867: epoch 159:	0.02691993  	0.19736205  	0.11099129  
2023-05-16 21:42:38.777: [iter 160 : loss : 0.1094 = 0.0199 + 0.0823 + 0.0071, time: 8.908992]
2023-05-16 21:42:38.941: epoch 160:	0.02691993  	0.19752215  	0.11095507  
2023-05-16 21:42:49.093: [iter 161 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0071, time: 10.144736]
2023-05-16 21:42:49.453: epoch 161:	0.02686347  	0.19703922  	0.11069383  
2023-05-16 21:42:59.964: [iter 162 : loss : 0.1082 = 0.0188 + 0.0823 + 0.0072, time: 10.506213]
2023-05-16 21:43:00.329: epoch 162:	0.02693404  	0.19753225  	0.11105222  
2023-05-16 21:43:10.739: [iter 163 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 10.408298]
2023-05-16 21:43:11.103: epoch 163:	0.02699050  	0.19788998  	0.11104269  
2023-05-16 21:43:20.731: [iter 164 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 9.624827]
2023-05-16 21:43:20.929: epoch 164:	0.02696227  	0.19793445  	0.11108439  
2023-05-16 21:43:30.083: [iter 165 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0072, time: 9.150766]
2023-05-16 21:43:30.277: epoch 165:	0.02694110  	0.19790666  	0.11092731  
2023-05-16 21:43:40.462: [iter 166 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 10.174501]
2023-05-16 21:43:40.736: epoch 166:	0.02691288  	0.19766936  	0.11084143  
2023-05-16 21:43:51.198: [iter 167 : loss : 0.1085 = 0.0191 + 0.0821 + 0.0073, time: 10.456071]
2023-05-16 21:43:51.564: epoch 167:	0.02694817  	0.19798271  	0.11091545  
2023-05-16 21:44:01.113: [iter 168 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 9.547601]
2023-05-16 21:44:01.439: epoch 168:	0.02695522  	0.19782080  	0.11095998  
2023-05-16 21:44:09.977: [iter 169 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 8.535902]
2023-05-16 21:44:10.142: epoch 169:	0.02694817  	0.19757795  	0.11106507  
2023-05-16 21:44:19.451: [iter 170 : loss : 0.1076 = 0.0182 + 0.0820 + 0.0073, time: 9.307782]
2023-05-16 21:44:19.604: epoch 170:	0.02699051  	0.19820112  	0.11108770  
2023-05-16 21:44:28.451: [iter 171 : loss : 0.1082 = 0.0188 + 0.0820 + 0.0074, time: 8.837689]
2023-05-16 21:44:28.715: epoch 171:	0.02693405  	0.19772731  	0.11096968  
2023-05-16 21:44:28.715: Early stopping is trigger at epoch: 171
2023-05-16 21:44:28.715: best_result@epoch 146:

2023-05-16 21:44:28.715: 		0.0271      	0.1995      	0.1116      
2023-05-16 21:45:17.028: my pid: 8852
2023-05-16 21:45:17.029: model: model.general_recommender.SGL
2023-05-16 21:45:17.029: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-16 21:45:17.029: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-16 21:45:21.363: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-16 21:45:31.900: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.527781]
2023-05-16 21:45:32.217: epoch 1:	0.00139007  	0.01010901  	0.00520447  
2023-05-16 21:45:32.217: Find a better model.
2023-05-16 21:45:43.143: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 10.922544]
2023-05-16 21:45:43.536: epoch 2:	0.00245555  	0.01815950  	0.00894797  
2023-05-16 21:45:43.537: Find a better model.
2023-05-16 21:45:54.566: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 11.028095]
2023-05-16 21:45:54.748: epoch 3:	0.00454415  	0.03334283  	0.01607583  
2023-05-16 21:45:54.748: Find a better model.
2023-05-16 21:46:05.439: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 10.688174]
2023-05-16 21:46:05.748: epoch 4:	0.00795929  	0.05860250  	0.02799720  
2023-05-16 21:46:05.748: Find a better model.
2023-05-16 21:46:14.032: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 8.281629]
2023-05-16 21:46:14.200: epoch 5:	0.01172033  	0.08448830  	0.04037610  
2023-05-16 21:46:14.200: Find a better model.
2023-05-16 21:46:24.546: [iter 6 : loss : 0.7672 = 0.6880 + 0.0792 + 0.0000, time: 10.341416]
2023-05-16 21:46:24.853: epoch 6:	0.01518503  	0.10924241  	0.05333127  
2023-05-16 21:46:24.853: Find a better model.
2023-05-16 21:46:34.744: [iter 7 : loss : 0.7607 = 0.6807 + 0.0799 + 0.0000, time: 9.889991]
2023-05-16 21:46:34.903: epoch 7:	0.01777473  	0.12910219  	0.06410269  
2023-05-16 21:46:34.903: Find a better model.
2023-05-16 21:46:44.820: [iter 8 : loss : 0.7447 = 0.6628 + 0.0819 + 0.0001, time: 9.914654]
2023-05-16 21:46:45.128: epoch 8:	0.01869913  	0.13713557  	0.06848434  
2023-05-16 21:46:45.128: Find a better model.
2023-05-16 21:46:55.502: [iter 9 : loss : 0.7090 = 0.6232 + 0.0857 + 0.0001, time: 10.369421]
2023-05-16 21:46:55.800: epoch 9:	0.01882615  	0.13834739  	0.06908212  
2023-05-16 21:46:55.800: Find a better model.
2023-05-16 21:47:06.184: [iter 10 : loss : 0.6480 = 0.5567 + 0.0911 + 0.0002, time: 10.383283]
2023-05-16 21:47:06.485: epoch 10:	0.01888261  	0.13915034  	0.06932630  
2023-05-16 21:47:06.486: Find a better model.
2023-05-16 21:47:16.899: [iter 11 : loss : 0.5728 = 0.4764 + 0.0960 + 0.0004, time: 10.411550]
2023-05-16 21:47:17.070: epoch 11:	0.01866386  	0.13814366  	0.06865899  
2023-05-16 21:47:27.697: [iter 12 : loss : 0.5043 = 0.4045 + 0.0993 + 0.0006, time: 10.621998]
2023-05-16 21:47:27.988: epoch 12:	0.01852273  	0.13700438  	0.06841370  
2023-05-16 21:47:38.314: [iter 13 : loss : 0.4539 = 0.3521 + 0.1011 + 0.0007, time: 10.323214]
2023-05-16 21:47:38.705: epoch 13:	0.01875559  	0.13889827  	0.06934801  
2023-05-16 21:47:49.147: [iter 14 : loss : 0.4155 = 0.3126 + 0.1020 + 0.0008, time: 10.438721]
2023-05-16 21:47:49.450: epoch 14:	0.01892495  	0.14042631  	0.07009277  
2023-05-16 21:47:49.450: Find a better model.
2023-05-16 21:47:59.903: [iter 15 : loss : 0.3888 = 0.2854 + 0.1024 + 0.0010, time: 10.451341]
2023-05-16 21:48:00.387: epoch 15:	0.01905196  	0.14142513  	0.07066503  
2023-05-16 21:48:00.387: Find a better model.
2023-05-16 21:48:11.118: [iter 16 : loss : 0.3663 = 0.2628 + 0.1024 + 0.0011, time: 10.719593]
2023-05-16 21:48:11.454: epoch 16:	0.01910136  	0.14136760  	0.07120221  
2023-05-16 21:48:21.256: [iter 17 : loss : 0.3498 = 0.2464 + 0.1022 + 0.0012, time: 9.797750]
2023-05-16 21:48:21.884: epoch 17:	0.01948241  	0.14385872  	0.07232002  
2023-05-16 21:48:21.884: Find a better model.
2023-05-16 21:48:30.857: [iter 18 : loss : 0.3344 = 0.2311 + 0.1019 + 0.0013, time: 8.972001]
2023-05-16 21:48:31.020: epoch 18:	0.01963766  	0.14490958  	0.07313732  
2023-05-16 21:48:31.020: Find a better model.
2023-05-16 21:48:41.228: [iter 19 : loss : 0.3202 = 0.2173 + 0.1016 + 0.0014, time: 10.197501]
2023-05-16 21:48:41.545: epoch 19:	0.01977173  	0.14601597  	0.07400805  
2023-05-16 21:48:41.545: Find a better model.
2023-05-16 21:48:50.381: [iter 20 : loss : 0.3105 = 0.2078 + 0.1012 + 0.0015, time: 8.831468]
2023-05-16 21:48:50.990: epoch 20:	0.02001871  	0.14756393  	0.07486483  
2023-05-16 21:48:50.990: Find a better model.
2023-05-16 21:49:01.133: [iter 21 : loss : 0.3008 = 0.1985 + 0.1008 + 0.0016, time: 10.137582]
2023-05-16 21:49:01.422: epoch 21:	0.02023746  	0.14896488  	0.07570749  
2023-05-16 21:49:01.423: Find a better model.
2023-05-16 21:49:11.415: [iter 22 : loss : 0.2926 = 0.1906 + 0.1004 + 0.0017, time: 9.990996]
2023-05-16 21:49:11.569: epoch 22:	0.02050561  	0.15109983  	0.07649876  
2023-05-16 21:49:11.569: Find a better model.
2023-05-16 21:49:19.657: [iter 23 : loss : 0.2843 = 0.1826 + 0.1000 + 0.0017, time: 8.087205]
2023-05-16 21:49:19.825: epoch 23:	0.02065379  	0.15210719  	0.07721874  
2023-05-16 21:49:19.825: Find a better model.
2023-05-16 21:49:30.273: [iter 24 : loss : 0.2777 = 0.1764 + 0.0995 + 0.0018, time: 10.443844]
2023-05-16 21:49:30.577: epoch 24:	0.02083021  	0.15342127  	0.07793992  
2023-05-16 21:49:30.577: Find a better model.
2023-05-16 21:49:40.384: [iter 25 : loss : 0.2710 = 0.1699 + 0.0992 + 0.0019, time: 9.804993]
2023-05-16 21:49:40.698: epoch 25:	0.02097840  	0.15460075  	0.07874677  
2023-05-16 21:49:40.698: Find a better model.
2023-05-16 21:49:50.729: [iter 26 : loss : 0.2675 = 0.1668 + 0.0987 + 0.0019, time: 10.028532]
2023-05-16 21:49:50.904: epoch 26:	0.02121832  	0.15617764  	0.07970534  
2023-05-16 21:49:50.904: Find a better model.
2023-05-16 21:50:00.846: [iter 27 : loss : 0.2599 = 0.1597 + 0.0982 + 0.0020, time: 9.940003]
2023-05-16 21:50:01.010: epoch 27:	0.02131711  	0.15648217  	0.08020627  
2023-05-16 21:50:01.011: Find a better model.
2023-05-16 21:50:10.075: [iter 28 : loss : 0.2548 = 0.1548 + 0.0979 + 0.0021, time: 9.062238]
2023-05-16 21:50:10.242: epoch 28:	0.02159232  	0.15865012  	0.08138045  
2023-05-16 21:50:10.243: Find a better model.
2023-05-16 21:50:20.087: [iter 29 : loss : 0.2503 = 0.1507 + 0.0975 + 0.0021, time: 9.840562]
2023-05-16 21:50:20.422: epoch 29:	0.02181813  	0.16019751  	0.08201104  
2023-05-16 21:50:20.422: Find a better model.
2023-05-16 21:50:30.712: [iter 30 : loss : 0.2439 = 0.1445 + 0.0971 + 0.0022, time: 10.288678]
2023-05-16 21:50:31.053: epoch 30:	0.02198042  	0.16166568  	0.08269877  
2023-05-16 21:50:31.053: Find a better model.
2023-05-16 21:50:40.813: [iter 31 : loss : 0.2400 = 0.1411 + 0.0967 + 0.0023, time: 9.757680]
2023-05-16 21:50:40.989: epoch 31:	0.02214978  	0.16300638  	0.08340514  
2023-05-16 21:50:40.989: Find a better model.
2023-05-16 21:50:49.869: [iter 32 : loss : 0.2346 = 0.1359 + 0.0964 + 0.0023, time: 8.879055]
2023-05-16 21:50:50.044: epoch 32:	0.02225562  	0.16384614  	0.08406357  
2023-05-16 21:50:50.044: Find a better model.
2023-05-16 21:50:59.742: [iter 33 : loss : 0.2317 = 0.1334 + 0.0959 + 0.0024, time: 9.697272]
2023-05-16 21:50:59.903: epoch 33:	0.02243203  	0.16516177  	0.08472493  
2023-05-16 21:50:59.903: Find a better model.
2023-05-16 21:51:09.756: [iter 34 : loss : 0.2278 = 0.1298 + 0.0956 + 0.0024, time: 9.845079]
2023-05-16 21:51:10.104: epoch 34:	0.02255199  	0.16633740  	0.08551943  
2023-05-16 21:51:10.104: Find a better model.
2023-05-16 21:51:20.441: [iter 35 : loss : 0.2243 = 0.1264 + 0.0954 + 0.0025, time: 10.332058]
2023-05-16 21:51:20.803: epoch 35:	0.02272841  	0.16765274  	0.08640186  
2023-05-16 21:51:20.803: Find a better model.
2023-05-16 21:51:31.033: [iter 36 : loss : 0.2207 = 0.1231 + 0.0950 + 0.0026, time: 10.223999]
2023-05-16 21:51:31.383: epoch 36:	0.02294010  	0.16871749  	0.08706073  
2023-05-16 21:51:31.383: Find a better model.
2023-05-16 21:51:40.935: [iter 37 : loss : 0.2170 = 0.1197 + 0.0947 + 0.0026, time: 9.549714]
2023-05-16 21:51:41.366: epoch 37:	0.02308829  	0.16996653  	0.08782031  
2023-05-16 21:51:41.366: Find a better model.
2023-05-16 21:51:49.456: [iter 38 : loss : 0.2152 = 0.1182 + 0.0944 + 0.0027, time: 8.088460]
2023-05-16 21:51:49.660: epoch 38:	0.02316591  	0.17033623  	0.08817583  
2023-05-16 21:51:49.660: Find a better model.
2023-05-16 21:51:59.950: [iter 39 : loss : 0.2110 = 0.1142 + 0.0941 + 0.0027, time: 10.288028]
2023-05-16 21:52:00.122: epoch 39:	0.02318708  	0.17033729  	0.08841373  
2023-05-16 21:52:00.122: Find a better model.
2023-05-16 21:52:10.616: [iter 40 : loss : 0.2077 = 0.1111 + 0.0938 + 0.0028, time: 10.491798]
2023-05-16 21:52:10.988: epoch 40:	0.02331410  	0.17166710  	0.08901209  
2023-05-16 21:52:10.988: Find a better model.
2023-05-16 21:52:21.316: [iter 41 : loss : 0.2061 = 0.1098 + 0.0935 + 0.0028, time: 10.318990]
2023-05-16 21:52:21.661: epoch 41:	0.02337760  	0.17190893  	0.08947825  
2023-05-16 21:52:21.661: Find a better model.
2023-05-16 21:52:32.073: [iter 42 : loss : 0.2037 = 0.1076 + 0.0932 + 0.0029, time: 10.407990]
2023-05-16 21:52:32.435: epoch 42:	0.02351874  	0.17304862  	0.09006814  
2023-05-16 21:52:32.435: Find a better model.
2023-05-16 21:52:42.029: [iter 43 : loss : 0.1998 = 0.1039 + 0.0929 + 0.0029, time: 9.591991]
2023-05-16 21:52:42.190: epoch 43:	0.02365987  	0.17369930  	0.09076248  
2023-05-16 21:52:42.190: Find a better model.
2023-05-16 21:52:50.340: [iter 44 : loss : 0.1963 = 0.1007 + 0.0926 + 0.0030, time: 8.149041]
2023-05-16 21:52:50.500: epoch 44:	0.02376571  	0.17477536  	0.09136455  
2023-05-16 21:52:50.500: Find a better model.
2023-05-16 21:53:00.372: [iter 45 : loss : 0.1943 = 0.0988 + 0.0925 + 0.0030, time: 9.869447]
2023-05-16 21:53:00.676: epoch 45:	0.02387156  	0.17552830  	0.09188637  
2023-05-16 21:53:00.676: Find a better model.
2023-05-16 21:53:10.988: [iter 46 : loss : 0.1918 = 0.0965 + 0.0922 + 0.0031, time: 10.308157]
2023-05-16 21:53:11.363: epoch 46:	0.02392801  	0.17596173  	0.09228817  
2023-05-16 21:53:11.363: Find a better model.
2023-05-16 21:53:21.639: [iter 47 : loss : 0.1911 = 0.0960 + 0.0919 + 0.0031, time: 10.270934]
2023-05-16 21:53:21.997: epoch 47:	0.02394918  	0.17616011  	0.09272980  
2023-05-16 21:53:21.997: Find a better model.
2023-05-16 21:53:32.337: [iter 48 : loss : 0.1871 = 0.0922 + 0.0917 + 0.0032, time: 10.331512]
2023-05-16 21:53:32.678: epoch 48:	0.02409030  	0.17736065  	0.09336778  
2023-05-16 21:53:32.678: Find a better model.
2023-05-16 21:53:42.553: [iter 49 : loss : 0.1842 = 0.0895 + 0.0915 + 0.0032, time: 9.873537]
2023-05-16 21:53:42.722: epoch 49:	0.02414675  	0.17753513  	0.09370551  
2023-05-16 21:53:42.723: Find a better model.
2023-05-16 21:53:51.606: [iter 50 : loss : 0.1833 = 0.0887 + 0.0913 + 0.0033, time: 8.880999]
2023-05-16 21:53:51.865: epoch 50:	0.02421732  	0.17803212  	0.09399979  
2023-05-16 21:53:51.865: Find a better model.
2023-05-16 21:54:01.608: [iter 51 : loss : 0.1803 = 0.0859 + 0.0911 + 0.0033, time: 9.741991]
2023-05-16 21:54:01.768: epoch 51:	0.02425966  	0.17820105  	0.09448861  
2023-05-16 21:54:01.768: Find a better model.
2023-05-16 21:54:12.027: [iter 52 : loss : 0.1804 = 0.0861 + 0.0909 + 0.0034, time: 10.256738]
2023-05-16 21:54:12.380: epoch 52:	0.02433022  	0.17868525  	0.09498772  
2023-05-16 21:54:12.381: Find a better model.
2023-05-16 21:54:22.882: [iter 53 : loss : 0.1782 = 0.0841 + 0.0907 + 0.0034, time: 10.494995]
2023-05-16 21:54:23.240: epoch 53:	0.02433022  	0.17863478  	0.09519641  
2023-05-16 21:54:32.648: [iter 54 : loss : 0.1759 = 0.0820 + 0.0905 + 0.0035, time: 9.404301]
2023-05-16 21:54:32.997: epoch 54:	0.02441490  	0.17926884  	0.09553060  
2023-05-16 21:54:32.997: Find a better model.
2023-05-16 21:54:42.334: [iter 55 : loss : 0.1741 = 0.0803 + 0.0903 + 0.0035, time: 9.336287]
2023-05-16 21:54:42.503: epoch 55:	0.02442195  	0.17923042  	0.09577700  
2023-05-16 21:54:52.017: [iter 56 : loss : 0.1724 = 0.0788 + 0.0901 + 0.0036, time: 9.512008]
2023-05-16 21:54:52.238: epoch 56:	0.02450663  	0.17977396  	0.09601640  
2023-05-16 21:54:52.239: Find a better model.
2023-05-16 21:55:02.285: [iter 57 : loss : 0.1706 = 0.0771 + 0.0899 + 0.0036, time: 10.043005]
2023-05-16 21:55:02.548: epoch 57:	0.02454897  	0.18016699  	0.09627303  
2023-05-16 21:55:02.548: Find a better model.
2023-05-16 21:55:12.841: [iter 58 : loss : 0.1686 = 0.0752 + 0.0897 + 0.0037, time: 10.288994]
2023-05-16 21:55:13.204: epoch 58:	0.02466893  	0.18085377  	0.09668831  
2023-05-16 21:55:13.204: Find a better model.
2023-05-16 21:55:23.605: [iter 59 : loss : 0.1677 = 0.0744 + 0.0896 + 0.0037, time: 10.399440]
2023-05-16 21:55:23.975: epoch 59:	0.02471127  	0.18122558  	0.09700529  
2023-05-16 21:55:23.975: Find a better model.
2023-05-16 21:55:33.208: [iter 60 : loss : 0.1659 = 0.0728 + 0.0894 + 0.0037, time: 9.232048]
2023-05-16 21:55:33.413: epoch 60:	0.02481006  	0.18223231  	0.09758531  
2023-05-16 21:55:33.413: Find a better model.
2023-05-16 21:55:41.890: [iter 61 : loss : 0.1648 = 0.0717 + 0.0893 + 0.0038, time: 8.476010]
2023-05-16 21:55:42.055: epoch 61:	0.02490885  	0.18285850  	0.09796680  
2023-05-16 21:55:42.055: Find a better model.
2023-05-16 21:55:51.903: [iter 62 : loss : 0.1633 = 0.0704 + 0.0891 + 0.0038, time: 9.846012]
2023-05-16 21:55:52.066: epoch 62:	0.02487357  	0.18279116  	0.09818944  
2023-05-16 21:56:02.231: [iter 63 : loss : 0.1618 = 0.0690 + 0.0889 + 0.0039, time: 10.160192]
2023-05-16 21:56:02.599: epoch 63:	0.02498647  	0.18402375  	0.09873131  
2023-05-16 21:56:02.599: Find a better model.
2023-05-16 21:56:12.943: [iter 64 : loss : 0.1608 = 0.0682 + 0.0887 + 0.0039, time: 10.341440]
2023-05-16 21:56:13.322: epoch 64:	0.02500764  	0.18411712  	0.09905349  
2023-05-16 21:56:13.322: Find a better model.
2023-05-16 21:56:22.833: [iter 65 : loss : 0.1593 = 0.0668 + 0.0886 + 0.0040, time: 9.509709]
2023-05-16 21:56:23.158: epoch 65:	0.02507820  	0.18456934  	0.09931567  
2023-05-16 21:56:23.158: Find a better model.
2023-05-16 21:56:32.874: [iter 66 : loss : 0.1580 = 0.0656 + 0.0884 + 0.0040, time: 9.713932]
2023-05-16 21:56:33.024: epoch 66:	0.02514171  	0.18521313  	0.09974513  
2023-05-16 21:56:33.024: Find a better model.
2023-05-16 21:56:41.920: [iter 67 : loss : 0.1563 = 0.0639 + 0.0883 + 0.0040, time: 8.894992]
2023-05-16 21:56:42.080: epoch 67:	0.02514171  	0.18514678  	0.10009778  
2023-05-16 21:56:51.665: [iter 68 : loss : 0.1560 = 0.0638 + 0.0882 + 0.0041, time: 9.582052]
2023-05-16 21:56:51.981: epoch 68:	0.02520522  	0.18593650  	0.10070779  
2023-05-16 21:56:51.981: Find a better model.
2023-05-16 21:57:02.396: [iter 69 : loss : 0.1542 = 0.0620 + 0.0880 + 0.0041, time: 10.413312]
2023-05-16 21:57:02.740: epoch 69:	0.02528990  	0.18662699  	0.10085104  
2023-05-16 21:57:02.740: Find a better model.
2023-05-16 21:57:12.796: [iter 70 : loss : 0.1525 = 0.0604 + 0.0879 + 0.0042, time: 10.053151]
2023-05-16 21:57:13.112: epoch 70:	0.02532518  	0.18681026  	0.10111427  
2023-05-16 21:57:13.112: Find a better model.
2023-05-16 21:57:21.993: [iter 71 : loss : 0.1511 = 0.0591 + 0.0878 + 0.0042, time: 8.879991]
2023-05-16 21:57:22.164: epoch 71:	0.02543103  	0.18752962  	0.10160004  
2023-05-16 21:57:22.164: Find a better model.
2023-05-16 21:57:32.233: [iter 72 : loss : 0.1507 = 0.0588 + 0.0877 + 0.0043, time: 10.067991]
2023-05-16 21:57:32.456: epoch 72:	0.02545220  	0.18752167  	0.10173292  
2023-05-16 21:57:41.518: [iter 73 : loss : 0.1494 = 0.0576 + 0.0876 + 0.0043, time: 9.060999]
2023-05-16 21:57:41.670: epoch 73:	0.02555099  	0.18841173  	0.10212135  
2023-05-16 21:57:41.670: Find a better model.
2023-05-16 21:57:51.015: [iter 74 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0043, time: 9.342414]
2023-05-16 21:57:51.328: epoch 74:	0.02562861  	0.18929672  	0.10259536  
2023-05-16 21:57:51.328: Find a better model.
2023-05-16 21:58:01.683: [iter 75 : loss : 0.1477 = 0.0560 + 0.0873 + 0.0044, time: 10.349398]
2023-05-16 21:58:02.027: epoch 75:	0.02569212  	0.18929850  	0.10285730  
2023-05-16 21:58:02.027: Find a better model.
2023-05-16 21:58:12.014: [iter 76 : loss : 0.1466 = 0.0550 + 0.0872 + 0.0044, time: 9.984994]
2023-05-16 21:58:12.379: epoch 76:	0.02580502  	0.19015785  	0.10334338  
2023-05-16 21:58:12.379: Find a better model.
2023-05-16 21:58:22.133: [iter 77 : loss : 0.1455 = 0.0540 + 0.0871 + 0.0045, time: 9.752990]
2023-05-16 21:58:22.316: epoch 77:	0.02579091  	0.19005279  	0.10343835  
2023-05-16 21:58:30.454: [iter 78 : loss : 0.1446 = 0.0532 + 0.0869 + 0.0045, time: 8.135999]
2023-05-16 21:58:30.621: epoch 78:	0.02584736  	0.19060795  	0.10352524  
2023-05-16 21:58:30.622: Find a better model.
2023-05-16 21:58:40.410: [iter 79 : loss : 0.1433 = 0.0520 + 0.0868 + 0.0045, time: 9.786147]
2023-05-16 21:58:40.692: epoch 79:	0.02585442  	0.19094349  	0.10381208  
2023-05-16 21:58:40.692: Find a better model.
2023-05-16 21:58:50.906: [iter 80 : loss : 0.1426 = 0.0513 + 0.0868 + 0.0046, time: 10.209793]
2023-05-16 21:58:51.211: epoch 80:	0.02586853  	0.19124597  	0.10395219  
2023-05-16 21:58:51.211: Find a better model.
2023-05-16 21:59:01.595: [iter 81 : loss : 0.1423 = 0.0510 + 0.0866 + 0.0046, time: 10.379443]
2023-05-16 21:59:01.898: epoch 81:	0.02589676  	0.19121623  	0.10405937  
2023-05-16 21:59:12.121: [iter 82 : loss : 0.1409 = 0.0498 + 0.0865 + 0.0047, time: 10.221768]
2023-05-16 21:59:12.302: epoch 82:	0.02593205  	0.19138028  	0.10405258  
2023-05-16 21:59:12.302: Find a better model.
2023-05-16 21:59:20.261: [iter 83 : loss : 0.1402 = 0.0491 + 0.0864 + 0.0047, time: 7.956242]
2023-05-16 21:59:20.516: epoch 83:	0.02598850  	0.19172300  	0.10422237  
2023-05-16 21:59:20.516: Find a better model.
2023-05-16 21:59:30.662: [iter 84 : loss : 0.1400 = 0.0489 + 0.0863 + 0.0047, time: 10.143877]
2023-05-16 21:59:30.954: epoch 84:	0.02604495  	0.19224949  	0.10450889  
2023-05-16 21:59:30.954: Find a better model.
2023-05-16 21:59:40.993: [iter 85 : loss : 0.1389 = 0.0479 + 0.0862 + 0.0048, time: 10.035760]
2023-05-16 21:59:41.380: epoch 85:	0.02601672  	0.19205941  	0.10464876  
2023-05-16 21:59:50.486: [iter 86 : loss : 0.1390 = 0.0481 + 0.0861 + 0.0048, time: 9.104380]
2023-05-16 21:59:50.666: epoch 86:	0.02602377  	0.19225548  	0.10481128  
2023-05-16 21:59:50.666: Find a better model.
2023-05-16 22:00:00.288: [iter 87 : loss : 0.1362 = 0.0453 + 0.0860 + 0.0049, time: 9.620399]
2023-05-16 22:00:00.442: epoch 87:	0.02608729  	0.19251131  	0.10499624  
2023-05-16 22:00:00.442: Find a better model.
2023-05-16 22:00:10.408: [iter 88 : loss : 0.1355 = 0.0446 + 0.0860 + 0.0049, time: 9.961051]
2023-05-16 22:00:10.709: epoch 88:	0.02607317  	0.19240743  	0.10489740  
2023-05-16 22:00:18.551: [iter 89 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0049, time: 7.840755]
2023-05-16 22:00:18.711: epoch 89:	0.02613668  	0.19284956  	0.10512407  
2023-05-16 22:00:18.711: Find a better model.
2023-05-16 22:00:28.879: [iter 90 : loss : 0.1359 = 0.0452 + 0.0858 + 0.0050, time: 10.157368]
2023-05-16 22:00:29.196: epoch 90:	0.02616489  	0.19292499  	0.10552866  
2023-05-16 22:00:29.196: Find a better model.
2023-05-16 22:00:38.111: [iter 91 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0050, time: 8.912992]
2023-05-16 22:00:38.284: epoch 91:	0.02620018  	0.19325264  	0.10578436  
2023-05-16 22:00:38.285: Find a better model.
2023-05-16 22:00:48.188: [iter 92 : loss : 0.1338 = 0.0432 + 0.0856 + 0.0050, time: 9.899989]
2023-05-16 22:00:48.480: epoch 92:	0.02622134  	0.19334163  	0.10575518  
2023-05-16 22:00:48.480: Find a better model.
2023-05-16 22:00:58.574: [iter 93 : loss : 0.1337 = 0.0431 + 0.0855 + 0.0051, time: 10.092727]
2023-05-16 22:00:58.868: epoch 93:	0.02622135  	0.19339593  	0.10579138  
2023-05-16 22:00:58.868: Find a better model.
2023-05-16 22:01:07.563: [iter 94 : loss : 0.1316 = 0.0411 + 0.0855 + 0.0051, time: 8.694012]
2023-05-16 22:01:07.724: epoch 94:	0.02621429  	0.19307321  	0.10561249  
2023-05-16 22:01:17.231: [iter 95 : loss : 0.1310 = 0.0405 + 0.0854 + 0.0051, time: 9.504532]
2023-05-16 22:01:17.508: epoch 95:	0.02625663  	0.19375969  	0.10594377  
2023-05-16 22:01:17.508: Find a better model.
2023-05-16 22:01:26.431: [iter 96 : loss : 0.1309 = 0.0404 + 0.0853 + 0.0052, time: 8.921997]
2023-05-16 22:01:26.591: epoch 96:	0.02624252  	0.19368181  	0.10610195  
2023-05-16 22:01:36.236: [iter 97 : loss : 0.1293 = 0.0389 + 0.0852 + 0.0052, time: 9.642090]
2023-05-16 22:01:36.531: epoch 97:	0.02624251  	0.19349484  	0.10590566  
2023-05-16 22:01:45.380: [iter 98 : loss : 0.1304 = 0.0400 + 0.0851 + 0.0053, time: 8.847437]
2023-05-16 22:01:45.539: epoch 98:	0.02620017  	0.19302857  	0.10577695  
2023-05-16 22:01:54.527: [iter 99 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 8.987005]
2023-05-16 22:01:54.749: epoch 99:	0.02627074  	0.19347064  	0.10621118  
2023-05-16 22:02:04.879: [iter 100 : loss : 0.1288 = 0.0385 + 0.0850 + 0.0053, time: 10.120001]
2023-05-16 22:02:05.199: epoch 100:	0.02634130  	0.19409791  	0.10653052  
2023-05-16 22:02:05.199: Find a better model.
2023-05-16 22:02:13.304: [iter 101 : loss : 0.1282 = 0.0379 + 0.0849 + 0.0054, time: 8.104678]
2023-05-16 22:02:13.465: epoch 101:	0.02639775  	0.19455722  	0.10664692  
2023-05-16 22:02:13.465: Find a better model.
2023-05-16 22:02:23.192: [iter 102 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 9.718630]
2023-05-16 22:02:23.488: epoch 102:	0.02644715  	0.19501100  	0.10691153  
2023-05-16 22:02:23.489: Find a better model.
2023-05-16 22:02:33.009: [iter 103 : loss : 0.1268 = 0.0365 + 0.0848 + 0.0054, time: 9.518358]
2023-05-16 22:02:33.340: epoch 103:	0.02647537  	0.19501528  	0.10678713  
2023-05-16 22:02:33.340: Find a better model.
2023-05-16 22:02:42.511: [iter 104 : loss : 0.1274 = 0.0372 + 0.0847 + 0.0055, time: 9.166991]
2023-05-16 22:02:42.829: epoch 104:	0.02654594  	0.19538841  	0.10716349  
2023-05-16 22:02:42.829: Find a better model.
2023-05-16 22:02:53.315: [iter 105 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 10.482641]
2023-05-16 22:02:53.623: epoch 105:	0.02656005  	0.19561984  	0.10736012  
2023-05-16 22:02:53.623: Find a better model.
2023-05-16 22:03:03.650: [iter 106 : loss : 0.1261 = 0.0360 + 0.0846 + 0.0055, time: 10.025723]
2023-05-16 22:03:03.950: epoch 106:	0.02646831  	0.19494869  	0.10727915  
2023-05-16 22:03:11.606: [iter 107 : loss : 0.1251 = 0.0350 + 0.0845 + 0.0056, time: 7.653993]
2023-05-16 22:03:11.807: epoch 107:	0.02648948  	0.19536655  	0.10733862  
2023-05-16 22:03:21.583: [iter 108 : loss : 0.1250 = 0.0349 + 0.0845 + 0.0056, time: 9.775008]
2023-05-16 22:03:21.745: epoch 108:	0.02661649  	0.19614498  	0.10758527  
2023-05-16 22:03:21.745: Find a better model.
2023-05-16 22:03:32.195: [iter 109 : loss : 0.1237 = 0.0337 + 0.0844 + 0.0056, time: 10.447003]
2023-05-16 22:03:32.474: epoch 109:	0.02657416  	0.19587673  	0.10759518  
2023-05-16 22:03:42.693: [iter 110 : loss : 0.1231 = 0.0331 + 0.0844 + 0.0057, time: 10.216116]
2023-05-16 22:03:43.054: epoch 110:	0.02653181  	0.19549558  	0.10759361  
2023-05-16 22:03:52.203: [iter 111 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 9.145463]
2023-05-16 22:03:52.513: epoch 111:	0.02661649  	0.19617847  	0.10779111  
2023-05-16 22:03:52.513: Find a better model.
2023-05-16 22:04:00.626: [iter 112 : loss : 0.1228 = 0.0328 + 0.0842 + 0.0057, time: 8.110995]
2023-05-16 22:04:00.793: epoch 112:	0.02660238  	0.19591080  	0.10770238  
2023-05-16 22:04:10.375: [iter 113 : loss : 0.1229 = 0.0329 + 0.0842 + 0.0058, time: 9.579991]
2023-05-16 22:04:10.713: epoch 113:	0.02662355  	0.19623055  	0.10789908  
2023-05-16 22:04:10.713: Find a better model.
2023-05-16 22:04:19.897: [iter 114 : loss : 0.1221 = 0.0322 + 0.0841 + 0.0058, time: 9.183008]
2023-05-16 22:04:20.048: epoch 114:	0.02663061  	0.19605862  	0.10794347  
2023-05-16 22:04:29.778: [iter 115 : loss : 0.1216 = 0.0317 + 0.0841 + 0.0058, time: 9.721004]
2023-05-16 22:04:30.137: epoch 115:	0.02663767  	0.19616137  	0.10808583  
2023-05-16 22:04:40.404: [iter 116 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 10.257961]
2023-05-16 22:04:40.778: epoch 116:	0.02663767  	0.19639230  	0.10806613  
2023-05-16 22:04:40.778: Find a better model.
2023-05-16 22:04:49.953: [iter 117 : loss : 0.1207 = 0.0309 + 0.0839 + 0.0059, time: 9.173491]
2023-05-16 22:04:50.218: epoch 117:	0.02658827  	0.19641556  	0.10817748  
2023-05-16 22:04:50.218: Find a better model.
2023-05-16 22:04:59.483: [iter 118 : loss : 0.1204 = 0.0306 + 0.0839 + 0.0059, time: 9.263140]
2023-05-16 22:04:59.718: epoch 118:	0.02665883  	0.19692312  	0.10852835  
2023-05-16 22:04:59.718: Find a better model.
2023-05-16 22:05:08.236: [iter 119 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 8.516014]
2023-05-16 22:05:08.425: epoch 119:	0.02663061  	0.19652294  	0.10843927  
2023-05-16 22:05:17.496: [iter 120 : loss : 0.1199 = 0.0301 + 0.0838 + 0.0060, time: 9.067518]
2023-05-16 22:05:17.661: epoch 120:	0.02660238  	0.19630332  	0.10839143  
2023-05-16 22:05:27.918: [iter 121 : loss : 0.1196 = 0.0298 + 0.0837 + 0.0060, time: 10.254496]
2023-05-16 22:05:28.272: epoch 121:	0.02660944  	0.19635415  	0.10841369  
2023-05-16 22:05:38.481: [iter 122 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 10.202581]
2023-05-16 22:05:38.844: epoch 122:	0.02653182  	0.19602117  	0.10821150  
2023-05-16 22:05:48.693: [iter 123 : loss : 0.1188 = 0.0290 + 0.0837 + 0.0061, time: 9.844989]
2023-05-16 22:05:48.994: epoch 123:	0.02651771  	0.19575866  	0.10821711  
2023-05-16 22:05:58.569: [iter 124 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0061, time: 9.573003]
2023-05-16 22:05:58.746: epoch 124:	0.02654593  	0.19584985  	0.10827787  
2023-05-16 22:06:07.825: [iter 125 : loss : 0.1172 = 0.0275 + 0.0835 + 0.0062, time: 9.076972]
2023-05-16 22:06:08.444: epoch 125:	0.02649654  	0.19533841  	0.10827802  
2023-05-16 22:06:16.857: [iter 126 : loss : 0.1176 = 0.0279 + 0.0835 + 0.0062, time: 8.405015]
2023-05-16 22:06:17.007: epoch 126:	0.02654593  	0.19608517  	0.10835098  
2023-05-16 22:06:27.143: [iter 127 : loss : 0.1165 = 0.0269 + 0.0835 + 0.0062, time: 10.129463]
2023-05-16 22:06:27.502: epoch 127:	0.02655300  	0.19644034  	0.10851774  
2023-05-16 22:06:37.618: [iter 128 : loss : 0.1176 = 0.0279 + 0.0834 + 0.0063, time: 10.109352]
2023-05-16 22:06:37.983: epoch 128:	0.02656006  	0.19618808  	0.10834201  
2023-05-16 22:06:48.079: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 10.092793]
2023-05-16 22:06:48.465: epoch 129:	0.02653182  	0.19598716  	0.10841536  
2023-05-16 22:06:58.138: [iter 130 : loss : 0.1165 = 0.0269 + 0.0833 + 0.0063, time: 9.670729]
2023-05-16 22:06:58.362: epoch 130:	0.02659534  	0.19651808  	0.10862504  
2023-05-16 22:07:06.747: [iter 131 : loss : 0.1158 = 0.0262 + 0.0833 + 0.0063, time: 8.375012]
2023-05-16 22:07:06.951: epoch 131:	0.02654594  	0.19625741  	0.10848771  
2023-05-16 22:07:16.268: [iter 132 : loss : 0.1161 = 0.0265 + 0.0832 + 0.0064, time: 9.314260]
2023-05-16 22:07:16.427: epoch 132:	0.02651066  	0.19621320  	0.10847978  
2023-05-16 22:07:26.717: [iter 133 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0064, time: 10.285926]
2023-05-16 22:07:27.062: epoch 133:	0.02654594  	0.19650438  	0.10862001  
2023-05-16 22:07:37.312: [iter 134 : loss : 0.1155 = 0.0260 + 0.0831 + 0.0064, time: 10.248090]
2023-05-16 22:07:37.675: epoch 134:	0.02657417  	0.19668306  	0.10886160  
2023-05-16 22:07:47.274: [iter 135 : loss : 0.1153 = 0.0257 + 0.0831 + 0.0065, time: 9.596964]
2023-05-16 22:07:47.591: epoch 135:	0.02653889  	0.19653280  	0.10902430  
2023-05-16 22:07:57.086: [iter 136 : loss : 0.1149 = 0.0254 + 0.0831 + 0.0065, time: 9.493358]
2023-05-16 22:07:57.253: epoch 136:	0.02652477  	0.19604626  	0.10882280  
2023-05-16 22:08:05.750: [iter 137 : loss : 0.1146 = 0.0250 + 0.0830 + 0.0065, time: 8.495473]
2023-05-16 22:08:05.921: epoch 137:	0.02648949  	0.19561502  	0.10877872  
2023-05-16 22:08:14.867: [iter 138 : loss : 0.1142 = 0.0246 + 0.0830 + 0.0065, time: 8.945004]
2023-05-16 22:08:15.027: epoch 138:	0.02646832  	0.19520575  	0.10875434  
2023-05-16 22:08:25.248: [iter 139 : loss : 0.1138 = 0.0243 + 0.0830 + 0.0066, time: 10.217269]
2023-05-16 22:08:25.603: epoch 139:	0.02646832  	0.19548960  	0.10891378  
2023-05-16 22:08:35.817: [iter 140 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 10.209992]
2023-05-16 22:08:36.174: epoch 140:	0.02652477  	0.19610244  	0.10911998  
2023-05-16 22:08:45.871: [iter 141 : loss : 0.1139 = 0.0244 + 0.0829 + 0.0066, time: 9.695681]
2023-05-16 22:08:46.044: epoch 141:	0.02644009  	0.19576056  	0.10908750  
2023-05-16 22:08:54.872: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0067, time: 8.826456]
2023-05-16 22:08:55.036: epoch 142:	0.02650360  	0.19599722  	0.10923760  
2023-05-16 22:09:04.669: [iter 143 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 9.631270]
2023-05-16 22:09:04.834: epoch 143:	0.02653889  	0.19622216  	0.10930585  
2023-05-16 22:09:04.835: Early stopping is trigger at epoch: 143
2023-05-16 22:09:04.835: best_result@epoch 118:

2023-05-16 22:09:04.835: 		0.0267      	0.1969      	0.1085      
2023-05-17 09:14:49.163: my pid: 10052
2023-05-17 09:14:49.163: model: model.general_recommender.SGL
2023-05-17 09:14:49.163: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 09:14:49.163: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 09:14:52.520: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 09:15:01.107: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.587390]
2023-05-17 09:15:01.282: epoch 1:	0.00122778  	0.00895395  	0.00429505  
2023-05-17 09:15:01.282: Find a better model.
2023-05-17 09:15:09.955: [iter 2 : loss : 0.7713 = 0.6928 + 0.0785 + 0.0000, time: 8.671212]
2023-05-17 09:15:10.162: epoch 2:	0.00256139  	0.01973354  	0.00935136  
2023-05-17 09:15:10.162: Find a better model.
2023-05-17 09:15:18.804: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.641001]
2023-05-17 09:15:18.975: epoch 3:	0.00505219  	0.03808714  	0.01822203  
2023-05-17 09:15:18.975: Find a better model.
2023-05-17 09:15:27.096: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.120796]
2023-05-17 09:15:27.270: epoch 4:	0.00806513  	0.05995604  	0.02930291  
2023-05-17 09:15:27.270: Find a better model.
2023-05-17 09:15:35.398: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 8.127105]
2023-05-17 09:15:35.546: epoch 5:	0.01166388  	0.08548991  	0.04140510  
2023-05-17 09:15:35.546: Find a better model.
2023-05-17 09:15:43.540: [iter 6 : loss : 0.7672 = 0.6880 + 0.0792 + 0.0000, time: 7.991669]
2023-05-17 09:15:43.687: epoch 6:	0.01548140  	0.11145245  	0.05448484  
2023-05-17 09:15:43.687: Find a better model.
2023-05-17 09:15:51.728: [iter 7 : loss : 0.7608 = 0.6808 + 0.0800 + 0.0000, time: 8.040518]
2023-05-17 09:15:51.889: epoch 7:	0.01795821  	0.12967367  	0.06481913  
2023-05-17 09:15:51.889: Find a better model.
2023-05-17 09:16:00.315: [iter 8 : loss : 0.7449 = 0.6629 + 0.0819 + 0.0001, time: 8.424916]
2023-05-17 09:16:00.469: epoch 8:	0.01892494  	0.13861559  	0.07002889  
2023-05-17 09:16:00.469: Find a better model.
2023-05-17 09:16:08.697: [iter 9 : loss : 0.7090 = 0.6230 + 0.0858 + 0.0001, time: 8.227045]
2023-05-17 09:16:08.843: epoch 9:	0.01900962  	0.14025576  	0.07025371  
2023-05-17 09:16:08.844: Find a better model.
2023-05-17 09:16:16.529: [iter 10 : loss : 0.6474 = 0.5558 + 0.0913 + 0.0002, time: 7.684083]
2023-05-17 09:16:16.678: epoch 10:	0.01868503  	0.13856778  	0.06924330  
2023-05-17 09:16:25.827: [iter 11 : loss : 0.5717 = 0.4750 + 0.0963 + 0.0004, time: 9.145573]
2023-05-17 09:16:26.091: epoch 11:	0.01855095  	0.13759768  	0.06881345  
2023-05-17 09:16:33.948: [iter 12 : loss : 0.5034 = 0.4032 + 0.0996 + 0.0006, time: 7.855741]
2023-05-17 09:16:34.107: epoch 12:	0.01831808  	0.13562973  	0.06830566  
2023-05-17 09:16:42.102: [iter 13 : loss : 0.4535 = 0.3514 + 0.1014 + 0.0007, time: 7.992013]
2023-05-17 09:16:42.258: epoch 13:	0.01851567  	0.13712494  	0.06900086  
2023-05-17 09:16:50.513: [iter 14 : loss : 0.4155 = 0.3123 + 0.1023 + 0.0008, time: 8.254009]
2023-05-17 09:16:50.670: epoch 14:	0.01870619  	0.13852823  	0.06965376  
2023-05-17 09:17:00.102: [iter 15 : loss : 0.3890 = 0.2854 + 0.1027 + 0.0010, time: 9.430779]
2023-05-17 09:17:00.375: epoch 15:	0.01889672  	0.14002803  	0.07044508  
2023-05-17 09:17:09.541: [iter 16 : loss : 0.3667 = 0.2630 + 0.1026 + 0.0011, time: 9.162059]
2023-05-17 09:17:09.810: epoch 16:	0.01901668  	0.14076383  	0.07107504  
2023-05-17 09:17:09.810: Find a better model.
2023-05-17 09:17:17.963: [iter 17 : loss : 0.3502 = 0.2465 + 0.1025 + 0.0012, time: 8.152088]
2023-05-17 09:17:18.184: epoch 17:	0.01927777  	0.14295089  	0.07210398  
2023-05-17 09:17:18.184: Find a better model.
2023-05-17 09:17:25.713: [iter 18 : loss : 0.3351 = 0.2316 + 0.1022 + 0.0013, time: 7.527013]
2023-05-17 09:17:25.871: epoch 18:	0.01941185  	0.14347558  	0.07269374  
2023-05-17 09:17:25.871: Find a better model.
2023-05-17 09:17:34.505: [iter 19 : loss : 0.3210 = 0.2178 + 0.1018 + 0.0014, time: 8.632004]
2023-05-17 09:17:34.687: epoch 19:	0.01963765  	0.14486615  	0.07374536  
2023-05-17 09:17:34.687: Find a better model.
2023-05-17 09:17:43.693: [iter 20 : loss : 0.3110 = 0.2082 + 0.1014 + 0.0015, time: 9.002463]
2023-05-17 09:17:43.992: epoch 20:	0.01989169  	0.14677036  	0.07463061  
2023-05-17 09:17:43.992: Find a better model.
2023-05-17 09:17:53.078: [iter 21 : loss : 0.3014 = 0.1989 + 0.1010 + 0.0016, time: 9.084009]
2023-05-17 09:17:53.258: epoch 21:	0.02002577  	0.14799440  	0.07521301  
2023-05-17 09:17:53.258: Find a better model.
2023-05-17 09:18:01.280: [iter 22 : loss : 0.2930 = 0.1908 + 0.1006 + 0.0016, time: 8.019635]
2023-05-17 09:18:01.445: epoch 22:	0.02023746  	0.14909573  	0.07563508  
2023-05-17 09:18:01.446: Find a better model.
2023-05-17 09:18:09.835: [iter 23 : loss : 0.2848 = 0.1830 + 0.1001 + 0.0017, time: 8.385992]
2023-05-17 09:18:10.180: epoch 23:	0.02048444  	0.15095267  	0.07647401  
2023-05-17 09:18:10.180: Find a better model.
2023-05-17 09:18:17.884: [iter 24 : loss : 0.2781 = 0.1766 + 0.0997 + 0.0018, time: 7.703016]
2023-05-17 09:18:18.041: epoch 24:	0.02058323  	0.15169126  	0.07724710  
2023-05-17 09:18:18.041: Find a better model.
2023-05-17 09:18:27.060: [iter 25 : loss : 0.2714 = 0.1702 + 0.0993 + 0.0019, time: 9.015246]
2023-05-17 09:18:27.359: epoch 25:	0.02075259  	0.15242280  	0.07788853  
2023-05-17 09:18:27.360: Find a better model.
2023-05-17 09:18:34.722: [iter 26 : loss : 0.2677 = 0.1670 + 0.0988 + 0.0019, time: 7.361022]
2023-05-17 09:18:34.883: epoch 26:	0.02090783  	0.15355970  	0.07854120  
2023-05-17 09:18:34.883: Find a better model.
2023-05-17 09:18:43.083: [iter 27 : loss : 0.2600 = 0.1595 + 0.0984 + 0.0020, time: 8.199011]
2023-05-17 09:18:43.231: epoch 27:	0.02109836  	0.15475835  	0.07936777  
2023-05-17 09:18:43.231: Find a better model.
2023-05-17 09:18:51.622: [iter 28 : loss : 0.2552 = 0.1551 + 0.0980 + 0.0021, time: 8.390013]
2023-05-17 09:18:51.779: epoch 28:	0.02133122  	0.15649809  	0.08039540  
2023-05-17 09:18:51.779: Find a better model.
2023-05-17 09:18:59.451: [iter 29 : loss : 0.2507 = 0.1510 + 0.0976 + 0.0021, time: 7.670006]
2023-05-17 09:18:59.610: epoch 29:	0.02140179  	0.15702337  	0.08072072  
2023-05-17 09:18:59.610: Find a better model.
2023-05-17 09:19:08.711: [iter 30 : loss : 0.2442 = 0.1448 + 0.0973 + 0.0022, time: 9.097861]
2023-05-17 09:19:09.006: epoch 30:	0.02165582  	0.15915087  	0.08171416  
2023-05-17 09:19:09.006: Find a better model.
2023-05-17 09:19:16.727: [iter 31 : loss : 0.2404 = 0.1414 + 0.0968 + 0.0023, time: 7.719434]
2023-05-17 09:19:16.880: epoch 31:	0.02176872  	0.16023356  	0.08239100  
2023-05-17 09:19:16.880: Find a better model.
2023-05-17 09:19:24.834: [iter 32 : loss : 0.2348 = 0.1360 + 0.0965 + 0.0023, time: 7.952142]
2023-05-17 09:19:24.989: epoch 32:	0.02204392  	0.16243650  	0.08339041  
2023-05-17 09:19:24.990: Find a better model.
2023-05-17 09:19:33.250: [iter 33 : loss : 0.2321 = 0.1336 + 0.0961 + 0.0024, time: 8.258411]
2023-05-17 09:19:33.541: epoch 33:	0.02224151  	0.16410454  	0.08416450  
2023-05-17 09:19:33.541: Find a better model.
2023-05-17 09:19:42.553: [iter 34 : loss : 0.2283 = 0.1301 + 0.0958 + 0.0024, time: 9.008538]
2023-05-17 09:19:42.815: epoch 34:	0.02234030  	0.16473591  	0.08486746  
2023-05-17 09:19:42.815: Find a better model.
2023-05-17 09:19:51.968: [iter 35 : loss : 0.2246 = 0.1267 + 0.0954 + 0.0025, time: 9.149089]
2023-05-17 09:19:52.273: epoch 35:	0.02246731  	0.16581419  	0.08551131  
2023-05-17 09:19:52.273: Find a better model.
2023-05-17 09:20:00.353: [iter 36 : loss : 0.2211 = 0.1234 + 0.0951 + 0.0025, time: 8.076952]
2023-05-17 09:20:00.503: epoch 36:	0.02267195  	0.16737366  	0.08639020  
2023-05-17 09:20:00.503: Find a better model.
2023-05-17 09:20:08.038: [iter 37 : loss : 0.2174 = 0.1200 + 0.0948 + 0.0026, time: 7.534015]
2023-05-17 09:20:08.199: epoch 37:	0.02277074  	0.16834573  	0.08687197  
2023-05-17 09:20:08.199: Find a better model.
2023-05-17 09:20:16.691: [iter 38 : loss : 0.2160 = 0.1189 + 0.0945 + 0.0027, time: 8.490658]
2023-05-17 09:20:16.855: epoch 38:	0.02293303  	0.16982415  	0.08761642  
2023-05-17 09:20:16.856: Find a better model.
2023-05-17 09:20:26.029: [iter 39 : loss : 0.2113 = 0.1144 + 0.0942 + 0.0027, time: 9.171189]
2023-05-17 09:20:26.294: epoch 39:	0.02300360  	0.17014460  	0.08818246  
2023-05-17 09:20:26.294: Find a better model.
2023-05-17 09:20:35.436: [iter 40 : loss : 0.2082 = 0.1115 + 0.0939 + 0.0028, time: 9.139921]
2023-05-17 09:20:35.732: epoch 40:	0.02307417  	0.17055142  	0.08882932  
2023-05-17 09:20:35.732: Find a better model.
2023-05-17 09:20:43.832: [iter 41 : loss : 0.2064 = 0.1100 + 0.0936 + 0.0028, time: 8.097073]
2023-05-17 09:20:43.993: epoch 41:	0.02333526  	0.17225406  	0.08974427  
2023-05-17 09:20:43.994: Find a better model.
2023-05-17 09:20:51.942: [iter 42 : loss : 0.2042 = 0.1080 + 0.0933 + 0.0029, time: 7.946006]
2023-05-17 09:20:52.300: epoch 42:	0.02340583  	0.17276481  	0.09027584  
2023-05-17 09:20:52.300: Find a better model.
2023-05-17 09:21:00.393: [iter 43 : loss : 0.2000 = 0.1041 + 0.0930 + 0.0029, time: 8.091025]
2023-05-17 09:21:00.548: epoch 43:	0.02348345  	0.17311285  	0.09080938  
2023-05-17 09:21:00.549: Find a better model.
2023-05-17 09:21:09.786: [iter 44 : loss : 0.1967 = 0.1010 + 0.0928 + 0.0030, time: 9.236341]
2023-05-17 09:21:10.084: epoch 44:	0.02363869  	0.17440574  	0.09165593  
2023-05-17 09:21:10.084: Find a better model.
2023-05-17 09:21:17.611: [iter 45 : loss : 0.1947 = 0.0991 + 0.0926 + 0.0030, time: 7.525717]
2023-05-17 09:21:17.773: epoch 45:	0.02378688  	0.17536755  	0.09235238  
2023-05-17 09:21:17.774: Find a better model.
2023-05-17 09:21:26.005: [iter 46 : loss : 0.1921 = 0.0968 + 0.0923 + 0.0031, time: 8.230175]
2023-05-17 09:21:26.163: epoch 46:	0.02373748  	0.17477959  	0.09240999  
2023-05-17 09:21:34.586: [iter 47 : loss : 0.1917 = 0.0965 + 0.0920 + 0.0031, time: 8.422006]
2023-05-17 09:21:34.744: epoch 47:	0.02389272  	0.17575414  	0.09297266  
2023-05-17 09:21:34.744: Find a better model.
2023-05-17 09:21:42.431: [iter 48 : loss : 0.1875 = 0.0925 + 0.0919 + 0.0032, time: 7.686023]
2023-05-17 09:21:42.592: epoch 48:	0.02394918  	0.17604715  	0.09323028  
2023-05-17 09:21:42.592: Find a better model.
2023-05-17 09:21:51.823: [iter 49 : loss : 0.1845 = 0.0896 + 0.0916 + 0.0032, time: 9.228011]
2023-05-17 09:21:52.124: epoch 49:	0.02399857  	0.17629929  	0.09362565  
2023-05-17 09:21:52.124: Find a better model.
2023-05-17 09:22:00.238: [iter 50 : loss : 0.1836 = 0.0890 + 0.0914 + 0.0033, time: 8.112992]
2023-05-17 09:22:00.450: epoch 50:	0.02407619  	0.17720760  	0.09410595  
2023-05-17 09:22:00.450: Find a better model.
2023-05-17 09:22:08.431: [iter 51 : loss : 0.1806 = 0.0861 + 0.0912 + 0.0033, time: 7.980034]
2023-05-17 09:22:08.593: epoch 51:	0.02418909  	0.17842263  	0.09446147  
2023-05-17 09:22:08.593: Find a better model.
2023-05-17 09:22:17.247: [iter 52 : loss : 0.1804 = 0.0861 + 0.0910 + 0.0034, time: 8.652011]
2023-05-17 09:22:17.400: epoch 52:	0.02426672  	0.17868161  	0.09489742  
2023-05-17 09:22:17.400: Find a better model.
2023-05-17 09:22:26.602: [iter 53 : loss : 0.1788 = 0.0846 + 0.0907 + 0.0034, time: 9.200038]
2023-05-17 09:22:26.901: epoch 53:	0.02444312  	0.18044145  	0.09567294  
2023-05-17 09:22:26.901: Find a better model.
2023-05-17 09:22:36.107: [iter 54 : loss : 0.1764 = 0.0823 + 0.0906 + 0.0035, time: 9.204372]
2023-05-17 09:22:36.409: epoch 54:	0.02454897  	0.18113095  	0.09593227  
2023-05-17 09:22:36.409: Find a better model.
2023-05-17 09:22:44.782: [iter 55 : loss : 0.1746 = 0.0807 + 0.0904 + 0.0035, time: 8.372344]
2023-05-17 09:22:44.941: epoch 55:	0.02461953  	0.18201424  	0.09653736  
2023-05-17 09:22:44.941: Find a better model.
2023-05-17 09:22:53.035: [iter 56 : loss : 0.1727 = 0.0789 + 0.0902 + 0.0035, time: 8.092006]
2023-05-17 09:22:53.210: epoch 56:	0.02464776  	0.18196093  	0.09695552  
2023-05-17 09:23:01.339: [iter 57 : loss : 0.1710 = 0.0773 + 0.0900 + 0.0036, time: 8.127252]
2023-05-17 09:23:01.493: epoch 57:	0.02475362  	0.18297137  	0.09724453  
2023-05-17 09:23:01.493: Find a better model.
2023-05-17 09:23:10.782: [iter 58 : loss : 0.1690 = 0.0755 + 0.0899 + 0.0036, time: 9.287158]
2023-05-17 09:23:11.076: epoch 58:	0.02485240  	0.18356542  	0.09756922  
2023-05-17 09:23:11.077: Find a better model.
2023-05-17 09:23:18.581: [iter 59 : loss : 0.1681 = 0.0748 + 0.0897 + 0.0037, time: 7.503258]
2023-05-17 09:23:18.743: epoch 59:	0.02482417  	0.18356052  	0.09775095  
2023-05-17 09:23:27.181: [iter 60 : loss : 0.1666 = 0.0733 + 0.0895 + 0.0037, time: 8.437017]
2023-05-17 09:23:27.329: epoch 60:	0.02490179  	0.18370655  	0.09802589  
2023-05-17 09:23:27.329: Find a better model.
2023-05-17 09:23:35.776: [iter 61 : loss : 0.1652 = 0.0721 + 0.0893 + 0.0038, time: 8.445992]
2023-05-17 09:23:35.934: epoch 61:	0.02495825  	0.18417011  	0.09843402  
2023-05-17 09:23:35.934: Find a better model.
2023-05-17 09:23:43.788: [iter 62 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 7.852034]
2023-05-17 09:23:44.006: epoch 62:	0.02499352  	0.18438023  	0.09867714  
2023-05-17 09:23:44.006: Find a better model.
2023-05-17 09:23:53.337: [iter 63 : loss : 0.1620 = 0.0691 + 0.0890 + 0.0039, time: 9.327101]
2023-05-17 09:23:53.640: epoch 63:	0.02513465  	0.18519717  	0.09921314  
2023-05-17 09:23:53.640: Find a better model.
2023-05-17 09:24:01.848: [iter 64 : loss : 0.1612 = 0.0685 + 0.0888 + 0.0039, time: 8.207007]
2023-05-17 09:24:02.238: epoch 64:	0.02520522  	0.18614052  	0.09967853  
2023-05-17 09:24:02.239: Find a better model.
2023-05-17 09:24:09.996: [iter 65 : loss : 0.1599 = 0.0672 + 0.0887 + 0.0039, time: 7.755415]
2023-05-17 09:24:10.178: epoch 65:	0.02521933  	0.18620124  	0.09992328  
2023-05-17 09:24:10.178: Find a better model.
2023-05-17 09:24:18.655: [iter 66 : loss : 0.1582 = 0.0657 + 0.0885 + 0.0040, time: 8.475014]
2023-05-17 09:24:18.821: epoch 66:	0.02523345  	0.18626860  	0.10023683  
2023-05-17 09:24:18.821: Find a better model.
2023-05-17 09:24:27.973: [iter 67 : loss : 0.1568 = 0.0643 + 0.0884 + 0.0040, time: 9.151027]
2023-05-17 09:24:28.276: epoch 67:	0.02524050  	0.18618073  	0.10036668  
2023-05-17 09:24:37.489: [iter 68 : loss : 0.1567 = 0.0643 + 0.0883 + 0.0041, time: 9.209023]
2023-05-17 09:24:37.780: epoch 68:	0.02523344  	0.18615152  	0.10065413  
2023-05-17 09:24:46.114: [iter 69 : loss : 0.1547 = 0.0624 + 0.0881 + 0.0041, time: 8.332992]
2023-05-17 09:24:46.272: epoch 69:	0.02521227  	0.18608627  	0.10082486  
2023-05-17 09:24:54.168: [iter 70 : loss : 0.1530 = 0.0608 + 0.0880 + 0.0042, time: 7.894002]
2023-05-17 09:24:54.325: epoch 70:	0.02524049  	0.18618481  	0.10082682  
2023-05-17 09:25:02.495: [iter 71 : loss : 0.1516 = 0.0595 + 0.0879 + 0.0042, time: 8.168018]
2023-05-17 09:25:02.650: epoch 71:	0.02536045  	0.18715872  	0.10137256  
2023-05-17 09:25:02.650: Find a better model.
2023-05-17 09:25:11.836: [iter 72 : loss : 0.1512 = 0.0592 + 0.0877 + 0.0042, time: 9.183414]
2023-05-17 09:25:12.118: epoch 72:	0.02535340  	0.18707108  	0.10161725  
2023-05-17 09:25:19.565: [iter 73 : loss : 0.1498 = 0.0579 + 0.0876 + 0.0043, time: 7.446031]
2023-05-17 09:25:19.730: epoch 73:	0.02534635  	0.18699464  	0.10183652  
2023-05-17 09:25:28.140: [iter 74 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0043, time: 8.409002]
2023-05-17 09:25:28.299: epoch 74:	0.02545220  	0.18761931  	0.10232401  
2023-05-17 09:25:28.299: Find a better model.
2023-05-17 09:25:36.685: [iter 75 : loss : 0.1481 = 0.0563 + 0.0874 + 0.0044, time: 8.385151]
2023-05-17 09:25:36.844: epoch 75:	0.02550159  	0.18835855  	0.10260280  
2023-05-17 09:25:36.845: Find a better model.
2023-05-17 09:25:44.720: [iter 76 : loss : 0.1471 = 0.0554 + 0.0873 + 0.0044, time: 7.873996]
2023-05-17 09:25:44.876: epoch 76:	0.02551570  	0.18843557  	0.10283352  
2023-05-17 09:25:44.876: Find a better model.
2023-05-17 09:25:53.992: [iter 77 : loss : 0.1458 = 0.0542 + 0.0871 + 0.0044, time: 9.112477]
2023-05-17 09:25:54.284: epoch 77:	0.02555098  	0.18861413  	0.10292701  
2023-05-17 09:25:54.284: Find a better model.
2023-05-17 09:26:01.763: [iter 78 : loss : 0.1450 = 0.0535 + 0.0870 + 0.0045, time: 7.478077]
2023-05-17 09:26:01.922: epoch 78:	0.02559333  	0.18880516  	0.10297271  
2023-05-17 09:26:01.922: Find a better model.
2023-05-17 09:26:09.874: [iter 79 : loss : 0.1438 = 0.0523 + 0.0869 + 0.0045, time: 7.950043]
2023-05-17 09:26:10.030: epoch 79:	0.02562861  	0.18921719  	0.10331421  
2023-05-17 09:26:10.030: Find a better model.
2023-05-17 09:26:18.461: [iter 80 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 8.430009]
2023-05-17 09:26:18.619: epoch 80:	0.02557216  	0.18860836  	0.10329159  
2023-05-17 09:26:26.909: [iter 81 : loss : 0.1427 = 0.0514 + 0.0867 + 0.0046, time: 8.288020]
2023-05-17 09:26:27.202: epoch 81:	0.02558627  	0.18867457  	0.10342567  
2023-05-17 09:26:36.526: [iter 82 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 9.322366]
2023-05-17 09:26:36.814: epoch 82:	0.02570623  	0.18932459  	0.10371491  
2023-05-17 09:26:36.814: Find a better model.
2023-05-17 09:26:45.102: [iter 83 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 8.286995]
2023-05-17 09:26:45.270: epoch 83:	0.02572034  	0.18980256  	0.10404046  
2023-05-17 09:26:45.271: Find a better model.
2023-05-17 09:26:52.940: [iter 84 : loss : 0.1404 = 0.0492 + 0.0864 + 0.0047, time: 7.668004]
2023-05-17 09:26:53.127: epoch 84:	0.02572740  	0.18969974  	0.10394294  
2023-05-17 09:27:01.726: [iter 85 : loss : 0.1394 = 0.0483 + 0.0863 + 0.0048, time: 8.597221]
2023-05-17 09:27:01.895: epoch 85:	0.02576974  	0.18999206  	0.10428416  
2023-05-17 09:27:01.895: Find a better model.
2023-05-17 09:27:11.030: [iter 86 : loss : 0.1394 = 0.0484 + 0.0862 + 0.0048, time: 9.132037]
2023-05-17 09:27:11.314: epoch 86:	0.02580502  	0.19044103  	0.10439987  
2023-05-17 09:27:11.314: Find a better model.
2023-05-17 09:27:20.714: [iter 87 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0048, time: 9.398038]
2023-05-17 09:27:21.000: epoch 87:	0.02586853  	0.19086939  	0.10455396  
2023-05-17 09:27:21.000: Find a better model.
2023-05-17 09:27:29.281: [iter 88 : loss : 0.1358 = 0.0449 + 0.0861 + 0.0049, time: 8.279993]
2023-05-17 09:27:29.449: epoch 88:	0.02593204  	0.19121985  	0.10467716  
2023-05-17 09:27:29.449: Find a better model.
2023-05-17 09:27:37.612: [iter 89 : loss : 0.1356 = 0.0447 + 0.0860 + 0.0049, time: 8.159993]
2023-05-17 09:27:37.930: epoch 89:	0.02603083  	0.19211449  	0.10505019  
2023-05-17 09:27:37.930: Find a better model.
2023-05-17 09:27:46.078: [iter 90 : loss : 0.1361 = 0.0453 + 0.0859 + 0.0049, time: 8.147026]
2023-05-17 09:27:46.233: epoch 90:	0.02605200  	0.19231211  	0.10524664  
2023-05-17 09:27:46.234: Find a better model.
2023-05-17 09:27:55.512: [iter 91 : loss : 0.1349 = 0.0441 + 0.0858 + 0.0050, time: 9.277110]
2023-05-17 09:27:55.817: epoch 91:	0.02610140  	0.19267876  	0.10547431  
2023-05-17 09:27:55.817: Find a better model.
2023-05-17 09:28:03.318: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 7.500169]
2023-05-17 09:28:03.479: epoch 92:	0.02612257  	0.19276975  	0.10548636  
2023-05-17 09:28:03.479: Find a better model.
2023-05-17 09:28:11.860: [iter 93 : loss : 0.1341 = 0.0434 + 0.0856 + 0.0051, time: 8.379013]
2023-05-17 09:28:12.015: epoch 93:	0.02612963  	0.19273454  	0.10566376  
2023-05-17 09:28:20.637: [iter 94 : loss : 0.1320 = 0.0414 + 0.0855 + 0.0051, time: 8.619368]
2023-05-17 09:28:20.794: epoch 94:	0.02605906  	0.19225195  	0.10554060  
2023-05-17 09:28:28.662: [iter 95 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 7.866027]
2023-05-17 09:28:28.929: epoch 95:	0.02605906  	0.19219260  	0.10576236  
2023-05-17 09:28:38.212: [iter 96 : loss : 0.1316 = 0.0410 + 0.0854 + 0.0052, time: 9.280105]
2023-05-17 09:28:38.480: epoch 96:	0.02606611  	0.19242953  	0.10577594  
2023-05-17 09:28:46.576: [iter 97 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0052, time: 8.094359]
2023-05-17 09:28:46.764: epoch 97:	0.02605200  	0.19216254  	0.10582545  
2023-05-17 09:28:54.463: [iter 98 : loss : 0.1308 = 0.0403 + 0.0853 + 0.0052, time: 7.685514]
2023-05-17 09:28:54.626: epoch 98:	0.02618608  	0.19314681  	0.10626241  
2023-05-17 09:28:54.626: Find a better model.
2023-05-17 09:29:03.430: [iter 99 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0053, time: 8.802025]
2023-05-17 09:29:03.595: epoch 99:	0.02625665  	0.19353963  	0.10638240  
2023-05-17 09:29:03.596: Find a better model.
2023-05-17 09:29:12.744: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 9.144065]
2023-05-17 09:29:13.035: epoch 100:	0.02623547  	0.19352329  	0.10640711  
2023-05-17 09:29:22.203: [iter 101 : loss : 0.1284 = 0.0380 + 0.0850 + 0.0053, time: 9.157043]
2023-05-17 09:29:22.489: epoch 101:	0.02621430  	0.19343756  	0.10639355  
2023-05-17 09:29:30.670: [iter 102 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 8.179993]
2023-05-17 09:29:30.836: epoch 102:	0.02627781  	0.19379276  	0.10660879  
2023-05-17 09:29:30.836: Find a better model.
2023-05-17 09:29:38.632: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 7.793006]
2023-05-17 09:29:38.792: epoch 103:	0.02615079  	0.19263944  	0.10622115  
2023-05-17 09:29:47.055: [iter 104 : loss : 0.1277 = 0.0375 + 0.0848 + 0.0055, time: 8.262003]
2023-05-17 09:29:47.214: epoch 104:	0.02620725  	0.19293611  	0.10643354  
2023-05-17 09:29:56.363: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 9.144022]
2023-05-17 09:29:56.632: epoch 105:	0.02621431  	0.19304493  	0.10652367  
2023-05-17 09:30:04.548: [iter 106 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 7.914880]
2023-05-17 09:30:04.714: epoch 106:	0.02616491  	0.19272834  	0.10654137  
2023-05-17 09:30:13.263: [iter 107 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0055, time: 8.546003]
2023-05-17 09:30:13.418: epoch 107:	0.02618608  	0.19260292  	0.10662556  
2023-05-17 09:30:21.865: [iter 108 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 8.445003]
2023-05-17 09:30:22.039: epoch 108:	0.02615079  	0.19227560  	0.10658042  
2023-05-17 09:30:29.837: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 7.796004]
2023-05-17 09:30:29.995: epoch 109:	0.02624958  	0.19311933  	0.10680490  
2023-05-17 09:30:39.260: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 9.261291]
2023-05-17 09:30:39.560: epoch 110:	0.02627075  	0.19313632  	0.10681452  
2023-05-17 09:30:47.511: [iter 111 : loss : 0.1233 = 0.0333 + 0.0844 + 0.0057, time: 7.950005]
2023-05-17 09:30:47.748: epoch 111:	0.02621430  	0.19265412  	0.10676394  
2023-05-17 09:30:55.618: [iter 112 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0057, time: 7.869004]
2023-05-17 09:30:55.785: epoch 112:	0.02624253  	0.19290462  	0.10703627  
2023-05-17 09:31:04.339: [iter 113 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0058, time: 8.551992]
2023-05-17 09:31:04.488: epoch 113:	0.02632720  	0.19344886  	0.10730276  
2023-05-17 09:31:13.705: [iter 114 : loss : 0.1225 = 0.0325 + 0.0842 + 0.0058, time: 9.212024]
2023-05-17 09:31:13.997: epoch 114:	0.02632720  	0.19347747  	0.10723956  
2023-05-17 09:31:23.203: [iter 115 : loss : 0.1218 = 0.0318 + 0.0841 + 0.0058, time: 9.202990]
2023-05-17 09:31:23.492: epoch 115:	0.02628486  	0.19288863  	0.10730107  
2023-05-17 09:31:31.707: [iter 116 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 8.213017]
2023-05-17 09:31:31.908: epoch 116:	0.02622841  	0.19272161  	0.10738937  
2023-05-17 09:31:39.373: [iter 117 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0059, time: 7.464008]
2023-05-17 09:31:39.530: epoch 117:	0.02634132  	0.19342916  	0.10781870  
2023-05-17 09:31:48.004: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.473190]
2023-05-17 09:31:48.234: epoch 118:	0.02636955  	0.19403742  	0.10795645  
2023-05-17 09:31:48.234: Find a better model.
2023-05-17 09:31:57.450: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 9.213212]
2023-05-17 09:31:57.744: epoch 119:	0.02636955  	0.19410053  	0.10792099  
2023-05-17 09:31:57.745: Find a better model.
2023-05-17 09:32:06.621: [iter 120 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 8.875037]
2023-05-17 09:32:06.799: epoch 120:	0.02639071  	0.19434376  	0.10815742  
2023-05-17 09:32:06.799: Find a better model.
2023-05-17 09:32:15.434: [iter 121 : loss : 0.1200 = 0.0301 + 0.0838 + 0.0060, time: 8.633021]
2023-05-17 09:32:15.601: epoch 121:	0.02636954  	0.19400096  	0.10807560  
2023-05-17 09:32:24.038: [iter 122 : loss : 0.1191 = 0.0292 + 0.0838 + 0.0060, time: 8.436013]
2023-05-17 09:32:24.247: epoch 122:	0.02636954  	0.19385064  	0.10818571  
2023-05-17 09:32:32.017: [iter 123 : loss : 0.1194 = 0.0296 + 0.0837 + 0.0061, time: 7.767582]
2023-05-17 09:32:32.174: epoch 123:	0.02635543  	0.19369854  	0.10818748  
2023-05-17 09:32:41.429: [iter 124 : loss : 0.1184 = 0.0287 + 0.0837 + 0.0061, time: 9.252526]
2023-05-17 09:32:41.721: epoch 124:	0.02635542  	0.19386847  	0.10804739  
2023-05-17 09:32:49.189: [iter 125 : loss : 0.1175 = 0.0277 + 0.0836 + 0.0061, time: 7.457937]
2023-05-17 09:32:49.349: epoch 125:	0.02638366  	0.19405165  	0.10812173  
2023-05-17 09:32:57.355: [iter 126 : loss : 0.1180 = 0.0282 + 0.0836 + 0.0062, time: 8.005022]
2023-05-17 09:32:57.510: epoch 126:	0.02644717  	0.19464992  	0.10841545  
2023-05-17 09:32:57.510: Find a better model.
2023-05-17 09:33:05.940: [iter 127 : loss : 0.1168 = 0.0271 + 0.0835 + 0.0062, time: 8.429013]
2023-05-17 09:33:06.099: epoch 127:	0.02641894  	0.19431004  	0.10840253  
2023-05-17 09:33:13.747: [iter 128 : loss : 0.1179 = 0.0281 + 0.0835 + 0.0062, time: 7.647017]
2023-05-17 09:33:13.904: epoch 128:	0.02639777  	0.19425766  	0.10840525  
2023-05-17 09:33:23.078: [iter 129 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 9.171004]
2023-05-17 09:33:23.380: epoch 129:	0.02648244  	0.19525431  	0.10879143  
2023-05-17 09:33:23.380: Find a better model.
2023-05-17 09:33:31.105: [iter 130 : loss : 0.1169 = 0.0273 + 0.0834 + 0.0063, time: 7.722655]
2023-05-17 09:33:31.272: epoch 130:	0.02648950  	0.19509614  	0.10880878  
2023-05-17 09:33:39.114: [iter 131 : loss : 0.1161 = 0.0265 + 0.0833 + 0.0063, time: 7.839998]
2023-05-17 09:33:39.273: epoch 131:	0.02653184  	0.19543755  	0.10885469  
2023-05-17 09:33:39.273: Find a better model.
2023-05-17 09:33:47.330: [iter 132 : loss : 0.1165 = 0.0269 + 0.0833 + 0.0063, time: 8.055183]
2023-05-17 09:33:47.487: epoch 132:	0.02648950  	0.19498941  	0.10876618  
2023-05-17 09:33:56.853: [iter 133 : loss : 0.1151 = 0.0255 + 0.0833 + 0.0064, time: 9.364032]
2023-05-17 09:33:57.133: epoch 133:	0.02646127  	0.19459590  	0.10869060  
2023-05-17 09:34:06.192: [iter 134 : loss : 0.1159 = 0.0263 + 0.0832 + 0.0064, time: 9.056431]
2023-05-17 09:34:06.483: epoch 134:	0.02641893  	0.19428663  	0.10861599  
2023-05-17 09:34:14.780: [iter 135 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 8.295958]
2023-05-17 09:34:14.938: epoch 135:	0.02646833  	0.19469973  	0.10890433  
2023-05-17 09:34:22.533: [iter 136 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 7.593993]
2023-05-17 09:34:22.699: epoch 136:	0.02644716  	0.19485158  	0.10888797  
2023-05-17 09:34:31.151: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 8.451001]
2023-05-17 09:34:31.312: epoch 137:	0.02643304  	0.19491747  	0.10887843  
2023-05-17 09:34:40.448: [iter 138 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 9.134012]
2023-05-17 09:34:40.717: epoch 138:	0.02648949  	0.19535597  	0.10907021  
2023-05-17 09:34:49.843: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 9.124023]
2023-05-17 09:34:50.142: epoch 139:	0.02648244  	0.19529833  	0.10910595  
2023-05-17 09:34:58.347: [iter 140 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 8.203002]
2023-05-17 09:34:58.509: epoch 140:	0.02642599  	0.19475287  	0.10899708  
2023-05-17 09:35:06.335: [iter 141 : loss : 0.1144 = 0.0249 + 0.0829 + 0.0066, time: 7.825028]
2023-05-17 09:35:06.535: epoch 141:	0.02651067  	0.19561356  	0.10944068  
2023-05-17 09:35:06.536: Find a better model.
2023-05-17 09:35:14.507: [iter 142 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0066, time: 7.957004]
2023-05-17 09:35:14.664: epoch 142:	0.02654595  	0.19562674  	0.10944124  
2023-05-17 09:35:14.664: Find a better model.
2023-05-17 09:35:23.535: [iter 143 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0067, time: 8.869349]
2023-05-17 09:35:23.833: epoch 143:	0.02648244  	0.19516310  	0.10948045  
2023-05-17 09:35:31.575: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.739003]
2023-05-17 09:35:31.738: epoch 144:	0.02646127  	0.19488621  	0.10947019  
2023-05-17 09:35:39.942: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 8.203005]
2023-05-17 09:35:40.168: epoch 145:	0.02639071  	0.19459966  	0.10934859  
2023-05-17 09:35:48.488: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 8.318007]
2023-05-17 09:35:48.671: epoch 146:	0.02644010  	0.19470891  	0.10944933  
2023-05-17 09:35:56.323: [iter 147 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0068, time: 7.651000]
2023-05-17 09:35:56.478: epoch 147:	0.02641893  	0.19446686  	0.10941629  
2023-05-17 09:36:05.512: [iter 148 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 9.032027]
2023-05-17 09:36:05.812: epoch 148:	0.02650362  	0.19548975  	0.10962828  
2023-05-17 09:36:13.353: [iter 149 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.539282]
2023-05-17 09:36:13.534: epoch 149:	0.02645422  	0.19498427  	0.10947435  
2023-05-17 09:36:21.887: [iter 150 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0068, time: 8.351086]
2023-05-17 09:36:22.045: epoch 150:	0.02647539  	0.19505465  	0.10956167  
2023-05-17 09:36:30.058: [iter 151 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0069, time: 8.011012]
2023-05-17 09:36:30.221: epoch 151:	0.02646833  	0.19475497  	0.10945243  
2023-05-17 09:36:37.908: [iter 152 : loss : 0.1111 = 0.0216 + 0.0826 + 0.0069, time: 7.686017]
2023-05-17 09:36:38.069: epoch 152:	0.02648950  	0.19492605  	0.10950325  
2023-05-17 09:36:47.098: [iter 153 : loss : 0.1100 = 0.0206 + 0.0826 + 0.0069, time: 9.027031]
2023-05-17 09:36:47.407: epoch 153:	0.02651067  	0.19494151  	0.10960776  
2023-05-17 09:36:55.170: [iter 154 : loss : 0.1104 = 0.0209 + 0.0825 + 0.0070, time: 7.759142]
2023-05-17 09:36:55.328: epoch 154:	0.02639071  	0.19397555  	0.10927790  
2023-05-17 09:37:03.269: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 7.939369]
2023-05-17 09:37:03.427: epoch 155:	0.02648950  	0.19472355  	0.10953388  
2023-05-17 09:37:11.687: [iter 156 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 8.259005]
2023-05-17 09:37:11.843: epoch 156:	0.02644010  	0.19440328  	0.10943349  
2023-05-17 09:37:19.525: [iter 157 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 7.678059]
2023-05-17 09:37:19.769: epoch 157:	0.02648244  	0.19463937  	0.10937121  
2023-05-17 09:37:28.872: [iter 158 : loss : 0.1098 = 0.0204 + 0.0824 + 0.0071, time: 9.101023]
2023-05-17 09:37:29.139: epoch 158:	0.02646128  	0.19425008  	0.10926801  
2023-05-17 09:37:37.147: [iter 159 : loss : 0.1099 = 0.0205 + 0.0823 + 0.0071, time: 8.006003]
2023-05-17 09:37:37.364: epoch 159:	0.02644717  	0.19410276  	0.10919922  
2023-05-17 09:37:45.044: [iter 160 : loss : 0.1095 = 0.0201 + 0.0823 + 0.0071, time: 7.679016]
2023-05-17 09:37:45.232: epoch 160:	0.02644717  	0.19423991  	0.10926487  
2023-05-17 09:37:53.319: [iter 161 : loss : 0.1089 = 0.0195 + 0.0823 + 0.0071, time: 8.085490]
2023-05-17 09:37:53.543: epoch 161:	0.02637660  	0.19381005  	0.10909408  
2023-05-17 09:38:02.612: [iter 162 : loss : 0.1085 = 0.0191 + 0.0823 + 0.0072, time: 9.064992]
2023-05-17 09:38:02.872: epoch 162:	0.02634837  	0.19354561  	0.10895228  
2023-05-17 09:38:11.875: [iter 163 : loss : 0.1089 = 0.0195 + 0.0822 + 0.0072, time: 8.997015]
2023-05-17 09:38:12.169: epoch 163:	0.02639777  	0.19404799  	0.10919613  
2023-05-17 09:38:20.381: [iter 164 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 8.211068]
2023-05-17 09:38:20.540: epoch 164:	0.02634838  	0.19348648  	0.10908698  
2023-05-17 09:38:28.065: [iter 165 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 7.523939]
2023-05-17 09:38:28.226: epoch 165:	0.02639777  	0.19375803  	0.10914298  
2023-05-17 09:38:36.686: [iter 166 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0072, time: 8.458997]
2023-05-17 09:38:36.857: epoch 166:	0.02641188  	0.19391450  	0.10914725  
2023-05-17 09:38:45.820: [iter 167 : loss : 0.1086 = 0.0192 + 0.0821 + 0.0073, time: 8.959182]
2023-05-17 09:38:46.117: epoch 167:	0.02640483  	0.19395269  	0.10920446  
2023-05-17 09:38:46.117: Early stopping is trigger at epoch: 167
2023-05-17 09:38:46.117: best_result@epoch 142:

2023-05-17 09:38:46.117: 		0.0265      	0.1956      	0.1094      
2023-05-17 09:48:53.863: my pid: 980
2023-05-17 09:48:53.863: model: model.general_recommender.SGL
2023-05-17 09:48:53.863: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 09:48:53.863: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 09:48:57.091: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 09:49:06.036: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.945061]
2023-05-17 09:49:06.204: epoch 1:	0.00135479  	0.01024136  	0.00496711  
2023-05-17 09:49:06.204: Find a better model.
2023-05-17 09:49:16.813: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 10.606296]
2023-05-17 09:49:17.155: epoch 2:	0.00233560  	0.01787913  	0.00896289  
2023-05-17 09:49:17.155: Find a better model.
2023-05-17 09:49:27.322: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.161689]
2023-05-17 09:49:27.645: epoch 3:	0.00446653  	0.03338036  	0.01582943  
2023-05-17 09:49:27.645: Find a better model.
2023-05-17 09:49:36.610: [iter 4 : loss : 0.7706 = 0.6921 + 0.0786 + 0.0000, time: 8.963304]
2023-05-17 09:49:36.795: epoch 4:	0.00735247  	0.05515684  	0.02604703  
2023-05-17 09:49:36.795: Find a better model.
2023-05-17 09:49:45.914: [iter 5 : loss : 0.7697 = 0.6910 + 0.0788 + 0.0000, time: 9.116991]
2023-05-17 09:49:46.062: epoch 5:	0.01119815  	0.08199940  	0.03849529  
2023-05-17 09:49:46.062: Find a better model.
2023-05-17 09:49:54.211: [iter 6 : loss : 0.7676 = 0.6885 + 0.0791 + 0.0000, time: 8.147572]
2023-05-17 09:49:54.368: epoch 6:	0.01500157  	0.10832044  	0.05250478  
2023-05-17 09:49:54.369: Find a better model.
2023-05-17 09:50:03.848: [iter 7 : loss : 0.7619 = 0.6820 + 0.0798 + 0.0000, time: 9.471031]
2023-05-17 09:50:04.148: epoch 7:	0.01756304  	0.12821434  	0.06307725  
2023-05-17 09:50:04.148: Find a better model.
2023-05-17 09:50:12.090: [iter 8 : loss : 0.7476 = 0.6659 + 0.0816 + 0.0001, time: 7.941003]
2023-05-17 09:50:12.248: epoch 8:	0.01877676  	0.13793944  	0.06892910  
2023-05-17 09:50:12.248: Find a better model.
2023-05-17 09:50:20.419: [iter 9 : loss : 0.7143 = 0.6288 + 0.0854 + 0.0001, time: 8.170025]
2023-05-17 09:50:20.578: epoch 9:	0.01885437  	0.13880271  	0.06940615  
2023-05-17 09:50:20.578: Find a better model.
2023-05-17 09:50:28.996: [iter 10 : loss : 0.6546 = 0.5634 + 0.0909 + 0.0002, time: 8.416893]
2023-05-17 09:50:29.270: epoch 10:	0.01852272  	0.13648240  	0.06825542  
2023-05-17 09:50:38.701: [iter 11 : loss : 0.5785 = 0.4819 + 0.0962 + 0.0004, time: 9.428012]
2023-05-17 09:50:38.998: epoch 11:	0.01826163  	0.13474430  	0.06745057  
2023-05-17 09:50:48.161: [iter 12 : loss : 0.5083 = 0.4080 + 0.0997 + 0.0005, time: 9.154042]
2023-05-17 09:50:48.447: epoch 12:	0.01837454  	0.13581493  	0.06783119  
2023-05-17 09:50:56.553: [iter 13 : loss : 0.4566 = 0.3543 + 0.1017 + 0.0007, time: 8.105315]
2023-05-17 09:50:56.709: epoch 13:	0.01837454  	0.13591743  	0.06822118  
2023-05-17 09:51:04.393: [iter 14 : loss : 0.4178 = 0.3144 + 0.1026 + 0.0008, time: 7.682003]
2023-05-17 09:51:04.555: epoch 14:	0.01857917  	0.13746686  	0.06921407  
2023-05-17 09:51:13.233: [iter 15 : loss : 0.3908 = 0.2869 + 0.1029 + 0.0010, time: 8.676003]
2023-05-17 09:51:13.408: epoch 15:	0.01874147  	0.13887544  	0.06999397  
2023-05-17 09:51:13.408: Find a better model.
2023-05-17 09:51:22.571: [iter 16 : loss : 0.3683 = 0.2642 + 0.1030 + 0.0011, time: 9.159824]
2023-05-17 09:51:22.861: epoch 16:	0.01893906  	0.14016107  	0.07084507  
2023-05-17 09:51:22.861: Find a better model.
2023-05-17 09:51:32.122: [iter 17 : loss : 0.3517 = 0.2477 + 0.1028 + 0.0012, time: 9.254042]
2023-05-17 09:51:32.303: epoch 17:	0.01922132  	0.14223199  	0.07176555  
2023-05-17 09:51:32.303: Find a better model.
2023-05-17 09:51:40.616: [iter 18 : loss : 0.3364 = 0.2326 + 0.1025 + 0.0013, time: 8.311031]
2023-05-17 09:51:40.788: epoch 18:	0.01939067  	0.14306700  	0.07251351  
2023-05-17 09:51:40.788: Find a better model.
2023-05-17 09:51:49.114: [iter 19 : loss : 0.3221 = 0.2186 + 0.1021 + 0.0014, time: 8.323992]
2023-05-17 09:51:49.588: epoch 19:	0.01960237  	0.14417134  	0.07316478  
2023-05-17 09:51:49.588: Find a better model.
2023-05-17 09:51:57.556: [iter 20 : loss : 0.3124 = 0.2091 + 0.1018 + 0.0015, time: 7.965502]
2023-05-17 09:51:57.710: epoch 20:	0.01982818  	0.14569886  	0.07405360  
2023-05-17 09:51:57.710: Find a better model.
2023-05-17 09:52:06.840: [iter 21 : loss : 0.3025 = 0.1996 + 0.1013 + 0.0016, time: 9.125033]
2023-05-17 09:52:07.103: epoch 21:	0.02001165  	0.14692748  	0.07473200  
2023-05-17 09:52:07.103: Find a better model.
2023-05-17 09:52:14.738: [iter 22 : loss : 0.2943 = 0.1918 + 0.1009 + 0.0016, time: 7.633195]
2023-05-17 09:52:14.898: epoch 22:	0.02019512  	0.14834951  	0.07538858  
2023-05-17 09:52:14.898: Find a better model.
2023-05-17 09:52:23.149: [iter 23 : loss : 0.2861 = 0.1838 + 0.1005 + 0.0017, time: 8.249529]
2023-05-17 09:52:23.304: epoch 23:	0.02046327  	0.15024865  	0.07641835  
2023-05-17 09:52:23.304: Find a better model.
2023-05-17 09:52:31.743: [iter 24 : loss : 0.2796 = 0.1778 + 0.1000 + 0.0018, time: 8.438003]
2023-05-17 09:52:31.899: epoch 24:	0.02066791  	0.15192257  	0.07743621  
2023-05-17 09:52:31.899: Find a better model.
2023-05-17 09:52:40.093: [iter 25 : loss : 0.2728 = 0.1713 + 0.0997 + 0.0019, time: 8.187013]
2023-05-17 09:52:40.381: epoch 25:	0.02076670  	0.15268174  	0.07796425  
2023-05-17 09:52:40.381: Find a better model.
2023-05-17 09:52:49.794: [iter 26 : loss : 0.2693 = 0.1681 + 0.0992 + 0.0019, time: 9.411025]
2023-05-17 09:52:50.073: epoch 26:	0.02103485  	0.15472189  	0.07894727  
2023-05-17 09:52:50.073: Find a better model.
2023-05-17 09:52:58.569: [iter 27 : loss : 0.2615 = 0.1607 + 0.0987 + 0.0020, time: 8.495434]
2023-05-17 09:52:58.726: epoch 27:	0.02114070  	0.15556619  	0.07959787  
2023-05-17 09:52:58.726: Find a better model.
2023-05-17 09:53:06.567: [iter 28 : loss : 0.2565 = 0.1561 + 0.0983 + 0.0021, time: 7.840029]
2023-05-17 09:53:06.728: epoch 28:	0.02122538  	0.15591477  	0.08038193  
2023-05-17 09:53:06.728: Find a better model.
2023-05-17 09:53:15.241: [iter 29 : loss : 0.2519 = 0.1518 + 0.0979 + 0.0021, time: 8.510994]
2023-05-17 09:53:15.418: epoch 29:	0.02143002  	0.15755418  	0.08128940  
2023-05-17 09:53:15.418: Find a better model.
2023-05-17 09:53:24.734: [iter 30 : loss : 0.2455 = 0.1458 + 0.0976 + 0.0022, time: 9.311991]
2023-05-17 09:53:25.018: epoch 30:	0.02155704  	0.15833528  	0.08211134  
2023-05-17 09:53:25.018: Find a better model.
2023-05-17 09:53:34.292: [iter 31 : loss : 0.2418 = 0.1424 + 0.0972 + 0.0022, time: 9.271000]
2023-05-17 09:53:34.584: epoch 31:	0.02186752  	0.16093561  	0.08325928  
2023-05-17 09:53:34.584: Find a better model.
2023-05-17 09:53:42.603: [iter 32 : loss : 0.2361 = 0.1370 + 0.0968 + 0.0023, time: 8.017996]
2023-05-17 09:53:42.767: epoch 32:	0.02192397  	0.16148099  	0.08357304  
2023-05-17 09:53:42.767: Find a better model.
2023-05-17 09:53:50.768: [iter 33 : loss : 0.2338 = 0.1350 + 0.0964 + 0.0024, time: 8.000004]
2023-05-17 09:53:50.929: epoch 33:	0.02196631  	0.16180468  	0.08404110  
2023-05-17 09:53:50.930: Find a better model.
2023-05-17 09:53:59.347: [iter 34 : loss : 0.2299 = 0.1313 + 0.0961 + 0.0024, time: 8.416022]
2023-05-17 09:53:59.501: epoch 34:	0.02211449  	0.16323824  	0.08480112  
2023-05-17 09:53:59.501: Find a better model.
2023-05-17 09:54:08.709: [iter 35 : loss : 0.2261 = 0.1278 + 0.0958 + 0.0025, time: 9.203227]
2023-05-17 09:54:08.960: epoch 35:	0.02225562  	0.16413336  	0.08534055  
2023-05-17 09:54:08.960: Find a better model.
2023-05-17 09:54:16.957: [iter 36 : loss : 0.2226 = 0.1246 + 0.0955 + 0.0025, time: 7.996708]
2023-05-17 09:54:17.120: epoch 36:	0.02237558  	0.16515331  	0.08577032  
2023-05-17 09:54:17.121: Find a better model.
2023-05-17 09:54:25.793: [iter 37 : loss : 0.2187 = 0.1211 + 0.0951 + 0.0026, time: 8.670992]
2023-05-17 09:54:25.948: epoch 37:	0.02258022  	0.16676114  	0.08645112  
2023-05-17 09:54:25.948: Find a better model.
2023-05-17 09:54:34.641: [iter 38 : loss : 0.2172 = 0.1197 + 0.0948 + 0.0026, time: 8.691992]
2023-05-17 09:54:34.794: epoch 38:	0.02262961  	0.16720350  	0.08700993  
2023-05-17 09:54:34.795: Find a better model.
2023-05-17 09:54:42.738: [iter 39 : loss : 0.2126 = 0.1154 + 0.0945 + 0.0027, time: 7.941995]
2023-05-17 09:54:42.893: epoch 39:	0.02277075  	0.16801266  	0.08771499  
2023-05-17 09:54:42.893: Find a better model.
2023-05-17 09:54:52.260: [iter 40 : loss : 0.2093 = 0.1123 + 0.0942 + 0.0027, time: 9.365992]
2023-05-17 09:54:52.545: epoch 40:	0.02297539  	0.16971396  	0.08858690  
2023-05-17 09:54:52.545: Find a better model.
2023-05-17 09:55:00.397: [iter 41 : loss : 0.2078 = 0.1111 + 0.0939 + 0.0028, time: 7.850579]
2023-05-17 09:55:00.554: epoch 41:	0.02303890  	0.16988288  	0.08910839  
2023-05-17 09:55:00.554: Find a better model.
2023-05-17 09:55:08.689: [iter 42 : loss : 0.2052 = 0.1088 + 0.0936 + 0.0028, time: 8.133955]
2023-05-17 09:55:08.843: epoch 42:	0.02314474  	0.17069493  	0.08982163  
2023-05-17 09:55:08.843: Find a better model.
2023-05-17 09:55:17.095: [iter 43 : loss : 0.2013 = 0.1051 + 0.0933 + 0.0029, time: 8.250574]
2023-05-17 09:55:17.254: epoch 43:	0.02323648  	0.17134146  	0.09034357  
2023-05-17 09:55:17.254: Find a better model.
2023-05-17 09:55:26.995: [iter 44 : loss : 0.1978 = 0.1019 + 0.0930 + 0.0029, time: 9.737991]
2023-05-17 09:55:27.256: epoch 44:	0.02335644  	0.17216067  	0.09085463  
2023-05-17 09:55:27.256: Find a better model.
2023-05-17 09:55:36.676: [iter 45 : loss : 0.1958 = 0.1000 + 0.0928 + 0.0030, time: 9.417916]
2023-05-17 09:55:36.938: epoch 45:	0.02344110  	0.17266488  	0.09138297  
2023-05-17 09:55:36.939: Find a better model.
2023-05-17 09:55:45.264: [iter 46 : loss : 0.1934 = 0.0978 + 0.0925 + 0.0030, time: 8.323992]
2023-05-17 09:55:45.419: epoch 46:	0.02362457  	0.17409509  	0.09222016  
2023-05-17 09:55:45.419: Find a better model.
2023-05-17 09:55:53.321: [iter 47 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 7.900136]
2023-05-17 09:55:53.482: epoch 47:	0.02368102  	0.17439434  	0.09267351  
2023-05-17 09:55:53.482: Find a better model.
2023-05-17 09:56:01.927: [iter 48 : loss : 0.1886 = 0.0934 + 0.0920 + 0.0032, time: 8.443505]
2023-05-17 09:56:02.101: epoch 48:	0.02376570  	0.17522264  	0.09318008  
2023-05-17 09:56:02.101: Find a better model.
2023-05-17 09:56:11.426: [iter 49 : loss : 0.1856 = 0.0905 + 0.0919 + 0.0032, time: 9.322231]
2023-05-17 09:56:11.718: epoch 49:	0.02385743  	0.17579414  	0.09376749  
2023-05-17 09:56:11.718: Find a better model.
2023-05-17 09:56:20.635: [iter 50 : loss : 0.1847 = 0.0898 + 0.0916 + 0.0032, time: 8.915820]
2023-05-17 09:56:20.810: epoch 50:	0.02395622  	0.17663203  	0.09433172  
2023-05-17 09:56:20.811: Find a better model.
2023-05-17 09:56:29.370: [iter 51 : loss : 0.1816 = 0.0869 + 0.0914 + 0.0033, time: 8.557777]
2023-05-17 09:56:29.540: epoch 51:	0.02412558  	0.17778687  	0.09484075  
2023-05-17 09:56:29.540: Find a better model.
2023-05-17 09:56:38.105: [iter 52 : loss : 0.1815 = 0.0869 + 0.0912 + 0.0033, time: 8.562993]
2023-05-17 09:56:38.355: epoch 52:	0.02429493  	0.17937420  	0.09573644  
2023-05-17 09:56:38.355: Find a better model.
2023-05-17 09:56:46.289: [iter 53 : loss : 0.1794 = 0.0851 + 0.0910 + 0.0034, time: 7.933019]
2023-05-17 09:56:46.445: epoch 53:	0.02442901  	0.18043482  	0.09619634  
2023-05-17 09:56:46.445: Find a better model.
2023-05-17 09:56:55.715: [iter 54 : loss : 0.1774 = 0.0832 + 0.0908 + 0.0034, time: 9.267125]
2023-05-17 09:56:56.004: epoch 54:	0.02458425  	0.18150060  	0.09686011  
2023-05-17 09:56:56.004: Find a better model.
2023-05-17 09:57:03.513: [iter 55 : loss : 0.1753 = 0.0812 + 0.0906 + 0.0035, time: 7.507992]
2023-05-17 09:57:03.669: epoch 55:	0.02459835  	0.18113561  	0.09685648  
2023-05-17 09:57:11.652: [iter 56 : loss : 0.1736 = 0.0796 + 0.0904 + 0.0035, time: 7.981992]
2023-05-17 09:57:11.806: epoch 56:	0.02471126  	0.18222521  	0.09721462  
2023-05-17 09:57:11.806: Find a better model.
2023-05-17 09:57:20.288: [iter 57 : loss : 0.1719 = 0.0781 + 0.0902 + 0.0036, time: 8.480552]
2023-05-17 09:57:20.445: epoch 57:	0.02482417  	0.18294410  	0.09785245  
2023-05-17 09:57:20.445: Find a better model.
2023-05-17 09:57:28.501: [iter 58 : loss : 0.1697 = 0.0761 + 0.0901 + 0.0036, time: 8.049517]
2023-05-17 09:57:28.755: epoch 58:	0.02476065  	0.18250339  	0.09791649  
2023-05-17 09:57:38.119: [iter 59 : loss : 0.1690 = 0.0755 + 0.0898 + 0.0037, time: 9.363349]
2023-05-17 09:57:38.375: epoch 59:	0.02488062  	0.18348643  	0.09822310  
2023-05-17 09:57:38.375: Find a better model.
2023-05-17 09:57:46.626: [iter 60 : loss : 0.1672 = 0.0738 + 0.0897 + 0.0037, time: 8.248401]
2023-05-17 09:57:46.948: epoch 60:	0.02491589  	0.18374041  	0.09855040  
2023-05-17 09:57:46.948: Find a better model.
2023-05-17 09:57:54.693: [iter 61 : loss : 0.1660 = 0.0727 + 0.0895 + 0.0038, time: 7.744214]
2023-05-17 09:57:54.858: epoch 61:	0.02488767  	0.18300863  	0.09877471  
2023-05-17 09:58:03.581: [iter 62 : loss : 0.1643 = 0.0712 + 0.0893 + 0.0038, time: 8.720001]
2023-05-17 09:58:03.748: epoch 62:	0.02496528  	0.18365753  	0.09898578  
2023-05-17 09:58:12.934: [iter 63 : loss : 0.1630 = 0.0700 + 0.0892 + 0.0038, time: 9.185379]
2023-05-17 09:58:13.223: epoch 63:	0.02500762  	0.18404518  	0.09921683  
2023-05-17 09:58:13.223: Find a better model.
2023-05-17 09:58:22.666: [iter 64 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 9.441999]
2023-05-17 09:58:22.955: epoch 64:	0.02509230  	0.18465959  	0.09964605  
2023-05-17 09:58:22.955: Find a better model.
2023-05-17 09:58:31.260: [iter 65 : loss : 0.1606 = 0.0678 + 0.0888 + 0.0039, time: 8.303495]
2023-05-17 09:58:31.407: epoch 65:	0.02502174  	0.18422748  	0.09973047  
2023-05-17 09:58:39.454: [iter 66 : loss : 0.1589 = 0.0662 + 0.0887 + 0.0040, time: 8.043993]
2023-05-17 09:58:39.613: epoch 66:	0.02503585  	0.18407719  	0.09998517  
2023-05-17 09:58:48.017: [iter 67 : loss : 0.1576 = 0.0650 + 0.0886 + 0.0040, time: 8.401448]
2023-05-17 09:58:48.175: epoch 67:	0.02507113  	0.18424417  	0.10026836  
2023-05-17 09:58:57.403: [iter 68 : loss : 0.1577 = 0.0652 + 0.0884 + 0.0041, time: 9.224991]
2023-05-17 09:58:57.686: epoch 68:	0.02517697  	0.18498965  	0.10053328  
2023-05-17 09:58:57.686: Find a better model.
2023-05-17 09:59:05.433: [iter 69 : loss : 0.1551 = 0.0628 + 0.0883 + 0.0041, time: 7.745004]
2023-05-17 09:59:05.597: epoch 69:	0.02527576  	0.18577887  	0.10113947  
2023-05-17 09:59:05.597: Find a better model.
2023-05-17 09:59:14.060: [iter 70 : loss : 0.1534 = 0.0612 + 0.0881 + 0.0041, time: 8.461992]
2023-05-17 09:59:14.224: epoch 70:	0.02532516  	0.18597145  	0.10125287  
2023-05-17 09:59:14.224: Find a better model.
2023-05-17 09:59:23.705: [iter 71 : loss : 0.1521 = 0.0599 + 0.0880 + 0.0042, time: 9.479274]
2023-05-17 09:59:23.863: epoch 71:	0.02531810  	0.18581894  	0.10144693  
2023-05-17 09:59:32.242: [iter 72 : loss : 0.1520 = 0.0599 + 0.0879 + 0.0042, time: 8.376286]
2023-05-17 09:59:32.398: epoch 72:	0.02541690  	0.18662827  	0.10175263  
2023-05-17 09:59:32.398: Find a better model.
2023-05-17 09:59:42.356: [iter 73 : loss : 0.1504 = 0.0584 + 0.0878 + 0.0043, time: 9.953500]
2023-05-17 09:59:42.659: epoch 73:	0.02543101  	0.18647763  	0.10175461  
2023-05-17 09:59:50.408: [iter 74 : loss : 0.1494 = 0.0575 + 0.0877 + 0.0043, time: 7.748092]
2023-05-17 09:59:50.576: epoch 74:	0.02548040  	0.18714562  	0.10205915  
2023-05-17 09:59:50.576: Find a better model.
2023-05-17 09:59:59.115: [iter 75 : loss : 0.1487 = 0.0568 + 0.0875 + 0.0043, time: 8.537610]
2023-05-17 09:59:59.282: epoch 75:	0.02552274  	0.18720064  	0.10226021  
2023-05-17 09:59:59.282: Find a better model.
2023-05-17 10:00:08.310: [iter 76 : loss : 0.1477 = 0.0559 + 0.0874 + 0.0044, time: 9.027460]
2023-05-17 10:00:08.471: epoch 76:	0.02556508  	0.18723863  	0.10242196  
2023-05-17 10:00:08.471: Find a better model.
2023-05-17 10:00:16.960: [iter 77 : loss : 0.1467 = 0.0551 + 0.0873 + 0.0044, time: 8.485871]
2023-05-17 10:00:17.252: epoch 77:	0.02557919  	0.18740053  	0.10253695  
2023-05-17 10:00:17.252: Find a better model.
2023-05-17 10:00:27.117: [iter 78 : loss : 0.1456 = 0.0540 + 0.0871 + 0.0045, time: 9.862943]
2023-05-17 10:00:27.374: epoch 78:	0.02574149  	0.18845810  	0.10290255  
2023-05-17 10:00:27.374: Find a better model.
2023-05-17 10:00:35.828: [iter 79 : loss : 0.1440 = 0.0524 + 0.0871 + 0.0045, time: 8.451992]
2023-05-17 10:00:36.175: epoch 79:	0.02590379  	0.18942893  	0.10325170  
2023-05-17 10:00:36.175: Find a better model.
2023-05-17 10:00:44.324: [iter 80 : loss : 0.1436 = 0.0521 + 0.0870 + 0.0045, time: 8.144419]
2023-05-17 10:00:44.493: epoch 80:	0.02581912  	0.18876529  	0.10318461  
2023-05-17 10:00:53.611: [iter 81 : loss : 0.1431 = 0.0516 + 0.0868 + 0.0046, time: 9.116015]
2023-05-17 10:00:53.782: epoch 81:	0.02587557  	0.18944393  	0.10347199  
2023-05-17 10:00:53.782: Find a better model.
2023-05-17 10:01:03.394: [iter 82 : loss : 0.1420 = 0.0506 + 0.0868 + 0.0046, time: 9.608990]
2023-05-17 10:01:03.686: epoch 82:	0.02594613  	0.18994051  	0.10372777  
2023-05-17 10:01:03.686: Find a better model.
2023-05-17 10:01:13.436: [iter 83 : loss : 0.1410 = 0.0497 + 0.0866 + 0.0047, time: 9.742258]
2023-05-17 10:01:13.735: epoch 83:	0.02591790  	0.18941920  	0.10355150  
2023-05-17 10:01:22.390: [iter 84 : loss : 0.1409 = 0.0496 + 0.0866 + 0.0047, time: 8.652992]
2023-05-17 10:01:22.561: epoch 84:	0.02596731  	0.18975440  	0.10396699  
2023-05-17 10:01:30.688: [iter 85 : loss : 0.1399 = 0.0488 + 0.0864 + 0.0047, time: 8.124996]
2023-05-17 10:01:30.866: epoch 85:	0.02598142  	0.18967408  	0.10406335  
2023-05-17 10:01:39.931: [iter 86 : loss : 0.1396 = 0.0485 + 0.0863 + 0.0048, time: 9.062716]
2023-05-17 10:01:40.087: epoch 86:	0.02600259  	0.18997575  	0.10424262  
2023-05-17 10:01:40.088: Find a better model.
2023-05-17 10:01:49.484: [iter 87 : loss : 0.1371 = 0.0460 + 0.0862 + 0.0048, time: 9.394991]
2023-05-17 10:01:49.749: epoch 87:	0.02610844  	0.19068395  	0.10441665  
2023-05-17 10:01:49.749: Find a better model.
2023-05-17 10:01:58.273: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 8.522360]
2023-05-17 10:01:58.593: epoch 88:	0.02608727  	0.19096774  	0.10464951  
2023-05-17 10:01:58.594: Find a better model.
2023-05-17 10:02:08.730: [iter 89 : loss : 0.1358 = 0.0449 + 0.0861 + 0.0049, time: 10.120237]
2023-05-17 10:02:08.898: epoch 89:	0.02615078  	0.19144967  	0.10477168  
2023-05-17 10:02:08.898: Find a better model.
2023-05-17 10:02:19.062: [iter 90 : loss : 0.1365 = 0.0456 + 0.0860 + 0.0049, time: 10.162029]
2023-05-17 10:02:19.227: epoch 90:	0.02615078  	0.19126996  	0.10494076  
2023-05-17 10:02:27.736: [iter 91 : loss : 0.1353 = 0.0445 + 0.0859 + 0.0050, time: 8.507845]
2023-05-17 10:02:27.897: epoch 91:	0.02624957  	0.19221647  	0.10523041  
2023-05-17 10:02:27.897: Find a better model.
2023-05-17 10:02:38.395: [iter 92 : loss : 0.1345 = 0.0437 + 0.0858 + 0.0050, time: 10.494993]
2023-05-17 10:02:38.757: epoch 92:	0.02625662  	0.19239067  	0.10542212  
2023-05-17 10:02:38.757: Find a better model.
2023-05-17 10:02:49.287: [iter 93 : loss : 0.1347 = 0.0440 + 0.0857 + 0.0050, time: 10.525993]
2023-05-17 10:02:49.663: epoch 93:	0.02622840  	0.19212064  	0.10552918  
2023-05-17 10:02:58.429: [iter 94 : loss : 0.1324 = 0.0417 + 0.0857 + 0.0051, time: 8.763921]
2023-05-17 10:02:58.618: epoch 94:	0.02629191  	0.19274715  	0.10583997  
2023-05-17 10:02:58.618: Find a better model.
2023-05-17 10:03:08.399: [iter 95 : loss : 0.1319 = 0.0412 + 0.0856 + 0.0051, time: 9.778991]
2023-05-17 10:03:08.569: epoch 95:	0.02622840  	0.19207828  	0.10568235  
2023-05-17 10:03:18.886: [iter 96 : loss : 0.1319 = 0.0412 + 0.0855 + 0.0052, time: 10.316046]
2023-05-17 10:03:19.058: epoch 96:	0.02630602  	0.19299833  	0.10598933  
2023-05-17 10:03:19.058: Find a better model.
2023-05-17 10:03:28.986: [iter 97 : loss : 0.1303 = 0.0398 + 0.0854 + 0.0052, time: 9.925498]
2023-05-17 10:03:29.265: epoch 97:	0.02627780  	0.19271368  	0.10595169  
2023-05-17 10:03:39.719: [iter 98 : loss : 0.1312 = 0.0407 + 0.0854 + 0.0052, time: 10.451990]
2023-05-17 10:03:40.081: epoch 98:	0.02624957  	0.19234146  	0.10591426  
2023-05-17 10:03:50.762: [iter 99 : loss : 0.1299 = 0.0394 + 0.0853 + 0.0053, time: 10.674991]
2023-05-17 10:03:51.130: epoch 99:	0.02635542  	0.19333164  	0.10616441  
2023-05-17 10:03:51.131: Find a better model.
2023-05-17 10:04:00.350: [iter 100 : loss : 0.1293 = 0.0388 + 0.0852 + 0.0053, time: 9.217865]
2023-05-17 10:04:00.517: epoch 100:	0.02646832  	0.19385479  	0.10635116  
2023-05-17 10:04:00.517: Find a better model.
2023-05-17 10:04:08.946: [iter 101 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 8.425526]
2023-05-17 10:04:09.111: epoch 101:	0.02652477  	0.19423276  	0.10655349  
2023-05-17 10:04:09.111: Find a better model.
2023-05-17 10:04:19.412: [iter 102 : loss : 0.1279 = 0.0376 + 0.0850 + 0.0054, time: 10.299978]
2023-05-17 10:04:19.698: epoch 102:	0.02654595  	0.19416115  	0.10652905  
2023-05-17 10:04:30.367: [iter 103 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 10.664275]
2023-05-17 10:04:30.703: epoch 103:	0.02657417  	0.19460770  	0.10673101  
2023-05-17 10:04:30.703: Find a better model.
2023-05-17 10:04:41.239: [iter 104 : loss : 0.1281 = 0.0378 + 0.0849 + 0.0054, time: 10.532995]
2023-05-17 10:04:41.593: epoch 104:	0.02663768  	0.19516340  	0.10705769  
2023-05-17 10:04:41.593: Find a better model.
2023-05-17 10:04:51.843: [iter 105 : loss : 0.1270 = 0.0367 + 0.0848 + 0.0055, time: 10.240042]
2023-05-17 10:04:52.122: epoch 105:	0.02663768  	0.19539429  	0.10712653  
2023-05-17 10:04:52.123: Find a better model.
2023-05-17 10:05:01.979: [iter 106 : loss : 0.1265 = 0.0363 + 0.0848 + 0.0055, time: 9.854991]
2023-05-17 10:05:02.137: epoch 106:	0.02663063  	0.19519712  	0.10734650  
2023-05-17 10:05:11.089: [iter 107 : loss : 0.1259 = 0.0356 + 0.0847 + 0.0055, time: 8.950992]
2023-05-17 10:05:11.291: epoch 107:	0.02670118  	0.19572751  	0.10754781  
2023-05-17 10:05:11.291: Find a better model.
2023-05-17 10:05:20.136: [iter 108 : loss : 0.1259 = 0.0357 + 0.0846 + 0.0056, time: 8.842494]
2023-05-17 10:05:20.375: epoch 108:	0.02657417  	0.19472551  	0.10710814  
2023-05-17 10:05:30.873: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 10.493606]
2023-05-17 10:05:31.229: epoch 109:	0.02658828  	0.19491674  	0.10730821  
2023-05-17 10:05:41.882: [iter 110 : loss : 0.1237 = 0.0335 + 0.0845 + 0.0056, time: 10.649994]
2023-05-17 10:05:42.249: epoch 110:	0.02661651  	0.19523330  	0.10737863  
2023-05-17 10:05:50.918: [iter 111 : loss : 0.1237 = 0.0335 + 0.0845 + 0.0057, time: 8.667216]
2023-05-17 10:05:51.155: epoch 111:	0.02668002  	0.19588301  	0.10758683  
2023-05-17 10:05:51.155: Find a better model.
2023-05-17 10:06:00.564: [iter 112 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 9.407991]
2023-05-17 10:06:00.760: epoch 112:	0.02668707  	0.19587724  	0.10781837  
2023-05-17 10:06:10.812: [iter 113 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 10.050454]
2023-05-17 10:06:11.228: epoch 113:	0.02663062  	0.19551767  	0.10788544  
2023-05-17 10:06:20.979: [iter 114 : loss : 0.1227 = 0.0327 + 0.0843 + 0.0058, time: 9.736991]
2023-05-17 10:06:21.281: epoch 114:	0.02660944  	0.19529305  	0.10788582  
2023-05-17 10:06:31.809: [iter 115 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.523445]
2023-05-17 10:06:32.195: epoch 115:	0.02669412  	0.19571488  	0.10808631  
2023-05-17 10:06:42.708: [iter 116 : loss : 0.1214 = 0.0314 + 0.0842 + 0.0058, time: 10.509497]
2023-05-17 10:06:43.072: epoch 116:	0.02663767  	0.19542435  	0.10791454  
2023-05-17 10:06:52.489: [iter 117 : loss : 0.1214 = 0.0314 + 0.0841 + 0.0059, time: 9.413992]
2023-05-17 10:06:52.736: epoch 117:	0.02677175  	0.19652213  	0.10822847  
2023-05-17 10:06:52.736: Find a better model.
2023-05-17 10:07:00.883: [iter 118 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0059, time: 8.144138]
2023-05-17 10:07:01.043: epoch 118:	0.02675058  	0.19648598  	0.10839359  
2023-05-17 10:07:10.885: [iter 119 : loss : 0.1201 = 0.0302 + 0.0840 + 0.0059, time: 9.840003]
2023-05-17 10:07:11.233: epoch 119:	0.02675763  	0.19654302  	0.10844219  
2023-05-17 10:07:11.234: Find a better model.
2023-05-17 10:07:21.920: [iter 120 : loss : 0.1204 = 0.0305 + 0.0840 + 0.0060, time: 10.676490]
2023-05-17 10:07:22.270: epoch 120:	0.02665885  	0.19587906  	0.10825920  
2023-05-17 10:07:32.861: [iter 121 : loss : 0.1201 = 0.0303 + 0.0839 + 0.0060, time: 10.583826]
2023-05-17 10:07:33.225: epoch 121:	0.02663768  	0.19567807  	0.10831487  
2023-05-17 10:07:43.007: [iter 122 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0060, time: 9.779991]
2023-05-17 10:07:43.335: epoch 122:	0.02664474  	0.19592686  	0.10841997  
2023-05-17 10:07:53.133: [iter 123 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0061, time: 9.795318]
2023-05-17 10:07:53.339: epoch 123:	0.02676470  	0.19673002  	0.10863777  
2023-05-17 10:07:53.339: Find a better model.
2023-05-17 10:08:02.084: [iter 124 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 8.743053]
2023-05-17 10:08:02.284: epoch 124:	0.02676470  	0.19665204  	0.10873762  
2023-05-17 10:08:11.458: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 9.171992]
2023-05-17 10:08:11.624: epoch 125:	0.02682115  	0.19697806  	0.10898412  
2023-05-17 10:08:11.625: Find a better model.
2023-05-17 10:08:22.257: [iter 126 : loss : 0.1180 = 0.0282 + 0.0837 + 0.0062, time: 10.628990]
2023-05-17 10:08:22.609: epoch 126:	0.02681409  	0.19683200  	0.10897418  
2023-05-17 10:08:33.042: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 10.430468]
2023-05-17 10:08:33.391: epoch 127:	0.02682821  	0.19701430  	0.10906438  
2023-05-17 10:08:33.392: Find a better model.
2023-05-17 10:08:42.305: [iter 128 : loss : 0.1183 = 0.0285 + 0.0836 + 0.0062, time: 8.911964]
2023-05-17 10:08:42.495: epoch 128:	0.02691288  	0.19723895  	0.10923357  
2023-05-17 10:08:42.496: Find a better model.
2023-05-17 10:08:51.500: [iter 129 : loss : 0.1173 = 0.0275 + 0.0835 + 0.0062, time: 9.003363]
2023-05-17 10:08:51.672: epoch 129:	0.02692700  	0.19745491  	0.10919040  
2023-05-17 10:08:51.672: Find a better model.
2023-05-17 10:09:01.157: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 9.482331]
2023-05-17 10:09:01.499: epoch 130:	0.02694817  	0.19777235  	0.10929397  
2023-05-17 10:09:01.499: Find a better model.
2023-05-17 10:09:11.363: [iter 131 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 9.861107]
2023-05-17 10:09:11.662: epoch 131:	0.02690582  	0.19747308  	0.10918898  
2023-05-17 10:09:22.170: [iter 132 : loss : 0.1166 = 0.0269 + 0.0834 + 0.0063, time: 10.504990]
2023-05-17 10:09:22.525: epoch 132:	0.02694816  	0.19786394  	0.10950944  
2023-05-17 10:09:22.525: Find a better model.
2023-05-17 10:09:33.098: [iter 133 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 10.571228]
2023-05-17 10:09:33.410: epoch 133:	0.02689171  	0.19741018  	0.10941971  
2023-05-17 10:09:42.929: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 9.518110]
2023-05-17 10:09:43.109: epoch 134:	0.02688465  	0.19737041  	0.10961030  
2023-05-17 10:09:51.643: [iter 135 : loss : 0.1158 = 0.0261 + 0.0832 + 0.0064, time: 8.531992]
2023-05-17 10:09:51.812: epoch 135:	0.02686348  	0.19725861  	0.10964894  
2023-05-17 10:10:01.484: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 9.670991]
2023-05-17 10:10:01.637: epoch 136:	0.02688465  	0.19755809  	0.10959377  
2023-05-17 10:10:11.706: [iter 137 : loss : 0.1149 = 0.0252 + 0.0832 + 0.0065, time: 10.055019]
2023-05-17 10:10:12.066: epoch 137:	0.02682820  	0.19722004  	0.10950491  
2023-05-17 10:10:22.665: [iter 138 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 10.596990]
2023-05-17 10:10:23.035: epoch 138:	0.02691288  	0.19779475  	0.10968577  
2023-05-17 10:10:32.365: [iter 139 : loss : 0.1144 = 0.0247 + 0.0831 + 0.0065, time: 9.328226]
2023-05-17 10:10:32.687: epoch 139:	0.02697638  	0.19839001  	0.10994062  
2023-05-17 10:10:32.687: Find a better model.
2023-05-17 10:10:42.161: [iter 140 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 9.472991]
2023-05-17 10:10:42.323: epoch 140:	0.02689170  	0.19781476  	0.10976967  
2023-05-17 10:10:51.620: [iter 141 : loss : 0.1145 = 0.0249 + 0.0830 + 0.0066, time: 9.295455]
2023-05-17 10:10:51.782: epoch 141:	0.02692699  	0.19792113  	0.10993506  
2023-05-17 10:11:01.805: [iter 142 : loss : 0.1135 = 0.0240 + 0.0830 + 0.0066, time: 10.020124]
2023-05-17 10:11:02.151: epoch 142:	0.02688465  	0.19755235  	0.10982768  
2023-05-17 10:11:12.677: [iter 143 : loss : 0.1136 = 0.0240 + 0.0829 + 0.0066, time: 10.522483]
2023-05-17 10:11:13.055: epoch 143:	0.02687759  	0.19766463  	0.10999291  
2023-05-17 10:11:23.462: [iter 144 : loss : 0.1130 = 0.0235 + 0.0829 + 0.0067, time: 10.405904]
2023-05-17 10:11:23.796: epoch 144:	0.02689171  	0.19782171  	0.10985759  
2023-05-17 10:11:32.876: [iter 145 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 9.077550]
2023-05-17 10:11:33.048: epoch 145:	0.02682819  	0.19695899  	0.10962158  
2023-05-17 10:11:42.275: [iter 146 : loss : 0.1135 = 0.0240 + 0.0828 + 0.0067, time: 9.225991]
2023-05-17 10:11:42.490: epoch 146:	0.02679997  	0.19712810  	0.10969026  
2023-05-17 10:11:51.577: [iter 147 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0068, time: 9.084991]
2023-05-17 10:11:51.728: epoch 147:	0.02679292  	0.19694644  	0.10966847  
2023-05-17 10:12:01.246: [iter 148 : loss : 0.1116 = 0.0220 + 0.0828 + 0.0068, time: 9.497992]
2023-05-17 10:12:01.583: epoch 148:	0.02679292  	0.19672859  	0.10982806  
2023-05-17 10:12:12.103: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 10.510990]
2023-05-17 10:12:12.485: epoch 149:	0.02682114  	0.19714944  	0.11007003  
2023-05-17 10:12:22.097: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 9.606283]
2023-05-17 10:12:22.573: epoch 150:	0.02683525  	0.19682986  	0.11012855  
2023-05-17 10:12:31.369: [iter 151 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0069, time: 8.793992]
2023-05-17 10:12:31.528: epoch 151:	0.02684936  	0.19720809  	0.11016285  
2023-05-17 10:12:40.515: [iter 152 : loss : 0.1110 = 0.0214 + 0.0826 + 0.0069, time: 8.986025]
2023-05-17 10:12:40.687: epoch 152:	0.02680703  	0.19697291  	0.11002466  
2023-05-17 10:12:51.187: [iter 153 : loss : 0.1101 = 0.0206 + 0.0826 + 0.0069, time: 10.495990]
2023-05-17 10:12:51.476: epoch 153:	0.02679292  	0.19669652  	0.11006292  
2023-05-17 10:13:01.964: [iter 154 : loss : 0.1106 = 0.0211 + 0.0826 + 0.0069, time: 10.485996]
2023-05-17 10:13:02.311: epoch 154:	0.02681409  	0.19670524  	0.11012812  
2023-05-17 10:13:11.862: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 9.547978]
2023-05-17 10:13:12.192: epoch 155:	0.02678587  	0.19678056  	0.11013448  
2023-05-17 10:13:21.184: [iter 156 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 8.990437]
2023-05-17 10:13:21.352: epoch 156:	0.02686349  	0.19703105  	0.11023329  
2023-05-17 10:13:30.738: [iter 157 : loss : 0.1105 = 0.0209 + 0.0825 + 0.0070, time: 9.385375]
2023-05-17 10:13:30.892: epoch 157:	0.02684232  	0.19672340  	0.11006002  
2023-05-17 10:13:39.749: [iter 158 : loss : 0.1098 = 0.0203 + 0.0824 + 0.0070, time: 8.854992]
2023-05-17 10:13:39.904: epoch 158:	0.02686349  	0.19710447  	0.11009486  
2023-05-17 10:13:49.485: [iter 159 : loss : 0.1100 = 0.0205 + 0.0824 + 0.0071, time: 9.574991]
2023-05-17 10:13:49.785: epoch 159:	0.02681409  	0.19641525  	0.10984655  
2023-05-17 10:14:00.231: [iter 160 : loss : 0.1095 = 0.0200 + 0.0824 + 0.0071, time: 10.444011]
2023-05-17 10:14:00.562: epoch 160:	0.02684937  	0.19648121  	0.10990513  
2023-05-17 10:14:10.540: [iter 161 : loss : 0.1091 = 0.0196 + 0.0824 + 0.0071, time: 9.975910]
2023-05-17 10:14:10.712: epoch 161:	0.02687760  	0.19687362  	0.10978138  
2023-05-17 10:14:20.569: [iter 162 : loss : 0.1086 = 0.0191 + 0.0823 + 0.0071, time: 9.854991]
2023-05-17 10:14:20.734: epoch 162:	0.02681408  	0.19640572  	0.10969901  
2023-05-17 10:14:29.334: [iter 163 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0072, time: 8.598992]
2023-05-17 10:14:29.505: epoch 163:	0.02685642  	0.19703168  	0.10984553  
2023-05-17 10:14:39.327: [iter 164 : loss : 0.1090 = 0.0195 + 0.0823 + 0.0072, time: 9.818946]
2023-05-17 10:14:39.592: epoch 164:	0.02687759  	0.19713929  	0.10984694  
2023-05-17 10:14:39.592: Early stopping is trigger at epoch: 164
2023-05-17 10:14:39.592: best_result@epoch 139:

2023-05-17 10:14:39.592: 		0.0270      	0.1984      	0.1099      
2023-05-17 10:20:29.640: my pid: 2988
2023-05-17 10:20:29.640: model: model.general_recommender.SGL
2023-05-17 10:20:29.640: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 10:20:29.640: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 10:20:33.036: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 10:20:44.776: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 11.734364]
2023-05-17 10:20:45.118: epoch 1:	0.00141829  	0.00991044  	0.00485175  
2023-05-17 10:20:45.118: Find a better model.
2023-05-17 10:20:56.207: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 11.087320]
2023-05-17 10:20:56.584: epoch 2:	0.00278013  	0.02109958  	0.00980554  
2023-05-17 10:20:56.584: Find a better model.
2023-05-17 10:21:06.849: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.264143]
2023-05-17 10:21:07.044: epoch 3:	0.00460765  	0.03518714  	0.01671001  
2023-05-17 10:21:07.044: Find a better model.
2023-05-17 10:21:17.770: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 10.725232]
2023-05-17 10:21:17.929: epoch 4:	0.00754298  	0.05557747  	0.02691627  
2023-05-17 10:21:17.929: Find a better model.
2023-05-17 10:21:29.590: [iter 5 : loss : 0.7698 = 0.6910 + 0.0788 + 0.0000, time: 11.659003]
2023-05-17 10:21:29.952: epoch 5:	0.01157920  	0.08371501  	0.03964987  
2023-05-17 10:21:29.952: Find a better model.
2023-05-17 10:21:41.241: [iter 6 : loss : 0.7677 = 0.6886 + 0.0791 + 0.0000, time: 11.286132]
2023-05-17 10:21:41.623: epoch 6:	0.01490983  	0.10805153  	0.05174028  
2023-05-17 10:21:41.623: Find a better model.
2023-05-17 10:21:51.634: [iter 7 : loss : 0.7622 = 0.6824 + 0.0798 + 0.0000, time: 10.004991]
2023-05-17 10:21:51.921: epoch 7:	0.01757010  	0.12736756  	0.06260822  
2023-05-17 10:21:51.921: Find a better model.
2023-05-17 10:22:01.093: [iter 8 : loss : 0.7485 = 0.6669 + 0.0815 + 0.0001, time: 9.170178]
2023-05-17 10:22:01.452: epoch 8:	0.01886144  	0.13722700  	0.06870314  
2023-05-17 10:22:01.452: Find a better model.
2023-05-17 10:22:11.096: [iter 9 : loss : 0.7166 = 0.6314 + 0.0851 + 0.0001, time: 9.642990]
2023-05-17 10:22:11.326: epoch 9:	0.01896728  	0.13898504  	0.06978687  
2023-05-17 10:22:11.326: Find a better model.
2023-05-17 10:22:22.516: [iter 10 : loss : 0.6589 = 0.5682 + 0.0905 + 0.0002, time: 11.188504]
2023-05-17 10:22:22.824: epoch 10:	0.01881204  	0.13902947  	0.06902187  
2023-05-17 10:22:22.824: Find a better model.
2023-05-17 10:22:33.534: [iter 11 : loss : 0.5836 = 0.4875 + 0.0957 + 0.0004, time: 10.706990]
2023-05-17 10:22:33.912: epoch 11:	0.01867797  	0.13853620  	0.06891809  
2023-05-17 10:22:44.490: [iter 12 : loss : 0.5126 = 0.4127 + 0.0993 + 0.0005, time: 10.575432]
2023-05-17 10:22:44.824: epoch 12:	0.01857918  	0.13721351  	0.06887800  
2023-05-17 10:22:53.928: [iter 13 : loss : 0.4596 = 0.3576 + 0.1013 + 0.0007, time: 9.102644]
2023-05-17 10:22:54.095: epoch 13:	0.01869914  	0.13819206  	0.06938809  
2023-05-17 10:23:02.175: [iter 14 : loss : 0.4196 = 0.3165 + 0.1024 + 0.0008, time: 8.078992]
2023-05-17 10:23:02.333: epoch 14:	0.01886144  	0.13944273  	0.07021996  
2023-05-17 10:23:02.333: Find a better model.
2023-05-17 10:23:10.821: [iter 15 : loss : 0.3917 = 0.2880 + 0.1027 + 0.0010, time: 8.485091]
2023-05-17 10:23:10.982: epoch 15:	0.01903079  	0.14118715  	0.07120926  
2023-05-17 10:23:10.982: Find a better model.
2023-05-17 10:23:20.369: [iter 16 : loss : 0.3686 = 0.2647 + 0.1027 + 0.0011, time: 9.378179]
2023-05-17 10:23:20.677: epoch 16:	0.01917898  	0.14168428  	0.07181216  
2023-05-17 10:23:20.677: Find a better model.
2023-05-17 10:23:30.087: [iter 17 : loss : 0.3515 = 0.2478 + 0.1025 + 0.0012, time: 9.407991]
2023-05-17 10:23:30.369: epoch 17:	0.01947535  	0.14364684  	0.07284174  
2023-05-17 10:23:30.369: Find a better model.
2023-05-17 10:23:38.977: [iter 18 : loss : 0.3360 = 0.2323 + 0.1023 + 0.0013, time: 8.606977]
2023-05-17 10:23:39.137: epoch 18:	0.01967294  	0.14475556  	0.07359183  
2023-05-17 10:23:39.138: Find a better model.
2023-05-17 10:23:47.323: [iter 19 : loss : 0.3216 = 0.2183 + 0.1020 + 0.0014, time: 8.183997]
2023-05-17 10:23:47.483: epoch 19:	0.01987052  	0.14572875  	0.07428735  
2023-05-17 10:23:47.483: Find a better model.
2023-05-17 10:23:55.756: [iter 20 : loss : 0.3120 = 0.2089 + 0.1016 + 0.0015, time: 8.270992]
2023-05-17 10:23:55.912: epoch 20:	0.02014572  	0.14769830  	0.07510000  
2023-05-17 10:23:55.912: Find a better model.
2023-05-17 10:24:05.317: [iter 21 : loss : 0.3021 = 0.1993 + 0.1012 + 0.0016, time: 9.401482]
2023-05-17 10:24:05.628: epoch 21:	0.02034330  	0.14917238  	0.07585920  
2023-05-17 10:24:05.628: Find a better model.
2023-05-17 10:24:14.887: [iter 22 : loss : 0.2937 = 0.1913 + 0.1008 + 0.0016, time: 9.256995]
2023-05-17 10:24:15.078: epoch 22:	0.02049149  	0.15027575  	0.07647451  
2023-05-17 10:24:15.078: Find a better model.
2023-05-17 10:24:23.741: [iter 23 : loss : 0.2854 = 0.1833 + 0.1003 + 0.0017, time: 8.660033]
2023-05-17 10:24:23.912: epoch 23:	0.02068202  	0.15194540  	0.07748347  
2023-05-17 10:24:23.912: Find a better model.
2023-05-17 10:24:31.955: [iter 24 : loss : 0.2789 = 0.1772 + 0.0999 + 0.0018, time: 8.041992]
2023-05-17 10:24:32.112: epoch 24:	0.02090078  	0.15353160  	0.07835528  
2023-05-17 10:24:32.112: Find a better model.
2023-05-17 10:24:40.337: [iter 25 : loss : 0.2720 = 0.1706 + 0.0995 + 0.0019, time: 8.223993]
2023-05-17 10:24:40.493: epoch 25:	0.02111247  	0.15520820  	0.07919570  
2023-05-17 10:24:40.493: Find a better model.
2023-05-17 10:24:49.995: [iter 26 : loss : 0.2685 = 0.1675 + 0.0991 + 0.0019, time: 9.492991]
2023-05-17 10:24:50.312: epoch 26:	0.02132417  	0.15652494  	0.07991753  
2023-05-17 10:24:50.312: Find a better model.
2023-05-17 10:24:59.477: [iter 27 : loss : 0.2607 = 0.1601 + 0.0986 + 0.0020, time: 9.163313]
2023-05-17 10:24:59.654: epoch 27:	0.02147941  	0.15775864  	0.08088749  
2023-05-17 10:24:59.655: Find a better model.
2023-05-17 10:25:08.308: [iter 28 : loss : 0.2557 = 0.1554 + 0.0982 + 0.0021, time: 8.652000]
2023-05-17 10:25:08.481: epoch 28:	0.02154998  	0.15849894  	0.08130744  
2023-05-17 10:25:08.481: Find a better model.
2023-05-17 10:25:16.545: [iter 29 : loss : 0.2513 = 0.1514 + 0.0978 + 0.0021, time: 8.061993]
2023-05-17 10:25:16.704: epoch 29:	0.02171934  	0.15941224  	0.08201172  
2023-05-17 10:25:16.704: Find a better model.
2023-05-17 10:25:25.069: [iter 30 : loss : 0.2449 = 0.1453 + 0.0974 + 0.0022, time: 8.362545]
2023-05-17 10:25:25.232: epoch 30:	0.02190986  	0.16119823  	0.08292786  
2023-05-17 10:25:25.232: Find a better model.
2023-05-17 10:25:34.653: [iter 31 : loss : 0.2412 = 0.1419 + 0.0971 + 0.0023, time: 9.417622]
2023-05-17 10:25:34.936: epoch 31:	0.02211450  	0.16289948  	0.08373476  
2023-05-17 10:25:34.936: Find a better model.
2023-05-17 10:25:43.926: [iter 32 : loss : 0.2355 = 0.1365 + 0.0967 + 0.0023, time: 8.987275]
2023-05-17 10:25:44.102: epoch 32:	0.02224856  	0.16347212  	0.08431379  
2023-05-17 10:25:44.102: Find a better model.
2023-05-17 10:25:52.523: [iter 33 : loss : 0.2329 = 0.1343 + 0.0963 + 0.0024, time: 8.419002]
2023-05-17 10:25:52.690: epoch 33:	0.02234030  	0.16404781  	0.08491948  
2023-05-17 10:25:52.690: Find a better model.
2023-05-17 10:26:00.679: [iter 34 : loss : 0.2290 = 0.1306 + 0.0960 + 0.0024, time: 7.988293]
2023-05-17 10:26:00.836: epoch 34:	0.02250259  	0.16536787  	0.08570375  
2023-05-17 10:26:00.836: Find a better model.
2023-05-17 10:26:09.284: [iter 35 : loss : 0.2253 = 0.1272 + 0.0957 + 0.0025, time: 8.446992]
2023-05-17 10:26:09.430: epoch 35:	0.02252376  	0.16563670  	0.08600248  
2023-05-17 10:26:09.430: Find a better model.
2023-05-17 10:26:18.763: [iter 36 : loss : 0.2219 = 0.1241 + 0.0953 + 0.0025, time: 9.325992]
2023-05-17 10:26:19.073: epoch 36:	0.02272840  	0.16697666  	0.08697961  
2023-05-17 10:26:19.073: Find a better model.
2023-05-17 10:26:28.394: [iter 37 : loss : 0.2180 = 0.1204 + 0.0950 + 0.0026, time: 9.317991]
2023-05-17 10:26:28.590: epoch 37:	0.02290482  	0.16797507  	0.08749252  
2023-05-17 10:26:28.590: Find a better model.
2023-05-17 10:26:36.898: [iter 38 : loss : 0.2163 = 0.1190 + 0.0947 + 0.0027, time: 8.306992]
2023-05-17 10:26:37.056: epoch 38:	0.02296832  	0.16865334  	0.08801953  
2023-05-17 10:26:37.056: Find a better model.
2023-05-17 10:26:44.889: [iter 39 : loss : 0.2121 = 0.1150 + 0.0943 + 0.0027, time: 7.832004]
2023-05-17 10:26:45.047: epoch 39:	0.02310240  	0.16973870  	0.08875749  
2023-05-17 10:26:45.047: Find a better model.
2023-05-17 10:26:53.527: [iter 40 : loss : 0.2088 = 0.1119 + 0.0941 + 0.0028, time: 8.478992]
2023-05-17 10:26:53.691: epoch 40:	0.02317296  	0.17031299  	0.08916545  
2023-05-17 10:26:53.691: Find a better model.
2023-05-17 10:27:03.107: [iter 41 : loss : 0.2070 = 0.1104 + 0.0938 + 0.0028, time: 9.412991]
2023-05-17 10:27:03.410: epoch 41:	0.02331410  	0.17152543  	0.08986799  
2023-05-17 10:27:03.410: Find a better model.
2023-05-17 10:27:12.745: [iter 42 : loss : 0.2046 = 0.1082 + 0.0935 + 0.0029, time: 9.331991]
2023-05-17 10:27:13.051: epoch 42:	0.02344817  	0.17255950  	0.09058996  
2023-05-17 10:27:13.051: Find a better model.
2023-05-17 10:27:21.875: [iter 43 : loss : 0.2008 = 0.1047 + 0.0932 + 0.0029, time: 8.822992]
2023-05-17 10:27:22.037: epoch 43:	0.02351873  	0.17296849  	0.09112825  
2023-05-17 10:27:22.038: Find a better model.
2023-05-17 10:27:29.874: [iter 44 : loss : 0.1973 = 0.1014 + 0.0929 + 0.0030, time: 7.834993]
2023-05-17 10:27:30.033: epoch 44:	0.02357518  	0.17321526  	0.09166074  
2023-05-17 10:27:30.033: Find a better model.
2023-05-17 10:27:38.494: [iter 45 : loss : 0.1953 = 0.0996 + 0.0927 + 0.0030, time: 8.459992]
2023-05-17 10:27:38.657: epoch 45:	0.02371631  	0.17399620  	0.09230721  
2023-05-17 10:27:38.657: Find a better model.
2023-05-17 10:27:48.039: [iter 46 : loss : 0.1927 = 0.0972 + 0.0924 + 0.0031, time: 9.378117]
2023-05-17 10:27:48.347: epoch 46:	0.02387861  	0.17502765  	0.09301101  
2023-05-17 10:27:48.347: Find a better model.
2023-05-17 10:27:57.797: [iter 47 : loss : 0.1922 = 0.0969 + 0.0922 + 0.0031, time: 9.442034]
2023-05-17 10:27:58.062: epoch 47:	0.02392801  	0.17516646  	0.09354912  
2023-05-17 10:27:58.062: Find a better model.
2023-05-17 10:28:06.472: [iter 48 : loss : 0.1882 = 0.0931 + 0.0919 + 0.0032, time: 8.408992]
2023-05-17 10:28:06.630: epoch 48:	0.02394918  	0.17567059  	0.09401473  
2023-05-17 10:28:06.630: Find a better model.
2023-05-17 10:28:14.457: [iter 49 : loss : 0.1851 = 0.0901 + 0.0917 + 0.0032, time: 7.825490]
2023-05-17 10:28:14.617: epoch 49:	0.02406208  	0.17669155  	0.09458791  
2023-05-17 10:28:14.618: Find a better model.
2023-05-17 10:28:22.896: [iter 50 : loss : 0.1843 = 0.0896 + 0.0915 + 0.0033, time: 8.276521]
2023-05-17 10:28:23.059: epoch 50:	0.02412558  	0.17718033  	0.09506083  
2023-05-17 10:28:23.059: Find a better model.
2023-05-17 10:28:32.378: [iter 51 : loss : 0.1810 = 0.0864 + 0.0913 + 0.0033, time: 9.314505]
2023-05-17 10:28:32.690: epoch 51:	0.02430905  	0.17851596  	0.09589987  
2023-05-17 10:28:32.691: Find a better model.
2023-05-17 10:28:42.156: [iter 52 : loss : 0.1812 = 0.0867 + 0.0911 + 0.0034, time: 9.462991]
2023-05-17 10:28:42.461: epoch 52:	0.02432316  	0.17857507  	0.09605768  
2023-05-17 10:28:42.461: Find a better model.
2023-05-17 10:28:51.086: [iter 53 : loss : 0.1791 = 0.0849 + 0.0909 + 0.0034, time: 8.622249]
2023-05-17 10:28:51.281: epoch 53:	0.02441489  	0.17930064  	0.09659879  
2023-05-17 10:28:51.281: Find a better model.
2023-05-17 10:28:59.035: [iter 54 : loss : 0.1770 = 0.0829 + 0.0907 + 0.0035, time: 7.753141]
2023-05-17 10:28:59.201: epoch 54:	0.02445018  	0.17984456  	0.09712234  
2023-05-17 10:28:59.202: Find a better model.
2023-05-17 10:29:07.658: [iter 55 : loss : 0.1750 = 0.0810 + 0.0905 + 0.0035, time: 8.454993]
2023-05-17 10:29:07.836: epoch 55:	0.02450662  	0.18014431  	0.09731167  
2023-05-17 10:29:07.836: Find a better model.
2023-05-17 10:29:17.273: [iter 56 : loss : 0.1734 = 0.0795 + 0.0903 + 0.0035, time: 9.435311]
2023-05-17 10:29:17.576: epoch 56:	0.02455602  	0.18054892  	0.09763585  
2023-05-17 10:29:17.576: Find a better model.
2023-05-17 10:29:27.051: [iter 57 : loss : 0.1716 = 0.0779 + 0.0901 + 0.0036, time: 9.466994]
2023-05-17 10:29:27.349: epoch 57:	0.02464775  	0.18178329  	0.09798279  
2023-05-17 10:29:27.349: Find a better model.
2023-05-17 10:29:35.664: [iter 58 : loss : 0.1695 = 0.0759 + 0.0900 + 0.0036, time: 8.312326]
2023-05-17 10:29:35.828: epoch 58:	0.02461953  	0.18138742  	0.09815918  
2023-05-17 10:29:43.598: [iter 59 : loss : 0.1686 = 0.0751 + 0.0898 + 0.0037, time: 7.767264]
2023-05-17 10:29:43.757: epoch 59:	0.02477477  	0.18233332  	0.09858682  
2023-05-17 10:29:43.757: Find a better model.
2023-05-17 10:29:52.064: [iter 60 : loss : 0.1670 = 0.0737 + 0.0896 + 0.0037, time: 8.304992]
2023-05-17 10:29:52.278: epoch 60:	0.02486650  	0.18312047  	0.09906007  
2023-05-17 10:29:52.279: Find a better model.
2023-05-17 10:30:01.690: [iter 61 : loss : 0.1655 = 0.0723 + 0.0894 + 0.0038, time: 9.407994]
2023-05-17 10:30:01.998: epoch 61:	0.02488767  	0.18325451  	0.09913325  
2023-05-17 10:30:01.998: Find a better model.
2023-05-17 10:30:11.374: [iter 62 : loss : 0.1642 = 0.0711 + 0.0893 + 0.0038, time: 9.373993]
2023-05-17 10:30:11.687: epoch 62:	0.02488061  	0.18346947  	0.09927962  
2023-05-17 10:30:11.687: Find a better model.
2023-05-17 10:30:20.168: [iter 63 : loss : 0.1626 = 0.0696 + 0.0891 + 0.0039, time: 8.480330]
2023-05-17 10:30:20.327: epoch 63:	0.02484533  	0.18349765  	0.09935353  
2023-05-17 10:30:20.327: Find a better model.
2023-05-17 10:30:28.194: [iter 64 : loss : 0.1618 = 0.0690 + 0.0890 + 0.0039, time: 7.865049]
2023-05-17 10:30:28.361: epoch 64:	0.02497235  	0.18424159  	0.09992923  
2023-05-17 10:30:28.361: Find a better model.
2023-05-17 10:30:37.012: [iter 65 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 8.649992]
2023-05-17 10:30:37.184: epoch 65:	0.02503585  	0.18448833  	0.10044609  
2023-05-17 10:30:37.184: Find a better model.
2023-05-17 10:30:46.665: [iter 66 : loss : 0.1587 = 0.0660 + 0.0887 + 0.0040, time: 9.477559]
2023-05-17 10:30:46.975: epoch 66:	0.02500057  	0.18420656  	0.10052991  
2023-05-17 10:30:56.416: [iter 67 : loss : 0.1570 = 0.0645 + 0.0885 + 0.0040, time: 9.434992]
2023-05-17 10:30:56.713: epoch 67:	0.02510642  	0.18539365  	0.10095628  
2023-05-17 10:30:56.713: Find a better model.
2023-05-17 10:31:05.549: [iter 68 : loss : 0.1569 = 0.0645 + 0.0883 + 0.0041, time: 8.834991]
2023-05-17 10:31:05.708: epoch 68:	0.02516286  	0.18544319  	0.10125692  
2023-05-17 10:31:05.708: Find a better model.
2023-05-17 10:31:13.623: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 7.912992]
2023-05-17 10:31:13.787: epoch 69:	0.02526166  	0.18635327  	0.10154163  
2023-05-17 10:31:13.787: Find a better model.
2023-05-17 10:31:22.342: [iter 70 : loss : 0.1535 = 0.0612 + 0.0881 + 0.0042, time: 8.554040]
2023-05-17 10:31:22.499: epoch 70:	0.02528282  	0.18658648  	0.10159726  
2023-05-17 10:31:22.499: Find a better model.
2023-05-17 10:31:31.900: [iter 71 : loss : 0.1521 = 0.0599 + 0.0880 + 0.0042, time: 9.391991]
2023-05-17 10:31:32.187: epoch 71:	0.02528988  	0.18655472  	0.10164777  
2023-05-17 10:31:41.602: [iter 72 : loss : 0.1516 = 0.0595 + 0.0878 + 0.0042, time: 9.412382]
2023-05-17 10:31:41.909: epoch 72:	0.02540278  	0.18736780  	0.10209790  
2023-05-17 10:31:41.910: Find a better model.
2023-05-17 10:31:50.739: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 8.827509]
2023-05-17 10:31:50.896: epoch 73:	0.02544512  	0.18763849  	0.10237512  
2023-05-17 10:31:50.896: Find a better model.
2023-05-17 10:31:58.789: [iter 74 : loss : 0.1490 = 0.0571 + 0.0876 + 0.0043, time: 7.890806]
2023-05-17 10:31:58.955: epoch 74:	0.02548040  	0.18824877  	0.10270881  
2023-05-17 10:31:58.955: Find a better model.
2023-05-17 10:32:07.447: [iter 75 : loss : 0.1483 = 0.0565 + 0.0875 + 0.0044, time: 8.491014]
2023-05-17 10:32:07.612: epoch 75:	0.02555802  	0.18861532  	0.10307239  
2023-05-17 10:32:07.612: Find a better model.
2023-05-17 10:32:17.177: [iter 76 : loss : 0.1473 = 0.0555 + 0.0873 + 0.0044, time: 9.562001]
2023-05-17 10:32:17.479: epoch 76:	0.02557214  	0.18864381  	0.10315508  
2023-05-17 10:32:17.479: Find a better model.
2023-05-17 10:32:26.916: [iter 77 : loss : 0.1463 = 0.0546 + 0.0873 + 0.0044, time: 9.433021]
2023-05-17 10:32:27.226: epoch 77:	0.02575562  	0.18994851  	0.10361859  
2023-05-17 10:32:27.226: Find a better model.
2023-05-17 10:32:35.741: [iter 78 : loss : 0.1454 = 0.0537 + 0.0872 + 0.0045, time: 8.513018]
2023-05-17 10:32:35.898: epoch 78:	0.02584734  	0.19016500  	0.10386303  
2023-05-17 10:32:35.899: Find a better model.
2023-05-17 10:32:43.518: [iter 79 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 7.617004]
2023-05-17 10:32:43.693: epoch 79:	0.02587557  	0.19037661  	0.10390945  
2023-05-17 10:32:43.693: Find a better model.
2023-05-17 10:32:52.181: [iter 80 : loss : 0.1435 = 0.0521 + 0.0869 + 0.0046, time: 8.486992]
2023-05-17 10:32:52.387: epoch 80:	0.02590380  	0.19022311  	0.10410503  
2023-05-17 10:33:02.017: [iter 81 : loss : 0.1433 = 0.0519 + 0.0868 + 0.0046, time: 9.627025]
2023-05-17 10:33:02.330: epoch 81:	0.02591791  	0.19017115  	0.10447671  
2023-05-17 10:33:11.718: [iter 82 : loss : 0.1418 = 0.0505 + 0.0867 + 0.0046, time: 9.378021]
2023-05-17 10:33:12.032: epoch 82:	0.02592497  	0.19040747  	0.10458605  
2023-05-17 10:33:12.032: Find a better model.
2023-05-17 10:33:20.517: [iter 83 : loss : 0.1409 = 0.0496 + 0.0866 + 0.0047, time: 8.482992]
2023-05-17 10:33:20.690: epoch 83:	0.02592497  	0.19059892  	0.10492122  
2023-05-17 10:33:20.690: Find a better model.
2023-05-17 10:33:28.361: [iter 84 : loss : 0.1410 = 0.0498 + 0.0865 + 0.0047, time: 7.670003]
2023-05-17 10:33:28.527: epoch 84:	0.02604493  	0.19151199  	0.10530853  
2023-05-17 10:33:28.527: Find a better model.
2023-05-17 10:33:37.240: [iter 85 : loss : 0.1399 = 0.0487 + 0.0864 + 0.0048, time: 8.711010]
2023-05-17 10:33:37.415: epoch 85:	0.02602376  	0.19091497  	0.10515852  
2023-05-17 10:33:46.934: [iter 86 : loss : 0.1394 = 0.0484 + 0.0863 + 0.0048, time: 9.515015]
2023-05-17 10:33:47.250: epoch 86:	0.02608022  	0.19141330  	0.10535106  
2023-05-17 10:33:56.663: [iter 87 : loss : 0.1370 = 0.0459 + 0.0862 + 0.0048, time: 9.412176]
2023-05-17 10:33:56.976: epoch 87:	0.02603082  	0.19109397  	0.10529541  
2023-05-17 10:34:05.736: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 8.758997]
2023-05-17 10:34:05.891: epoch 88:	0.02610844  	0.19173738  	0.10570642  
2023-05-17 10:34:05.891: Find a better model.
2023-05-17 10:34:13.523: [iter 89 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 7.630523]
2023-05-17 10:34:13.698: epoch 89:	0.02615078  	0.19217178  	0.10564247  
2023-05-17 10:34:13.698: Find a better model.
2023-05-17 10:34:22.220: [iter 90 : loss : 0.1364 = 0.0455 + 0.0859 + 0.0049, time: 8.520136]
2023-05-17 10:34:22.393: epoch 90:	0.02624957  	0.19301839  	0.10616572  
2023-05-17 10:34:22.393: Find a better model.
2023-05-17 10:34:32.062: [iter 91 : loss : 0.1353 = 0.0445 + 0.0859 + 0.0050, time: 9.667006]
2023-05-17 10:34:32.370: epoch 91:	0.02631308  	0.19331712  	0.10657991  
2023-05-17 10:34:32.371: Find a better model.
2023-05-17 10:34:41.668: [iter 92 : loss : 0.1344 = 0.0436 + 0.0857 + 0.0050, time: 9.291002]
2023-05-17 10:34:41.959: epoch 92:	0.02631308  	0.19323285  	0.10647563  
2023-05-17 10:34:50.640: [iter 93 : loss : 0.1344 = 0.0437 + 0.0857 + 0.0051, time: 8.680023]
2023-05-17 10:34:50.797: epoch 93:	0.02636953  	0.19372058  	0.10669829  
2023-05-17 10:34:50.797: Find a better model.
2023-05-17 10:34:58.462: [iter 94 : loss : 0.1323 = 0.0416 + 0.0856 + 0.0051, time: 7.664540]
2023-05-17 10:34:58.626: epoch 94:	0.02634836  	0.19355156  	0.10678218  
2023-05-17 10:35:07.062: [iter 95 : loss : 0.1319 = 0.0412 + 0.0855 + 0.0051, time: 8.434992]
2023-05-17 10:35:07.341: epoch 95:	0.02633424  	0.19310553  	0.10680255  
2023-05-17 10:35:16.534: [iter 96 : loss : 0.1315 = 0.0409 + 0.0854 + 0.0052, time: 9.184083]
2023-05-17 10:35:16.862: epoch 96:	0.02635541  	0.19314694  	0.10686406  
2023-05-17 10:35:26.144: [iter 97 : loss : 0.1303 = 0.0397 + 0.0853 + 0.0052, time: 9.280123]
2023-05-17 10:35:26.459: epoch 97:	0.02635541  	0.19361500  	0.10708859  
2023-05-17 10:35:34.555: [iter 98 : loss : 0.1311 = 0.0406 + 0.0853 + 0.0052, time: 8.095025]
2023-05-17 10:35:34.718: epoch 98:	0.02637658  	0.19391477  	0.10726861  
2023-05-17 10:35:34.718: Find a better model.
2023-05-17 10:35:42.451: [iter 99 : loss : 0.1296 = 0.0391 + 0.0852 + 0.0053, time: 7.730213]
2023-05-17 10:35:42.610: epoch 99:	0.02646126  	0.19440815  	0.10746738  
2023-05-17 10:35:42.610: Find a better model.
2023-05-17 10:35:50.855: [iter 100 : loss : 0.1292 = 0.0387 + 0.0852 + 0.0053, time: 8.243992]
2023-05-17 10:35:51.013: epoch 100:	0.02651771  	0.19491881  	0.10766742  
2023-05-17 10:35:51.013: Find a better model.
2023-05-17 10:35:58.667: [iter 101 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 7.652609]
2023-05-17 10:35:58.825: epoch 101:	0.02662356  	0.19505717  	0.10776039  
2023-05-17 10:35:58.825: Find a better model.
2023-05-17 10:36:08.133: [iter 102 : loss : 0.1278 = 0.0374 + 0.0850 + 0.0054, time: 9.300703]
2023-05-17 10:36:08.456: epoch 102:	0.02663767  	0.19509299  	0.10792879  
2023-05-17 10:36:08.456: Find a better model.
2023-05-17 10:36:16.112: [iter 103 : loss : 0.1275 = 0.0371 + 0.0850 + 0.0054, time: 7.655012]
2023-05-17 10:36:16.278: epoch 103:	0.02665178  	0.19526747  	0.10805064  
2023-05-17 10:36:16.279: Find a better model.
2023-05-17 10:36:24.544: [iter 104 : loss : 0.1280 = 0.0377 + 0.0849 + 0.0055, time: 8.264140]
2023-05-17 10:36:24.707: epoch 104:	0.02663061  	0.19528821  	0.10837895  
2023-05-17 10:36:24.708: Find a better model.
2023-05-17 10:36:33.134: [iter 105 : loss : 0.1273 = 0.0370 + 0.0848 + 0.0055, time: 8.424015]
2023-05-17 10:36:33.333: epoch 105:	0.02665178  	0.19537009  	0.10841022  
2023-05-17 10:36:33.334: Find a better model.
2023-05-17 10:36:41.036: [iter 106 : loss : 0.1267 = 0.0364 + 0.0848 + 0.0055, time: 7.701379]
2023-05-17 10:36:41.196: epoch 106:	0.02668706  	0.19548160  	0.10850370  
2023-05-17 10:36:41.196: Find a better model.
2023-05-17 10:36:50.448: [iter 107 : loss : 0.1260 = 0.0357 + 0.0847 + 0.0055, time: 9.251022]
2023-05-17 10:36:50.722: epoch 107:	0.02660945  	0.19518127  	0.10843994  
2023-05-17 10:36:59.111: [iter 108 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 8.385359]
2023-05-17 10:36:59.304: epoch 108:	0.02663767  	0.19523424  	0.10866433  
2023-05-17 10:37:07.499: [iter 109 : loss : 0.1243 = 0.0342 + 0.0845 + 0.0056, time: 8.192993]
2023-05-17 10:37:07.663: epoch 109:	0.02666589  	0.19554259  	0.10864850  
2023-05-17 10:37:07.663: Find a better model.
2023-05-17 10:37:15.420: [iter 110 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0057, time: 7.755002]
2023-05-17 10:37:15.579: epoch 110:	0.02666589  	0.19537812  	0.10849027  
2023-05-17 10:37:23.675: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 8.094004]
2023-05-17 10:37:23.842: epoch 111:	0.02667295  	0.19553052  	0.10844789  
2023-05-17 10:37:32.989: [iter 112 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 9.143012]
2023-05-17 10:37:33.304: epoch 112:	0.02670118  	0.19577776  	0.10850155  
2023-05-17 10:37:33.304: Find a better model.
2023-05-17 10:37:42.633: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0058, time: 9.326058]
2023-05-17 10:37:42.934: epoch 113:	0.02674352  	0.19583137  	0.10863090  
2023-05-17 10:37:42.934: Find a better model.
2023-05-17 10:37:51.273: [iter 114 : loss : 0.1226 = 0.0326 + 0.0842 + 0.0058, time: 8.338024]
2023-05-17 10:37:51.435: epoch 114:	0.02681408  	0.19643852  	0.10873312  
2023-05-17 10:37:51.435: Find a better model.
2023-05-17 10:37:59.069: [iter 115 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 7.633013]
2023-05-17 10:37:59.238: epoch 115:	0.02682819  	0.19645925  	0.10883377  
2023-05-17 10:37:59.239: Find a better model.
2023-05-17 10:38:07.678: [iter 116 : loss : 0.1212 = 0.0312 + 0.0841 + 0.0058, time: 8.438504]
2023-05-17 10:38:07.836: epoch 116:	0.02683525  	0.19627556  	0.10870263  
2023-05-17 10:38:17.167: [iter 117 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0059, time: 9.326011]
2023-05-17 10:38:17.480: epoch 117:	0.02679997  	0.19593464  	0.10872404  
2023-05-17 10:38:26.775: [iter 118 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 9.293025]
2023-05-17 10:38:27.076: epoch 118:	0.02684936  	0.19616477  	0.10873262  
2023-05-17 10:38:35.586: [iter 119 : loss : 0.1199 = 0.0300 + 0.0840 + 0.0059, time: 8.508016]
2023-05-17 10:38:35.743: epoch 119:	0.02682114  	0.19622998  	0.10898969  
2023-05-17 10:38:43.228: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 7.483002]
2023-05-17 10:38:43.392: epoch 120:	0.02676469  	0.19625862  	0.10899190  
2023-05-17 10:38:51.584: [iter 121 : loss : 0.1201 = 0.0303 + 0.0839 + 0.0060, time: 8.189522]
2023-05-17 10:38:51.846: epoch 121:	0.02677174  	0.19610950  	0.10911068  
2023-05-17 10:39:00.729: [iter 122 : loss : 0.1194 = 0.0295 + 0.0839 + 0.0060, time: 8.880035]
2023-05-17 10:39:01.059: epoch 122:	0.02673646  	0.19585156  	0.10902428  
2023-05-17 10:39:10.346: [iter 123 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0061, time: 9.285750]
2023-05-17 10:39:10.677: epoch 123:	0.02679291  	0.19622217  	0.10908473  
2023-05-17 10:39:18.731: [iter 124 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 8.053588]
2023-05-17 10:39:18.887: epoch 124:	0.02672235  	0.19572289  	0.10898419  
2023-05-17 10:39:26.583: [iter 125 : loss : 0.1178 = 0.0280 + 0.0837 + 0.0061, time: 7.695012]
2023-05-17 10:39:26.740: epoch 125:	0.02682820  	0.19676630  	0.10931911  
2023-05-17 10:39:26.740: Find a better model.
2023-05-17 10:39:34.964: [iter 126 : loss : 0.1182 = 0.0283 + 0.0837 + 0.0062, time: 8.220992]
2023-05-17 10:39:35.121: epoch 126:	0.02677880  	0.19621831  	0.10921680  
2023-05-17 10:39:42.804: [iter 127 : loss : 0.1170 = 0.0273 + 0.0836 + 0.0062, time: 7.680042]
2023-05-17 10:39:42.960: epoch 127:	0.02674352  	0.19578412  	0.10911973  
2023-05-17 10:39:52.253: [iter 128 : loss : 0.1180 = 0.0282 + 0.0836 + 0.0062, time: 9.286377]
2023-05-17 10:39:52.550: epoch 128:	0.02679997  	0.19634447  	0.10939195  
2023-05-17 10:40:00.268: [iter 129 : loss : 0.1173 = 0.0275 + 0.0835 + 0.0063, time: 7.715002]
2023-05-17 10:40:00.488: epoch 129:	0.02679997  	0.19613138  	0.10925592  
2023-05-17 10:40:08.640: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 8.148993]
2023-05-17 10:40:08.802: epoch 130:	0.02689876  	0.19702388  	0.10960915  
2023-05-17 10:40:08.802: Find a better model.
2023-05-17 10:40:16.793: [iter 131 : loss : 0.1167 = 0.0269 + 0.0834 + 0.0063, time: 7.989315]
2023-05-17 10:40:16.952: epoch 131:	0.02681408  	0.19619459  	0.10937951  
2023-05-17 10:40:25.168: [iter 132 : loss : 0.1167 = 0.0271 + 0.0833 + 0.0063, time: 8.213993]
2023-05-17 10:40:25.322: epoch 132:	0.02683525  	0.19660501  	0.10952467  
2023-05-17 10:40:34.528: [iter 133 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 9.201480]
2023-05-17 10:40:34.828: epoch 133:	0.02688465  	0.19695164  	0.10967074  
2023-05-17 10:40:43.991: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 9.161995]
2023-05-17 10:40:44.178: epoch 134:	0.02692699  	0.19721548  	0.10983387  
2023-05-17 10:40:44.179: Find a better model.
2023-05-17 10:40:52.401: [iter 135 : loss : 0.1159 = 0.0263 + 0.0832 + 0.0064, time: 8.219035]
2023-05-17 10:40:52.561: epoch 135:	0.02685642  	0.19656895  	0.10957935  
2023-05-17 10:41:00.384: [iter 136 : loss : 0.1154 = 0.0257 + 0.0832 + 0.0065, time: 7.820993]
2023-05-17 10:41:00.546: epoch 136:	0.02687759  	0.19700503  	0.10976882  
2023-05-17 10:41:08.799: [iter 137 : loss : 0.1149 = 0.0253 + 0.0831 + 0.0065, time: 8.251992]
2023-05-17 10:41:08.975: epoch 137:	0.02683525  	0.19693747  	0.10966140  
2023-05-17 10:41:18.301: [iter 138 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 9.323303]
2023-05-17 10:41:18.618: epoch 138:	0.02680703  	0.19698739  	0.10967545  
2023-05-17 10:41:27.876: [iter 139 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 9.253335]
2023-05-17 10:41:28.205: epoch 139:	0.02681408  	0.19695812  	0.10983355  
2023-05-17 10:41:36.539: [iter 140 : loss : 0.1136 = 0.0241 + 0.0830 + 0.0066, time: 8.332998]
2023-05-17 10:41:36.696: epoch 140:	0.02682819  	0.19696556  	0.10986338  
2023-05-17 10:41:44.551: [iter 141 : loss : 0.1146 = 0.0250 + 0.0830 + 0.0066, time: 7.853993]
2023-05-17 10:41:44.717: epoch 141:	0.02685642  	0.19726327  	0.10995465  
2023-05-17 10:41:44.717: Find a better model.
2023-05-17 10:41:53.069: [iter 142 : loss : 0.1133 = 0.0237 + 0.0830 + 0.0066, time: 8.349686]
2023-05-17 10:41:53.296: epoch 142:	0.02684231  	0.19713020  	0.11012996  
2023-05-17 10:42:02.717: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 9.418201]
2023-05-17 10:42:03.030: epoch 143:	0.02684230  	0.19689006  	0.11011706  
2023-05-17 10:42:12.266: [iter 144 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 9.232041]
2023-05-17 10:42:12.577: epoch 144:	0.02684936  	0.19724120  	0.11019167  
2023-05-17 10:42:20.716: [iter 145 : loss : 0.1127 = 0.0231 + 0.0828 + 0.0067, time: 8.138036]
2023-05-17 10:42:20.972: epoch 145:	0.02687052  	0.19745259  	0.11009184  
2023-05-17 10:42:20.973: Find a better model.
2023-05-17 10:42:28.723: [iter 146 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0067, time: 7.742391]
2023-05-17 10:42:28.879: epoch 146:	0.02686347  	0.19736278  	0.10999513  
2023-05-17 10:42:37.285: [iter 147 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0068, time: 8.404992]
2023-05-17 10:42:37.441: epoch 147:	0.02691286  	0.19743472  	0.11021764  
2023-05-17 10:42:45.166: [iter 148 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 7.723157]
2023-05-17 10:42:45.329: epoch 148:	0.02691286  	0.19737673  	0.11038171  
2023-05-17 10:42:54.590: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 9.259995]
2023-05-17 10:42:54.901: epoch 149:	0.02694814  	0.19735454  	0.11040111  
2023-05-17 10:43:02.552: [iter 150 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.650131]
2023-05-17 10:43:02.715: epoch 150:	0.02691285  	0.19727768  	0.11031591  
2023-05-17 10:43:10.959: [iter 151 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0069, time: 8.240442]
2023-05-17 10:43:11.131: epoch 151:	0.02691992  	0.19726078  	0.11049521  
2023-05-17 10:43:19.099: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.966227]
2023-05-17 10:43:19.351: epoch 152:	0.02696225  	0.19741151  	0.11040898  
2023-05-17 10:43:27.349: [iter 153 : loss : 0.1102 = 0.0207 + 0.0826 + 0.0069, time: 7.996334]
2023-05-17 10:43:27.504: epoch 153:	0.02694814  	0.19749770  	0.11043247  
2023-05-17 10:43:27.504: Find a better model.
2023-05-17 10:43:36.713: [iter 154 : loss : 0.1107 = 0.0212 + 0.0826 + 0.0070, time: 9.206425]
2023-05-17 10:43:37.016: epoch 154:	0.02691991  	0.19702327  	0.11013582  
2023-05-17 10:43:46.176: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 9.159421]
2023-05-17 10:43:46.354: epoch 155:	0.02696225  	0.19716816  	0.11024186  
2023-05-17 10:43:54.536: [iter 156 : loss : 0.1107 = 0.0212 + 0.0825 + 0.0070, time: 8.180455]
2023-05-17 10:43:54.700: epoch 156:	0.02694108  	0.19704564  	0.11007204  
2023-05-17 10:44:02.301: [iter 157 : loss : 0.1105 = 0.0211 + 0.0824 + 0.0070, time: 7.598461]
2023-05-17 10:44:02.463: epoch 157:	0.02695519  	0.19712560  	0.11010841  
2023-05-17 10:44:10.773: [iter 158 : loss : 0.1097 = 0.0202 + 0.0825 + 0.0071, time: 8.309070]
2023-05-17 10:44:10.934: epoch 158:	0.02691991  	0.19667529  	0.10996607  
2023-05-17 10:44:20.271: [iter 159 : loss : 0.1101 = 0.0206 + 0.0824 + 0.0071, time: 9.334991]
2023-05-17 10:44:20.580: epoch 159:	0.02695520  	0.19674547  	0.10983739  
2023-05-17 10:44:29.825: [iter 160 : loss : 0.1097 = 0.0202 + 0.0824 + 0.0071, time: 9.238995]
2023-05-17 10:44:30.116: epoch 160:	0.02691286  	0.19649656  	0.10985380  
2023-05-17 10:44:37.627: [iter 161 : loss : 0.1092 = 0.0197 + 0.0823 + 0.0071, time: 7.509757]
2023-05-17 10:44:37.783: epoch 161:	0.02690580  	0.19645996  	0.10976724  
2023-05-17 10:44:45.058: [iter 162 : loss : 0.1086 = 0.0191 + 0.0823 + 0.0072, time: 7.273420]
2023-05-17 10:44:45.205: epoch 162:	0.02694814  	0.19701257  	0.10996357  
2023-05-17 10:44:52.447: [iter 163 : loss : 0.1090 = 0.0195 + 0.0823 + 0.0072, time: 7.240090]
2023-05-17 10:44:52.602: epoch 163:	0.02695519  	0.19718195  	0.11013789  
2023-05-17 10:44:59.848: [iter 164 : loss : 0.1090 = 0.0195 + 0.0823 + 0.0072, time: 7.244602]
2023-05-17 10:45:00.003: epoch 164:	0.02698343  	0.19711454  	0.11015151  
2023-05-17 10:45:07.235: [iter 165 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 7.231592]
2023-05-17 10:45:07.378: epoch 165:	0.02691286  	0.19654086  	0.10986859  
2023-05-17 10:45:14.633: [iter 166 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0073, time: 7.252191]
2023-05-17 10:45:14.788: epoch 166:	0.02684935  	0.19632213  	0.10969109  
2023-05-17 10:45:22.036: [iter 167 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0073, time: 7.246959]
2023-05-17 10:45:22.190: epoch 167:	0.02682818  	0.19603741  	0.10972881  
2023-05-17 10:45:29.426: [iter 168 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 7.235732]
2023-05-17 10:45:29.582: epoch 168:	0.02679995  	0.19581784  	0.10961243  
2023-05-17 10:45:37.059: [iter 169 : loss : 0.1083 = 0.0188 + 0.0821 + 0.0073, time: 7.475520]
2023-05-17 10:45:37.215: epoch 169:	0.02685641  	0.19617414  	0.10983048  
2023-05-17 10:45:44.430: [iter 170 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 7.212745]
2023-05-17 10:45:44.584: epoch 170:	0.02684935  	0.19580148  	0.10961308  
2023-05-17 10:45:51.818: [iter 171 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0074, time: 7.231910]
2023-05-17 10:45:51.971: epoch 171:	0.02679995  	0.19554089  	0.10958456  
2023-05-17 10:45:59.210: [iter 172 : loss : 0.1073 = 0.0178 + 0.0820 + 0.0074, time: 7.237603]
2023-05-17 10:45:59.369: epoch 172:	0.02691992  	0.19644122  	0.10988756  
2023-05-17 10:46:06.615: [iter 173 : loss : 0.1080 = 0.0185 + 0.0820 + 0.0074, time: 7.244067]
2023-05-17 10:46:06.759: epoch 173:	0.02685641  	0.19583653  	0.10981528  
2023-05-17 10:46:14.019: [iter 174 : loss : 0.1075 = 0.0181 + 0.0820 + 0.0074, time: 7.258914]
2023-05-17 10:46:14.173: epoch 174:	0.02684230  	0.19585186  	0.10967026  
2023-05-17 10:46:21.412: [iter 175 : loss : 0.1071 = 0.0176 + 0.0820 + 0.0075, time: 7.237696]
2023-05-17 10:46:21.569: epoch 175:	0.02678584  	0.19519904  	0.10948879  
2023-05-17 10:46:28.825: [iter 176 : loss : 0.1065 = 0.0171 + 0.0819 + 0.0075, time: 7.255596]
2023-05-17 10:46:28.980: epoch 176:	0.02676467  	0.19526839  	0.10952108  
2023-05-17 10:46:36.209: [iter 177 : loss : 0.1071 = 0.0177 + 0.0819 + 0.0075, time: 7.227805]
2023-05-17 10:46:36.367: epoch 177:	0.02679290  	0.19507222  	0.10922837  
2023-05-17 10:46:43.620: [iter 178 : loss : 0.1064 = 0.0170 + 0.0819 + 0.0075, time: 7.252370]
2023-05-17 10:46:43.774: epoch 178:	0.02687757  	0.19578245  	0.10948936  
2023-05-17 10:46:43.774: Early stopping is trigger at epoch: 178
2023-05-17 10:46:43.774: best_result@epoch 153:

2023-05-17 10:46:43.774: 		0.0269      	0.1975      	0.1104      
2023-05-17 10:57:32.832: my pid: 7620
2023-05-17 10:57:32.832: model: model.general_recommender.SGL
2023-05-17 10:57:32.832: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 10:57:32.832: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 10:57:36.049: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 10:57:44.656: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.607087]
2023-05-17 10:57:44.808: epoch 1:	0.00137595  	0.00971051  	0.00475468  
2023-05-17 10:57:44.808: Find a better model.
2023-05-17 10:57:53.461: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 8.651762]
2023-05-17 10:57:53.645: epoch 2:	0.00254022  	0.01856746  	0.00867087  
2023-05-17 10:57:53.645: Find a better model.
2023-05-17 10:58:02.233: [iter 3 : loss : 0.7711 = 0.6926 + 0.0784 + 0.0000, time: 8.586493]
2023-05-17 10:58:02.389: epoch 3:	0.00427602  	0.03144388  	0.01492662  
2023-05-17 10:58:02.389: Find a better model.
2023-05-17 10:58:10.858: [iter 4 : loss : 0.7707 = 0.6921 + 0.0785 + 0.0000, time: 8.468115]
2023-05-17 10:58:11.019: epoch 4:	0.00699966  	0.05148860  	0.02495874  
2023-05-17 10:58:11.019: Find a better model.
2023-05-17 10:58:19.651: [iter 5 : loss : 0.7699 = 0.6912 + 0.0787 + 0.0000, time: 8.629684]
2023-05-17 10:58:19.814: epoch 5:	0.01040077  	0.07545453  	0.03614145  
2023-05-17 10:58:19.814: Find a better model.
2023-05-17 10:58:28.731: [iter 6 : loss : 0.7681 = 0.6890 + 0.0791 + 0.0000, time: 8.915309]
2023-05-17 10:58:29.160: epoch 6:	0.01448646  	0.10365705  	0.05017336  
2023-05-17 10:58:29.160: Find a better model.
2023-05-17 10:58:38.392: [iter 7 : loss : 0.7633 = 0.6836 + 0.0797 + 0.0000, time: 9.226490]
2023-05-17 10:58:38.683: epoch 7:	0.01732312  	0.12481997  	0.06168684  
2023-05-17 10:58:38.683: Find a better model.
2023-05-17 10:58:47.336: [iter 8 : loss : 0.7512 = 0.6699 + 0.0812 + 0.0001, time: 8.651630]
2023-05-17 10:58:47.495: epoch 8:	0.01843098  	0.13346997  	0.06708425  
2023-05-17 10:58:47.495: Find a better model.
2023-05-17 10:58:56.164: [iter 9 : loss : 0.7224 = 0.6378 + 0.0845 + 0.0001, time: 8.668044]
2023-05-17 10:58:56.367: epoch 9:	0.01875559  	0.13758157  	0.06871463  
2023-05-17 10:58:56.367: Find a better model.
2023-05-17 10:59:05.641: [iter 10 : loss : 0.6683 = 0.5783 + 0.0898 + 0.0002, time: 9.270196]
2023-05-17 10:59:05.928: epoch 10:	0.01860740  	0.13737273  	0.06828033  
2023-05-17 10:59:14.598: [iter 11 : loss : 0.5942 = 0.4987 + 0.0951 + 0.0004, time: 8.669032]
2023-05-17 10:59:14.765: epoch 11:	0.01861446  	0.13717705  	0.06813352  
2023-05-17 10:59:23.401: [iter 12 : loss : 0.5214 = 0.4220 + 0.0989 + 0.0005, time: 8.634168]
2023-05-17 10:59:23.558: epoch 12:	0.01858623  	0.13717757  	0.06837583  
2023-05-17 10:59:32.976: [iter 13 : loss : 0.4660 = 0.3643 + 0.1011 + 0.0007, time: 9.415719]
2023-05-17 10:59:33.260: epoch 13:	0.01862858  	0.13775979  	0.06891678  
2023-05-17 10:59:33.260: Find a better model.
2023-05-17 10:59:43.222: [iter 14 : loss : 0.4242 = 0.3211 + 0.1023 + 0.0008, time: 9.960092]
2023-05-17 10:59:43.519: epoch 14:	0.01877677  	0.13915721  	0.06973679  
2023-05-17 10:59:43.520: Find a better model.
2023-05-17 10:59:52.156: [iter 15 : loss : 0.3952 = 0.2916 + 0.1026 + 0.0010, time: 8.634637]
2023-05-17 10:59:52.326: epoch 15:	0.01893906  	0.14054093  	0.07050254  
2023-05-17 10:59:52.326: Find a better model.
2023-05-17 11:00:02.766: [iter 16 : loss : 0.3713 = 0.2676 + 0.1027 + 0.0011, time: 10.433936]
2023-05-17 11:00:03.082: epoch 16:	0.01913664  	0.14189900  	0.07147107  
2023-05-17 11:00:03.083: Find a better model.
2023-05-17 11:00:13.341: [iter 17 : loss : 0.3537 = 0.2500 + 0.1025 + 0.0012, time: 10.255084]
2023-05-17 11:00:13.652: epoch 17:	0.01939774  	0.14305943  	0.07218487  
2023-05-17 11:00:13.652: Find a better model.
2023-05-17 11:00:23.070: [iter 18 : loss : 0.3377 = 0.2341 + 0.1023 + 0.0013, time: 9.415528]
2023-05-17 11:00:23.362: epoch 18:	0.01971528  	0.14587791  	0.07339176  
2023-05-17 11:00:23.362: Find a better model.
2023-05-17 11:00:33.068: [iter 19 : loss : 0.3232 = 0.2198 + 0.1020 + 0.0014, time: 9.703991]
2023-05-17 11:00:33.281: epoch 19:	0.01989876  	0.14691296  	0.07409195  
2023-05-17 11:00:33.281: Find a better model.
2023-05-17 11:00:42.655: [iter 20 : loss : 0.3132 = 0.2101 + 0.1016 + 0.0015, time: 9.372991]
2023-05-17 11:00:42.809: epoch 20:	0.02004694  	0.14777057  	0.07482336  
2023-05-17 11:00:42.809: Find a better model.
2023-05-17 11:00:51.625: [iter 21 : loss : 0.3031 = 0.2003 + 0.1012 + 0.0016, time: 8.814993]
2023-05-17 11:00:51.791: epoch 21:	0.02030098  	0.14953947  	0.07568989  
2023-05-17 11:00:51.791: Find a better model.
2023-05-17 11:01:02.410: [iter 22 : loss : 0.2948 = 0.1923 + 0.1008 + 0.0016, time: 10.609038]
2023-05-17 11:01:02.726: epoch 22:	0.02044210  	0.15042984  	0.07624696  
2023-05-17 11:01:02.726: Find a better model.
2023-05-17 11:01:12.433: [iter 23 : loss : 0.2862 = 0.1841 + 0.1004 + 0.0017, time: 9.706353]
2023-05-17 11:01:12.628: epoch 23:	0.02067497  	0.15197794  	0.07730415  
2023-05-17 11:01:12.628: Find a better model.
2023-05-17 11:01:21.961: [iter 24 : loss : 0.2796 = 0.1779 + 0.0999 + 0.0018, time: 9.329992]
2023-05-17 11:01:22.196: epoch 24:	0.02077376  	0.15239029  	0.07766717  
2023-05-17 11:01:22.197: Find a better model.
2023-05-17 11:01:32.337: [iter 25 : loss : 0.2728 = 0.1714 + 0.0995 + 0.0019, time: 10.133101]
2023-05-17 11:01:32.624: epoch 25:	0.02095017  	0.15343106  	0.07832423  
2023-05-17 11:01:32.624: Find a better model.
2023-05-17 11:01:41.532: [iter 26 : loss : 0.2691 = 0.1681 + 0.0991 + 0.0019, time: 8.907157]
2023-05-17 11:01:41.701: epoch 26:	0.02114070  	0.15511061  	0.07927356  
2023-05-17 11:01:41.701: Find a better model.
2023-05-17 11:01:51.909: [iter 27 : loss : 0.2614 = 0.1608 + 0.0986 + 0.0020, time: 10.202952]
2023-05-17 11:01:52.201: epoch 27:	0.02131712  	0.15629855  	0.07994110  
2023-05-17 11:01:52.201: Find a better model.
2023-05-17 11:02:02.089: [iter 28 : loss : 0.2565 = 0.1561 + 0.0982 + 0.0021, time: 9.884045]
2023-05-17 11:02:02.363: epoch 28:	0.02148648  	0.15769264  	0.08077089  
2023-05-17 11:02:02.363: Find a better model.
2023-05-17 11:02:11.179: [iter 29 : loss : 0.2516 = 0.1517 + 0.0978 + 0.0021, time: 8.814992]
2023-05-17 11:02:11.342: epoch 29:	0.02168406  	0.15873817  	0.08153702  
2023-05-17 11:02:11.342: Find a better model.
2023-05-17 11:02:20.836: [iter 30 : loss : 0.2452 = 0.1454 + 0.0975 + 0.0022, time: 9.490961]
2023-05-17 11:02:21.001: epoch 30:	0.02184636  	0.15986541  	0.08222201  
2023-05-17 11:02:21.002: Find a better model.
2023-05-17 11:02:31.453: [iter 31 : loss : 0.2416 = 0.1423 + 0.0970 + 0.0023, time: 10.445006]
2023-05-17 11:02:31.779: epoch 31:	0.02210039  	0.16213413  	0.08331211  
2023-05-17 11:02:31.779: Find a better model.
2023-05-17 11:02:41.869: [iter 32 : loss : 0.2359 = 0.1369 + 0.0967 + 0.0023, time: 10.084999]
2023-05-17 11:02:42.237: epoch 32:	0.02224152  	0.16337419  	0.08385429  
2023-05-17 11:02:42.238: Find a better model.
2023-05-17 11:02:51.763: [iter 33 : loss : 0.2335 = 0.1348 + 0.0963 + 0.0024, time: 9.524003]
2023-05-17 11:02:52.022: epoch 33:	0.02244615  	0.16508248  	0.08460879  
2023-05-17 11:02:52.022: Find a better model.
2023-05-17 11:03:01.301: [iter 34 : loss : 0.2292 = 0.1308 + 0.0960 + 0.0024, time: 9.275513]
2023-05-17 11:03:01.594: epoch 34:	0.02264374  	0.16623485  	0.08547845  
2023-05-17 11:03:01.594: Find a better model.
2023-05-17 11:03:10.999: [iter 35 : loss : 0.2257 = 0.1276 + 0.0956 + 0.0025, time: 9.403022]
2023-05-17 11:03:11.164: epoch 35:	0.02272136  	0.16675477  	0.08618938  
2023-05-17 11:03:11.164: Find a better model.
2023-05-17 11:03:21.170: [iter 36 : loss : 0.2220 = 0.1241 + 0.0953 + 0.0025, time: 10.003998]
2023-05-17 11:03:21.492: epoch 36:	0.02284132  	0.16761222  	0.08680500  
2023-05-17 11:03:21.492: Find a better model.
2023-05-17 11:03:31.823: [iter 37 : loss : 0.2183 = 0.1207 + 0.0950 + 0.0026, time: 10.329037]
2023-05-17 11:03:32.142: epoch 37:	0.02290482  	0.16804481  	0.08719642  
2023-05-17 11:03:32.142: Find a better model.
2023-05-17 11:03:41.803: [iter 38 : loss : 0.2166 = 0.1193 + 0.0947 + 0.0027, time: 9.660016]
2023-05-17 11:03:41.977: epoch 38:	0.02309535  	0.16965592  	0.08810556  
2023-05-17 11:03:41.978: Find a better model.
2023-05-17 11:03:50.746: [iter 39 : loss : 0.2125 = 0.1154 + 0.0944 + 0.0027, time: 8.767052]
2023-05-17 11:03:50.921: epoch 39:	0.02322237  	0.17086898  	0.08888070  
2023-05-17 11:03:50.922: Find a better model.
2023-05-17 11:04:00.714: [iter 40 : loss : 0.2089 = 0.1121 + 0.0940 + 0.0028, time: 9.788017]
2023-05-17 11:04:00.997: epoch 40:	0.02321531  	0.17082614  	0.08924858  
2023-05-17 11:04:11.078: [iter 41 : loss : 0.2073 = 0.1107 + 0.0938 + 0.0028, time: 10.078994]
2023-05-17 11:04:11.426: epoch 41:	0.02338466  	0.17144231  	0.08978436  
2023-05-17 11:04:11.426: Find a better model.
2023-05-17 11:04:19.618: [iter 42 : loss : 0.2050 = 0.1086 + 0.0935 + 0.0029, time: 8.191409]
2023-05-17 11:04:19.780: epoch 42:	0.02354696  	0.17291877  	0.09060305  
2023-05-17 11:04:19.780: Find a better model.
2023-05-17 11:04:29.700: [iter 43 : loss : 0.2009 = 0.1047 + 0.0932 + 0.0029, time: 9.912015]
2023-05-17 11:04:29.987: epoch 43:	0.02367397  	0.17369495  	0.09120396  
2023-05-17 11:04:29.987: Find a better model.
2023-05-17 11:04:39.517: [iter 44 : loss : 0.1976 = 0.1017 + 0.0929 + 0.0030, time: 9.527553]
2023-05-17 11:04:39.688: epoch 44:	0.02377982  	0.17445366  	0.09149823  
2023-05-17 11:04:39.689: Find a better model.
2023-05-17 11:04:50.317: [iter 45 : loss : 0.1955 = 0.0997 + 0.0927 + 0.0030, time: 10.627560]
2023-05-17 11:04:50.607: epoch 45:	0.02389272  	0.17531064  	0.09230468  
2023-05-17 11:04:50.607: Find a better model.
2023-05-17 11:05:00.965: [iter 46 : loss : 0.1930 = 0.0975 + 0.0924 + 0.0031, time: 10.353029]
2023-05-17 11:05:01.307: epoch 46:	0.02394918  	0.17579855  	0.09260216  
2023-05-17 11:05:01.307: Find a better model.
2023-05-17 11:05:09.557: [iter 47 : loss : 0.1923 = 0.0970 + 0.0922 + 0.0031, time: 8.248015]
2023-05-17 11:05:09.735: epoch 47:	0.02409030  	0.17703521  	0.09329650  
2023-05-17 11:05:09.735: Find a better model.
2023-05-17 11:05:18.498: [iter 48 : loss : 0.1881 = 0.0931 + 0.0919 + 0.0032, time: 8.760971]
2023-05-17 11:05:18.657: epoch 48:	0.02415381  	0.17759012  	0.09388829  
2023-05-17 11:05:18.657: Find a better model.
2023-05-17 11:05:27.744: [iter 49 : loss : 0.1853 = 0.0903 + 0.0917 + 0.0032, time: 9.086020]
2023-05-17 11:05:27.908: epoch 49:	0.02418203  	0.17765972  	0.09418087  
2023-05-17 11:05:27.908: Find a better model.
2023-05-17 11:05:36.521: [iter 50 : loss : 0.1844 = 0.0895 + 0.0916 + 0.0033, time: 8.612003]
2023-05-17 11:05:36.679: epoch 50:	0.02425965  	0.17805944  	0.09443630  
2023-05-17 11:05:36.679: Find a better model.
2023-05-17 11:05:46.474: [iter 51 : loss : 0.1816 = 0.0869 + 0.0914 + 0.0033, time: 9.792259]
2023-05-17 11:05:46.877: epoch 51:	0.02435138  	0.17842475  	0.09492286  
2023-05-17 11:05:46.877: Find a better model.
2023-05-17 11:05:57.014: [iter 52 : loss : 0.1810 = 0.0866 + 0.0911 + 0.0034, time: 10.131035]
2023-05-17 11:05:57.306: epoch 52:	0.02440078  	0.17865078  	0.09539145  
2023-05-17 11:05:57.306: Find a better model.
2023-05-17 11:06:05.848: [iter 53 : loss : 0.1793 = 0.0850 + 0.0909 + 0.0034, time: 8.539015]
2023-05-17 11:06:06.022: epoch 53:	0.02461247  	0.18028802  	0.09627374  
2023-05-17 11:06:06.023: Find a better model.
2023-05-17 11:06:15.685: [iter 54 : loss : 0.1773 = 0.0831 + 0.0907 + 0.0035, time: 9.660026]
2023-05-17 11:06:15.845: epoch 54:	0.02467598  	0.18105245  	0.09663243  
2023-05-17 11:06:15.845: Find a better model.
2023-05-17 11:06:26.407: [iter 55 : loss : 0.1752 = 0.0812 + 0.0905 + 0.0035, time: 10.559096]
2023-05-17 11:06:26.741: epoch 55:	0.02469010  	0.18121853  	0.09689282  
2023-05-17 11:06:26.741: Find a better model.
2023-05-17 11:06:36.522: [iter 56 : loss : 0.1735 = 0.0796 + 0.0903 + 0.0035, time: 9.777014]
2023-05-17 11:06:36.814: epoch 56:	0.02476066  	0.18168415  	0.09706849  
2023-05-17 11:06:36.815: Find a better model.
2023-05-17 11:06:45.763: [iter 57 : loss : 0.1721 = 0.0783 + 0.0902 + 0.0036, time: 8.947006]
2023-05-17 11:06:45.929: epoch 57:	0.02481711  	0.18180010  	0.09731434  
2023-05-17 11:06:45.929: Find a better model.
2023-05-17 11:06:54.653: [iter 58 : loss : 0.1697 = 0.0761 + 0.0900 + 0.0036, time: 8.722006]
2023-05-17 11:06:54.823: epoch 58:	0.02487356  	0.18238106  	0.09760546  
2023-05-17 11:06:54.824: Find a better model.
2023-05-17 11:07:03.932: [iter 59 : loss : 0.1686 = 0.0751 + 0.0898 + 0.0037, time: 9.107003]
2023-05-17 11:07:04.105: epoch 59:	0.02481711  	0.18197119  	0.09760792  
2023-05-17 11:07:14.018: [iter 60 : loss : 0.1670 = 0.0737 + 0.0896 + 0.0037, time: 9.909033]
2023-05-17 11:07:14.273: epoch 60:	0.02485240  	0.18236414  	0.09795880  
2023-05-17 11:07:24.738: [iter 61 : loss : 0.1657 = 0.0725 + 0.0894 + 0.0038, time: 10.462202]
2023-05-17 11:07:25.053: epoch 61:	0.02484534  	0.18195339  	0.09801611  
2023-05-17 11:07:33.573: [iter 62 : loss : 0.1642 = 0.0712 + 0.0893 + 0.0038, time: 8.519004]
2023-05-17 11:07:33.889: epoch 62:	0.02495119  	0.18317205  	0.09840649  
2023-05-17 11:07:33.889: Find a better model.
2023-05-17 11:07:42.441: [iter 63 : loss : 0.1628 = 0.0699 + 0.0891 + 0.0039, time: 8.551011]
2023-05-17 11:07:42.605: epoch 63:	0.02503586  	0.18384756  	0.09879968  
2023-05-17 11:07:42.605: Find a better model.
2023-05-17 11:07:52.377: [iter 64 : loss : 0.1619 = 0.0690 + 0.0890 + 0.0039, time: 9.770884]
2023-05-17 11:07:52.548: epoch 64:	0.02507820  	0.18413097  	0.09923517  
2023-05-17 11:07:52.548: Find a better model.
2023-05-17 11:08:02.078: [iter 65 : loss : 0.1606 = 0.0679 + 0.0888 + 0.0039, time: 9.525002]
2023-05-17 11:08:02.436: epoch 65:	0.02516287  	0.18443090  	0.09948150  
2023-05-17 11:08:02.437: Find a better model.
2023-05-17 11:08:12.363: [iter 66 : loss : 0.1591 = 0.0664 + 0.0887 + 0.0040, time: 9.916021]
2023-05-17 11:08:12.685: epoch 66:	0.02512054  	0.18416889  	0.09946121  
2023-05-17 11:08:22.739: [iter 67 : loss : 0.1575 = 0.0650 + 0.0885 + 0.0040, time: 10.052997]
2023-05-17 11:08:23.044: epoch 67:	0.02520522  	0.18478248  	0.09978168  
2023-05-17 11:08:23.044: Find a better model.
2023-05-17 11:08:32.961: [iter 68 : loss : 0.1573 = 0.0648 + 0.0884 + 0.0041, time: 9.915028]
2023-05-17 11:08:33.142: epoch 68:	0.02531106  	0.18565619  	0.10012459  
2023-05-17 11:08:33.143: Find a better model.
2023-05-17 11:08:41.460: [iter 69 : loss : 0.1550 = 0.0626 + 0.0882 + 0.0041, time: 8.313992]
2023-05-17 11:08:41.618: epoch 69:	0.02536046  	0.18599588  	0.10030308  
2023-05-17 11:08:41.618: Find a better model.
2023-05-17 11:08:51.881: [iter 70 : loss : 0.1534 = 0.0611 + 0.0881 + 0.0042, time: 10.259365]
2023-05-17 11:08:52.218: epoch 70:	0.02543809  	0.18624783  	0.10061128  
2023-05-17 11:08:52.219: Find a better model.
2023-05-17 11:09:01.959: [iter 71 : loss : 0.1520 = 0.0598 + 0.0880 + 0.0042, time: 9.734215]
2023-05-17 11:09:02.248: epoch 71:	0.02545219  	0.18598512  	0.10070386  
2023-05-17 11:09:11.462: [iter 72 : loss : 0.1519 = 0.0598 + 0.0879 + 0.0042, time: 9.212282]
2023-05-17 11:09:11.628: epoch 72:	0.02540280  	0.18591817  	0.10083697  
2023-05-17 11:09:20.874: [iter 73 : loss : 0.1505 = 0.0585 + 0.0877 + 0.0043, time: 9.244002]
2023-05-17 11:09:21.097: epoch 73:	0.02548747  	0.18652375  	0.10117477  
2023-05-17 11:09:21.098: Find a better model.
2023-05-17 11:09:29.669: [iter 74 : loss : 0.1490 = 0.0571 + 0.0876 + 0.0043, time: 8.568323]
2023-05-17 11:09:29.828: epoch 74:	0.02555098  	0.18706411  	0.10150851  
2023-05-17 11:09:29.828: Find a better model.
2023-05-17 11:09:39.609: [iter 75 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0044, time: 9.771028]
2023-05-17 11:09:39.969: epoch 75:	0.02557921  	0.18732826  	0.10164739  
2023-05-17 11:09:39.969: Find a better model.
2023-05-17 11:09:49.100: [iter 76 : loss : 0.1474 = 0.0556 + 0.0874 + 0.0044, time: 9.127296]
2023-05-17 11:09:49.395: epoch 76:	0.02564272  	0.18769267  	0.10193035  
2023-05-17 11:09:49.395: Find a better model.
2023-05-17 11:09:58.297: [iter 77 : loss : 0.1462 = 0.0546 + 0.0872 + 0.0044, time: 8.895137]
2023-05-17 11:09:58.454: epoch 77:	0.02560744  	0.18775581  	0.10194322  
2023-05-17 11:09:58.454: Find a better model.
2023-05-17 11:10:07.444: [iter 78 : loss : 0.1453 = 0.0537 + 0.0871 + 0.0045, time: 8.987014]
2023-05-17 11:10:07.756: epoch 78:	0.02562155  	0.18782593  	0.10199840  
2023-05-17 11:10:07.756: Find a better model.
2023-05-17 11:10:18.172: [iter 79 : loss : 0.1442 = 0.0526 + 0.0870 + 0.0045, time: 10.414492]
2023-05-17 11:10:18.504: epoch 79:	0.02569212  	0.18866967  	0.10227805  
2023-05-17 11:10:18.504: Find a better model.
2023-05-17 11:10:28.628: [iter 80 : loss : 0.1436 = 0.0521 + 0.0869 + 0.0046, time: 10.114030]
2023-05-17 11:10:28.922: epoch 80:	0.02569918  	0.18860316  	0.10231505  
2023-05-17 11:10:36.962: [iter 81 : loss : 0.1432 = 0.0517 + 0.0868 + 0.0046, time: 8.038006]
2023-05-17 11:10:37.178: epoch 81:	0.02568506  	0.18840919  	0.10244112  
2023-05-17 11:10:46.601: [iter 82 : loss : 0.1419 = 0.0507 + 0.0866 + 0.0046, time: 9.420356]
2023-05-17 11:10:46.772: epoch 82:	0.02574152  	0.18925805  	0.10280991  
2023-05-17 11:10:46.772: Find a better model.
2023-05-17 11:10:55.936: [iter 83 : loss : 0.1409 = 0.0496 + 0.0866 + 0.0047, time: 9.162001]
2023-05-17 11:10:56.110: epoch 83:	0.02577680  	0.18934549  	0.10307281  
2023-05-17 11:10:56.110: Find a better model.
2023-05-17 11:11:04.621: [iter 84 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.510043]
2023-05-17 11:11:04.795: epoch 84:	0.02579797  	0.18929444  	0.10318284  
2023-05-17 11:11:14.878: [iter 85 : loss : 0.1402 = 0.0491 + 0.0864 + 0.0048, time: 10.080231]
2023-05-17 11:11:15.207: epoch 85:	0.02581208  	0.18984051  	0.10352521  
2023-05-17 11:11:15.207: Find a better model.
2023-05-17 11:11:25.248: [iter 86 : loss : 0.1398 = 0.0487 + 0.0863 + 0.0048, time: 10.039030]
2023-05-17 11:11:25.533: epoch 86:	0.02586147  	0.19032963  	0.10374895  
2023-05-17 11:11:25.533: Find a better model.
2023-05-17 11:11:34.994: [iter 87 : loss : 0.1371 = 0.0460 + 0.0862 + 0.0048, time: 9.458999]
2023-05-17 11:11:35.201: epoch 87:	0.02584736  	0.19015186  	0.10380702  
2023-05-17 11:11:45.017: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 9.811990]
2023-05-17 11:11:45.247: epoch 88:	0.02600260  	0.19113240  	0.10420953  
2023-05-17 11:11:45.247: Find a better model.
2023-05-17 11:11:54.435: [iter 89 : loss : 0.1360 = 0.0451 + 0.0860 + 0.0049, time: 9.184429]
2023-05-17 11:11:54.615: epoch 89:	0.02591792  	0.19023156  	0.10407533  
2023-05-17 11:12:04.634: [iter 90 : loss : 0.1366 = 0.0457 + 0.0860 + 0.0049, time: 10.011324]
2023-05-17 11:12:04.934: epoch 90:	0.02598142  	0.19071317  	0.10436962  
2023-05-17 11:12:13.880: [iter 91 : loss : 0.1351 = 0.0443 + 0.0858 + 0.0050, time: 8.943992]
2023-05-17 11:12:14.037: epoch 91:	0.02598142  	0.19073512  	0.10447375  
2023-05-17 11:12:22.413: [iter 92 : loss : 0.1344 = 0.0436 + 0.0858 + 0.0050, time: 8.375046]
2023-05-17 11:12:22.611: epoch 92:	0.02591792  	0.19046168  	0.10428022  
2023-05-17 11:12:32.171: [iter 93 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0051, time: 9.559005]
2023-05-17 11:12:32.397: epoch 93:	0.02596731  	0.19036576  	0.10444565  
2023-05-17 11:12:42.302: [iter 94 : loss : 0.1324 = 0.0417 + 0.0856 + 0.0051, time: 9.902026]
2023-05-17 11:12:42.639: epoch 94:	0.02609432  	0.19122027  	0.10493793  
2023-05-17 11:12:42.639: Find a better model.
2023-05-17 11:12:52.915: [iter 95 : loss : 0.1321 = 0.0414 + 0.0855 + 0.0051, time: 10.272074]
2023-05-17 11:12:53.257: epoch 95:	0.02605904  	0.19104367  	0.10497462  
2023-05-17 11:13:01.810: [iter 96 : loss : 0.1320 = 0.0414 + 0.0855 + 0.0052, time: 8.551010]
2023-05-17 11:13:01.988: epoch 96:	0.02608022  	0.19115922  	0.10506148  
2023-05-17 11:13:11.132: [iter 97 : loss : 0.1303 = 0.0397 + 0.0853 + 0.0052, time: 9.142041]
2023-05-17 11:13:11.292: epoch 97:	0.02605904  	0.19084854  	0.10506187  
2023-05-17 11:13:21.819: [iter 98 : loss : 0.1311 = 0.0405 + 0.0853 + 0.0052, time: 10.518096]
2023-05-17 11:13:22.147: epoch 98:	0.02605904  	0.19073914  	0.10527509  
2023-05-17 11:13:32.404: [iter 99 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0053, time: 10.251083]
2023-05-17 11:13:32.684: epoch 99:	0.02609432  	0.19084406  	0.10561183  
2023-05-17 11:13:42.839: [iter 100 : loss : 0.1291 = 0.0387 + 0.0851 + 0.0053, time: 10.153999]
2023-05-17 11:13:43.157: epoch 100:	0.02613666  	0.19093214  	0.10544772  
2023-05-17 11:13:52.069: [iter 101 : loss : 0.1288 = 0.0384 + 0.0850 + 0.0053, time: 8.908001]
2023-05-17 11:13:52.252: epoch 101:	0.02613665  	0.19101362  	0.10563608  
2023-05-17 11:14:00.581: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 8.327003]
2023-05-17 11:14:00.781: epoch 102:	0.02608726  	0.19083476  	0.10555620  
2023-05-17 11:14:10.457: [iter 103 : loss : 0.1276 = 0.0372 + 0.0849 + 0.0054, time: 9.674991]
2023-05-17 11:14:10.621: epoch 103:	0.02607314  	0.19076070  	0.10570557  
2023-05-17 11:14:20.310: [iter 104 : loss : 0.1283 = 0.0379 + 0.0849 + 0.0055, time: 9.677012]
2023-05-17 11:14:20.611: epoch 104:	0.02608726  	0.19086117  	0.10579214  
2023-05-17 11:14:30.390: [iter 105 : loss : 0.1273 = 0.0370 + 0.0848 + 0.0055, time: 9.776004]
2023-05-17 11:14:30.704: epoch 105:	0.02612959  	0.19094929  	0.10580046  
2023-05-17 11:14:39.739: [iter 106 : loss : 0.1268 = 0.0365 + 0.0848 + 0.0055, time: 9.033024]
2023-05-17 11:14:40.093: epoch 106:	0.02615076  	0.19150235  	0.10595793  
2023-05-17 11:14:40.102: Find a better model.
2023-05-17 11:14:48.695: [iter 107 : loss : 0.1258 = 0.0356 + 0.0847 + 0.0055, time: 8.591809]
2023-05-17 11:14:48.891: epoch 107:	0.02610137  	0.19116232  	0.10605649  
2023-05-17 11:14:57.764: [iter 108 : loss : 0.1258 = 0.0356 + 0.0846 + 0.0056, time: 8.872429]
2023-05-17 11:14:57.934: epoch 108:	0.02610843  	0.19119604  	0.10593282  
2023-05-17 11:15:08.604: [iter 109 : loss : 0.1245 = 0.0343 + 0.0845 + 0.0056, time: 10.667012]
2023-05-17 11:15:08.934: epoch 109:	0.02616488  	0.19171946  	0.10605983  
2023-05-17 11:15:08.934: Find a better model.
2023-05-17 11:15:19.179: [iter 110 : loss : 0.1237 = 0.0336 + 0.0845 + 0.0057, time: 10.240849]
2023-05-17 11:15:19.504: epoch 110:	0.02620016  	0.19175528  	0.10625139  
2023-05-17 11:15:19.504: Find a better model.
2023-05-17 11:15:29.042: [iter 111 : loss : 0.1238 = 0.0337 + 0.0844 + 0.0057, time: 9.537030]
2023-05-17 11:15:29.206: epoch 111:	0.02620722  	0.19180556  	0.10626961  
2023-05-17 11:15:29.206: Find a better model.
2023-05-17 11:15:37.734: [iter 112 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 8.526991]
2023-05-17 11:15:37.925: epoch 112:	0.02614371  	0.19138835  	0.10623044  
2023-05-17 11:15:47.864: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0058, time: 9.936033]
2023-05-17 11:15:48.063: epoch 113:	0.02608021  	0.19090612  	0.10608117  
2023-05-17 11:15:58.093: [iter 114 : loss : 0.1227 = 0.0326 + 0.0843 + 0.0058, time: 10.023004]
2023-05-17 11:15:58.390: epoch 114:	0.02612255  	0.19108841  	0.10623081  
2023-05-17 11:16:08.646: [iter 115 : loss : 0.1223 = 0.0322 + 0.0842 + 0.0058, time: 10.251979]
2023-05-17 11:16:08.959: epoch 115:	0.02617194  	0.19159390  	0.10630783  
2023-05-17 11:16:18.389: [iter 116 : loss : 0.1215 = 0.0315 + 0.0841 + 0.0059, time: 9.427005]
2023-05-17 11:16:18.568: epoch 116:	0.02618606  	0.19147775  	0.10659155  
2023-05-17 11:16:27.827: [iter 117 : loss : 0.1213 = 0.0313 + 0.0841 + 0.0059, time: 9.256927]
2023-05-17 11:16:28.805: epoch 117:	0.02618605  	0.19144775  	0.10666109  
2023-05-17 11:16:38.271: [iter 118 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 9.462233]
2023-05-17 11:16:38.568: epoch 118:	0.02623546  	0.19225194  	0.10684430  
2023-05-17 11:16:38.568: Find a better model.
2023-05-17 11:16:48.163: [iter 119 : loss : 0.1201 = 0.0302 + 0.0840 + 0.0060, time: 9.591676]
2023-05-17 11:16:48.475: epoch 119:	0.02621428  	0.19199957  	0.10695573  
2023-05-17 11:16:56.994: [iter 120 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0060, time: 8.518025]
2023-05-17 11:16:57.220: epoch 120:	0.02627779  	0.19236305  	0.10718540  
2023-05-17 11:16:57.220: Find a better model.
2023-05-17 11:17:06.711: [iter 121 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 9.488041]
2023-05-17 11:17:06.882: epoch 121:	0.02628485  	0.19198824  	0.10685381  
2023-05-17 11:17:16.258: [iter 122 : loss : 0.1198 = 0.0298 + 0.0839 + 0.0060, time: 9.374002]
2023-05-17 11:17:16.417: epoch 122:	0.02632719  	0.19207481  	0.10696726  
2023-05-17 11:17:25.015: [iter 123 : loss : 0.1194 = 0.0295 + 0.0838 + 0.0061, time: 8.595997]
2023-05-17 11:17:25.181: epoch 123:	0.02636247  	0.19235463  	0.10695972  
2023-05-17 11:17:35.676: [iter 124 : loss : 0.1186 = 0.0287 + 0.0838 + 0.0061, time: 10.490038]
2023-05-17 11:17:36.017: epoch 124:	0.02639070  	0.19220717  	0.10728084  
2023-05-17 11:17:46.101: [iter 125 : loss : 0.1179 = 0.0280 + 0.0837 + 0.0061, time: 10.080031]
2023-05-17 11:17:46.478: epoch 125:	0.02641186  	0.19265947  	0.10751335  
2023-05-17 11:17:46.478: Find a better model.
2023-05-17 11:17:55.853: [iter 126 : loss : 0.1181 = 0.0282 + 0.0837 + 0.0062, time: 9.373752]
2023-05-17 11:17:56.024: epoch 126:	0.02640481  	0.19266653  	0.10749272  
2023-05-17 11:17:56.024: Find a better model.
2023-05-17 11:18:05.579: [iter 127 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 9.553991]
2023-05-17 11:18:05.912: epoch 127:	0.02648243  	0.19359700  	0.10788724  
2023-05-17 11:18:05.912: Find a better model.
2023-05-17 11:18:14.541: [iter 128 : loss : 0.1184 = 0.0286 + 0.0836 + 0.0062, time: 8.595130]
2023-05-17 11:18:14.703: epoch 128:	0.02640481  	0.19303633  	0.10770799  
2023-05-17 11:18:24.397: [iter 129 : loss : 0.1174 = 0.0276 + 0.0835 + 0.0063, time: 9.683036]
2023-05-17 11:18:24.696: epoch 129:	0.02639775  	0.19287108  	0.10764125  
2023-05-17 11:18:32.909: [iter 130 : loss : 0.1174 = 0.0277 + 0.0835 + 0.0063, time: 8.210992]
2023-05-17 11:18:33.085: epoch 130:	0.02636247  	0.19258979  	0.10756598  
2023-05-17 11:18:42.276: [iter 131 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 9.189992]
2023-05-17 11:18:42.434: epoch 131:	0.02639069  	0.19287185  	0.10760559  
2023-05-17 11:18:51.683: [iter 132 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 9.248642]
2023-05-17 11:18:51.847: epoch 132:	0.02642597  	0.19311494  	0.10768023  
2023-05-17 11:19:00.617: [iter 133 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 8.766132]
2023-05-17 11:19:00.907: epoch 133:	0.02641186  	0.19277155  	0.10770655  
2023-05-17 11:19:10.938: [iter 134 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0064, time: 10.029135]
2023-05-17 11:19:11.252: epoch 134:	0.02646125  	0.19317965  	0.10783603  
2023-05-17 11:19:20.641: [iter 135 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 9.387002]
2023-05-17 11:19:20.825: epoch 135:	0.02636246  	0.19259477  	0.10763548  
2023-05-17 11:19:30.235: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 9.408028]
2023-05-17 11:19:30.407: epoch 136:	0.02636952  	0.19273305  	0.10768196  
2023-05-17 11:19:39.105: [iter 137 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 8.696991]
2023-05-17 11:19:39.701: epoch 137:	0.02645419  	0.19331564  	0.10798450  
2023-05-17 11:19:48.209: [iter 138 : loss : 0.1147 = 0.0250 + 0.0831 + 0.0065, time: 8.506036]
2023-05-17 11:19:48.373: epoch 138:	0.02644714  	0.19304965  	0.10798237  
2023-05-17 11:19:58.278: [iter 139 : loss : 0.1146 = 0.0250 + 0.0830 + 0.0066, time: 9.903008]
2023-05-17 11:19:58.608: epoch 139:	0.02644714  	0.19300488  	0.10828938  
2023-05-17 11:20:08.887: [iter 140 : loss : 0.1138 = 0.0241 + 0.0831 + 0.0066, time: 10.277358]
2023-05-17 11:20:09.209: epoch 140:	0.02636246  	0.19261177  	0.10831743  
2023-05-17 11:20:18.602: [iter 141 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 9.390995]
2023-05-17 11:20:18.763: epoch 141:	0.02643302  	0.19290693  	0.10850157  
2023-05-17 11:20:27.182: [iter 142 : loss : 0.1137 = 0.0240 + 0.0830 + 0.0066, time: 8.416992]
2023-05-17 11:20:27.446: epoch 142:	0.02629190  	0.19180830  	0.10819220  
2023-05-17 11:20:37.395: [iter 143 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0067, time: 9.935237]
2023-05-17 11:20:37.659: epoch 143:	0.02629190  	0.19222319  	0.10808651  
2023-05-17 11:20:47.534: [iter 144 : loss : 0.1130 = 0.0235 + 0.0829 + 0.0067, time: 9.871059]
2023-05-17 11:20:47.861: epoch 144:	0.02625662  	0.19196746  	0.10809282  
2023-05-17 11:20:56.720: [iter 145 : loss : 0.1130 = 0.0234 + 0.0829 + 0.0067, time: 8.857461]
2023-05-17 11:20:56.887: epoch 145:	0.02637657  	0.19305852  	0.10839936  
2023-05-17 11:21:05.663: [iter 146 : loss : 0.1132 = 0.0236 + 0.0828 + 0.0067, time: 8.775024]
2023-05-17 11:21:05.830: epoch 146:	0.02640480  	0.19301338  	0.10838033  
2023-05-17 11:21:14.655: [iter 147 : loss : 0.1131 = 0.0235 + 0.0828 + 0.0068, time: 8.822992]
2023-05-17 11:21:14.857: epoch 147:	0.02643302  	0.19336694  	0.10856558  
2023-05-17 11:21:23.998: [iter 148 : loss : 0.1119 = 0.0224 + 0.0828 + 0.0068, time: 9.132163]
2023-05-17 11:21:24.165: epoch 148:	0.02644008  	0.19322951  	0.10852457  
2023-05-17 11:21:34.460: [iter 149 : loss : 0.1120 = 0.0224 + 0.0827 + 0.0068, time: 10.293080]
2023-05-17 11:21:34.809: epoch 149:	0.02636246  	0.19269402  	0.10853308  
2023-05-17 11:21:44.432: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 9.620005]
2023-05-17 11:21:44.748: epoch 150:	0.02639774  	0.19317843  	0.10850594  
2023-05-17 11:21:54.091: [iter 151 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0069, time: 9.340991]
2023-05-17 11:21:54.251: epoch 151:	0.02636953  	0.19286272  	0.10837793  
2023-05-17 11:22:03.588: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 9.332467]
2023-05-17 11:22:03.856: epoch 152:	0.02632718  	0.19237858  	0.10815187  
2023-05-17 11:22:03.856: Early stopping is trigger at epoch: 152
2023-05-17 11:22:03.856: best_result@epoch 127:

2023-05-17 11:22:03.857: 		0.0265      	0.1936      	0.1079      
2023-05-17 14:35:45.937: my pid: 1180
2023-05-17 14:35:45.937: model: model.general_recommender.SGL
2023-05-17 14:35:45.937: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 14:35:45.937: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 14:35:49.965: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 14:36:00.624: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.655213]
2023-05-17 14:36:00.937: epoch 1:	0.00139712  	0.00973021  	0.00481532  
2023-05-17 14:36:00.937: Find a better model.
2023-05-17 14:36:12.053: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 11.111057]
2023-05-17 14:36:12.359: epoch 2:	0.00232854  	0.01778010  	0.00799579  
2023-05-17 14:36:12.359: Find a better model.
2023-05-17 14:36:22.015: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 9.654031]
2023-05-17 14:36:22.215: epoch 3:	0.00488990  	0.03615986  	0.01704150  
2023-05-17 14:36:22.215: Find a better model.
2023-05-17 14:36:31.827: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 9.609207]
2023-05-17 14:36:31.998: epoch 4:	0.00788873  	0.05842554  	0.02826452  
2023-05-17 14:36:31.998: Find a better model.
2023-05-17 14:36:42.740: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 10.739025]
2023-05-17 14:36:43.068: epoch 5:	0.01143807  	0.08284291  	0.04003598  
2023-05-17 14:36:43.068: Find a better model.
2023-05-17 14:36:52.709: [iter 6 : loss : 0.7672 = 0.6880 + 0.0792 + 0.0000, time: 9.637122]
2023-05-17 14:36:52.987: epoch 6:	0.01507214  	0.10933714  	0.05305913  
2023-05-17 14:36:52.987: Find a better model.
2023-05-17 14:37:01.987: [iter 7 : loss : 0.7608 = 0.6808 + 0.0799 + 0.0000, time: 8.998296]
2023-05-17 14:37:02.157: epoch 7:	0.01749955  	0.12724802  	0.06307527  
2023-05-17 14:37:02.158: Find a better model.
2023-05-17 14:37:11.347: [iter 8 : loss : 0.7448 = 0.6629 + 0.0819 + 0.0001, time: 9.183010]
2023-05-17 14:37:11.636: epoch 8:	0.01862857  	0.13527755  	0.06834161  
2023-05-17 14:37:11.636: Find a better model.
2023-05-17 14:37:21.094: [iter 9 : loss : 0.7088 = 0.6228 + 0.0858 + 0.0001, time: 9.456442]
2023-05-17 14:37:21.274: epoch 9:	0.01866386  	0.13699655  	0.06890173  
2023-05-17 14:37:21.274: Find a better model.
2023-05-17 14:37:31.094: [iter 10 : loss : 0.6467 = 0.5550 + 0.0914 + 0.0003, time: 9.817577]
2023-05-17 14:37:31.396: epoch 10:	0.01862151  	0.13708515  	0.06856530  
2023-05-17 14:37:31.396: Find a better model.
2023-05-17 14:37:41.940: [iter 11 : loss : 0.5701 = 0.4732 + 0.0965 + 0.0004, time: 10.540025]
2023-05-17 14:37:42.260: epoch 11:	0.01831103  	0.13503587  	0.06788893  
2023-05-17 14:37:51.784: [iter 12 : loss : 0.5015 = 0.4010 + 0.0999 + 0.0006, time: 9.522003]
2023-05-17 14:37:51.975: epoch 12:	0.01819107  	0.13395958  	0.06781143  
2023-05-17 14:38:01.616: [iter 13 : loss : 0.4516 = 0.3491 + 0.1017 + 0.0007, time: 9.640058]
2023-05-17 14:38:01.780: epoch 13:	0.01831808  	0.13485660  	0.06829187  
2023-05-17 14:38:11.008: [iter 14 : loss : 0.4141 = 0.3105 + 0.1027 + 0.0008, time: 9.224051]
2023-05-17 14:38:11.350: epoch 14:	0.01855800  	0.13658218  	0.06921060  
2023-05-17 14:38:21.370: [iter 15 : loss : 0.3879 = 0.2840 + 0.1030 + 0.0010, time: 10.018040]
2023-05-17 14:38:21.666: epoch 15:	0.01886850  	0.13923034  	0.07040487  
2023-05-17 14:38:21.666: Find a better model.
2023-05-17 14:38:30.338: [iter 16 : loss : 0.3660 = 0.2620 + 0.1029 + 0.0011, time: 8.670002]
2023-05-17 14:38:30.526: epoch 16:	0.01909430  	0.14104393  	0.07132905  
2023-05-17 14:38:30.526: Find a better model.
2023-05-17 14:38:39.887: [iter 17 : loss : 0.3498 = 0.2459 + 0.1027 + 0.0012, time: 9.357643]
2023-05-17 14:38:40.171: epoch 17:	0.01933422  	0.14286852  	0.07244731  
2023-05-17 14:38:40.171: Find a better model.
2023-05-17 14:38:49.964: [iter 18 : loss : 0.3349 = 0.2311 + 0.1025 + 0.0013, time: 9.792047]
2023-05-17 14:38:50.123: epoch 18:	0.01956709  	0.14431378  	0.07333781  
2023-05-17 14:38:50.123: Find a better model.
2023-05-17 14:39:00.051: [iter 19 : loss : 0.3208 = 0.2173 + 0.1021 + 0.0014, time: 9.924015]
2023-05-17 14:39:00.362: epoch 19:	0.01969411  	0.14551553  	0.07410011  
2023-05-17 14:39:00.362: Find a better model.
2023-05-17 14:39:10.643: [iter 20 : loss : 0.3114 = 0.2082 + 0.1017 + 0.0015, time: 10.277964]
2023-05-17 14:39:10.991: epoch 20:	0.01987052  	0.14702129  	0.07475156  
2023-05-17 14:39:10.992: Find a better model.
2023-05-17 14:39:20.069: [iter 21 : loss : 0.3018 = 0.1990 + 0.1013 + 0.0016, time: 9.075034]
2023-05-17 14:39:20.265: epoch 21:	0.02009634  	0.14844935  	0.07551041  
2023-05-17 14:39:20.266: Find a better model.
2023-05-17 14:39:28.682: [iter 22 : loss : 0.2935 = 0.1911 + 0.1008 + 0.0016, time: 8.412006]
2023-05-17 14:39:28.846: epoch 22:	0.02022335  	0.14939928  	0.07608163  
2023-05-17 14:39:28.846: Find a better model.
2023-05-17 14:39:38.868: [iter 23 : loss : 0.2851 = 0.1830 + 0.1004 + 0.0017, time: 10.019425]
2023-05-17 14:39:39.164: epoch 23:	0.02046327  	0.15105867  	0.07694166  
2023-05-17 14:39:39.164: Find a better model.
2023-05-17 14:39:49.263: [iter 24 : loss : 0.2786 = 0.1769 + 0.0999 + 0.0018, time: 10.094049]
2023-05-17 14:39:49.567: epoch 24:	0.02062557  	0.15212984  	0.07768541  
2023-05-17 14:39:49.567: Find a better model.
2023-05-17 14:39:59.285: [iter 25 : loss : 0.2722 = 0.1708 + 0.0995 + 0.0019, time: 9.717015]
2023-05-17 14:39:59.491: epoch 25:	0.02088666  	0.15381134  	0.07847090  
2023-05-17 14:39:59.491: Find a better model.
2023-05-17 14:40:08.484: [iter 26 : loss : 0.2685 = 0.1674 + 0.0991 + 0.0019, time: 8.991028]
2023-05-17 14:40:08.697: epoch 26:	0.02110542  	0.15550739  	0.07920548  
2023-05-17 14:40:08.698: Find a better model.
2023-05-17 14:40:18.123: [iter 27 : loss : 0.2607 = 0.1601 + 0.0986 + 0.0020, time: 9.424003]
2023-05-17 14:40:18.315: epoch 27:	0.02125361  	0.15655062  	0.07989101  
2023-05-17 14:40:18.315: Find a better model.
2023-05-17 14:40:27.100: [iter 28 : loss : 0.2558 = 0.1555 + 0.0983 + 0.0021, time: 8.784013]
2023-05-17 14:40:27.263: epoch 28:	0.02150059  	0.15829925  	0.08089320  
2023-05-17 14:40:27.263: Find a better model.
2023-05-17 14:40:37.671: [iter 29 : loss : 0.2512 = 0.1513 + 0.0978 + 0.0021, time: 10.404225]
2023-05-17 14:40:38.005: epoch 29:	0.02150059  	0.15850621  	0.08132182  
2023-05-17 14:40:38.005: Find a better model.
2023-05-17 14:40:47.924: [iter 30 : loss : 0.2446 = 0.1449 + 0.0975 + 0.0022, time: 9.917023]
2023-05-17 14:40:48.108: epoch 30:	0.02169817  	0.15989661  	0.08218201  
2023-05-17 14:40:48.108: Find a better model.
2023-05-17 14:40:57.627: [iter 31 : loss : 0.2412 = 0.1419 + 0.0970 + 0.0022, time: 9.517001]
2023-05-17 14:40:57.815: epoch 31:	0.02190280  	0.16129631  	0.08287822  
2023-05-17 14:40:57.816: Find a better model.
2023-05-17 14:41:07.196: [iter 32 : loss : 0.2356 = 0.1365 + 0.0967 + 0.0023, time: 9.377301]
2023-05-17 14:41:07.536: epoch 32:	0.02214979  	0.16311915  	0.08395141  
2023-05-17 14:41:07.537: Find a better model.
2023-05-17 14:41:16.299: [iter 33 : loss : 0.2328 = 0.1342 + 0.0962 + 0.0024, time: 8.740062]
2023-05-17 14:41:16.462: epoch 33:	0.02224857  	0.16423459  	0.08456232  
2023-05-17 14:41:16.462: Find a better model.
2023-05-17 14:41:26.479: [iter 34 : loss : 0.2289 = 0.1305 + 0.0959 + 0.0024, time: 10.006618]
2023-05-17 14:41:26.770: epoch 34:	0.02243910  	0.16544805  	0.08543114  
2023-05-17 14:41:26.770: Find a better model.
2023-05-17 14:41:36.962: [iter 35 : loss : 0.2252 = 0.1271 + 0.0956 + 0.0025, time: 10.184004]
2023-05-17 14:41:37.254: epoch 35:	0.02245321  	0.16576928  	0.08584732  
2023-05-17 14:41:37.254: Find a better model.
2023-05-17 14:41:46.724: [iter 36 : loss : 0.2218 = 0.1240 + 0.0953 + 0.0025, time: 9.466044]
2023-05-17 14:41:46.899: epoch 36:	0.02258728  	0.16671574  	0.08639689  
2023-05-17 14:41:46.899: Find a better model.
2023-05-17 14:41:56.620: [iter 37 : loss : 0.2180 = 0.1204 + 0.0950 + 0.0026, time: 9.718972]
2023-05-17 14:41:56.801: epoch 37:	0.02263667  	0.16702631  	0.08686522  
2023-05-17 14:41:56.801: Find a better model.
2023-05-17 14:42:05.628: [iter 38 : loss : 0.2163 = 0.1191 + 0.0946 + 0.0026, time: 8.824943]
2023-05-17 14:42:05.810: epoch 38:	0.02284132  	0.16863251  	0.08774815  
2023-05-17 14:42:05.810: Find a better model.
2023-05-17 14:42:15.896: [iter 39 : loss : 0.2119 = 0.1149 + 0.0943 + 0.0027, time: 10.084001]
2023-05-17 14:42:16.191: epoch 39:	0.02297539  	0.16933128  	0.08823401  
2023-05-17 14:42:16.191: Find a better model.
2023-05-17 14:42:24.823: [iter 40 : loss : 0.2087 = 0.1119 + 0.0941 + 0.0028, time: 8.631711]
2023-05-17 14:42:25.069: epoch 40:	0.02313063  	0.17058444  	0.08893771  
2023-05-17 14:42:25.069: Find a better model.
2023-05-17 14:42:33.321: [iter 41 : loss : 0.2067 = 0.1101 + 0.0938 + 0.0028, time: 8.250002]
2023-05-17 14:42:33.481: epoch 41:	0.02322236  	0.17147784  	0.08946689  
2023-05-17 14:42:33.481: Find a better model.
2023-05-17 14:42:42.828: [iter 42 : loss : 0.2047 = 0.1084 + 0.0934 + 0.0029, time: 9.344992]
2023-05-17 14:42:43.012: epoch 42:	0.02332821  	0.17224470  	0.08994941  
2023-05-17 14:42:43.012: Find a better model.
2023-05-17 14:42:53.138: [iter 43 : loss : 0.2010 = 0.1049 + 0.0932 + 0.0029, time: 10.121048]
2023-05-17 14:42:53.467: epoch 43:	0.02343405  	0.17292328  	0.09054996  
2023-05-17 14:42:53.467: Find a better model.
2023-05-17 14:43:03.771: [iter 44 : loss : 0.1971 = 0.1013 + 0.0929 + 0.0030, time: 10.299958]
2023-05-17 14:43:04.098: epoch 44:	0.02351873  	0.17325121  	0.09101827  
2023-05-17 14:43:04.098: Find a better model.
2023-05-17 14:43:12.504: [iter 45 : loss : 0.1950 = 0.0993 + 0.0927 + 0.0030, time: 8.403993]
2023-05-17 14:43:12.668: epoch 45:	0.02371632  	0.17443877  	0.09174124  
2023-05-17 14:43:12.668: Find a better model.
2023-05-17 14:43:21.684: [iter 46 : loss : 0.1928 = 0.0973 + 0.0924 + 0.0031, time: 9.014991]
2023-05-17 14:43:21.848: epoch 46:	0.02382922  	0.17551042  	0.09246852  
2023-05-17 14:43:21.848: Find a better model.
2023-05-17 14:43:31.424: [iter 47 : loss : 0.1917 = 0.0965 + 0.0922 + 0.0031, time: 9.573951]
2023-05-17 14:43:31.603: epoch 47:	0.02380805  	0.17563702  	0.09275871  
2023-05-17 14:43:31.604: Find a better model.
2023-05-17 14:43:41.225: [iter 48 : loss : 0.1880 = 0.0929 + 0.0919 + 0.0032, time: 9.618039]
2023-05-17 14:43:41.532: epoch 48:	0.02397035  	0.17694502  	0.09351180  
2023-05-17 14:43:41.532: Find a better model.
2023-05-17 14:43:51.465: [iter 49 : loss : 0.1847 = 0.0898 + 0.0917 + 0.0032, time: 9.931450]
2023-05-17 14:43:51.788: epoch 49:	0.02396329  	0.17671525  	0.09372444  
2023-05-17 14:44:00.405: [iter 50 : loss : 0.1842 = 0.0894 + 0.0915 + 0.0032, time: 8.615013]
2023-05-17 14:44:00.594: epoch 50:	0.02403385  	0.17721434  	0.09413436  
2023-05-17 14:44:00.594: Find a better model.
2023-05-17 14:44:09.813: [iter 51 : loss : 0.1812 = 0.0866 + 0.0913 + 0.0033, time: 9.217022]
2023-05-17 14:44:09.985: epoch 51:	0.02410442  	0.17801568  	0.09465928  
2023-05-17 14:44:09.985: Find a better model.
2023-05-17 14:44:19.817: [iter 52 : loss : 0.1811 = 0.0866 + 0.0911 + 0.0033, time: 9.829486]
2023-05-17 14:44:19.973: epoch 52:	0.02411853  	0.17827792  	0.09474909  
2023-05-17 14:44:19.974: Find a better model.
2023-05-17 14:44:29.279: [iter 53 : loss : 0.1789 = 0.0846 + 0.0909 + 0.0034, time: 9.303992]
2023-05-17 14:44:29.573: epoch 53:	0.02437962  	0.18011825  	0.09557125  
2023-05-17 14:44:29.574: Find a better model.
2023-05-17 14:44:39.503: [iter 54 : loss : 0.1767 = 0.0826 + 0.0907 + 0.0034, time: 9.926465]
2023-05-17 14:44:39.835: epoch 54:	0.02437962  	0.17995994  	0.09601206  
2023-05-17 14:44:49.670: [iter 55 : loss : 0.1749 = 0.0809 + 0.0905 + 0.0035, time: 9.829029]
2023-05-17 14:44:49.958: epoch 55:	0.02441490  	0.18002801  	0.09620947  
2023-05-17 14:44:59.075: [iter 56 : loss : 0.1730 = 0.0792 + 0.0903 + 0.0035, time: 9.115006]
2023-05-17 14:44:59.264: epoch 56:	0.02447136  	0.18020841  	0.09656502  
2023-05-17 14:44:59.264: Find a better model.
2023-05-17 14:45:08.384: [iter 57 : loss : 0.1713 = 0.0776 + 0.0901 + 0.0036, time: 9.117646]
2023-05-17 14:45:08.553: epoch 57:	0.02469715  	0.18191785  	0.09709396  
2023-05-17 14:45:08.553: Find a better model.
2023-05-17 14:45:18.947: [iter 58 : loss : 0.1692 = 0.0757 + 0.0899 + 0.0036, time: 10.391010]
2023-05-17 14:45:19.277: epoch 58:	0.02465482  	0.18160081  	0.09723972  
2023-05-17 14:45:28.797: [iter 59 : loss : 0.1684 = 0.0750 + 0.0898 + 0.0037, time: 9.510001]
2023-05-17 14:45:29.091: epoch 59:	0.02468304  	0.18166074  	0.09757265  
2023-05-17 14:45:38.088: [iter 60 : loss : 0.1666 = 0.0733 + 0.0896 + 0.0037, time: 8.996383]
2023-05-17 14:45:38.259: epoch 60:	0.02476067  	0.18247618  	0.09817443  
2023-05-17 14:45:38.259: Find a better model.
2023-05-17 14:45:48.171: [iter 61 : loss : 0.1653 = 0.0721 + 0.0894 + 0.0038, time: 9.910991]
2023-05-17 14:45:48.455: epoch 61:	0.02476066  	0.18239892  	0.09837990  
2023-05-17 14:45:57.817: [iter 62 : loss : 0.1638 = 0.0707 + 0.0893 + 0.0038, time: 9.359515]
2023-05-17 14:45:58.031: epoch 62:	0.02483828  	0.18270762  	0.09869663  
2023-05-17 14:45:58.031: Find a better model.
2023-05-17 14:46:08.023: [iter 63 : loss : 0.1625 = 0.0696 + 0.0891 + 0.0038, time: 9.987910]
2023-05-17 14:46:08.464: epoch 63:	0.02495824  	0.18339311  	0.09920882  
2023-05-17 14:46:08.464: Find a better model.
2023-05-17 14:46:18.804: [iter 64 : loss : 0.1615 = 0.0687 + 0.0889 + 0.0039, time: 10.337422]
2023-05-17 14:46:19.144: epoch 64:	0.02504292  	0.18471299  	0.09966797  
2023-05-17 14:46:19.144: Find a better model.
2023-05-17 14:46:29.076: [iter 65 : loss : 0.1601 = 0.0674 + 0.0887 + 0.0039, time: 9.930053]
2023-05-17 14:46:29.284: epoch 65:	0.02509231  	0.18505241  	0.10000827  
2023-05-17 14:46:29.285: Find a better model.
2023-05-17 14:46:38.016: [iter 66 : loss : 0.1586 = 0.0661 + 0.0886 + 0.0040, time: 8.727213]
2023-05-17 14:46:38.188: epoch 66:	0.02526167  	0.18619102  	0.10051733  
2023-05-17 14:46:38.189: Find a better model.
2023-05-17 14:46:48.047: [iter 67 : loss : 0.1569 = 0.0644 + 0.0885 + 0.0040, time: 9.856157]
2023-05-17 14:46:48.327: epoch 67:	0.02526167  	0.18616076  	0.10084298  
2023-05-17 14:46:58.208: [iter 68 : loss : 0.1568 = 0.0644 + 0.0883 + 0.0041, time: 9.877722]
2023-05-17 14:46:58.527: epoch 68:	0.02545219  	0.18734914  	0.10140567  
2023-05-17 14:46:58.527: Find a better model.
2023-05-17 14:47:06.836: [iter 69 : loss : 0.1547 = 0.0624 + 0.0882 + 0.0041, time: 8.307002]
2023-05-17 14:47:07.020: epoch 69:	0.02542397  	0.18729809  	0.10155908  
2023-05-17 14:47:16.777: [iter 70 : loss : 0.1531 = 0.0609 + 0.0881 + 0.0041, time: 9.756018]
2023-05-17 14:47:17.060: epoch 70:	0.02544513  	0.18764518  	0.10164198  
2023-05-17 14:47:17.060: Find a better model.
2023-05-17 14:47:26.964: [iter 71 : loss : 0.1516 = 0.0595 + 0.0879 + 0.0042, time: 9.902001]
2023-05-17 14:47:27.221: epoch 71:	0.02546630  	0.18771607  	0.10175271  
2023-05-17 14:47:27.221: Find a better model.
2023-05-17 14:47:37.725: [iter 72 : loss : 0.1514 = 0.0594 + 0.0878 + 0.0042, time: 10.501014]
2023-05-17 14:47:38.043: epoch 72:	0.02545219  	0.18778102  	0.10204399  
2023-05-17 14:47:38.043: Find a better model.
2023-05-17 14:47:48.356: [iter 73 : loss : 0.1501 = 0.0582 + 0.0877 + 0.0043, time: 10.310011]
2023-05-17 14:47:48.702: epoch 73:	0.02552981  	0.18830818  	0.10224522  
2023-05-17 14:47:48.702: Find a better model.
2023-05-17 14:47:57.384: [iter 74 : loss : 0.1488 = 0.0569 + 0.0876 + 0.0043, time: 8.680419]
2023-05-17 14:47:57.566: epoch 74:	0.02549453  	0.18798970  	0.10240705  
2023-05-17 14:48:06.654: [iter 75 : loss : 0.1478 = 0.0561 + 0.0874 + 0.0043, time: 9.086010]
2023-05-17 14:48:06.835: epoch 75:	0.02560743  	0.18892254  	0.10272520  
2023-05-17 14:48:06.835: Find a better model.
2023-05-17 14:48:16.678: [iter 76 : loss : 0.1472 = 0.0555 + 0.0873 + 0.0044, time: 9.841358]
2023-05-17 14:48:16.973: epoch 76:	0.02568505  	0.18931815  	0.10297493  
2023-05-17 14:48:16.973: Find a better model.
2023-05-17 14:48:27.579: [iter 77 : loss : 0.1460 = 0.0544 + 0.0872 + 0.0044, time: 10.599024]
2023-05-17 14:48:27.847: epoch 77:	0.02569210  	0.18962173  	0.10314226  
2023-05-17 14:48:27.847: Find a better model.
2023-05-17 14:48:38.118: [iter 78 : loss : 0.1451 = 0.0536 + 0.0871 + 0.0045, time: 10.268352]
2023-05-17 14:48:38.437: epoch 78:	0.02574856  	0.18971659  	0.10327696  
2023-05-17 14:48:38.438: Find a better model.
2023-05-17 14:48:47.080: [iter 79 : loss : 0.1439 = 0.0524 + 0.0870 + 0.0045, time: 8.640405]
2023-05-17 14:48:47.267: epoch 79:	0.02576268  	0.18979248  	0.10332216  
2023-05-17 14:48:47.267: Find a better model.
2023-05-17 14:48:55.570: [iter 80 : loss : 0.1431 = 0.0517 + 0.0869 + 0.0045, time: 8.298504]
2023-05-17 14:48:55.768: epoch 80:	0.02581207  	0.18997508  	0.10360600  
2023-05-17 14:48:55.768: Find a better model.
2023-05-17 14:49:05.541: [iter 81 : loss : 0.1428 = 0.0515 + 0.0867 + 0.0046, time: 9.771080]
2023-05-17 14:49:05.715: epoch 81:	0.02582618  	0.19029208  	0.10368318  
2023-05-17 14:49:05.715: Find a better model.
2023-05-17 14:49:15.336: [iter 82 : loss : 0.1417 = 0.0504 + 0.0866 + 0.0046, time: 9.616067]
2023-05-17 14:49:15.643: epoch 82:	0.02581913  	0.19028167  	0.10384350  
2023-05-17 14:49:25.434: [iter 83 : loss : 0.1405 = 0.0494 + 0.0865 + 0.0047, time: 9.782012]
2023-05-17 14:49:25.731: epoch 83:	0.02589675  	0.19067715  	0.10418310  
2023-05-17 14:49:25.731: Find a better model.
2023-05-17 14:49:35.561: [iter 84 : loss : 0.1405 = 0.0493 + 0.0864 + 0.0047, time: 9.823022]
2023-05-17 14:49:35.861: epoch 84:	0.02598143  	0.19179131  	0.10448584  
2023-05-17 14:49:35.861: Find a better model.
2023-05-17 14:49:45.627: [iter 85 : loss : 0.1394 = 0.0483 + 0.0864 + 0.0047, time: 9.763002]
2023-05-17 14:49:45.796: epoch 85:	0.02603082  	0.19229782  	0.10475250  
2023-05-17 14:49:45.797: Find a better model.
2023-05-17 14:49:54.402: [iter 86 : loss : 0.1394 = 0.0484 + 0.0862 + 0.0048, time: 8.604233]
2023-05-17 14:49:54.560: epoch 86:	0.02600965  	0.19206081  	0.10471661  
2023-05-17 14:50:05.023: [iter 87 : loss : 0.1366 = 0.0457 + 0.0862 + 0.0048, time: 10.459904]
2023-05-17 14:50:05.349: epoch 87:	0.02603082  	0.19223888  	0.10482585  
2023-05-17 14:50:15.277: [iter 88 : loss : 0.1360 = 0.0451 + 0.0861 + 0.0049, time: 9.926967]
2023-05-17 14:50:15.633: epoch 88:	0.02609433  	0.19264401  	0.10508929  
2023-05-17 14:50:15.633: Find a better model.
2023-05-17 14:50:25.157: [iter 89 : loss : 0.1355 = 0.0446 + 0.0860 + 0.0049, time: 9.520003]
2023-05-17 14:50:25.405: epoch 89:	0.02610844  	0.19266520  	0.10503434  
2023-05-17 14:50:25.405: Find a better model.
2023-05-17 14:50:35.444: [iter 90 : loss : 0.1363 = 0.0455 + 0.0859 + 0.0049, time: 10.037001]
2023-05-17 14:50:35.720: epoch 90:	0.02617196  	0.19327189  	0.10538500  
2023-05-17 14:50:35.720: Find a better model.
2023-05-17 14:50:44.425: [iter 91 : loss : 0.1348 = 0.0441 + 0.0858 + 0.0050, time: 8.702014]
2023-05-17 14:50:44.610: epoch 91:	0.02621429  	0.19346453  	0.10551685  
2023-05-17 14:50:44.610: Find a better model.
2023-05-17 14:50:54.347: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 9.734003]
2023-05-17 14:50:54.697: epoch 92:	0.02622841  	0.19366616  	0.10552638  
2023-05-17 14:50:54.697: Find a better model.
2023-05-17 14:51:03.777: [iter 93 : loss : 0.1342 = 0.0436 + 0.0856 + 0.0050, time: 9.078306]
2023-05-17 14:51:04.071: epoch 93:	0.02622135  	0.19330041  	0.10552869  
2023-05-17 14:51:13.337: [iter 94 : loss : 0.1322 = 0.0416 + 0.0855 + 0.0051, time: 9.265013]
2023-05-17 14:51:13.494: epoch 94:	0.02620724  	0.19309358  	0.10577030  
2023-05-17 14:51:22.821: [iter 95 : loss : 0.1315 = 0.0409 + 0.0855 + 0.0051, time: 9.324044]
2023-05-17 14:51:23.015: epoch 95:	0.02627780  	0.19362229  	0.10618118  
2023-05-17 14:51:32.990: [iter 96 : loss : 0.1316 = 0.0411 + 0.0854 + 0.0052, time: 9.968278]
2023-05-17 14:51:33.314: epoch 96:	0.02631308  	0.19377330  	0.10626801  
2023-05-17 14:51:33.314: Find a better model.
2023-05-17 14:51:43.343: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 10.025037]
2023-05-17 14:51:43.607: epoch 97:	0.02638365  	0.19435272  	0.10640540  
2023-05-17 14:51:43.607: Find a better model.
2023-05-17 14:51:52.893: [iter 98 : loss : 0.1309 = 0.0404 + 0.0853 + 0.0052, time: 9.285270]
2023-05-17 14:51:53.294: epoch 98:	0.02643304  	0.19453405  	0.10653670  
2023-05-17 14:51:53.294: Find a better model.
2023-05-17 14:52:02.183: [iter 99 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0053, time: 8.884004]
2023-05-17 14:52:02.386: epoch 99:	0.02641893  	0.19436850  	0.10649914  
2023-05-17 14:52:12.104: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 9.716004]
2023-05-17 14:52:12.343: epoch 100:	0.02644010  	0.19452040  	0.10646693  
2023-05-17 14:52:22.374: [iter 101 : loss : 0.1286 = 0.0382 + 0.0850 + 0.0053, time: 10.027018]
2023-05-17 14:52:22.637: epoch 101:	0.02641187  	0.19454023  	0.10656072  
2023-05-17 14:52:22.637: Find a better model.
2023-05-17 14:52:32.788: [iter 102 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 10.148028]
2023-05-17 14:52:33.117: epoch 102:	0.02631308  	0.19392228  	0.10653134  
2023-05-17 14:52:42.118: [iter 103 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 9.000034]
2023-05-17 14:52:42.451: epoch 103:	0.02644010  	0.19499643  	0.10693090  
2023-05-17 14:52:42.451: Find a better model.
2023-05-17 14:52:51.083: [iter 104 : loss : 0.1279 = 0.0377 + 0.0848 + 0.0054, time: 8.630011]
2023-05-17 14:52:51.280: epoch 104:	0.02644009  	0.19511274  	0.10708318  
2023-05-17 14:52:51.280: Find a better model.
2023-05-17 14:53:01.472: [iter 105 : loss : 0.1271 = 0.0369 + 0.0847 + 0.0055, time: 10.189446]
2023-05-17 14:53:01.777: epoch 105:	0.02648949  	0.19555458  	0.10720785  
2023-05-17 14:53:01.777: Find a better model.
2023-05-17 14:53:11.564: [iter 106 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 9.778028]
2023-05-17 14:53:11.892: epoch 106:	0.02651066  	0.19554079  	0.10727688  
2023-05-17 14:53:21.784: [iter 107 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0055, time: 9.890990]
2023-05-17 14:53:21.965: epoch 107:	0.02652477  	0.19540930  	0.10736077  
2023-05-17 14:53:30.943: [iter 108 : loss : 0.1254 = 0.0352 + 0.0846 + 0.0056, time: 8.975992]
2023-05-17 14:53:31.112: epoch 108:	0.02659534  	0.19622348  	0.10767164  
2023-05-17 14:53:31.113: Find a better model.
2023-05-17 14:53:39.971: [iter 109 : loss : 0.1239 = 0.0339 + 0.0845 + 0.0056, time: 8.856991]
2023-05-17 14:53:40.360: epoch 109:	0.02664473  	0.19637850  	0.10788745  
2023-05-17 14:53:40.360: Find a better model.
2023-05-17 14:53:50.043: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0056, time: 9.679050]
2023-05-17 14:53:50.324: epoch 110:	0.02656006  	0.19593790  	0.10761028  
2023-05-17 14:53:59.922: [iter 111 : loss : 0.1233 = 0.0332 + 0.0844 + 0.0057, time: 9.588002]
2023-05-17 14:54:00.215: epoch 111:	0.02657417  	0.19632351  	0.10785589  
2023-05-17 14:54:09.085: [iter 112 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0057, time: 8.868051]
2023-05-17 14:54:09.297: epoch 112:	0.02657417  	0.19613290  	0.10778097  
2023-05-17 14:54:19.072: [iter 113 : loss : 0.1230 = 0.0330 + 0.0843 + 0.0057, time: 9.762003]
2023-05-17 14:54:19.364: epoch 113:	0.02656006  	0.19610678  	0.10777087  
2023-05-17 14:54:28.828: [iter 114 : loss : 0.1222 = 0.0323 + 0.0842 + 0.0058, time: 9.461995]
2023-05-17 14:54:29.005: epoch 114:	0.02668707  	0.19704211  	0.10801772  
2023-05-17 14:54:29.005: Find a better model.
2023-05-17 14:54:37.874: [iter 115 : loss : 0.1220 = 0.0320 + 0.0841 + 0.0058, time: 8.867055]
2023-05-17 14:54:38.033: epoch 115:	0.02662356  	0.19648570  	0.10792550  
2023-05-17 14:54:48.547: [iter 116 : loss : 0.1208 = 0.0309 + 0.0841 + 0.0058, time: 10.513010]
2023-05-17 14:54:48.879: epoch 116:	0.02668707  	0.19688283  	0.10803227  
2023-05-17 14:54:58.367: [iter 117 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 9.487032]
2023-05-17 14:54:58.548: epoch 117:	0.02666590  	0.19669196  	0.10808454  
2023-05-17 14:55:07.460: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.908991]
2023-05-17 14:55:07.635: epoch 118:	0.02667296  	0.19667380  	0.10807462  
2023-05-17 14:55:16.663: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0059, time: 9.025017]
2023-05-17 14:55:16.821: epoch 119:	0.02669413  	0.19674933  	0.10805394  
2023-05-17 14:55:25.296: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 8.473010]
2023-05-17 14:55:25.519: epoch 120:	0.02675764  	0.19698301  	0.10835089  
2023-05-17 14:55:35.160: [iter 121 : loss : 0.1201 = 0.0302 + 0.0838 + 0.0060, time: 9.639047]
2023-05-17 14:55:35.435: epoch 121:	0.02680703  	0.19747110  	0.10850310  
2023-05-17 14:55:35.435: Find a better model.
2023-05-17 14:55:44.929: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 9.489023]
2023-05-17 14:55:45.220: epoch 122:	0.02685643  	0.19772115  	0.10874555  
2023-05-17 14:55:45.220: Find a better model.
2023-05-17 14:55:54.716: [iter 123 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 9.494003]
2023-05-17 14:55:54.949: epoch 123:	0.02684232  	0.19762269  	0.10866454  
2023-05-17 14:56:04.449: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 9.497509]
2023-05-17 14:56:04.612: epoch 124:	0.02679292  	0.19718643  	0.10856446  
2023-05-17 14:56:13.618: [iter 125 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0061, time: 9.003014]
2023-05-17 14:56:13.939: epoch 125:	0.02677881  	0.19725394  	0.10859534  
2023-05-17 14:56:23.367: [iter 126 : loss : 0.1177 = 0.0279 + 0.0836 + 0.0062, time: 9.417125]
2023-05-17 14:56:23.666: epoch 126:	0.02678586  	0.19700773  	0.10851499  
2023-05-17 14:56:31.767: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 8.100233]
2023-05-17 14:56:31.963: epoch 127:	0.02679292  	0.19698836  	0.10869783  
2023-05-17 14:56:41.418: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 9.452003]
2023-05-17 14:56:41.696: epoch 128:	0.02683526  	0.19735786  	0.10887441  
2023-05-17 14:56:51.277: [iter 129 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0062, time: 9.580535]
2023-05-17 14:56:51.449: epoch 129:	0.02684937  	0.19737294  	0.10885338  
2023-05-17 14:57:00.065: [iter 130 : loss : 0.1169 = 0.0273 + 0.0834 + 0.0063, time: 8.612993]
2023-05-17 14:57:00.361: epoch 130:	0.02687760  	0.19753528  	0.10909694  
2023-05-17 14:57:10.657: [iter 131 : loss : 0.1161 = 0.0265 + 0.0833 + 0.0063, time: 10.293055]
2023-05-17 14:57:11.000: epoch 131:	0.02688465  	0.19777110  	0.10891819  
2023-05-17 14:57:11.000: Find a better model.
2023-05-17 14:57:20.845: [iter 132 : loss : 0.1162 = 0.0266 + 0.0833 + 0.0063, time: 9.841020]
2023-05-17 14:57:21.147: epoch 132:	0.02685643  	0.19770052  	0.10886569  
2023-05-17 14:57:30.184: [iter 133 : loss : 0.1152 = 0.0256 + 0.0833 + 0.0064, time: 9.035079]
2023-05-17 14:57:30.367: epoch 133:	0.02687760  	0.19764036  	0.10904827  
2023-05-17 14:57:39.197: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 8.826531]
2023-05-17 14:57:39.373: epoch 134:	0.02682114  	0.19707380  	0.10896054  
2023-05-17 14:57:47.893: [iter 135 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0064, time: 8.517014]
2023-05-17 14:57:48.056: epoch 135:	0.02685643  	0.19731762  	0.10904381  
2023-05-17 14:57:57.691: [iter 136 : loss : 0.1151 = 0.0256 + 0.0831 + 0.0065, time: 9.627005]
2023-05-17 14:57:57.991: epoch 136:	0.02684232  	0.19756858  	0.10911353  
2023-05-17 14:58:07.871: [iter 137 : loss : 0.1146 = 0.0251 + 0.0831 + 0.0065, time: 9.876029]
2023-05-17 14:58:08.155: epoch 137:	0.02687760  	0.19786410  	0.10930829  
2023-05-17 14:58:08.155: Find a better model.
2023-05-17 14:58:17.555: [iter 138 : loss : 0.1144 = 0.0249 + 0.0831 + 0.0065, time: 9.397991]
2023-05-17 14:58:17.774: epoch 138:	0.02688465  	0.19774212  	0.10923427  
2023-05-17 14:58:27.320: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0065, time: 9.544024]
2023-05-17 14:58:27.493: epoch 139:	0.02693405  	0.19813807  	0.10953151  
2023-05-17 14:58:27.493: Find a better model.
2023-05-17 14:58:36.682: [iter 140 : loss : 0.1134 = 0.0239 + 0.0830 + 0.0066, time: 9.186472]
2023-05-17 14:58:36.965: epoch 140:	0.02687054  	0.19770321  	0.10933152  
2023-05-17 14:58:46.356: [iter 141 : loss : 0.1142 = 0.0246 + 0.0829 + 0.0066, time: 9.388528]
2023-05-17 14:58:46.658: epoch 141:	0.02684232  	0.19745754  	0.10918951  
2023-05-17 14:58:54.849: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 8.190035]
2023-05-17 14:58:55.045: epoch 142:	0.02700461  	0.19841601  	0.10951886  
2023-05-17 14:58:55.045: Find a better model.
2023-05-17 14:59:04.784: [iter 143 : loss : 0.1132 = 0.0237 + 0.0828 + 0.0067, time: 9.732024]
2023-05-17 14:59:05.061: epoch 143:	0.02694816  	0.19806179  	0.10936578  
2023-05-17 14:59:14.472: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 9.408982]
2023-05-17 14:59:14.635: epoch 144:	0.02693405  	0.19804506  	0.10947024  
2023-05-17 14:59:23.369: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 8.733002]
2023-05-17 14:59:23.530: epoch 145:	0.02694816  	0.19793992  	0.10946520  
2023-05-17 14:59:33.837: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 10.304281]
2023-05-17 14:59:34.178: epoch 146:	0.02689876  	0.19759126  	0.10950699  
2023-05-17 14:59:43.730: [iter 147 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0068, time: 9.549489]
2023-05-17 14:59:43.980: epoch 147:	0.02690582  	0.19775645  	0.10949253  
2023-05-17 14:59:52.959: [iter 148 : loss : 0.1115 = 0.0221 + 0.0827 + 0.0068, time: 8.976938]
2023-05-17 14:59:53.137: epoch 148:	0.02689877  	0.19775762  	0.10950535  
2023-05-17 15:00:01.940: [iter 149 : loss : 0.1116 = 0.0222 + 0.0826 + 0.0068, time: 8.801437]
2023-05-17 15:00:02.120: epoch 149:	0.02693405  	0.19807747  	0.10968290  
2023-05-17 15:00:10.573: [iter 150 : loss : 0.1112 = 0.0218 + 0.0826 + 0.0068, time: 8.452003]
2023-05-17 15:00:10.731: epoch 150:	0.02694111  	0.19809760  	0.10977585  
2023-05-17 15:00:20.242: [iter 151 : loss : 0.1113 = 0.0219 + 0.0826 + 0.0069, time: 9.507927]
2023-05-17 15:00:20.546: epoch 151:	0.02701873  	0.19878380  	0.10996799  
2023-05-17 15:00:20.546: Find a better model.
2023-05-17 15:00:30.092: [iter 152 : loss : 0.1107 = 0.0213 + 0.0826 + 0.0069, time: 9.543024]
2023-05-17 15:00:30.392: epoch 152:	0.02699756  	0.19837946  	0.10969827  
2023-05-17 15:00:39.850: [iter 153 : loss : 0.1099 = 0.0205 + 0.0825 + 0.0069, time: 9.457059]
2023-05-17 15:00:40.065: epoch 153:	0.02694817  	0.19805984  	0.10976698  
2023-05-17 15:00:49.527: [iter 154 : loss : 0.1103 = 0.0209 + 0.0825 + 0.0069, time: 9.458484]
2023-05-17 15:00:49.704: epoch 154:	0.02696933  	0.19814527  	0.10983129  
2023-05-17 15:00:59.047: [iter 155 : loss : 0.1108 = 0.0214 + 0.0825 + 0.0070, time: 9.341162]
2023-05-17 15:00:59.353: epoch 155:	0.02690582  	0.19760989  	0.10944080  
2023-05-17 15:01:08.842: [iter 156 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 9.484025]
2023-05-17 15:01:09.167: epoch 156:	0.02688465  	0.19765207  	0.10932087  
2023-05-17 15:01:17.583: [iter 157 : loss : 0.1102 = 0.0208 + 0.0824 + 0.0070, time: 8.415003]
2023-05-17 15:01:17.763: epoch 157:	0.02696227  	0.19802314  	0.10953613  
2023-05-17 15:01:27.473: [iter 158 : loss : 0.1095 = 0.0201 + 0.0823 + 0.0071, time: 9.708036]
2023-05-17 15:01:27.747: epoch 158:	0.02692699  	0.19792429  	0.10938780  
2023-05-17 15:01:36.773: [iter 159 : loss : 0.1098 = 0.0204 + 0.0823 + 0.0071, time: 9.024002]
2023-05-17 15:01:36.927: epoch 159:	0.02693405  	0.19818747  	0.10955702  
2023-05-17 15:01:45.323: [iter 160 : loss : 0.1093 = 0.0199 + 0.0823 + 0.0071, time: 8.393054]
2023-05-17 15:01:45.629: epoch 160:	0.02698345  	0.19837752  	0.10957519  
2023-05-17 15:01:54.701: [iter 161 : loss : 0.1091 = 0.0197 + 0.0823 + 0.0071, time: 9.069501]
2023-05-17 15:01:54.952: epoch 161:	0.02697639  	0.19855312  	0.10960743  
2023-05-17 15:02:02.818: [iter 162 : loss : 0.1083 = 0.0189 + 0.0822 + 0.0072, time: 7.864163]
2023-05-17 15:02:03.121: epoch 162:	0.02696228  	0.19832885  	0.10969034  
2023-05-17 15:02:11.017: [iter 163 : loss : 0.1090 = 0.0196 + 0.0822 + 0.0072, time: 7.893664]
2023-05-17 15:02:11.180: epoch 163:	0.02689877  	0.19786592  	0.10958910  
2023-05-17 15:02:19.674: [iter 164 : loss : 0.1087 = 0.0193 + 0.0822 + 0.0072, time: 8.492990]
2023-05-17 15:02:19.827: epoch 164:	0.02691994  	0.19775763  	0.10964011  
2023-05-17 15:02:29.351: [iter 165 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 9.520014]
2023-05-17 15:02:29.623: epoch 165:	0.02688466  	0.19772781  	0.10965990  
2023-05-17 15:02:38.713: [iter 166 : loss : 0.1079 = 0.0185 + 0.0821 + 0.0072, time: 9.086306]
2023-05-17 15:02:39.030: epoch 166:	0.02687760  	0.19759385  	0.10953561  
2023-05-17 15:02:47.144: [iter 167 : loss : 0.1086 = 0.0193 + 0.0821 + 0.0073, time: 8.111991]
2023-05-17 15:02:47.341: epoch 167:	0.02687054  	0.19738194  	0.10949741  
2023-05-17 15:02:55.066: [iter 168 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 7.724008]
2023-05-17 15:02:55.239: epoch 168:	0.02687760  	0.19734120  	0.10953151  
2023-05-17 15:03:04.108: [iter 169 : loss : 0.1079 = 0.0185 + 0.0821 + 0.0073, time: 8.866642]
2023-05-17 15:03:04.373: epoch 169:	0.02687054  	0.19770114  	0.10966782  
2023-05-17 15:03:13.880: [iter 170 : loss : 0.1077 = 0.0183 + 0.0820 + 0.0073, time: 9.504075]
2023-05-17 15:03:14.182: epoch 170:	0.02683527  	0.19751738  	0.10955583  
2023-05-17 15:03:23.424: [iter 171 : loss : 0.1081 = 0.0187 + 0.0820 + 0.0074, time: 9.238163]
2023-05-17 15:03:23.746: epoch 171:	0.02679998  	0.19712152  	0.10952242  
2023-05-17 15:03:32.647: [iter 172 : loss : 0.1069 = 0.0175 + 0.0820 + 0.0074, time: 8.898688]
2023-05-17 15:03:32.821: epoch 172:	0.02672236  	0.19640929  	0.10922530  
2023-05-17 15:03:41.267: [iter 173 : loss : 0.1075 = 0.0182 + 0.0819 + 0.0074, time: 8.443014]
2023-05-17 15:03:41.441: epoch 173:	0.02684937  	0.19708338  	0.10952327  
2023-05-17 15:03:50.958: [iter 174 : loss : 0.1075 = 0.0181 + 0.0819 + 0.0074, time: 9.514685]
2023-05-17 15:03:51.159: epoch 174:	0.02682115  	0.19676271  	0.10950556  
2023-05-17 15:04:01.510: [iter 175 : loss : 0.1069 = 0.0175 + 0.0819 + 0.0075, time: 10.346300]
2023-05-17 15:04:01.838: epoch 175:	0.02677881  	0.19630627  	0.10930598  
2023-05-17 15:04:11.303: [iter 176 : loss : 0.1065 = 0.0172 + 0.0819 + 0.0075, time: 9.462991]
2023-05-17 15:04:11.620: epoch 176:	0.02682821  	0.19672047  	0.10938769  
2023-05-17 15:04:11.620: Early stopping is trigger at epoch: 176
2023-05-17 15:04:11.620: best_result@epoch 151:

2023-05-17 15:04:11.620: 		0.0270      	0.1988      	0.1100      
2023-05-17 15:06:42.252: my pid: 9376
2023-05-17 15:06:42.253: model: model.general_recommender.SGL
2023-05-17 15:06:42.253: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 15:06:42.253: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 15:06:46.540: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 15:06:56.179: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.639686]
2023-05-17 15:06:56.347: epoch 1:	0.00140418  	0.01034137  	0.00485419  
2023-05-17 15:06:56.347: Find a better model.
2023-05-17 15:07:07.856: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 11.507056]
2023-05-17 15:07:08.221: epoch 2:	0.00257550  	0.02020034  	0.00971118  
2023-05-17 15:07:08.221: Find a better model.
2023-05-17 15:07:18.423: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 10.198207]
2023-05-17 15:07:18.658: epoch 3:	0.00471350  	0.03559709  	0.01713438  
2023-05-17 15:07:18.658: Find a better model.
2023-05-17 15:07:28.809: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 10.149802]
2023-05-17 15:07:28.985: epoch 4:	0.00774055  	0.05776045  	0.02774469  
2023-05-17 15:07:28.985: Find a better model.
2023-05-17 15:07:38.891: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 9.903990]
2023-05-17 15:07:39.114: epoch 5:	0.01140985  	0.08350595  	0.04049947  
2023-05-17 15:07:39.114: Find a better model.
2023-05-17 15:07:48.192: [iter 6 : loss : 0.7673 = 0.6881 + 0.0792 + 0.0000, time: 9.077033]
2023-05-17 15:07:48.420: epoch 6:	0.01505802  	0.10905366  	0.05411433  
2023-05-17 15:07:48.420: Find a better model.
2023-05-17 15:07:58.658: [iter 7 : loss : 0.7610 = 0.6810 + 0.0799 + 0.0000, time: 10.235080]
2023-05-17 15:07:58.961: epoch 7:	0.01776768  	0.12897803  	0.06436807  
2023-05-17 15:07:58.961: Find a better model.
2023-05-17 15:08:09.019: [iter 8 : loss : 0.7453 = 0.6635 + 0.0818 + 0.0001, time: 10.055027]
2023-05-17 15:08:09.294: epoch 8:	0.01852271  	0.13603063  	0.06857040  
2023-05-17 15:08:09.294: Find a better model.
2023-05-17 15:08:18.570: [iter 9 : loss : 0.7101 = 0.6244 + 0.0856 + 0.0001, time: 9.274390]
2023-05-17 15:08:18.743: epoch 9:	0.01859328  	0.13715796  	0.06859869  
2023-05-17 15:08:18.744: Find a better model.
2023-05-17 15:08:28.708: [iter 10 : loss : 0.6493 = 0.5581 + 0.0910 + 0.0002, time: 9.962504]
2023-05-17 15:08:28.893: epoch 10:	0.01846628  	0.13647568  	0.06777500  
2023-05-17 15:08:39.167: [iter 11 : loss : 0.5735 = 0.4772 + 0.0960 + 0.0004, time: 10.270049]
2023-05-17 15:08:39.490: epoch 11:	0.01837454  	0.13593718  	0.06749059  
2023-05-17 15:08:49.584: [iter 12 : loss : 0.5047 = 0.4047 + 0.0994 + 0.0005, time: 10.091007]
2023-05-17 15:08:49.912: epoch 12:	0.01835338  	0.13567008  	0.06755842  
2023-05-17 15:08:59.449: [iter 13 : loss : 0.4537 = 0.3518 + 0.1012 + 0.0007, time: 9.535016]
2023-05-17 15:08:59.616: epoch 13:	0.01837455  	0.13597704  	0.06815528  
2023-05-17 15:09:08.058: [iter 14 : loss : 0.4152 = 0.3122 + 0.1022 + 0.0008, time: 8.441009]
2023-05-17 15:09:08.264: epoch 14:	0.01866386  	0.13850483  	0.06926084  
2023-05-17 15:09:08.264: Find a better model.
2023-05-17 15:09:17.602: [iter 15 : loss : 0.3886 = 0.2850 + 0.1026 + 0.0010, time: 9.337025]
2023-05-17 15:09:17.775: epoch 15:	0.01877676  	0.13937928  	0.06983874  
2023-05-17 15:09:17.775: Find a better model.
2023-05-17 15:09:28.326: [iter 16 : loss : 0.3663 = 0.2627 + 0.1025 + 0.0011, time: 10.546035]
2023-05-17 15:09:28.669: epoch 16:	0.01897434  	0.14066979  	0.07079540  
2023-05-17 15:09:28.669: Find a better model.
2023-05-17 15:09:38.761: [iter 17 : loss : 0.3498 = 0.2462 + 0.1024 + 0.0012, time: 10.087034]
2023-05-17 15:09:39.323: epoch 17:	0.01920721  	0.14235379  	0.07181796  
2023-05-17 15:09:39.324: Find a better model.
2023-05-17 15:09:48.687: [iter 18 : loss : 0.3346 = 0.2311 + 0.1022 + 0.0013, time: 9.359999]
2023-05-17 15:09:48.850: epoch 18:	0.01948242  	0.14421301  	0.07282398  
2023-05-17 15:09:48.850: Find a better model.
2023-05-17 15:09:57.501: [iter 19 : loss : 0.3205 = 0.2173 + 0.1018 + 0.0014, time: 8.650957]
2023-05-17 15:09:57.670: epoch 19:	0.01973646  	0.14576450  	0.07380491  
2023-05-17 15:09:57.670: Find a better model.
2023-05-17 15:10:06.806: [iter 20 : loss : 0.3108 = 0.2079 + 0.1014 + 0.0015, time: 9.134018]
2023-05-17 15:10:06.972: epoch 20:	0.01989875  	0.14658152  	0.07453535  
2023-05-17 15:10:06.972: Find a better model.
2023-05-17 15:10:16.833: [iter 21 : loss : 0.3011 = 0.1985 + 0.1010 + 0.0016, time: 9.858015]
2023-05-17 15:10:17.150: epoch 21:	0.02010339  	0.14809045  	0.07534373  
2023-05-17 15:10:17.151: Find a better model.
2023-05-17 15:10:28.032: [iter 22 : loss : 0.2928 = 0.1906 + 0.1006 + 0.0016, time: 10.878034]
2023-05-17 15:10:28.391: epoch 22:	0.02030803  	0.14987469  	0.07605620  
2023-05-17 15:10:28.391: Find a better model.
2023-05-17 15:10:37.731: [iter 23 : loss : 0.2846 = 0.1827 + 0.1002 + 0.0017, time: 9.338365]
2023-05-17 15:10:37.903: epoch 23:	0.02049856  	0.15134376  	0.07697469  
2023-05-17 15:10:37.903: Find a better model.
2023-05-17 15:10:46.934: [iter 24 : loss : 0.2780 = 0.1766 + 0.0996 + 0.0018, time: 9.029118]
2023-05-17 15:10:47.110: epoch 24:	0.02071024  	0.15324229  	0.07778168  
2023-05-17 15:10:47.110: Find a better model.
2023-05-17 15:10:57.450: [iter 25 : loss : 0.2714 = 0.1702 + 0.0993 + 0.0019, time: 10.334013]
2023-05-17 15:10:57.727: epoch 25:	0.02079492  	0.15341961  	0.07836764  
2023-05-17 15:10:57.727: Find a better model.
2023-05-17 15:11:08.090: [iter 26 : loss : 0.2678 = 0.1670 + 0.0988 + 0.0019, time: 10.357991]
2023-05-17 15:11:08.409: epoch 26:	0.02095017  	0.15454882  	0.07894097  
2023-05-17 15:11:08.409: Find a better model.
2023-05-17 15:11:16.902: [iter 27 : loss : 0.2602 = 0.1598 + 0.0985 + 0.0020, time: 8.491204]
2023-05-17 15:11:17.078: epoch 27:	0.02116892  	0.15615505  	0.07982992  
2023-05-17 15:11:17.078: Find a better model.
2023-05-17 15:11:26.747: [iter 28 : loss : 0.2551 = 0.1550 + 0.0981 + 0.0021, time: 9.665992]
2023-05-17 15:11:26.926: epoch 28:	0.02140179  	0.15779053  	0.08068836  
2023-05-17 15:11:26.926: Find a better model.
2023-05-17 15:11:36.568: [iter 29 : loss : 0.2505 = 0.1509 + 0.0975 + 0.0021, time: 9.638991]
2023-05-17 15:11:36.728: epoch 29:	0.02148647  	0.15828785  	0.08116140  
2023-05-17 15:11:36.728: Find a better model.
2023-05-17 15:11:45.778: [iter 30 : loss : 0.2441 = 0.1446 + 0.0973 + 0.0022, time: 9.046917]
2023-05-17 15:11:45.936: epoch 30:	0.02155703  	0.15876743  	0.08168077  
2023-05-17 15:11:45.936: Find a better model.
2023-05-17 15:11:56.190: [iter 31 : loss : 0.2404 = 0.1413 + 0.0969 + 0.0023, time: 10.252040]
2023-05-17 15:11:56.528: epoch 31:	0.02164171  	0.15969051  	0.08239993  
2023-05-17 15:11:56.528: Find a better model.
2023-05-17 15:12:05.723: [iter 32 : loss : 0.2350 = 0.1362 + 0.0966 + 0.0023, time: 9.192308]
2023-05-17 15:12:05.912: epoch 32:	0.02183929  	0.16100253  	0.08315922  
2023-05-17 15:12:05.912: Find a better model.
2023-05-17 15:12:15.489: [iter 33 : loss : 0.2326 = 0.1340 + 0.0962 + 0.0024, time: 9.575072]
2023-05-17 15:12:15.667: epoch 33:	0.02196631  	0.16188179  	0.08387589  
2023-05-17 15:12:15.667: Find a better model.
2023-05-17 15:12:25.518: [iter 34 : loss : 0.2285 = 0.1302 + 0.0958 + 0.0024, time: 9.849024]
2023-05-17 15:12:25.801: epoch 34:	0.02213567  	0.16324180  	0.08467139  
2023-05-17 15:12:25.802: Find a better model.
2023-05-17 15:12:34.475: [iter 35 : loss : 0.2247 = 0.1267 + 0.0954 + 0.0025, time: 8.672014]
2023-05-17 15:12:34.649: epoch 35:	0.02239675  	0.16547517  	0.08589858  
2023-05-17 15:12:34.649: Find a better model.
2023-05-17 15:12:44.666: [iter 36 : loss : 0.2211 = 0.1234 + 0.0952 + 0.0025, time: 10.004991]
2023-05-17 15:12:44.985: epoch 36:	0.02260139  	0.16673428  	0.08649779  
2023-05-17 15:12:44.985: Find a better model.
2023-05-17 15:12:54.354: [iter 37 : loss : 0.2174 = 0.1200 + 0.0948 + 0.0026, time: 9.361361]
2023-05-17 15:12:54.623: epoch 37:	0.02269313  	0.16756932  	0.08727221  
2023-05-17 15:12:54.624: Find a better model.
2023-05-17 15:13:04.121: [iter 38 : loss : 0.2156 = 0.1184 + 0.0946 + 0.0027, time: 9.496004]
2023-05-17 15:13:04.299: epoch 38:	0.02283425  	0.16820537  	0.08779188  
2023-05-17 15:13:04.299: Find a better model.
2023-05-17 15:13:14.339: [iter 39 : loss : 0.2113 = 0.1144 + 0.0942 + 0.0027, time: 10.037991]
2023-05-17 15:13:14.511: epoch 39:	0.02294010  	0.16885087  	0.08817483  
2023-05-17 15:13:14.511: Find a better model.
2023-05-17 15:13:23.026: [iter 40 : loss : 0.2080 = 0.1113 + 0.0939 + 0.0028, time: 8.512060]
2023-05-17 15:13:23.220: epoch 40:	0.02302478  	0.16962031  	0.08848424  
2023-05-17 15:13:23.220: Find a better model.
2023-05-17 15:13:33.331: [iter 41 : loss : 0.2064 = 0.1099 + 0.0936 + 0.0028, time: 10.067014]
2023-05-17 15:13:33.647: epoch 41:	0.02309535  	0.16974272  	0.08911777  
2023-05-17 15:13:33.647: Find a better model.
2023-05-17 15:13:41.732: [iter 42 : loss : 0.2041 = 0.1079 + 0.0934 + 0.0029, time: 8.083115]
2023-05-17 15:13:41.889: epoch 42:	0.02325764  	0.17084569  	0.08984216  
2023-05-17 15:13:41.889: Find a better model.
2023-05-17 15:13:49.643: [iter 43 : loss : 0.2004 = 0.1045 + 0.0930 + 0.0029, time: 7.753061]
2023-05-17 15:13:49.804: epoch 43:	0.02332116  	0.17133227  	0.09029371  
2023-05-17 15:13:49.805: Find a better model.
2023-05-17 15:13:57.831: [iter 44 : loss : 0.1966 = 0.1009 + 0.0928 + 0.0030, time: 8.025181]
2023-05-17 15:13:57.992: epoch 44:	0.02346934  	0.17299771  	0.09115811  
2023-05-17 15:13:57.992: Find a better model.
2023-05-17 15:14:06.283: [iter 45 : loss : 0.1947 = 0.0991 + 0.0926 + 0.0030, time: 8.290607]
2023-05-17 15:14:06.449: epoch 45:	0.02356108  	0.17375530  	0.09167988  
2023-05-17 15:14:06.449: Find a better model.
2023-05-17 15:14:14.536: [iter 46 : loss : 0.1923 = 0.0969 + 0.0923 + 0.0031, time: 8.086243]
2023-05-17 15:14:14.708: epoch 46:	0.02360342  	0.17403823  	0.09203187  
2023-05-17 15:14:14.708: Find a better model.
2023-05-17 15:14:22.879: [iter 47 : loss : 0.1914 = 0.0962 + 0.0921 + 0.0031, time: 8.169038]
2023-05-17 15:14:23.178: epoch 47:	0.02370927  	0.17504109  	0.09245718  
2023-05-17 15:14:23.178: Find a better model.
2023-05-17 15:14:32.406: [iter 48 : loss : 0.1877 = 0.0926 + 0.0918 + 0.0032, time: 9.224166]
2023-05-17 15:14:32.677: epoch 48:	0.02390685  	0.17644735  	0.09324666  
2023-05-17 15:14:32.678: Find a better model.
2023-05-17 15:14:40.976: [iter 49 : loss : 0.1844 = 0.0896 + 0.0916 + 0.0032, time: 8.295228]
2023-05-17 15:14:41.145: epoch 49:	0.02398447  	0.17688550  	0.09364417  
2023-05-17 15:14:41.145: Find a better model.
2023-05-17 15:14:49.618: [iter 50 : loss : 0.1836 = 0.0889 + 0.0914 + 0.0033, time: 8.470443]
2023-05-17 15:14:49.788: epoch 50:	0.02401975  	0.17716818  	0.09408265  
2023-05-17 15:14:49.788: Find a better model.
2023-05-17 15:14:58.987: [iter 51 : loss : 0.1805 = 0.0860 + 0.0912 + 0.0033, time: 9.196427]
2023-05-17 15:14:59.261: epoch 51:	0.02411148  	0.17815797  	0.09454618  
2023-05-17 15:14:59.262: Find a better model.
2023-05-17 15:15:07.642: [iter 52 : loss : 0.1805 = 0.0861 + 0.0910 + 0.0034, time: 8.378124]
2023-05-17 15:15:07.816: epoch 52:	0.02421732  	0.17895022  	0.09502850  
2023-05-17 15:15:07.816: Find a better model.
2023-05-17 15:15:16.313: [iter 53 : loss : 0.1787 = 0.0845 + 0.0908 + 0.0034, time: 8.493993]
2023-05-17 15:15:16.475: epoch 53:	0.02430905  	0.17998195  	0.09570362  
2023-05-17 15:15:16.475: Find a better model.
2023-05-17 15:15:25.371: [iter 54 : loss : 0.1763 = 0.0823 + 0.0906 + 0.0035, time: 8.894714]
2023-05-17 15:15:25.551: epoch 54:	0.02450664  	0.18111372  	0.09630016  
2023-05-17 15:15:25.551: Find a better model.
2023-05-17 15:15:34.180: [iter 55 : loss : 0.1747 = 0.0809 + 0.0904 + 0.0035, time: 8.627992]
2023-05-17 15:15:34.365: epoch 55:	0.02452075  	0.18117446  	0.09649213  
2023-05-17 15:15:34.365: Find a better model.
2023-05-17 15:15:42.852: [iter 56 : loss : 0.1727 = 0.0790 + 0.0902 + 0.0035, time: 8.484992]
2023-05-17 15:15:43.016: epoch 56:	0.02452780  	0.18140003  	0.09680840  
2023-05-17 15:15:43.016: Find a better model.
2023-05-17 15:15:50.768: [iter 57 : loss : 0.1708 = 0.0772 + 0.0900 + 0.0036, time: 7.751236]
2023-05-17 15:15:50.928: epoch 57:	0.02457720  	0.18163639  	0.09693386  
2023-05-17 15:15:50.928: Find a better model.
2023-05-17 15:15:59.191: [iter 58 : loss : 0.1690 = 0.0756 + 0.0898 + 0.0036, time: 8.261952]
2023-05-17 15:15:59.354: epoch 58:	0.02473950  	0.18310410  	0.09771436  
2023-05-17 15:15:59.354: Find a better model.
2023-05-17 15:16:07.562: [iter 59 : loss : 0.1680 = 0.0746 + 0.0897 + 0.0037, time: 8.205041]
2023-05-17 15:16:07.716: epoch 59:	0.02476067  	0.18319957  	0.09790800  
2023-05-17 15:16:07.716: Find a better model.
2023-05-17 15:16:15.738: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 8.020992]
2023-05-17 15:16:15.899: epoch 60:	0.02476773  	0.18344846  	0.09822873  
2023-05-17 15:16:15.899: Find a better model.
2023-05-17 15:16:24.220: [iter 61 : loss : 0.1652 = 0.0721 + 0.0893 + 0.0038, time: 8.318992]
2023-05-17 15:16:24.380: epoch 61:	0.02478889  	0.18368316  	0.09845767  
2023-05-17 15:16:24.380: Find a better model.
2023-05-17 15:16:33.761: [iter 62 : loss : 0.1636 = 0.0706 + 0.0891 + 0.0038, time: 9.378991]
2023-05-17 15:16:34.027: epoch 62:	0.02488768  	0.18436319  	0.09880713  
2023-05-17 15:16:34.027: Find a better model.
2023-05-17 15:16:42.503: [iter 63 : loss : 0.1620 = 0.0691 + 0.0890 + 0.0039, time: 8.474026]
2023-05-17 15:16:42.671: epoch 63:	0.02497235  	0.18506865  	0.09911076  
2023-05-17 15:16:42.671: Find a better model.
2023-05-17 15:16:51.090: [iter 64 : loss : 0.1610 = 0.0683 + 0.0888 + 0.0039, time: 8.416992]
2023-05-17 15:16:51.327: epoch 64:	0.02496530  	0.18493490  	0.09943853  
2023-05-17 15:17:00.455: [iter 65 : loss : 0.1600 = 0.0674 + 0.0886 + 0.0039, time: 9.126019]
2023-05-17 15:17:00.693: epoch 65:	0.02504998  	0.18549369  	0.09989452  
2023-05-17 15:17:00.693: Find a better model.
2023-05-17 15:17:09.124: [iter 66 : loss : 0.1582 = 0.0657 + 0.0885 + 0.0040, time: 8.429992]
2023-05-17 15:17:09.359: epoch 66:	0.02511348  	0.18552512  	0.10021259  
2023-05-17 15:17:09.359: Find a better model.
2023-05-17 15:17:17.735: [iter 67 : loss : 0.1565 = 0.0641 + 0.0884 + 0.0040, time: 8.373414]
2023-05-17 15:17:17.888: epoch 67:	0.02520522  	0.18662935  	0.10059144  
2023-05-17 15:17:17.888: Find a better model.
2023-05-17 15:17:26.895: [iter 68 : loss : 0.1565 = 0.0642 + 0.0882 + 0.0041, time: 9.003363]
2023-05-17 15:17:27.153: epoch 68:	0.02528284  	0.18714757  	0.10093500  
2023-05-17 15:17:27.153: Find a better model.
2023-05-17 15:17:35.759: [iter 69 : loss : 0.1545 = 0.0623 + 0.0881 + 0.0041, time: 8.605303]
2023-05-17 15:17:35.927: epoch 69:	0.02522639  	0.18669091  	0.10086361  
2023-05-17 15:17:44.171: [iter 70 : loss : 0.1529 = 0.0608 + 0.0880 + 0.0042, time: 8.242345]
2023-05-17 15:17:44.392: epoch 70:	0.02528990  	0.18706529  	0.10112906  
2023-05-17 15:17:52.570: [iter 71 : loss : 0.1513 = 0.0592 + 0.0879 + 0.0042, time: 8.177002]
2023-05-17 15:17:53.030: epoch 71:	0.02536752  	0.18771438  	0.10141614  
2023-05-17 15:17:53.030: Find a better model.
2023-05-17 15:18:01.339: [iter 72 : loss : 0.1512 = 0.0593 + 0.0877 + 0.0042, time: 8.306993]
2023-05-17 15:18:01.502: epoch 72:	0.02540986  	0.18846594  	0.10190161  
2023-05-17 15:18:01.502: Find a better model.
2023-05-17 15:18:09.746: [iter 73 : loss : 0.1497 = 0.0578 + 0.0876 + 0.0043, time: 8.241992]
2023-05-17 15:18:09.912: epoch 73:	0.02555804  	0.18944360  	0.10227966  
2023-05-17 15:18:09.912: Find a better model.
2023-05-17 15:18:17.657: [iter 74 : loss : 0.1483 = 0.0564 + 0.0875 + 0.0043, time: 7.742992]
2023-05-17 15:18:17.816: epoch 74:	0.02557215  	0.18956019  	0.10265781  
2023-05-17 15:18:17.816: Find a better model.
2023-05-17 15:18:25.938: [iter 75 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0044, time: 8.118992]
2023-05-17 15:18:26.099: epoch 75:	0.02564271  	0.18969885  	0.10292858  
2023-05-17 15:18:26.099: Find a better model.
2023-05-17 15:18:34.475: [iter 76 : loss : 0.1468 = 0.0551 + 0.0872 + 0.0044, time: 8.375110]
2023-05-17 15:18:34.636: epoch 76:	0.02574856  	0.19074205  	0.10338604  
2023-05-17 15:18:34.637: Find a better model.
2023-05-17 15:18:42.659: [iter 77 : loss : 0.1458 = 0.0543 + 0.0871 + 0.0044, time: 8.021062]
2023-05-17 15:18:42.819: epoch 77:	0.02576973  	0.19114836  	0.10369878  
2023-05-17 15:18:42.820: Find a better model.
2023-05-17 15:18:50.718: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 7.896186]
2023-05-17 15:18:50.876: epoch 78:	0.02584030  	0.19120979  	0.10372192  
2023-05-17 15:18:50.876: Find a better model.
2023-05-17 15:18:59.949: [iter 79 : loss : 0.1434 = 0.0519 + 0.0869 + 0.0045, time: 9.072037]
2023-05-17 15:19:00.216: epoch 79:	0.02583324  	0.19111550  	0.10364927  
2023-05-17 15:19:08.463: [iter 80 : loss : 0.1428 = 0.0514 + 0.0868 + 0.0046, time: 8.244992]
2023-05-17 15:19:08.613: epoch 80:	0.02591086  	0.19158383  	0.10408750  
2023-05-17 15:19:08.613: Find a better model.
2023-05-17 15:19:16.916: [iter 81 : loss : 0.1426 = 0.0513 + 0.0867 + 0.0046, time: 8.299998]
2023-05-17 15:19:17.085: epoch 81:	0.02593203  	0.19184312  	0.10421927  
2023-05-17 15:19:17.085: Find a better model.
2023-05-17 15:19:26.209: [iter 82 : loss : 0.1416 = 0.0504 + 0.0866 + 0.0046, time: 9.121991]
2023-05-17 15:19:26.483: epoch 82:	0.02582619  	0.19129868  	0.10412548  
2023-05-17 15:19:35.084: [iter 83 : loss : 0.1403 = 0.0491 + 0.0865 + 0.0047, time: 8.599512]
2023-05-17 15:19:35.293: epoch 83:	0.02591086  	0.19173467  	0.10436516  
2023-05-17 15:19:43.713: [iter 84 : loss : 0.1402 = 0.0490 + 0.0864 + 0.0047, time: 8.417992]
2023-05-17 15:19:43.867: epoch 84:	0.02594615  	0.19222830  	0.10461658  
2023-05-17 15:19:43.867: Find a better model.
2023-05-17 15:19:52.844: [iter 85 : loss : 0.1394 = 0.0483 + 0.0863 + 0.0048, time: 8.974812]
2023-05-17 15:19:53.119: epoch 85:	0.02602376  	0.19271231  	0.10484169  
2023-05-17 15:19:53.119: Find a better model.
2023-05-17 15:20:01.312: [iter 86 : loss : 0.1393 = 0.0483 + 0.0862 + 0.0048, time: 8.192082]
2023-05-17 15:20:01.460: epoch 86:	0.02610845  	0.19336225  	0.10511009  
2023-05-17 15:20:01.460: Find a better model.
2023-05-17 15:20:09.552: [iter 87 : loss : 0.1365 = 0.0455 + 0.0861 + 0.0048, time: 8.089997]
2023-05-17 15:20:09.711: epoch 87:	0.02611550  	0.19313477  	0.10509598  
2023-05-17 15:20:18.620: [iter 88 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 8.908055]
2023-05-17 15:20:18.799: epoch 88:	0.02612256  	0.19320241  	0.10507739  
2023-05-17 15:20:27.286: [iter 89 : loss : 0.1356 = 0.0448 + 0.0859 + 0.0049, time: 8.486569]
2023-05-17 15:20:27.445: epoch 89:	0.02617195  	0.19350231  	0.10530582  
2023-05-17 15:20:27.445: Find a better model.
2023-05-17 15:20:35.918: [iter 90 : loss : 0.1361 = 0.0453 + 0.0858 + 0.0049, time: 8.472003]
2023-05-17 15:20:36.086: epoch 90:	0.02619312  	0.19372082  	0.10556301  
2023-05-17 15:20:36.086: Find a better model.
2023-05-17 15:20:43.839: [iter 91 : loss : 0.1348 = 0.0440 + 0.0857 + 0.0050, time: 7.751993]
2023-05-17 15:20:44.000: epoch 91:	0.02629897  	0.19439395  	0.10563600  
2023-05-17 15:20:44.000: Find a better model.
2023-05-17 15:20:52.085: [iter 92 : loss : 0.1339 = 0.0433 + 0.0857 + 0.0050, time: 8.081603]
2023-05-17 15:20:52.268: epoch 92:	0.02629191  	0.19480769  	0.10580354  
2023-05-17 15:20:52.268: Find a better model.
2023-05-17 15:21:00.682: [iter 93 : loss : 0.1342 = 0.0435 + 0.0856 + 0.0051, time: 8.412992]
2023-05-17 15:21:00.833: epoch 93:	0.02634836  	0.19505531  	0.10591984  
2023-05-17 15:21:00.833: Find a better model.
2023-05-17 15:21:08.721: [iter 94 : loss : 0.1321 = 0.0415 + 0.0855 + 0.0051, time: 7.885996]
2023-05-17 15:21:08.881: epoch 94:	0.02631308  	0.19485620  	0.10586353  
2023-05-17 15:21:17.302: [iter 95 : loss : 0.1313 = 0.0407 + 0.0854 + 0.0051, time: 8.418371]
2023-05-17 15:21:17.463: epoch 95:	0.02632720  	0.19504479  	0.10620386  
2023-05-17 15:21:25.683: [iter 96 : loss : 0.1314 = 0.0409 + 0.0854 + 0.0052, time: 8.219075]
2023-05-17 15:21:25.852: epoch 96:	0.02640481  	0.19546168  	0.10637485  
2023-05-17 15:21:25.852: Find a better model.
2023-05-17 15:21:33.589: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 7.735030]
2023-05-17 15:21:33.752: epoch 97:	0.02640481  	0.19561954  	0.10654072  
2023-05-17 15:21:33.752: Find a better model.
2023-05-17 15:21:41.764: [iter 98 : loss : 0.1307 = 0.0402 + 0.0852 + 0.0052, time: 8.008561]
2023-05-17 15:21:41.940: epoch 98:	0.02634837  	0.19522838  	0.10645106  
2023-05-17 15:21:50.930: [iter 99 : loss : 0.1294 = 0.0390 + 0.0851 + 0.0053, time: 8.989080]
2023-05-17 15:21:51.093: epoch 99:	0.02639070  	0.19555297  	0.10663325  
2023-05-17 15:21:59.375: [iter 100 : loss : 0.1287 = 0.0384 + 0.0851 + 0.0053, time: 8.281647]
2023-05-17 15:21:59.537: epoch 100:	0.02646833  	0.19600567  	0.10668452  
2023-05-17 15:21:59.537: Find a better model.
2023-05-17 15:22:08.860: [iter 101 : loss : 0.1284 = 0.0381 + 0.0850 + 0.0053, time: 9.321973]
2023-05-17 15:22:09.135: epoch 101:	0.02650361  	0.19658439  	0.10687141  
2023-05-17 15:22:09.136: Find a better model.
2023-05-17 15:22:19.078: [iter 102 : loss : 0.1277 = 0.0373 + 0.0849 + 0.0054, time: 9.939017]
2023-05-17 15:22:19.429: epoch 102:	0.02650361  	0.19677228  	0.10713817  
2023-05-17 15:22:19.429: Find a better model.
2023-05-17 15:22:29.740: [iter 103 : loss : 0.1274 = 0.0372 + 0.0849 + 0.0054, time: 10.296405]
2023-05-17 15:22:30.072: epoch 103:	0.02649655  	0.19663538  	0.10720690  
2023-05-17 15:22:38.447: [iter 104 : loss : 0.1278 = 0.0376 + 0.0848 + 0.0055, time: 8.373475]
2023-05-17 15:22:38.614: epoch 104:	0.02653888  	0.19669998  	0.10740644  
2023-05-17 15:22:47.741: [iter 105 : loss : 0.1269 = 0.0366 + 0.0847 + 0.0055, time: 9.125992]
2023-05-17 15:22:47.908: epoch 105:	0.02652478  	0.19689217  	0.10742284  
2023-05-17 15:22:47.908: Find a better model.
2023-05-17 15:22:57.397: [iter 106 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 9.486991]
2023-05-17 15:22:57.926: epoch 106:	0.02658123  	0.19736239  	0.10750249  
2023-05-17 15:22:57.927: Find a better model.
2023-05-17 15:23:06.997: [iter 107 : loss : 0.1254 = 0.0353 + 0.0846 + 0.0055, time: 9.068141]
2023-05-17 15:23:07.326: epoch 107:	0.02660946  	0.19730105  	0.10770589  
2023-05-17 15:23:17.350: [iter 108 : loss : 0.1252 = 0.0351 + 0.0845 + 0.0056, time: 10.021044]
2023-05-17 15:23:17.678: epoch 108:	0.02663768  	0.19757023  	0.10778701  
2023-05-17 15:23:17.678: Find a better model.
2023-05-17 15:23:26.399: [iter 109 : loss : 0.1240 = 0.0339 + 0.0844 + 0.0056, time: 8.717149]
2023-05-17 15:23:26.591: epoch 109:	0.02669412  	0.19784741  	0.10793275  
2023-05-17 15:23:26.591: Find a better model.
2023-05-17 15:23:35.821: [iter 110 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 9.227991]
2023-05-17 15:23:35.978: epoch 110:	0.02668707  	0.19820070  	0.10791329  
2023-05-17 15:23:35.978: Find a better model.
2023-05-17 15:23:46.209: [iter 111 : loss : 0.1236 = 0.0335 + 0.0843 + 0.0057, time: 10.228991]
2023-05-17 15:23:46.371: epoch 111:	0.02663062  	0.19778979  	0.10795611  
2023-05-17 15:23:54.824: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 8.449995]
2023-05-17 15:23:55.132: epoch 112:	0.02654594  	0.19741708  	0.10772139  
2023-05-17 15:24:04.840: [iter 113 : loss : 0.1232 = 0.0332 + 0.0842 + 0.0058, time: 9.703682]
2023-05-17 15:24:05.217: epoch 113:	0.02668002  	0.19840632  	0.10804861  
2023-05-17 15:24:05.218: Find a better model.
2023-05-17 15:24:15.287: [iter 114 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.064990]
2023-05-17 15:24:15.564: epoch 114:	0.02669413  	0.19802417  	0.10793813  
2023-05-17 15:24:24.317: [iter 115 : loss : 0.1219 = 0.0320 + 0.0841 + 0.0058, time: 8.751025]
2023-05-17 15:24:24.498: epoch 115:	0.02664474  	0.19790800  	0.10798415  
2023-05-17 15:24:33.822: [iter 116 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 9.321506]
2023-05-17 15:24:34.028: epoch 116:	0.02662357  	0.19784051  	0.10820313  
2023-05-17 15:24:44.466: [iter 117 : loss : 0.1209 = 0.0311 + 0.0840 + 0.0059, time: 10.434990]
2023-05-17 15:24:44.795: epoch 117:	0.02662357  	0.19754328  	0.10810307  
2023-05-17 15:24:54.171: [iter 118 : loss : 0.1206 = 0.0307 + 0.0839 + 0.0059, time: 9.374065]
2023-05-17 15:24:54.444: epoch 118:	0.02667296  	0.19772287  	0.10824093  
2023-05-17 15:25:03.603: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 9.156991]
2023-05-17 15:25:03.811: epoch 119:	0.02661651  	0.19753203  	0.10828625  
2023-05-17 15:25:12.469: [iter 120 : loss : 0.1202 = 0.0303 + 0.0838 + 0.0060, time: 8.656516]
2023-05-17 15:25:12.678: epoch 120:	0.02673647  	0.19856183  	0.10855805  
2023-05-17 15:25:12.679: Find a better model.
2023-05-17 15:25:22.522: [iter 121 : loss : 0.1199 = 0.0301 + 0.0838 + 0.0060, time: 9.840991]
2023-05-17 15:25:22.701: epoch 121:	0.02676470  	0.19905971  	0.10864533  
2023-05-17 15:25:22.702: Find a better model.
2023-05-17 15:25:32.451: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 9.745470]
2023-05-17 15:25:32.752: epoch 122:	0.02679998  	0.19904378  	0.10879661  
2023-05-17 15:25:43.091: [iter 123 : loss : 0.1191 = 0.0294 + 0.0837 + 0.0061, time: 10.336993]
2023-05-17 15:25:43.418: epoch 123:	0.02681410  	0.19895697  	0.10884149  
2023-05-17 15:25:51.946: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 8.525661]
2023-05-17 15:25:52.132: epoch 124:	0.02680704  	0.19911805  	0.10891122  
2023-05-17 15:25:52.132: Find a better model.
2023-05-17 15:26:01.036: [iter 125 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0061, time: 8.901991]
2023-05-17 15:26:01.196: epoch 125:	0.02677176  	0.19873466  	0.10877579  
2023-05-17 15:26:11.020: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 9.819991]
2023-05-17 15:26:11.408: epoch 126:	0.02682821  	0.19931883  	0.10904594  
2023-05-17 15:26:11.408: Find a better model.
2023-05-17 15:26:21.359: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 9.946993]
2023-05-17 15:26:21.677: epoch 127:	0.02679999  	0.19898617  	0.10890087  
2023-05-17 15:26:31.705: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 10.026023]
2023-05-17 15:26:32.031: epoch 128:	0.02675764  	0.19867639  	0.10893587  
2023-05-17 15:26:41.226: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0063, time: 9.192995]
2023-05-17 15:26:41.774: epoch 129:	0.02679998  	0.19884999  	0.10913806  
2023-05-17 15:26:50.590: [iter 130 : loss : 0.1170 = 0.0274 + 0.0834 + 0.0063, time: 8.813437]
2023-05-17 15:26:50.786: epoch 130:	0.02684232  	0.19871415  	0.10929121  
2023-05-17 15:27:00.345: [iter 131 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0063, time: 9.555991]
2023-05-17 15:27:00.503: epoch 131:	0.02685644  	0.19898975  	0.10929648  
2023-05-17 15:27:10.733: [iter 132 : loss : 0.1163 = 0.0266 + 0.0833 + 0.0063, time: 10.227994]
2023-05-17 15:27:11.051: epoch 132:	0.02684232  	0.19904152  	0.10920586  
2023-05-17 15:27:21.104: [iter 133 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 10.046991]
2023-05-17 15:27:21.412: epoch 133:	0.02682821  	0.19885394  	0.10925271  
2023-05-17 15:27:30.773: [iter 134 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 9.358991]
2023-05-17 15:27:30.939: epoch 134:	0.02686350  	0.19900891  	0.10916626  
2023-05-17 15:27:39.505: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 8.564993]
2023-05-17 15:27:39.765: epoch 135:	0.02680705  	0.19877914  	0.10909327  
2023-05-17 15:27:48.546: [iter 136 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 8.779998]
2023-05-17 15:27:48.708: epoch 136:	0.02687056  	0.19925874  	0.10927739  
2023-05-17 15:27:59.080: [iter 137 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 10.368996]
2023-05-17 15:27:59.438: epoch 137:	0.02688467  	0.19913876  	0.10931271  
2023-05-17 15:28:09.390: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 9.949991]
2023-05-17 15:28:09.706: epoch 138:	0.02689878  	0.19919959  	0.10933576  
2023-05-17 15:28:19.156: [iter 139 : loss : 0.1144 = 0.0249 + 0.0830 + 0.0065, time: 9.448322]
2023-05-17 15:28:19.372: epoch 139:	0.02691995  	0.19961241  	0.10953776  
2023-05-17 15:28:19.372: Find a better model.
2023-05-17 15:28:28.598: [iter 140 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 9.224992]
2023-05-17 15:28:28.770: epoch 140:	0.02691995  	0.19958068  	0.10955531  
2023-05-17 15:28:37.542: [iter 141 : loss : 0.1142 = 0.0246 + 0.0829 + 0.0066, time: 8.769937]
2023-05-17 15:28:37.707: epoch 141:	0.02706813  	0.20043139  	0.10979642  
2023-05-17 15:28:37.707: Find a better model.
2023-05-17 15:28:47.377: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 9.666163]
2023-05-17 15:28:47.651: epoch 142:	0.02697640  	0.19989945  	0.10978287  
2023-05-17 15:28:57.083: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 9.428991]
2023-05-17 15:28:57.383: epoch 143:	0.02701873  	0.19999455  	0.10977092  
2023-05-17 15:29:06.853: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 9.467437]
2023-05-17 15:29:07.014: epoch 144:	0.02704696  	0.20016848  	0.10976706  
2023-05-17 15:29:16.753: [iter 145 : loss : 0.1126 = 0.0231 + 0.0828 + 0.0067, time: 9.737991]
2023-05-17 15:29:16.946: epoch 145:	0.02702579  	0.20012957  	0.11000882  
2023-05-17 15:29:26.328: [iter 146 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0067, time: 9.377991]
2023-05-17 15:29:26.624: epoch 146:	0.02703990  	0.20012802  	0.11001942  
2023-05-17 15:29:36.265: [iter 147 : loss : 0.1130 = 0.0235 + 0.0827 + 0.0068, time: 9.638758]
2023-05-17 15:29:36.586: epoch 147:	0.02697640  	0.19974455  	0.10997386  
2023-05-17 15:29:44.936: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 8.346993]
2023-05-17 15:29:45.119: epoch 148:	0.02704696  	0.20017137  	0.11014771  
2023-05-17 15:29:55.084: [iter 149 : loss : 0.1118 = 0.0224 + 0.0826 + 0.0068, time: 9.960196]
2023-05-17 15:29:55.362: epoch 149:	0.02702580  	0.19981988  	0.11016938  
2023-05-17 15:30:04.467: [iter 150 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0068, time: 9.104287]
2023-05-17 15:30:04.634: epoch 150:	0.02701874  	0.19981700  	0.11021238  
2023-05-17 15:30:14.258: [iter 151 : loss : 0.1115 = 0.0221 + 0.0826 + 0.0069, time: 9.621567]
2023-05-17 15:30:14.507: epoch 151:	0.02701874  	0.19968702  	0.11014237  
2023-05-17 15:30:23.715: [iter 152 : loss : 0.1111 = 0.0217 + 0.0825 + 0.0069, time: 9.201727]
2023-05-17 15:30:24.030: epoch 152:	0.02701874  	0.19979864  	0.10994411  
2023-05-17 15:30:32.423: [iter 153 : loss : 0.1100 = 0.0206 + 0.0825 + 0.0069, time: 8.391516]
2023-05-17 15:30:32.589: epoch 153:	0.02704696  	0.19990864  	0.11025561  
2023-05-17 15:30:40.465: [iter 154 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 7.875698]
2023-05-17 15:30:40.630: epoch 154:	0.02708224  	0.20012851  	0.11023767  
2023-05-17 15:30:49.337: [iter 155 : loss : 0.1110 = 0.0215 + 0.0825 + 0.0070, time: 8.703201]
2023-05-17 15:30:49.497: epoch 155:	0.02708930  	0.20019034  	0.11018541  
2023-05-17 15:30:58.694: [iter 156 : loss : 0.1106 = 0.0212 + 0.0824 + 0.0070, time: 9.192991]
2023-05-17 15:30:59.000: epoch 156:	0.02708930  	0.20027466  	0.11037666  
2023-05-17 15:31:08.225: [iter 157 : loss : 0.1105 = 0.0211 + 0.0824 + 0.0070, time: 9.220991]
2023-05-17 15:31:08.495: epoch 157:	0.02706813  	0.20000713  	0.11032551  
2023-05-17 15:31:16.878: [iter 158 : loss : 0.1098 = 0.0204 + 0.0824 + 0.0071, time: 8.382262]
2023-05-17 15:31:17.039: epoch 158:	0.02706108  	0.19997174  	0.11037967  
2023-05-17 15:31:25.532: [iter 159 : loss : 0.1100 = 0.0206 + 0.0823 + 0.0071, time: 8.490995]
2023-05-17 15:31:25.869: epoch 159:	0.02702579  	0.19971108  	0.11020575  
2023-05-17 15:31:33.886: [iter 160 : loss : 0.1094 = 0.0200 + 0.0823 + 0.0071, time: 8.013094]
2023-05-17 15:31:34.049: epoch 160:	0.02691994  	0.19895102  	0.11006524  
2023-05-17 15:31:43.121: [iter 161 : loss : 0.1090 = 0.0195 + 0.0823 + 0.0071, time: 9.069992]
2023-05-17 15:31:43.435: epoch 161:	0.02696228  	0.19913593  	0.10978646  
2023-05-17 15:31:50.899: [iter 162 : loss : 0.1083 = 0.0189 + 0.0823 + 0.0072, time: 7.462993]
2023-05-17 15:31:51.074: epoch 162:	0.02699756  	0.19932678  	0.10968769  
2023-05-17 15:31:59.312: [iter 163 : loss : 0.1089 = 0.0195 + 0.0822 + 0.0072, time: 8.235997]
2023-05-17 15:31:59.487: epoch 163:	0.02691288  	0.19874138  	0.10961715  
2023-05-17 15:32:07.945: [iter 164 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 8.455992]
2023-05-17 15:32:08.102: epoch 164:	0.02691994  	0.19855501  	0.10946345  
2023-05-17 15:32:16.062: [iter 165 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 7.958993]
2023-05-17 15:32:16.219: epoch 165:	0.02684938  	0.19800805  	0.10929080  
2023-05-17 15:32:25.240: [iter 166 : loss : 0.1083 = 0.0189 + 0.0821 + 0.0072, time: 9.017992]
2023-05-17 15:32:25.552: epoch 166:	0.02684232  	0.19803847  	0.10923491  
2023-05-17 15:32:25.552: Early stopping is trigger at epoch: 166
2023-05-17 15:32:25.552: best_result@epoch 141:

2023-05-17 15:32:25.552: 		0.0271      	0.2004      	0.1098      
2023-05-17 15:47:26.499: my pid: 6440
2023-05-17 15:47:26.499: model: model.general_recommender.SGL
2023-05-17 15:47:26.499: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 15:47:26.499: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 15:47:30.195: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 15:47:40.649: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.452584]
2023-05-17 15:47:40.811: epoch 1:	0.00146063  	0.01018053  	0.00503690  
2023-05-17 15:47:40.811: Find a better model.
2023-05-17 15:47:51.932: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 11.117001]
2023-05-17 15:47:52.268: epoch 2:	0.00265312  	0.01949755  	0.00966831  
2023-05-17 15:47:52.268: Find a better model.
2023-05-17 15:48:03.530: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 11.259029]
2023-05-17 15:48:03.884: epoch 3:	0.00482639  	0.03598385  	0.01693032  
2023-05-17 15:48:03.884: Find a better model.
2023-05-17 15:48:13.899: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 10.013016]
2023-05-17 15:48:14.141: epoch 4:	0.00774761  	0.05664438  	0.02702948  
2023-05-17 15:48:14.141: Find a better model.
2023-05-17 15:48:23.520: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 9.377033]
2023-05-17 15:48:23.769: epoch 5:	0.01162859  	0.08400311  	0.03941787  
2023-05-17 15:48:23.769: Find a better model.
2023-05-17 15:48:34.299: [iter 6 : loss : 0.7674 = 0.6883 + 0.0791 + 0.0000, time: 10.527991]
2023-05-17 15:48:34.500: epoch 6:	0.01503685  	0.10855367  	0.05191924  
2023-05-17 15:48:34.501: Find a better model.
2023-05-17 15:48:44.821: [iter 7 : loss : 0.7613 = 0.6814 + 0.0799 + 0.0000, time: 10.313015]
2023-05-17 15:48:45.125: epoch 7:	0.01752775  	0.12696022  	0.06236995  
2023-05-17 15:48:45.125: Find a better model.
2023-05-17 15:48:55.052: [iter 8 : loss : 0.7461 = 0.6643 + 0.0817 + 0.0001, time: 9.924018]
2023-05-17 15:48:55.341: epoch 8:	0.01861445  	0.13667518  	0.06838708  
2023-05-17 15:48:55.341: Find a better model.
2023-05-17 15:49:04.945: [iter 9 : loss : 0.7115 = 0.6258 + 0.0856 + 0.0001, time: 9.603039]
2023-05-17 15:49:05.113: epoch 9:	0.01881910  	0.13887003  	0.06965310  
2023-05-17 15:49:05.113: Find a better model.
2023-05-17 15:49:14.951: [iter 10 : loss : 0.6509 = 0.5596 + 0.0910 + 0.0002, time: 9.837012]
2023-05-17 15:49:15.117: epoch 10:	0.01865679  	0.13791749  	0.06847050  
2023-05-17 15:49:24.663: [iter 11 : loss : 0.5750 = 0.4785 + 0.0961 + 0.0004, time: 9.545012]
2023-05-17 15:49:24.981: epoch 11:	0.01850861  	0.13666624  	0.06821346  
2023-05-17 15:49:34.958: [iter 12 : loss : 0.5058 = 0.4057 + 0.0996 + 0.0005, time: 9.975030]
2023-05-17 15:49:35.262: epoch 12:	0.01848040  	0.13624926  	0.06822085  
2023-05-17 15:49:44.227: [iter 13 : loss : 0.4548 = 0.3526 + 0.1014 + 0.0007, time: 8.962991]
2023-05-17 15:49:44.445: epoch 13:	0.01860741  	0.13747278  	0.06925680  
2023-05-17 15:49:52.980: [iter 14 : loss : 0.4163 = 0.3130 + 0.1024 + 0.0008, time: 8.526017]
2023-05-17 15:49:53.376: epoch 14:	0.01884027  	0.13960895  	0.07026706  
2023-05-17 15:49:53.376: Find a better model.
2023-05-17 15:50:03.031: [iter 15 : loss : 0.3893 = 0.2856 + 0.1028 + 0.0010, time: 9.653145]
2023-05-17 15:50:03.198: epoch 15:	0.01906608  	0.14176263  	0.07136370  
2023-05-17 15:50:03.198: Find a better model.
2023-05-17 15:50:13.552: [iter 16 : loss : 0.3670 = 0.2632 + 0.1027 + 0.0011, time: 10.351010]
2023-05-17 15:50:13.893: epoch 16:	0.01920721  	0.14278261  	0.07199663  
2023-05-17 15:50:13.893: Find a better model.
2023-05-17 15:50:24.099: [iter 17 : loss : 0.3504 = 0.2466 + 0.1026 + 0.0012, time: 10.204020]
2023-05-17 15:50:24.410: epoch 17:	0.01943302  	0.14402135  	0.07299771  
2023-05-17 15:50:24.410: Find a better model.
2023-05-17 15:50:33.369: [iter 18 : loss : 0.3352 = 0.2315 + 0.1024 + 0.0013, time: 8.956998]
2023-05-17 15:50:33.566: epoch 18:	0.01962355  	0.14504914  	0.07351360  
2023-05-17 15:50:33.567: Find a better model.
2023-05-17 15:50:42.844: [iter 19 : loss : 0.3211 = 0.2177 + 0.1020 + 0.0014, time: 9.274999]
2023-05-17 15:50:42.999: epoch 19:	0.01967999  	0.14537904  	0.07381161  
2023-05-17 15:50:42.999: Find a better model.
2023-05-17 15:50:51.884: [iter 20 : loss : 0.3114 = 0.2082 + 0.1017 + 0.0015, time: 8.883001]
2023-05-17 15:50:52.049: epoch 20:	0.01989170  	0.14679705  	0.07469604  
2023-05-17 15:50:52.049: Find a better model.
2023-05-17 15:51:02.514: [iter 21 : loss : 0.3016 = 0.1988 + 0.1012 + 0.0016, time: 10.463437]
2023-05-17 15:51:02.787: epoch 21:	0.02018101  	0.14884070  	0.07559056  
2023-05-17 15:51:02.787: Find a better model.
2023-05-17 15:51:13.089: [iter 22 : loss : 0.2934 = 0.1910 + 0.1008 + 0.0016, time: 10.296014]
2023-05-17 15:51:13.419: epoch 22:	0.02037859  	0.15046786  	0.07636446  
2023-05-17 15:51:13.419: Find a better model.
2023-05-17 15:51:21.511: [iter 23 : loss : 0.2852 = 0.1831 + 0.1003 + 0.0017, time: 8.091033]
2023-05-17 15:51:21.715: epoch 23:	0.02054795  	0.15164399  	0.07693649  
2023-05-17 15:51:21.715: Find a better model.
2023-05-17 15:51:30.660: [iter 24 : loss : 0.2786 = 0.1769 + 0.0999 + 0.0018, time: 8.943000]
2023-05-17 15:51:30.822: epoch 24:	0.02071025  	0.15301491  	0.07791673  
2023-05-17 15:51:30.822: Find a better model.
2023-05-17 15:51:40.115: [iter 25 : loss : 0.2721 = 0.1707 + 0.0995 + 0.0019, time: 9.290999]
2023-05-17 15:51:40.363: epoch 25:	0.02090783  	0.15430649  	0.07861743  
2023-05-17 15:51:40.363: Find a better model.
2023-05-17 15:51:49.073: [iter 26 : loss : 0.2683 = 0.1673 + 0.0991 + 0.0019, time: 8.709027]
2023-05-17 15:51:49.244: epoch 26:	0.02100662  	0.15498963  	0.07918738  
2023-05-17 15:51:49.244: Find a better model.
2023-05-17 15:51:59.136: [iter 27 : loss : 0.2606 = 0.1599 + 0.0986 + 0.0020, time: 9.890008]
2023-05-17 15:51:59.455: epoch 27:	0.02128182  	0.15679830  	0.08012381  
2023-05-17 15:51:59.455: Find a better model.
2023-05-17 15:52:09.215: [iter 28 : loss : 0.2558 = 0.1555 + 0.0982 + 0.0021, time: 9.755533]
2023-05-17 15:52:09.520: epoch 28:	0.02144412  	0.15803610  	0.08088174  
2023-05-17 15:52:09.521: Find a better model.
2023-05-17 15:52:18.632: [iter 29 : loss : 0.2512 = 0.1513 + 0.0978 + 0.0021, time: 9.110036]
2023-05-17 15:52:18.815: epoch 29:	0.02154997  	0.15871280  	0.08148132  
2023-05-17 15:52:18.815: Find a better model.
2023-05-17 15:52:28.891: [iter 30 : loss : 0.2449 = 0.1453 + 0.0974 + 0.0022, time: 10.074015]
2023-05-17 15:52:29.053: epoch 30:	0.02173345  	0.16015291  	0.08222889  
2023-05-17 15:52:29.053: Find a better model.
2023-05-17 15:52:38.540: [iter 31 : loss : 0.2413 = 0.1420 + 0.0970 + 0.0023, time: 9.486027]
2023-05-17 15:52:38.843: epoch 31:	0.02178990  	0.16057946  	0.08271292  
2023-05-17 15:52:38.843: Find a better model.
2023-05-17 15:52:48.886: [iter 32 : loss : 0.2355 = 0.1365 + 0.0967 + 0.0023, time: 10.040001]
2023-05-17 15:52:49.226: epoch 32:	0.02200864  	0.16244005  	0.08358399  
2023-05-17 15:52:49.226: Find a better model.
2023-05-17 15:52:59.053: [iter 33 : loss : 0.2330 = 0.1343 + 0.0963 + 0.0024, time: 9.818518]
2023-05-17 15:52:59.314: epoch 33:	0.02217800  	0.16400287  	0.08422943  
2023-05-17 15:52:59.314: Find a better model.
2023-05-17 15:53:08.966: [iter 34 : loss : 0.2291 = 0.1307 + 0.0960 + 0.0024, time: 9.650285]
2023-05-17 15:53:09.141: epoch 34:	0.02229090  	0.16459170  	0.08479220  
2023-05-17 15:53:09.142: Find a better model.
2023-05-17 15:53:17.855: [iter 35 : loss : 0.2253 = 0.1272 + 0.0956 + 0.0025, time: 8.711030]
2023-05-17 15:53:18.011: epoch 35:	0.02257316  	0.16656545  	0.08561985  
2023-05-17 15:53:18.011: Find a better model.
2023-05-17 15:53:28.190: [iter 36 : loss : 0.2217 = 0.1238 + 0.0953 + 0.0025, time: 10.174026]
2023-05-17 15:53:28.537: epoch 36:	0.02272840  	0.16735286  	0.08624288  
2023-05-17 15:53:28.538: Find a better model.
2023-05-17 15:53:38.156: [iter 37 : loss : 0.2182 = 0.1206 + 0.0950 + 0.0026, time: 9.616028]
2023-05-17 15:53:38.478: epoch 37:	0.02282720  	0.16830263  	0.08684288  
2023-05-17 15:53:38.478: Find a better model.
2023-05-17 15:53:48.157: [iter 38 : loss : 0.2164 = 0.1191 + 0.0947 + 0.0026, time: 9.675516]
2023-05-17 15:53:48.344: epoch 38:	0.02294716  	0.16889937  	0.08734171  
2023-05-17 15:53:48.345: Find a better model.
2023-05-17 15:53:57.951: [iter 39 : loss : 0.2121 = 0.1150 + 0.0944 + 0.0027, time: 9.603000]
2023-05-17 15:53:58.362: epoch 39:	0.02309534  	0.16974664  	0.08806138  
2023-05-17 15:53:58.362: Find a better model.
2023-05-17 15:54:07.643: [iter 40 : loss : 0.2088 = 0.1120 + 0.0941 + 0.0028, time: 9.277072]
2023-05-17 15:54:07.800: epoch 40:	0.02322236  	0.17059064  	0.08846436  
2023-05-17 15:54:07.800: Find a better model.
2023-05-17 15:54:17.956: [iter 41 : loss : 0.2071 = 0.1105 + 0.0938 + 0.0028, time: 10.154008]
2023-05-17 15:54:18.250: epoch 41:	0.02323647  	0.17076768  	0.08902045  
2023-05-17 15:54:18.250: Find a better model.
2023-05-17 15:54:28.376: [iter 42 : loss : 0.2049 = 0.1085 + 0.0935 + 0.0029, time: 10.121022]
2023-05-17 15:54:28.656: epoch 42:	0.02332116  	0.17138739  	0.08958355  
2023-05-17 15:54:28.656: Find a better model.
2023-05-17 15:54:38.420: [iter 43 : loss : 0.2010 = 0.1049 + 0.0932 + 0.0029, time: 9.762008]
2023-05-17 15:54:38.647: epoch 43:	0.02344817  	0.17235596  	0.09010251  
2023-05-17 15:54:38.647: Find a better model.
2023-05-17 15:54:48.840: [iter 44 : loss : 0.1975 = 0.1016 + 0.0929 + 0.0030, time: 10.190991]
2023-05-17 15:54:49.000: epoch 44:	0.02364575  	0.17380144  	0.09097036  
2023-05-17 15:54:49.000: Find a better model.
2023-05-17 15:54:57.161: [iter 45 : loss : 0.1951 = 0.0995 + 0.0927 + 0.0030, time: 8.160017]
2023-05-17 15:54:57.325: epoch 45:	0.02375865  	0.17477234  	0.09148385  
2023-05-17 15:54:57.325: Find a better model.
2023-05-17 15:55:07.193: [iter 46 : loss : 0.1930 = 0.0975 + 0.0925 + 0.0031, time: 9.863998]
2023-05-17 15:55:07.846: epoch 46:	0.02389978  	0.17614265  	0.09231146  
2023-05-17 15:55:07.846: Find a better model.
2023-05-17 15:55:17.241: [iter 47 : loss : 0.1922 = 0.0969 + 0.0922 + 0.0031, time: 9.393017]
2023-05-17 15:55:17.522: epoch 47:	0.02395623  	0.17612137  	0.09264079  
2023-05-17 15:55:26.808: [iter 48 : loss : 0.1882 = 0.0931 + 0.0920 + 0.0032, time: 9.284102]
2023-05-17 15:55:26.984: epoch 48:	0.02399856  	0.17646503  	0.09303360  
2023-05-17 15:55:26.984: Find a better model.
2023-05-17 15:55:36.780: [iter 49 : loss : 0.1850 = 0.0900 + 0.0918 + 0.0032, time: 9.795006]
2023-05-17 15:55:36.961: epoch 49:	0.02399151  	0.17656691  	0.09327906  
2023-05-17 15:55:36.961: Find a better model.
2023-05-17 15:55:47.602: [iter 50 : loss : 0.1843 = 0.0895 + 0.0915 + 0.0033, time: 10.639029]
2023-05-17 15:55:47.915: epoch 50:	0.02418203  	0.17788422  	0.09399934  
2023-05-17 15:55:47.915: Find a better model.
2023-05-17 15:55:58.237: [iter 51 : loss : 0.1812 = 0.0866 + 0.0913 + 0.0033, time: 10.319007]
2023-05-17 15:55:58.544: epoch 51:	0.02430905  	0.17861472  	0.09439425  
2023-05-17 15:55:58.544: Find a better model.
2023-05-17 15:56:07.937: [iter 52 : loss : 0.1812 = 0.0867 + 0.0911 + 0.0033, time: 9.391956]
2023-05-17 15:56:08.269: epoch 52:	0.02432316  	0.17876668  	0.09483624  
2023-05-17 15:56:08.269: Find a better model.
2023-05-17 15:56:17.125: [iter 53 : loss : 0.1793 = 0.0850 + 0.0909 + 0.0034, time: 8.853445]
2023-05-17 15:56:17.316: epoch 53:	0.02433022  	0.17865789  	0.09520180  
2023-05-17 15:56:26.879: [iter 54 : loss : 0.1768 = 0.0827 + 0.0907 + 0.0034, time: 9.561001]
2023-05-17 15:56:27.045: epoch 54:	0.02440079  	0.17893150  	0.09564970  
2023-05-17 15:56:27.046: Find a better model.
2023-05-17 15:56:37.542: [iter 55 : loss : 0.1753 = 0.0813 + 0.0905 + 0.0035, time: 10.491511]
2023-05-17 15:56:37.863: epoch 55:	0.02454897  	0.18051232  	0.09615729  
2023-05-17 15:56:37.863: Find a better model.
2023-05-17 15:56:47.329: [iter 56 : loss : 0.1733 = 0.0794 + 0.0903 + 0.0035, time: 9.458013]
2023-05-17 15:56:47.634: epoch 56:	0.02469715  	0.18165545  	0.09669226  
2023-05-17 15:56:47.634: Find a better model.
2023-05-17 15:56:56.829: [iter 57 : loss : 0.1717 = 0.0780 + 0.0902 + 0.0036, time: 9.193590]
2023-05-17 15:56:56.995: epoch 57:	0.02482417  	0.18298595  	0.09727173  
2023-05-17 15:56:56.995: Find a better model.
2023-05-17 15:57:06.903: [iter 58 : loss : 0.1695 = 0.0759 + 0.0900 + 0.0036, time: 9.906005]
2023-05-17 15:57:07.178: epoch 58:	0.02481711  	0.18278927  	0.09740115  
2023-05-17 15:57:17.168: [iter 59 : loss : 0.1686 = 0.0752 + 0.0898 + 0.0037, time: 9.989176]
2023-05-17 15:57:17.348: epoch 59:	0.02494413  	0.18381515  	0.09782979  
2023-05-17 15:57:17.348: Find a better model.
2023-05-17 15:57:27.524: [iter 60 : loss : 0.1670 = 0.0737 + 0.0896 + 0.0037, time: 10.168968]
2023-05-17 15:57:27.891: epoch 60:	0.02495119  	0.18399014  	0.09805353  
2023-05-17 15:57:27.891: Find a better model.
2023-05-17 15:57:38.204: [iter 61 : loss : 0.1657 = 0.0725 + 0.0894 + 0.0038, time: 10.304016]
2023-05-17 15:57:38.554: epoch 61:	0.02511349  	0.18508695  	0.09868380  
2023-05-17 15:57:38.554: Find a better model.
2023-05-17 15:57:48.345: [iter 62 : loss : 0.1641 = 0.0710 + 0.0893 + 0.0038, time: 9.790002]
2023-05-17 15:57:48.548: epoch 62:	0.02518404  	0.18564929  	0.09902062  
2023-05-17 15:57:48.549: Find a better model.
2023-05-17 15:57:57.321: [iter 63 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0038, time: 8.770541]
2023-05-17 15:57:57.495: epoch 63:	0.02521933  	0.18579985  	0.09939968  
2023-05-17 15:57:57.495: Find a better model.
2023-05-17 15:58:07.805: [iter 64 : loss : 0.1616 = 0.0687 + 0.0889 + 0.0039, time: 10.308420]
2023-05-17 15:58:07.989: epoch 64:	0.02528284  	0.18622543  	0.09978322  
2023-05-17 15:58:07.989: Find a better model.
2023-05-17 15:58:18.150: [iter 65 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 10.158013]
2023-05-17 15:58:18.468: epoch 65:	0.02533223  	0.18661131  	0.10021631  
2023-05-17 15:58:18.468: Find a better model.
2023-05-17 15:58:28.128: [iter 66 : loss : 0.1589 = 0.0663 + 0.0886 + 0.0040, time: 9.656008]
2023-05-17 15:58:28.414: epoch 66:	0.02533929  	0.18642713  	0.10029881  
2023-05-17 15:58:38.055: [iter 67 : loss : 0.1569 = 0.0644 + 0.0885 + 0.0040, time: 9.639999]
2023-05-17 15:58:38.271: epoch 67:	0.02538163  	0.18646437  	0.10045315  
2023-05-17 15:58:47.848: [iter 68 : loss : 0.1571 = 0.0647 + 0.0884 + 0.0041, time: 9.574119]
2023-05-17 15:58:48.024: epoch 68:	0.02545924  	0.18729974  	0.10095605  
2023-05-17 15:58:48.024: Find a better model.
2023-05-17 15:58:57.476: [iter 69 : loss : 0.1551 = 0.0629 + 0.0882 + 0.0041, time: 9.444052]
2023-05-17 15:58:57.805: epoch 69:	0.02558626  	0.18810655  	0.10146616  
2023-05-17 15:58:57.805: Find a better model.
2023-05-17 15:59:07.465: [iter 70 : loss : 0.1532 = 0.0610 + 0.0881 + 0.0041, time: 9.658448]
2023-05-17 15:59:07.769: epoch 70:	0.02566388  	0.18862361  	0.10188045  
2023-05-17 15:59:07.769: Find a better model.
2023-05-17 15:59:16.192: [iter 71 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 8.422001]
2023-05-17 15:59:16.372: epoch 71:	0.02571328  	0.18902895  	0.10228492  
2023-05-17 15:59:16.372: Find a better model.
2023-05-17 15:59:25.996: [iter 72 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 9.619018]
2023-05-17 15:59:26.280: epoch 72:	0.02571328  	0.18913265  	0.10244799  
2023-05-17 15:59:26.281: Find a better model.
2023-05-17 15:59:35.920: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 9.637999]
2023-05-17 15:59:36.088: epoch 73:	0.02576973  	0.19001855  	0.10276462  
2023-05-17 15:59:36.088: Find a better model.
2023-05-17 15:59:46.313: [iter 74 : loss : 0.1489 = 0.0570 + 0.0876 + 0.0043, time: 10.223135]
2023-05-17 15:59:46.627: epoch 74:	0.02586852  	0.19073291  	0.10325505  
2023-05-17 15:59:46.628: Find a better model.
2023-05-17 15:59:56.801: [iter 75 : loss : 0.1481 = 0.0563 + 0.0875 + 0.0043, time: 10.170587]
2023-05-17 15:59:57.128: epoch 75:	0.02585440  	0.19051117  	0.10329296  
2023-05-17 16:00:05.718: [iter 76 : loss : 0.1476 = 0.0558 + 0.0874 + 0.0044, time: 8.589013]
2023-05-17 16:00:05.900: epoch 76:	0.02592497  	0.19098231  	0.10350154  
2023-05-17 16:00:05.900: Find a better model.
2023-05-17 16:00:14.676: [iter 77 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 8.773513]
2023-05-17 16:00:14.836: epoch 77:	0.02587557  	0.19046018  	0.10352729  
2023-05-17 16:00:24.726: [iter 78 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0045, time: 9.884999]
2023-05-17 16:00:24.968: epoch 78:	0.02581912  	0.18993717  	0.10341710  
2023-05-17 16:00:33.889: [iter 79 : loss : 0.1441 = 0.0525 + 0.0870 + 0.0045, time: 8.920504]
2023-05-17 16:00:34.049: epoch 79:	0.02591791  	0.19046398  	0.10368904  
2023-05-17 16:00:44.134: [iter 80 : loss : 0.1433 = 0.0518 + 0.0869 + 0.0045, time: 10.074018]
2023-05-17 16:00:44.441: epoch 80:	0.02593908  	0.19048747  	0.10382184  
2023-05-17 16:00:53.351: [iter 81 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 8.904045]
2023-05-17 16:00:53.641: epoch 81:	0.02598848  	0.19079781  	0.10394449  
2023-05-17 16:01:02.878: [iter 82 : loss : 0.1419 = 0.0506 + 0.0867 + 0.0046, time: 9.234998]
2023-05-17 16:01:03.051: epoch 82:	0.02588263  	0.19010079  	0.10394250  
2023-05-17 16:01:12.758: [iter 83 : loss : 0.1411 = 0.0499 + 0.0866 + 0.0047, time: 9.704233]
2023-05-17 16:01:12.919: epoch 83:	0.02588969  	0.19033977  	0.10414606  
2023-05-17 16:01:20.929: [iter 84 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.007017]
2023-05-17 16:01:21.090: epoch 84:	0.02591791  	0.19059399  	0.10421084  
2023-05-17 16:01:30.956: [iter 85 : loss : 0.1397 = 0.0486 + 0.0864 + 0.0047, time: 9.861999]
2023-05-17 16:01:31.334: epoch 85:	0.02598143  	0.19105600  	0.10439903  
2023-05-17 16:01:31.335: Find a better model.
2023-05-17 16:01:40.819: [iter 86 : loss : 0.1396 = 0.0486 + 0.0863 + 0.0048, time: 9.474068]
2023-05-17 16:01:41.064: epoch 86:	0.02601671  	0.19128604  	0.10466794  
2023-05-17 16:01:41.065: Find a better model.
2023-05-17 16:01:49.195: [iter 87 : loss : 0.1369 = 0.0458 + 0.0862 + 0.0048, time: 8.127186]
2023-05-17 16:01:49.424: epoch 87:	0.02614374  	0.19267288  	0.10538901  
2023-05-17 16:01:49.424: Find a better model.
2023-05-17 16:01:57.552: [iter 88 : loss : 0.1363 = 0.0454 + 0.0861 + 0.0049, time: 8.126026]
2023-05-17 16:01:57.719: epoch 88:	0.02606611  	0.19193169  	0.10529495  
2023-05-17 16:02:06.612: [iter 89 : loss : 0.1360 = 0.0452 + 0.0860 + 0.0049, time: 8.892133]
2023-05-17 16:02:06.861: epoch 89:	0.02605200  	0.19140102  	0.10513978  
2023-05-17 16:02:15.006: [iter 90 : loss : 0.1365 = 0.0457 + 0.0859 + 0.0049, time: 8.144683]
2023-05-17 16:02:15.169: epoch 90:	0.02609433  	0.19182286  	0.10546509  
2023-05-17 16:02:23.398: [iter 91 : loss : 0.1354 = 0.0446 + 0.0858 + 0.0050, time: 8.227027]
2023-05-17 16:02:23.554: epoch 91:	0.02607316  	0.19184233  	0.10552585  
2023-05-17 16:02:32.456: [iter 92 : loss : 0.1344 = 0.0436 + 0.0858 + 0.0050, time: 8.891011]
2023-05-17 16:02:32.727: epoch 92:	0.02610139  	0.19213216  	0.10575218  
2023-05-17 16:02:40.816: [iter 93 : loss : 0.1347 = 0.0441 + 0.0856 + 0.0050, time: 8.088011]
2023-05-17 16:02:40.983: epoch 93:	0.02610139  	0.19228028  	0.10584145  
2023-05-17 16:02:49.082: [iter 94 : loss : 0.1323 = 0.0417 + 0.0856 + 0.0051, time: 8.097642]
2023-05-17 16:02:49.251: epoch 94:	0.02608022  	0.19210885  	0.10565135  
2023-05-17 16:02:57.172: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.918019]
2023-05-17 16:02:57.327: epoch 95:	0.02612962  	0.19240615  	0.10596772  
2023-05-17 16:03:05.449: [iter 96 : loss : 0.1318 = 0.0413 + 0.0854 + 0.0052, time: 8.120023]
2023-05-17 16:03:05.613: epoch 96:	0.02622841  	0.19271892  	0.10621537  
2023-05-17 16:03:05.614: Find a better model.
2023-05-17 16:03:14.002: [iter 97 : loss : 0.1302 = 0.0397 + 0.0853 + 0.0052, time: 8.386999]
2023-05-17 16:03:14.163: epoch 97:	0.02617902  	0.19235855  	0.10624521  
2023-05-17 16:03:21.840: [iter 98 : loss : 0.1311 = 0.0405 + 0.0853 + 0.0052, time: 7.676023]
2023-05-17 16:03:21.997: epoch 98:	0.02625664  	0.19313936  	0.10650154  
2023-05-17 16:03:21.998: Find a better model.
2023-05-17 16:03:30.022: [iter 99 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0053, time: 8.023013]
2023-05-17 16:03:30.183: epoch 99:	0.02631309  	0.19348264  	0.10667818  
2023-05-17 16:03:30.183: Find a better model.
2023-05-17 16:03:38.631: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 8.445532]
2023-05-17 16:03:38.808: epoch 100:	0.02624252  	0.19316277  	0.10656177  
2023-05-17 16:03:46.661: [iter 101 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 7.851684]
2023-05-17 16:03:46.823: epoch 101:	0.02619313  	0.19262025  	0.10652855  
2023-05-17 16:03:54.582: [iter 102 : loss : 0.1278 = 0.0375 + 0.0850 + 0.0054, time: 7.757015]
2023-05-17 16:03:54.735: epoch 102:	0.02625664  	0.19301455  	0.10670910  
2023-05-17 16:04:04.120: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 9.381206]
2023-05-17 16:04:04.373: epoch 103:	0.02634131  	0.19370307  	0.10696448  
2023-05-17 16:04:04.373: Find a better model.
2023-05-17 16:04:12.535: [iter 104 : loss : 0.1281 = 0.0378 + 0.0848 + 0.0054, time: 8.160021]
2023-05-17 16:04:12.741: epoch 104:	0.02627075  	0.19317000  	0.10683437  
2023-05-17 16:04:20.682: [iter 105 : loss : 0.1271 = 0.0369 + 0.0848 + 0.0055, time: 7.938993]
2023-05-17 16:04:20.860: epoch 105:	0.02625663  	0.19328529  	0.10707270  
2023-05-17 16:04:29.616: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 8.751430]
2023-05-17 16:04:29.861: epoch 106:	0.02627075  	0.19330895  	0.10699467  
2023-05-17 16:04:37.965: [iter 107 : loss : 0.1258 = 0.0356 + 0.0846 + 0.0055, time: 8.103010]
2023-05-17 16:04:38.131: epoch 107:	0.02634131  	0.19397093  	0.10700335  
2023-05-17 16:04:38.131: Find a better model.
2023-05-17 16:04:46.327: [iter 108 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 8.195207]
2023-05-17 16:04:46.483: epoch 108:	0.02624957  	0.19306369  	0.10693926  
2023-05-17 16:04:55.283: [iter 109 : loss : 0.1242 = 0.0341 + 0.0845 + 0.0056, time: 8.799009]
2023-05-17 16:04:55.562: epoch 109:	0.02626369  	0.19309135  	0.10690701  
2023-05-17 16:05:03.760: [iter 110 : loss : 0.1236 = 0.0335 + 0.0845 + 0.0056, time: 8.197007]
2023-05-17 16:05:03.927: epoch 110:	0.02631308  	0.19332679  	0.10702565  
2023-05-17 16:05:11.848: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 7.919992]
2023-05-17 16:05:12.018: epoch 111:	0.02631308  	0.19347835  	0.10728047  
2023-05-17 16:05:20.068: [iter 112 : loss : 0.1236 = 0.0335 + 0.0843 + 0.0057, time: 8.048683]
2023-05-17 16:05:20.602: epoch 112:	0.02636953  	0.19399007  	0.10754230  
2023-05-17 16:05:20.602: Find a better model.
2023-05-17 16:05:28.563: [iter 113 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0057, time: 7.957225]
2023-05-17 16:05:28.723: epoch 113:	0.02638365  	0.19407497  	0.10740517  
2023-05-17 16:05:28.723: Find a better model.
2023-05-17 16:05:36.971: [iter 114 : loss : 0.1226 = 0.0326 + 0.0842 + 0.0058, time: 8.246202]
2023-05-17 16:05:37.133: epoch 114:	0.02639070  	0.19422939  	0.10746779  
2023-05-17 16:05:37.133: Find a better model.
2023-05-17 16:05:44.838: [iter 115 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 7.703098]
2023-05-17 16:05:44.997: epoch 115:	0.02636954  	0.19398551  	0.10763808  
2023-05-17 16:05:52.945: [iter 116 : loss : 0.1212 = 0.0313 + 0.0841 + 0.0058, time: 7.947059]
2023-05-17 16:05:53.102: epoch 116:	0.02634837  	0.19362436  	0.10736138  
2023-05-17 16:06:01.142: [iter 117 : loss : 0.1213 = 0.0313 + 0.0841 + 0.0059, time: 8.037016]
2023-05-17 16:06:01.292: epoch 117:	0.02635543  	0.19399257  	0.10766398  
2023-05-17 16:06:08.842: [iter 118 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 7.548305]
2023-05-17 16:06:08.992: epoch 118:	0.02640482  	0.19444428  	0.10787565  
2023-05-17 16:06:08.993: Find a better model.
2023-05-17 16:06:16.493: [iter 119 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0059, time: 7.499056]
2023-05-17 16:06:16.643: epoch 119:	0.02638366  	0.19449961  	0.10782629  
2023-05-17 16:06:16.644: Find a better model.
2023-05-17 16:06:24.113: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 7.467664]
2023-05-17 16:06:24.263: epoch 120:	0.02644011  	0.19481404  	0.10796231  
2023-05-17 16:06:24.263: Find a better model.
2023-05-17 16:06:31.688: [iter 121 : loss : 0.1203 = 0.0305 + 0.0838 + 0.0060, time: 7.423733]
2023-05-17 16:06:31.837: epoch 121:	0.02641894  	0.19478914  	0.10811023  
2023-05-17 16:06:39.275: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 7.436735]
2023-05-17 16:06:39.425: epoch 122:	0.02657418  	0.19579266  	0.10859199  
2023-05-17 16:06:39.425: Find a better model.
2023-05-17 16:06:46.693: [iter 123 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0061, time: 7.266909]
2023-05-17 16:06:46.859: epoch 123:	0.02658123  	0.19571017  	0.10848588  
2023-05-17 16:06:54.337: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 7.474842]
2023-05-17 16:06:54.502: epoch 124:	0.02653183  	0.19530779  	0.10853232  
2023-05-17 16:07:01.888: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0061, time: 7.383902]
2023-05-17 16:07:02.050: epoch 125:	0.02644011  	0.19419828  	0.10820732  
2023-05-17 16:07:09.485: [iter 126 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0062, time: 7.432893]
2023-05-17 16:07:09.633: epoch 126:	0.02646127  	0.19446094  	0.10833090  
2023-05-17 16:07:17.078: [iter 127 : loss : 0.1170 = 0.0273 + 0.0836 + 0.0062, time: 7.442875]
2023-05-17 16:07:17.226: epoch 127:	0.02648950  	0.19456363  	0.10828137  
2023-05-17 16:07:24.676: [iter 128 : loss : 0.1181 = 0.0284 + 0.0835 + 0.0062, time: 7.448235]
2023-05-17 16:07:24.824: epoch 128:	0.02651772  	0.19493359  	0.10839701  
2023-05-17 16:07:32.290: [iter 129 : loss : 0.1173 = 0.0276 + 0.0835 + 0.0062, time: 7.464926]
2023-05-17 16:07:32.451: epoch 129:	0.02650361  	0.19462548  	0.10827965  
2023-05-17 16:07:39.865: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 7.412018]
2023-05-17 16:07:40.013: epoch 130:	0.02656711  	0.19513509  	0.10839055  
2023-05-17 16:07:47.465: [iter 131 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 7.450379]
2023-05-17 16:07:47.626: epoch 131:	0.02663768  	0.19596852  	0.10863861  
2023-05-17 16:07:47.626: Find a better model.
2023-05-17 16:07:55.073: [iter 132 : loss : 0.1165 = 0.0269 + 0.0833 + 0.0063, time: 7.446404]
2023-05-17 16:07:55.225: epoch 132:	0.02660240  	0.19538872  	0.10846394  
2023-05-17 16:08:02.662: [iter 133 : loss : 0.1154 = 0.0257 + 0.0833 + 0.0064, time: 7.436434]
2023-05-17 16:08:02.812: epoch 133:	0.02667296  	0.19602945  	0.10882617  
2023-05-17 16:08:02.812: Find a better model.
2023-05-17 16:08:10.256: [iter 134 : loss : 0.1160 = 0.0263 + 0.0832 + 0.0064, time: 7.442962]
2023-05-17 16:08:10.406: epoch 134:	0.02664473  	0.19560046  	0.10881703  
2023-05-17 16:08:17.865: [iter 135 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 7.457289]
2023-05-17 16:08:18.013: epoch 135:	0.02665885  	0.19582650  	0.10902756  
2023-05-17 16:08:25.481: [iter 136 : loss : 0.1154 = 0.0258 + 0.0832 + 0.0065, time: 7.466813]
2023-05-17 16:08:25.644: epoch 136:	0.02675058  	0.19669977  	0.10913330  
2023-05-17 16:08:25.645: Find a better model.
2023-05-17 16:08:33.058: [iter 137 : loss : 0.1148 = 0.0251 + 0.0831 + 0.0065, time: 7.411903]
2023-05-17 16:08:33.224: epoch 137:	0.02677881  	0.19645506  	0.10917515  
2023-05-17 16:08:40.650: [iter 138 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0065, time: 7.424895]
2023-05-17 16:08:40.797: epoch 138:	0.02667296  	0.19607060  	0.10894418  
2023-05-17 16:08:48.229: [iter 139 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 7.429963]
2023-05-17 16:08:48.379: epoch 139:	0.02669413  	0.19622193  	0.10895438  
2023-05-17 16:08:55.819: [iter 140 : loss : 0.1138 = 0.0243 + 0.0830 + 0.0066, time: 7.438445]
2023-05-17 16:08:55.967: epoch 140:	0.02664473  	0.19541086  	0.10875195  
2023-05-17 16:09:03.447: [iter 141 : loss : 0.1144 = 0.0249 + 0.0829 + 0.0066, time: 7.479813]
2023-05-17 16:09:03.604: epoch 141:	0.02665885  	0.19575399  	0.10905814  
2023-05-17 16:09:10.844: [iter 142 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0066, time: 7.239265]
2023-05-17 16:09:10.992: epoch 142:	0.02663062  	0.19568077  	0.10914746  
2023-05-17 16:09:18.450: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 7.455705]
2023-05-17 16:09:18.600: epoch 143:	0.02664474  	0.19546750  	0.10920794  
2023-05-17 16:09:25.849: [iter 144 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 7.247994]
2023-05-17 16:09:26.013: epoch 144:	0.02656006  	0.19489907  	0.10905107  
2023-05-17 16:09:33.454: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 7.440004]
2023-05-17 16:09:33.611: epoch 145:	0.02660240  	0.19520900  	0.10904606  
2023-05-17 16:09:40.848: [iter 146 : loss : 0.1133 = 0.0237 + 0.0828 + 0.0067, time: 7.235415]
2023-05-17 16:09:40.996: epoch 146:	0.02663768  	0.19525374  	0.10918136  
2023-05-17 16:09:48.449: [iter 147 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0068, time: 7.450423]
2023-05-17 16:09:48.614: epoch 147:	0.02659534  	0.19495890  	0.10908700  
2023-05-17 16:09:56.023: [iter 148 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.407889]
2023-05-17 16:09:56.176: epoch 148:	0.02668002  	0.19561853  	0.10938028  
2023-05-17 16:10:03.439: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 7.261198]
2023-05-17 16:10:03.608: epoch 149:	0.02669414  	0.19563712  	0.10936484  
2023-05-17 16:10:11.014: [iter 150 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.404227]
2023-05-17 16:10:11.164: epoch 150:	0.02667296  	0.19517021  	0.10933296  
2023-05-17 16:10:18.441: [iter 151 : loss : 0.1118 = 0.0223 + 0.0826 + 0.0069, time: 7.275355]
2023-05-17 16:10:18.599: epoch 151:	0.02668707  	0.19529694  	0.10937009  
2023-05-17 16:10:25.839: [iter 152 : loss : 0.1111 = 0.0216 + 0.0826 + 0.0069, time: 7.237185]
2023-05-17 16:10:25.987: epoch 152:	0.02669413  	0.19556153  	0.10931667  
2023-05-17 16:10:33.439: [iter 153 : loss : 0.1101 = 0.0206 + 0.0825 + 0.0069, time: 7.451600]
2023-05-17 16:10:33.592: epoch 153:	0.02670119  	0.19579549  	0.10927955  
2023-05-17 16:10:40.995: [iter 154 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0069, time: 7.400027]
2023-05-17 16:10:41.157: epoch 154:	0.02672942  	0.19599070  	0.10943875  
2023-05-17 16:10:48.590: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 7.431113]
2023-05-17 16:10:48.743: epoch 155:	0.02671530  	0.19540797  	0.10932241  
2023-05-17 16:10:56.227: [iter 156 : loss : 0.1105 = 0.0211 + 0.0824 + 0.0070, time: 7.482665]
2023-05-17 16:10:56.389: epoch 156:	0.02663768  	0.19498500  	0.10927009  
2023-05-17 16:11:03.819: [iter 157 : loss : 0.1104 = 0.0210 + 0.0824 + 0.0070, time: 7.427716]
2023-05-17 16:11:03.969: epoch 157:	0.02665884  	0.19517654  	0.10931480  
2023-05-17 16:11:11.390: [iter 158 : loss : 0.1098 = 0.0203 + 0.0824 + 0.0070, time: 7.419587]
2023-05-17 16:11:11.538: epoch 158:	0.02665885  	0.19544138  	0.10944094  
2023-05-17 16:11:19.003: [iter 159 : loss : 0.1099 = 0.0205 + 0.0823 + 0.0071, time: 7.464223]
2023-05-17 16:11:19.153: epoch 159:	0.02666590  	0.19543244  	0.10939862  
2023-05-17 16:11:26.592: [iter 160 : loss : 0.1096 = 0.0201 + 0.0823 + 0.0071, time: 7.437264]
2023-05-17 16:11:26.744: epoch 160:	0.02668707  	0.19541737  	0.10939585  
2023-05-17 16:11:34.181: [iter 161 : loss : 0.1092 = 0.0198 + 0.0823 + 0.0071, time: 7.434539]
2023-05-17 16:11:34.331: epoch 161:	0.02658123  	0.19469959  	0.10907511  
2023-05-17 16:11:34.331: Early stopping is trigger at epoch: 161
2023-05-17 16:11:34.331: best_result@epoch 136:

2023-05-17 16:11:34.331: 		0.0268      	0.1967      	0.1091      
2023-05-17 16:21:28.141: my pid: 9384
2023-05-17 16:21:28.141: model: model.general_recommender.SGL
2023-05-17 16:21:28.141: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 16:21:28.141: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 16:21:31.644: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 16:21:41.885: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.237772]
2023-05-17 16:21:42.152: epoch 1:	0.00127011  	0.00956133  	0.00471099  
2023-05-17 16:21:42.152: Find a better model.
2023-05-17 16:21:51.269: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.116440]
2023-05-17 16:21:51.454: epoch 2:	0.00258961  	0.01991473  	0.00969435  
2023-05-17 16:21:51.454: Find a better model.
2023-05-17 16:22:01.624: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 10.168887]
2023-05-17 16:22:01.804: epoch 3:	0.00484051  	0.03582956  	0.01700472  
2023-05-17 16:22:01.804: Find a better model.
2023-05-17 16:22:12.035: [iter 4 : loss : 0.7706 = 0.6921 + 0.0786 + 0.0000, time: 10.228824]
2023-05-17 16:22:12.233: epoch 4:	0.00762766  	0.05674843  	0.02736242  
2023-05-17 16:22:12.234: Find a better model.
2023-05-17 16:22:22.362: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 10.127557]
2023-05-17 16:22:22.522: epoch 5:	0.01119815  	0.08253422  	0.03950961  
2023-05-17 16:22:22.522: Find a better model.
2023-05-17 16:22:32.445: [iter 6 : loss : 0.7675 = 0.6884 + 0.0791 + 0.0000, time: 9.921160]
2023-05-17 16:22:32.779: epoch 6:	0.01501568  	0.10931525  	0.05299218  
2023-05-17 16:22:32.779: Find a better model.
2023-05-17 16:22:43.076: [iter 7 : loss : 0.7616 = 0.6817 + 0.0799 + 0.0000, time: 10.292001]
2023-05-17 16:22:43.383: epoch 7:	0.01769006  	0.12832944  	0.06330032  
2023-05-17 16:22:43.383: Find a better model.
2023-05-17 16:22:52.930: [iter 8 : loss : 0.7469 = 0.6652 + 0.0817 + 0.0001, time: 9.545187]
2023-05-17 16:22:53.082: epoch 8:	0.01855800  	0.13587093  	0.06808611  
2023-05-17 16:22:53.082: Find a better model.
2023-05-17 16:23:01.127: [iter 9 : loss : 0.7132 = 0.6277 + 0.0854 + 0.0001, time: 8.042547]
2023-05-17 16:23:01.429: epoch 9:	0.01862151  	0.13663684  	0.06885789  
2023-05-17 16:23:01.429: Find a better model.
2023-05-17 16:23:10.729: [iter 10 : loss : 0.6534 = 0.5623 + 0.0909 + 0.0002, time: 9.298006]
2023-05-17 16:23:10.907: epoch 10:	0.01840276  	0.13558026  	0.06776652  
2023-05-17 16:23:21.491: [iter 11 : loss : 0.5776 = 0.4812 + 0.0961 + 0.0004, time: 10.581035]
2023-05-17 16:23:21.799: epoch 11:	0.01838865  	0.13549143  	0.06758279  
2023-05-17 16:23:31.701: [iter 12 : loss : 0.5080 = 0.4079 + 0.0996 + 0.0005, time: 9.899031]
2023-05-17 16:23:32.212: epoch 12:	0.01848745  	0.13655645  	0.06819857  
2023-05-17 16:23:40.690: [iter 13 : loss : 0.4563 = 0.3543 + 0.1014 + 0.0007, time: 8.472411]
2023-05-17 16:23:40.876: epoch 13:	0.01855801  	0.13720377  	0.06877100  
2023-05-17 16:23:40.876: Find a better model.
2023-05-17 16:23:49.768: [iter 14 : loss : 0.4175 = 0.3143 + 0.1023 + 0.0008, time: 8.890122]
2023-05-17 16:23:49.922: epoch 14:	0.01881204  	0.13932808  	0.06985307  
2023-05-17 16:23:49.922: Find a better model.
2023-05-17 16:23:59.619: [iter 15 : loss : 0.3904 = 0.2867 + 0.1027 + 0.0010, time: 9.694991]
2023-05-17 16:24:00.025: epoch 15:	0.01900256  	0.14036252  	0.07060780  
2023-05-17 16:24:00.025: Find a better model.
2023-05-17 16:24:10.164: [iter 16 : loss : 0.3678 = 0.2639 + 0.1027 + 0.0011, time: 10.136001]
2023-05-17 16:24:10.476: epoch 16:	0.01904490  	0.14068304  	0.07118331  
2023-05-17 16:24:10.476: Find a better model.
2023-05-17 16:24:20.910: [iter 17 : loss : 0.3509 = 0.2472 + 0.1025 + 0.0012, time: 10.432528]
2023-05-17 16:24:21.239: epoch 17:	0.01927071  	0.14222322  	0.07193443  
2023-05-17 16:24:21.239: Find a better model.
2023-05-17 16:24:29.717: [iter 18 : loss : 0.3356 = 0.2320 + 0.1023 + 0.0013, time: 8.477013]
2023-05-17 16:24:30.047: epoch 18:	0.01948947  	0.14358297  	0.07282206  
2023-05-17 16:24:30.048: Find a better model.
2023-05-17 16:24:39.156: [iter 19 : loss : 0.3212 = 0.2179 + 0.1019 + 0.0014, time: 9.096964]
2023-05-17 16:24:39.312: epoch 19:	0.01972939  	0.14529477  	0.07401600  
2023-05-17 16:24:39.312: Find a better model.
2023-05-17 16:24:49.728: [iter 20 : loss : 0.3115 = 0.2085 + 0.1016 + 0.0015, time: 10.414206]
2023-05-17 16:24:50.007: epoch 20:	0.01989170  	0.14677334  	0.07462750  
2023-05-17 16:24:50.007: Find a better model.
2023-05-17 16:25:00.144: [iter 21 : loss : 0.3016 = 0.1990 + 0.1010 + 0.0016, time: 10.135010]
2023-05-17 16:25:00.395: epoch 21:	0.02015985  	0.14867181  	0.07545780  
2023-05-17 16:25:00.395: Find a better model.
2023-05-17 16:25:10.535: [iter 22 : loss : 0.2933 = 0.1909 + 0.1007 + 0.0016, time: 10.137074]
2023-05-17 16:25:10.849: epoch 22:	0.02032214  	0.14983024  	0.07611988  
2023-05-17 16:25:10.849: Find a better model.
2023-05-17 16:25:19.446: [iter 23 : loss : 0.2851 = 0.1830 + 0.1003 + 0.0017, time: 8.596002]
2023-05-17 16:25:19.801: epoch 23:	0.02056911  	0.15146105  	0.07692888  
2023-05-17 16:25:19.801: Find a better model.
2023-05-17 16:25:28.186: [iter 24 : loss : 0.2784 = 0.1768 + 0.0998 + 0.0018, time: 8.382993]
2023-05-17 16:25:28.381: epoch 24:	0.02070318  	0.15207592  	0.07763544  
2023-05-17 16:25:28.382: Find a better model.
2023-05-17 16:25:39.048: [iter 25 : loss : 0.2717 = 0.1704 + 0.0994 + 0.0019, time: 10.659001]
2023-05-17 16:25:39.386: epoch 25:	0.02098544  	0.15406017  	0.07853941  
2023-05-17 16:25:39.387: Find a better model.
2023-05-17 16:25:49.621: [iter 26 : loss : 0.2682 = 0.1673 + 0.0990 + 0.0019, time: 10.231014]
2023-05-17 16:25:49.932: epoch 26:	0.02116892  	0.15523604  	0.07942776  
2023-05-17 16:25:49.932: Find a better model.
2023-05-17 16:25:59.344: [iter 27 : loss : 0.2603 = 0.1598 + 0.0985 + 0.0020, time: 9.410002]
2023-05-17 16:25:59.513: epoch 27:	0.02128888  	0.15610252  	0.07986257  
2023-05-17 16:25:59.514: Find a better model.
2023-05-17 16:26:08.616: [iter 28 : loss : 0.2552 = 0.1550 + 0.0981 + 0.0021, time: 9.101052]
2023-05-17 16:26:08.795: epoch 28:	0.02145118  	0.15738514  	0.08075034  
2023-05-17 16:26:08.796: Find a better model.
2023-05-17 16:26:18.949: [iter 29 : loss : 0.2509 = 0.1510 + 0.0978 + 0.0021, time: 10.151000]
2023-05-17 16:26:19.119: epoch 29:	0.02163466  	0.15861093  	0.08154815  
2023-05-17 16:26:19.119: Find a better model.
2023-05-17 16:26:28.443: [iter 30 : loss : 0.2441 = 0.1446 + 0.0973 + 0.0022, time: 9.321011]
2023-05-17 16:26:28.718: epoch 30:	0.02181107  	0.16022177  	0.08231660  
2023-05-17 16:26:28.719: Find a better model.
2023-05-17 16:26:38.646: [iter 31 : loss : 0.2406 = 0.1414 + 0.0969 + 0.0023, time: 9.916794]
2023-05-17 16:26:38.984: epoch 31:	0.02195220  	0.16094388  	0.08301283  
2023-05-17 16:26:38.984: Find a better model.
2023-05-17 16:26:47.658: [iter 32 : loss : 0.2351 = 0.1361 + 0.0966 + 0.0023, time: 8.673016]
2023-05-17 16:26:47.833: epoch 32:	0.02214978  	0.16227932  	0.08371568  
2023-05-17 16:26:47.833: Find a better model.
2023-05-17 16:26:57.378: [iter 33 : loss : 0.2325 = 0.1339 + 0.0962 + 0.0024, time: 9.534159]
2023-05-17 16:26:57.646: epoch 33:	0.02234736  	0.16389026  	0.08452225  
2023-05-17 16:26:57.646: Find a better model.
2023-05-17 16:27:07.127: [iter 34 : loss : 0.2284 = 0.1301 + 0.0959 + 0.0024, time: 9.480062]
2023-05-17 16:27:07.276: epoch 34:	0.02236853  	0.16412733  	0.08493700  
2023-05-17 16:27:07.276: Find a better model.
2023-05-17 16:27:17.147: [iter 35 : loss : 0.2249 = 0.1269 + 0.0956 + 0.0025, time: 9.867002]
2023-05-17 16:27:17.469: epoch 35:	0.02250259  	0.16506003  	0.08570347  
2023-05-17 16:27:17.470: Find a better model.
2023-05-17 16:27:27.571: [iter 36 : loss : 0.2214 = 0.1237 + 0.0952 + 0.0025, time: 10.096045]
2023-05-17 16:27:27.895: epoch 36:	0.02262256  	0.16599089  	0.08636167  
2023-05-17 16:27:27.895: Find a better model.
2023-05-17 16:27:36.427: [iter 37 : loss : 0.2177 = 0.1202 + 0.0949 + 0.0026, time: 8.530992]
2023-05-17 16:27:36.599: epoch 37:	0.02282014  	0.16778231  	0.08709757  
2023-05-17 16:27:36.600: Find a better model.
2023-05-17 16:27:45.599: [iter 38 : loss : 0.2161 = 0.1189 + 0.0946 + 0.0027, time: 8.997194]
2023-05-17 16:27:45.762: epoch 38:	0.02295421  	0.16883534  	0.08787783  
2023-05-17 16:27:45.762: Find a better model.
2023-05-17 16:27:54.957: [iter 39 : loss : 0.2115 = 0.1145 + 0.0943 + 0.0027, time: 9.193046]
2023-05-17 16:27:55.158: epoch 39:	0.02312357  	0.17000288  	0.08865296  
2023-05-17 16:27:55.159: Find a better model.
2023-05-17 16:28:03.503: [iter 40 : loss : 0.2082 = 0.1115 + 0.0940 + 0.0028, time: 8.339024]
2023-05-17 16:28:03.663: epoch 40:	0.02321531  	0.17076382  	0.08903665  
2023-05-17 16:28:03.663: Find a better model.
2023-05-17 16:28:14.044: [iter 41 : loss : 0.2065 = 0.1100 + 0.0937 + 0.0028, time: 10.379426]
2023-05-17 16:28:14.363: epoch 41:	0.02334233  	0.17161219  	0.08992878  
2023-05-17 16:28:14.364: Find a better model.
2023-05-17 16:28:23.805: [iter 42 : loss : 0.2044 = 0.1081 + 0.0935 + 0.0029, time: 9.440021]
2023-05-17 16:28:24.007: epoch 42:	0.02339172  	0.17206988  	0.09029038  
2023-05-17 16:28:24.007: Find a better model.
2023-05-17 16:28:33.572: [iter 43 : loss : 0.2004 = 0.1043 + 0.0932 + 0.0029, time: 9.562304]
2023-05-17 16:28:33.750: epoch 43:	0.02343406  	0.17212066  	0.09077175  
2023-05-17 16:28:33.750: Find a better model.
2023-05-17 16:28:43.444: [iter 44 : loss : 0.1969 = 0.1011 + 0.0929 + 0.0030, time: 9.692001]
2023-05-17 16:28:43.599: epoch 44:	0.02356107  	0.17271982  	0.09111052  
2023-05-17 16:28:43.599: Find a better model.
2023-05-17 16:28:51.919: [iter 45 : loss : 0.1950 = 0.0993 + 0.0927 + 0.0030, time: 8.319053]
2023-05-17 16:28:52.076: epoch 45:	0.02368809  	0.17327046  	0.09180693  
2023-05-17 16:28:52.076: Find a better model.
2023-05-17 16:29:01.956: [iter 46 : loss : 0.1925 = 0.0971 + 0.0924 + 0.0031, time: 9.877360]
2023-05-17 16:29:02.265: epoch 46:	0.02371632  	0.17391928  	0.09208854  
2023-05-17 16:29:02.265: Find a better model.
2023-05-17 16:29:11.542: [iter 47 : loss : 0.1919 = 0.0966 + 0.0921 + 0.0031, time: 9.274996]
2023-05-17 16:29:11.827: epoch 47:	0.02385745  	0.17508058  	0.09255091  
2023-05-17 16:29:11.827: Find a better model.
2023-05-17 16:29:21.492: [iter 48 : loss : 0.1877 = 0.0926 + 0.0919 + 0.0032, time: 9.662991]
2023-05-17 16:29:21.649: epoch 48:	0.02396329  	0.17567250  	0.09309468  
2023-05-17 16:29:21.649: Find a better model.
2023-05-17 16:29:31.020: [iter 49 : loss : 0.1848 = 0.0899 + 0.0917 + 0.0032, time: 9.369991]
2023-05-17 16:29:31.242: epoch 49:	0.02411853  	0.17759445  	0.09393489  
2023-05-17 16:29:31.242: Find a better model.
2023-05-17 16:29:39.625: [iter 50 : loss : 0.1840 = 0.0893 + 0.0915 + 0.0033, time: 8.382303]
2023-05-17 16:29:40.046: epoch 50:	0.02413264  	0.17770492  	0.09436779  
2023-05-17 16:29:40.046: Find a better model.
2023-05-17 16:29:49.926: [iter 51 : loss : 0.1808 = 0.0862 + 0.0913 + 0.0033, time: 9.877001]
2023-05-17 16:29:50.236: epoch 51:	0.02413264  	0.17761417  	0.09448258  
2023-05-17 16:30:00.498: [iter 52 : loss : 0.1806 = 0.0862 + 0.0911 + 0.0034, time: 10.260047]
2023-05-17 16:30:00.755: epoch 52:	0.02409736  	0.17727521  	0.09462986  
2023-05-17 16:30:09.458: [iter 53 : loss : 0.1789 = 0.0846 + 0.0909 + 0.0034, time: 8.701992]
2023-05-17 16:30:09.671: epoch 53:	0.02428789  	0.17846400  	0.09538855  
2023-05-17 16:30:09.671: Find a better model.
2023-05-17 16:30:19.085: [iter 54 : loss : 0.1766 = 0.0825 + 0.0907 + 0.0035, time: 9.411991]
2023-05-17 16:30:19.247: epoch 54:	0.02430200  	0.17860565  	0.09569276  
2023-05-17 16:30:19.247: Find a better model.
2023-05-17 16:30:29.568: [iter 55 : loss : 0.1747 = 0.0807 + 0.0905 + 0.0035, time: 10.317066]
2023-05-17 16:30:29.896: epoch 55:	0.02435846  	0.17877035  	0.09573480  
2023-05-17 16:30:29.896: Find a better model.
2023-05-17 16:30:39.438: [iter 56 : loss : 0.1728 = 0.0790 + 0.0902 + 0.0035, time: 9.537459]
2023-05-17 16:30:39.708: epoch 56:	0.02433023  	0.17877030  	0.09589849  
2023-05-17 16:30:48.893: [iter 57 : loss : 0.1710 = 0.0773 + 0.0901 + 0.0036, time: 9.182992]
2023-05-17 16:30:49.340: epoch 57:	0.02445019  	0.17949980  	0.09626118  
2023-05-17 16:30:49.340: Find a better model.
2023-05-17 16:30:58.473: [iter 58 : loss : 0.1693 = 0.0757 + 0.0899 + 0.0036, time: 9.124012]
2023-05-17 16:30:58.751: epoch 58:	0.02456309  	0.18052277  	0.09686822  
2023-05-17 16:30:58.751: Find a better model.
2023-05-17 16:31:08.457: [iter 59 : loss : 0.1683 = 0.0749 + 0.0897 + 0.0037, time: 9.703999]
2023-05-17 16:31:08.615: epoch 59:	0.02456309  	0.18022685  	0.09688044  
2023-05-17 16:31:18.786: [iter 60 : loss : 0.1668 = 0.0735 + 0.0896 + 0.0037, time: 10.167001]
2023-05-17 16:31:19.102: epoch 60:	0.02472539  	0.18124771  	0.09726368  
2023-05-17 16:31:19.102: Find a better model.
2023-05-17 16:31:29.224: [iter 61 : loss : 0.1654 = 0.0723 + 0.0894 + 0.0038, time: 10.119427]
2023-05-17 16:31:29.568: epoch 61:	0.02472539  	0.18132794  	0.09758689  
2023-05-17 16:31:29.568: Find a better model.
2023-05-17 16:31:38.864: [iter 62 : loss : 0.1639 = 0.0708 + 0.0892 + 0.0038, time: 9.293991]
2023-05-17 16:31:39.120: epoch 62:	0.02476067  	0.18157165  	0.09792561  
2023-05-17 16:31:39.120: Find a better model.
2023-05-17 16:31:48.236: [iter 63 : loss : 0.1624 = 0.0695 + 0.0891 + 0.0039, time: 9.110002]
2023-05-17 16:31:48.398: epoch 63:	0.02486652  	0.18210396  	0.09831471  
2023-05-17 16:31:48.398: Find a better model.
2023-05-17 16:31:57.408: [iter 64 : loss : 0.1614 = 0.0686 + 0.0889 + 0.0039, time: 9.009015]
2023-05-17 16:31:57.580: epoch 64:	0.02491591  	0.18247022  	0.09852299  
2023-05-17 16:31:57.580: Find a better model.
2023-05-17 16:32:07.382: [iter 65 : loss : 0.1601 = 0.0673 + 0.0888 + 0.0039, time: 9.792116]
2023-05-17 16:32:07.872: epoch 65:	0.02499353  	0.18315668  	0.09888303  
2023-05-17 16:32:07.872: Find a better model.
2023-05-17 16:32:18.163: [iter 66 : loss : 0.1586 = 0.0660 + 0.0886 + 0.0040, time: 10.287001]
2023-05-17 16:32:18.482: epoch 66:	0.02508526  	0.18407847  	0.09937101  
2023-05-17 16:32:18.482: Find a better model.
2023-05-17 16:32:26.977: [iter 67 : loss : 0.1567 = 0.0642 + 0.0885 + 0.0040, time: 8.493006]
2023-05-17 16:32:27.320: epoch 67:	0.02524051  	0.18532355  	0.10005913  
2023-05-17 16:32:27.320: Find a better model.
2023-05-17 16:32:36.318: [iter 68 : loss : 0.1569 = 0.0645 + 0.0883 + 0.0041, time: 8.996003]
2023-05-17 16:32:36.604: epoch 68:	0.02533224  	0.18568857  	0.10039173  
2023-05-17 16:32:36.604: Find a better model.
2023-05-17 16:32:46.658: [iter 69 : loss : 0.1547 = 0.0624 + 0.0882 + 0.0041, time: 10.044014]
2023-05-17 16:32:46.946: epoch 69:	0.02525461  	0.18534587  	0.10051156  
2023-05-17 16:32:57.185: [iter 70 : loss : 0.1530 = 0.0608 + 0.0881 + 0.0042, time: 10.236316]
2023-05-17 16:32:57.444: epoch 70:	0.02530401  	0.18573925  	0.10082649  
2023-05-17 16:32:57.444: Find a better model.
2023-05-17 16:33:07.605: [iter 71 : loss : 0.1515 = 0.0594 + 0.0879 + 0.0042, time: 10.158360]
2023-05-17 16:33:07.935: epoch 71:	0.02530401  	0.18556455  	0.10098530  
2023-05-17 16:33:17.496: [iter 72 : loss : 0.1516 = 0.0595 + 0.0878 + 0.0042, time: 9.560093]
2023-05-17 16:33:17.654: epoch 72:	0.02538163  	0.18637666  	0.10118805  
2023-05-17 16:33:17.654: Find a better model.
2023-05-17 16:33:26.615: [iter 73 : loss : 0.1499 = 0.0580 + 0.0877 + 0.0043, time: 8.959013]
2023-05-17 16:33:26.819: epoch 73:	0.02552276  	0.18752454  	0.10186683  
2023-05-17 16:33:26.819: Find a better model.
2023-05-17 16:33:36.440: [iter 74 : loss : 0.1487 = 0.0567 + 0.0876 + 0.0043, time: 9.619034]
2023-05-17 16:33:36.708: epoch 74:	0.02558627  	0.18792325  	0.10210508  
2023-05-17 16:33:36.708: Find a better model.
2023-05-17 16:33:46.663: [iter 75 : loss : 0.1481 = 0.0562 + 0.0875 + 0.0044, time: 9.953406]
2023-05-17 16:33:46.942: epoch 75:	0.02557921  	0.18778993  	0.10216621  
2023-05-17 16:33:55.893: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 8.949225]
2023-05-17 16:33:56.062: epoch 76:	0.02572034  	0.18841434  	0.10256290  
2023-05-17 16:33:56.062: Find a better model.
2023-05-17 16:34:04.343: [iter 77 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 8.280021]
2023-05-17 16:34:04.500: epoch 77:	0.02567094  	0.18833925  	0.10259467  
2023-05-17 16:34:13.949: [iter 78 : loss : 0.1451 = 0.0535 + 0.0871 + 0.0045, time: 9.445992]
2023-05-17 16:34:14.120: epoch 78:	0.02568505  	0.18837109  	0.10266517  
2023-05-17 16:34:24.872: [iter 79 : loss : 0.1440 = 0.0525 + 0.0870 + 0.0045, time: 10.746046]
2023-05-17 16:34:25.192: epoch 79:	0.02580500  	0.18936419  	0.10312621  
2023-05-17 16:34:25.192: Find a better model.
2023-05-17 16:34:34.933: [iter 80 : loss : 0.1432 = 0.0518 + 0.0869 + 0.0046, time: 9.737992]
2023-05-17 16:34:35.223: epoch 80:	0.02574856  	0.18904178  	0.10287937  
2023-05-17 16:34:43.403: [iter 81 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 8.178026]
2023-05-17 16:34:43.601: epoch 81:	0.02579796  	0.18965514  	0.10327146  
2023-05-17 16:34:43.602: Find a better model.
2023-05-17 16:34:52.993: [iter 82 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 9.387282]
2023-05-17 16:34:53.241: epoch 82:	0.02586146  	0.18996571  	0.10358644  
2023-05-17 16:34:53.241: Find a better model.
2023-05-17 16:35:03.024: [iter 83 : loss : 0.1406 = 0.0493 + 0.0866 + 0.0047, time: 9.782002]
2023-05-17 16:35:03.248: epoch 83:	0.02592497  	0.18997139  	0.10377752  
2023-05-17 16:35:03.248: Find a better model.
2023-05-17 16:35:11.739: [iter 84 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 8.488014]
2023-05-17 16:35:12.003: epoch 84:	0.02593202  	0.19006714  	0.10392991  
2023-05-17 16:35:12.003: Find a better model.
2023-05-17 16:35:22.310: [iter 85 : loss : 0.1394 = 0.0482 + 0.0864 + 0.0048, time: 10.304032]
2023-05-17 16:35:22.611: epoch 85:	0.02596025  	0.19052176  	0.10420071  
2023-05-17 16:35:22.611: Find a better model.
2023-05-17 16:35:30.785: [iter 86 : loss : 0.1397 = 0.0487 + 0.0862 + 0.0048, time: 8.173012]
2023-05-17 16:35:30.969: epoch 86:	0.02587557  	0.18989740  	0.10399977  
2023-05-17 16:35:40.398: [iter 87 : loss : 0.1367 = 0.0457 + 0.0862 + 0.0048, time: 9.426992]
2023-05-17 16:35:40.620: epoch 87:	0.02592496  	0.19007109  	0.10419784  
2023-05-17 16:35:50.882: [iter 88 : loss : 0.1360 = 0.0450 + 0.0861 + 0.0049, time: 10.241998]
2023-05-17 16:35:51.152: epoch 88:	0.02594613  	0.19025424  	0.10431372  
2023-05-17 16:36:00.171: [iter 89 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 9.015991]
2023-05-17 16:36:00.330: epoch 89:	0.02598141  	0.19065334  	0.10452399  
2023-05-17 16:36:00.331: Find a better model.
2023-05-17 16:36:10.316: [iter 90 : loss : 0.1364 = 0.0455 + 0.0859 + 0.0049, time: 9.978011]
2023-05-17 16:36:10.612: epoch 90:	0.02606609  	0.19150190  	0.10484030  
2023-05-17 16:36:10.612: Find a better model.
2023-05-17 16:36:19.509: [iter 91 : loss : 0.1350 = 0.0442 + 0.0858 + 0.0050, time: 8.886123]
2023-05-17 16:36:19.789: epoch 91:	0.02604492  	0.19134632  	0.10494487  
2023-05-17 16:36:29.159: [iter 92 : loss : 0.1341 = 0.0433 + 0.0858 + 0.0050, time: 9.368117]
2023-05-17 16:36:29.317: epoch 92:	0.02593907  	0.19056717  	0.10479157  
2023-05-17 16:36:39.099: [iter 93 : loss : 0.1345 = 0.0438 + 0.0857 + 0.0051, time: 9.781175]
2023-05-17 16:36:39.254: epoch 93:	0.02596024  	0.19115022  	0.10509165  
2023-05-17 16:36:48.987: [iter 94 : loss : 0.1322 = 0.0415 + 0.0856 + 0.0051, time: 9.730002]
2023-05-17 16:36:49.299: epoch 94:	0.02594613  	0.19090508  	0.10493799  
2023-05-17 16:36:59.348: [iter 95 : loss : 0.1314 = 0.0408 + 0.0855 + 0.0051, time: 10.046469]
2023-05-17 16:36:59.665: epoch 95:	0.02597436  	0.19091469  	0.10508257  
2023-05-17 16:37:08.675: [iter 96 : loss : 0.1317 = 0.0411 + 0.0854 + 0.0052, time: 9.008005]
2023-05-17 16:37:08.925: epoch 96:	0.02598847  	0.19113025  	0.10528336  
2023-05-17 16:37:17.390: [iter 97 : loss : 0.1300 = 0.0394 + 0.0853 + 0.0052, time: 8.463002]
2023-05-17 16:37:17.588: epoch 97:	0.02606609  	0.19168857  	0.10554884  
2023-05-17 16:37:17.588: Find a better model.
2023-05-17 16:37:27.317: [iter 98 : loss : 0.1309 = 0.0404 + 0.0853 + 0.0052, time: 9.727031]
2023-05-17 16:37:27.492: epoch 98:	0.02612254  	0.19209322  	0.10575919  
2023-05-17 16:37:27.492: Find a better model.
2023-05-17 16:37:37.125: [iter 99 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0053, time: 9.630992]
2023-05-17 16:37:37.438: epoch 99:	0.02605903  	0.19170101  	0.10552848  
2023-05-17 16:37:47.356: [iter 100 : loss : 0.1289 = 0.0384 + 0.0852 + 0.0053, time: 9.916158]
2023-05-17 16:37:47.550: epoch 100:	0.02612253  	0.19205730  	0.10574368  
2023-05-17 16:37:57.471: [iter 101 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 9.918009]
2023-05-17 16:37:57.663: epoch 101:	0.02612959  	0.19205919  	0.10596811  
2023-05-17 16:38:07.353: [iter 102 : loss : 0.1276 = 0.0372 + 0.0850 + 0.0054, time: 9.686991]
2023-05-17 16:38:07.515: epoch 102:	0.02612959  	0.19211233  	0.10603831  
2023-05-17 16:38:07.515: Find a better model.
2023-05-17 16:38:16.315: [iter 103 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 8.799003]
2023-05-17 16:38:16.474: epoch 103:	0.02615076  	0.19228666  	0.10625457  
2023-05-17 16:38:16.474: Find a better model.
2023-05-17 16:38:26.573: [iter 104 : loss : 0.1279 = 0.0376 + 0.0848 + 0.0055, time: 10.096991]
2023-05-17 16:38:26.900: epoch 104:	0.02620721  	0.19251291  	0.10662188  
2023-05-17 16:38:26.900: Find a better model.
2023-05-17 16:38:36.458: [iter 105 : loss : 0.1270 = 0.0367 + 0.0847 + 0.0055, time: 9.556174]
2023-05-17 16:38:36.637: epoch 105:	0.02622838  	0.19264653  	0.10658330  
2023-05-17 16:38:36.637: Find a better model.
2023-05-17 16:38:46.358: [iter 106 : loss : 0.1265 = 0.0362 + 0.0847 + 0.0055, time: 9.719030]
2023-05-17 16:38:46.527: epoch 106:	0.02623544  	0.19259728  	0.10668939  
2023-05-17 16:38:55.997: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0055, time: 9.467025]
2023-05-17 16:38:56.448: epoch 107:	0.02620016  	0.19250044  	0.10661964  
2023-05-17 16:39:05.220: [iter 108 : loss : 0.1254 = 0.0352 + 0.0846 + 0.0056, time: 8.769002]
2023-05-17 16:39:05.371: epoch 108:	0.02631306  	0.19312552  	0.10690985  
2023-05-17 16:39:05.372: Find a better model.
2023-05-17 16:39:15.655: [iter 109 : loss : 0.1240 = 0.0338 + 0.0845 + 0.0056, time: 10.281085]
2023-05-17 16:39:15.975: epoch 109:	0.02624250  	0.19296503  	0.10697673  
2023-05-17 16:39:25.443: [iter 110 : loss : 0.1235 = 0.0334 + 0.0845 + 0.0057, time: 9.466000]
2023-05-17 16:39:25.820: epoch 110:	0.02629189  	0.19312859  	0.10718377  
2023-05-17 16:39:25.820: Find a better model.
2023-05-17 16:39:35.545: [iter 111 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 9.723991]
2023-05-17 16:39:35.703: epoch 111:	0.02632718  	0.19339527  	0.10722851  
2023-05-17 16:39:35.703: Find a better model.
2023-05-17 16:39:45.904: [iter 112 : loss : 0.1235 = 0.0335 + 0.0843 + 0.0057, time: 10.193976]
2023-05-17 16:39:46.206: epoch 112:	0.02630601  	0.19337450  	0.10741279  
2023-05-17 16:39:55.228: [iter 113 : loss : 0.1231 = 0.0330 + 0.0843 + 0.0058, time: 9.020068]
2023-05-17 16:39:55.394: epoch 113:	0.02639774  	0.19416155  	0.10740148  
2023-05-17 16:39:55.394: Find a better model.
2023-05-17 16:40:05.538: [iter 114 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.139436]
2023-05-17 16:40:05.860: epoch 114:	0.02632012  	0.19335636  	0.10738432  
2023-05-17 16:40:15.115: [iter 115 : loss : 0.1219 = 0.0320 + 0.0842 + 0.0058, time: 9.249498]
2023-05-17 16:40:15.400: epoch 115:	0.02634129  	0.19380206  	0.10749242  
2023-05-17 16:40:24.899: [iter 116 : loss : 0.1213 = 0.0313 + 0.0841 + 0.0058, time: 9.497048]
2023-05-17 16:40:25.059: epoch 116:	0.02639068  	0.19413108  	0.10741822  
2023-05-17 16:40:34.739: [iter 117 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 9.679057]
2023-05-17 16:40:34.910: epoch 117:	0.02640480  	0.19426660  	0.10758226  
2023-05-17 16:40:34.910: Find a better model.
2023-05-17 16:40:43.482: [iter 118 : loss : 0.1209 = 0.0309 + 0.0840 + 0.0059, time: 8.571000]
2023-05-17 16:40:43.638: epoch 118:	0.02646831  	0.19470465  	0.10782118  
2023-05-17 16:40:43.638: Find a better model.
2023-05-17 16:40:53.626: [iter 119 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 9.979486]
2023-05-17 16:40:53.891: epoch 119:	0.02638363  	0.19401503  	0.10768826  
2023-05-17 16:41:02.892: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 8.999047]
2023-05-17 16:41:03.183: epoch 120:	0.02641186  	0.19446059  	0.10799779  
2023-05-17 16:41:12.435: [iter 121 : loss : 0.1201 = 0.0303 + 0.0838 + 0.0060, time: 9.250065]
2023-05-17 16:41:12.591: epoch 121:	0.02644009  	0.19425976  	0.10804715  
2023-05-17 16:41:22.011: [iter 122 : loss : 0.1193 = 0.0294 + 0.0838 + 0.0060, time: 9.418002]
2023-05-17 16:41:22.303: epoch 122:	0.02644714  	0.19428822  	0.10804614  
2023-05-17 16:41:30.578: [iter 123 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0061, time: 8.271196]
2023-05-17 16:41:30.925: epoch 123:	0.02641186  	0.19398370  	0.10804399  
2023-05-17 16:41:40.792: [iter 124 : loss : 0.1182 = 0.0285 + 0.0837 + 0.0061, time: 9.860046]
2023-05-17 16:41:41.186: epoch 124:	0.02640480  	0.19396012  	0.10803414  
2023-05-17 16:41:51.001: [iter 125 : loss : 0.1176 = 0.0278 + 0.0837 + 0.0061, time: 9.806741]
2023-05-17 16:41:51.295: epoch 125:	0.02641186  	0.19371651  	0.10785992  
2023-05-17 16:42:00.281: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 8.984691]
2023-05-17 16:42:00.468: epoch 126:	0.02633424  	0.19296947  	0.10764070  
2023-05-17 16:42:10.032: [iter 127 : loss : 0.1169 = 0.0272 + 0.0836 + 0.0062, time: 9.563003]
2023-05-17 16:42:10.192: epoch 127:	0.02625662  	0.19286269  	0.10753054  
2023-05-17 16:42:20.548: [iter 128 : loss : 0.1181 = 0.0283 + 0.0835 + 0.0062, time: 10.352040]
2023-05-17 16:42:20.870: epoch 128:	0.02624956  	0.19240901  	0.10738037  
2023-05-17 16:42:30.986: [iter 129 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0063, time: 10.113089]
2023-05-17 16:42:31.286: epoch 129:	0.02626368  	0.19258000  	0.10766827  
2023-05-17 16:42:40.795: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 9.507991]
2023-05-17 16:42:40.951: epoch 130:	0.02627073  	0.19226660  	0.10750013  
2023-05-17 16:42:49.113: [iter 131 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 8.159006]
2023-05-17 16:42:49.312: epoch 131:	0.02627779  	0.19217035  	0.10734411  
2023-05-17 16:42:58.421: [iter 132 : loss : 0.1164 = 0.0268 + 0.0833 + 0.0063, time: 9.107992]
2023-05-17 16:42:58.590: epoch 132:	0.02627073  	0.19192740  	0.10740841  
2023-05-17 16:43:09.316: [iter 133 : loss : 0.1150 = 0.0253 + 0.0833 + 0.0064, time: 10.720147]
2023-05-17 16:43:09.654: epoch 133:	0.02630601  	0.19211794  	0.10757233  
2023-05-17 16:43:19.301: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 9.640024]
2023-05-17 16:43:19.593: epoch 134:	0.02632012  	0.19209194  	0.10776668  
2023-05-17 16:43:28.372: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 8.777001]
2023-05-17 16:43:28.612: epoch 135:	0.02620722  	0.19141530  	0.10750219  
2023-05-17 16:43:37.395: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 8.781027]
2023-05-17 16:43:37.570: epoch 136:	0.02624250  	0.19158871  	0.10751228  
2023-05-17 16:43:47.440: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 9.868000]
2023-05-17 16:43:47.641: epoch 137:	0.02630601  	0.19202690  	0.10778743  
2023-05-17 16:43:57.495: [iter 138 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 9.849003]
2023-05-17 16:43:57.750: epoch 138:	0.02629896  	0.19188350  	0.10790580  
2023-05-17 16:44:08.075: [iter 139 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 10.318032]
2023-05-17 16:44:08.403: epoch 139:	0.02627073  	0.19196196  	0.10792278  
2023-05-17 16:44:16.348: [iter 140 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 7.942272]
2023-05-17 16:44:16.513: epoch 140:	0.02629190  	0.19177401  	0.10767555  
2023-05-17 16:44:24.784: [iter 141 : loss : 0.1142 = 0.0246 + 0.0830 + 0.0066, time: 8.269034]
2023-05-17 16:44:24.935: epoch 141:	0.02629896  	0.19167626  	0.10777821  
2023-05-17 16:44:33.272: [iter 142 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0066, time: 8.334027]
2023-05-17 16:44:33.451: epoch 142:	0.02628485  	0.19173832  	0.10787695  
2023-05-17 16:44:41.358: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 7.905145]
2023-05-17 16:44:41.513: epoch 143:	0.02639775  	0.19236578  	0.10823010  
2023-05-17 16:44:41.513: Early stopping is trigger at epoch: 143
2023-05-17 16:44:41.513: best_result@epoch 118:

2023-05-17 16:44:41.513: 		0.0265      	0.1947      	0.1078      
2023-05-17 16:51:27.735: my pid: 7584
2023-05-17 16:51:27.735: model: model.general_recommender.SGL
2023-05-17 16:51:27.735: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 16:51:27.735: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 16:51:31.468: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 16:51:40.800: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.331521]
2023-05-17 16:51:40.953: epoch 1:	0.00158058  	0.01178951  	0.00565702  
2023-05-17 16:51:40.954: Find a better model.
2023-05-17 16:51:50.788: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.832556]
2023-05-17 16:51:50.983: epoch 2:	0.00257550  	0.01908108  	0.00945172  
2023-05-17 16:51:50.984: Find a better model.
2023-05-17 16:52:01.385: [iter 3 : loss : 0.7711 = 0.6926 + 0.0784 + 0.0000, time: 10.400019]
2023-05-17 16:52:01.689: epoch 3:	0.00460060  	0.03566307  	0.01661169  
2023-05-17 16:52:01.689: Find a better model.
2023-05-17 16:52:12.261: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 10.568326]
2023-05-17 16:52:12.557: epoch 4:	0.00731719  	0.05415562  	0.02620524  
2023-05-17 16:52:12.557: Find a better model.
2023-05-17 16:52:22.440: [iter 5 : loss : 0.7698 = 0.6910 + 0.0788 + 0.0000, time: 9.881410]
2023-05-17 16:52:22.625: epoch 5:	0.01102879  	0.08076170  	0.03840692  
2023-05-17 16:52:22.625: Find a better model.
2023-05-17 16:52:32.043: [iter 6 : loss : 0.7678 = 0.6887 + 0.0791 + 0.0000, time: 9.417556]
2023-05-17 16:52:32.217: epoch 6:	0.01491689  	0.10711994  	0.05187467  
2023-05-17 16:52:32.217: Find a better model.
2023-05-17 16:52:41.870: [iter 7 : loss : 0.7624 = 0.6827 + 0.0797 + 0.0000, time: 9.652014]
2023-05-17 16:52:42.040: epoch 7:	0.01745014  	0.12639546  	0.06245107  
2023-05-17 16:52:42.040: Find a better model.
2023-05-17 16:52:52.196: [iter 8 : loss : 0.7491 = 0.6676 + 0.0814 + 0.0001, time: 10.151023]
2023-05-17 16:52:52.567: epoch 8:	0.01870619  	0.13605440  	0.06828735  
2023-05-17 16:52:52.567: Find a better model.
2023-05-17 16:53:02.177: [iter 9 : loss : 0.7179 = 0.6329 + 0.0849 + 0.0001, time: 9.608039]
2023-05-17 16:53:02.468: epoch 9:	0.01889672  	0.13885199  	0.06969090  
2023-05-17 16:53:02.468: Find a better model.
2023-05-17 16:53:11.815: [iter 10 : loss : 0.6609 = 0.5706 + 0.0901 + 0.0002, time: 9.345004]
2023-05-17 16:53:11.973: epoch 10:	0.01876265  	0.13873409  	0.06915664  
2023-05-17 16:53:21.862: [iter 11 : loss : 0.5857 = 0.4899 + 0.0954 + 0.0004, time: 9.888019]
2023-05-17 16:53:22.028: epoch 11:	0.01849450  	0.13657297  	0.06805778  
2023-05-17 16:53:30.363: [iter 12 : loss : 0.5140 = 0.4144 + 0.0991 + 0.0005, time: 8.333026]
2023-05-17 16:53:30.548: epoch 12:	0.01838866  	0.13562897  	0.06813259  
2023-05-17 16:53:40.517: [iter 13 : loss : 0.4605 = 0.3586 + 0.1013 + 0.0007, time: 9.966011]
2023-05-17 16:53:41.012: epoch 13:	0.01848039  	0.13658597  	0.06854194  
2023-05-17 16:53:50.574: [iter 14 : loss : 0.4202 = 0.3171 + 0.1023 + 0.0008, time: 9.558572]
2023-05-17 16:53:50.916: epoch 14:	0.01869208  	0.13840903  	0.06942929  
2023-05-17 16:53:59.787: [iter 15 : loss : 0.3924 = 0.2887 + 0.1028 + 0.0010, time: 8.869013]
2023-05-17 16:53:59.960: epoch 15:	0.01890377  	0.14023969  	0.07043235  
2023-05-17 16:53:59.961: Find a better model.
2023-05-17 16:54:09.765: [iter 16 : loss : 0.3693 = 0.2655 + 0.1028 + 0.0011, time: 9.803014]
2023-05-17 16:54:10.105: epoch 16:	0.01906607  	0.14119704  	0.07114372  
2023-05-17 16:54:10.105: Find a better model.
2023-05-17 16:54:20.268: [iter 17 : loss : 0.3524 = 0.2486 + 0.1026 + 0.0012, time: 10.160325]
2023-05-17 16:54:20.593: epoch 17:	0.01929894  	0.14225148  	0.07199575  
2023-05-17 16:54:20.593: Find a better model.
2023-05-17 16:54:30.640: [iter 18 : loss : 0.3367 = 0.2330 + 0.1024 + 0.0013, time: 10.045162]
2023-05-17 16:54:31.028: epoch 18:	0.01957414  	0.14421827  	0.07293344  
2023-05-17 16:54:31.028: Find a better model.
2023-05-17 16:54:40.970: [iter 19 : loss : 0.3224 = 0.2190 + 0.1020 + 0.0014, time: 9.936996]
2023-05-17 16:54:41.221: epoch 19:	0.01972234  	0.14507528  	0.07369637  
2023-05-17 16:54:41.221: Find a better model.
2023-05-17 16:54:50.644: [iter 20 : loss : 0.3125 = 0.2094 + 0.1016 + 0.0015, time: 9.421763]
2023-05-17 16:54:50.840: epoch 20:	0.01999754  	0.14707416  	0.07462300  
2023-05-17 16:54:50.840: Find a better model.
2023-05-17 16:55:00.115: [iter 21 : loss : 0.3028 = 0.2000 + 0.1012 + 0.0016, time: 9.273041]
2023-05-17 16:55:00.342: epoch 21:	0.02017395  	0.14815460  	0.07535047  
2023-05-17 16:55:00.342: Find a better model.
2023-05-17 16:55:10.664: [iter 22 : loss : 0.2942 = 0.1917 + 0.1008 + 0.0016, time: 10.319011]
2023-05-17 16:55:10.982: epoch 22:	0.02036448  	0.14953482  	0.07616685  
2023-05-17 16:55:10.982: Find a better model.
2023-05-17 16:55:20.820: [iter 23 : loss : 0.2858 = 0.1837 + 0.1004 + 0.0017, time: 9.835251]
2023-05-17 16:55:21.147: epoch 23:	0.02054796  	0.15088245  	0.07699724  
2023-05-17 16:55:21.147: Find a better model.
2023-05-17 16:55:30.581: [iter 24 : loss : 0.2793 = 0.1776 + 0.0999 + 0.0018, time: 9.433002]
2023-05-17 16:55:30.752: epoch 24:	0.02067497  	0.15171331  	0.07766475  
2023-05-17 16:55:30.752: Find a better model.
2023-05-17 16:55:40.189: [iter 25 : loss : 0.2725 = 0.1711 + 0.0995 + 0.0019, time: 9.434015]
2023-05-17 16:55:40.497: epoch 25:	0.02081610  	0.15274060  	0.07837565  
2023-05-17 16:55:40.498: Find a better model.
2023-05-17 16:55:49.936: [iter 26 : loss : 0.2688 = 0.1679 + 0.0990 + 0.0019, time: 9.424015]
2023-05-17 16:55:50.099: epoch 26:	0.02103485  	0.15440923  	0.07930904  
2023-05-17 16:55:50.099: Find a better model.
2023-05-17 16:56:00.215: [iter 27 : loss : 0.2610 = 0.1604 + 0.0986 + 0.0020, time: 10.114967]
2023-05-17 16:56:00.548: epoch 27:	0.02126772  	0.15589200  	0.08007260  
2023-05-17 16:56:00.548: Find a better model.
2023-05-17 16:56:10.744: [iter 28 : loss : 0.2561 = 0.1558 + 0.0982 + 0.0021, time: 10.194022]
2023-05-17 16:56:11.053: epoch 28:	0.02142297  	0.15742785  	0.08087038  
2023-05-17 16:56:11.053: Find a better model.
2023-05-17 16:56:21.160: [iter 29 : loss : 0.2517 = 0.1517 + 0.0978 + 0.0021, time: 10.105509]
2023-05-17 16:56:21.374: epoch 29:	0.02164877  	0.15874048  	0.08181161  
2023-05-17 16:56:21.374: Find a better model.
2023-05-17 16:56:30.584: [iter 30 : loss : 0.2449 = 0.1452 + 0.0974 + 0.0022, time: 9.207000]
2023-05-17 16:56:30.760: epoch 30:	0.02183224  	0.16015297  	0.08265676  
2023-05-17 16:56:30.760: Find a better model.
2023-05-17 16:56:39.540: [iter 31 : loss : 0.2415 = 0.1422 + 0.0970 + 0.0023, time: 8.779201]
2023-05-17 16:56:39.699: epoch 31:	0.02202276  	0.16168901  	0.08352745  
2023-05-17 16:56:39.699: Find a better model.
2023-05-17 16:56:49.533: [iter 32 : loss : 0.2358 = 0.1368 + 0.0967 + 0.0023, time: 9.827017]
2023-05-17 16:56:49.962: epoch 32:	0.02217095  	0.16284877  	0.08409376  
2023-05-17 16:56:49.962: Find a better model.
2023-05-17 16:57:00.047: [iter 33 : loss : 0.2334 = 0.1348 + 0.0963 + 0.0024, time: 10.082027]
2023-05-17 16:57:00.355: epoch 33:	0.02220623  	0.16373456  	0.08481216  
2023-05-17 16:57:00.355: Find a better model.
2023-05-17 16:57:09.748: [iter 34 : loss : 0.2291 = 0.1307 + 0.0959 + 0.0024, time: 9.391105]
2023-05-17 16:57:09.925: epoch 34:	0.02241086  	0.16481359  	0.08569480  
2023-05-17 16:57:09.925: Find a better model.
2023-05-17 16:57:19.449: [iter 35 : loss : 0.2255 = 0.1274 + 0.0956 + 0.0025, time: 9.522991]
2023-05-17 16:57:19.694: epoch 35:	0.02253082  	0.16545321  	0.08626982  
2023-05-17 16:57:19.695: Find a better model.
2023-05-17 16:57:28.436: [iter 36 : loss : 0.2219 = 0.1241 + 0.0953 + 0.0025, time: 8.738650]
2023-05-17 16:57:28.833: epoch 36:	0.02260844  	0.16576441  	0.08690157  
2023-05-17 16:57:28.833: Find a better model.
2023-05-17 16:57:38.600: [iter 37 : loss : 0.2181 = 0.1206 + 0.0949 + 0.0026, time: 9.762003]
2023-05-17 16:57:38.908: epoch 37:	0.02279897  	0.16747458  	0.08775664  
2023-05-17 16:57:38.908: Find a better model.
2023-05-17 16:57:48.206: [iter 38 : loss : 0.2165 = 0.1193 + 0.0946 + 0.0027, time: 9.295022]
2023-05-17 16:57:48.462: epoch 38:	0.02296832  	0.16861066  	0.08856183  
2023-05-17 16:57:48.462: Find a better model.
2023-05-17 16:57:57.710: [iter 39 : loss : 0.2121 = 0.1150 + 0.0944 + 0.0027, time: 9.246004]
2023-05-17 16:57:57.874: epoch 39:	0.02311651  	0.16970788  	0.08916395  
2023-05-17 16:57:57.874: Find a better model.
2023-05-17 16:58:07.339: [iter 40 : loss : 0.2088 = 0.1120 + 0.0941 + 0.0028, time: 9.462991]
2023-05-17 16:58:07.569: epoch 40:	0.02328587  	0.17124182  	0.08986524  
2023-05-17 16:58:07.569: Find a better model.
2023-05-17 16:58:17.107: [iter 41 : loss : 0.2071 = 0.1105 + 0.0938 + 0.0028, time: 9.534991]
2023-05-17 16:58:17.427: epoch 41:	0.02341994  	0.17177820  	0.09033313  
2023-05-17 16:58:17.428: Find a better model.
2023-05-17 16:58:27.413: [iter 42 : loss : 0.2052 = 0.1088 + 0.0935 + 0.0029, time: 9.982019]
2023-05-17 16:58:27.726: epoch 42:	0.02357518  	0.17343618  	0.09095003  
2023-05-17 16:58:27.726: Find a better model.
2023-05-17 16:58:36.905: [iter 43 : loss : 0.2009 = 0.1048 + 0.0932 + 0.0029, time: 9.177991]
2023-05-17 16:58:37.059: epoch 43:	0.02361047  	0.17360763  	0.09121344  
2023-05-17 16:58:37.059: Find a better model.
2023-05-17 16:58:45.750: [iter 44 : loss : 0.1974 = 0.1016 + 0.0929 + 0.0030, time: 8.690007]
2023-05-17 16:58:45.935: epoch 44:	0.02365281  	0.17415883  	0.09163117  
2023-05-17 16:58:45.935: Find a better model.
2023-05-17 16:58:55.816: [iter 45 : loss : 0.1955 = 0.0998 + 0.0927 + 0.0030, time: 9.879999]
2023-05-17 16:58:56.003: epoch 45:	0.02380805  	0.17483373  	0.09214494  
2023-05-17 16:58:56.003: Find a better model.
2023-05-17 16:59:06.332: [iter 46 : loss : 0.1929 = 0.0974 + 0.0924 + 0.0031, time: 10.325012]
2023-05-17 16:59:06.657: epoch 46:	0.02385039  	0.17527843  	0.09262969  
2023-05-17 16:59:06.658: Find a better model.
2023-05-17 16:59:16.415: [iter 47 : loss : 0.1923 = 0.0969 + 0.0922 + 0.0031, time: 9.753067]
2023-05-17 16:59:16.836: epoch 47:	0.02390684  	0.17547774  	0.09294958  
2023-05-17 16:59:16.836: Find a better model.
2023-05-17 16:59:25.877: [iter 48 : loss : 0.1882 = 0.0930 + 0.0920 + 0.0032, time: 9.039003]
2023-05-17 16:59:26.137: epoch 48:	0.02401974  	0.17642754  	0.09358913  
2023-05-17 16:59:26.137: Find a better model.
2023-05-17 16:59:35.438: [iter 49 : loss : 0.1852 = 0.0902 + 0.0918 + 0.0032, time: 9.300004]
2023-05-17 16:59:35.710: epoch 49:	0.02406914  	0.17681314  	0.09390319  
2023-05-17 16:59:35.711: Find a better model.
2023-05-17 16:59:45.713: [iter 50 : loss : 0.1843 = 0.0896 + 0.0915 + 0.0033, time: 10.000991]
2023-05-17 16:59:45.873: epoch 50:	0.02416087  	0.17755967  	0.09437043  
2023-05-17 16:59:45.873: Find a better model.
2023-05-17 16:59:55.940: [iter 51 : loss : 0.1813 = 0.0867 + 0.0913 + 0.0033, time: 10.064003]
2023-05-17 16:59:56.235: epoch 51:	0.02422437  	0.17756109  	0.09476323  
2023-05-17 16:59:56.235: Find a better model.
2023-05-17 17:00:06.442: [iter 52 : loss : 0.1812 = 0.0867 + 0.0911 + 0.0034, time: 10.201157]
2023-05-17 17:00:06.766: epoch 52:	0.02427377  	0.17785725  	0.09503505  
2023-05-17 17:00:06.766: Find a better model.
2023-05-17 17:00:15.729: [iter 53 : loss : 0.1790 = 0.0848 + 0.0909 + 0.0034, time: 8.960992]
2023-05-17 17:00:15.893: epoch 53:	0.02433022  	0.17846479  	0.09551223  
2023-05-17 17:00:15.894: Find a better model.
2023-05-17 17:00:25.064: [iter 54 : loss : 0.1771 = 0.0829 + 0.0907 + 0.0035, time: 9.167712]
2023-05-17 17:00:25.236: epoch 54:	0.02438667  	0.17871627  	0.09574067  
2023-05-17 17:00:25.236: Find a better model.
2023-05-17 17:00:34.304: [iter 55 : loss : 0.1748 = 0.0808 + 0.0905 + 0.0035, time: 9.065085]
2023-05-17 17:00:34.463: epoch 55:	0.02442900  	0.17932941  	0.09602568  
2023-05-17 17:00:34.463: Find a better model.
2023-05-17 17:00:43.079: [iter 56 : loss : 0.1733 = 0.0794 + 0.0903 + 0.0035, time: 8.613084]
2023-05-17 17:00:43.338: epoch 56:	0.02445723  	0.17955051  	0.09642427  
2023-05-17 17:00:43.338: Find a better model.
2023-05-17 17:00:53.851: [iter 57 : loss : 0.1717 = 0.0780 + 0.0902 + 0.0036, time: 10.511040]
2023-05-17 17:00:54.185: epoch 57:	0.02461247  	0.18073985  	0.09684712  
2023-05-17 17:00:54.185: Find a better model.
2023-05-17 17:01:02.428: [iter 58 : loss : 0.1695 = 0.0759 + 0.0900 + 0.0036, time: 8.240578]
2023-05-17 17:01:02.716: epoch 58:	0.02463364  	0.18125921  	0.09732161  
2023-05-17 17:01:02.716: Find a better model.
2023-05-17 17:01:11.706: [iter 59 : loss : 0.1686 = 0.0752 + 0.0897 + 0.0037, time: 8.989674]
2023-05-17 17:01:11.879: epoch 59:	0.02478182  	0.18235153  	0.09777136  
2023-05-17 17:01:11.879: Find a better model.
2023-05-17 17:01:21.077: [iter 60 : loss : 0.1672 = 0.0739 + 0.0896 + 0.0037, time: 9.196004]
2023-05-17 17:01:21.327: epoch 60:	0.02483827  	0.18296617  	0.09820759  
2023-05-17 17:01:21.328: Find a better model.
2023-05-17 17:01:30.088: [iter 61 : loss : 0.1655 = 0.0723 + 0.0894 + 0.0038, time: 8.748006]
2023-05-17 17:01:30.511: epoch 61:	0.02485239  	0.18309593  	0.09860051  
2023-05-17 17:01:30.511: Find a better model.
2023-05-17 17:01:40.302: [iter 62 : loss : 0.1642 = 0.0711 + 0.0893 + 0.0038, time: 9.786038]
2023-05-17 17:01:40.598: epoch 62:	0.02490884  	0.18329884  	0.09885340  
2023-05-17 17:01:40.598: Find a better model.
2023-05-17 17:01:50.048: [iter 63 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0039, time: 9.447033]
2023-05-17 17:01:50.318: epoch 63:	0.02499353  	0.18392025  	0.09948969  
2023-05-17 17:01:50.318: Find a better model.
2023-05-17 17:01:59.638: [iter 64 : loss : 0.1619 = 0.0690 + 0.0889 + 0.0039, time: 9.319005]
2023-05-17 17:01:59.796: epoch 64:	0.02502881  	0.18423113  	0.09973434  
2023-05-17 17:01:59.796: Find a better model.
2023-05-17 17:02:09.728: [iter 65 : loss : 0.1605 = 0.0678 + 0.0888 + 0.0039, time: 9.927991]
2023-05-17 17:02:09.898: epoch 65:	0.02502880  	0.18406130  	0.09993702  
2023-05-17 17:02:18.109: [iter 66 : loss : 0.1587 = 0.0661 + 0.0887 + 0.0040, time: 8.210027]
2023-05-17 17:02:18.274: epoch 66:	0.02496529  	0.18388532  	0.09996586  
2023-05-17 17:02:28.152: [iter 67 : loss : 0.1571 = 0.0646 + 0.0885 + 0.0040, time: 9.873518]
2023-05-17 17:02:28.713: epoch 67:	0.02502175  	0.18454015  	0.10037186  
2023-05-17 17:02:28.713: Find a better model.
2023-05-17 17:02:37.790: [iter 68 : loss : 0.1570 = 0.0646 + 0.0883 + 0.0041, time: 9.066503]
2023-05-17 17:02:38.060: epoch 68:	0.02500763  	0.18428147  	0.10036952  
2023-05-17 17:02:47.161: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 9.097992]
2023-05-17 17:02:47.355: epoch 69:	0.02502880  	0.18452021  	0.10065429  
2023-05-17 17:02:56.858: [iter 70 : loss : 0.1531 = 0.0609 + 0.0881 + 0.0042, time: 9.502129]
2023-05-17 17:02:57.038: epoch 70:	0.02507113  	0.18487048  	0.10064255  
2023-05-17 17:02:57.038: Find a better model.
2023-05-17 17:03:05.256: [iter 71 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 8.216975]
2023-05-17 17:03:05.531: epoch 71:	0.02515581  	0.18535873  	0.10115542  
2023-05-17 17:03:05.531: Find a better model.
2023-05-17 17:03:15.341: [iter 72 : loss : 0.1517 = 0.0596 + 0.0879 + 0.0042, time: 9.800021]
2023-05-17 17:03:15.696: epoch 72:	0.02516286  	0.18541443  	0.10129707  
2023-05-17 17:03:15.696: Find a better model.
2023-05-17 17:03:25.603: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 9.904690]
2023-05-17 17:03:25.919: epoch 73:	0.02524754  	0.18587132  	0.10159795  
2023-05-17 17:03:25.919: Find a better model.
2023-05-17 17:03:34.778: [iter 74 : loss : 0.1490 = 0.0570 + 0.0876 + 0.0043, time: 8.857991]
2023-05-17 17:03:34.952: epoch 74:	0.02526871  	0.18580024  	0.10179044  
2023-05-17 17:03:44.772: [iter 75 : loss : 0.1483 = 0.0565 + 0.0875 + 0.0044, time: 9.818003]
2023-05-17 17:03:44.929: epoch 75:	0.02532516  	0.18634364  	0.10217325  
2023-05-17 17:03:44.929: Find a better model.
2023-05-17 17:03:55.296: [iter 76 : loss : 0.1472 = 0.0554 + 0.0873 + 0.0044, time: 10.365273]
2023-05-17 17:03:55.610: epoch 76:	0.02540279  	0.18715529  	0.10245419  
2023-05-17 17:03:55.610: Find a better model.
2023-05-17 17:04:05.690: [iter 77 : loss : 0.1464 = 0.0547 + 0.0872 + 0.0044, time: 10.074024]
2023-05-17 17:04:05.986: epoch 77:	0.02539573  	0.18693490  	0.10254198  
2023-05-17 17:04:14.697: [iter 78 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0045, time: 8.710018]
2023-05-17 17:04:14.857: epoch 78:	0.02548747  	0.18785389  	0.10287862  
2023-05-17 17:04:14.858: Find a better model.
2023-05-17 17:04:22.454: [iter 79 : loss : 0.1442 = 0.0526 + 0.0870 + 0.0045, time: 7.595394]
2023-05-17 17:04:22.609: epoch 79:	0.02545219  	0.18734978  	0.10285661  
2023-05-17 17:04:30.543: [iter 80 : loss : 0.1435 = 0.0520 + 0.0869 + 0.0046, time: 7.932133]
2023-05-17 17:04:30.699: epoch 80:	0.02549453  	0.18768226  	0.10299381  
2023-05-17 17:04:39.565: [iter 81 : loss : 0.1431 = 0.0517 + 0.0868 + 0.0046, time: 8.863316]
2023-05-17 17:04:39.817: epoch 81:	0.02552981  	0.18798235  	0.10319161  
2023-05-17 17:04:39.817: Find a better model.
2023-05-17 17:04:48.021: [iter 82 : loss : 0.1418 = 0.0505 + 0.0867 + 0.0046, time: 8.201154]
2023-05-17 17:04:48.187: epoch 82:	0.02559332  	0.18858702  	0.10362963  
2023-05-17 17:04:48.187: Find a better model.
2023-05-17 17:04:56.279: [iter 83 : loss : 0.1409 = 0.0496 + 0.0866 + 0.0047, time: 8.090549]
2023-05-17 17:04:56.471: epoch 83:	0.02562155  	0.18877934  	0.10392459  
2023-05-17 17:04:56.471: Find a better model.
2023-05-17 17:05:05.307: [iter 84 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.834004]
2023-05-17 17:05:05.575: epoch 84:	0.02568505  	0.18907359  	0.10421778  
2023-05-17 17:05:05.575: Find a better model.
2023-05-17 17:05:13.931: [iter 85 : loss : 0.1397 = 0.0485 + 0.0864 + 0.0048, time: 8.354035]
2023-05-17 17:05:14.090: epoch 85:	0.02580501  	0.19017585  	0.10471795  
2023-05-17 17:05:14.091: Find a better model.
2023-05-17 17:05:22.206: [iter 86 : loss : 0.1398 = 0.0488 + 0.0862 + 0.0048, time: 8.112993]
2023-05-17 17:05:22.423: epoch 86:	0.02581913  	0.19034889  	0.10483085  
2023-05-17 17:05:22.423: Find a better model.
2023-05-17 17:05:30.194: [iter 87 : loss : 0.1369 = 0.0459 + 0.0862 + 0.0048, time: 7.768476]
2023-05-17 17:05:30.461: epoch 87:	0.02588264  	0.19075617  	0.10514112  
2023-05-17 17:05:30.461: Find a better model.
2023-05-17 17:05:38.523: [iter 88 : loss : 0.1362 = 0.0452 + 0.0861 + 0.0049, time: 8.060003]
2023-05-17 17:05:38.681: epoch 88:	0.02584029  	0.19054665  	0.10513867  
2023-05-17 17:05:46.719: [iter 89 : loss : 0.1360 = 0.0450 + 0.0860 + 0.0049, time: 8.036029]
2023-05-17 17:05:46.882: epoch 89:	0.02588263  	0.19071455  	0.10536682  
2023-05-17 17:05:54.809: [iter 90 : loss : 0.1367 = 0.0458 + 0.0860 + 0.0049, time: 7.926305]
2023-05-17 17:05:54.967: epoch 90:	0.02594614  	0.19135533  	0.10569243  
2023-05-17 17:05:54.967: Find a better model.
2023-05-17 17:06:02.898: [iter 91 : loss : 0.1349 = 0.0441 + 0.0858 + 0.0050, time: 7.930177]
2023-05-17 17:06:03.055: epoch 91:	0.02592498  	0.19153625  	0.10583610  
2023-05-17 17:06:03.055: Find a better model.
2023-05-17 17:06:12.132: [iter 92 : loss : 0.1342 = 0.0434 + 0.0858 + 0.0050, time: 9.073991]
2023-05-17 17:06:12.408: epoch 92:	0.02595320  	0.19183159  	0.10599005  
2023-05-17 17:06:12.408: Find a better model.
2023-05-17 17:06:20.647: [iter 93 : loss : 0.1345 = 0.0438 + 0.0857 + 0.0051, time: 8.238013]
2023-05-17 17:06:20.810: epoch 93:	0.02598142  	0.19213602  	0.10597579  
2023-05-17 17:06:20.810: Find a better model.
2023-05-17 17:06:28.854: [iter 94 : loss : 0.1325 = 0.0418 + 0.0856 + 0.0051, time: 8.040993]
2023-05-17 17:06:29.018: epoch 94:	0.02596025  	0.19191746  	0.10600874  
2023-05-17 17:06:37.774: [iter 95 : loss : 0.1316 = 0.0410 + 0.0855 + 0.0051, time: 8.753023]
2023-05-17 17:06:38.034: epoch 95:	0.02596731  	0.19182871  	0.10617258  
2023-05-17 17:06:46.243: [iter 96 : loss : 0.1316 = 0.0410 + 0.0854 + 0.0052, time: 8.208328]
2023-05-17 17:06:46.409: epoch 96:	0.02598848  	0.19188309  	0.10639971  
2023-05-17 17:06:54.530: [iter 97 : loss : 0.1302 = 0.0397 + 0.0853 + 0.0052, time: 8.118245]
2023-05-17 17:06:54.693: epoch 97:	0.02603787  	0.19241601  	0.10644950  
2023-05-17 17:06:54.693: Find a better model.
2023-05-17 17:07:02.249: [iter 98 : loss : 0.1314 = 0.0408 + 0.0853 + 0.0052, time: 7.554996]
2023-05-17 17:07:02.405: epoch 98:	0.02608727  	0.19294384  	0.10665882  
2023-05-17 17:07:02.405: Find a better model.
2023-05-17 17:07:10.293: [iter 99 : loss : 0.1300 = 0.0395 + 0.0852 + 0.0053, time: 7.886993]
2023-05-17 17:07:10.452: epoch 99:	0.02605200  	0.19274744  	0.10678108  
2023-05-17 17:07:19.137: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 8.681047]
2023-05-17 17:07:19.414: epoch 100:	0.02605200  	0.19266196  	0.10679407  
2023-05-17 17:07:27.597: [iter 101 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 8.181046]
2023-05-17 17:07:27.764: epoch 101:	0.02617196  	0.19337700  	0.10699148  
2023-05-17 17:07:27.764: Find a better model.
2023-05-17 17:07:35.919: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 8.153132]
2023-05-17 17:07:36.080: epoch 102:	0.02620724  	0.19365676  	0.10722828  
2023-05-17 17:07:36.080: Find a better model.
2023-05-17 17:07:44.787: [iter 103 : loss : 0.1273 = 0.0369 + 0.0849 + 0.0054, time: 8.704012]
2023-05-17 17:07:45.060: epoch 103:	0.02616490  	0.19317454  	0.10709108  
2023-05-17 17:07:53.423: [iter 104 : loss : 0.1281 = 0.0378 + 0.0848 + 0.0055, time: 8.360931]
2023-05-17 17:07:53.583: epoch 104:	0.02620724  	0.19353288  	0.10741629  
2023-05-17 17:08:01.748: [iter 105 : loss : 0.1272 = 0.0369 + 0.0848 + 0.0055, time: 8.164017]
2023-05-17 17:08:01.910: epoch 105:	0.02630603  	0.19433980  	0.10747889  
2023-05-17 17:08:01.910: Find a better model.
2023-05-17 17:08:09.544: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 7.633225]
2023-05-17 17:08:09.702: epoch 106:	0.02635543  	0.19447401  	0.10765618  
2023-05-17 17:08:09.702: Find a better model.
2023-05-17 17:08:17.659: [iter 107 : loss : 0.1259 = 0.0357 + 0.0847 + 0.0056, time: 7.954993]
2023-05-17 17:08:17.816: epoch 107:	0.02636249  	0.19442044  	0.10769671  
2023-05-17 17:08:25.948: [iter 108 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0056, time: 8.130009]
2023-05-17 17:08:26.215: epoch 108:	0.02628487  	0.19375791  	0.10765372  
2023-05-17 17:08:34.332: [iter 109 : loss : 0.1241 = 0.0339 + 0.0845 + 0.0056, time: 8.115062]
2023-05-17 17:08:34.481: epoch 109:	0.02630604  	0.19382612  	0.10801761  
2023-05-17 17:08:42.615: [iter 110 : loss : 0.1239 = 0.0337 + 0.0845 + 0.0057, time: 8.132997]
2023-05-17 17:08:42.801: epoch 110:	0.02629898  	0.19376291  	0.10806827  
2023-05-17 17:08:51.468: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 8.660027]
2023-05-17 17:08:51.734: epoch 111:	0.02632721  	0.19396798  	0.10832985  
2023-05-17 17:09:00.039: [iter 112 : loss : 0.1232 = 0.0331 + 0.0843 + 0.0057, time: 8.304002]
2023-05-17 17:09:00.187: epoch 112:	0.02644716  	0.19469664  	0.10851216  
2023-05-17 17:09:00.187: Find a better model.
2023-05-17 17:09:08.303: [iter 113 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0058, time: 8.114349]
2023-05-17 17:09:08.464: epoch 113:	0.02651067  	0.19511735  	0.10885549  
2023-05-17 17:09:08.464: Find a better model.
2023-05-17 17:09:16.362: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 7.896026]
2023-05-17 17:09:16.605: epoch 114:	0.02647539  	0.19480161  	0.10882078  
2023-05-17 17:09:24.447: [iter 115 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 7.840993]
2023-05-17 17:09:24.606: epoch 115:	0.02648245  	0.19476226  	0.10881069  
2023-05-17 17:09:32.625: [iter 116 : loss : 0.1213 = 0.0313 + 0.0842 + 0.0059, time: 8.017992]
2023-05-17 17:09:32.778: epoch 116:	0.02651773  	0.19503406  	0.10873771  
2023-05-17 17:09:40.658: [iter 117 : loss : 0.1212 = 0.0312 + 0.0841 + 0.0059, time: 7.878006]
2023-05-17 17:09:40.814: epoch 117:	0.02649656  	0.19504654  	0.10882271  
2023-05-17 17:09:48.833: [iter 118 : loss : 0.1210 = 0.0311 + 0.0840 + 0.0059, time: 8.017003]
2023-05-17 17:09:49.055: epoch 118:	0.02644717  	0.19448814  	0.10884672  
2023-05-17 17:09:58.014: [iter 119 : loss : 0.1201 = 0.0301 + 0.0840 + 0.0060, time: 8.952025]
2023-05-17 17:09:58.280: epoch 119:	0.02646127  	0.19466437  	0.10878626  
2023-05-17 17:10:06.426: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 8.145840]
2023-05-17 17:10:06.593: epoch 120:	0.02653890  	0.19506365  	0.10899062  
2023-05-17 17:10:14.778: [iter 121 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 8.184005]
2023-05-17 17:10:14.927: epoch 121:	0.02653184  	0.19541378  	0.10909477  
2023-05-17 17:10:14.927: Find a better model.
2023-05-17 17:10:23.566: [iter 122 : loss : 0.1194 = 0.0295 + 0.0838 + 0.0060, time: 8.637036]
2023-05-17 17:10:23.742: epoch 122:	0.02653184  	0.19559416  	0.10928598  
2023-05-17 17:10:23.742: Find a better model.
2023-05-17 17:10:31.827: [iter 123 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0061, time: 8.083009]
2023-05-17 17:10:31.990: epoch 123:	0.02646833  	0.19489880  	0.10922379  
2023-05-17 17:10:40.228: [iter 124 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 8.237024]
2023-05-17 17:10:40.382: epoch 124:	0.02647539  	0.19515865  	0.10935403  
2023-05-17 17:10:48.414: [iter 125 : loss : 0.1179 = 0.0281 + 0.0837 + 0.0061, time: 8.031016]
2023-05-17 17:10:48.571: epoch 125:	0.02656007  	0.19561549  	0.10943116  
2023-05-17 17:10:48.572: Find a better model.
2023-05-17 17:10:56.404: [iter 126 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0062, time: 7.831016]
2023-05-17 17:10:56.560: epoch 126:	0.02655301  	0.19567814  	0.10941903  
2023-05-17 17:10:56.560: Find a better model.
2023-05-17 17:11:05.464: [iter 127 : loss : 0.1170 = 0.0273 + 0.0836 + 0.0062, time: 8.897109]
2023-05-17 17:11:05.728: epoch 127:	0.02650362  	0.19556282  	0.10936867  
2023-05-17 17:11:14.006: [iter 128 : loss : 0.1183 = 0.0285 + 0.0835 + 0.0062, time: 8.277023]
2023-05-17 17:11:14.172: epoch 128:	0.02652479  	0.19566588  	0.10966896  
2023-05-17 17:11:22.356: [iter 129 : loss : 0.1171 = 0.0274 + 0.0835 + 0.0063, time: 8.181992]
2023-05-17 17:11:22.519: epoch 129:	0.02652478  	0.19557856  	0.10944927  
2023-05-17 17:11:31.151: [iter 130 : loss : 0.1171 = 0.0274 + 0.0834 + 0.0063, time: 8.630040]
2023-05-17 17:11:31.331: epoch 130:	0.02658124  	0.19579291  	0.10946468  
2023-05-17 17:11:31.332: Find a better model.
2023-05-17 17:11:39.382: [iter 131 : loss : 0.1164 = 0.0266 + 0.0834 + 0.0063, time: 8.049011]
2023-05-17 17:11:39.543: epoch 131:	0.02659535  	0.19607581  	0.10964853  
2023-05-17 17:11:39.543: Find a better model.
2023-05-17 17:11:47.810: [iter 132 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 8.266003]
2023-05-17 17:11:47.960: epoch 132:	0.02656007  	0.19564743  	0.10950577  
2023-05-17 17:11:55.803: [iter 133 : loss : 0.1154 = 0.0257 + 0.0833 + 0.0064, time: 7.841112]
2023-05-17 17:11:55.956: epoch 133:	0.02657418  	0.19551910  	0.10956930  
2023-05-17 17:12:03.764: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 7.807004]
2023-05-17 17:12:03.916: epoch 134:	0.02660946  	0.19577605  	0.10959979  
2023-05-17 17:12:12.921: [iter 135 : loss : 0.1158 = 0.0261 + 0.0832 + 0.0064, time: 9.000012]
2023-05-17 17:12:13.185: epoch 135:	0.02651067  	0.19512253  	0.10951452  
2023-05-17 17:12:21.388: [iter 136 : loss : 0.1154 = 0.0257 + 0.0832 + 0.0065, time: 8.202002]
2023-05-17 17:12:21.558: epoch 136:	0.02646833  	0.19516230  	0.10952918  
2023-05-17 17:12:29.572: [iter 137 : loss : 0.1150 = 0.0253 + 0.0831 + 0.0065, time: 8.013006]
2023-05-17 17:12:29.722: epoch 137:	0.02648244  	0.19494008  	0.10949039  
2023-05-17 17:12:38.373: [iter 138 : loss : 0.1147 = 0.0250 + 0.0831 + 0.0065, time: 8.649034]
2023-05-17 17:12:38.619: epoch 138:	0.02639071  	0.19438395  	0.10933197  
2023-05-17 17:12:46.556: [iter 139 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0066, time: 7.936049]
2023-05-17 17:12:46.721: epoch 139:	0.02640483  	0.19456090  	0.10962778  
2023-05-17 17:12:55.007: [iter 140 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 8.283992]
2023-05-17 17:12:55.155: epoch 140:	0.02636249  	0.19403201  	0.10958419  
2023-05-17 17:13:02.698: [iter 141 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0066, time: 7.542300]
2023-05-17 17:13:02.854: epoch 141:	0.02637660  	0.19431606  	0.10971098  
2023-05-17 17:13:10.787: [iter 142 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0066, time: 7.931476]
2023-05-17 17:13:10.945: epoch 142:	0.02640483  	0.19461216  	0.10973268  
2023-05-17 17:13:19.860: [iter 143 : loss : 0.1137 = 0.0241 + 0.0829 + 0.0067, time: 8.912992]
2023-05-17 17:13:20.139: epoch 143:	0.02641189  	0.19452310  	0.10979545  
2023-05-17 17:13:28.287: [iter 144 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 8.147444]
2023-05-17 17:13:28.434: epoch 144:	0.02644716  	0.19475447  	0.10992734  
2023-05-17 17:13:36.741: [iter 145 : loss : 0.1131 = 0.0235 + 0.0828 + 0.0067, time: 8.304994]
2023-05-17 17:13:36.908: epoch 145:	0.02654595  	0.19499986  	0.11025739  
2023-05-17 17:13:45.570: [iter 146 : loss : 0.1132 = 0.0236 + 0.0828 + 0.0067, time: 8.659955]
2023-05-17 17:13:45.851: epoch 146:	0.02654595  	0.19491693  	0.11012822  
2023-05-17 17:13:54.314: [iter 147 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0068, time: 8.460217]
2023-05-17 17:13:54.477: epoch 147:	0.02653184  	0.19488813  	0.11006537  
2023-05-17 17:14:02.586: [iter 148 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 8.106067]
2023-05-17 17:14:02.750: epoch 148:	0.02659534  	0.19516413  	0.11034625  
2023-05-17 17:14:10.391: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 7.639370]
2023-05-17 17:14:10.550: epoch 149:	0.02663063  	0.19547716  	0.11046231  
2023-05-17 17:14:18.764: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0069, time: 8.213494]
2023-05-17 17:14:18.924: epoch 150:	0.02658123  	0.19523227  	0.11053137  
2023-05-17 17:14:27.157: [iter 151 : loss : 0.1119 = 0.0224 + 0.0826 + 0.0069, time: 8.223292]
2023-05-17 17:14:27.445: epoch 151:	0.02668002  	0.19590576  	0.11071940  
2023-05-17 17:14:35.469: [iter 152 : loss : 0.1111 = 0.0216 + 0.0826 + 0.0069, time: 8.022992]
2023-05-17 17:14:35.636: epoch 152:	0.02667296  	0.19581300  	0.11060632  
2023-05-17 17:14:44.451: [iter 153 : loss : 0.1099 = 0.0204 + 0.0826 + 0.0069, time: 8.814021]
2023-05-17 17:14:44.624: epoch 153:	0.02672236  	0.19609958  	0.11075837  
2023-05-17 17:14:44.624: Find a better model.
2023-05-17 17:14:54.315: [iter 154 : loss : 0.1105 = 0.0210 + 0.0826 + 0.0070, time: 9.684994]
2023-05-17 17:14:54.552: epoch 154:	0.02666591  	0.19597585  	0.11074086  
2023-05-17 17:15:04.334: [iter 155 : loss : 0.1113 = 0.0218 + 0.0825 + 0.0070, time: 9.780991]
2023-05-17 17:15:04.491: epoch 155:	0.02666590  	0.19557486  	0.11053804  
2023-05-17 17:15:13.009: [iter 156 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 8.516235]
2023-05-17 17:15:13.171: epoch 156:	0.02670824  	0.19554818  	0.11063034  
2023-05-17 17:15:23.241: [iter 157 : loss : 0.1105 = 0.0210 + 0.0824 + 0.0070, time: 10.068419]
2023-05-17 17:15:23.566: epoch 157:	0.02666590  	0.19554940  	0.11048286  
2023-05-17 17:15:32.782: [iter 158 : loss : 0.1097 = 0.0203 + 0.0824 + 0.0071, time: 9.213995]
2023-05-17 17:15:32.960: epoch 158:	0.02665178  	0.19519378  	0.11030351  
2023-05-17 17:15:42.324: [iter 159 : loss : 0.1102 = 0.0207 + 0.0824 + 0.0071, time: 9.360992]
2023-05-17 17:15:42.494: epoch 159:	0.02663062  	0.19523950  	0.11040454  
2023-05-17 17:15:52.402: [iter 160 : loss : 0.1095 = 0.0201 + 0.0824 + 0.0071, time: 9.906991]
2023-05-17 17:15:52.594: epoch 160:	0.02660945  	0.19482045  	0.11018793  
2023-05-17 17:16:01.508: [iter 161 : loss : 0.1092 = 0.0197 + 0.0823 + 0.0071, time: 8.911663]
2023-05-17 17:16:01.669: epoch 161:	0.02655300  	0.19457199  	0.11005058  
2023-05-17 17:16:12.097: [iter 162 : loss : 0.1084 = 0.0190 + 0.0823 + 0.0072, time: 10.424445]
2023-05-17 17:16:12.432: epoch 162:	0.02649655  	0.19369403  	0.10983720  
2023-05-17 17:16:22.354: [iter 163 : loss : 0.1091 = 0.0196 + 0.0823 + 0.0072, time: 9.921160]
2023-05-17 17:16:22.560: epoch 163:	0.02654594  	0.19403774  	0.11000397  
2023-05-17 17:16:31.731: [iter 164 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0072, time: 9.168991]
2023-05-17 17:16:31.901: epoch 164:	0.02658828  	0.19419424  	0.11008681  
2023-05-17 17:16:41.444: [iter 165 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0072, time: 9.539990]
2023-05-17 17:16:41.601: epoch 165:	0.02651066  	0.19359741  	0.10981710  
2023-05-17 17:16:50.395: [iter 166 : loss : 0.1084 = 0.0189 + 0.0822 + 0.0073, time: 8.793372]
2023-05-17 17:16:50.551: epoch 166:	0.02656711  	0.19418707  	0.11003398  
2023-05-17 17:17:00.334: [iter 167 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0073, time: 9.780991]
2023-05-17 17:17:00.661: epoch 167:	0.02655299  	0.19423951  	0.10991576  
2023-05-17 17:17:10.380: [iter 168 : loss : 0.1082 = 0.0187 + 0.0822 + 0.0073, time: 9.715003]
2023-05-17 17:17:10.669: epoch 168:	0.02656005  	0.19448979  	0.10993583  
2023-05-17 17:17:19.519: [iter 169 : loss : 0.1082 = 0.0187 + 0.0821 + 0.0073, time: 8.847678]
2023-05-17 17:17:19.694: epoch 169:	0.02659534  	0.19442056  	0.10999126  
2023-05-17 17:17:28.036: [iter 170 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 8.341280]
2023-05-17 17:17:28.193: epoch 170:	0.02658122  	0.19429424  	0.10991174  
2023-05-17 17:17:36.462: [iter 171 : loss : 0.1084 = 0.0189 + 0.0821 + 0.0074, time: 8.267999]
2023-05-17 17:17:36.613: epoch 171:	0.02651066  	0.19366890  	0.10980977  
2023-05-17 17:17:45.675: [iter 172 : loss : 0.1072 = 0.0178 + 0.0820 + 0.0074, time: 9.059351]
2023-05-17 17:17:45.975: epoch 172:	0.02648949  	0.19360720  	0.10962051  
2023-05-17 17:17:53.465: [iter 173 : loss : 0.1078 = 0.0184 + 0.0820 + 0.0074, time: 7.488406]
2023-05-17 17:17:53.629: epoch 173:	0.02649654  	0.19381121  	0.10981731  
2023-05-17 17:18:02.113: [iter 174 : loss : 0.1075 = 0.0181 + 0.0820 + 0.0074, time: 8.482992]
2023-05-17 17:18:02.273: epoch 174:	0.02650360  	0.19378309  	0.10974944  
2023-05-17 17:18:10.614: [iter 175 : loss : 0.1070 = 0.0175 + 0.0820 + 0.0075, time: 8.339171]
2023-05-17 17:18:10.999: epoch 175:	0.02644715  	0.19342673  	0.10937886  
2023-05-17 17:18:18.847: [iter 176 : loss : 0.1067 = 0.0173 + 0.0819 + 0.0075, time: 7.836992]
2023-05-17 17:18:18.996: epoch 176:	0.02648243  	0.19358109  	0.10942201  
2023-05-17 17:18:28.030: [iter 177 : loss : 0.1070 = 0.0176 + 0.0819 + 0.0075, time: 9.024441]
2023-05-17 17:18:28.324: epoch 177:	0.02652477  	0.19387816  	0.10960135  
2023-05-17 17:18:35.717: [iter 178 : loss : 0.1064 = 0.0170 + 0.0819 + 0.0075, time: 7.391134]
2023-05-17 17:18:35.878: epoch 178:	0.02646125  	0.19345778  	0.10942642  
2023-05-17 17:18:35.878: Early stopping is trigger at epoch: 178
2023-05-17 17:18:35.878: best_result@epoch 153:

2023-05-17 17:18:35.878: 		0.0267      	0.1961      	0.1108      
2023-05-17 18:37:00.522: my pid: 11968
2023-05-17 18:37:00.522: model: model.general_recommender.SGL
2023-05-17 18:37:00.522: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 18:37:00.523: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 18:37:04.097: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 18:37:14.677: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.573179]
2023-05-17 18:37:14.972: epoch 1:	0.00129128  	0.00924714  	0.00446480  
2023-05-17 18:37:14.972: Find a better model.
2023-05-17 18:37:23.725: [iter 2 : loss : 0.7712 = 0.6929 + 0.0784 + 0.0000, time: 8.751768]
2023-05-17 18:37:23.942: epoch 2:	0.00224387  	0.01673280  	0.00811341  
2023-05-17 18:37:23.942: Find a better model.
2023-05-17 18:37:33.206: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 9.263961]
2023-05-17 18:37:33.381: epoch 3:	0.00437480  	0.03297048  	0.01541848  
2023-05-17 18:37:33.381: Find a better model.
2023-05-17 18:37:43.246: [iter 4 : loss : 0.7707 = 0.6921 + 0.0785 + 0.0000, time: 9.862545]
2023-05-17 18:37:43.427: epoch 4:	0.00737364  	0.05404373  	0.02568212  
2023-05-17 18:37:43.427: Find a better model.
2023-05-17 18:37:54.515: [iter 5 : loss : 0.7698 = 0.6911 + 0.0787 + 0.0000, time: 11.081662]
2023-05-17 18:37:54.827: epoch 5:	0.01078888  	0.07896964  	0.03723325  
2023-05-17 18:37:54.827: Find a better model.
2023-05-17 18:38:05.622: [iter 6 : loss : 0.7680 = 0.6890 + 0.0791 + 0.0000, time: 10.793282]
2023-05-17 18:38:05.952: epoch 6:	0.01417597  	0.10290562  	0.04962188  
2023-05-17 18:38:05.952: Find a better model.
2023-05-17 18:38:15.841: [iter 7 : loss : 0.7630 = 0.6833 + 0.0797 + 0.0000, time: 9.887990]
2023-05-17 18:38:16.020: epoch 7:	0.01724551  	0.12536263  	0.06073968  
2023-05-17 18:38:16.020: Find a better model.
2023-05-17 18:38:26.120: [iter 8 : loss : 0.7505 = 0.6692 + 0.0813 + 0.0001, time: 10.097994]
2023-05-17 18:38:26.304: epoch 8:	0.01847333  	0.13507265  	0.06683268  
2023-05-17 18:38:26.304: Find a better model.
2023-05-17 18:38:35.315: [iter 9 : loss : 0.7211 = 0.6364 + 0.0846 + 0.0001, time: 9.009533]
2023-05-17 18:38:35.482: epoch 9:	0.01860739  	0.13691111  	0.06857458  
2023-05-17 18:38:35.482: Find a better model.
2023-05-17 18:38:45.553: [iter 10 : loss : 0.6661 = 0.5760 + 0.0899 + 0.0002, time: 10.069971]
2023-05-17 18:38:46.151: epoch 10:	0.01860034  	0.13752426  	0.06826801  
2023-05-17 18:38:46.151: Find a better model.
2023-05-17 18:38:55.755: [iter 11 : loss : 0.5917 = 0.4961 + 0.0952 + 0.0004, time: 9.602020]
2023-05-17 18:38:56.075: epoch 11:	0.01832514  	0.13602288  	0.06809980  
2023-05-17 18:39:04.999: [iter 12 : loss : 0.5195 = 0.4198 + 0.0991 + 0.0005, time: 8.923023]
2023-05-17 18:39:05.170: epoch 12:	0.01831103  	0.13580474  	0.06784160  
2023-05-17 18:39:15.517: [iter 13 : loss : 0.4649 = 0.3630 + 0.1013 + 0.0007, time: 10.344957]
2023-05-17 18:39:15.739: epoch 13:	0.01847333  	0.13674422  	0.06882399  
2023-05-17 18:39:25.684: [iter 14 : loss : 0.4236 = 0.3205 + 0.1023 + 0.0008, time: 9.943034]
2023-05-17 18:39:26.035: epoch 14:	0.01857919  	0.13782990  	0.06945455  
2023-05-17 18:39:26.035: Find a better model.
2023-05-17 18:39:36.456: [iter 15 : loss : 0.3951 = 0.2913 + 0.1029 + 0.0010, time: 10.411011]
2023-05-17 18:39:36.849: epoch 15:	0.01883321  	0.13963641  	0.07044271  
2023-05-17 18:39:36.850: Find a better model.
2023-05-17 18:39:46.103: [iter 16 : loss : 0.3715 = 0.2676 + 0.1028 + 0.0011, time: 9.252506]
2023-05-17 18:39:46.268: epoch 16:	0.01906608  	0.14121091  	0.07132278  
2023-05-17 18:39:46.268: Find a better model.
2023-05-17 18:39:56.068: [iter 17 : loss : 0.3540 = 0.2502 + 0.1026 + 0.0012, time: 9.797933]
2023-05-17 18:39:56.256: epoch 17:	0.01936951  	0.14347757  	0.07239682  
2023-05-17 18:39:56.256: Find a better model.
2023-05-17 18:40:05.967: [iter 18 : loss : 0.3384 = 0.2346 + 0.1025 + 0.0013, time: 9.709065]
2023-05-17 18:40:06.213: epoch 18:	0.01944714  	0.14357097  	0.07297095  
2023-05-17 18:40:06.214: Find a better model.
2023-05-17 18:40:16.559: [iter 19 : loss : 0.3236 = 0.2201 + 0.1021 + 0.0014, time: 10.341437]
2023-05-17 18:40:16.869: epoch 19:	0.01963060  	0.14495246  	0.07381976  
2023-05-17 18:40:16.870: Find a better model.
2023-05-17 18:40:26.050: [iter 20 : loss : 0.3136 = 0.2105 + 0.1017 + 0.0015, time: 9.179494]
2023-05-17 18:40:26.298: epoch 20:	0.01985642  	0.14666243  	0.07491585  
2023-05-17 18:40:26.298: Find a better model.
2023-05-17 18:40:35.107: [iter 21 : loss : 0.3038 = 0.2009 + 0.1014 + 0.0016, time: 8.807201]
2023-05-17 18:40:35.291: epoch 21:	0.02003988  	0.14802989  	0.07558469  
2023-05-17 18:40:35.292: Find a better model.
2023-05-17 18:40:45.420: [iter 22 : loss : 0.2951 = 0.1926 + 0.1009 + 0.0016, time: 10.126103]
2023-05-17 18:40:45.654: epoch 22:	0.02017395  	0.14893068  	0.07615940  
2023-05-17 18:40:45.655: Find a better model.
2023-05-17 18:40:56.170: [iter 23 : loss : 0.2867 = 0.1846 + 0.1005 + 0.0017, time: 10.512165]
2023-05-17 18:40:56.481: epoch 23:	0.02042093  	0.15061134  	0.07729307  
2023-05-17 18:40:56.482: Find a better model.
2023-05-17 18:41:06.580: [iter 24 : loss : 0.2800 = 0.1782 + 0.1000 + 0.0018, time: 10.094290]
2023-05-17 18:41:06.884: epoch 24:	0.02065379  	0.15227407  	0.07807538  
2023-05-17 18:41:06.884: Find a better model.
2023-05-17 18:41:16.307: [iter 25 : loss : 0.2735 = 0.1720 + 0.0996 + 0.0019, time: 9.421230]
2023-05-17 18:41:16.464: epoch 25:	0.02070319  	0.15279517  	0.07846157  
2023-05-17 18:41:16.464: Find a better model.
2023-05-17 18:41:25.331: [iter 26 : loss : 0.2694 = 0.1684 + 0.0991 + 0.0019, time: 8.866014]
2023-05-17 18:41:25.721: epoch 26:	0.02080904  	0.15357713  	0.07909466  
2023-05-17 18:41:25.721: Find a better model.
2023-05-17 18:41:35.554: [iter 27 : loss : 0.2617 = 0.1611 + 0.0986 + 0.0020, time: 9.831014]
2023-05-17 18:41:35.823: epoch 27:	0.02103485  	0.15519100  	0.07981224  
2023-05-17 18:41:35.823: Find a better model.
2023-05-17 18:41:46.286: [iter 28 : loss : 0.2565 = 0.1563 + 0.0982 + 0.0021, time: 10.459042]
2023-05-17 18:41:46.616: epoch 28:	0.02126066  	0.15654291  	0.08079702  
2023-05-17 18:41:46.616: Find a better model.
2023-05-17 18:41:56.706: [iter 29 : loss : 0.2520 = 0.1521 + 0.0978 + 0.0021, time: 10.086023]
2023-05-17 18:41:57.054: epoch 29:	0.02152881  	0.15852301  	0.08162075  
2023-05-17 18:41:57.054: Find a better model.
2023-05-17 18:42:06.716: [iter 30 : loss : 0.2453 = 0.1456 + 0.0974 + 0.0022, time: 9.661002]
2023-05-17 18:42:07.038: epoch 30:	0.02164171  	0.15930609  	0.08213145  
2023-05-17 18:42:07.038: Find a better model.
2023-05-17 18:42:15.626: [iter 31 : loss : 0.2417 = 0.1423 + 0.0971 + 0.0023, time: 8.585034]
2023-05-17 18:42:16.085: epoch 31:	0.02188164  	0.16100238  	0.08319332  
2023-05-17 18:42:16.087: Find a better model.
2023-05-17 18:42:25.826: [iter 32 : loss : 0.2362 = 0.1371 + 0.0967 + 0.0023, time: 9.722000]
2023-05-17 18:42:25.998: epoch 32:	0.02210038  	0.16273940  	0.08404284  
2023-05-17 18:42:25.998: Find a better model.
2023-05-17 18:42:36.691: [iter 33 : loss : 0.2336 = 0.1349 + 0.0963 + 0.0024, time: 10.691001]
2023-05-17 18:42:37.002: epoch 33:	0.02224151  	0.16367815  	0.08468573  
2023-05-17 18:42:37.002: Find a better model.
2023-05-17 18:42:46.938: [iter 34 : loss : 0.2291 = 0.1308 + 0.0959 + 0.0024, time: 9.926059]
2023-05-17 18:42:47.251: epoch 34:	0.02237558  	0.16476020  	0.08524539  
2023-05-17 18:42:47.251: Find a better model.
2023-05-17 18:42:56.535: [iter 35 : loss : 0.2259 = 0.1278 + 0.0957 + 0.0025, time: 9.281991]
2023-05-17 18:42:56.786: epoch 35:	0.02256611  	0.16617443  	0.08592156  
2023-05-17 18:42:56.787: Find a better model.
2023-05-17 18:43:06.224: [iter 36 : loss : 0.2224 = 0.1246 + 0.0953 + 0.0025, time: 9.436034]
2023-05-17 18:43:06.514: epoch 36:	0.02279192  	0.16832249  	0.08676885  
2023-05-17 18:43:06.514: Find a better model.
2023-05-17 18:43:16.237: [iter 37 : loss : 0.2184 = 0.1209 + 0.0950 + 0.0026, time: 9.720460]
2023-05-17 18:43:16.408: epoch 37:	0.02282720  	0.16855051  	0.08705362  
2023-05-17 18:43:16.408: Find a better model.
2023-05-17 18:43:26.456: [iter 38 : loss : 0.2166 = 0.1193 + 0.0946 + 0.0027, time: 10.038271]
2023-05-17 18:43:26.751: epoch 38:	0.02296127  	0.16964734  	0.08764677  
2023-05-17 18:43:26.751: Find a better model.
2023-05-17 18:43:37.163: [iter 39 : loss : 0.2123 = 0.1152 + 0.0943 + 0.0027, time: 10.408999]
2023-05-17 18:43:37.478: epoch 39:	0.02309534  	0.17110988  	0.08833025  
2023-05-17 18:43:37.478: Find a better model.
2023-05-17 18:43:47.367: [iter 40 : loss : 0.2090 = 0.1121 + 0.0941 + 0.0028, time: 9.886559]
2023-05-17 18:43:47.574: epoch 40:	0.02313769  	0.17114194  	0.08858741  
2023-05-17 18:43:47.574: Find a better model.
2023-05-17 18:43:56.541: [iter 41 : loss : 0.2074 = 0.1108 + 0.0938 + 0.0028, time: 8.960993]
2023-05-17 18:43:56.717: epoch 41:	0.02331411  	0.17255124  	0.08943941  
2023-05-17 18:43:56.717: Find a better model.
2023-05-17 18:44:06.122: [iter 42 : loss : 0.2049 = 0.1086 + 0.0934 + 0.0029, time: 9.403063]
2023-05-17 18:44:06.458: epoch 42:	0.02346934  	0.17375408  	0.09025080  
2023-05-17 18:44:06.458: Find a better model.
2023-05-17 18:44:16.427: [iter 43 : loss : 0.2013 = 0.1053 + 0.0932 + 0.0029, time: 9.966000]
2023-05-17 18:44:16.725: epoch 43:	0.02349757  	0.17375888  	0.09070237  
2023-05-17 18:44:16.726: Find a better model.
2023-05-17 18:44:26.993: [iter 44 : loss : 0.1975 = 0.1016 + 0.0929 + 0.0030, time: 10.265027]
2023-05-17 18:44:27.318: epoch 44:	0.02365281  	0.17461440  	0.09131781  
2023-05-17 18:44:27.318: Find a better model.
2023-05-17 18:44:37.031: [iter 45 : loss : 0.1954 = 0.0997 + 0.0927 + 0.0030, time: 9.712521]
2023-05-17 18:44:37.195: epoch 45:	0.02366692  	0.17470284  	0.09164489  
2023-05-17 18:44:37.195: Find a better model.
2023-05-17 18:44:46.338: [iter 46 : loss : 0.1932 = 0.0977 + 0.0924 + 0.0031, time: 9.140003]
2023-05-17 18:44:46.564: epoch 46:	0.02375866  	0.17541789  	0.09209556  
2023-05-17 18:44:46.564: Find a better model.
2023-05-17 18:44:55.448: [iter 47 : loss : 0.1921 = 0.0968 + 0.0922 + 0.0031, time: 8.878051]
2023-05-17 18:44:55.699: epoch 47:	0.02384333  	0.17616411  	0.09242344  
2023-05-17 18:44:55.699: Find a better model.
2023-05-17 18:45:05.956: [iter 48 : loss : 0.1882 = 0.0931 + 0.0919 + 0.0032, time: 10.254205]
2023-05-17 18:45:06.275: epoch 48:	0.02399152  	0.17731684  	0.09313785  
2023-05-17 18:45:06.275: Find a better model.
2023-05-17 18:45:16.856: [iter 49 : loss : 0.1850 = 0.0901 + 0.0917 + 0.0032, time: 10.578500]
2023-05-17 18:45:17.183: epoch 49:	0.02404797  	0.17730126  	0.09343310  
2023-05-17 18:45:26.775: [iter 50 : loss : 0.1844 = 0.0896 + 0.0915 + 0.0033, time: 9.590036]
2023-05-17 18:45:26.935: epoch 50:	0.02411854  	0.17779036  	0.09388179  
2023-05-17 18:45:26.936: Find a better model.
2023-05-17 18:45:36.318: [iter 51 : loss : 0.1812 = 0.0866 + 0.0912 + 0.0033, time: 9.381001]
2023-05-17 18:45:36.632: epoch 51:	0.02421027  	0.17857046  	0.09434851  
2023-05-17 18:45:36.633: Find a better model.
2023-05-17 18:45:45.433: [iter 52 : loss : 0.1813 = 0.0869 + 0.0911 + 0.0034, time: 8.797047]
2023-05-17 18:45:45.610: epoch 52:	0.02420321  	0.17869304  	0.09461886  
2023-05-17 18:45:45.610: Find a better model.
2023-05-17 18:45:55.804: [iter 53 : loss : 0.1790 = 0.0848 + 0.0908 + 0.0034, time: 10.186041]
2023-05-17 18:45:56.066: epoch 53:	0.02430906  	0.17930393  	0.09520759  
2023-05-17 18:45:56.066: Find a better model.
2023-05-17 18:46:06.291: [iter 54 : loss : 0.1771 = 0.0830 + 0.0907 + 0.0035, time: 10.222052]
2023-05-17 18:46:06.606: epoch 54:	0.02442196  	0.18028766  	0.09588113  
2023-05-17 18:46:06.606: Find a better model.
2023-05-17 18:46:16.299: [iter 55 : loss : 0.1749 = 0.0810 + 0.0905 + 0.0035, time: 9.691000]
2023-05-17 18:46:16.471: epoch 55:	0.02452780  	0.18080181  	0.09628390  
2023-05-17 18:46:16.471: Find a better model.
2023-05-17 18:46:26.403: [iter 56 : loss : 0.1733 = 0.0794 + 0.0903 + 0.0035, time: 9.930142]
2023-05-17 18:46:26.617: epoch 56:	0.02455603  	0.18101534  	0.09661046  
2023-05-17 18:46:26.617: Find a better model.
2023-05-17 18:46:35.734: [iter 57 : loss : 0.1714 = 0.0777 + 0.0901 + 0.0036, time: 9.113992]
2023-05-17 18:46:35.895: epoch 57:	0.02466894  	0.18177408  	0.09693948  
2023-05-17 18:46:35.895: Find a better model.
2023-05-17 18:46:45.788: [iter 58 : loss : 0.1697 = 0.0761 + 0.0900 + 0.0036, time: 9.889018]
2023-05-17 18:46:46.172: epoch 58:	0.02474656  	0.18238121  	0.09720997  
2023-05-17 18:46:46.172: Find a better model.
2023-05-17 18:46:55.528: [iter 59 : loss : 0.1685 = 0.0751 + 0.0897 + 0.0037, time: 9.352382]
2023-05-17 18:46:55.818: epoch 59:	0.02469010  	0.18185654  	0.09743997  
2023-05-17 18:47:05.443: [iter 60 : loss : 0.1671 = 0.0738 + 0.0896 + 0.0037, time: 9.623944]
2023-05-17 18:47:05.623: epoch 60:	0.02481006  	0.18300891  	0.09784855  
2023-05-17 18:47:05.624: Find a better model.
2023-05-17 18:47:15.188: [iter 61 : loss : 0.1655 = 0.0724 + 0.0893 + 0.0038, time: 9.561466]
2023-05-17 18:47:15.537: epoch 61:	0.02480300  	0.18277898  	0.09806652  
2023-05-17 18:47:24.332: [iter 62 : loss : 0.1641 = 0.0711 + 0.0892 + 0.0038, time: 8.792005]
2023-05-17 18:47:24.490: epoch 62:	0.02488062  	0.18339509  	0.09850407  
2023-05-17 18:47:24.490: Find a better model.
2023-05-17 18:47:34.399: [iter 63 : loss : 0.1625 = 0.0696 + 0.0891 + 0.0039, time: 9.906312]
2023-05-17 18:47:34.776: epoch 63:	0.02492297  	0.18344270  	0.09879018  
2023-05-17 18:47:34.776: Find a better model.
2023-05-17 18:47:44.029: [iter 64 : loss : 0.1616 = 0.0688 + 0.0889 + 0.0039, time: 9.250993]
2023-05-17 18:47:44.296: epoch 64:	0.02495825  	0.18385661  	0.09918628  
2023-05-17 18:47:44.296: Find a better model.
2023-05-17 18:47:53.833: [iter 65 : loss : 0.1603 = 0.0676 + 0.0887 + 0.0040, time: 9.534877]
2023-05-17 18:47:53.996: epoch 65:	0.02497941  	0.18432888  	0.09952303  
2023-05-17 18:47:53.996: Find a better model.
2023-05-17 18:48:03.923: [iter 66 : loss : 0.1587 = 0.0661 + 0.0886 + 0.0040, time: 9.925437]
2023-05-17 18:48:04.094: epoch 66:	0.02507820  	0.18525980  	0.09984873  
2023-05-17 18:48:04.094: Find a better model.
2023-05-17 18:48:12.932: [iter 67 : loss : 0.1572 = 0.0647 + 0.0884 + 0.0040, time: 8.837141]
2023-05-17 18:48:13.090: epoch 67:	0.02518405  	0.18568528  	0.10020561  
2023-05-17 18:48:13.090: Find a better model.
2023-05-17 18:48:23.263: [iter 68 : loss : 0.1568 = 0.0644 + 0.0883 + 0.0041, time: 10.170098]
2023-05-17 18:48:23.658: epoch 68:	0.02524756  	0.18618456  	0.10038006  
2023-05-17 18:48:23.658: Find a better model.
2023-05-17 18:48:32.715: [iter 69 : loss : 0.1548 = 0.0625 + 0.0881 + 0.0041, time: 9.044966]
2023-05-17 18:48:33.015: epoch 69:	0.02521228  	0.18574895  	0.10042328  
2023-05-17 18:48:42.612: [iter 70 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 9.595000]
2023-05-17 18:48:42.776: epoch 70:	0.02538869  	0.18715142  	0.10094652  
2023-05-17 18:48:42.776: Find a better model.
2023-05-17 18:48:53.052: [iter 71 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 10.274159]
2023-05-17 18:48:53.316: epoch 71:	0.02534635  	0.18698944  	0.10105048  
2023-05-17 18:49:03.228: [iter 72 : loss : 0.1518 = 0.0598 + 0.0878 + 0.0042, time: 9.910017]
2023-05-17 18:49:03.556: epoch 72:	0.02548043  	0.18818350  	0.10163479  
2023-05-17 18:49:03.557: Find a better model.
2023-05-17 18:49:13.732: [iter 73 : loss : 0.1505 = 0.0585 + 0.0877 + 0.0043, time: 10.171204]
2023-05-17 18:49:14.042: epoch 73:	0.02553688  	0.18853623  	0.10191993  
2023-05-17 18:49:14.042: Find a better model.
2023-05-17 18:49:23.422: [iter 74 : loss : 0.1489 = 0.0570 + 0.0876 + 0.0043, time: 9.378417]
2023-05-17 18:49:23.644: epoch 74:	0.02560038  	0.18880093  	0.10224687  
2023-05-17 18:49:23.644: Find a better model.
2023-05-17 18:49:32.874: [iter 75 : loss : 0.1481 = 0.0563 + 0.0874 + 0.0044, time: 9.228232]
2023-05-17 18:49:33.052: epoch 75:	0.02561450  	0.18854308  	0.10222988  
2023-05-17 18:49:43.208: [iter 76 : loss : 0.1474 = 0.0557 + 0.0873 + 0.0044, time: 10.153024]
2023-05-17 18:49:43.494: epoch 76:	0.02567800  	0.18900912  	0.10250446  
2023-05-17 18:49:43.494: Find a better model.
2023-05-17 18:49:53.881: [iter 77 : loss : 0.1462 = 0.0546 + 0.0872 + 0.0045, time: 10.380162]
2023-05-17 18:49:54.178: epoch 77:	0.02583324  	0.19033150  	0.10310338  
2023-05-17 18:49:54.178: Find a better model.
2023-05-17 18:50:04.969: [iter 78 : loss : 0.1454 = 0.0539 + 0.0871 + 0.0045, time: 10.787050]
2023-05-17 18:50:05.277: epoch 78:	0.02573445  	0.18978798  	0.10303229  
2023-05-17 18:50:15.213: [iter 79 : loss : 0.1441 = 0.0526 + 0.0869 + 0.0045, time: 9.934994]
2023-05-17 18:50:15.390: epoch 79:	0.02575562  	0.18976781  	0.10316324  
2023-05-17 18:50:25.026: [iter 80 : loss : 0.1433 = 0.0518 + 0.0869 + 0.0046, time: 9.633005]
2023-05-17 18:50:25.244: epoch 80:	0.02576268  	0.18976964  	0.10325412  
2023-05-17 18:50:33.938: [iter 81 : loss : 0.1431 = 0.0518 + 0.0867 + 0.0046, time: 8.690476]
2023-05-17 18:50:34.103: epoch 81:	0.02583324  	0.19031085  	0.10351844  
2023-05-17 18:50:44.354: [iter 82 : loss : 0.1418 = 0.0505 + 0.0866 + 0.0046, time: 10.246023]
2023-05-17 18:50:44.699: epoch 82:	0.02580502  	0.19022612  	0.10345834  
2023-05-17 18:50:53.758: [iter 83 : loss : 0.1407 = 0.0495 + 0.0866 + 0.0047, time: 9.057542]
2023-05-17 18:50:54.045: epoch 83:	0.02586147  	0.19079426  	0.10363983  
2023-05-17 18:50:54.045: Find a better model.
2023-05-17 18:51:03.519: [iter 84 : loss : 0.1405 = 0.0494 + 0.0864 + 0.0047, time: 9.470274]
2023-05-17 18:51:03.675: epoch 84:	0.02591793  	0.19138744  	0.10386474  
2023-05-17 18:51:03.676: Find a better model.
2023-05-17 18:51:13.971: [iter 85 : loss : 0.1397 = 0.0486 + 0.0863 + 0.0048, time: 10.293991]
2023-05-17 18:51:14.134: epoch 85:	0.02598849  	0.19211936  	0.10419263  
2023-05-17 18:51:14.134: Find a better model.
2023-05-17 18:51:22.920: [iter 86 : loss : 0.1395 = 0.0485 + 0.0862 + 0.0048, time: 8.784003]
2023-05-17 18:51:23.093: epoch 86:	0.02605906  	0.19217430  	0.10437711  
2023-05-17 18:51:23.093: Find a better model.
2023-05-17 18:51:33.402: [iter 87 : loss : 0.1368 = 0.0458 + 0.0862 + 0.0048, time: 10.303991]
2023-05-17 18:51:33.764: epoch 87:	0.02608729  	0.19194472  	0.10447939  
2023-05-17 18:51:42.456: [iter 88 : loss : 0.1361 = 0.0451 + 0.0861 + 0.0049, time: 8.691048]
2023-05-17 18:51:42.706: epoch 88:	0.02614374  	0.19243498  	0.10478046  
2023-05-17 18:51:42.706: Find a better model.
2023-05-17 18:51:51.932: [iter 89 : loss : 0.1361 = 0.0452 + 0.0860 + 0.0049, time: 9.223003]
2023-05-17 18:51:52.095: epoch 89:	0.02615785  	0.19259858  	0.10472926  
2023-05-17 18:51:52.096: Find a better model.
2023-05-17 18:52:02.970: [iter 90 : loss : 0.1365 = 0.0457 + 0.0859 + 0.0050, time: 10.872442]
2023-05-17 18:52:03.229: epoch 90:	0.02627780  	0.19318061  	0.10505313  
2023-05-17 18:52:03.229: Find a better model.
2023-05-17 18:52:13.496: [iter 91 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 10.262013]
2023-05-17 18:52:13.796: epoch 91:	0.02633426  	0.19374475  	0.10527214  
2023-05-17 18:52:13.796: Find a better model.
2023-05-17 18:52:24.106: [iter 92 : loss : 0.1341 = 0.0434 + 0.0857 + 0.0050, time: 10.304001]
2023-05-17 18:52:24.456: epoch 92:	0.02628486  	0.19344249  	0.10528849  
2023-05-17 18:52:33.958: [iter 93 : loss : 0.1346 = 0.0439 + 0.0856 + 0.0051, time: 9.501006]
2023-05-17 18:52:34.126: epoch 93:	0.02630603  	0.19371337  	0.10532919  
2023-05-17 18:52:42.829: [iter 94 : loss : 0.1325 = 0.0419 + 0.0855 + 0.0051, time: 8.701992]
2023-05-17 18:52:43.010: epoch 94:	0.02635542  	0.19411518  	0.10545412  
2023-05-17 18:52:43.010: Find a better model.
2023-05-17 18:52:53.091: [iter 95 : loss : 0.1316 = 0.0410 + 0.0855 + 0.0051, time: 10.078558]
2023-05-17 18:52:53.350: epoch 95:	0.02634837  	0.19441007  	0.10566597  
2023-05-17 18:52:53.350: Find a better model.
2023-05-17 18:53:03.815: [iter 96 : loss : 0.1317 = 0.0412 + 0.0854 + 0.0052, time: 10.464077]
2023-05-17 18:53:04.122: epoch 96:	0.02634836  	0.19444738  	0.10573567  
2023-05-17 18:53:04.122: Find a better model.
2023-05-17 18:53:13.848: [iter 97 : loss : 0.1302 = 0.0397 + 0.0853 + 0.0052, time: 9.724062]
2023-05-17 18:53:14.129: epoch 97:	0.02636247  	0.19435017  	0.10586791  
2023-05-17 18:53:23.936: [iter 98 : loss : 0.1313 = 0.0408 + 0.0853 + 0.0052, time: 9.806522]
2023-05-17 18:53:24.098: epoch 98:	0.02639070  	0.19439566  	0.10596835  
2023-05-17 18:53:34.188: [iter 99 : loss : 0.1298 = 0.0393 + 0.0852 + 0.0053, time: 10.089000]
2023-05-17 18:53:34.350: epoch 99:	0.02636952  	0.19441548  	0.10611123  
2023-05-17 18:53:42.613: [iter 100 : loss : 0.1290 = 0.0385 + 0.0851 + 0.0053, time: 8.261035]
2023-05-17 18:53:42.771: epoch 100:	0.02634836  	0.19424914  	0.10604157  
2023-05-17 18:53:52.805: [iter 101 : loss : 0.1287 = 0.0383 + 0.0850 + 0.0054, time: 10.030811]
2023-05-17 18:53:53.143: epoch 101:	0.02641892  	0.19498581  	0.10647474  
2023-05-17 18:53:53.143: Find a better model.
2023-05-17 18:54:02.203: [iter 102 : loss : 0.1277 = 0.0373 + 0.0850 + 0.0054, time: 9.056998]
2023-05-17 18:54:02.456: epoch 102:	0.02652476  	0.19557527  	0.10660717  
2023-05-17 18:54:02.456: Find a better model.
2023-05-17 18:54:11.912: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 9.455019]
2023-05-17 18:54:12.076: epoch 103:	0.02649653  	0.19528808  	0.10660403  
2023-05-17 18:54:22.081: [iter 104 : loss : 0.1281 = 0.0378 + 0.0848 + 0.0055, time: 10.002991]
2023-05-17 18:54:22.245: epoch 104:	0.02653887  	0.19553660  	0.10684445  
2023-05-17 18:54:32.595: [iter 105 : loss : 0.1273 = 0.0370 + 0.0847 + 0.0055, time: 10.349258]
2023-05-17 18:54:32.870: epoch 105:	0.02655299  	0.19576664  	0.10686693  
2023-05-17 18:54:32.870: Find a better model.
2023-05-17 18:54:43.260: [iter 106 : loss : 0.1267 = 0.0364 + 0.0847 + 0.0055, time: 10.388000]
2023-05-17 18:54:43.570: epoch 106:	0.02650360  	0.19540635  	0.10685740  
2023-05-17 18:54:52.920: [iter 107 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 9.346129]
2023-05-17 18:54:53.084: epoch 107:	0.02648949  	0.19533354  	0.10679481  
2023-05-17 18:55:02.044: [iter 108 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 8.958104]
2023-05-17 18:55:02.224: epoch 108:	0.02657415  	0.19599059  	0.10702464  
2023-05-17 18:55:02.225: Find a better model.
2023-05-17 18:55:12.651: [iter 109 : loss : 0.1243 = 0.0342 + 0.0845 + 0.0056, time: 10.423004]
2023-05-17 18:55:12.927: epoch 109:	0.02654593  	0.19579308  	0.10686815  
2023-05-17 18:55:23.196: [iter 110 : loss : 0.1238 = 0.0337 + 0.0845 + 0.0057, time: 10.267011]
2023-05-17 18:55:23.507: epoch 110:	0.02652476  	0.19567779  	0.10688899  
2023-05-17 18:55:33.560: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 10.051001]
2023-05-17 18:55:33.836: epoch 111:	0.02651770  	0.19588268  	0.10707344  
2023-05-17 18:55:43.699: [iter 112 : loss : 0.1236 = 0.0335 + 0.0843 + 0.0057, time: 9.862181]
2023-05-17 18:55:43.853: epoch 112:	0.02655298  	0.19605131  	0.10725522  
2023-05-17 18:55:43.854: Find a better model.
2023-05-17 18:55:53.671: [iter 113 : loss : 0.1235 = 0.0334 + 0.0843 + 0.0058, time: 9.815703]
2023-05-17 18:55:54.171: epoch 113:	0.02658826  	0.19599985  	0.10718076  
2023-05-17 18:56:02.913: [iter 114 : loss : 0.1226 = 0.0326 + 0.0842 + 0.0058, time: 8.737304]
2023-05-17 18:56:03.072: epoch 114:	0.02663766  	0.19650221  	0.10735465  
2023-05-17 18:56:03.073: Find a better model.
2023-05-17 18:56:13.240: [iter 115 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 10.165117]
2023-05-17 18:56:13.543: epoch 115:	0.02665178  	0.19660051  	0.10742983  
2023-05-17 18:56:13.543: Find a better model.
2023-05-17 18:56:22.767: [iter 116 : loss : 0.1213 = 0.0313 + 0.0842 + 0.0059, time: 9.217267]
2023-05-17 18:56:23.047: epoch 116:	0.02665883  	0.19671662  	0.10744543  
2023-05-17 18:56:23.047: Find a better model.
2023-05-17 18:56:32.659: [iter 117 : loss : 0.1213 = 0.0313 + 0.0840 + 0.0059, time: 9.609435]
2023-05-17 18:56:32.821: epoch 117:	0.02668001  	0.19667348  	0.10747327  
2023-05-17 18:56:43.262: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 10.439001]
2023-05-17 18:56:43.543: epoch 118:	0.02669412  	0.19696316  	0.10763883  
2023-05-17 18:56:43.543: Find a better model.
2023-05-17 18:56:53.888: [iter 119 : loss : 0.1201 = 0.0302 + 0.0839 + 0.0060, time: 10.343680]
2023-05-17 18:56:54.172: epoch 119:	0.02673646  	0.19739981  	0.10785529  
2023-05-17 18:56:54.172: Find a better model.
2023-05-17 18:57:04.528: [iter 120 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0060, time: 10.352436]
2023-05-17 18:57:04.854: epoch 120:	0.02668707  	0.19721372  	0.10785483  
2023-05-17 18:57:14.106: [iter 121 : loss : 0.1202 = 0.0304 + 0.0838 + 0.0060, time: 9.250667]
2023-05-17 18:57:14.273: epoch 121:	0.02672941  	0.19746040  	0.10797203  
2023-05-17 18:57:14.273: Find a better model.
2023-05-17 18:57:23.294: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0061, time: 9.019106]
2023-05-17 18:57:23.475: epoch 122:	0.02671529  	0.19716087  	0.10775068  
2023-05-17 18:57:33.857: [iter 123 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 10.380148]
2023-05-17 18:57:34.144: epoch 123:	0.02669412  	0.19715934  	0.10779284  
2023-05-17 18:57:44.323: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 10.176224]
2023-05-17 18:57:44.625: epoch 124:	0.02665884  	0.19675592  	0.10777883  
2023-05-17 18:57:55.537: [iter 125 : loss : 0.1178 = 0.0280 + 0.0837 + 0.0061, time: 10.909052]
2023-05-17 18:57:55.850: epoch 125:	0.02665884  	0.19670482  	0.10775866  
2023-05-17 18:58:05.882: [iter 126 : loss : 0.1181 = 0.0283 + 0.0836 + 0.0062, time: 10.031516]
2023-05-17 18:58:06.063: epoch 126:	0.02664473  	0.19651352  	0.10778038  
2023-05-17 18:58:16.182: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 10.116004]
2023-05-17 18:58:16.449: epoch 127:	0.02663766  	0.19642779  	0.10782165  
2023-05-17 18:58:24.995: [iter 128 : loss : 0.1182 = 0.0284 + 0.0835 + 0.0062, time: 8.543002]
2023-05-17 18:58:25.159: epoch 128:	0.02666589  	0.19644655  	0.10789143  
2023-05-17 18:58:35.537: [iter 129 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 10.372012]
2023-05-17 18:58:35.840: epoch 129:	0.02664472  	0.19610904  	0.10779370  
2023-05-17 18:58:45.458: [iter 130 : loss : 0.1174 = 0.0276 + 0.0834 + 0.0063, time: 9.616014]
2023-05-17 18:58:45.749: epoch 130:	0.02668000  	0.19648162  	0.10796050  
2023-05-17 18:58:55.224: [iter 131 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 9.474001]
2023-05-17 18:58:55.397: epoch 131:	0.02670117  	0.19666028  	0.10807052  
2023-05-17 18:59:05.129: [iter 132 : loss : 0.1166 = 0.0269 + 0.0833 + 0.0064, time: 9.729743]
2023-05-17 18:59:05.648: epoch 132:	0.02676468  	0.19720256  	0.10822229  
2023-05-17 18:59:14.420: [iter 133 : loss : 0.1154 = 0.0257 + 0.0833 + 0.0064, time: 8.768015]
2023-05-17 18:59:14.614: epoch 133:	0.02668706  	0.19686434  	0.10818294  
2023-05-17 18:59:24.472: [iter 134 : loss : 0.1160 = 0.0263 + 0.0833 + 0.0064, time: 9.852996]
2023-05-17 18:59:24.778: epoch 134:	0.02665883  	0.19672087  	0.10821522  
2023-05-17 18:59:34.297: [iter 135 : loss : 0.1155 = 0.0258 + 0.0832 + 0.0064, time: 9.517043]
2023-05-17 18:59:34.570: epoch 135:	0.02661649  	0.19610220  	0.10813814  
2023-05-17 18:59:44.052: [iter 136 : loss : 0.1156 = 0.0259 + 0.0832 + 0.0065, time: 9.479235]
2023-05-17 18:59:44.217: epoch 136:	0.02659533  	0.19573173  	0.10794017  
2023-05-17 18:59:53.827: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 9.609051]
2023-05-17 18:59:53.991: epoch 137:	0.02658827  	0.19578260  	0.10780175  
2023-05-17 19:00:03.123: [iter 138 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 9.130654]
2023-05-17 19:00:03.281: epoch 138:	0.02659533  	0.19584011  	0.10790264  
2023-05-17 19:00:13.632: [iter 139 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0066, time: 10.341222]
2023-05-17 19:00:13.944: epoch 139:	0.02660944  	0.19586238  	0.10796605  
2023-05-17 19:00:23.742: [iter 140 : loss : 0.1137 = 0.0242 + 0.0830 + 0.0066, time: 9.791361]
2023-05-17 19:00:24.032: epoch 140:	0.02658827  	0.19588840  	0.10793188  
2023-05-17 19:00:33.842: [iter 141 : loss : 0.1143 = 0.0247 + 0.0829 + 0.0066, time: 9.808173]
2023-05-17 19:00:34.011: epoch 141:	0.02658827  	0.19576006  	0.10811770  
2023-05-17 19:00:43.791: [iter 142 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0066, time: 9.779001]
2023-05-17 19:00:43.964: epoch 142:	0.02658122  	0.19602227  	0.10809711  
2023-05-17 19:00:53.091: [iter 143 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0067, time: 9.126195]
2023-05-17 19:00:53.253: epoch 143:	0.02659533  	0.19602756  	0.10798770  
2023-05-17 19:01:03.400: [iter 144 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 10.140286]
2023-05-17 19:01:03.801: epoch 144:	0.02656005  	0.19568069  	0.10787300  
2023-05-17 19:01:13.744: [iter 145 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 9.940337]
2023-05-17 19:01:14.029: epoch 145:	0.02656710  	0.19561549  	0.10791197  
2023-05-17 19:01:23.815: [iter 146 : loss : 0.1132 = 0.0237 + 0.0828 + 0.0067, time: 9.784002]
2023-05-17 19:01:23.994: epoch 146:	0.02650359  	0.19504692  	0.10769649  
2023-05-17 19:01:23.994: Early stopping is trigger at epoch: 146
2023-05-17 19:01:23.994: best_result@epoch 121:

2023-05-17 19:01:23.994: 		0.0267      	0.1975      	0.1080      
2023-05-17 19:19:44.993: my pid: 5284
2023-05-17 19:19:44.993: model: model.general_recommender.SGL
2023-05-17 19:19:44.993: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 19:19:44.993: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 19:19:48.782: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 19:19:59.452: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.669092]
2023-05-17 19:19:59.625: epoch 1:	0.00134773  	0.00979109  	0.00465780  
2023-05-17 19:19:59.625: Find a better model.
2023-05-17 19:20:10.774: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 11.142885]
2023-05-17 19:20:11.143: epoch 2:	0.00258962  	0.01989474  	0.00928428  
2023-05-17 19:20:11.143: Find a better model.
2023-05-17 19:20:22.069: [iter 3 : loss : 0.7711 = 0.6926 + 0.0785 + 0.0000, time: 10.923038]
2023-05-17 19:20:22.394: epoch 3:	0.00457237  	0.03468339  	0.01627753  
2023-05-17 19:20:22.394: Find a better model.
2023-05-17 19:20:32.617: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 10.222001]
2023-05-17 19:20:32.799: epoch 4:	0.00760649  	0.05572637  	0.02672889  
2023-05-17 19:20:32.799: Find a better model.
2023-05-17 19:20:42.678: [iter 5 : loss : 0.7696 = 0.6909 + 0.0788 + 0.0000, time: 9.876506]
2023-05-17 19:20:42.838: epoch 5:	0.01148040  	0.08381060  	0.03991462  
2023-05-17 19:20:42.838: Find a better model.
2023-05-17 19:20:52.350: [iter 6 : loss : 0.7674 = 0.6882 + 0.0791 + 0.0000, time: 9.511010]
2023-05-17 19:20:52.522: epoch 6:	0.01506508  	0.11004443  	0.05259305  
2023-05-17 19:20:52.522: Find a better model.
2023-05-17 19:21:02.928: [iter 7 : loss : 0.7612 = 0.6813 + 0.0799 + 0.0000, time: 10.397220]
2023-05-17 19:21:03.232: epoch 7:	0.01736546  	0.12627307  	0.06222521  
2023-05-17 19:21:03.232: Find a better model.
2023-05-17 19:21:13.075: [iter 8 : loss : 0.7460 = 0.6642 + 0.0817 + 0.0001, time: 9.841365]
2023-05-17 19:21:13.356: epoch 8:	0.01869208  	0.13677050  	0.06820380  
2023-05-17 19:21:13.356: Find a better model.
2023-05-17 19:21:22.974: [iter 9 : loss : 0.7112 = 0.6255 + 0.0856 + 0.0001, time: 9.617013]
2023-05-17 19:21:23.205: epoch 9:	0.01875559  	0.13780600  	0.06866529  
2023-05-17 19:21:23.205: Find a better model.
2023-05-17 19:21:32.420: [iter 10 : loss : 0.6503 = 0.5590 + 0.0910 + 0.0002, time: 9.210990]
2023-05-17 19:21:32.590: epoch 10:	0.01862152  	0.13808751  	0.06835476  
2023-05-17 19:21:32.590: Find a better model.
2023-05-17 19:21:41.899: [iter 11 : loss : 0.5743 = 0.4778 + 0.0961 + 0.0004, time: 9.307003]
2023-05-17 19:21:42.082: epoch 11:	0.01852978  	0.13693564  	0.06815854  
2023-05-17 19:21:52.370: [iter 12 : loss : 0.5055 = 0.4054 + 0.0995 + 0.0005, time: 10.287041]
2023-05-17 19:21:52.690: epoch 12:	0.01836749  	0.13543622  	0.06786124  
2023-05-17 19:22:02.333: [iter 13 : loss : 0.4545 = 0.3524 + 0.1014 + 0.0007, time: 9.642027]
2023-05-17 19:22:02.515: epoch 13:	0.01832514  	0.13571757  	0.06834034  
2023-05-17 19:22:12.368: [iter 14 : loss : 0.4162 = 0.3131 + 0.1023 + 0.0008, time: 9.849991]
2023-05-17 19:22:12.527: epoch 14:	0.01867797  	0.13856031  	0.06951670  
2023-05-17 19:22:12.527: Find a better model.
2023-05-17 19:22:21.667: [iter 15 : loss : 0.3895 = 0.2858 + 0.1027 + 0.0010, time: 9.136994]
2023-05-17 19:22:22.602: epoch 15:	0.01887555  	0.13979752  	0.07038355  
2023-05-17 19:22:22.602: Find a better model.
2023-05-17 19:22:31.127: [iter 16 : loss : 0.3670 = 0.2632 + 0.1027 + 0.0011, time: 8.522132]
2023-05-17 19:22:31.289: epoch 16:	0.01919309  	0.14175220  	0.07120413  
2023-05-17 19:22:31.289: Find a better model.
2023-05-17 19:22:41.969: [iter 17 : loss : 0.3505 = 0.2469 + 0.1025 + 0.0012, time: 10.675473]
2023-05-17 19:22:42.291: epoch 17:	0.01939773  	0.14331679  	0.07210495  
2023-05-17 19:22:42.291: Find a better model.
2023-05-17 19:22:51.690: [iter 18 : loss : 0.3352 = 0.2316 + 0.1023 + 0.0013, time: 9.397518]
2023-05-17 19:22:51.872: epoch 18:	0.01958120  	0.14467928  	0.07278575  
2023-05-17 19:22:51.873: Find a better model.
2023-05-17 19:23:02.069: [iter 19 : loss : 0.3209 = 0.2176 + 0.1019 + 0.0014, time: 10.194003]
2023-05-17 19:23:02.293: epoch 19:	0.01972938  	0.14543566  	0.07344851  
2023-05-17 19:23:02.293: Find a better model.
2023-05-17 19:23:12.563: [iter 20 : loss : 0.3113 = 0.2084 + 0.1014 + 0.0015, time: 10.264497]
2023-05-17 19:23:12.844: epoch 20:	0.01993403  	0.14681093  	0.07436337  
2023-05-17 19:23:12.844: Find a better model.
2023-05-17 19:23:21.919: [iter 21 : loss : 0.3017 = 0.1990 + 0.1011 + 0.0016, time: 9.073003]
2023-05-17 19:23:22.087: epoch 21:	0.02016689  	0.14880019  	0.07528028  
2023-05-17 19:23:22.087: Find a better model.
2023-05-17 19:23:32.603: [iter 22 : loss : 0.2932 = 0.1910 + 0.1006 + 0.0016, time: 10.513018]
2023-05-17 19:23:32.948: epoch 22:	0.02033625  	0.15024033  	0.07614367  
2023-05-17 19:23:32.948: Find a better model.
2023-05-17 19:23:41.644: [iter 23 : loss : 0.2850 = 0.1830 + 0.1002 + 0.0017, time: 8.692857]
2023-05-17 19:23:42.024: epoch 23:	0.02047033  	0.15133007  	0.07692926  
2023-05-17 19:23:42.024: Find a better model.
2023-05-17 19:23:51.401: [iter 24 : loss : 0.2786 = 0.1770 + 0.0998 + 0.0018, time: 9.374011]
2023-05-17 19:23:51.570: epoch 24:	0.02072436  	0.15298337  	0.07776413  
2023-05-17 19:23:51.570: Find a better model.
2023-05-17 19:24:01.746: [iter 25 : loss : 0.2719 = 0.1706 + 0.0994 + 0.0019, time: 10.173199]
2023-05-17 19:24:02.045: epoch 25:	0.02077376  	0.15358093  	0.07827973  
2023-05-17 19:24:02.046: Find a better model.
2023-05-17 19:24:11.076: [iter 26 : loss : 0.2682 = 0.1673 + 0.0990 + 0.0019, time: 9.029013]
2023-05-17 19:24:11.324: epoch 26:	0.02099956  	0.15491253  	0.07905497  
2023-05-17 19:24:11.325: Find a better model.
2023-05-17 19:24:21.238: [iter 27 : loss : 0.2605 = 0.1600 + 0.0985 + 0.0020, time: 9.909474]
2023-05-17 19:24:21.541: epoch 27:	0.02117598  	0.15633456  	0.08000891  
2023-05-17 19:24:21.541: Find a better model.
2023-05-17 19:24:30.262: [iter 28 : loss : 0.2557 = 0.1555 + 0.0982 + 0.0021, time: 8.720068]
2023-05-17 19:24:30.452: epoch 28:	0.02138768  	0.15789247  	0.08101464  
2023-05-17 19:24:30.452: Find a better model.
2023-05-17 19:24:39.704: [iter 29 : loss : 0.2509 = 0.1512 + 0.0976 + 0.0021, time: 9.250992]
2023-05-17 19:24:39.866: epoch 29:	0.02154998  	0.15878871  	0.08175322  
2023-05-17 19:24:39.866: Find a better model.
2023-05-17 19:24:49.544: [iter 30 : loss : 0.2444 = 0.1448 + 0.0974 + 0.0022, time: 9.675659]
2023-05-17 19:24:49.706: epoch 30:	0.02174756  	0.16072117  	0.08261839  
2023-05-17 19:24:49.706: Find a better model.
2023-05-17 19:24:58.349: [iter 31 : loss : 0.2410 = 0.1418 + 0.0969 + 0.0023, time: 8.642003]
2023-05-17 19:24:58.506: epoch 31:	0.02201571  	0.16276023  	0.08349957  
2023-05-17 19:24:58.506: Find a better model.
2023-05-17 19:25:08.446: [iter 32 : loss : 0.2352 = 0.1363 + 0.0966 + 0.0023, time: 9.929380]
2023-05-17 19:25:08.766: epoch 32:	0.02210038  	0.16338927  	0.08404415  
2023-05-17 19:25:08.766: Find a better model.
2023-05-17 19:25:17.720: [iter 33 : loss : 0.2327 = 0.1341 + 0.0962 + 0.0024, time: 8.944484]
2023-05-17 19:25:17.988: epoch 33:	0.02234030  	0.16509797  	0.08477579  
2023-05-17 19:25:17.989: Find a better model.
2023-05-17 19:25:27.279: [iter 34 : loss : 0.2286 = 0.1303 + 0.0958 + 0.0024, time: 9.289521]
2023-05-17 19:25:27.441: epoch 34:	0.02234736  	0.16544446  	0.08508445  
2023-05-17 19:25:27.441: Find a better model.
2023-05-17 19:25:36.696: [iter 35 : loss : 0.2250 = 0.1270 + 0.0956 + 0.0025, time: 9.252008]
2023-05-17 19:25:37.076: epoch 35:	0.02251671  	0.16661035  	0.08581007  
2023-05-17 19:25:37.076: Find a better model.
2023-05-17 19:25:45.601: [iter 36 : loss : 0.2218 = 0.1240 + 0.0953 + 0.0025, time: 8.522223]
2023-05-17 19:25:45.929: epoch 36:	0.02265079  	0.16783157  	0.08642930  
2023-05-17 19:25:45.929: Find a better model.
2023-05-17 19:25:55.620: [iter 37 : loss : 0.2180 = 0.1205 + 0.0949 + 0.0026, time: 9.688028]
2023-05-17 19:25:55.920: epoch 37:	0.02279192  	0.16916065  	0.08708435  
2023-05-17 19:25:55.920: Find a better model.
2023-05-17 19:26:05.301: [iter 38 : loss : 0.2162 = 0.1189 + 0.0946 + 0.0026, time: 9.379012]
2023-05-17 19:26:05.593: epoch 38:	0.02289071  	0.16955186  	0.08759318  
2023-05-17 19:26:05.593: Find a better model.
2023-05-17 19:26:15.232: [iter 39 : loss : 0.2116 = 0.1146 + 0.0943 + 0.0027, time: 9.637243]
2023-05-17 19:26:15.393: epoch 39:	0.02310240  	0.17140685  	0.08859641  
2023-05-17 19:26:15.393: Find a better model.
2023-05-17 19:26:24.574: [iter 40 : loss : 0.2084 = 0.1116 + 0.0940 + 0.0028, time: 9.178992]
2023-05-17 19:26:25.080: epoch 40:	0.02316592  	0.17174910  	0.08899521  
2023-05-17 19:26:25.080: Find a better model.
2023-05-17 19:26:33.626: [iter 41 : loss : 0.2068 = 0.1103 + 0.0937 + 0.0028, time: 8.545055]
2023-05-17 19:26:33.916: epoch 41:	0.02327882  	0.17262584  	0.08955214  
2023-05-17 19:26:33.916: Find a better model.
2023-05-17 19:26:43.592: [iter 42 : loss : 0.2044 = 0.1082 + 0.0934 + 0.0029, time: 9.673149]
2023-05-17 19:26:43.906: epoch 42:	0.02341995  	0.17351599  	0.09031896  
2023-05-17 19:26:43.906: Find a better model.
2023-05-17 19:26:53.539: [iter 43 : loss : 0.2008 = 0.1048 + 0.0931 + 0.0029, time: 9.626044]
2023-05-17 19:26:53.817: epoch 43:	0.02344112  	0.17346160  	0.09055964  
2023-05-17 19:27:03.279: [iter 44 : loss : 0.1971 = 0.1013 + 0.0929 + 0.0030, time: 9.460608]
2023-05-17 19:27:03.439: epoch 44:	0.02344112  	0.17359437  	0.09092991  
2023-05-17 19:27:03.439: Find a better model.
2023-05-17 19:27:12.912: [iter 45 : loss : 0.1951 = 0.0994 + 0.0926 + 0.0030, time: 9.471002]
2023-05-17 19:27:13.502: epoch 45:	0.02359636  	0.17450605  	0.09147623  
2023-05-17 19:27:13.502: Find a better model.
2023-05-17 19:27:22.266: [iter 46 : loss : 0.1926 = 0.0971 + 0.0924 + 0.0031, time: 8.763101]
2023-05-17 19:27:22.421: epoch 46:	0.02360342  	0.17518263  	0.09192965  
2023-05-17 19:27:22.421: Find a better model.
2023-05-17 19:27:32.354: [iter 47 : loss : 0.1919 = 0.0966 + 0.0922 + 0.0031, time: 9.923201]
2023-05-17 19:27:32.673: epoch 47:	0.02378688  	0.17649935  	0.09267416  
2023-05-17 19:27:32.673: Find a better model.
2023-05-17 19:27:41.825: [iter 48 : loss : 0.1882 = 0.0932 + 0.0919 + 0.0032, time: 9.151024]
2023-05-17 19:27:42.082: epoch 48:	0.02389979  	0.17745996  	0.09315320  
2023-05-17 19:27:42.082: Find a better model.
2023-05-17 19:27:51.439: [iter 49 : loss : 0.1850 = 0.0902 + 0.0917 + 0.0032, time: 9.355552]
2023-05-17 19:27:51.600: epoch 49:	0.02399858  	0.17820600  	0.09373170  
2023-05-17 19:27:51.600: Find a better model.
2023-05-17 19:28:01.350: [iter 50 : loss : 0.1842 = 0.0894 + 0.0915 + 0.0033, time: 9.748809]
2023-05-17 19:28:01.580: epoch 50:	0.02405503  	0.17853031  	0.09399062  
2023-05-17 19:28:01.580: Find a better model.
2023-05-17 19:28:10.326: [iter 51 : loss : 0.1809 = 0.0863 + 0.0912 + 0.0033, time: 8.744002]
2023-05-17 19:28:10.479: epoch 51:	0.02409738  	0.17890008  	0.09435007  
2023-05-17 19:28:10.479: Find a better model.
2023-05-17 19:28:20.088: [iter 52 : loss : 0.1809 = 0.0865 + 0.0911 + 0.0034, time: 9.597024]
2023-05-17 19:28:20.439: epoch 52:	0.02417500  	0.17929748  	0.09504747  
2023-05-17 19:28:20.440: Find a better model.
2023-05-17 19:28:29.599: [iter 53 : loss : 0.1790 = 0.0848 + 0.0908 + 0.0034, time: 9.152618]
2023-05-17 19:28:29.889: epoch 53:	0.02429496  	0.17974305  	0.09538059  
2023-05-17 19:28:29.890: Find a better model.
2023-05-17 19:28:39.397: [iter 54 : loss : 0.1768 = 0.0827 + 0.0907 + 0.0034, time: 9.504520]
2023-05-17 19:28:39.560: epoch 54:	0.02430906  	0.18001877  	0.09563267  
2023-05-17 19:28:39.560: Find a better model.
2023-05-17 19:28:48.802: [iter 55 : loss : 0.1749 = 0.0810 + 0.0904 + 0.0035, time: 9.240981]
2023-05-17 19:28:49.324: epoch 55:	0.02433729  	0.18027185  	0.09600451  
2023-05-17 19:28:49.324: Find a better model.
2023-05-17 19:28:57.852: [iter 56 : loss : 0.1732 = 0.0794 + 0.0903 + 0.0035, time: 8.526018]
2023-05-17 19:28:58.041: epoch 56:	0.02449253  	0.18102825  	0.09651553  
2023-05-17 19:28:58.041: Find a better model.
2023-05-17 19:29:07.819: [iter 57 : loss : 0.1712 = 0.0775 + 0.0901 + 0.0036, time: 9.776034]
2023-05-17 19:29:08.126: epoch 57:	0.02458426  	0.18166421  	0.09691757  
2023-05-17 19:29:08.126: Find a better model.
2023-05-17 19:29:17.443: [iter 58 : loss : 0.1695 = 0.0760 + 0.0899 + 0.0036, time: 9.315093]
2023-05-17 19:29:17.749: epoch 58:	0.02466189  	0.18252292  	0.09729114  
2023-05-17 19:29:17.749: Find a better model.
2023-05-17 19:29:27.387: [iter 59 : loss : 0.1682 = 0.0748 + 0.0897 + 0.0037, time: 9.637189]
2023-05-17 19:29:27.551: epoch 59:	0.02473951  	0.18360673  	0.09781293  
2023-05-17 19:29:27.551: Find a better model.
2023-05-17 19:29:36.778: [iter 60 : loss : 0.1671 = 0.0738 + 0.0896 + 0.0037, time: 9.226099]
2023-05-17 19:29:37.299: epoch 60:	0.02490180  	0.18458208  	0.09832603  
2023-05-17 19:29:37.299: Find a better model.
2023-05-17 19:29:45.875: [iter 61 : loss : 0.1653 = 0.0722 + 0.0894 + 0.0038, time: 8.575012]
2023-05-17 19:29:46.037: epoch 61:	0.02490886  	0.18447864  	0.09857757  
2023-05-17 19:29:56.127: [iter 62 : loss : 0.1638 = 0.0708 + 0.0892 + 0.0038, time: 10.081989]
2023-05-17 19:29:56.398: epoch 62:	0.02497236  	0.18497147  	0.09885331  
2023-05-17 19:29:56.398: Find a better model.
2023-05-17 19:30:05.643: [iter 63 : loss : 0.1624 = 0.0695 + 0.0891 + 0.0039, time: 9.243977]
2023-05-17 19:30:05.917: epoch 63:	0.02493003  	0.18469262  	0.09884579  
2023-05-17 19:30:15.380: [iter 64 : loss : 0.1615 = 0.0687 + 0.0889 + 0.0039, time: 9.461572]
2023-05-17 19:30:15.541: epoch 64:	0.02496531  	0.18512511  	0.09909660  
2023-05-17 19:30:15.541: Find a better model.
2023-05-17 19:30:24.926: [iter 65 : loss : 0.1605 = 0.0678 + 0.0887 + 0.0039, time: 9.382001]
2023-05-17 19:30:25.487: epoch 65:	0.02500059  	0.18519033  	0.09926456  
2023-05-17 19:30:25.487: Find a better model.
2023-05-17 19:30:34.194: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 8.706003]
2023-05-17 19:30:34.359: epoch 66:	0.02506410  	0.18570194  	0.09963442  
2023-05-17 19:30:34.360: Find a better model.
2023-05-17 19:30:44.345: [iter 67 : loss : 0.1570 = 0.0645 + 0.0885 + 0.0040, time: 9.977022]
2023-05-17 19:30:44.686: epoch 67:	0.02513467  	0.18617235  	0.09995173  
2023-05-17 19:30:44.686: Find a better model.
2023-05-17 19:30:53.988: [iter 68 : loss : 0.1568 = 0.0644 + 0.0883 + 0.0041, time: 9.299343]
2023-05-17 19:30:54.270: epoch 68:	0.02524757  	0.18712221  	0.10049603  
2023-05-17 19:30:54.270: Find a better model.
2023-05-17 19:31:03.757: [iter 69 : loss : 0.1549 = 0.0627 + 0.0881 + 0.0041, time: 9.486026]
2023-05-17 19:31:03.920: epoch 69:	0.02531813  	0.18750896  	0.10080652  
2023-05-17 19:31:03.920: Find a better model.
2023-05-17 19:31:13.563: [iter 70 : loss : 0.1532 = 0.0610 + 0.0880 + 0.0041, time: 9.642002]
2023-05-17 19:31:13.727: epoch 70:	0.02534636  	0.18755992  	0.10104724  
2023-05-17 19:31:13.727: Find a better model.
2023-05-17 19:31:22.415: [iter 71 : loss : 0.1518 = 0.0596 + 0.0879 + 0.0042, time: 8.686016]
2023-05-17 19:31:22.585: epoch 71:	0.02538164  	0.18738529  	0.10114197  
2023-05-17 19:31:32.605: [iter 72 : loss : 0.1516 = 0.0596 + 0.0878 + 0.0042, time: 10.017003]
2023-05-17 19:31:32.921: epoch 72:	0.02538871  	0.18729568  	0.10129102  
2023-05-17 19:31:41.971: [iter 73 : loss : 0.1501 = 0.0581 + 0.0877 + 0.0043, time: 9.040024]
2023-05-17 19:31:42.234: epoch 73:	0.02539576  	0.18761554  	0.10151380  
2023-05-17 19:31:42.235: Find a better model.
2023-05-17 19:31:51.529: [iter 74 : loss : 0.1489 = 0.0571 + 0.0876 + 0.0043, time: 9.293028]
2023-05-17 19:31:51.692: epoch 74:	0.02550866  	0.18831047  	0.10190958  
2023-05-17 19:31:51.692: Find a better model.
2023-05-17 19:32:01.136: [iter 75 : loss : 0.1483 = 0.0565 + 0.0874 + 0.0044, time: 9.442001]
2023-05-17 19:32:01.461: epoch 75:	0.02550160  	0.18820794  	0.10223232  
2023-05-17 19:32:10.416: [iter 76 : loss : 0.1472 = 0.0555 + 0.0873 + 0.0044, time: 8.952025]
2023-05-17 19:32:10.576: epoch 76:	0.02546632  	0.18821885  	0.10231632  
2023-05-17 19:32:20.627: [iter 77 : loss : 0.1463 = 0.0547 + 0.0872 + 0.0044, time: 10.048377]
2023-05-17 19:32:20.948: epoch 77:	0.02551571  	0.18848053  	0.10228161  
2023-05-17 19:32:20.948: Find a better model.
2023-05-17 19:32:30.065: [iter 78 : loss : 0.1455 = 0.0539 + 0.0871 + 0.0045, time: 9.105007]
2023-05-17 19:32:30.341: epoch 78:	0.02558628  	0.18894619  	0.10269501  
2023-05-17 19:32:30.341: Find a better model.
2023-05-17 19:32:39.900: [iter 79 : loss : 0.1442 = 0.0527 + 0.0870 + 0.0045, time: 9.556992]
2023-05-17 19:32:40.060: epoch 79:	0.02565684  	0.18944113  	0.10296649  
2023-05-17 19:32:40.060: Find a better model.
2023-05-17 19:32:50.155: [iter 80 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0046, time: 10.092991]
2023-05-17 19:32:50.456: epoch 80:	0.02560745  	0.18884286  	0.10287195  
2023-05-17 19:32:59.400: [iter 81 : loss : 0.1431 = 0.0518 + 0.0868 + 0.0046, time: 8.943002]
2023-05-17 19:32:59.642: epoch 81:	0.02561450  	0.18887489  	0.10300860  
2023-05-17 19:33:09.743: [iter 82 : loss : 0.1417 = 0.0504 + 0.0867 + 0.0046, time: 10.096011]
2023-05-17 19:33:10.055: epoch 82:	0.02565684  	0.18910752  	0.10313580  
2023-05-17 19:33:18.698: [iter 83 : loss : 0.1409 = 0.0497 + 0.0866 + 0.0047, time: 8.641013]
2023-05-17 19:33:18.893: epoch 83:	0.02564978  	0.18897733  	0.10328218  
2023-05-17 19:33:28.303: [iter 84 : loss : 0.1406 = 0.0495 + 0.0865 + 0.0047, time: 9.408992]
2023-05-17 19:33:28.467: epoch 84:	0.02571329  	0.18977202  	0.10352702  
2023-05-17 19:33:28.467: Find a better model.
2023-05-17 19:33:38.457: [iter 85 : loss : 0.1396 = 0.0485 + 0.0863 + 0.0047, time: 9.984020]
2023-05-17 19:33:38.753: epoch 85:	0.02569918  	0.18976264  	0.10356160  
2023-05-17 19:33:47.575: [iter 86 : loss : 0.1395 = 0.0485 + 0.0862 + 0.0048, time: 8.821002]
2023-05-17 19:33:47.814: epoch 86:	0.02566389  	0.18978627  	0.10397401  
2023-05-17 19:33:47.814: Find a better model.
2023-05-17 19:33:57.917: [iter 87 : loss : 0.1367 = 0.0458 + 0.0861 + 0.0048, time: 10.100023]
2023-05-17 19:33:58.214: epoch 87:	0.02574857  	0.19017608  	0.10415718  
2023-05-17 19:33:58.215: Find a better model.
2023-05-17 19:34:06.845: [iter 88 : loss : 0.1358 = 0.0448 + 0.0861 + 0.0049, time: 8.629005]
2023-05-17 19:34:07.030: epoch 88:	0.02579797  	0.19094096  	0.10443564  
2023-05-17 19:34:07.030: Find a better model.
2023-05-17 19:34:16.262: [iter 89 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 9.230005]
2023-05-17 19:34:16.426: epoch 89:	0.02579091  	0.19085670  	0.10443828  
2023-05-17 19:34:26.431: [iter 90 : loss : 0.1364 = 0.0455 + 0.0859 + 0.0049, time: 10.003017]
2023-05-17 19:34:26.721: epoch 90:	0.02582619  	0.19104035  	0.10474974  
2023-05-17 19:34:26.721: Find a better model.
2023-05-17 19:34:35.593: [iter 91 : loss : 0.1351 = 0.0443 + 0.0858 + 0.0050, time: 8.870007]
2023-05-17 19:34:35.804: epoch 91:	0.02576974  	0.19043733  	0.10478289  
2023-05-17 19:34:45.879: [iter 92 : loss : 0.1342 = 0.0434 + 0.0858 + 0.0050, time: 10.070002]
2023-05-17 19:34:46.144: epoch 92:	0.02578385  	0.19056788  	0.10487161  
2023-05-17 19:34:54.674: [iter 93 : loss : 0.1343 = 0.0437 + 0.0856 + 0.0050, time: 8.526811]
2023-05-17 19:34:54.951: epoch 93:	0.02580502  	0.19057426  	0.10500922  
2023-05-17 19:35:04.260: [iter 94 : loss : 0.1323 = 0.0416 + 0.0856 + 0.0051, time: 9.290059]
2023-05-17 19:35:04.422: epoch 94:	0.02581208  	0.19063418  	0.10488687  
2023-05-17 19:35:15.310: [iter 95 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 10.882989]
2023-05-17 19:35:15.698: epoch 95:	0.02581208  	0.19050653  	0.10512954  
2023-05-17 19:35:26.061: [iter 96 : loss : 0.1316 = 0.0410 + 0.0854 + 0.0052, time: 10.360575]
2023-05-17 19:35:26.381: epoch 96:	0.02587559  	0.19076735  	0.10529101  
2023-05-17 19:35:37.046: [iter 97 : loss : 0.1301 = 0.0395 + 0.0853 + 0.0052, time: 10.663011]
2023-05-17 19:35:37.377: epoch 97:	0.02590382  	0.19104703  	0.10533643  
2023-05-17 19:35:37.377: Find a better model.
2023-05-17 19:35:46.578: [iter 98 : loss : 0.1310 = 0.0405 + 0.0853 + 0.0052, time: 9.200000]
2023-05-17 19:35:46.756: epoch 98:	0.02582619  	0.19029985  	0.10541471  
2023-05-17 19:35:55.526: [iter 99 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 8.768035]
2023-05-17 19:35:55.705: epoch 99:	0.02593204  	0.19105013  	0.10546456  
2023-05-17 19:35:55.706: Find a better model.
2023-05-17 19:36:05.964: [iter 100 : loss : 0.1292 = 0.0387 + 0.0851 + 0.0053, time: 10.257013]
2023-05-17 19:36:06.289: epoch 100:	0.02598143  	0.19117758  	0.10583704  
2023-05-17 19:36:06.289: Find a better model.
2023-05-17 19:36:16.669: [iter 101 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 10.376109]
2023-05-17 19:36:16.981: epoch 101:	0.02595321  	0.19113201  	0.10591427  
2023-05-17 19:36:27.615: [iter 102 : loss : 0.1278 = 0.0374 + 0.0850 + 0.0054, time: 10.633023]
2023-05-17 19:36:27.915: epoch 102:	0.02597438  	0.19138275  	0.10613240  
2023-05-17 19:36:27.915: Find a better model.
2023-05-17 19:36:37.432: [iter 103 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 9.515004]
2023-05-17 19:36:37.594: epoch 103:	0.02597438  	0.19147703  	0.10644373  
2023-05-17 19:36:37.594: Find a better model.
2023-05-17 19:36:47.569: [iter 104 : loss : 0.1282 = 0.0379 + 0.0848 + 0.0054, time: 9.973991]
2023-05-17 19:36:47.730: epoch 104:	0.02604495  	0.19222733  	0.10658429  
2023-05-17 19:36:47.731: Find a better model.
2023-05-17 19:36:56.666: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 8.934318]
2023-05-17 19:36:56.898: epoch 105:	0.02608023  	0.19239783  	0.10680389  
2023-05-17 19:36:56.898: Find a better model.
2023-05-17 19:37:06.902: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 9.998017]
2023-05-17 19:37:07.200: epoch 106:	0.02605906  	0.19217572  	0.10681020  
2023-05-17 19:37:17.451: [iter 107 : loss : 0.1257 = 0.0356 + 0.0846 + 0.0055, time: 10.249035]
2023-05-17 19:37:17.741: epoch 107:	0.02605201  	0.19198838  	0.10659956  
2023-05-17 19:37:27.657: [iter 108 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 9.913993]
2023-05-17 19:37:27.839: epoch 108:	0.02606612  	0.19231331  	0.10670700  
2023-05-17 19:37:37.434: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 9.591120]
2023-05-17 19:37:37.596: epoch 109:	0.02612256  	0.19265465  	0.10677972  
2023-05-17 19:37:37.596: Find a better model.
2023-05-17 19:37:46.519: [iter 110 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0056, time: 8.922006]
2023-05-17 19:37:46.679: epoch 110:	0.02605906  	0.19239902  	0.10692091  
2023-05-17 19:37:56.696: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 10.014005]
2023-05-17 19:37:57.021: epoch 111:	0.02616490  	0.19293332  	0.10697900  
2023-05-17 19:37:57.021: Find a better model.
2023-05-17 19:38:07.268: [iter 112 : loss : 0.1237 = 0.0336 + 0.0843 + 0.0057, time: 10.244815]
2023-05-17 19:38:07.569: epoch 112:	0.02620018  	0.19326159  	0.10709599  
2023-05-17 19:38:07.570: Find a better model.
2023-05-17 19:38:17.006: [iter 113 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0057, time: 9.435171]
2023-05-17 19:38:17.243: epoch 113:	0.02614373  	0.19259186  	0.10703176  
2023-05-17 19:38:27.010: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 9.760044]
2023-05-17 19:38:27.496: epoch 114:	0.02621430  	0.19301370  	0.10719902  
2023-05-17 19:38:36.660: [iter 115 : loss : 0.1219 = 0.0319 + 0.0842 + 0.0058, time: 9.162003]
2023-05-17 19:38:36.832: epoch 115:	0.02627075  	0.19356354  	0.10740770  
2023-05-17 19:38:36.832: Find a better model.
2023-05-17 19:38:47.070: [iter 116 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0058, time: 10.235015]
2023-05-17 19:38:47.410: epoch 116:	0.02627075  	0.19343939  	0.10754818  
2023-05-17 19:38:57.513: [iter 117 : loss : 0.1209 = 0.0309 + 0.0841 + 0.0059, time: 10.099025]
2023-05-17 19:38:57.831: epoch 117:	0.02629898  	0.19380453  	0.10763352  
2023-05-17 19:38:57.831: Find a better model.
2023-05-17 19:39:07.414: [iter 118 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 9.582012]
2023-05-17 19:39:07.583: epoch 118:	0.02629898  	0.19369312  	0.10784653  
2023-05-17 19:39:16.919: [iter 119 : loss : 0.1198 = 0.0299 + 0.0839 + 0.0059, time: 9.333100]
2023-05-17 19:39:17.387: epoch 119:	0.02632015  	0.19377489  	0.10787295  
2023-05-17 19:39:26.697: [iter 120 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0060, time: 9.308182]
2023-05-17 19:39:26.857: epoch 120:	0.02630604  	0.19418932  	0.10820223  
2023-05-17 19:39:26.857: Find a better model.
2023-05-17 19:39:36.972: [iter 121 : loss : 0.1201 = 0.0302 + 0.0838 + 0.0060, time: 10.112018]
2023-05-17 19:39:37.314: epoch 121:	0.02625664  	0.19372544  	0.10817228  
2023-05-17 19:39:47.337: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 10.020924]
2023-05-17 19:39:47.653: epoch 122:	0.02629192  	0.19360693  	0.10817904  
2023-05-17 19:39:57.189: [iter 123 : loss : 0.1194 = 0.0296 + 0.0837 + 0.0061, time: 9.533439]
2023-05-17 19:39:57.360: epoch 123:	0.02619313  	0.19307999  	0.10801642  
2023-05-17 19:40:07.008: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 9.646017]
2023-05-17 19:40:07.253: epoch 124:	0.02621430  	0.19312194  	0.10810767  
2023-05-17 19:40:16.263: [iter 125 : loss : 0.1179 = 0.0281 + 0.0837 + 0.0061, time: 9.007014]
2023-05-17 19:40:16.422: epoch 125:	0.02620724  	0.19289126  	0.10799411  
2023-05-17 19:40:26.236: [iter 126 : loss : 0.1179 = 0.0282 + 0.0836 + 0.0062, time: 9.812001]
2023-05-17 19:40:26.577: epoch 126:	0.02618607  	0.19298479  	0.10799305  
2023-05-17 19:40:36.456: [iter 127 : loss : 0.1169 = 0.0271 + 0.0835 + 0.0062, time: 9.876188]
2023-05-17 19:40:36.775: epoch 127:	0.02632014  	0.19373834  	0.10825953  
2023-05-17 19:40:46.168: [iter 128 : loss : 0.1180 = 0.0282 + 0.0835 + 0.0062, time: 9.391510]
2023-05-17 19:40:46.334: epoch 128:	0.02635542  	0.19382003  	0.10833063  
2023-05-17 19:40:54.792: [iter 129 : loss : 0.1170 = 0.0272 + 0.0835 + 0.0063, time: 8.455007]
2023-05-17 19:40:54.971: epoch 129:	0.02639071  	0.19408947  	0.10840268  
2023-05-17 19:41:03.946: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 8.972404]
2023-05-17 19:41:04.115: epoch 130:	0.02646832  	0.19445159  	0.10867741  
2023-05-17 19:41:04.116: Find a better model.
2023-05-17 19:41:14.044: [iter 131 : loss : 0.1162 = 0.0265 + 0.0834 + 0.0063, time: 9.923907]
2023-05-17 19:41:14.417: epoch 131:	0.02645421  	0.19452888  	0.10874511  
2023-05-17 19:41:14.417: Find a better model.
2023-05-17 19:41:24.464: [iter 132 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0063, time: 10.045162]
2023-05-17 19:41:24.787: epoch 132:	0.02647538  	0.19454947  	0.10873319  
2023-05-17 19:41:24.787: Find a better model.
2023-05-17 19:41:33.868: [iter 133 : loss : 0.1154 = 0.0257 + 0.0833 + 0.0064, time: 9.079194]
2023-05-17 19:41:34.085: epoch 133:	0.02641187  	0.19384223  	0.10848396  
2023-05-17 19:41:42.515: [iter 134 : loss : 0.1160 = 0.0263 + 0.0832 + 0.0064, time: 8.404014]
2023-05-17 19:41:42.692: epoch 134:	0.02640481  	0.19382185  	0.10866521  
2023-05-17 19:41:52.952: [iter 135 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 10.256070]
2023-05-17 19:41:53.260: epoch 135:	0.02633424  	0.19316138  	0.10852151  
2023-05-17 19:42:03.338: [iter 136 : loss : 0.1152 = 0.0256 + 0.0831 + 0.0065, time: 10.072002]
2023-05-17 19:42:03.635: epoch 136:	0.02642598  	0.19383880  	0.10882004  
2023-05-17 19:42:14.046: [iter 137 : loss : 0.1149 = 0.0253 + 0.0831 + 0.0065, time: 10.407527]
2023-05-17 19:42:14.365: epoch 137:	0.02635542  	0.19369711  	0.10870724  
2023-05-17 19:42:22.916: [iter 138 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 8.548001]
2023-05-17 19:42:23.191: epoch 138:	0.02641186  	0.19398405  	0.10887145  
2023-05-17 19:42:32.084: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 8.891991]
2023-05-17 19:42:32.337: epoch 139:	0.02644009  	0.19434911  	0.10902870  
2023-05-17 19:42:42.591: [iter 140 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 10.252265]
2023-05-17 19:42:42.860: epoch 140:	0.02646126  	0.19437581  	0.10910361  
2023-05-17 19:42:53.077: [iter 141 : loss : 0.1144 = 0.0249 + 0.0829 + 0.0066, time: 10.214014]
2023-05-17 19:42:53.392: epoch 141:	0.02639776  	0.19391534  	0.10889775  
2023-05-17 19:43:04.077: [iter 142 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0066, time: 10.683033]
2023-05-17 19:43:04.407: epoch 142:	0.02635542  	0.19371164  	0.10883540  
2023-05-17 19:43:13.350: [iter 143 : loss : 0.1136 = 0.0240 + 0.0829 + 0.0067, time: 8.940109]
2023-05-17 19:43:13.864: epoch 143:	0.02632719  	0.19358623  	0.10869786  
2023-05-17 19:43:22.394: [iter 144 : loss : 0.1129 = 0.0234 + 0.0829 + 0.0067, time: 8.516077]
2023-05-17 19:43:22.566: epoch 144:	0.02631308  	0.19352329  	0.10889079  
2023-05-17 19:43:32.532: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 9.956267]
2023-05-17 19:43:32.808: epoch 145:	0.02639070  	0.19397609  	0.10923351  
2023-05-17 19:43:42.997: [iter 146 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 10.186008]
2023-05-17 19:43:43.306: epoch 146:	0.02641892  	0.19391429  	0.10917380  
2023-05-17 19:43:53.893: [iter 147 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0068, time: 10.582038]
2023-05-17 19:43:54.215: epoch 147:	0.02648243  	0.19441272  	0.10933712  
2023-05-17 19:44:03.480: [iter 148 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 9.261100]
2023-05-17 19:44:03.752: epoch 148:	0.02655299  	0.19500460  	0.10960483  
2023-05-17 19:44:03.752: Find a better model.
2023-05-17 19:44:12.166: [iter 149 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 8.409203]
2023-05-17 19:44:12.336: epoch 149:	0.02660944  	0.19542460  	0.10969456  
2023-05-17 19:44:12.336: Find a better model.
2023-05-17 19:44:22.506: [iter 150 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0068, time: 10.169157]
2023-05-17 19:44:22.792: epoch 150:	0.02659533  	0.19517531  	0.10963102  
2023-05-17 19:44:32.910: [iter 151 : loss : 0.1118 = 0.0223 + 0.0826 + 0.0069, time: 10.114990]
2023-05-17 19:44:33.226: epoch 151:	0.02665883  	0.19539452  	0.10974848  
2023-05-17 19:44:43.740: [iter 152 : loss : 0.1110 = 0.0215 + 0.0826 + 0.0069, time: 10.511037]
2023-05-17 19:44:44.066: epoch 152:	0.02660238  	0.19513555  	0.10956144  
2023-05-17 19:44:53.222: [iter 153 : loss : 0.1102 = 0.0207 + 0.0825 + 0.0069, time: 9.155325]
2023-05-17 19:44:53.396: epoch 153:	0.02661649  	0.19536877  	0.10983791  
2023-05-17 19:45:01.819: [iter 154 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0069, time: 8.422021]
2023-05-17 19:45:02.014: epoch 154:	0.02665883  	0.19552356  	0.10990954  
2023-05-17 19:45:02.014: Find a better model.
2023-05-17 19:45:12.153: [iter 155 : loss : 0.1111 = 0.0216 + 0.0825 + 0.0070, time: 10.135512]
2023-05-17 19:45:12.480: epoch 155:	0.02653887  	0.19464605  	0.10966534  
2023-05-17 19:45:22.697: [iter 156 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 10.214006]
2023-05-17 19:45:23.014: epoch 156:	0.02659533  	0.19493525  	0.10957614  
2023-05-17 19:45:33.648: [iter 157 : loss : 0.1106 = 0.0211 + 0.0824 + 0.0070, time: 10.632034]
2023-05-17 19:45:33.971: epoch 157:	0.02653888  	0.19448873  	0.10946850  
2023-05-17 19:45:42.681: [iter 158 : loss : 0.1096 = 0.0202 + 0.0824 + 0.0070, time: 8.707009]
2023-05-17 19:45:43.204: epoch 158:	0.02656005  	0.19458051  	0.10959090  
2023-05-17 19:45:51.839: [iter 159 : loss : 0.1098 = 0.0204 + 0.0823 + 0.0071, time: 8.630329]
2023-05-17 19:45:52.037: epoch 159:	0.02660944  	0.19503698  	0.10952336  
2023-05-17 19:46:02.231: [iter 160 : loss : 0.1096 = 0.0202 + 0.0823 + 0.0071, time: 10.185017]
2023-05-17 19:46:02.494: epoch 160:	0.02652476  	0.19427036  	0.10955550  
2023-05-17 19:46:12.740: [iter 161 : loss : 0.1090 = 0.0196 + 0.0823 + 0.0071, time: 10.244451]
2023-05-17 19:46:13.058: epoch 161:	0.02651771  	0.19416535  	0.10929384  
2023-05-17 19:46:23.805: [iter 162 : loss : 0.1084 = 0.0190 + 0.0823 + 0.0071, time: 10.741570]
2023-05-17 19:46:24.137: epoch 162:	0.02649654  	0.19429716  	0.10937916  
2023-05-17 19:46:33.006: [iter 163 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 8.867105]
2023-05-17 19:46:33.587: epoch 163:	0.02649654  	0.19452320  	0.10945734  
2023-05-17 19:46:42.024: [iter 164 : loss : 0.1089 = 0.0195 + 0.0822 + 0.0072, time: 8.436026]
2023-05-17 19:46:42.260: epoch 164:	0.02648949  	0.19416346  	0.10941201  
2023-05-17 19:46:52.214: [iter 165 : loss : 0.1083 = 0.0189 + 0.0822 + 0.0072, time: 9.953012]
2023-05-17 19:46:52.474: epoch 165:	0.02637658  	0.19342273  	0.10899681  
2023-05-17 19:47:02.598: [iter 166 : loss : 0.1085 = 0.0191 + 0.0822 + 0.0072, time: 10.122027]
2023-05-17 19:47:02.909: epoch 166:	0.02643303  	0.19399978  	0.10909086  
2023-05-17 19:47:13.461: [iter 167 : loss : 0.1086 = 0.0192 + 0.0821 + 0.0073, time: 10.547066]
2023-05-17 19:47:13.781: epoch 167:	0.02645420  	0.19431929  	0.10921200  
2023-05-17 19:47:22.514: [iter 168 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 8.731017]
2023-05-17 19:47:22.815: epoch 168:	0.02645421  	0.19444102  	0.10922456  
2023-05-17 19:47:30.617: [iter 169 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 7.783154]
2023-05-17 19:47:30.789: epoch 169:	0.02637659  	0.19388825  	0.10930732  
2023-05-17 19:47:39.172: [iter 170 : loss : 0.1078 = 0.0184 + 0.0820 + 0.0073, time: 8.381210]
2023-05-17 19:47:39.327: epoch 170:	0.02641893  	0.19410226  	0.10948025  
2023-05-17 19:47:48.622: [iter 171 : loss : 0.1082 = 0.0188 + 0.0820 + 0.0074, time: 9.291929]
2023-05-17 19:47:48.909: epoch 171:	0.02642598  	0.19408293  	0.10947859  
2023-05-17 19:47:58.037: [iter 172 : loss : 0.1072 = 0.0178 + 0.0820 + 0.0074, time: 9.123267]
2023-05-17 19:47:58.358: epoch 172:	0.02648243  	0.19427793  	0.10959348  
2023-05-17 19:48:06.688: [iter 173 : loss : 0.1076 = 0.0183 + 0.0819 + 0.0074, time: 8.327996]
2023-05-17 19:48:06.867: epoch 173:	0.02648243  	0.19452313  	0.10954376  
2023-05-17 19:48:14.636: [iter 174 : loss : 0.1075 = 0.0181 + 0.0820 + 0.0074, time: 7.766128]
2023-05-17 19:48:14.813: epoch 174:	0.02643304  	0.19417261  	0.10952090  
2023-05-17 19:48:23.886: [iter 175 : loss : 0.1068 = 0.0174 + 0.0819 + 0.0075, time: 9.070971]
2023-05-17 19:48:24.053: epoch 175:	0.02639070  	0.19363356  	0.10936385  
2023-05-17 19:48:33.398: [iter 176 : loss : 0.1065 = 0.0171 + 0.0819 + 0.0075, time: 9.343477]
2023-05-17 19:48:33.707: epoch 176:	0.02636247  	0.19325499  	0.10933241  
2023-05-17 19:48:43.045: [iter 177 : loss : 0.1071 = 0.0177 + 0.0819 + 0.0075, time: 9.336119]
2023-05-17 19:48:43.345: epoch 177:	0.02635542  	0.19316086  	0.10920432  
2023-05-17 19:48:52.369: [iter 178 : loss : 0.1064 = 0.0170 + 0.0819 + 0.0075, time: 9.022700]
2023-05-17 19:48:52.576: epoch 178:	0.02632719  	0.19288725  	0.10918062  
2023-05-17 19:49:01.142: [iter 179 : loss : 0.1063 = 0.0169 + 0.0818 + 0.0075, time: 8.564032]
2023-05-17 19:49:01.309: epoch 179:	0.02631308  	0.19277057  	0.10916854  
2023-05-17 19:49:01.309: Early stopping is trigger at epoch: 179
2023-05-17 19:49:01.309: best_result@epoch 154:

2023-05-17 19:49:01.309: 		0.0267      	0.1955      	0.1099      
2023-05-17 19:56:00.525: my pid: 980
2023-05-17 19:56:00.525: model: model.general_recommender.SGL
2023-05-17 19:56:00.525: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 19:56:00.525: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 19:56:04.360: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 19:56:15.737: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 11.376525]
2023-05-17 19:56:16.053: epoch 1:	0.00134067  	0.01048289  	0.00480800  
2023-05-17 19:56:16.053: Find a better model.
2023-05-17 19:56:26.034: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 9.979162]
2023-05-17 19:56:26.475: epoch 2:	0.00251905  	0.01917381  	0.00910858  
2023-05-17 19:56:26.476: Find a better model.
2023-05-17 19:56:37.048: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 10.571318]
2023-05-17 19:56:37.235: epoch 3:	0.00448065  	0.03309398  	0.01544838  
2023-05-17 19:56:37.235: Find a better model.
2023-05-17 19:56:48.271: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 11.035306]
2023-05-17 19:56:48.558: epoch 4:	0.00765588  	0.05743320  	0.02690501  
2023-05-17 19:56:48.558: Find a better model.
2023-05-17 19:56:59.847: [iter 5 : loss : 0.7696 = 0.6909 + 0.0788 + 0.0000, time: 11.288020]
2023-05-17 19:57:00.145: epoch 5:	0.01158625  	0.08530689  	0.04078011  
2023-05-17 19:57:00.145: Find a better model.
2023-05-17 19:57:11.247: [iter 6 : loss : 0.7674 = 0.6883 + 0.0791 + 0.0000, time: 11.097004]
2023-05-17 19:57:11.551: epoch 6:	0.01515681  	0.10916159  	0.05319938  
2023-05-17 19:57:11.551: Find a better model.
2023-05-17 19:57:21.018: [iter 7 : loss : 0.7612 = 0.6814 + 0.0798 + 0.0000, time: 9.464020]
2023-05-17 19:57:21.292: epoch 7:	0.01764067  	0.12719704  	0.06302186  
2023-05-17 19:57:21.293: Find a better model.
2023-05-17 19:57:30.227: [iter 8 : loss : 0.7461 = 0.6643 + 0.0817 + 0.0001, time: 8.921749]
2023-05-17 19:57:30.396: epoch 8:	0.01898139  	0.13878995  	0.06884838  
2023-05-17 19:57:30.396: Find a better model.
2023-05-17 19:57:40.258: [iter 9 : loss : 0.7115 = 0.6259 + 0.0855 + 0.0001, time: 9.861526]
2023-05-17 19:57:40.790: epoch 9:	0.01884026  	0.13814153  	0.06905936  
2023-05-17 19:57:51.085: [iter 10 : loss : 0.6513 = 0.5601 + 0.0909 + 0.0002, time: 10.291032]
2023-05-17 19:57:51.730: epoch 10:	0.01862152  	0.13705796  	0.06869680  
2023-05-17 19:58:02.282: [iter 11 : loss : 0.5754 = 0.4790 + 0.0961 + 0.0004, time: 10.548126]
2023-05-17 19:58:02.611: epoch 11:	0.01857918  	0.13734253  	0.06836621  
2023-05-17 19:58:11.862: [iter 12 : loss : 0.5060 = 0.4059 + 0.0995 + 0.0005, time: 9.249023]
2023-05-17 19:58:12.110: epoch 12:	0.01846628  	0.13609610  	0.06809047  
2023-05-17 19:58:20.791: [iter 13 : loss : 0.4549 = 0.3527 + 0.1015 + 0.0007, time: 8.677003]
2023-05-17 19:58:20.960: epoch 13:	0.01843805  	0.13631599  	0.06847639  
2023-05-17 19:58:30.870: [iter 14 : loss : 0.4161 = 0.3129 + 0.1024 + 0.0008, time: 9.908002]
2023-05-17 19:58:31.073: epoch 14:	0.01868502  	0.13788554  	0.06950600  
2023-05-17 19:58:41.613: [iter 15 : loss : 0.3894 = 0.2856 + 0.1028 + 0.0010, time: 10.536516]
2023-05-17 19:58:41.970: epoch 15:	0.01892494  	0.13990377  	0.07049037  
2023-05-17 19:58:41.970: Find a better model.
2023-05-17 19:58:52.684: [iter 16 : loss : 0.3670 = 0.2631 + 0.1028 + 0.0011, time: 10.710127]
2023-05-17 19:58:53.010: epoch 16:	0.01913664  	0.14174303  	0.07159208  
2023-05-17 19:58:53.010: Find a better model.
2023-05-17 19:59:02.123: [iter 17 : loss : 0.3506 = 0.2467 + 0.1026 + 0.0012, time: 9.110054]
2023-05-17 19:59:02.497: epoch 17:	0.01944007  	0.14365427  	0.07243302  
2023-05-17 19:59:02.498: Find a better model.
2023-05-17 19:59:11.385: [iter 18 : loss : 0.3354 = 0.2318 + 0.1024 + 0.0013, time: 8.886014]
2023-05-17 19:59:11.546: epoch 18:	0.01958826  	0.14434670  	0.07301069  
2023-05-17 19:59:11.546: Find a better model.
2023-05-17 19:59:21.815: [iter 19 : loss : 0.3212 = 0.2178 + 0.1020 + 0.0014, time: 10.267612]
2023-05-17 19:59:22.019: epoch 19:	0.01972234  	0.14567688  	0.07371604  
2023-05-17 19:59:22.020: Find a better model.
2023-05-17 19:59:32.828: [iter 20 : loss : 0.3117 = 0.2086 + 0.1016 + 0.0015, time: 10.805257]
2023-05-17 19:59:33.193: epoch 20:	0.01987053  	0.14702629  	0.07437471  
2023-05-17 19:59:33.193: Find a better model.
2023-05-17 19:59:43.587: [iter 21 : loss : 0.3018 = 0.1991 + 0.1012 + 0.0016, time: 10.390325]
2023-05-17 19:59:43.915: epoch 21:	0.02008928  	0.14844890  	0.07526783  
2023-05-17 19:59:43.915: Find a better model.
2023-05-17 19:59:52.535: [iter 22 : loss : 0.2939 = 0.1914 + 0.1008 + 0.0016, time: 8.618512]
2023-05-17 19:59:52.718: epoch 22:	0.02020218  	0.14940360  	0.07577358  
2023-05-17 19:59:52.719: Find a better model.
2023-05-17 20:00:02.091: [iter 23 : loss : 0.2854 = 0.1833 + 0.1004 + 0.0017, time: 9.370482]
2023-05-17 20:00:02.304: epoch 23:	0.02040683  	0.15105140  	0.07659899  
2023-05-17 20:00:02.304: Find a better model.
2023-05-17 20:00:12.559: [iter 24 : loss : 0.2790 = 0.1772 + 0.1000 + 0.0018, time: 10.253263]
2023-05-17 20:00:12.842: epoch 24:	0.02063263  	0.15257423  	0.07751966  
2023-05-17 20:00:12.842: Find a better model.
2023-05-17 20:00:23.577: [iter 25 : loss : 0.2722 = 0.1708 + 0.0995 + 0.0019, time: 10.734011]
2023-05-17 20:00:23.867: epoch 25:	0.02078082  	0.15329342  	0.07811522  
2023-05-17 20:00:23.867: Find a better model.
2023-05-17 20:00:34.640: [iter 26 : loss : 0.2690 = 0.1679 + 0.0991 + 0.0019, time: 10.770116]
2023-05-17 20:00:34.964: epoch 26:	0.02098546  	0.15457070  	0.07878771  
2023-05-17 20:00:34.964: Find a better model.
2023-05-17 20:00:43.681: [iter 27 : loss : 0.2609 = 0.1602 + 0.0986 + 0.0020, time: 8.716024]
2023-05-17 20:00:43.842: epoch 27:	0.02123949  	0.15629171  	0.07980106  
2023-05-17 20:00:43.843: Find a better model.
2023-05-17 20:00:52.883: [iter 28 : loss : 0.2560 = 0.1558 + 0.0982 + 0.0021, time: 9.038410]
2023-05-17 20:00:53.066: epoch 28:	0.02138768  	0.15729655  	0.08052131  
2023-05-17 20:00:53.066: Find a better model.
2023-05-17 20:01:03.293: [iter 29 : loss : 0.2514 = 0.1515 + 0.0978 + 0.0021, time: 10.226002]
2023-05-17 20:01:03.656: epoch 29:	0.02145824  	0.15809876  	0.08081694  
2023-05-17 20:01:03.656: Find a better model.
2023-05-17 20:01:14.052: [iter 30 : loss : 0.2450 = 0.1454 + 0.0974 + 0.0022, time: 10.394002]
2023-05-17 20:01:14.342: epoch 30:	0.02162054  	0.15954114  	0.08142290  
2023-05-17 20:01:14.342: Find a better model.
2023-05-17 20:01:24.894: [iter 31 : loss : 0.2414 = 0.1422 + 0.0970 + 0.0022, time: 10.549011]
2023-05-17 20:01:25.202: epoch 31:	0.02183224  	0.16120964  	0.08225112  
2023-05-17 20:01:25.202: Find a better model.
2023-05-17 20:01:33.639: [iter 32 : loss : 0.2358 = 0.1368 + 0.0967 + 0.0023, time: 8.433993]
2023-05-17 20:01:33.820: epoch 32:	0.02209332  	0.16283385  	0.08341779  
2023-05-17 20:01:33.820: Find a better model.
2023-05-17 20:01:43.054: [iter 33 : loss : 0.2333 = 0.1346 + 0.0963 + 0.0024, time: 9.231942]
2023-05-17 20:01:43.264: epoch 33:	0.02228385  	0.16396591  	0.08412378  
2023-05-17 20:01:43.264: Find a better model.
2023-05-17 20:01:53.520: [iter 34 : loss : 0.2291 = 0.1308 + 0.0959 + 0.0024, time: 10.247001]
2023-05-17 20:01:53.786: epoch 34:	0.02246027  	0.16525957  	0.08480638  
2023-05-17 20:01:53.786: Find a better model.
2023-05-17 20:02:04.463: [iter 35 : loss : 0.2253 = 0.1273 + 0.0956 + 0.0025, time: 10.672002]
2023-05-17 20:02:04.729: epoch 35:	0.02259433  	0.16600408  	0.08529709  
2023-05-17 20:02:04.729: Find a better model.
2023-05-17 20:02:15.337: [iter 36 : loss : 0.2220 = 0.1242 + 0.0953 + 0.0025, time: 10.605002]
2023-05-17 20:02:15.671: epoch 36:	0.02261550  	0.16627248  	0.08580302  
2023-05-17 20:02:15.671: Find a better model.
2023-05-17 20:02:24.041: [iter 37 : loss : 0.2180 = 0.1205 + 0.0949 + 0.0026, time: 8.369632]
2023-05-17 20:02:24.226: epoch 37:	0.02270724  	0.16698980  	0.08624015  
2023-05-17 20:02:24.226: Find a better model.
2023-05-17 20:02:33.656: [iter 38 : loss : 0.2165 = 0.1192 + 0.0947 + 0.0026, time: 9.428001]
2023-05-17 20:02:33.822: epoch 38:	0.02281308  	0.16788919  	0.08706239  
2023-05-17 20:02:33.822: Find a better model.
2023-05-17 20:02:43.840: [iter 39 : loss : 0.2119 = 0.1149 + 0.0943 + 0.0027, time: 10.015304]
2023-05-17 20:02:44.097: epoch 39:	0.02301772  	0.16955623  	0.08798194  
2023-05-17 20:02:44.097: Find a better model.
2023-05-17 20:02:53.959: [iter 40 : loss : 0.2089 = 0.1121 + 0.0940 + 0.0028, time: 9.853012]
2023-05-17 20:02:54.263: epoch 40:	0.02318002  	0.17091948  	0.08844811  
2023-05-17 20:02:54.264: Find a better model.
2023-05-17 20:03:04.698: [iter 41 : loss : 0.2072 = 0.1106 + 0.0938 + 0.0028, time: 10.432024]
2023-05-17 20:03:05.009: epoch 41:	0.02322942  	0.17118615  	0.08889899  
2023-05-17 20:03:05.010: Find a better model.
2023-05-17 20:03:13.125: [iter 42 : loss : 0.2049 = 0.1085 + 0.0935 + 0.0029, time: 8.113424]
2023-05-17 20:03:13.278: epoch 42:	0.02335643  	0.17184590  	0.08947134  
2023-05-17 20:03:13.278: Find a better model.
2023-05-17 20:03:21.493: [iter 43 : loss : 0.2008 = 0.1047 + 0.0932 + 0.0029, time: 8.214025]
2023-05-17 20:03:21.662: epoch 43:	0.02349051  	0.17292295  	0.09006454  
2023-05-17 20:03:21.662: Find a better model.
2023-05-17 20:03:30.816: [iter 44 : loss : 0.1974 = 0.1016 + 0.0929 + 0.0030, time: 9.153022]
2023-05-17 20:03:31.104: epoch 44:	0.02352579  	0.17322750  	0.09029763  
2023-05-17 20:03:31.104: Find a better model.
2023-05-17 20:03:39.427: [iter 45 : loss : 0.1955 = 0.0998 + 0.0926 + 0.0030, time: 8.320026]
2023-05-17 20:03:39.592: epoch 45:	0.02365986  	0.17415629  	0.09083942  
2023-05-17 20:03:39.592: Find a better model.
2023-05-17 20:03:48.074: [iter 46 : loss : 0.1928 = 0.0974 + 0.0924 + 0.0031, time: 8.481167]
2023-05-17 20:03:48.235: epoch 46:	0.02370220  	0.17469527  	0.09128205  
2023-05-17 20:03:48.236: Find a better model.
2023-05-17 20:03:56.537: [iter 47 : loss : 0.1922 = 0.0969 + 0.0922 + 0.0031, time: 8.299150]
2023-05-17 20:03:56.703: epoch 47:	0.02382216  	0.17552529  	0.09182288  
2023-05-17 20:03:56.704: Find a better model.
2023-05-17 20:04:04.831: [iter 48 : loss : 0.1880 = 0.0929 + 0.0919 + 0.0032, time: 8.125015]
2023-05-17 20:04:04.982: epoch 48:	0.02394917  	0.17646924  	0.09240818  
2023-05-17 20:04:04.982: Find a better model.
2023-05-17 20:04:13.343: [iter 49 : loss : 0.1852 = 0.0903 + 0.0917 + 0.0032, time: 8.360003]
2023-05-17 20:04:13.511: epoch 49:	0.02406912  	0.17704625  	0.09279545  
2023-05-17 20:04:13.511: Find a better model.
2023-05-17 20:04:22.064: [iter 50 : loss : 0.1842 = 0.0894 + 0.0915 + 0.0033, time: 8.551006]
2023-05-17 20:04:22.226: epoch 50:	0.02415380  	0.17741743  	0.09310818  
2023-05-17 20:04:22.226: Find a better model.
2023-05-17 20:04:31.458: [iter 51 : loss : 0.1813 = 0.0867 + 0.0913 + 0.0033, time: 9.228557]
2023-05-17 20:04:31.742: epoch 51:	0.02427376  	0.17841971  	0.09357446  
2023-05-17 20:04:31.743: Find a better model.
2023-05-17 20:04:40.198: [iter 52 : loss : 0.1811 = 0.0866 + 0.0911 + 0.0034, time: 8.453001]
2023-05-17 20:04:40.363: epoch 52:	0.02437255  	0.17920710  	0.09413546  
2023-05-17 20:04:40.363: Find a better model.
2023-05-17 20:04:48.508: [iter 53 : loss : 0.1792 = 0.0850 + 0.0908 + 0.0034, time: 8.144206]
2023-05-17 20:04:48.669: epoch 53:	0.02433727  	0.17894804  	0.09438316  
2023-05-17 20:04:56.645: [iter 54 : loss : 0.1770 = 0.0829 + 0.0906 + 0.0034, time: 7.973162]
2023-05-17 20:04:56.801: epoch 54:	0.02446429  	0.17990078  	0.09506561  
2023-05-17 20:04:56.801: Find a better model.
2023-05-17 20:05:05.647: [iter 55 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 8.845130]
2023-05-17 20:05:05.813: epoch 55:	0.02442900  	0.17943111  	0.09523351  
2023-05-17 20:05:14.803: [iter 56 : loss : 0.1730 = 0.0792 + 0.0903 + 0.0035, time: 8.988028]
2023-05-17 20:05:15.047: epoch 56:	0.02449957  	0.18008167  	0.09561350  
2023-05-17 20:05:15.047: Find a better model.
2023-05-17 20:05:23.654: [iter 57 : loss : 0.1714 = 0.0777 + 0.0901 + 0.0036, time: 8.605992]
2023-05-17 20:05:23.814: epoch 57:	0.02457014  	0.18066654  	0.09611034  
2023-05-17 20:05:23.814: Find a better model.
2023-05-17 20:05:33.308: [iter 58 : loss : 0.1696 = 0.0761 + 0.0899 + 0.0036, time: 9.485811]
2023-05-17 20:05:33.578: epoch 58:	0.02466187  	0.18088797  	0.09652510  
2023-05-17 20:05:33.578: Find a better model.
2023-05-17 20:05:41.983: [iter 59 : loss : 0.1684 = 0.0750 + 0.0897 + 0.0037, time: 8.403207]
2023-05-17 20:05:42.188: epoch 59:	0.02466187  	0.18134961  	0.09676748  
2023-05-17 20:05:42.188: Find a better model.
2023-05-17 20:05:50.655: [iter 60 : loss : 0.1672 = 0.0739 + 0.0896 + 0.0037, time: 8.464036]
2023-05-17 20:05:50.814: epoch 60:	0.02469715  	0.18151915  	0.09707432  
2023-05-17 20:05:50.814: Find a better model.
2023-05-17 20:05:58.868: [iter 61 : loss : 0.1653 = 0.0722 + 0.0894 + 0.0038, time: 8.052032]
2023-05-17 20:05:59.022: epoch 61:	0.02477477  	0.18215814  	0.09747125  
2023-05-17 20:05:59.022: Find a better model.
2023-05-17 20:06:07.536: [iter 62 : loss : 0.1640 = 0.0709 + 0.0892 + 0.0038, time: 8.512046]
2023-05-17 20:06:07.712: epoch 62:	0.02483828  	0.18265022  	0.09782826  
2023-05-17 20:06:07.712: Find a better model.
2023-05-17 20:06:16.442: [iter 63 : loss : 0.1626 = 0.0696 + 0.0891 + 0.0038, time: 8.723524]
2023-05-17 20:06:16.723: epoch 63:	0.02502881  	0.18374752  	0.09835032  
2023-05-17 20:06:16.723: Find a better model.
2023-05-17 20:06:25.324: [iter 64 : loss : 0.1616 = 0.0688 + 0.0889 + 0.0039, time: 8.598163]
2023-05-17 20:06:25.485: epoch 64:	0.02500058  	0.18394539  	0.09883548  
2023-05-17 20:06:25.485: Find a better model.
2023-05-17 20:06:34.454: [iter 65 : loss : 0.1606 = 0.0679 + 0.0887 + 0.0039, time: 8.965847]
2023-05-17 20:06:34.727: epoch 65:	0.02504292  	0.18427719  	0.09911390  
2023-05-17 20:06:34.727: Find a better model.
2023-05-17 20:06:43.186: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 8.457993]
2023-05-17 20:06:43.346: epoch 66:	0.02519815  	0.18531960  	0.09954412  
2023-05-17 20:06:43.346: Find a better model.
2023-05-17 20:06:51.946: [iter 67 : loss : 0.1571 = 0.0646 + 0.0885 + 0.0040, time: 8.598794]
2023-05-17 20:06:52.128: epoch 67:	0.02523343  	0.18574919  	0.09988884  
2023-05-17 20:06:52.128: Find a better model.
2023-05-17 20:07:00.133: [iter 68 : loss : 0.1568 = 0.0644 + 0.0883 + 0.0041, time: 8.001038]
2023-05-17 20:07:00.295: epoch 68:	0.02533222  	0.18663239  	0.10039479  
2023-05-17 20:07:00.295: Find a better model.
2023-05-17 20:07:10.045: [iter 69 : loss : 0.1549 = 0.0627 + 0.0882 + 0.0041, time: 9.749273]
2023-05-17 20:07:10.206: epoch 69:	0.02533222  	0.18671729  	0.10048896  
2023-05-17 20:07:10.206: Find a better model.
2023-05-17 20:07:19.588: [iter 70 : loss : 0.1532 = 0.0611 + 0.0880 + 0.0041, time: 9.378299]
2023-05-17 20:07:19.881: epoch 70:	0.02540278  	0.18719958  	0.10068185  
2023-05-17 20:07:19.881: Find a better model.
2023-05-17 20:07:29.625: [iter 71 : loss : 0.1517 = 0.0596 + 0.0879 + 0.0042, time: 9.743534]
2023-05-17 20:07:29.790: epoch 71:	0.02549452  	0.18796861  	0.10103644  
2023-05-17 20:07:29.790: Find a better model.
2023-05-17 20:07:40.299: [iter 72 : loss : 0.1517 = 0.0597 + 0.0878 + 0.0042, time: 10.505011]
2023-05-17 20:07:40.622: epoch 72:	0.02555097  	0.18817581  	0.10111091  
2023-05-17 20:07:40.622: Find a better model.
2023-05-17 20:07:50.305: [iter 73 : loss : 0.1501 = 0.0582 + 0.0877 + 0.0043, time: 9.678417]
2023-05-17 20:07:50.603: epoch 73:	0.02558626  	0.18822767  	0.10121200  
2023-05-17 20:07:50.603: Find a better model.
2023-05-17 20:07:59.647: [iter 74 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 9.042961]
2023-05-17 20:07:59.812: epoch 74:	0.02563565  	0.18864840  	0.10154776  
2023-05-17 20:07:59.812: Find a better model.
2023-05-17 20:08:09.282: [iter 75 : loss : 0.1481 = 0.0564 + 0.0874 + 0.0044, time: 9.468020]
2023-05-17 20:08:09.572: epoch 75:	0.02573445  	0.18944569  	0.10183894  
2023-05-17 20:08:09.572: Find a better model.
2023-05-17 20:08:19.582: [iter 76 : loss : 0.1472 = 0.0555 + 0.0873 + 0.0044, time: 10.009003]
2023-05-17 20:08:19.750: epoch 76:	0.02576973  	0.18966120  	0.10226806  
2023-05-17 20:08:19.750: Find a better model.
2023-05-17 20:08:29.538: [iter 77 : loss : 0.1462 = 0.0546 + 0.0872 + 0.0044, time: 9.785010]
2023-05-17 20:08:29.858: epoch 77:	0.02584029  	0.19000021  	0.10265999  
2023-05-17 20:08:29.858: Find a better model.
2023-05-17 20:08:39.766: [iter 78 : loss : 0.1454 = 0.0538 + 0.0871 + 0.0045, time: 9.905013]
2023-05-17 20:08:40.091: epoch 78:	0.02590380  	0.19037130  	0.10297912  
2023-05-17 20:08:40.091: Find a better model.
2023-05-17 20:08:49.697: [iter 79 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 9.605339]
2023-05-17 20:08:49.863: epoch 79:	0.02587557  	0.18984672  	0.10292596  
2023-05-17 20:08:59.284: [iter 80 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 9.411011]
2023-05-17 20:08:59.567: epoch 80:	0.02593203  	0.19059537  	0.10323280  
2023-05-17 20:08:59.567: Find a better model.
2023-05-17 20:09:09.681: [iter 81 : loss : 0.1429 = 0.0516 + 0.0867 + 0.0046, time: 10.111991]
2023-05-17 20:09:09.855: epoch 81:	0.02598142  	0.19100638  	0.10349423  
2023-05-17 20:09:09.855: Find a better model.
2023-05-17 20:09:19.674: [iter 82 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0046, time: 9.816992]
2023-05-17 20:09:19.986: epoch 82:	0.02607316  	0.19157366  	0.10383990  
2023-05-17 20:09:19.987: Find a better model.
2023-05-17 20:09:30.042: [iter 83 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 10.053001]
2023-05-17 20:09:30.374: epoch 83:	0.02601670  	0.19115922  	0.10408112  
2023-05-17 20:09:39.809: [iter 84 : loss : 0.1407 = 0.0496 + 0.0864 + 0.0047, time: 9.433991]
2023-05-17 20:09:39.990: epoch 84:	0.02598848  	0.19099493  	0.10408831  
2023-05-17 20:09:48.408: [iter 85 : loss : 0.1395 = 0.0485 + 0.0863 + 0.0047, time: 8.409004]
2023-05-17 20:09:48.691: epoch 85:	0.02606610  	0.19143006  	0.10434143  
2023-05-17 20:09:58.557: [iter 86 : loss : 0.1392 = 0.0482 + 0.0862 + 0.0048, time: 9.864991]
2023-05-17 20:09:58.803: epoch 86:	0.02610844  	0.19154885  	0.10444263  
2023-05-17 20:10:08.887: [iter 87 : loss : 0.1365 = 0.0455 + 0.0862 + 0.0048, time: 10.079447]
2023-05-17 20:10:09.195: epoch 87:	0.02612255  	0.19173560  	0.10450931  
2023-05-17 20:10:09.195: Find a better model.
2023-05-17 20:10:19.318: [iter 88 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 10.118021]
2023-05-17 20:10:19.617: epoch 88:	0.02609432  	0.19134788  	0.10448779  
2023-05-17 20:10:28.812: [iter 89 : loss : 0.1356 = 0.0448 + 0.0859 + 0.0049, time: 9.193991]
2023-05-17 20:10:28.999: epoch 89:	0.02610138  	0.19151521  	0.10451723  
2023-05-17 20:10:37.697: [iter 90 : loss : 0.1361 = 0.0453 + 0.0859 + 0.0049, time: 8.685524]
2023-05-17 20:10:37.866: epoch 90:	0.02604493  	0.19111618  	0.10464945  
2023-05-17 20:10:47.822: [iter 91 : loss : 0.1351 = 0.0444 + 0.0858 + 0.0050, time: 9.953990]
2023-05-17 20:10:48.051: epoch 91:	0.02618606  	0.19223201  	0.10489790  
2023-05-17 20:10:48.051: Find a better model.
2023-05-17 20:10:58.487: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 10.431470]
2023-05-17 20:10:58.786: epoch 92:	0.02621428  	0.19230394  	0.10510640  
2023-05-17 20:10:58.786: Find a better model.
2023-05-17 20:11:08.791: [iter 93 : loss : 0.1344 = 0.0438 + 0.0856 + 0.0051, time: 10.002294]
2023-05-17 20:11:09.115: epoch 93:	0.02629190  	0.19278531  	0.10524264  
2023-05-17 20:11:09.115: Find a better model.
2023-05-17 20:11:17.853: [iter 94 : loss : 0.1320 = 0.0414 + 0.0855 + 0.0051, time: 8.735992]
2023-05-17 20:11:18.035: epoch 94:	0.02622840  	0.19238740  	0.10505844  
2023-05-17 20:11:27.115: [iter 95 : loss : 0.1316 = 0.0411 + 0.0855 + 0.0051, time: 9.078496]
2023-05-17 20:11:27.276: epoch 95:	0.02618605  	0.19177698  	0.10508405  
2023-05-17 20:11:36.836: [iter 96 : loss : 0.1314 = 0.0408 + 0.0854 + 0.0052, time: 9.557518]
2023-05-17 20:11:36.995: epoch 96:	0.02627779  	0.19281723  	0.10551038  
2023-05-17 20:11:36.995: Find a better model.
2023-05-17 20:11:47.603: [iter 97 : loss : 0.1302 = 0.0398 + 0.0853 + 0.0052, time: 10.607032]
2023-05-17 20:11:47.880: epoch 97:	0.02631307  	0.19300508  	0.10560229  
2023-05-17 20:11:47.881: Find a better model.
2023-05-17 20:11:57.951: [iter 98 : loss : 0.1309 = 0.0405 + 0.0852 + 0.0052, time: 10.068012]
2023-05-17 20:11:58.267: epoch 98:	0.02640481  	0.19338115  	0.10574670  
2023-05-17 20:11:58.267: Find a better model.
2023-05-17 20:12:07.010: [iter 99 : loss : 0.1299 = 0.0395 + 0.0852 + 0.0053, time: 8.741992]
2023-05-17 20:12:07.206: epoch 99:	0.02639069  	0.19313398  	0.10571267  
2023-05-17 20:12:16.312: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 9.104036]
2023-05-17 20:12:16.481: epoch 100:	0.02642598  	0.19342458  	0.10579222  
2023-05-17 20:12:16.481: Find a better model.
2023-05-17 20:12:26.195: [iter 101 : loss : 0.1287 = 0.0384 + 0.0850 + 0.0053, time: 9.711990]
2023-05-17 20:12:26.359: epoch 101:	0.02646126  	0.19348833  	0.10601192  
2023-05-17 20:12:26.359: Find a better model.
2023-05-17 20:12:36.628: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 10.266349]
2023-05-17 20:12:36.938: epoch 102:	0.02650360  	0.19398893  	0.10629598  
2023-05-17 20:12:36.938: Find a better model.
2023-05-17 20:12:46.969: [iter 103 : loss : 0.1273 = 0.0371 + 0.0848 + 0.0054, time: 10.027025]
2023-05-17 20:12:47.267: epoch 103:	0.02656711  	0.19430502  	0.10643126  
2023-05-17 20:12:47.267: Find a better model.
2023-05-17 20:12:55.920: [iter 104 : loss : 0.1279 = 0.0377 + 0.0848 + 0.0055, time: 8.650995]
2023-05-17 20:12:56.109: epoch 104:	0.02655300  	0.19420095  	0.10648185  
2023-05-17 20:13:05.251: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 9.138927]
2023-05-17 20:13:05.410: epoch 105:	0.02653182  	0.19404456  	0.10663299  
2023-05-17 20:13:14.970: [iter 106 : loss : 0.1265 = 0.0363 + 0.0846 + 0.0055, time: 9.558018]
2023-05-17 20:13:15.142: epoch 106:	0.02655299  	0.19416554  	0.10682470  
2023-05-17 20:13:25.740: [iter 107 : loss : 0.1255 = 0.0354 + 0.0846 + 0.0055, time: 10.595383]
2023-05-17 20:13:26.054: epoch 107:	0.02656711  	0.19417281  	0.10684486  
2023-05-17 20:13:35.969: [iter 108 : loss : 0.1255 = 0.0354 + 0.0845 + 0.0056, time: 9.913028]
2023-05-17 20:13:36.279: epoch 108:	0.02656005  	0.19411200  	0.10708774  
2023-05-17 20:13:44.960: [iter 109 : loss : 0.1239 = 0.0339 + 0.0844 + 0.0056, time: 8.678941]
2023-05-17 20:13:45.149: epoch 109:	0.02656711  	0.19430788  	0.10717946  
2023-05-17 20:13:45.149: Find a better model.
2023-05-17 20:13:54.428: [iter 110 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0056, time: 9.275425]
2023-05-17 20:13:54.585: epoch 110:	0.02660945  	0.19467984  	0.10724871  
2023-05-17 20:13:54.585: Find a better model.
2023-05-17 20:14:04.132: [iter 111 : loss : 0.1235 = 0.0335 + 0.0843 + 0.0057, time: 9.545994]
2023-05-17 20:14:04.303: epoch 111:	0.02666590  	0.19508472  	0.10744945  
2023-05-17 20:14:04.303: Find a better model.
2023-05-17 20:14:14.874: [iter 112 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0057, time: 10.568033]
2023-05-17 20:14:15.172: epoch 112:	0.02675058  	0.19558649  	0.10770115  
2023-05-17 20:14:15.172: Find a better model.
2023-05-17 20:14:25.226: [iter 113 : loss : 0.1233 = 0.0333 + 0.0842 + 0.0058, time: 10.050013]
2023-05-17 20:14:25.554: epoch 113:	0.02669413  	0.19490536  	0.10747075  
2023-05-17 20:14:34.539: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 8.983007]
2023-05-17 20:14:34.728: epoch 114:	0.02672941  	0.19535890  	0.10774186  
2023-05-17 20:14:43.609: [iter 115 : loss : 0.1220 = 0.0321 + 0.0841 + 0.0058, time: 8.880002]
2023-05-17 20:14:43.768: epoch 115:	0.02667295  	0.19484144  	0.10755425  
2023-05-17 20:14:53.362: [iter 116 : loss : 0.1212 = 0.0313 + 0.0841 + 0.0058, time: 9.593103]
2023-05-17 20:14:53.533: epoch 116:	0.02667296  	0.19491646  	0.10751607  
2023-05-17 20:15:03.793: [iter 117 : loss : 0.1212 = 0.0313 + 0.0840 + 0.0059, time: 10.258002]
2023-05-17 20:15:04.112: epoch 117:	0.02672235  	0.19541471  	0.10777986  
2023-05-17 20:15:14.099: [iter 118 : loss : 0.1208 = 0.0309 + 0.0839 + 0.0059, time: 9.984036]
2023-05-17 20:15:14.413: epoch 118:	0.02672940  	0.19516332  	0.10785338  
2023-05-17 20:15:23.158: [iter 119 : loss : 0.1200 = 0.0302 + 0.0839 + 0.0059, time: 8.743005]
2023-05-17 20:15:23.333: epoch 119:	0.02677174  	0.19584464  	0.10811764  
2023-05-17 20:15:23.333: Find a better model.
2023-05-17 20:15:32.221: [iter 120 : loss : 0.1200 = 0.0302 + 0.0839 + 0.0060, time: 8.886395]
2023-05-17 20:15:32.376: epoch 120:	0.02669412  	0.19494206  	0.10792045  
2023-05-17 20:15:41.942: [iter 121 : loss : 0.1201 = 0.0303 + 0.0838 + 0.0060, time: 9.564073]
2023-05-17 20:15:42.127: epoch 121:	0.02668001  	0.19479665  	0.10801267  
2023-05-17 20:15:50.535: [iter 122 : loss : 0.1191 = 0.0293 + 0.0838 + 0.0060, time: 8.404992]
2023-05-17 20:15:50.783: epoch 122:	0.02675057  	0.19520813  	0.10809785  
2023-05-17 20:16:00.785: [iter 123 : loss : 0.1193 = 0.0295 + 0.0837 + 0.0061, time: 10.000031]
2023-05-17 20:16:01.111: epoch 123:	0.02675763  	0.19547409  	0.10802678  
2023-05-17 20:16:09.553: [iter 124 : loss : 0.1183 = 0.0285 + 0.0837 + 0.0061, time: 8.441003]
2023-05-17 20:16:09.716: epoch 124:	0.02673646  	0.19509864  	0.10781562  
2023-05-17 20:16:18.957: [iter 125 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0061, time: 9.239621]
2023-05-17 20:16:19.162: epoch 125:	0.02660944  	0.19436894  	0.10773609  
2023-05-17 20:16:28.619: [iter 126 : loss : 0.1179 = 0.0282 + 0.0836 + 0.0062, time: 9.451987]
2023-05-17 20:16:29.252: epoch 126:	0.02665178  	0.19489351  	0.10779189  
2023-05-17 20:16:37.582: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 8.326002]
2023-05-17 20:16:37.744: epoch 127:	0.02663767  	0.19475731  	0.10779008  
2023-05-17 20:16:48.232: [iter 128 : loss : 0.1179 = 0.0282 + 0.0835 + 0.0062, time: 10.485037]
2023-05-17 20:16:48.561: epoch 128:	0.02665884  	0.19462939  	0.10774019  
2023-05-17 20:16:57.839: [iter 129 : loss : 0.1170 = 0.0274 + 0.0834 + 0.0063, time: 9.273001]
2023-05-17 20:16:58.143: epoch 129:	0.02656710  	0.19408880  	0.10765605  
2023-05-17 20:17:07.835: [iter 130 : loss : 0.1172 = 0.0275 + 0.0834 + 0.0063, time: 9.689991]
2023-05-17 20:17:08.006: epoch 130:	0.02668707  	0.19479030  	0.10791826  
2023-05-17 20:17:17.538: [iter 131 : loss : 0.1163 = 0.0267 + 0.0833 + 0.0063, time: 9.529991]
2023-05-17 20:17:17.915: epoch 131:	0.02673646  	0.19487619  	0.10809296  
2023-05-17 20:17:27.203: [iter 132 : loss : 0.1165 = 0.0269 + 0.0833 + 0.0063, time: 9.286020]
2023-05-17 20:17:27.362: epoch 132:	0.02668707  	0.19489095  	0.10810391  
2023-05-17 20:17:37.616: [iter 133 : loss : 0.1151 = 0.0255 + 0.0832 + 0.0064, time: 10.252011]
2023-05-17 20:17:37.945: epoch 133:	0.02672941  	0.19494091  	0.10820303  
2023-05-17 20:17:47.472: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 9.524020]
2023-05-17 20:17:47.766: epoch 134:	0.02668001  	0.19449808  	0.10811372  
2023-05-17 20:17:57.014: [iter 135 : loss : 0.1156 = 0.0260 + 0.0831 + 0.0064, time: 9.245001]
2023-05-17 20:17:57.297: epoch 135:	0.02668002  	0.19474021  	0.10816000  
2023-05-17 20:18:06.220: [iter 136 : loss : 0.1151 = 0.0256 + 0.0831 + 0.0065, time: 8.920105]
2023-05-17 20:18:06.511: epoch 136:	0.02668707  	0.19479248  	0.10820983  
2023-05-17 20:18:15.955: [iter 137 : loss : 0.1149 = 0.0254 + 0.0830 + 0.0065, time: 9.441683]
2023-05-17 20:18:16.146: epoch 137:	0.02662357  	0.19427966  	0.10811170  
2023-05-17 20:18:26.073: [iter 138 : loss : 0.1144 = 0.0249 + 0.0830 + 0.0065, time: 9.923494]
2023-05-17 20:18:26.388: epoch 138:	0.02654595  	0.19391082  	0.10813478  
2023-05-17 20:18:36.062: [iter 139 : loss : 0.1142 = 0.0246 + 0.0830 + 0.0065, time: 9.673018]
2023-05-17 20:18:36.440: epoch 139:	0.02660240  	0.19468732  	0.10829322  
2023-05-17 20:18:45.887: [iter 140 : loss : 0.1137 = 0.0242 + 0.0829 + 0.0066, time: 9.443991]
2023-05-17 20:18:46.051: epoch 140:	0.02666591  	0.19492978  	0.10872664  
2023-05-17 20:18:55.405: [iter 141 : loss : 0.1143 = 0.0248 + 0.0829 + 0.0066, time: 9.343016]
2023-05-17 20:18:55.689: epoch 141:	0.02664474  	0.19509813  	0.10880707  
2023-05-17 20:19:05.590: [iter 142 : loss : 0.1132 = 0.0237 + 0.0829 + 0.0066, time: 9.900028]
2023-05-17 20:19:05.766: epoch 142:	0.02662357  	0.19469999  	0.10856140  
2023-05-17 20:19:15.554: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 9.786001]
2023-05-17 20:19:15.881: epoch 143:	0.02658828  	0.19429576  	0.10851279  
2023-05-17 20:19:25.891: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 10.007219]
2023-05-17 20:19:26.194: epoch 144:	0.02668002  	0.19475703  	0.10865940  
2023-05-17 20:19:26.194: Early stopping is trigger at epoch: 144
2023-05-17 20:19:26.194: best_result@epoch 119:

2023-05-17 20:19:26.194: 		0.0268      	0.1958      	0.1081      
2023-05-17 20:20:12.686: my pid: 7380
2023-05-17 20:20:12.687: model: model.general_recommender.SGL
2023-05-17 20:20:12.687: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 20:20:12.687: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 20:20:16.486: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 20:20:25.344: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.856357]
2023-05-17 20:20:25.511: epoch 1:	0.00146063  	0.01026192  	0.00503328  
2023-05-17 20:20:25.512: Find a better model.
2023-05-17 20:20:35.168: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 9.654507]
2023-05-17 20:20:35.356: epoch 2:	0.00244144  	0.01874859  	0.00916563  
2023-05-17 20:20:35.357: Find a better model.
2023-05-17 20:20:45.506: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 10.139273]
2023-05-17 20:20:45.841: epoch 3:	0.00487579  	0.03628989  	0.01718583  
2023-05-17 20:20:45.841: Find a better model.
2023-05-17 20:20:54.058: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.215015]
2023-05-17 20:20:54.236: epoch 4:	0.00773350  	0.05724784  	0.02730872  
2023-05-17 20:20:54.236: Find a better model.
2023-05-17 20:21:03.324: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 9.087014]
2023-05-17 20:21:03.487: epoch 5:	0.01145924  	0.08262406  	0.03962108  
2023-05-17 20:21:03.487: Find a better model.
2023-05-17 20:21:12.687: [iter 6 : loss : 0.7673 = 0.6882 + 0.0791 + 0.0000, time: 9.199379]
2023-05-17 20:21:12.845: epoch 6:	0.01514269  	0.11053329  	0.05328454  
2023-05-17 20:21:12.845: Find a better model.
2023-05-17 20:21:22.540: [iter 7 : loss : 0.7611 = 0.6812 + 0.0799 + 0.0000, time: 9.693063]
2023-05-17 20:21:22.835: epoch 7:	0.01745719  	0.12655255  	0.06271788  
2023-05-17 20:21:22.835: Find a better model.
2023-05-17 20:21:32.418: [iter 8 : loss : 0.7457 = 0.6639 + 0.0817 + 0.0001, time: 9.580022]
2023-05-17 20:21:32.683: epoch 8:	0.01857918  	0.13569783  	0.06829973  
2023-05-17 20:21:32.683: Find a better model.
2023-05-17 20:21:41.364: [iter 9 : loss : 0.7107 = 0.6249 + 0.0856 + 0.0001, time: 8.678991]
2023-05-17 20:21:41.584: epoch 9:	0.01861447  	0.13737941  	0.06863988  
2023-05-17 20:21:41.584: Find a better model.
2023-05-17 20:21:49.494: [iter 10 : loss : 0.6498 = 0.5585 + 0.0911 + 0.0002, time: 7.907005]
2023-05-17 20:21:49.660: epoch 10:	0.01863563  	0.13712309  	0.06829450  
2023-05-17 20:21:58.371: [iter 11 : loss : 0.5738 = 0.4773 + 0.0961 + 0.0004, time: 8.708546]
2023-05-17 20:21:58.550: epoch 11:	0.01849450  	0.13587484  	0.06795161  
2023-05-17 20:22:07.829: [iter 12 : loss : 0.5048 = 0.4048 + 0.0995 + 0.0005, time: 9.277011]
2023-05-17 20:22:08.129: epoch 12:	0.01845922  	0.13616975  	0.06813329  
2023-05-17 20:22:17.537: [iter 13 : loss : 0.4539 = 0.3519 + 0.1014 + 0.0007, time: 9.404974]
2023-05-17 20:22:17.799: epoch 13:	0.01862857  	0.13766918  	0.06910114  
2023-05-17 20:22:17.799: Find a better model.
2023-05-17 20:22:26.287: [iter 14 : loss : 0.4154 = 0.3123 + 0.1023 + 0.0008, time: 8.486007]
2023-05-17 20:22:26.459: epoch 14:	0.01879087  	0.13916221  	0.06999324  
2023-05-17 20:22:26.459: Find a better model.
2023-05-17 20:22:34.948: [iter 15 : loss : 0.3888 = 0.2853 + 0.1026 + 0.0010, time: 8.486992]
2023-05-17 20:22:35.304: epoch 15:	0.01892495  	0.13985959  	0.07041753  
2023-05-17 20:22:35.304: Find a better model.
2023-05-17 20:22:43.475: [iter 16 : loss : 0.3663 = 0.2626 + 0.1026 + 0.0011, time: 8.169014]
2023-05-17 20:22:43.627: epoch 16:	0.01916488  	0.14183511  	0.07174417  
2023-05-17 20:22:43.627: Find a better model.
2023-05-17 20:22:52.886: [iter 17 : loss : 0.3500 = 0.2464 + 0.1024 + 0.0012, time: 9.257315]
2023-05-17 20:22:53.179: epoch 17:	0.01944714  	0.14352600  	0.07274040  
2023-05-17 20:22:53.179: Find a better model.
2023-05-17 20:23:00.720: [iter 18 : loss : 0.3347 = 0.2312 + 0.1022 + 0.0013, time: 7.539009]
2023-05-17 20:23:00.887: epoch 18:	0.01962355  	0.14482264  	0.07346664  
2023-05-17 20:23:00.887: Find a better model.
2023-05-17 20:23:09.474: [iter 19 : loss : 0.3205 = 0.2173 + 0.1018 + 0.0014, time: 8.586005]
2023-05-17 20:23:09.627: epoch 19:	0.01974352  	0.14531691  	0.07422484  
2023-05-17 20:23:09.627: Find a better model.
2023-05-17 20:23:18.144: [iter 20 : loss : 0.3109 = 0.2080 + 0.1014 + 0.0015, time: 8.516242]
2023-05-17 20:23:18.303: epoch 20:	0.01987053  	0.14611937  	0.07493295  
2023-05-17 20:23:18.304: Find a better model.
2023-05-17 20:23:26.227: [iter 21 : loss : 0.3011 = 0.1985 + 0.1011 + 0.0016, time: 7.922006]
2023-05-17 20:23:26.380: epoch 21:	0.02001166  	0.14694251  	0.07535290  
2023-05-17 20:23:26.380: Find a better model.
2023-05-17 20:23:35.623: [iter 22 : loss : 0.2929 = 0.1906 + 0.1007 + 0.0016, time: 9.240020]
2023-05-17 20:23:35.935: epoch 22:	0.02025159  	0.14861254  	0.07613338  
2023-05-17 20:23:35.935: Find a better model.
2023-05-17 20:23:43.440: [iter 23 : loss : 0.2847 = 0.1827 + 0.1002 + 0.0017, time: 7.503004]
2023-05-17 20:23:43.602: epoch 23:	0.02047034  	0.15073712  	0.07706480  
2023-05-17 20:23:43.602: Find a better model.
2023-05-17 20:23:51.628: [iter 24 : loss : 0.2782 = 0.1766 + 0.0997 + 0.0018, time: 8.025007]
2023-05-17 20:23:51.793: epoch 24:	0.02063262  	0.15175554  	0.07778116  
2023-05-17 20:23:51.793: Find a better model.
2023-05-17 20:24:00.447: [iter 25 : loss : 0.2714 = 0.1702 + 0.0994 + 0.0019, time: 8.651012]
2023-05-17 20:24:00.599: epoch 25:	0.02085138  	0.15284266  	0.07824337  
2023-05-17 20:24:00.599: Find a better model.
2023-05-17 20:24:08.419: [iter 26 : loss : 0.2679 = 0.1671 + 0.0989 + 0.0019, time: 7.818232]
2023-05-17 20:24:08.574: epoch 26:	0.02104191  	0.15425324  	0.07890284  
2023-05-17 20:24:08.574: Find a better model.
2023-05-17 20:24:17.834: [iter 27 : loss : 0.2600 = 0.1595 + 0.0985 + 0.0020, time: 9.256376]
2023-05-17 20:24:18.125: epoch 27:	0.02125361  	0.15562330  	0.07981611  
2023-05-17 20:24:18.125: Find a better model.
2023-05-17 20:24:25.932: [iter 28 : loss : 0.2550 = 0.1549 + 0.0981 + 0.0021, time: 7.804025]
2023-05-17 20:24:26.091: epoch 28:	0.02150764  	0.15732969  	0.08072378  
2023-05-17 20:24:26.091: Find a better model.
2023-05-17 20:24:34.205: [iter 29 : loss : 0.2507 = 0.1509 + 0.0977 + 0.0021, time: 8.112009]
2023-05-17 20:24:34.356: epoch 29:	0.02162761  	0.15880553  	0.08126923  
2023-05-17 20:24:34.356: Find a better model.
2023-05-17 20:24:43.220: [iter 30 : loss : 0.2442 = 0.1447 + 0.0973 + 0.0022, time: 8.863145]
2023-05-17 20:24:43.371: epoch 30:	0.02175462  	0.15970239  	0.08201446  
2023-05-17 20:24:43.371: Find a better model.
2023-05-17 20:24:52.332: [iter 31 : loss : 0.2406 = 0.1414 + 0.0970 + 0.0023, time: 8.956262]
2023-05-17 20:24:52.635: epoch 31:	0.02188164  	0.16045500  	0.08263842  
2023-05-17 20:24:52.636: Find a better model.
2023-05-17 20:25:01.936: [iter 32 : loss : 0.2352 = 0.1363 + 0.0966 + 0.0023, time: 9.291656]
2023-05-17 20:25:02.242: epoch 32:	0.02200865  	0.16168708  	0.08337557  
2023-05-17 20:25:02.242: Find a better model.
2023-05-17 20:25:10.725: [iter 33 : loss : 0.2323 = 0.1338 + 0.0962 + 0.0024, time: 8.481115]
2023-05-17 20:25:10.899: epoch 33:	0.02213566  	0.16258872  	0.08393546  
2023-05-17 20:25:10.899: Find a better model.
2023-05-17 20:25:18.866: [iter 34 : loss : 0.2284 = 0.1301 + 0.0959 + 0.0024, time: 7.966083]
2023-05-17 20:25:19.036: epoch 34:	0.02229796  	0.16397068  	0.08452353  
2023-05-17 20:25:19.037: Find a better model.
2023-05-17 20:25:27.891: [iter 35 : loss : 0.2251 = 0.1270 + 0.0955 + 0.0025, time: 8.852376]
2023-05-17 20:25:28.060: epoch 35:	0.02241792  	0.16450377  	0.08512802  
2023-05-17 20:25:28.060: Find a better model.
2023-05-17 20:25:37.658: [iter 36 : loss : 0.2213 = 0.1235 + 0.0952 + 0.0025, time: 9.594266]
2023-05-17 20:25:37.973: epoch 36:	0.02260843  	0.16616274  	0.08593924  
2023-05-17 20:25:37.974: Find a better model.
2023-05-17 20:25:47.643: [iter 37 : loss : 0.2175 = 0.1200 + 0.0949 + 0.0026, time: 9.661781]
2023-05-17 20:25:47.935: epoch 37:	0.02272840  	0.16691357  	0.08646111  
2023-05-17 20:25:47.935: Find a better model.
2023-05-17 20:25:56.437: [iter 38 : loss : 0.2159 = 0.1187 + 0.0946 + 0.0027, time: 8.501004]
2023-05-17 20:25:56.611: epoch 38:	0.02298949  	0.16896696  	0.08730426  
2023-05-17 20:25:56.611: Find a better model.
2023-05-17 20:26:04.797: [iter 39 : loss : 0.2116 = 0.1146 + 0.0943 + 0.0027, time: 8.184992]
2023-05-17 20:26:04.964: epoch 39:	0.02318707  	0.17081654  	0.08844373  
2023-05-17 20:26:04.964: Find a better model.
2023-05-17 20:26:13.409: [iter 40 : loss : 0.2083 = 0.1115 + 0.0940 + 0.0028, time: 8.444062]
2023-05-17 20:26:13.575: epoch 40:	0.02339171  	0.17220390  	0.08919946  
2023-05-17 20:26:13.575: Find a better model.
2023-05-17 20:26:22.981: [iter 41 : loss : 0.2065 = 0.1099 + 0.0937 + 0.0028, time: 9.402708]
2023-05-17 20:26:23.256: epoch 41:	0.02343405  	0.17226870  	0.08943996  
2023-05-17 20:26:23.256: Find a better model.
2023-05-17 20:26:31.474: [iter 42 : loss : 0.2044 = 0.1081 + 0.0934 + 0.0029, time: 8.215250]
2023-05-17 20:26:31.642: epoch 42:	0.02359635  	0.17326358  	0.09009070  
2023-05-17 20:26:31.642: Find a better model.
2023-05-17 20:26:40.458: [iter 43 : loss : 0.2004 = 0.1044 + 0.0931 + 0.0029, time: 8.814622]
2023-05-17 20:26:40.626: epoch 43:	0.02357518  	0.17277992  	0.09035260  
2023-05-17 20:26:49.282: [iter 44 : loss : 0.1969 = 0.1012 + 0.0928 + 0.0030, time: 8.654002]
2023-05-17 20:26:49.701: epoch 44:	0.02368808  	0.17386600  	0.09095265  
2023-05-17 20:26:49.702: Find a better model.
2023-05-17 20:26:57.763: [iter 45 : loss : 0.1947 = 0.0991 + 0.0926 + 0.0030, time: 8.060396]
2023-05-17 20:26:57.917: epoch 45:	0.02382216  	0.17448784  	0.09160106  
2023-05-17 20:26:57.917: Find a better model.
2023-05-17 20:27:07.086: [iter 46 : loss : 0.1925 = 0.0970 + 0.0924 + 0.0031, time: 9.165001]
2023-05-17 20:27:07.392: epoch 46:	0.02389978  	0.17494391  	0.09206560  
2023-05-17 20:27:07.392: Find a better model.
2023-05-17 20:27:15.010: [iter 47 : loss : 0.1917 = 0.0965 + 0.0921 + 0.0031, time: 7.616032]
2023-05-17 20:27:15.178: epoch 47:	0.02406208  	0.17609176  	0.09279937  
2023-05-17 20:27:15.178: Find a better model.
2023-05-17 20:27:23.778: [iter 48 : loss : 0.1878 = 0.0928 + 0.0919 + 0.0032, time: 8.598531]
2023-05-17 20:27:23.931: epoch 48:	0.02408325  	0.17629786  	0.09305263  
2023-05-17 20:27:23.932: Find a better model.
2023-05-17 20:27:32.641: [iter 49 : loss : 0.1847 = 0.0898 + 0.0917 + 0.0032, time: 8.707066]
2023-05-17 20:27:32.791: epoch 49:	0.02416793  	0.17711419  	0.09352184  
2023-05-17 20:27:32.791: Find a better model.
2023-05-17 20:27:40.962: [iter 50 : loss : 0.1838 = 0.0891 + 0.0914 + 0.0033, time: 8.168992]
2023-05-17 20:27:41.130: epoch 50:	0.02421026  	0.17740071  	0.09372998  
2023-05-17 20:27:41.130: Find a better model.
2023-05-17 20:27:50.497: [iter 51 : loss : 0.1807 = 0.0862 + 0.0913 + 0.0033, time: 9.363154]
2023-05-17 20:27:50.813: epoch 51:	0.02427378  	0.17802069  	0.09410276  
2023-05-17 20:27:50.813: Find a better model.
2023-05-17 20:27:58.862: [iter 52 : loss : 0.1807 = 0.0863 + 0.0911 + 0.0034, time: 8.047993]
2023-05-17 20:27:59.095: epoch 52:	0.02433729  	0.17879176  	0.09461566  
2023-05-17 20:27:59.096: Find a better model.
2023-05-17 20:28:07.166: [iter 53 : loss : 0.1787 = 0.0845 + 0.0908 + 0.0034, time: 8.064447]
2023-05-17 20:28:07.316: epoch 53:	0.02439374  	0.17950308  	0.09509688  
2023-05-17 20:28:07.316: Find a better model.
2023-05-17 20:28:16.125: [iter 54 : loss : 0.1764 = 0.0823 + 0.0906 + 0.0035, time: 8.807012]
2023-05-17 20:28:16.279: epoch 54:	0.02444314  	0.18005408  	0.09553518  
2023-05-17 20:28:16.279: Find a better model.
2023-05-17 20:28:25.940: [iter 55 : loss : 0.1748 = 0.0808 + 0.0905 + 0.0035, time: 9.660246]
2023-05-17 20:28:26.208: epoch 55:	0.02462661  	0.18107407  	0.09597115  
2023-05-17 20:28:26.208: Find a better model.
2023-05-17 20:28:35.601: [iter 56 : loss : 0.1730 = 0.0792 + 0.0903 + 0.0035, time: 9.386405]
2023-05-17 20:28:35.901: epoch 56:	0.02472539  	0.18227717  	0.09649535  
2023-05-17 20:28:35.901: Find a better model.
2023-05-17 20:28:44.492: [iter 57 : loss : 0.1709 = 0.0773 + 0.0901 + 0.0036, time: 8.590207]
2023-05-17 20:28:44.643: epoch 57:	0.02477479  	0.18273075  	0.09698535  
2023-05-17 20:28:44.643: Find a better model.
2023-05-17 20:28:52.560: [iter 58 : loss : 0.1692 = 0.0757 + 0.0899 + 0.0036, time: 7.914240]
2023-05-17 20:28:52.726: epoch 58:	0.02479596  	0.18292123  	0.09724377  
2023-05-17 20:28:52.727: Find a better model.
2023-05-17 20:29:01.556: [iter 59 : loss : 0.1682 = 0.0749 + 0.0897 + 0.0037, time: 8.828003]
2023-05-17 20:29:01.714: epoch 59:	0.02485241  	0.18328945  	0.09751949  
2023-05-17 20:29:01.714: Find a better model.
2023-05-17 20:29:10.951: [iter 60 : loss : 0.1669 = 0.0736 + 0.0896 + 0.0037, time: 9.233875]
2023-05-17 20:29:11.253: epoch 60:	0.02508527  	0.18485916  	0.09822107  
2023-05-17 20:29:11.253: Find a better model.
2023-05-17 20:29:20.602: [iter 61 : loss : 0.1651 = 0.0720 + 0.0894 + 0.0038, time: 9.344145]
2023-05-17 20:29:20.806: epoch 61:	0.02504999  	0.18452176  	0.09834033  
2023-05-17 20:29:29.317: [iter 62 : loss : 0.1637 = 0.0707 + 0.0892 + 0.0038, time: 8.509013]
2023-05-17 20:29:29.478: epoch 62:	0.02516995  	0.18536232  	0.09869771  
2023-05-17 20:29:29.479: Find a better model.
2023-05-17 20:29:37.579: [iter 63 : loss : 0.1625 = 0.0696 + 0.0891 + 0.0039, time: 8.099013]
2023-05-17 20:29:37.755: epoch 63:	0.02530401  	0.18643108  	0.09909773  
2023-05-17 20:29:37.755: Find a better model.
2023-05-17 20:29:46.104: [iter 64 : loss : 0.1612 = 0.0685 + 0.0889 + 0.0039, time: 8.348115]
2023-05-17 20:29:46.262: epoch 64:	0.02540986  	0.18756235  	0.09961690  
2023-05-17 20:29:46.262: Find a better model.
2023-05-17 20:29:55.612: [iter 65 : loss : 0.1602 = 0.0675 + 0.0887 + 0.0039, time: 9.347359]
2023-05-17 20:29:55.922: epoch 65:	0.02538163  	0.18716374  	0.09974399  
2023-05-17 20:30:03.507: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 7.584303]
2023-05-17 20:30:03.670: epoch 66:	0.02536047  	0.18717282  	0.10007475  
2023-05-17 20:30:12.192: [iter 67 : loss : 0.1569 = 0.0644 + 0.0885 + 0.0040, time: 8.520004]
2023-05-17 20:30:12.349: epoch 67:	0.02540986  	0.18722582  	0.10016084  
2023-05-17 20:30:20.895: [iter 68 : loss : 0.1568 = 0.0644 + 0.0883 + 0.0041, time: 8.544021]
2023-05-17 20:30:21.354: epoch 68:	0.02550159  	0.18827248  	0.10062961  
2023-05-17 20:30:21.354: Find a better model.
2023-05-17 20:30:29.290: [iter 69 : loss : 0.1549 = 0.0626 + 0.0882 + 0.0041, time: 7.932003]
2023-05-17 20:30:29.439: epoch 69:	0.02550864  	0.18842047  	0.10081672  
2023-05-17 20:30:29.439: Find a better model.
2023-05-17 20:30:38.700: [iter 70 : loss : 0.1529 = 0.0607 + 0.0881 + 0.0041, time: 9.254287]
2023-05-17 20:30:39.010: epoch 70:	0.02553688  	0.18880834  	0.10098522  
2023-05-17 20:30:39.010: Find a better model.
2023-05-17 20:30:46.738: [iter 71 : loss : 0.1516 = 0.0595 + 0.0879 + 0.0042, time: 7.727003]
2023-05-17 20:30:46.905: epoch 71:	0.02560744  	0.18955985  	0.10144646  
2023-05-17 20:30:46.905: Find a better model.
2023-05-17 20:30:55.487: [iter 72 : loss : 0.1516 = 0.0595 + 0.0878 + 0.0042, time: 8.580328]
2023-05-17 20:30:55.650: epoch 72:	0.02565684  	0.18963653  	0.10149787  
2023-05-17 20:30:55.650: Find a better model.
2023-05-17 20:31:04.346: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 8.695000]
2023-05-17 20:31:04.532: epoch 73:	0.02572740  	0.19029669  	0.10174680  
2023-05-17 20:31:04.532: Find a better model.
2023-05-17 20:31:12.478: [iter 74 : loss : 0.1487 = 0.0569 + 0.0875 + 0.0043, time: 7.945160]
2023-05-17 20:31:12.643: epoch 74:	0.02581913  	0.19122361  	0.10225293  
2023-05-17 20:31:12.644: Find a better model.
2023-05-17 20:31:21.947: [iter 75 : loss : 0.1482 = 0.0564 + 0.0874 + 0.0044, time: 9.302002]
2023-05-17 20:31:22.249: epoch 75:	0.02591792  	0.19157271  	0.10251572  
2023-05-17 20:31:22.249: Find a better model.
2023-05-17 20:31:30.202: [iter 76 : loss : 0.1470 = 0.0553 + 0.0873 + 0.0044, time: 7.951993]
2023-05-17 20:31:30.362: epoch 76:	0.02598849  	0.19198832  	0.10272259  
2023-05-17 20:31:30.362: Find a better model.
2023-05-17 20:31:38.478: [iter 77 : loss : 0.1462 = 0.0545 + 0.0872 + 0.0044, time: 8.114511]
2023-05-17 20:31:38.639: epoch 77:	0.02600965  	0.19222836  	0.10291777  
2023-05-17 20:31:38.639: Find a better model.
2023-05-17 20:31:47.479: [iter 78 : loss : 0.1451 = 0.0536 + 0.0870 + 0.0045, time: 8.837991]
2023-05-17 20:31:47.629: epoch 78:	0.02596732  	0.19202468  	0.10287919  
2023-05-17 20:31:57.106: [iter 79 : loss : 0.1438 = 0.0523 + 0.0870 + 0.0045, time: 9.470002]
2023-05-17 20:31:57.393: epoch 79:	0.02600260  	0.19215035  	0.10309098  
2023-05-17 20:32:06.609: [iter 80 : loss : 0.1433 = 0.0519 + 0.0869 + 0.0046, time: 9.212172]
2023-05-17 20:32:06.926: epoch 80:	0.02603083  	0.19254830  	0.10328799  
2023-05-17 20:32:06.926: Find a better model.
2023-05-17 20:32:15.347: [iter 81 : loss : 0.1429 = 0.0516 + 0.0867 + 0.0046, time: 8.420516]
2023-05-17 20:32:15.515: epoch 81:	0.02610139  	0.19289888  	0.10340849  
2023-05-17 20:32:15.515: Find a better model.
2023-05-17 20:32:23.281: [iter 82 : loss : 0.1413 = 0.0501 + 0.0866 + 0.0046, time: 7.765214]
2023-05-17 20:32:23.445: epoch 82:	0.02608022  	0.19251671  	0.10361956  
2023-05-17 20:32:32.080: [iter 83 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 8.633007]
2023-05-17 20:32:32.316: epoch 83:	0.02612256  	0.19299512  	0.10383539  
2023-05-17 20:32:32.316: Find a better model.
2023-05-17 20:32:41.541: [iter 84 : loss : 0.1405 = 0.0493 + 0.0865 + 0.0047, time: 9.219991]
2023-05-17 20:32:41.854: epoch 84:	0.02608022  	0.19279636  	0.10392205  
2023-05-17 20:32:51.206: [iter 85 : loss : 0.1395 = 0.0484 + 0.0863 + 0.0047, time: 9.350023]
2023-05-17 20:32:51.515: epoch 85:	0.02611550  	0.19271468  	0.10416837  
2023-05-17 20:32:59.892: [iter 86 : loss : 0.1396 = 0.0486 + 0.0862 + 0.0048, time: 8.375470]
2023-05-17 20:33:00.056: epoch 86:	0.02615079  	0.19301653  	0.10427113  
2023-05-17 20:33:00.056: Find a better model.
2023-05-17 20:33:08.063: [iter 87 : loss : 0.1366 = 0.0456 + 0.0861 + 0.0048, time: 8.005395]
2023-05-17 20:33:08.234: epoch 87:	0.02615079  	0.19309282  	0.10437382  
2023-05-17 20:33:08.234: Find a better model.
2023-05-17 20:33:16.716: [iter 88 : loss : 0.1360 = 0.0451 + 0.0861 + 0.0049, time: 8.480993]
2023-05-17 20:33:16.874: epoch 88:	0.02619313  	0.19337247  	0.10442106  
2023-05-17 20:33:16.874: Find a better model.
2023-05-17 20:33:26.042: [iter 89 : loss : 0.1357 = 0.0448 + 0.0860 + 0.0049, time: 9.165021]
2023-05-17 20:33:26.345: epoch 89:	0.02624958  	0.19368508  	0.10447185  
2023-05-17 20:33:26.345: Find a better model.
2023-05-17 20:33:35.245: [iter 90 : loss : 0.1364 = 0.0456 + 0.0859 + 0.0049, time: 8.899017]
2023-05-17 20:33:35.429: epoch 90:	0.02632014  	0.19411166  	0.10476485  
2023-05-17 20:33:35.429: Find a better model.
2023-05-17 20:33:43.905: [iter 91 : loss : 0.1350 = 0.0443 + 0.0858 + 0.0050, time: 8.474018]
2023-05-17 20:33:44.063: epoch 91:	0.02629192  	0.19395325  	0.10470270  
2023-05-17 20:33:52.336: [iter 92 : loss : 0.1340 = 0.0432 + 0.0857 + 0.0050, time: 8.272031]
2023-05-17 20:33:52.659: epoch 92:	0.02627075  	0.19365719  	0.10482600  
2023-05-17 20:34:00.818: [iter 93 : loss : 0.1342 = 0.0436 + 0.0856 + 0.0051, time: 8.158021]
2023-05-17 20:34:00.983: epoch 93:	0.02627075  	0.19380085  	0.10503012  
2023-05-17 20:34:10.121: [iter 94 : loss : 0.1322 = 0.0415 + 0.0856 + 0.0051, time: 9.137012]
2023-05-17 20:34:10.434: epoch 94:	0.02627780  	0.19361833  	0.10515276  
2023-05-17 20:34:18.131: [iter 95 : loss : 0.1315 = 0.0410 + 0.0855 + 0.0051, time: 7.693299]
2023-05-17 20:34:18.309: epoch 95:	0.02625663  	0.19349167  	0.10528199  
2023-05-17 20:34:26.847: [iter 96 : loss : 0.1316 = 0.0410 + 0.0854 + 0.0052, time: 8.536522]
2023-05-17 20:34:27.016: epoch 96:	0.02636248  	0.19423118  	0.10552406  
2023-05-17 20:34:27.016: Find a better model.
2023-05-17 20:34:35.557: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 8.540001]
2023-05-17 20:34:35.832: epoch 97:	0.02634837  	0.19419079  	0.10557539  
2023-05-17 20:34:44.018: [iter 98 : loss : 0.1309 = 0.0404 + 0.0852 + 0.0052, time: 8.183992]
2023-05-17 20:34:44.176: epoch 98:	0.02637659  	0.19419320  	0.10565505  
2023-05-17 20:34:53.390: [iter 99 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0053, time: 9.212017]
2023-05-17 20:34:53.692: epoch 99:	0.02641188  	0.19487762  	0.10590900  
2023-05-17 20:34:53.692: Find a better model.
2023-05-17 20:35:01.256: [iter 100 : loss : 0.1290 = 0.0386 + 0.0851 + 0.0053, time: 7.560539]
2023-05-17 20:35:01.428: epoch 100:	0.02653183  	0.19542360  	0.10622520  
2023-05-17 20:35:01.428: Find a better model.
2023-05-17 20:35:09.854: [iter 101 : loss : 0.1286 = 0.0382 + 0.0850 + 0.0053, time: 8.423244]
2023-05-17 20:35:10.024: epoch 101:	0.02653184  	0.19549078  	0.10643882  
2023-05-17 20:35:10.024: Find a better model.
2023-05-17 20:35:18.417: [iter 102 : loss : 0.1277 = 0.0374 + 0.0849 + 0.0054, time: 8.392012]
2023-05-17 20:35:18.660: epoch 102:	0.02655301  	0.19541453  	0.10649635  
2023-05-17 20:35:26.635: [iter 103 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 7.966280]
2023-05-17 20:35:26.788: epoch 103:	0.02656006  	0.19562562  	0.10675596  
2023-05-17 20:35:26.788: Find a better model.
2023-05-17 20:35:35.921: [iter 104 : loss : 0.1279 = 0.0376 + 0.0848 + 0.0054, time: 9.130014]
2023-05-17 20:35:36.228: epoch 104:	0.02654595  	0.19557776  	0.10677837  
2023-05-17 20:35:43.737: [iter 105 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0055, time: 7.507004]
2023-05-17 20:35:43.904: epoch 105:	0.02668002  	0.19621146  	0.10701053  
2023-05-17 20:35:43.904: Find a better model.
2023-05-17 20:35:52.240: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 8.335028]
2023-05-17 20:35:52.399: epoch 106:	0.02667297  	0.19614539  	0.10699884  
2023-05-17 20:36:00.942: [iter 107 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0055, time: 8.540992]
2023-05-17 20:36:01.100: epoch 107:	0.02669414  	0.19617835  	0.10710197  
2023-05-17 20:36:09.181: [iter 108 : loss : 0.1255 = 0.0354 + 0.0846 + 0.0056, time: 8.080110]
2023-05-17 20:36:09.347: epoch 108:	0.02660240  	0.19548535  	0.10702290  
2023-05-17 20:36:18.578: [iter 109 : loss : 0.1239 = 0.0339 + 0.0845 + 0.0056, time: 9.224012]
2023-05-17 20:36:18.888: epoch 109:	0.02663063  	0.19565867  	0.10715158  
2023-05-17 20:36:26.346: [iter 110 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0056, time: 7.457007]
2023-05-17 20:36:26.514: epoch 110:	0.02660946  	0.19556901  	0.10713252  
2023-05-17 20:36:35.028: [iter 111 : loss : 0.1232 = 0.0331 + 0.0844 + 0.0057, time: 8.511015]
2023-05-17 20:36:35.204: epoch 111:	0.02668708  	0.19624433  	0.10746322  
2023-05-17 20:36:35.204: Find a better model.
2023-05-17 20:36:43.707: [iter 112 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0057, time: 8.501992]
2023-05-17 20:36:44.065: epoch 112:	0.02672942  	0.19656555  	0.10733119  
2023-05-17 20:36:44.065: Find a better model.
2023-05-17 20:36:51.960: [iter 113 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0057, time: 7.893004]
2023-05-17 20:36:52.121: epoch 113:	0.02677176  	0.19688627  	0.10757897  
2023-05-17 20:36:52.121: Find a better model.
2023-05-17 20:37:01.235: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 9.113025]
2023-05-17 20:37:01.539: epoch 114:	0.02670120  	0.19651477  	0.10741119  
2023-05-17 20:37:08.943: [iter 115 : loss : 0.1219 = 0.0320 + 0.0841 + 0.0058, time: 7.403003]
2023-05-17 20:37:09.117: epoch 115:	0.02672237  	0.19647172  	0.10737202  
2023-05-17 20:37:17.415: [iter 116 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0058, time: 8.295015]
2023-05-17 20:37:17.574: epoch 116:	0.02675059  	0.19664179  	0.10735837  
2023-05-17 20:37:25.874: [iter 117 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0059, time: 8.299022]
2023-05-17 20:37:26.209: epoch 117:	0.02675059  	0.19712420  	0.10755130  
2023-05-17 20:37:26.210: Find a better model.
2023-05-17 20:37:34.156: [iter 118 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 7.945005]
2023-05-17 20:37:34.309: epoch 118:	0.02680704  	0.19733320  	0.10754868  
2023-05-17 20:37:34.309: Find a better model.
2023-05-17 20:37:43.537: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0059, time: 9.225999]
2023-05-17 20:37:43.856: epoch 119:	0.02675764  	0.19687310  	0.10771723  
2023-05-17 20:37:51.356: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 7.498003]
2023-05-17 20:37:51.525: epoch 120:	0.02681410  	0.19758216  	0.10800220  
2023-05-17 20:37:51.525: Find a better model.
2023-05-17 20:38:00.245: [iter 121 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 8.718993]
2023-05-17 20:38:00.409: epoch 121:	0.02677882  	0.19729653  	0.10787863  
2023-05-17 20:38:08.819: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 8.408275]
2023-05-17 20:38:09.093: epoch 122:	0.02675764  	0.19701253  	0.10789397  
2023-05-17 20:38:17.312: [iter 123 : loss : 0.1192 = 0.0293 + 0.0837 + 0.0061, time: 8.217005]
2023-05-17 20:38:17.465: epoch 123:	0.02679292  	0.19738613  	0.10785891  
2023-05-17 20:38:26.693: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 9.226024]
2023-05-17 20:38:26.997: epoch 124:	0.02674353  	0.19676784  	0.10779174  
2023-05-17 20:38:34.496: [iter 125 : loss : 0.1176 = 0.0279 + 0.0836 + 0.0061, time: 7.496993]
2023-05-17 20:38:34.659: epoch 125:	0.02680705  	0.19736756  	0.10814498  
2023-05-17 20:38:43.168: [iter 126 : loss : 0.1179 = 0.0282 + 0.0836 + 0.0062, time: 8.508002]
2023-05-17 20:38:43.323: epoch 126:	0.02675765  	0.19686633  	0.10794836  
2023-05-17 20:38:51.669: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 8.344982]
2023-05-17 20:38:52.214: epoch 127:	0.02682115  	0.19720417  	0.10827577  
2023-05-17 20:39:00.106: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 7.891448]
2023-05-17 20:39:00.262: epoch 128:	0.02684938  	0.19716859  	0.10850848  
2023-05-17 20:39:09.436: [iter 129 : loss : 0.1172 = 0.0275 + 0.0834 + 0.0062, time: 9.171271]
2023-05-17 20:39:09.740: epoch 129:	0.02686350  	0.19742663  	0.10864427  
2023-05-17 20:39:17.225: [iter 130 : loss : 0.1170 = 0.0274 + 0.0834 + 0.0063, time: 7.483250]
2023-05-17 20:39:17.391: epoch 130:	0.02691289  	0.19767115  	0.10857493  
2023-05-17 20:39:17.391: Find a better model.
2023-05-17 20:39:25.929: [iter 131 : loss : 0.1161 = 0.0265 + 0.0834 + 0.0063, time: 8.536021]
2023-05-17 20:39:26.080: epoch 131:	0.02691994  	0.19759567  	0.10869578  
2023-05-17 20:39:34.276: [iter 132 : loss : 0.1165 = 0.0268 + 0.0833 + 0.0063, time: 8.194045]
2023-05-17 20:39:34.727: epoch 132:	0.02699051  	0.19804527  	0.10883420  
2023-05-17 20:39:34.727: Find a better model.
2023-05-17 20:39:42.726: [iter 133 : loss : 0.1153 = 0.0256 + 0.0833 + 0.0064, time: 7.997010]
2023-05-17 20:39:42.877: epoch 133:	0.02691288  	0.19756286  	0.10867898  
2023-05-17 20:39:52.077: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 9.198037]
2023-05-17 20:39:52.355: epoch 134:	0.02696228  	0.19795895  	0.10871487  
2023-05-17 20:39:59.972: [iter 135 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0064, time: 7.616003]
2023-05-17 20:40:00.144: epoch 135:	0.02694817  	0.19811088  	0.10887022  
2023-05-17 20:40:00.144: Find a better model.
2023-05-17 20:40:08.532: [iter 136 : loss : 0.1153 = 0.0257 + 0.0831 + 0.0065, time: 8.387017]
2023-05-17 20:40:08.682: epoch 136:	0.02695523  	0.19801888  	0.10893905  
2023-05-17 20:40:17.071: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 8.387001]
2023-05-17 20:40:17.597: epoch 137:	0.02687055  	0.19763373  	0.10886806  
2023-05-17 20:40:25.484: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 7.885015]
2023-05-17 20:40:25.635: epoch 138:	0.02685643  	0.19738385  	0.10894169  
2023-05-17 20:40:34.789: [iter 139 : loss : 0.1143 = 0.0248 + 0.0830 + 0.0065, time: 9.151969]
2023-05-17 20:40:35.112: epoch 139:	0.02692700  	0.19770950  	0.10923461  
2023-05-17 20:40:42.768: [iter 140 : loss : 0.1136 = 0.0240 + 0.0829 + 0.0066, time: 7.655005]
2023-05-17 20:40:42.930: epoch 140:	0.02689877  	0.19762745  	0.10922239  
2023-05-17 20:40:51.319: [iter 141 : loss : 0.1143 = 0.0247 + 0.0829 + 0.0066, time: 8.388018]
2023-05-17 20:40:51.483: epoch 141:	0.02690583  	0.19776937  	0.10931337  
2023-05-17 20:40:59.792: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 8.306025]
2023-05-17 20:41:00.234: epoch 142:	0.02684232  	0.19744682  	0.10919186  
2023-05-17 20:41:08.106: [iter 143 : loss : 0.1136 = 0.0241 + 0.0828 + 0.0067, time: 7.859006]
2023-05-17 20:41:08.259: epoch 143:	0.02684938  	0.19717722  	0.10925080  
2023-05-17 20:41:17.427: [iter 144 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 9.162405]
2023-05-17 20:41:17.733: epoch 144:	0.02682821  	0.19742911  	0.10940918  
2023-05-17 20:41:25.358: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.622015]
2023-05-17 20:41:25.519: epoch 145:	0.02678587  	0.19662103  	0.10941804  
2023-05-17 20:41:33.922: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 8.401410]
2023-05-17 20:41:34.086: epoch 146:	0.02680704  	0.19670989  	0.10930018  
2023-05-17 20:41:42.601: [iter 147 : loss : 0.1129 = 0.0234 + 0.0827 + 0.0068, time: 8.514013]
2023-05-17 20:41:43.026: epoch 147:	0.02682821  	0.19706881  	0.10950402  
2023-05-17 20:41:51.091: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 8.049082]
2023-05-17 20:41:51.246: epoch 148:	0.02683527  	0.19687444  	0.10951116  
2023-05-17 20:42:00.474: [iter 149 : loss : 0.1119 = 0.0224 + 0.0826 + 0.0068, time: 9.225992]
2023-05-17 20:42:00.781: epoch 149:	0.02679998  	0.19656511  	0.10935073  
2023-05-17 20:42:08.353: [iter 150 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0068, time: 7.571515]
2023-05-17 20:42:08.524: epoch 150:	0.02676470  	0.19614962  	0.10926186  
2023-05-17 20:42:17.143: [iter 151 : loss : 0.1116 = 0.0221 + 0.0826 + 0.0069, time: 8.617258]
2023-05-17 20:42:17.299: epoch 151:	0.02682115  	0.19638406  	0.10928554  
2023-05-17 20:42:25.751: [iter 152 : loss : 0.1109 = 0.0214 + 0.0825 + 0.0069, time: 8.451016]
2023-05-17 20:42:26.270: epoch 152:	0.02679998  	0.19641641  	0.10923415  
2023-05-17 20:42:34.234: [iter 153 : loss : 0.1099 = 0.0205 + 0.0825 + 0.0069, time: 7.951041]
2023-05-17 20:42:34.387: epoch 153:	0.02682821  	0.19673765  	0.10935138  
2023-05-17 20:42:43.615: [iter 154 : loss : 0.1104 = 0.0209 + 0.0825 + 0.0069, time: 9.223024]
2023-05-17 20:42:43.927: epoch 154:	0.02677881  	0.19645716  	0.10934307  
2023-05-17 20:42:51.463: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 7.534011]
2023-05-17 20:42:51.625: epoch 155:	0.02677175  	0.19660462  	0.10938628  
2023-05-17 20:43:00.242: [iter 156 : loss : 0.1103 = 0.0208 + 0.0824 + 0.0070, time: 8.615031]
2023-05-17 20:43:00.408: epoch 156:	0.02672941  	0.19591324  	0.10918662  
2023-05-17 20:43:08.775: [iter 157 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 8.365594]
2023-05-17 20:43:09.292: epoch 157:	0.02675058  	0.19621685  	0.10922988  
2023-05-17 20:43:17.256: [iter 158 : loss : 0.1095 = 0.0201 + 0.0824 + 0.0070, time: 7.962018]
2023-05-17 20:43:17.409: epoch 158:	0.02671530  	0.19546637  	0.10893325  
2023-05-17 20:43:26.657: [iter 159 : loss : 0.1100 = 0.0206 + 0.0823 + 0.0071, time: 9.243007]
2023-05-17 20:43:26.960: epoch 159:	0.02679998  	0.19631907  	0.10913926  
2023-05-17 20:43:34.438: [iter 160 : loss : 0.1094 = 0.0200 + 0.0823 + 0.0071, time: 7.477010]
2023-05-17 20:43:34.608: epoch 160:	0.02666591  	0.19545926  	0.10889610  
2023-05-17 20:43:34.608: Early stopping is trigger at epoch: 160
2023-05-17 20:43:34.608: best_result@epoch 135:

2023-05-17 20:43:34.608: 		0.0269      	0.1981      	0.1089      
2023-05-17 21:05:59.591: my pid: 3404
2023-05-17 21:05:59.592: model: model.general_recommender.SGL
2023-05-17 21:05:59.592: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-17 21:05:59.592: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-17 21:06:02.836: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-17 21:06:12.368: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.532598]
2023-05-17 21:06:12.520: epoch 1:	0.00140418  	0.00999632  	0.00463322  
2023-05-17 21:06:12.520: Find a better model.
2023-05-17 21:06:21.918: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 9.395893]
2023-05-17 21:06:22.103: epoch 2:	0.00249083  	0.01815438  	0.00927108  
2023-05-17 21:06:22.104: Find a better model.
2023-05-17 21:06:31.627: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 9.521505]
2023-05-17 21:06:31.800: epoch 3:	0.00472761  	0.03494053  	0.01721612  
2023-05-17 21:06:31.800: Find a better model.
2023-05-17 21:06:42.283: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 10.482037]
2023-05-17 21:06:42.472: epoch 4:	0.00777583  	0.05726621  	0.02809872  
2023-05-17 21:06:42.472: Find a better model.
2023-05-17 21:06:51.769: [iter 5 : loss : 0.7697 = 0.6909 + 0.0788 + 0.0000, time: 9.294374]
2023-05-17 21:06:51.931: epoch 5:	0.01149453  	0.08325780  	0.04026189  
2023-05-17 21:06:51.931: Find a better model.
2023-05-17 21:07:01.830: [iter 6 : loss : 0.7675 = 0.6884 + 0.0791 + 0.0000, time: 9.897300]
2023-05-17 21:07:01.995: epoch 6:	0.01503686  	0.10832009  	0.05333314  
2023-05-17 21:07:01.995: Find a better model.
2023-05-17 21:07:12.492: [iter 7 : loss : 0.7616 = 0.6817 + 0.0799 + 0.0000, time: 10.488028]
2023-05-17 21:07:12.749: epoch 7:	0.01756305  	0.12853807  	0.06375013  
2023-05-17 21:07:12.749: Find a better model.
2023-05-17 21:07:22.362: [iter 8 : loss : 0.7468 = 0.6651 + 0.0816 + 0.0001, time: 9.611653]
2023-05-17 21:07:22.567: epoch 8:	0.01860034  	0.13620125  	0.06876267  
2023-05-17 21:07:22.567: Find a better model.
2023-05-17 21:07:32.011: [iter 9 : loss : 0.7131 = 0.6276 + 0.0853 + 0.0001, time: 9.443025]
2023-05-17 21:07:32.183: epoch 9:	0.01880499  	0.13885182  	0.06957632  
2023-05-17 21:07:32.183: Find a better model.
2023-05-17 21:07:41.422: [iter 10 : loss : 0.6538 = 0.5629 + 0.0907 + 0.0002, time: 9.237012]
2023-05-17 21:07:41.913: epoch 10:	0.01861445  	0.13793290  	0.06877846  
2023-05-17 21:07:50.750: [iter 11 : loss : 0.5786 = 0.4825 + 0.0958 + 0.0004, time: 8.835036]
2023-05-17 21:07:50.901: epoch 11:	0.01861446  	0.13784125  	0.06840448  
2023-05-17 21:08:01.002: [iter 12 : loss : 0.5092 = 0.4093 + 0.0993 + 0.0005, time: 10.092001]
2023-05-17 21:08:01.307: epoch 12:	0.01863563  	0.13756135  	0.06855438  
2023-05-17 21:08:10.250: [iter 13 : loss : 0.4573 = 0.3555 + 0.1011 + 0.0007, time: 8.942433]
2023-05-17 21:08:10.408: epoch 13:	0.01843805  	0.13642062  	0.06832577  
2023-05-17 21:08:19.349: [iter 14 : loss : 0.4181 = 0.3152 + 0.1021 + 0.0008, time: 8.939981]
2023-05-17 21:08:19.553: epoch 14:	0.01864268  	0.13830422  	0.06939448  
2023-05-17 21:08:28.933: [iter 15 : loss : 0.3908 = 0.2873 + 0.1025 + 0.0010, time: 9.377992]
2023-05-17 21:08:29.098: epoch 15:	0.01881203  	0.13931111  	0.07011529  
2023-05-17 21:08:29.098: Find a better model.
2023-05-17 21:08:39.463: [iter 16 : loss : 0.3680 = 0.2643 + 0.1026 + 0.0011, time: 10.362036]
2023-05-17 21:08:39.741: epoch 16:	0.01912958  	0.14162455  	0.07132296  
2023-05-17 21:08:39.741: Find a better model.
2023-05-17 21:08:49.927: [iter 17 : loss : 0.3512 = 0.2476 + 0.1024 + 0.0012, time: 10.182043]
2023-05-17 21:08:50.226: epoch 17:	0.01939773  	0.14325458  	0.07242286  
2023-05-17 21:08:50.226: Find a better model.
2023-05-17 21:08:59.571: [iter 18 : loss : 0.3357 = 0.2322 + 0.1021 + 0.0013, time: 9.343139]
2023-05-17 21:08:59.731: epoch 18:	0.01959532  	0.14484712  	0.07324421  
2023-05-17 21:08:59.731: Find a better model.
2023-05-17 21:09:08.902: [iter 19 : loss : 0.3214 = 0.2182 + 0.1018 + 0.0014, time: 9.169140]
2023-05-17 21:09:09.235: epoch 19:	0.01975762  	0.14587048  	0.07413002  
2023-05-17 21:09:09.235: Find a better model.
2023-05-17 21:09:18.173: [iter 20 : loss : 0.3115 = 0.2087 + 0.1013 + 0.0015, time: 8.937299]
2023-05-17 21:09:18.337: epoch 20:	0.01995520  	0.14696844  	0.07476844  
2023-05-17 21:09:18.338: Find a better model.
2023-05-17 21:09:28.483: [iter 21 : loss : 0.3017 = 0.1992 + 0.1010 + 0.0016, time: 10.135968]
2023-05-17 21:09:29.009: epoch 21:	0.02031508  	0.14939219  	0.07587275  
2023-05-17 21:09:29.010: Find a better model.
2023-05-17 21:09:37.572: [iter 22 : loss : 0.2933 = 0.1911 + 0.1006 + 0.0016, time: 8.558073]
2023-05-17 21:09:37.737: epoch 22:	0.02035742  	0.15017411  	0.07658580  
2023-05-17 21:09:37.737: Find a better model.
2023-05-17 21:09:46.884: [iter 23 : loss : 0.2851 = 0.1833 + 0.1001 + 0.0017, time: 9.146027]
2023-05-17 21:09:47.035: epoch 23:	0.02043505  	0.15065482  	0.07715219  
2023-05-17 21:09:47.035: Find a better model.
2023-05-17 21:09:56.480: [iter 24 : loss : 0.2784 = 0.1769 + 0.0997 + 0.0018, time: 9.443002]
2023-05-17 21:09:56.630: epoch 24:	0.02064674  	0.15243959  	0.07808947  
2023-05-17 21:09:56.631: Find a better model.
2023-05-17 21:10:05.508: [iter 25 : loss : 0.2717 = 0.1706 + 0.0992 + 0.0019, time: 8.875044]
2023-05-17 21:10:05.656: epoch 25:	0.02093606  	0.15478814  	0.07910858  
2023-05-17 21:10:05.656: Find a better model.
2023-05-17 21:10:15.852: [iter 26 : loss : 0.2681 = 0.1673 + 0.0988 + 0.0019, time: 10.188039]
2023-05-17 21:10:16.158: epoch 26:	0.02101367  	0.15518112  	0.07959463  
2023-05-17 21:10:16.158: Find a better model.
2023-05-17 21:10:25.179: [iter 27 : loss : 0.2602 = 0.1597 + 0.0984 + 0.0020, time: 9.019015]
2023-05-17 21:10:25.331: epoch 27:	0.02109835  	0.15587318  	0.08013280  
2023-05-17 21:10:25.331: Find a better model.
2023-05-17 21:10:34.079: [iter 28 : loss : 0.2554 = 0.1553 + 0.0980 + 0.0021, time: 8.747969]
2023-05-17 21:10:34.248: epoch 28:	0.02127477  	0.15689994  	0.08075865  
2023-05-17 21:10:34.248: Find a better model.
2023-05-17 21:10:43.475: [iter 29 : loss : 0.2509 = 0.1511 + 0.0976 + 0.0021, time: 9.226001]
2023-05-17 21:10:43.624: epoch 29:	0.02147941  	0.15857826  	0.08165720  
2023-05-17 21:10:43.624: Find a better model.
2023-05-17 21:10:53.845: [iter 30 : loss : 0.2445 = 0.1450 + 0.0972 + 0.0022, time: 10.217046]
2023-05-17 21:10:54.146: epoch 30:	0.02157820  	0.15928832  	0.08228721  
2023-05-17 21:10:54.146: Find a better model.
2023-05-17 21:11:04.375: [iter 31 : loss : 0.2408 = 0.1417 + 0.0968 + 0.0023, time: 10.226029]
2023-05-17 21:11:04.674: epoch 31:	0.02173344  	0.16042741  	0.08273019  
2023-05-17 21:11:04.674: Find a better model.
2023-05-17 21:11:13.705: [iter 32 : loss : 0.2352 = 0.1364 + 0.0965 + 0.0023, time: 9.030072]
2023-05-17 21:11:13.872: epoch 32:	0.02199453  	0.16210230  	0.08377018  
2023-05-17 21:11:13.872: Find a better model.
2023-05-17 21:11:22.724: [iter 33 : loss : 0.2325 = 0.1340 + 0.0961 + 0.0024, time: 8.850006]
2023-05-17 21:11:22.972: epoch 33:	0.02210744  	0.16283616  	0.08417027  
2023-05-17 21:11:22.972: Find a better model.
2023-05-17 21:11:32.123: [iter 34 : loss : 0.2282 = 0.1300 + 0.0957 + 0.0024, time: 9.149253]
2023-05-17 21:11:32.277: epoch 34:	0.02235442  	0.16477317  	0.08508421  
2023-05-17 21:11:32.277: Find a better model.
2023-05-17 21:11:42.324: [iter 35 : loss : 0.2248 = 0.1269 + 0.0954 + 0.0025, time: 10.044023]
2023-05-17 21:11:42.603: epoch 35:	0.02243204  	0.16570757  	0.08581415  
2023-05-17 21:11:42.603: Find a better model.
2023-05-17 21:11:51.048: [iter 36 : loss : 0.2212 = 0.1236 + 0.0951 + 0.0025, time: 8.444012]
2023-05-17 21:11:51.214: epoch 36:	0.02252377  	0.16600084  	0.08637157  
2023-05-17 21:11:51.214: Find a better model.
2023-05-17 21:12:00.501: [iter 37 : loss : 0.2175 = 0.1201 + 0.0948 + 0.0026, time: 9.286023]
2023-05-17 21:12:00.655: epoch 37:	0.02267196  	0.16771965  	0.08719973  
2023-05-17 21:12:00.656: Find a better model.
2023-05-17 21:12:09.867: [iter 38 : loss : 0.2159 = 0.1187 + 0.0945 + 0.0027, time: 9.208016]
2023-05-17 21:12:10.137: epoch 38:	0.02286249  	0.16871314  	0.08781236  
2023-05-17 21:12:10.137: Find a better model.
2023-05-17 21:12:18.875: [iter 39 : loss : 0.2112 = 0.1144 + 0.0941 + 0.0027, time: 8.735321]
2023-05-17 21:12:19.028: epoch 39:	0.02296128  	0.16982394  	0.08857346  
2023-05-17 21:12:19.028: Find a better model.
2023-05-17 21:12:29.105: [iter 40 : loss : 0.2080 = 0.1114 + 0.0938 + 0.0028, time: 10.073654]
2023-05-17 21:12:29.410: epoch 40:	0.02303890  	0.17044860  	0.08898436  
2023-05-17 21:12:29.411: Find a better model.
2023-05-17 21:12:38.229: [iter 41 : loss : 0.2064 = 0.1100 + 0.0936 + 0.0028, time: 8.816027]
2023-05-17 21:12:38.475: epoch 41:	0.02319414  	0.17136209  	0.08983829  
2023-05-17 21:12:38.475: Find a better model.
2023-05-17 21:12:47.222: [iter 42 : loss : 0.2039 = 0.1077 + 0.0933 + 0.0029, time: 8.744992]
2023-05-17 21:12:47.371: epoch 42:	0.02327882  	0.17216797  	0.09033356  
2023-05-17 21:12:47.371: Find a better model.
2023-05-17 21:12:56.828: [iter 43 : loss : 0.2003 = 0.1044 + 0.0930 + 0.0029, time: 9.455012]
2023-05-17 21:12:56.997: epoch 43:	0.02343406  	0.17291881  	0.09082287  
2023-05-17 21:12:56.997: Find a better model.
2023-05-17 21:13:07.561: [iter 44 : loss : 0.1968 = 0.1010 + 0.0928 + 0.0030, time: 10.561529]
2023-05-17 21:13:07.842: epoch 44:	0.02347640  	0.17321774  	0.09141378  
2023-05-17 21:13:07.842: Find a better model.
2023-05-17 21:13:18.073: [iter 45 : loss : 0.1946 = 0.0990 + 0.0925 + 0.0030, time: 10.229138]
2023-05-17 21:13:18.378: epoch 45:	0.02352579  	0.17363447  	0.09198897  
2023-05-17 21:13:18.378: Find a better model.
2023-05-17 21:13:27.465: [iter 46 : loss : 0.1922 = 0.0968 + 0.0923 + 0.0031, time: 9.086191]
2023-05-17 21:13:27.628: epoch 46:	0.02361047  	0.17464544  	0.09239089  
2023-05-17 21:13:27.628: Find a better model.
2023-05-17 21:13:36.456: [iter 47 : loss : 0.1915 = 0.0963 + 0.0920 + 0.0031, time: 8.826016]
2023-05-17 21:13:36.613: epoch 47:	0.02377277  	0.17567845  	0.09298606  
2023-05-17 21:13:36.613: Find a better model.
2023-05-17 21:13:45.906: [iter 48 : loss : 0.1877 = 0.0927 + 0.0918 + 0.0032, time: 9.291022]
2023-05-17 21:13:46.082: epoch 48:	0.02392801  	0.17684381  	0.09357153  
2023-05-17 21:13:46.082: Find a better model.
2023-05-17 21:13:56.139: [iter 49 : loss : 0.1844 = 0.0896 + 0.0916 + 0.0032, time: 10.050028]
2023-05-17 21:13:56.402: epoch 49:	0.02399152  	0.17706080  	0.09423801  
2023-05-17 21:13:56.402: Find a better model.
2023-05-17 21:14:04.869: [iter 50 : loss : 0.1837 = 0.0891 + 0.0913 + 0.0033, time: 8.465021]
2023-05-17 21:14:05.038: epoch 50:	0.02409031  	0.17804496  	0.09481796  
2023-05-17 21:14:05.038: Find a better model.
2023-05-17 21:14:14.314: [iter 51 : loss : 0.1805 = 0.0861 + 0.0911 + 0.0033, time: 9.274018]
2023-05-17 21:14:14.486: epoch 51:	0.02412559  	0.17815328  	0.09516698  
2023-05-17 21:14:14.486: Find a better model.
2023-05-17 21:14:23.624: [iter 52 : loss : 0.1805 = 0.0861 + 0.0910 + 0.0034, time: 9.136009]
2023-05-17 21:14:23.972: epoch 52:	0.02420321  	0.17904897  	0.09570853  
2023-05-17 21:14:23.972: Find a better model.
2023-05-17 21:14:32.768: [iter 53 : loss : 0.1784 = 0.0843 + 0.0907 + 0.0034, time: 8.793992]
2023-05-17 21:14:32.938: epoch 53:	0.02426671  	0.17932579  	0.09615204  
2023-05-17 21:14:32.938: Find a better model.
2023-05-17 21:14:43.086: [iter 54 : loss : 0.1764 = 0.0825 + 0.0905 + 0.0035, time: 10.145003]
2023-05-17 21:14:43.384: epoch 54:	0.02437961  	0.18048021  	0.09671023  
2023-05-17 21:14:43.384: Find a better model.
2023-05-17 21:14:52.624: [iter 55 : loss : 0.1744 = 0.0805 + 0.0903 + 0.0035, time: 9.238992]
2023-05-17 21:14:52.789: epoch 55:	0.02450663  	0.18122821  	0.09733147  
2023-05-17 21:14:52.789: Find a better model.
2023-05-17 21:15:01.403: [iter 56 : loss : 0.1727 = 0.0790 + 0.0902 + 0.0036, time: 8.612003]
2023-05-17 21:15:01.589: epoch 56:	0.02459837  	0.18181203  	0.09767464  
2023-05-17 21:15:01.589: Find a better model.
2023-05-17 21:15:11.006: [iter 57 : loss : 0.1707 = 0.0772 + 0.0900 + 0.0036, time: 9.416021]
2023-05-17 21:15:11.159: epoch 57:	0.02466893  	0.18224882  	0.09795745  
2023-05-17 21:15:11.159: Find a better model.
2023-05-17 21:15:21.592: [iter 58 : loss : 0.1689 = 0.0755 + 0.0898 + 0.0036, time: 10.431082]
2023-05-17 21:15:21.852: epoch 58:	0.02473244  	0.18325196  	0.09833529  
2023-05-17 21:15:21.852: Find a better model.
2023-05-17 21:15:32.007: [iter 59 : loss : 0.1678 = 0.0745 + 0.0896 + 0.0037, time: 10.153032]
2023-05-17 21:15:32.306: epoch 59:	0.02489473  	0.18426120  	0.09887034  
2023-05-17 21:15:32.306: Find a better model.
2023-05-17 21:15:41.666: [iter 60 : loss : 0.1665 = 0.0734 + 0.0894 + 0.0037, time: 9.358016]
2023-05-17 21:15:41.837: epoch 60:	0.02493707  	0.18423840  	0.09924149  
2023-05-17 21:15:50.888: [iter 61 : loss : 0.1649 = 0.0718 + 0.0893 + 0.0038, time: 9.049176]
2023-05-17 21:15:51.225: epoch 61:	0.02495823  	0.18447232  	0.09941946  
2023-05-17 21:15:51.225: Find a better model.
2023-05-17 21:16:00.029: [iter 62 : loss : 0.1632 = 0.0703 + 0.0891 + 0.0038, time: 8.803009]
2023-05-17 21:16:00.186: epoch 62:	0.02497940  	0.18481441  	0.09963285  
2023-05-17 21:16:00.186: Find a better model.
2023-05-17 21:16:10.188: [iter 63 : loss : 0.1618 = 0.0690 + 0.0889 + 0.0039, time: 10.001015]
2023-05-17 21:16:10.453: epoch 63:	0.02507819  	0.18544824  	0.10004154  
2023-05-17 21:16:10.453: Find a better model.
2023-05-17 21:16:18.908: [iter 64 : loss : 0.1608 = 0.0681 + 0.0888 + 0.0039, time: 8.453003]
2023-05-17 21:16:19.073: epoch 64:	0.02513464  	0.18556266  	0.10027948  
2023-05-17 21:16:19.073: Find a better model.
2023-05-17 21:16:28.219: [iter 65 : loss : 0.1599 = 0.0673 + 0.0886 + 0.0040, time: 9.144002]
2023-05-17 21:16:28.391: epoch 65:	0.02524049  	0.18632127  	0.10063753  
2023-05-17 21:16:28.391: Find a better model.
2023-05-17 21:16:37.445: [iter 66 : loss : 0.1584 = 0.0659 + 0.0885 + 0.0040, time: 9.051170]
2023-05-17 21:16:37.862: epoch 66:	0.02531105  	0.18681610  	0.10087897  
2023-05-17 21:16:37.862: Find a better model.
2023-05-17 21:16:46.582: [iter 67 : loss : 0.1564 = 0.0641 + 0.0883 + 0.0040, time: 8.718013]
2023-05-17 21:16:46.733: epoch 67:	0.02536045  	0.18714187  	0.10114923  
2023-05-17 21:16:46.733: Find a better model.
2023-05-17 21:16:56.836: [iter 68 : loss : 0.1563 = 0.0640 + 0.0882 + 0.0041, time: 10.101119]
2023-05-17 21:16:57.136: epoch 68:	0.02540985  	0.18765312  	0.10178088  
2023-05-17 21:16:57.136: Find a better model.
2023-05-17 21:17:06.070: [iter 69 : loss : 0.1544 = 0.0622 + 0.0881 + 0.0041, time: 8.932003]
2023-05-17 21:17:06.294: epoch 69:	0.02543807  	0.18777034  	0.10199913  
2023-05-17 21:17:06.294: Find a better model.
2023-05-17 21:17:15.148: [iter 70 : loss : 0.1526 = 0.0605 + 0.0879 + 0.0042, time: 8.852467]
2023-05-17 21:17:15.309: epoch 70:	0.02540279  	0.18752106  	0.10202981  
2023-05-17 21:17:24.948: [iter 71 : loss : 0.1512 = 0.0592 + 0.0878 + 0.0042, time: 9.636020]
2023-05-17 21:17:25.110: epoch 71:	0.02548746  	0.18801485  	0.10228185  
2023-05-17 21:17:25.110: Find a better model.
2023-05-17 21:17:35.497: [iter 72 : loss : 0.1511 = 0.0591 + 0.0877 + 0.0042, time: 10.385822]
2023-05-17 21:17:35.762: epoch 72:	0.02553686  	0.18860516  	0.10242108  
2023-05-17 21:17:35.762: Find a better model.
2023-05-17 21:17:46.002: [iter 73 : loss : 0.1495 = 0.0577 + 0.0876 + 0.0043, time: 10.237238]
2023-05-17 21:17:46.313: epoch 73:	0.02563565  	0.18899694  	0.10261677  
2023-05-17 21:17:46.313: Find a better model.
2023-05-17 21:17:55.577: [iter 74 : loss : 0.1483 = 0.0565 + 0.0874 + 0.0043, time: 9.262020]
2023-05-17 21:17:55.746: epoch 74:	0.02563565  	0.18906051  	0.10272829  
2023-05-17 21:17:55.746: Find a better model.
2023-05-17 21:18:04.887: [iter 75 : loss : 0.1478 = 0.0561 + 0.0873 + 0.0044, time: 9.139001]
2023-05-17 21:18:05.239: epoch 75:	0.02579089  	0.19011660  	0.10314739  
2023-05-17 21:18:05.239: Find a better model.
2023-05-17 21:18:14.178: [iter 76 : loss : 0.1467 = 0.0551 + 0.0872 + 0.0044, time: 8.937937]
2023-05-17 21:18:14.348: epoch 76:	0.02588968  	0.19071911  	0.10343070  
2023-05-17 21:18:14.348: Find a better model.
2023-05-17 21:18:24.458: [iter 77 : loss : 0.1457 = 0.0542 + 0.0871 + 0.0045, time: 10.108077]
2023-05-17 21:18:24.762: epoch 77:	0.02588263  	0.19066675  	0.10368707  
2023-05-17 21:18:33.257: [iter 78 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 8.494012]
2023-05-17 21:18:33.426: epoch 78:	0.02596731  	0.19162685  	0.10416308  
2023-05-17 21:18:33.426: Find a better model.
2023-05-17 21:18:42.751: [iter 79 : loss : 0.1436 = 0.0522 + 0.0869 + 0.0045, time: 9.324048]
2023-05-17 21:18:42.900: epoch 79:	0.02590380  	0.19116475  	0.10403978  
2023-05-17 21:18:52.091: [iter 80 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 9.189016]
2023-05-17 21:18:52.254: epoch 80:	0.02600259  	0.19163366  	0.10434698  
2023-05-17 21:18:52.254: Find a better model.
2023-05-17 21:19:01.119: [iter 81 : loss : 0.1426 = 0.0513 + 0.0867 + 0.0046, time: 8.863001]
2023-05-17 21:19:01.269: epoch 81:	0.02596025  	0.19140470  	0.10445748  
2023-05-17 21:19:11.433: [iter 82 : loss : 0.1411 = 0.0499 + 0.0866 + 0.0047, time: 10.156045]
2023-05-17 21:19:11.728: epoch 82:	0.02600259  	0.19170974  	0.10493626  
2023-05-17 21:19:11.728: Find a better model.
2023-05-17 21:19:20.965: [iter 83 : loss : 0.1404 = 0.0492 + 0.0865 + 0.0047, time: 9.236017]
2023-05-17 21:19:21.128: epoch 83:	0.02608021  	0.19207688  	0.10520646  
2023-05-17 21:19:21.128: Find a better model.
2023-05-17 21:19:29.901: [iter 84 : loss : 0.1400 = 0.0490 + 0.0863 + 0.0047, time: 8.772006]
2023-05-17 21:19:30.071: epoch 84:	0.02624957  	0.19343586  	0.10564516  
2023-05-17 21:19:30.072: Find a better model.
2023-05-17 21:19:39.500: [iter 85 : loss : 0.1394 = 0.0483 + 0.0862 + 0.0048, time: 9.427016]
2023-05-17 21:19:39.652: epoch 85:	0.02624252  	0.19337942  	0.10578950  
2023-05-17 21:19:49.820: [iter 86 : loss : 0.1391 = 0.0482 + 0.0861 + 0.0048, time: 10.166105]
2023-05-17 21:19:50.123: epoch 86:	0.02624252  	0.19351240  	0.10604200  
2023-05-17 21:19:50.123: Find a better model.
2023-05-17 21:20:00.339: [iter 87 : loss : 0.1362 = 0.0453 + 0.0861 + 0.0048, time: 10.205021]
2023-05-17 21:20:00.637: epoch 87:	0.02630603  	0.19390692  	0.10619889  
2023-05-17 21:20:00.637: Find a better model.
2023-05-17 21:20:09.902: [iter 88 : loss : 0.1358 = 0.0450 + 0.0860 + 0.0049, time: 9.264001]
2023-05-17 21:20:10.078: epoch 88:	0.02642599  	0.19494689  	0.10650629  
2023-05-17 21:20:10.078: Find a better model.
2023-05-17 21:20:18.889: [iter 89 : loss : 0.1355 = 0.0447 + 0.0859 + 0.0049, time: 8.809213]
2023-05-17 21:20:19.047: epoch 89:	0.02634837  	0.19449417  	0.10634924  
2023-05-17 21:20:28.480: [iter 90 : loss : 0.1358 = 0.0450 + 0.0858 + 0.0050, time: 9.432078]
2023-05-17 21:20:28.671: epoch 90:	0.02633426  	0.19452536  	0.10659525  
2023-05-17 21:20:38.750: [iter 91 : loss : 0.1348 = 0.0441 + 0.0857 + 0.0050, time: 10.076014]
2023-05-17 21:20:39.020: epoch 91:	0.02645422  	0.19531082  	0.10694075  
2023-05-17 21:20:39.020: Find a better model.
2023-05-17 21:20:47.492: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 8.470574]
2023-05-17 21:20:47.658: epoch 92:	0.02648950  	0.19534984  	0.10705971  
2023-05-17 21:20:47.658: Find a better model.
2023-05-17 21:20:56.744: [iter 93 : loss : 0.1340 = 0.0434 + 0.0855 + 0.0051, time: 9.084991]
2023-05-17 21:20:56.909: epoch 93:	0.02647538  	0.19515820  	0.10716854  
2023-05-17 21:21:05.914: [iter 94 : loss : 0.1318 = 0.0413 + 0.0854 + 0.0051, time: 9.002001]
2023-05-17 21:21:06.074: epoch 94:	0.02649655  	0.19550821  	0.10732067  
2023-05-17 21:21:06.074: Find a better model.
2023-05-17 21:21:15.065: [iter 95 : loss : 0.1312 = 0.0406 + 0.0854 + 0.0051, time: 8.990027]
2023-05-17 21:21:15.227: epoch 95:	0.02651772  	0.19553642  	0.10736521  
2023-05-17 21:21:15.227: Find a better model.
2023-05-17 21:21:25.230: [iter 96 : loss : 0.1312 = 0.0407 + 0.0853 + 0.0052, time: 10.001045]
2023-05-17 21:21:25.533: epoch 96:	0.02655300  	0.19577041  	0.10742832  
2023-05-17 21:21:25.533: Find a better model.
2023-05-17 21:21:34.322: [iter 97 : loss : 0.1297 = 0.0392 + 0.0853 + 0.0052, time: 8.788002]
2023-05-17 21:21:34.490: epoch 97:	0.02658123  	0.19574656  	0.10743202  
2023-05-17 21:21:43.435: [iter 98 : loss : 0.1305 = 0.0401 + 0.0851 + 0.0053, time: 8.943008]
2023-05-17 21:21:43.597: epoch 98:	0.02661652  	0.19608116  	0.10759880  
2023-05-17 21:21:43.597: Find a better model.
2023-05-17 21:21:52.901: [iter 99 : loss : 0.1294 = 0.0390 + 0.0851 + 0.0053, time: 9.302536]
2023-05-17 21:21:53.070: epoch 99:	0.02658124  	0.19583559  	0.10763141  
2023-05-17 21:22:01.866: [iter 100 : loss : 0.1286 = 0.0382 + 0.0850 + 0.0053, time: 8.795043]
2023-05-17 21:22:02.018: epoch 100:	0.02657418  	0.19587615  	0.10784411  
2023-05-17 21:22:12.204: [iter 101 : loss : 0.1283 = 0.0380 + 0.0849 + 0.0054, time: 10.182035]
2023-05-17 21:22:12.510: epoch 101:	0.02667297  	0.19656381  	0.10810677  
2023-05-17 21:22:12.510: Find a better model.
2023-05-17 21:22:21.800: [iter 102 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 9.288271]
2023-05-17 21:22:21.975: epoch 102:	0.02665886  	0.19649415  	0.10809419  
2023-05-17 21:22:30.661: [iter 103 : loss : 0.1271 = 0.0368 + 0.0848 + 0.0054, time: 8.685039]
2023-05-17 21:22:30.826: epoch 103:	0.02670119  	0.19699015  	0.10833199  
2023-05-17 21:22:30.827: Find a better model.
2023-05-17 21:22:40.220: [iter 104 : loss : 0.1277 = 0.0374 + 0.0847 + 0.0055, time: 9.391313]
2023-05-17 21:22:40.384: epoch 104:	0.02674353  	0.19715278  	0.10857645  
2023-05-17 21:22:40.385: Find a better model.
2023-05-17 21:22:50.544: [iter 105 : loss : 0.1268 = 0.0366 + 0.0847 + 0.0055, time: 10.155403]
2023-05-17 21:22:50.852: epoch 105:	0.02677881  	0.19760039  	0.10887706  
2023-05-17 21:22:50.853: Find a better model.
2023-05-17 21:23:00.940: [iter 106 : loss : 0.1261 = 0.0359 + 0.0846 + 0.0055, time: 10.086144]
2023-05-17 21:23:01.233: epoch 106:	0.02677881  	0.19760549  	0.10873986  
2023-05-17 21:23:01.233: Find a better model.
2023-05-17 21:23:10.452: [iter 107 : loss : 0.1254 = 0.0353 + 0.0846 + 0.0056, time: 9.217004]
2023-05-17 21:23:10.622: epoch 107:	0.02678587  	0.19773647  	0.10889513  
2023-05-17 21:23:10.622: Find a better model.
2023-05-17 21:23:19.890: [iter 108 : loss : 0.1254 = 0.0353 + 0.0845 + 0.0056, time: 9.267030]
2023-05-17 21:23:20.056: epoch 108:	0.02678587  	0.19781162  	0.10910326  
2023-05-17 21:23:20.056: Find a better model.
2023-05-17 21:23:28.896: [iter 109 : loss : 0.1238 = 0.0337 + 0.0844 + 0.0056, time: 8.839093]
2023-05-17 21:23:29.063: epoch 109:	0.02679293  	0.19773050  	0.10882209  
2023-05-17 21:23:39.067: [iter 110 : loss : 0.1233 = 0.0333 + 0.0844 + 0.0057, time: 10.002024]
2023-05-17 21:23:39.365: epoch 110:	0.02677883  	0.19793141  	0.10900338  
2023-05-17 21:23:39.365: Find a better model.
2023-05-17 21:23:47.729: [iter 111 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0057, time: 8.363099]
2023-05-17 21:23:47.895: epoch 111:	0.02676471  	0.19767196  	0.10898538  
2023-05-17 21:23:57.058: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 9.160992]
2023-05-17 21:23:57.222: epoch 112:	0.02682116  	0.19797146  	0.10918815  
2023-05-17 21:23:57.222: Find a better model.
2023-05-17 21:24:06.039: [iter 113 : loss : 0.1231 = 0.0331 + 0.0842 + 0.0058, time: 8.814966]
2023-05-17 21:24:06.202: epoch 113:	0.02683527  	0.19797112  	0.10919133  
2023-05-17 21:24:14.982: [iter 114 : loss : 0.1222 = 0.0322 + 0.0841 + 0.0058, time: 8.778182]
2023-05-17 21:24:15.142: epoch 114:	0.02685644  	0.19817375  	0.10925148  
2023-05-17 21:24:15.142: Find a better model.
2023-05-17 21:24:25.189: [iter 115 : loss : 0.1217 = 0.0318 + 0.0841 + 0.0058, time: 10.044023]
2023-05-17 21:24:25.499: epoch 115:	0.02693407  	0.19871850  	0.10943411  
2023-05-17 21:24:25.499: Find a better model.
2023-05-17 21:24:33.840: [iter 116 : loss : 0.1210 = 0.0311 + 0.0840 + 0.0059, time: 8.339065]
2023-05-17 21:24:34.002: epoch 116:	0.02691995  	0.19860058  	0.10942350  
2023-05-17 21:24:42.799: [iter 117 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.795063]
2023-05-17 21:24:42.951: epoch 117:	0.02686350  	0.19810437  	0.10936684  
2023-05-17 21:24:52.246: [iter 118 : loss : 0.1208 = 0.0310 + 0.0839 + 0.0059, time: 9.294009]
2023-05-17 21:24:52.409: epoch 118:	0.02688467  	0.19849193  	0.10954913  
2023-05-17 21:25:01.189: [iter 119 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 8.777027]
2023-05-17 21:25:01.353: epoch 119:	0.02687056  	0.19865632  	0.10979202  
2023-05-17 21:25:11.416: [iter 120 : loss : 0.1201 = 0.0303 + 0.0838 + 0.0060, time: 10.061031]
2023-05-17 21:25:11.719: epoch 120:	0.02693406  	0.19891103  	0.10989321  
2023-05-17 21:25:11.719: Find a better model.
2023-05-17 21:25:20.934: [iter 121 : loss : 0.1198 = 0.0300 + 0.0837 + 0.0060, time: 9.214005]
2023-05-17 21:25:21.104: epoch 121:	0.02691289  	0.19881146  	0.10990041  
2023-05-17 21:25:29.772: [iter 122 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 8.665969]
2023-05-17 21:25:29.953: epoch 122:	0.02696934  	0.19927396  	0.11001785  
2023-05-17 21:25:29.953: Find a better model.
2023-05-17 21:25:39.576: [iter 123 : loss : 0.1186 = 0.0289 + 0.0836 + 0.0061, time: 9.622017]
2023-05-17 21:25:39.725: epoch 123:	0.02696934  	0.19910751  	0.10987266  
2023-05-17 21:25:50.168: [iter 124 : loss : 0.1183 = 0.0286 + 0.0836 + 0.0061, time: 10.439477]
2023-05-17 21:25:50.430: epoch 124:	0.02692700  	0.19882973  	0.10992465  
2023-05-17 21:26:00.439: [iter 125 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0061, time: 9.999135]
2023-05-17 21:26:00.730: epoch 125:	0.02699757  	0.19944312  	0.11013075  
2023-05-17 21:26:00.730: Find a better model.
2023-05-17 21:26:09.705: [iter 126 : loss : 0.1177 = 0.0280 + 0.0835 + 0.0062, time: 8.974002]
2023-05-17 21:26:09.935: epoch 126:	0.02706814  	0.19977053  	0.11035553  
2023-05-17 21:26:09.935: Find a better model.
2023-05-17 21:26:18.611: [iter 127 : loss : 0.1168 = 0.0271 + 0.0835 + 0.0062, time: 8.673990]
2023-05-17 21:26:18.780: epoch 127:	0.02695524  	0.19898243  	0.11027368  
2023-05-17 21:26:27.780: [iter 128 : loss : 0.1177 = 0.0280 + 0.0834 + 0.0062, time: 8.997253]
2023-05-17 21:26:27.952: epoch 128:	0.02694818  	0.19888243  	0.11029851  
2023-05-17 21:26:37.927: [iter 129 : loss : 0.1169 = 0.0273 + 0.0834 + 0.0063, time: 9.970024]
2023-05-17 21:26:38.215: epoch 129:	0.02693407  	0.19857752  	0.11040708  
2023-05-17 21:26:47.666: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 9.450011]
2023-05-17 21:26:47.843: epoch 130:	0.02696229  	0.19894485  	0.11046891  
2023-05-17 21:26:56.937: [iter 131 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0063, time: 9.091016]
2023-05-17 21:26:57.113: epoch 131:	0.02701874  	0.19921319  	0.11070789  
2023-05-17 21:27:06.221: [iter 132 : loss : 0.1164 = 0.0267 + 0.0833 + 0.0064, time: 9.106002]
2023-05-17 21:27:06.558: epoch 132:	0.02699757  	0.19902219  	0.11047650  
2023-05-17 21:27:15.584: [iter 133 : loss : 0.1151 = 0.0254 + 0.0832 + 0.0064, time: 9.013281]
2023-05-17 21:27:15.749: epoch 133:	0.02703991  	0.19953187  	0.11067085  
2023-05-17 21:27:25.766: [iter 134 : loss : 0.1156 = 0.0260 + 0.0832 + 0.0064, time: 10.012024]
2023-05-17 21:27:26.075: epoch 134:	0.02693406  	0.19866744  	0.11062788  
2023-05-17 21:27:34.498: [iter 135 : loss : 0.1155 = 0.0259 + 0.0831 + 0.0064, time: 8.419988]
2023-05-17 21:27:34.661: epoch 135:	0.02686350  	0.19749333  	0.11016110  
2023-05-17 21:27:43.526: [iter 136 : loss : 0.1151 = 0.0256 + 0.0831 + 0.0065, time: 8.863013]
2023-05-17 21:27:43.678: epoch 136:	0.02691995  	0.19840325  	0.11042994  
2023-05-17 21:27:53.129: [iter 137 : loss : 0.1146 = 0.0251 + 0.0830 + 0.0065, time: 9.448964]
2023-05-17 21:27:53.295: epoch 137:	0.02700462  	0.19891301  	0.11050466  
2023-05-17 21:28:01.910: [iter 138 : loss : 0.1142 = 0.0246 + 0.0830 + 0.0065, time: 8.613037]
2023-05-17 21:28:02.071: epoch 138:	0.02689172  	0.19776885  	0.11009088  
2023-05-17 21:28:12.084: [iter 139 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0066, time: 10.010092]
2023-05-17 21:28:12.399: epoch 139:	0.02688466  	0.19770366  	0.11028163  
2023-05-17 21:28:21.131: [iter 140 : loss : 0.1136 = 0.0241 + 0.0829 + 0.0066, time: 8.730013]
2023-05-17 21:28:21.356: epoch 140:	0.02697640  	0.19814907  	0.11046716  
2023-05-17 21:28:30.130: [iter 141 : loss : 0.1140 = 0.0245 + 0.0829 + 0.0066, time: 8.771015]
2023-05-17 21:28:30.280: epoch 141:	0.02697639  	0.19847624  	0.11059456  
2023-05-17 21:28:39.511: [iter 142 : loss : 0.1131 = 0.0236 + 0.0829 + 0.0066, time: 9.230165]
2023-05-17 21:28:39.665: epoch 142:	0.02695522  	0.19832243  	0.11063154  
2023-05-17 21:28:49.304: [iter 143 : loss : 0.1133 = 0.0238 + 0.0828 + 0.0067, time: 9.636026]
2023-05-17 21:28:49.608: epoch 143:	0.02699050  	0.19867755  	0.11059572  
2023-05-17 21:28:59.598: [iter 144 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 9.987041]
2023-05-17 21:28:59.888: epoch 144:	0.02710340  	0.19973390  	0.11097903  
2023-05-17 21:29:08.635: [iter 145 : loss : 0.1124 = 0.0229 + 0.0827 + 0.0067, time: 8.744982]
2023-05-17 21:29:08.788: epoch 145:	0.02701872  	0.19884223  	0.11080573  
2023-05-17 21:29:17.097: [iter 146 : loss : 0.1127 = 0.0232 + 0.0827 + 0.0067, time: 8.307012]
2023-05-17 21:29:17.254: epoch 146:	0.02703989  	0.19883750  	0.11086053  
2023-05-17 21:29:26.081: [iter 147 : loss : 0.1128 = 0.0234 + 0.0827 + 0.0068, time: 8.826011]
2023-05-17 21:29:26.348: epoch 147:	0.02709635  	0.19910586  	0.11112208  
2023-05-17 21:29:36.181: [iter 148 : loss : 0.1114 = 0.0220 + 0.0827 + 0.0068, time: 9.828210]
2023-05-17 21:29:36.482: epoch 148:	0.02715986  	0.19948693  	0.11129697  
2023-05-17 21:29:46.385: [iter 149 : loss : 0.1117 = 0.0223 + 0.0826 + 0.0068, time: 9.901296]
2023-05-17 21:29:46.669: epoch 149:	0.02707518  	0.19901171  	0.11112583  
2023-05-17 21:29:55.485: [iter 150 : loss : 0.1113 = 0.0219 + 0.0826 + 0.0069, time: 8.815000]
2023-05-17 21:29:55.629: epoch 150:	0.02705401  	0.19858696  	0.11104003  
2023-05-17 21:30:04.406: [iter 151 : loss : 0.1113 = 0.0219 + 0.0825 + 0.0069, time: 8.775986]
2023-05-17 21:30:04.732: epoch 151:	0.02703284  	0.19887641  	0.11107883  
2023-05-17 21:30:04.732: Early stopping is trigger at epoch: 151
2023-05-17 21:30:04.732: best_result@epoch 126:

2023-05-17 21:30:04.732: 		0.0271      	0.1998      	0.1104      
2023-05-18 09:14:34.739: my pid: 13592
2023-05-18 09:14:34.739: model: model.general_recommender.SGL
2023-05-18 09:14:34.739: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 09:14:34.739: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 09:14:37.949: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 09:14:46.827: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.877404]
2023-05-18 09:14:46.989: epoch 1:	0.00150297  	0.01060166  	0.00489578  
2023-05-18 09:14:46.989: Find a better model.
2023-05-18 09:14:55.829: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 8.837803]
2023-05-18 09:14:56.024: epoch 2:	0.00247672  	0.01857004  	0.00889475  
2023-05-18 09:14:56.024: Find a better model.
2023-05-18 09:15:04.647: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.621426]
2023-05-18 09:15:04.818: epoch 3:	0.00461471  	0.03472723  	0.01668883  
2023-05-18 09:15:04.818: Find a better model.
2023-05-18 09:15:13.353: [iter 4 : loss : 0.7706 = 0.6921 + 0.0786 + 0.0000, time: 8.533225]
2023-05-18 09:15:13.508: epoch 4:	0.00731719  	0.05477862  	0.02596992  
2023-05-18 09:15:13.508: Find a better model.
2023-05-18 09:15:21.801: [iter 5 : loss : 0.7697 = 0.6910 + 0.0787 + 0.0000, time: 8.291773]
2023-05-18 09:15:21.959: epoch 5:	0.01111347  	0.08173856  	0.03824755  
2023-05-18 09:15:21.960: Find a better model.
2023-05-18 09:15:29.839: [iter 6 : loss : 0.7677 = 0.6885 + 0.0791 + 0.0000, time: 7.877971]
2023-05-18 09:15:29.998: epoch 6:	0.01476166  	0.10795884  	0.05124622  
2023-05-18 09:15:29.999: Find a better model.
2023-05-18 09:15:38.002: [iter 7 : loss : 0.7620 = 0.6821 + 0.0798 + 0.0000, time: 8.002164]
2023-05-18 09:15:38.145: epoch 7:	0.01745014  	0.12674750  	0.06175323  
2023-05-18 09:15:38.145: Find a better model.
2023-05-18 09:15:46.409: [iter 8 : loss : 0.7478 = 0.6662 + 0.0815 + 0.0001, time: 8.261561]
2023-05-18 09:15:46.697: epoch 8:	0.01851566  	0.13541348  	0.06779318  
2023-05-18 09:15:46.697: Find a better model.
2023-05-18 09:15:55.406: [iter 9 : loss : 0.7152 = 0.6298 + 0.0852 + 0.0001, time: 8.708656]
2023-05-18 09:15:55.566: epoch 9:	0.01888967  	0.13906200  	0.06917700  
2023-05-18 09:15:55.567: Find a better model.
2023-05-18 09:16:04.029: [iter 10 : loss : 0.6567 = 0.5659 + 0.0906 + 0.0002, time: 8.460122]
2023-05-18 09:16:04.187: epoch 10:	0.01862152  	0.13744447  	0.06861437  
2023-05-18 09:16:12.165: [iter 11 : loss : 0.5816 = 0.4854 + 0.0958 + 0.0004, time: 7.975132]
2023-05-18 09:16:12.341: epoch 11:	0.01853684  	0.13720368  	0.06854945  
2023-05-18 09:16:21.644: [iter 12 : loss : 0.5112 = 0.4114 + 0.0993 + 0.0005, time: 9.298477]
2023-05-18 09:16:21.906: epoch 12:	0.01849451  	0.13671353  	0.06849305  
2023-05-18 09:16:29.659: [iter 13 : loss : 0.4588 = 0.3569 + 0.1013 + 0.0007, time: 7.751009]
2023-05-18 09:16:29.819: epoch 13:	0.01864975  	0.13812675  	0.06941622  
2023-05-18 09:16:37.739: [iter 14 : loss : 0.4191 = 0.3160 + 0.1023 + 0.0008, time: 7.919046]
2023-05-18 09:16:37.896: epoch 14:	0.01876971  	0.13914865  	0.07002961  
2023-05-18 09:16:37.896: Find a better model.
2023-05-18 09:16:46.348: [iter 15 : loss : 0.3914 = 0.2877 + 0.1027 + 0.0010, time: 8.450155]
2023-05-18 09:16:46.509: epoch 15:	0.01894612  	0.14068921  	0.07091045  
2023-05-18 09:16:46.509: Find a better model.
2023-05-18 09:16:56.052: [iter 16 : loss : 0.3685 = 0.2647 + 0.1027 + 0.0011, time: 9.540022]
2023-05-18 09:16:56.323: epoch 16:	0.01918604  	0.14195141  	0.07169884  
2023-05-18 09:16:56.324: Find a better model.
2023-05-18 09:17:05.748: [iter 17 : loss : 0.3518 = 0.2480 + 0.1026 + 0.0012, time: 9.421013]
2023-05-18 09:17:06.015: epoch 17:	0.01946124  	0.14372543  	0.07269970  
2023-05-18 09:17:06.015: Find a better model.
2023-05-18 09:17:14.286: [iter 18 : loss : 0.3364 = 0.2328 + 0.1023 + 0.0013, time: 8.270564]
2023-05-18 09:17:14.445: epoch 18:	0.01965883  	0.14493424  	0.07349870  
2023-05-18 09:17:14.446: Find a better model.
2023-05-18 09:17:22.377: [iter 19 : loss : 0.3221 = 0.2187 + 0.1020 + 0.0014, time: 7.928535]
2023-05-18 09:17:22.539: epoch 19:	0.01979290  	0.14578506  	0.07396445  
2023-05-18 09:17:22.539: Find a better model.
2023-05-18 09:17:31.160: [iter 20 : loss : 0.3121 = 0.2091 + 0.1015 + 0.0015, time: 8.620014]
2023-05-18 09:17:31.382: epoch 20:	0.01996226  	0.14726314  	0.07478113  
2023-05-18 09:17:31.382: Find a better model.
2023-05-18 09:17:40.634: [iter 21 : loss : 0.3024 = 0.1997 + 0.1012 + 0.0016, time: 9.250163]
2023-05-18 09:17:40.927: epoch 21:	0.02011045  	0.14857417  	0.07551979  
2023-05-18 09:17:40.927: Find a better model.
2023-05-18 09:17:49.617: [iter 22 : loss : 0.2942 = 0.1917 + 0.1008 + 0.0016, time: 8.688911]
2023-05-18 09:17:49.792: epoch 22:	0.02032920  	0.15007842  	0.07628562  
2023-05-18 09:17:49.792: Find a better model.
2023-05-18 09:17:58.389: [iter 23 : loss : 0.2856 = 0.1835 + 0.1004 + 0.0017, time: 8.595110]
2023-05-18 09:17:58.555: epoch 23:	0.02044210  	0.15096390  	0.07690419  
2023-05-18 09:17:58.555: Find a better model.
2023-05-18 09:18:07.217: [iter 24 : loss : 0.2792 = 0.1776 + 0.0998 + 0.0018, time: 8.660035]
2023-05-18 09:18:07.423: epoch 24:	0.02067496  	0.15251823  	0.07772061  
2023-05-18 09:18:07.423: Find a better model.
2023-05-18 09:18:15.344: [iter 25 : loss : 0.2726 = 0.1713 + 0.0994 + 0.0019, time: 7.918993]
2023-05-18 09:18:15.505: epoch 25:	0.02085138  	0.15388167  	0.07833885  
2023-05-18 09:18:15.505: Find a better model.
2023-05-18 09:18:24.928: [iter 26 : loss : 0.2690 = 0.1681 + 0.0990 + 0.0019, time: 9.421139]
2023-05-18 09:18:25.234: epoch 26:	0.02111248  	0.15534748  	0.07911623  
2023-05-18 09:18:25.234: Find a better model.
2023-05-18 09:18:32.996: [iter 27 : loss : 0.2610 = 0.1604 + 0.0986 + 0.0020, time: 7.761034]
2023-05-18 09:18:33.152: epoch 27:	0.02130300  	0.15689811  	0.07986354  
2023-05-18 09:18:33.152: Find a better model.
2023-05-18 09:18:41.299: [iter 28 : loss : 0.2561 = 0.1559 + 0.0982 + 0.0021, time: 8.145532]
2023-05-18 09:18:41.457: epoch 28:	0.02145118  	0.15787959  	0.08045105  
2023-05-18 09:18:41.457: Find a better model.
2023-05-18 09:18:49.894: [iter 29 : loss : 0.2515 = 0.1516 + 0.0978 + 0.0021, time: 8.435007]
2023-05-18 09:18:50.051: epoch 29:	0.02165582  	0.15890107  	0.08133008  
2023-05-18 09:18:50.051: Find a better model.
2023-05-18 09:18:59.601: [iter 30 : loss : 0.2448 = 0.1452 + 0.0974 + 0.0022, time: 9.542114]
2023-05-18 09:18:59.856: epoch 30:	0.02184635  	0.16086470  	0.08202773  
2023-05-18 09:18:59.856: Find a better model.
2023-05-18 09:19:09.231: [iter 31 : loss : 0.2414 = 0.1422 + 0.0970 + 0.0023, time: 9.367452]
2023-05-18 09:19:09.536: epoch 31:	0.02194514  	0.16156606  	0.08255905  
2023-05-18 09:19:09.536: Find a better model.
2023-05-18 09:19:17.809: [iter 32 : loss : 0.2358 = 0.1368 + 0.0967 + 0.0023, time: 8.271992]
2023-05-18 09:19:17.967: epoch 32:	0.02211450  	0.16308849  	0.08363578  
2023-05-18 09:19:17.967: Find a better model.
2023-05-18 09:19:25.725: [iter 33 : loss : 0.2334 = 0.1348 + 0.0962 + 0.0024, time: 7.757007]
2023-05-18 09:19:25.888: epoch 33:	0.02227679  	0.16419813  	0.08438684  
2023-05-18 09:19:25.888: Find a better model.
2023-05-18 09:19:34.509: [iter 34 : loss : 0.2288 = 0.1305 + 0.0959 + 0.0024, time: 8.619017]
2023-05-18 09:19:34.682: epoch 34:	0.02238969  	0.16493942  	0.08521130  
2023-05-18 09:19:34.682: Find a better model.
2023-05-18 09:19:43.896: [iter 35 : loss : 0.2255 = 0.1274 + 0.0956 + 0.0025, time: 9.211647]
2023-05-18 09:19:44.188: epoch 35:	0.02250259  	0.16546071  	0.08574152  
2023-05-18 09:19:44.188: Find a better model.
2023-05-18 09:19:53.445: [iter 36 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 9.252386]
2023-05-18 09:19:53.655: epoch 36:	0.02267901  	0.16710635  	0.08632927  
2023-05-18 09:19:53.655: Find a better model.
2023-05-18 09:20:01.903: [iter 37 : loss : 0.2180 = 0.1206 + 0.0949 + 0.0026, time: 8.247089]
2023-05-18 09:20:02.080: epoch 37:	0.02285542  	0.16817918  	0.08689216  
2023-05-18 09:20:02.080: Find a better model.
2023-05-18 09:20:10.406: [iter 38 : loss : 0.2166 = 0.1193 + 0.0946 + 0.0027, time: 8.325016]
2023-05-18 09:20:10.722: epoch 38:	0.02298244  	0.16915599  	0.08757088  
2023-05-18 09:20:10.722: Find a better model.
2023-05-18 09:20:18.685: [iter 39 : loss : 0.2122 = 0.1152 + 0.0943 + 0.0027, time: 7.958993]
2023-05-18 09:20:18.841: epoch 39:	0.02311652  	0.17023537  	0.08837751  
2023-05-18 09:20:18.841: Find a better model.
2023-05-18 09:20:28.086: [iter 40 : loss : 0.2086 = 0.1119 + 0.0940 + 0.0028, time: 9.240356]
2023-05-18 09:20:28.388: epoch 40:	0.02311651  	0.17025840  	0.08856344  
2023-05-18 09:20:28.389: Find a better model.
2023-05-18 09:20:36.033: [iter 41 : loss : 0.2072 = 0.1106 + 0.0937 + 0.0028, time: 7.643065]
2023-05-18 09:20:36.193: epoch 41:	0.02329293  	0.17139716  	0.08927521  
2023-05-18 09:20:36.194: Find a better model.
2023-05-18 09:20:44.647: [iter 42 : loss : 0.2046 = 0.1084 + 0.0934 + 0.0029, time: 8.451524]
2023-05-18 09:20:44.805: epoch 42:	0.02346228  	0.17281756  	0.09001412  
2023-05-18 09:20:44.805: Find a better model.
2023-05-18 09:20:53.260: [iter 43 : loss : 0.2007 = 0.1047 + 0.0931 + 0.0029, time: 8.454091]
2023-05-18 09:20:53.409: epoch 43:	0.02361047  	0.17367685  	0.09064918  
2023-05-18 09:20:53.409: Find a better model.
2023-05-18 09:21:01.289: [iter 44 : loss : 0.1973 = 0.1015 + 0.0929 + 0.0030, time: 7.879249]
2023-05-18 09:21:01.482: epoch 44:	0.02370926  	0.17441982  	0.09118533  
2023-05-18 09:21:01.482: Find a better model.
2023-05-18 09:21:10.904: [iter 45 : loss : 0.1952 = 0.0996 + 0.0926 + 0.0030, time: 9.419671]
2023-05-18 09:21:11.165: epoch 45:	0.02380805  	0.17522502  	0.09159090  
2023-05-18 09:21:11.165: Find a better model.
2023-05-18 09:21:19.401: [iter 46 : loss : 0.1929 = 0.0974 + 0.0924 + 0.0031, time: 8.233450]
2023-05-18 09:21:19.551: epoch 46:	0.02382216  	0.17532282  	0.09187763  
2023-05-18 09:21:19.551: Find a better model.
2023-05-18 09:21:27.466: [iter 47 : loss : 0.1919 = 0.0966 + 0.0921 + 0.0031, time: 7.914002]
2023-05-18 09:21:27.629: epoch 47:	0.02394212  	0.17616944  	0.09255712  
2023-05-18 09:21:27.629: Find a better model.
2023-05-18 09:21:36.432: [iter 48 : loss : 0.1880 = 0.0930 + 0.0919 + 0.0032, time: 8.800992]
2023-05-18 09:21:36.600: epoch 48:	0.02404797  	0.17675653  	0.09293981  
2023-05-18 09:21:36.600: Find a better model.
2023-05-18 09:21:45.838: [iter 49 : loss : 0.1849 = 0.0901 + 0.0917 + 0.0032, time: 9.234310]
2023-05-18 09:21:46.122: epoch 49:	0.02417498  	0.17826390  	0.09351007  
2023-05-18 09:21:46.122: Find a better model.
2023-05-18 09:21:55.404: [iter 50 : loss : 0.1843 = 0.0896 + 0.0915 + 0.0033, time: 9.278084]
2023-05-18 09:21:55.704: epoch 50:	0.02415381  	0.17802790  	0.09378734  
2023-05-18 09:22:04.074: [iter 51 : loss : 0.1811 = 0.0866 + 0.0912 + 0.0033, time: 8.367836]
2023-05-18 09:22:04.256: epoch 51:	0.02423849  	0.17840232  	0.09416455  
2023-05-18 09:22:04.256: Find a better model.
2023-05-18 09:22:12.250: [iter 52 : loss : 0.1812 = 0.0868 + 0.0911 + 0.0034, time: 7.990015]
2023-05-18 09:22:12.410: epoch 52:	0.02425261  	0.17853239  	0.09456827  
2023-05-18 09:22:12.410: Find a better model.
2023-05-18 09:22:20.654: [iter 53 : loss : 0.1791 = 0.0848 + 0.0908 + 0.0034, time: 8.241016]
2023-05-18 09:22:20.809: epoch 53:	0.02433728  	0.17932795  	0.09508343  
2023-05-18 09:22:20.809: Find a better model.
2023-05-18 09:22:30.101: [iter 54 : loss : 0.1768 = 0.0827 + 0.0906 + 0.0035, time: 9.287900]
2023-05-18 09:22:30.396: epoch 54:	0.02442196  	0.17962186  	0.09524491  
2023-05-18 09:22:30.396: Find a better model.
2023-05-18 09:22:38.174: [iter 55 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 7.777350]
2023-05-18 09:22:38.359: epoch 55:	0.02442901  	0.17965496  	0.09546939  
2023-05-18 09:22:38.359: Find a better model.
2023-05-18 09:22:46.912: [iter 56 : loss : 0.1733 = 0.0796 + 0.0902 + 0.0035, time: 8.549218]
2023-05-18 09:22:47.068: epoch 56:	0.02450663  	0.18029851  	0.09596371  
2023-05-18 09:22:47.069: Find a better model.
2023-05-18 09:22:55.647: [iter 57 : loss : 0.1713 = 0.0776 + 0.0901 + 0.0036, time: 8.576992]
2023-05-18 09:22:55.807: epoch 57:	0.02462659  	0.18135031  	0.09639995  
2023-05-18 09:22:55.808: Find a better model.
2023-05-18 09:23:03.618: [iter 58 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 7.809010]
2023-05-18 09:23:03.773: epoch 58:	0.02473949  	0.18235967  	0.09684187  
2023-05-18 09:23:03.773: Find a better model.
2023-05-18 09:23:13.168: [iter 59 : loss : 0.1685 = 0.0751 + 0.0897 + 0.0037, time: 9.392211]
2023-05-18 09:23:13.457: epoch 59:	0.02478183  	0.18283182  	0.09724735  
2023-05-18 09:23:13.457: Find a better model.
2023-05-18 09:23:21.225: [iter 60 : loss : 0.1670 = 0.0737 + 0.0895 + 0.0037, time: 7.767246]
2023-05-18 09:23:21.384: epoch 60:	0.02481711  	0.18283199  	0.09742756  
2023-05-18 09:23:21.384: Find a better model.
2023-05-18 09:23:29.399: [iter 61 : loss : 0.1653 = 0.0722 + 0.0893 + 0.0038, time: 8.013332]
2023-05-18 09:23:29.557: epoch 61:	0.02482417  	0.18299945  	0.09750425  
2023-05-18 09:23:29.557: Find a better model.
2023-05-18 09:23:37.836: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 8.277924]
2023-05-18 09:23:37.992: epoch 62:	0.02490884  	0.18356602  	0.09792263  
2023-05-18 09:23:37.992: Find a better model.
2023-05-18 09:23:45.602: [iter 63 : loss : 0.1624 = 0.0695 + 0.0890 + 0.0039, time: 7.608005]
2023-05-18 09:23:45.764: epoch 63:	0.02498646  	0.18374631  	0.09828001  
2023-05-18 09:23:45.764: Find a better model.
2023-05-18 09:23:55.096: [iter 64 : loss : 0.1614 = 0.0686 + 0.0888 + 0.0039, time: 9.327011]
2023-05-18 09:23:55.385: epoch 64:	0.02495823  	0.18360028  	0.09827760  
2023-05-18 09:24:03.674: [iter 65 : loss : 0.1601 = 0.0675 + 0.0887 + 0.0039, time: 8.286600]
2023-05-18 09:24:03.843: epoch 65:	0.02512759  	0.18457349  	0.09887660  
2023-05-18 09:24:03.843: Find a better model.
2023-05-18 09:24:11.601: [iter 66 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 7.757023]
2023-05-18 09:24:11.768: epoch 66:	0.02511348  	0.18421748  	0.09898105  
2023-05-18 09:24:20.321: [iter 67 : loss : 0.1570 = 0.0646 + 0.0884 + 0.0040, time: 8.552180]
2023-05-18 09:24:20.477: epoch 67:	0.02521227  	0.18535478  	0.09942495  
2023-05-18 09:24:20.477: Find a better model.
2023-05-18 09:24:29.710: [iter 68 : loss : 0.1566 = 0.0642 + 0.0883 + 0.0041, time: 9.225873]
2023-05-18 09:24:29.998: epoch 68:	0.02528283  	0.18591179  	0.09973088  
2023-05-18 09:24:29.998: Find a better model.
2023-05-18 09:24:39.384: [iter 69 : loss : 0.1549 = 0.0626 + 0.0881 + 0.0041, time: 9.382031]
2023-05-18 09:24:39.691: epoch 69:	0.02527578  	0.18579452  	0.09988884  
2023-05-18 09:24:47.834: [iter 70 : loss : 0.1530 = 0.0609 + 0.0880 + 0.0042, time: 8.142004]
2023-05-18 09:24:47.997: epoch 70:	0.02536045  	0.18644762  	0.10014517  
2023-05-18 09:24:47.997: Find a better model.
2023-05-18 09:24:55.977: [iter 71 : loss : 0.1517 = 0.0596 + 0.0879 + 0.0042, time: 7.977995]
2023-05-18 09:24:56.139: epoch 71:	0.02547336  	0.18726346  	0.10057505  
2023-05-18 09:24:56.139: Find a better model.
2023-05-18 09:25:04.408: [iter 72 : loss : 0.1514 = 0.0594 + 0.0877 + 0.0042, time: 8.266990]
2023-05-18 09:25:04.565: epoch 72:	0.02552275  	0.18744561  	0.10086679  
2023-05-18 09:25:04.565: Find a better model.
2023-05-18 09:25:13.793: [iter 73 : loss : 0.1498 = 0.0579 + 0.0876 + 0.0043, time: 9.220002]
2023-05-18 09:25:14.088: epoch 73:	0.02560742  	0.18817128  	0.10114641  
2023-05-18 09:25:14.088: Find a better model.
2023-05-18 09:25:21.979: [iter 74 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 7.889327]
2023-05-18 09:25:22.144: epoch 74:	0.02571327  	0.18901172  	0.10158385  
2023-05-18 09:25:22.144: Find a better model.
2023-05-18 09:25:30.668: [iter 75 : loss : 0.1480 = 0.0563 + 0.0874 + 0.0044, time: 8.523108]
2023-05-18 09:25:30.834: epoch 75:	0.02572032  	0.18870771  	0.10173177  
2023-05-18 09:25:39.556: [iter 76 : loss : 0.1471 = 0.0554 + 0.0873 + 0.0044, time: 8.721015]
2023-05-18 09:25:39.716: epoch 76:	0.02565682  	0.18840982  	0.10178719  
2023-05-18 09:25:47.730: [iter 77 : loss : 0.1461 = 0.0545 + 0.0871 + 0.0044, time: 8.011145]
2023-05-18 09:25:47.887: epoch 77:	0.02578384  	0.18913500  	0.10218097  
2023-05-18 09:25:47.887: Find a better model.
2023-05-18 09:25:57.213: [iter 78 : loss : 0.1451 = 0.0536 + 0.0870 + 0.0045, time: 9.319108]
2023-05-18 09:25:57.505: epoch 78:	0.02574150  	0.18877223  	0.10209690  
2023-05-18 09:26:05.420: [iter 79 : loss : 0.1439 = 0.0525 + 0.0869 + 0.0045, time: 7.914502]
2023-05-18 09:26:05.577: epoch 79:	0.02571327  	0.18884169  	0.10203680  
2023-05-18 09:26:13.742: [iter 80 : loss : 0.1432 = 0.0519 + 0.0868 + 0.0046, time: 8.162992]
2023-05-18 09:26:13.902: epoch 80:	0.02579089  	0.18914545  	0.10225523  
2023-05-18 09:26:13.902: Find a better model.
2023-05-18 09:26:22.346: [iter 81 : loss : 0.1430 = 0.0517 + 0.0867 + 0.0046, time: 8.442461]
2023-05-18 09:26:22.505: epoch 81:	0.02584735  	0.18976231  	0.10254639  
2023-05-18 09:26:22.506: Find a better model.
2023-05-18 09:26:32.035: [iter 82 : loss : 0.1413 = 0.0501 + 0.0866 + 0.0046, time: 9.523991]
2023-05-18 09:26:32.326: epoch 82:	0.02581206  	0.18960276  	0.10258061  
2023-05-18 09:26:41.786: [iter 83 : loss : 0.1407 = 0.0496 + 0.0865 + 0.0047, time: 9.451991]
2023-05-18 09:26:42.076: epoch 83:	0.02596025  	0.19064723  	0.10302978  
2023-05-18 09:26:42.077: Find a better model.
2023-05-18 09:26:50.429: [iter 84 : loss : 0.1404 = 0.0492 + 0.0864 + 0.0047, time: 8.349995]
2023-05-18 09:26:50.669: epoch 84:	0.02601670  	0.19131598  	0.10317568  
2023-05-18 09:26:50.669: Find a better model.
2023-05-18 09:26:58.366: [iter 85 : loss : 0.1395 = 0.0484 + 0.0863 + 0.0048, time: 7.694993]
2023-05-18 09:26:58.528: epoch 85:	0.02601671  	0.19130263  	0.10326133  
2023-05-18 09:27:07.169: [iter 86 : loss : 0.1392 = 0.0482 + 0.0862 + 0.0048, time: 8.640619]
2023-05-18 09:27:07.390: epoch 86:	0.02600965  	0.19141710  	0.10340895  
2023-05-18 09:27:07.391: Find a better model.
2023-05-18 09:27:16.607: [iter 87 : loss : 0.1368 = 0.0459 + 0.0861 + 0.0048, time: 9.211991]
2023-05-18 09:27:16.910: epoch 87:	0.02605904  	0.19187452  	0.10354313  
2023-05-18 09:27:16.910: Find a better model.
2023-05-18 09:27:25.717: [iter 88 : loss : 0.1360 = 0.0451 + 0.0860 + 0.0049, time: 8.803349]
2023-05-18 09:27:25.897: epoch 88:	0.02610844  	0.19226079  	0.10376541  
2023-05-18 09:27:25.898: Find a better model.
2023-05-18 09:27:34.578: [iter 89 : loss : 0.1356 = 0.0447 + 0.0859 + 0.0049, time: 8.678992]
2023-05-18 09:27:34.745: epoch 89:	0.02612255  	0.19257225  	0.10396493  
2023-05-18 09:27:34.745: Find a better model.
2023-05-18 09:27:43.474: [iter 90 : loss : 0.1363 = 0.0455 + 0.0858 + 0.0050, time: 8.727200]
2023-05-18 09:27:43.639: epoch 90:	0.02617900  	0.19274420  	0.10415212  
2023-05-18 09:27:43.639: Find a better model.
2023-05-18 09:27:51.322: [iter 91 : loss : 0.1350 = 0.0443 + 0.0858 + 0.0050, time: 7.682019]
2023-05-18 09:27:51.478: epoch 91:	0.02614372  	0.19243686  	0.10413896  
2023-05-18 09:28:00.647: [iter 92 : loss : 0.1340 = 0.0433 + 0.0857 + 0.0050, time: 9.166036]
2023-05-18 09:28:00.953: epoch 92:	0.02617900  	0.19284743  	0.10416542  
2023-05-18 09:28:00.953: Find a better model.
2023-05-18 09:28:08.436: [iter 93 : loss : 0.1343 = 0.0437 + 0.0856 + 0.0051, time: 7.482003]
2023-05-18 09:28:08.597: epoch 93:	0.02620018  	0.19304621  	0.10451715  
2023-05-18 09:28:08.597: Find a better model.
2023-05-18 09:28:16.731: [iter 94 : loss : 0.1320 = 0.0414 + 0.0855 + 0.0051, time: 8.132036]
2023-05-18 09:28:16.888: epoch 94:	0.02629191  	0.19340366  	0.10474300  
2023-05-18 09:28:16.888: Find a better model.
2023-05-18 09:28:25.292: [iter 95 : loss : 0.1317 = 0.0412 + 0.0854 + 0.0051, time: 8.403013]
2023-05-18 09:28:25.449: epoch 95:	0.02618606  	0.19268769  	0.10463633  
2023-05-18 09:28:33.322: [iter 96 : loss : 0.1316 = 0.0410 + 0.0853 + 0.0052, time: 7.872273]
2023-05-18 09:28:33.480: epoch 96:	0.02614372  	0.19244727  	0.10454874  
2023-05-18 09:28:42.784: [iter 97 : loss : 0.1298 = 0.0393 + 0.0853 + 0.0052, time: 9.295033]
2023-05-18 09:28:43.065: epoch 97:	0.02620723  	0.19294280  	0.10487208  
2023-05-18 09:28:50.821: [iter 98 : loss : 0.1308 = 0.0404 + 0.0852 + 0.0052, time: 7.755005]
2023-05-18 09:28:51.048: epoch 98:	0.02627074  	0.19345006  	0.10515498  
2023-05-18 09:28:51.048: Find a better model.
2023-05-18 09:28:58.887: [iter 99 : loss : 0.1295 = 0.0391 + 0.0851 + 0.0053, time: 7.834098]
2023-05-18 09:28:59.042: epoch 99:	0.02633425  	0.19383441  	0.10545373  
2023-05-18 09:28:59.042: Find a better model.
2023-05-18 09:29:07.505: [iter 100 : loss : 0.1288 = 0.0384 + 0.0851 + 0.0053, time: 8.461002]
2023-05-18 09:29:07.783: epoch 100:	0.02632014  	0.19357771  	0.10528903  
2023-05-18 09:29:16.922: [iter 101 : loss : 0.1288 = 0.0384 + 0.0850 + 0.0054, time: 9.130041]
2023-05-18 09:29:17.196: epoch 101:	0.02629896  	0.19335912  	0.10526730  
2023-05-18 09:29:26.441: [iter 102 : loss : 0.1275 = 0.0371 + 0.0849 + 0.0054, time: 9.243005]
2023-05-18 09:29:26.746: epoch 102:	0.02624251  	0.19275379  	0.10526541  
2023-05-18 09:29:34.978: [iter 103 : loss : 0.1271 = 0.0368 + 0.0849 + 0.0054, time: 8.229992]
2023-05-18 09:29:35.136: epoch 103:	0.02625663  	0.19303288  	0.10527570  
2023-05-18 09:29:42.926: [iter 104 : loss : 0.1277 = 0.0375 + 0.0847 + 0.0055, time: 7.787004]
2023-05-18 09:29:43.087: epoch 104:	0.02627780  	0.19301924  	0.10541732  
2023-05-18 09:29:51.721: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 8.633155]
2023-05-18 09:29:51.899: epoch 105:	0.02627780  	0.19302030  	0.10545027  
2023-05-18 09:30:01.107: [iter 106 : loss : 0.1262 = 0.0361 + 0.0846 + 0.0055, time: 9.206022]
2023-05-18 09:30:01.393: epoch 106:	0.02631308  	0.19319309  	0.10568497  
2023-05-18 09:30:10.461: [iter 107 : loss : 0.1254 = 0.0352 + 0.0846 + 0.0056, time: 9.067045]
2023-05-18 09:30:10.640: epoch 107:	0.02630603  	0.19330218  	0.10564656  
2023-05-18 09:30:18.915: [iter 108 : loss : 0.1255 = 0.0354 + 0.0845 + 0.0056, time: 8.274007]
2023-05-18 09:30:19.091: epoch 108:	0.02631308  	0.19314991  	0.10573868  
2023-05-18 09:30:27.434: [iter 109 : loss : 0.1243 = 0.0342 + 0.0844 + 0.0056, time: 8.341090]
2023-05-18 09:30:27.669: epoch 109:	0.02635542  	0.19372725  	0.10611183  
2023-05-18 09:30:35.451: [iter 110 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 7.770991]
2023-05-18 09:30:35.608: epoch 110:	0.02629191  	0.19318300  	0.10590575  
2023-05-18 09:30:44.787: [iter 111 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0057, time: 9.174003]
2023-05-18 09:30:45.079: epoch 111:	0.02635542  	0.19368024  	0.10609630  
2023-05-18 09:30:52.531: [iter 112 : loss : 0.1233 = 0.0332 + 0.0843 + 0.0057, time: 7.451313]
2023-05-18 09:30:52.690: epoch 112:	0.02635542  	0.19363976  	0.10627823  
2023-05-18 09:31:01.080: [iter 113 : loss : 0.1233 = 0.0333 + 0.0842 + 0.0058, time: 8.388011]
2023-05-18 09:31:01.245: epoch 113:	0.02636953  	0.19375221  	0.10638490  
2023-05-18 09:31:09.428: [iter 114 : loss : 0.1224 = 0.0324 + 0.0842 + 0.0058, time: 8.180995]
2023-05-18 09:31:09.587: epoch 114:	0.02643304  	0.19430162  	0.10660020  
2023-05-18 09:31:09.587: Find a better model.
2023-05-18 09:31:17.429: [iter 115 : loss : 0.1219 = 0.0320 + 0.0841 + 0.0058, time: 7.840417]
2023-05-18 09:31:17.590: epoch 115:	0.02644715  	0.19424213  	0.10673352  
2023-05-18 09:31:26.826: [iter 116 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0059, time: 9.228020]
2023-05-18 09:31:27.115: epoch 116:	0.02642598  	0.19424430  	0.10673621  
2023-05-18 09:31:34.737: [iter 117 : loss : 0.1211 = 0.0312 + 0.0840 + 0.0059, time: 7.621003]
2023-05-18 09:31:34.894: epoch 117:	0.02644715  	0.19403979  	0.10675247  
2023-05-18 09:31:42.825: [iter 118 : loss : 0.1210 = 0.0311 + 0.0839 + 0.0059, time: 7.928997]
2023-05-18 09:31:42.982: epoch 118:	0.02646832  	0.19405140  	0.10675301  
2023-05-18 09:31:51.425: [iter 119 : loss : 0.1197 = 0.0299 + 0.0839 + 0.0060, time: 8.442002]
2023-05-18 09:31:51.580: epoch 119:	0.02644715  	0.19381185  	0.10668033  
2023-05-18 09:32:00.230: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 8.646981]
2023-05-18 09:32:00.515: epoch 120:	0.02650360  	0.19424242  	0.10692674  
2023-05-18 09:32:09.732: [iter 121 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 9.215023]
2023-05-18 09:32:10.020: epoch 121:	0.02655299  	0.19436328  	0.10701632  
2023-05-18 09:32:10.020: Find a better model.
2023-05-18 09:32:18.294: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 8.272006]
2023-05-18 09:32:18.474: epoch 122:	0.02653182  	0.19385314  	0.10685833  
2023-05-18 09:32:26.060: [iter 123 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0061, time: 7.584006]
2023-05-18 09:32:26.236: epoch 123:	0.02655299  	0.19395873  	0.10713054  
2023-05-18 09:32:34.546: [iter 124 : loss : 0.1181 = 0.0283 + 0.0837 + 0.0061, time: 8.306349]
2023-05-18 09:32:34.704: epoch 124:	0.02646832  	0.19328174  	0.10686991  
2023-05-18 09:32:43.814: [iter 125 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0061, time: 9.102005]
2023-05-18 09:32:44.108: epoch 125:	0.02648948  	0.19355233  	0.10696560  
2023-05-18 09:32:53.283: [iter 126 : loss : 0.1178 = 0.0281 + 0.0836 + 0.0062, time: 9.171379]
2023-05-18 09:32:53.589: epoch 126:	0.02647537  	0.19352806  	0.10706545  
2023-05-18 09:33:01.778: [iter 127 : loss : 0.1169 = 0.0272 + 0.0835 + 0.0062, time: 8.187995]
2023-05-18 09:33:01.935: epoch 127:	0.02642597  	0.19345409  	0.10718947  
2023-05-18 09:33:09.618: [iter 128 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 7.682183]
2023-05-18 09:33:09.777: epoch 128:	0.02639775  	0.19328974  	0.10711597  
2023-05-18 09:33:18.232: [iter 129 : loss : 0.1170 = 0.0274 + 0.0834 + 0.0063, time: 8.453335]
2023-05-18 09:33:18.431: epoch 129:	0.02642598  	0.19345133  	0.10722094  
2023-05-18 09:33:27.526: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 9.089010]
2023-05-18 09:33:27.819: epoch 130:	0.02644714  	0.19356194  	0.10736155  
2023-05-18 09:33:36.984: [iter 131 : loss : 0.1163 = 0.0267 + 0.0833 + 0.0063, time: 9.161623]
2023-05-18 09:33:37.253: epoch 131:	0.02644714  	0.19356054  	0.10745801  
2023-05-18 09:33:45.410: [iter 132 : loss : 0.1164 = 0.0268 + 0.0833 + 0.0064, time: 8.155360]
2023-05-18 09:33:45.574: epoch 132:	0.02645420  	0.19364351  	0.10742898  
2023-05-18 09:33:53.438: [iter 133 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0064, time: 7.862013]
2023-05-18 09:33:53.593: epoch 133:	0.02644714  	0.19355330  	0.10752483  
2023-05-18 09:34:01.603: [iter 134 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 8.009009]
2023-05-18 09:34:01.760: epoch 134:	0.02644714  	0.19340348  	0.10753126  
2023-05-18 09:34:10.910: [iter 135 : loss : 0.1155 = 0.0259 + 0.0831 + 0.0064, time: 9.148000]
2023-05-18 09:34:11.200: epoch 135:	0.02639069  	0.19310276  	0.10756437  
2023-05-18 09:34:19.097: [iter 136 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 7.895538]
2023-05-18 09:34:19.292: epoch 136:	0.02634835  	0.19280800  	0.10744101  
2023-05-18 09:34:27.841: [iter 137 : loss : 0.1147 = 0.0251 + 0.0831 + 0.0065, time: 8.546993]
2023-05-18 09:34:28.006: epoch 137:	0.02632718  	0.19295141  	0.10751795  
2023-05-18 09:34:36.129: [iter 138 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 8.120008]
2023-05-18 09:34:36.645: epoch 138:	0.02634835  	0.19300351  	0.10735638  
2023-05-18 09:34:44.390: [iter 139 : loss : 0.1144 = 0.0248 + 0.0830 + 0.0066, time: 7.743039]
2023-05-18 09:34:44.548: epoch 139:	0.02629896  	0.19274673  	0.10739592  
2023-05-18 09:34:53.792: [iter 140 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 9.240574]
2023-05-18 09:34:54.051: epoch 140:	0.02629190  	0.19240321  	0.10714032  
2023-05-18 09:35:01.440: [iter 141 : loss : 0.1141 = 0.0246 + 0.0829 + 0.0066, time: 7.387998]
2023-05-18 09:35:01.600: epoch 141:	0.02621427  	0.19178119  	0.10706431  
2023-05-18 09:35:09.768: [iter 142 : loss : 0.1133 = 0.0238 + 0.0829 + 0.0066, time: 8.167045]
2023-05-18 09:35:09.926: epoch 142:	0.02625661  	0.19191131  	0.10725078  
2023-05-18 09:35:18.155: [iter 143 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0067, time: 8.228006]
2023-05-18 09:35:18.355: epoch 143:	0.02630600  	0.19221118  	0.10734183  
2023-05-18 09:35:25.975: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.618993]
2023-05-18 09:35:26.145: epoch 144:	0.02631307  	0.19222468  	0.10758206  
2023-05-18 09:35:35.220: [iter 145 : loss : 0.1127 = 0.0232 + 0.0828 + 0.0067, time: 9.074825]
2023-05-18 09:35:35.502: epoch 145:	0.02639068  	0.19243428  	0.10782330  
2023-05-18 09:35:43.183: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.679993]
2023-05-18 09:35:43.339: epoch 146:	0.02637657  	0.19259849  	0.10772053  
2023-05-18 09:35:43.339: Early stopping is trigger at epoch: 146
2023-05-18 09:35:43.339: best_result@epoch 121:

2023-05-18 09:35:43.339: 		0.0266      	0.1944      	0.1070      
2023-05-18 09:39:58.670: my pid: 8372
2023-05-18 09:39:58.670: model: model.general_recommender.SGL
2023-05-18 09:39:58.670: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 09:39:58.670: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 09:40:01.794: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 09:40:12.101: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.305079]
2023-05-18 09:40:12.412: epoch 1:	0.00148180  	0.01068756  	0.00488396  
2023-05-18 09:40:12.412: Find a better model.
2023-05-18 09:40:21.803: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.390125]
2023-05-18 09:40:22.002: epoch 2:	0.00227915  	0.01717786  	0.00837937  
2023-05-18 09:40:22.002: Find a better model.
2023-05-18 09:40:30.695: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.692159]
2023-05-18 09:40:30.873: epoch 3:	0.00436775  	0.03261336  	0.01564603  
2023-05-18 09:40:30.873: Find a better model.
2023-05-18 09:40:40.101: [iter 4 : loss : 0.7707 = 0.6921 + 0.0786 + 0.0000, time: 9.227243]
2023-05-18 09:40:40.272: epoch 4:	0.00717607  	0.05285233  	0.02515083  
2023-05-18 09:40:40.272: Find a better model.
2023-05-18 09:40:50.012: [iter 5 : loss : 0.7698 = 0.6911 + 0.0787 + 0.0000, time: 9.739024]
2023-05-18 09:40:50.305: epoch 5:	0.01093001  	0.07992093  	0.03784866  
2023-05-18 09:40:50.305: Find a better model.
2023-05-18 09:40:58.381: [iter 6 : loss : 0.7679 = 0.6888 + 0.0791 + 0.0000, time: 8.075203]
2023-05-18 09:40:58.562: epoch 6:	0.01447940  	0.10435360  	0.05123042  
2023-05-18 09:40:58.562: Find a better model.
2023-05-18 09:41:07.316: [iter 7 : loss : 0.7626 = 0.6829 + 0.0797 + 0.0000, time: 8.752192]
2023-05-18 09:41:07.475: epoch 7:	0.01704793  	0.12389871  	0.06127980  
2023-05-18 09:41:07.475: Find a better model.
2023-05-18 09:41:16.281: [iter 8 : loss : 0.7496 = 0.6682 + 0.0813 + 0.0001, time: 8.805453]
2023-05-18 09:41:16.427: epoch 8:	0.01874147  	0.13593712  	0.06830645  
2023-05-18 09:41:16.427: Find a better model.
2023-05-18 09:41:24.223: [iter 9 : loss : 0.7190 = 0.6341 + 0.0847 + 0.0001, time: 7.795010]
2023-05-18 09:41:24.383: epoch 9:	0.01888966  	0.13865304  	0.06928866  
2023-05-18 09:41:24.383: Find a better model.
2023-05-18 09:41:33.744: [iter 10 : loss : 0.6629 = 0.5727 + 0.0900 + 0.0002, time: 9.360005]
2023-05-18 09:41:34.031: epoch 10:	0.01860035  	0.13778917  	0.06881122  
2023-05-18 09:41:41.955: [iter 11 : loss : 0.5884 = 0.4927 + 0.0952 + 0.0004, time: 7.923012]
2023-05-18 09:41:42.107: epoch 11:	0.01847334  	0.13678089  	0.06845064  
2023-05-18 09:41:50.434: [iter 12 : loss : 0.5168 = 0.4173 + 0.0990 + 0.0005, time: 8.326041]
2023-05-18 09:41:50.593: epoch 12:	0.01843101  	0.13617274  	0.06846569  
2023-05-18 09:41:59.204: [iter 13 : loss : 0.4629 = 0.3611 + 0.1011 + 0.0007, time: 8.610002]
2023-05-18 09:41:59.361: epoch 13:	0.01843100  	0.13657147  	0.06897634  
2023-05-18 09:42:08.864: [iter 14 : loss : 0.4219 = 0.3190 + 0.1021 + 0.0008, time: 9.501053]
2023-05-18 09:42:09.167: epoch 14:	0.01857918  	0.13776666  	0.06967738  
2023-05-18 09:42:18.531: [iter 15 : loss : 0.3934 = 0.2898 + 0.1026 + 0.0010, time: 9.361011]
2023-05-18 09:42:18.823: epoch 15:	0.01888966  	0.13974421  	0.07041791  
2023-05-18 09:42:18.823: Find a better model.
2023-05-18 09:42:27.194: [iter 16 : loss : 0.3700 = 0.2664 + 0.1026 + 0.0011, time: 8.370070]
2023-05-18 09:42:27.432: epoch 16:	0.01902373  	0.14054613  	0.07124169  
2023-05-18 09:42:27.432: Find a better model.
2023-05-18 09:42:35.235: [iter 17 : loss : 0.3527 = 0.2491 + 0.1025 + 0.0012, time: 7.797292]
2023-05-18 09:42:35.392: epoch 17:	0.01936245  	0.14306626  	0.07212177  
2023-05-18 09:42:35.392: Find a better model.
2023-05-18 09:42:44.042: [iter 18 : loss : 0.3368 = 0.2333 + 0.1022 + 0.0013, time: 8.647516]
2023-05-18 09:42:44.217: epoch 18:	0.01954592  	0.14355373  	0.07278099  
2023-05-18 09:42:44.217: Find a better model.
2023-05-18 09:42:53.494: [iter 19 : loss : 0.3224 = 0.2191 + 0.1019 + 0.0014, time: 9.272012]
2023-05-18 09:42:53.803: epoch 19:	0.01977878  	0.14556620  	0.07388712  
2023-05-18 09:42:53.803: Find a better model.
2023-05-18 09:43:02.809: [iter 20 : loss : 0.3125 = 0.2095 + 0.1015 + 0.0015, time: 9.004973]
2023-05-18 09:43:02.985: epoch 20:	0.02001165  	0.14757517  	0.07492546  
2023-05-18 09:43:02.985: Find a better model.
2023-05-18 09:43:11.437: [iter 21 : loss : 0.3024 = 0.1998 + 0.1010 + 0.0016, time: 8.450943]
2023-05-18 09:43:11.661: epoch 21:	0.02024451  	0.14942624  	0.07574949  
2023-05-18 09:43:11.661: Find a better model.
2023-05-18 09:43:20.079: [iter 22 : loss : 0.2940 = 0.1917 + 0.1007 + 0.0016, time: 8.415517]
2023-05-18 09:43:20.284: epoch 22:	0.02043504  	0.15096562  	0.07660459  
2023-05-18 09:43:20.284: Find a better model.
2023-05-18 09:43:28.409: [iter 23 : loss : 0.2856 = 0.1836 + 0.1003 + 0.0017, time: 8.123020]
2023-05-18 09:43:28.568: epoch 23:	0.02051972  	0.15153874  	0.07712127  
2023-05-18 09:43:28.568: Find a better model.
2023-05-18 09:43:37.940: [iter 24 : loss : 0.2789 = 0.1773 + 0.0998 + 0.0018, time: 9.371700]
2023-05-18 09:43:38.247: epoch 24:	0.02083021  	0.15355715  	0.07808258  
2023-05-18 09:43:38.247: Find a better model.
2023-05-18 09:43:45.914: [iter 25 : loss : 0.2723 = 0.1711 + 0.0993 + 0.0019, time: 7.665275]
2023-05-18 09:43:46.077: epoch 25:	0.02093606  	0.15411276  	0.07859610  
2023-05-18 09:43:46.077: Find a better model.
2023-05-18 09:43:54.595: [iter 26 : loss : 0.2684 = 0.1675 + 0.0990 + 0.0019, time: 8.516002]
2023-05-18 09:43:54.738: epoch 26:	0.02107013  	0.15525395  	0.07930391  
2023-05-18 09:43:54.739: Find a better model.
2023-05-18 09:44:03.154: [iter 27 : loss : 0.2607 = 0.1602 + 0.0985 + 0.0020, time: 8.413543]
2023-05-18 09:44:03.331: epoch 27:	0.02123949  	0.15652759  	0.08023307  
2023-05-18 09:44:03.331: Find a better model.
2023-05-18 09:44:11.173: [iter 28 : loss : 0.2557 = 0.1555 + 0.0981 + 0.0021, time: 7.840241]
2023-05-18 09:44:11.331: epoch 28:	0.02138062  	0.15772171  	0.08106202  
2023-05-18 09:44:11.331: Find a better model.
2023-05-18 09:44:20.702: [iter 29 : loss : 0.2511 = 0.1513 + 0.0977 + 0.0021, time: 9.364145]
2023-05-18 09:44:20.992: epoch 29:	0.02162760  	0.15936843  	0.08173431  
2023-05-18 09:44:20.992: Find a better model.
2023-05-18 09:44:28.939: [iter 30 : loss : 0.2447 = 0.1451 + 0.0973 + 0.0022, time: 7.945013]
2023-05-18 09:44:29.092: epoch 30:	0.02177580  	0.16072001  	0.08248270  
2023-05-18 09:44:29.092: Find a better model.
2023-05-18 09:44:37.157: [iter 31 : loss : 0.2410 = 0.1417 + 0.0970 + 0.0023, time: 8.064293]
2023-05-18 09:44:37.312: epoch 31:	0.02200866  	0.16262810  	0.08340393  
2023-05-18 09:44:37.312: Find a better model.
2023-05-18 09:44:45.945: [iter 32 : loss : 0.2353 = 0.1364 + 0.0966 + 0.0023, time: 8.632214]
2023-05-18 09:44:46.101: epoch 32:	0.02222740  	0.16453072  	0.08423241  
2023-05-18 09:44:46.101: Find a better model.
2023-05-18 09:44:55.629: [iter 33 : loss : 0.2328 = 0.1342 + 0.0962 + 0.0024, time: 9.525084]
2023-05-18 09:44:55.927: epoch 33:	0.02234736  	0.16538420  	0.08507907  
2023-05-18 09:44:55.927: Find a better model.
2023-05-18 09:45:05.408: [iter 34 : loss : 0.2287 = 0.1304 + 0.0959 + 0.0024, time: 9.479023]
2023-05-18 09:45:05.696: epoch 34:	0.02243204  	0.16568266  	0.08562756  
2023-05-18 09:45:05.696: Find a better model.
2023-05-18 09:45:14.110: [iter 35 : loss : 0.2252 = 0.1272 + 0.0955 + 0.0025, time: 8.412734]
2023-05-18 09:45:14.265: epoch 35:	0.02265784  	0.16738619  	0.08654731  
2023-05-18 09:45:14.265: Find a better model.
2023-05-18 09:45:22.160: [iter 36 : loss : 0.2218 = 0.1240 + 0.0952 + 0.0025, time: 7.894068]
2023-05-18 09:45:22.320: epoch 36:	0.02276369  	0.16834173  	0.08711481  
2023-05-18 09:45:22.320: Find a better model.
2023-05-18 09:45:30.966: [iter 37 : loss : 0.2176 = 0.1202 + 0.0949 + 0.0026, time: 8.644865]
2023-05-18 09:45:31.135: epoch 37:	0.02280603  	0.16893868  	0.08754694  
2023-05-18 09:45:31.135: Find a better model.
2023-05-18 09:45:40.448: [iter 38 : loss : 0.2161 = 0.1189 + 0.0946 + 0.0027, time: 9.308015]
2023-05-18 09:45:40.739: epoch 38:	0.02287659  	0.16962011  	0.08798137  
2023-05-18 09:45:40.739: Find a better model.
2023-05-18 09:45:49.923: [iter 39 : loss : 0.2118 = 0.1148 + 0.0942 + 0.0027, time: 9.182687]
2023-05-18 09:45:50.098: epoch 39:	0.02297539  	0.17030258  	0.08856357  
2023-05-18 09:45:50.098: Find a better model.
2023-05-18 09:45:58.354: [iter 40 : loss : 0.2085 = 0.1118 + 0.0939 + 0.0028, time: 8.253992]
2023-05-18 09:45:58.538: epoch 40:	0.02312358  	0.17146555  	0.08919780  
2023-05-18 09:45:58.538: Find a better model.
2023-05-18 09:46:06.668: [iter 41 : loss : 0.2066 = 0.1102 + 0.0937 + 0.0028, time: 8.126508]
2023-05-18 09:46:06.984: epoch 41:	0.02314474  	0.17110740  	0.08952009  
2023-05-18 09:46:15.128: [iter 42 : loss : 0.2045 = 0.1083 + 0.0934 + 0.0029, time: 8.143195]
2023-05-18 09:46:15.283: epoch 42:	0.02330704  	0.17237613  	0.09015051  
2023-05-18 09:46:15.284: Find a better model.
2023-05-18 09:46:24.562: [iter 43 : loss : 0.2004 = 0.1044 + 0.0931 + 0.0029, time: 9.275022]
2023-05-18 09:46:24.862: epoch 43:	0.02345523  	0.17344521  	0.09074260  
2023-05-18 09:46:24.862: Find a better model.
2023-05-18 09:46:32.402: [iter 44 : loss : 0.1971 = 0.1012 + 0.0928 + 0.0030, time: 7.539010]
2023-05-18 09:46:32.562: epoch 44:	0.02351874  	0.17431760  	0.09129275  
2023-05-18 09:46:32.562: Find a better model.
2023-05-18 09:46:40.993: [iter 45 : loss : 0.1950 = 0.0994 + 0.0926 + 0.0030, time: 8.428549]
2023-05-18 09:46:41.147: epoch 45:	0.02363164  	0.17509556  	0.09179206  
2023-05-18 09:46:41.147: Find a better model.
2023-05-18 09:46:49.543: [iter 46 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 8.393014]
2023-05-18 09:46:49.973: epoch 46:	0.02375160  	0.17592533  	0.09234821  
2023-05-18 09:46:49.973: Find a better model.
2023-05-18 09:46:57.909: [iter 47 : loss : 0.1917 = 0.0965 + 0.0921 + 0.0031, time: 7.935012]
2023-05-18 09:46:58.062: epoch 47:	0.02381512  	0.17660740  	0.09292632  
2023-05-18 09:46:58.062: Find a better model.
2023-05-18 09:47:07.259: [iter 48 : loss : 0.1877 = 0.0927 + 0.0918 + 0.0032, time: 9.195022]
2023-05-18 09:47:07.552: epoch 48:	0.02394213  	0.17776179  	0.09347910  
2023-05-18 09:47:07.552: Find a better model.
2023-05-18 09:47:15.080: [iter 49 : loss : 0.1848 = 0.0899 + 0.0917 + 0.0032, time: 7.526992]
2023-05-18 09:47:15.243: epoch 49:	0.02398448  	0.17770745  	0.09375569  
2023-05-18 09:47:23.716: [iter 50 : loss : 0.1840 = 0.0893 + 0.0914 + 0.0033, time: 8.472085]
2023-05-18 09:47:23.872: epoch 50:	0.02410443  	0.17854781  	0.09420647  
2023-05-18 09:47:23.872: Find a better model.
2023-05-18 09:47:32.141: [iter 51 : loss : 0.1809 = 0.0864 + 0.0913 + 0.0033, time: 8.268056]
2023-05-18 09:47:32.296: epoch 51:	0.02421733  	0.17947753  	0.09462056  
2023-05-18 09:47:32.296: Find a better model.
2023-05-18 09:47:40.104: [iter 52 : loss : 0.1809 = 0.0865 + 0.0910 + 0.0034, time: 7.807088]
2023-05-18 09:47:40.262: epoch 52:	0.02423850  	0.17979974  	0.09503774  
2023-05-18 09:47:40.262: Find a better model.
2023-05-18 09:47:49.617: [iter 53 : loss : 0.1789 = 0.0847 + 0.0908 + 0.0034, time: 9.352010]
2023-05-18 09:47:49.913: epoch 53:	0.02437258  	0.18079765  	0.09571464  
2023-05-18 09:47:49.913: Find a better model.
2023-05-18 09:47:57.742: [iter 54 : loss : 0.1766 = 0.0826 + 0.0906 + 0.0035, time: 7.827003]
2023-05-18 09:47:57.893: epoch 54:	0.02451370  	0.18199328  	0.09635518  
2023-05-18 09:47:57.893: Find a better model.
2023-05-18 09:48:06.099: [iter 55 : loss : 0.1747 = 0.0808 + 0.0904 + 0.0035, time: 8.205126]
2023-05-18 09:48:06.255: epoch 55:	0.02445726  	0.18144614  	0.09642674  
2023-05-18 09:48:14.702: [iter 56 : loss : 0.1727 = 0.0789 + 0.0902 + 0.0035, time: 8.445358]
2023-05-18 09:48:14.859: epoch 56:	0.02449253  	0.18191589  	0.09684543  
2023-05-18 09:48:22.928: [iter 57 : loss : 0.1711 = 0.0775 + 0.0901 + 0.0036, time: 8.066938]
2023-05-18 09:48:23.200: epoch 57:	0.02460544  	0.18287182  	0.09719338  
2023-05-18 09:48:23.200: Find a better model.
2023-05-18 09:48:32.519: [iter 58 : loss : 0.1692 = 0.0757 + 0.0899 + 0.0036, time: 9.317018]
2023-05-18 09:48:32.804: epoch 58:	0.02462661  	0.18293415  	0.09742986  
2023-05-18 09:48:32.804: Find a better model.
2023-05-18 09:48:40.938: [iter 59 : loss : 0.1682 = 0.0748 + 0.0897 + 0.0037, time: 8.132202]
2023-05-18 09:48:41.089: epoch 59:	0.02473246  	0.18340921  	0.09768583  
2023-05-18 09:48:41.089: Find a better model.
2023-05-18 09:48:49.126: [iter 60 : loss : 0.1669 = 0.0736 + 0.0895 + 0.0037, time: 8.036015]
2023-05-18 09:48:49.292: epoch 60:	0.02480302  	0.18392389  	0.09822398  
2023-05-18 09:48:49.292: Find a better model.
2023-05-18 09:48:57.677: [iter 61 : loss : 0.1654 = 0.0723 + 0.0894 + 0.0038, time: 8.382993]
2023-05-18 09:48:57.942: epoch 61:	0.02481713  	0.18375680  	0.09856568  
2023-05-18 09:49:07.120: [iter 62 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 9.173830]
2023-05-18 09:49:07.416: epoch 62:	0.02493709  	0.18455005  	0.09899402  
2023-05-18 09:49:07.417: Find a better model.
2023-05-18 09:49:16.598: [iter 63 : loss : 0.1624 = 0.0695 + 0.0890 + 0.0039, time: 9.176991]
2023-05-18 09:49:16.860: epoch 63:	0.02490181  	0.18443970  	0.09910607  
2023-05-18 09:49:25.042: [iter 64 : loss : 0.1614 = 0.0686 + 0.0889 + 0.0039, time: 8.181001]
2023-05-18 09:49:25.197: epoch 64:	0.02502176  	0.18526036  	0.09949774  
2023-05-18 09:49:25.197: Find a better model.
2023-05-18 09:49:33.069: [iter 65 : loss : 0.1601 = 0.0675 + 0.0887 + 0.0040, time: 7.871742]
2023-05-18 09:49:33.235: epoch 65:	0.02508527  	0.18580016  	0.09986592  
2023-05-18 09:49:33.235: Find a better model.
2023-05-18 09:49:41.722: [iter 66 : loss : 0.1586 = 0.0661 + 0.0886 + 0.0040, time: 8.486005]
2023-05-18 09:49:41.891: epoch 66:	0.02507821  	0.18563393  	0.09993839  
2023-05-18 09:49:51.060: [iter 67 : loss : 0.1569 = 0.0644 + 0.0884 + 0.0040, time: 9.166011]
2023-05-18 09:49:51.356: epoch 67:	0.02516994  	0.18639605  	0.10026380  
2023-05-18 09:49:51.356: Find a better model.
2023-05-18 09:50:00.686: [iter 68 : loss : 0.1567 = 0.0643 + 0.0883 + 0.0041, time: 9.325197]
2023-05-18 09:50:00.984: epoch 68:	0.02523345  	0.18676800  	0.10062937  
2023-05-18 09:50:00.985: Find a better model.
2023-05-18 09:50:09.296: [iter 69 : loss : 0.1547 = 0.0625 + 0.0881 + 0.0041, time: 8.310017]
2023-05-18 09:50:09.460: epoch 69:	0.02524051  	0.18717666  	0.10077372  
2023-05-18 09:50:09.460: Find a better model.
2023-05-18 09:50:17.308: [iter 70 : loss : 0.1529 = 0.0607 + 0.0880 + 0.0042, time: 7.847007]
2023-05-18 09:50:17.467: epoch 70:	0.02526168  	0.18713024  	0.10093267  
2023-05-18 09:50:25.948: [iter 71 : loss : 0.1515 = 0.0594 + 0.0879 + 0.0042, time: 8.479012]
2023-05-18 09:50:26.103: epoch 71:	0.02532518  	0.18755113  	0.10119649  
2023-05-18 09:50:26.103: Find a better model.
2023-05-18 09:50:35.288: [iter 72 : loss : 0.1512 = 0.0592 + 0.0877 + 0.0042, time: 9.184043]
2023-05-18 09:50:35.544: epoch 72:	0.02537458  	0.18789558  	0.10151187  
2023-05-18 09:50:35.544: Find a better model.
2023-05-18 09:50:43.944: [iter 73 : loss : 0.1500 = 0.0581 + 0.0876 + 0.0043, time: 8.399003]
2023-05-18 09:50:44.121: epoch 73:	0.02542397  	0.18809150  	0.10159860  
2023-05-18 09:50:44.121: Find a better model.
2023-05-18 09:50:52.506: [iter 74 : loss : 0.1487 = 0.0568 + 0.0875 + 0.0043, time: 8.384288]
2023-05-18 09:50:52.696: epoch 74:	0.02548748  	0.18848149  	0.10207285  
2023-05-18 09:50:52.696: Find a better model.
2023-05-18 09:51:00.680: [iter 75 : loss : 0.1482 = 0.0564 + 0.0874 + 0.0044, time: 7.983039]
2023-05-18 09:51:00.835: epoch 75:	0.02550160  	0.18828075  	0.10217249  
2023-05-18 09:51:09.036: [iter 76 : loss : 0.1472 = 0.0555 + 0.0873 + 0.0044, time: 8.200001]
2023-05-18 09:51:09.192: epoch 76:	0.02557216  	0.18856451  	0.10226786  
2023-05-18 09:51:09.192: Find a better model.
2023-05-18 09:51:18.432: [iter 77 : loss : 0.1460 = 0.0544 + 0.0871 + 0.0045, time: 9.237006]
2023-05-18 09:51:18.719: epoch 77:	0.02560745  	0.18864498  	0.10251253  
2023-05-18 09:51:18.719: Find a better model.
2023-05-18 09:51:26.325: [iter 78 : loss : 0.1452 = 0.0537 + 0.0870 + 0.0045, time: 7.605009]
2023-05-18 09:51:26.491: epoch 78:	0.02565684  	0.18927474  	0.10280471  
2023-05-18 09:51:26.491: Find a better model.
2023-05-18 09:51:34.907: [iter 79 : loss : 0.1438 = 0.0524 + 0.0869 + 0.0045, time: 8.414038]
2023-05-18 09:51:35.083: epoch 79:	0.02581208  	0.19023851  	0.10324156  
2023-05-18 09:51:35.083: Find a better model.
2023-05-18 09:51:43.283: [iter 80 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 8.198010]
2023-05-18 09:51:43.468: epoch 80:	0.02575563  	0.18965413  	0.10328241  
2023-05-18 09:51:51.609: [iter 81 : loss : 0.1429 = 0.0515 + 0.0867 + 0.0046, time: 8.140103]
2023-05-18 09:51:51.768: epoch 81:	0.02585442  	0.19039169  	0.10356726  
2023-05-18 09:51:51.768: Find a better model.
2023-05-18 09:52:01.274: [iter 82 : loss : 0.1417 = 0.0504 + 0.0866 + 0.0046, time: 9.496038]
2023-05-18 09:52:01.567: epoch 82:	0.02593204  	0.19110192  	0.10397887  
2023-05-18 09:52:01.567: Find a better model.
2023-05-18 09:52:09.160: [iter 83 : loss : 0.1405 = 0.0493 + 0.0865 + 0.0047, time: 7.592038]
2023-05-18 09:52:09.323: epoch 83:	0.02591087  	0.19127302  	0.10442565  
2023-05-18 09:52:09.323: Find a better model.
2023-05-18 09:52:17.902: [iter 84 : loss : 0.1406 = 0.0494 + 0.0864 + 0.0047, time: 8.578027]
2023-05-18 09:52:18.064: epoch 84:	0.02594615  	0.19140938  	0.10460649  
2023-05-18 09:52:18.065: Find a better model.
2023-05-18 09:52:26.568: [iter 85 : loss : 0.1395 = 0.0484 + 0.0864 + 0.0048, time: 8.499223]
2023-05-18 09:52:26.864: epoch 85:	0.02597438  	0.19134955  	0.10482914  
2023-05-18 09:52:34.797: [iter 86 : loss : 0.1393 = 0.0482 + 0.0862 + 0.0048, time: 7.924008]
2023-05-18 09:52:34.954: epoch 86:	0.02595321  	0.19129503  	0.10499814  
2023-05-18 09:52:44.118: [iter 87 : loss : 0.1368 = 0.0457 + 0.0862 + 0.0048, time: 9.161068]
2023-05-18 09:52:44.420: epoch 87:	0.02600260  	0.19146374  	0.10513660  
2023-05-18 09:52:44.420: Find a better model.
2023-05-18 09:52:51.886: [iter 88 : loss : 0.1360 = 0.0450 + 0.0861 + 0.0049, time: 7.465003]
2023-05-18 09:52:52.048: epoch 88:	0.02604494  	0.19155775  	0.10519066  
2023-05-18 09:52:52.048: Find a better model.
2023-05-18 09:53:00.433: [iter 89 : loss : 0.1357 = 0.0449 + 0.0859 + 0.0049, time: 8.384444]
2023-05-18 09:53:00.599: epoch 89:	0.02604494  	0.19155031  	0.10537863  
2023-05-18 09:53:09.136: [iter 90 : loss : 0.1364 = 0.0455 + 0.0859 + 0.0050, time: 8.535012]
2023-05-18 09:53:09.314: epoch 90:	0.02607317  	0.19194888  	0.10540860  
2023-05-18 09:53:09.314: Find a better model.
2023-05-18 09:53:17.200: [iter 91 : loss : 0.1349 = 0.0442 + 0.0858 + 0.0050, time: 7.883484]
2023-05-18 09:53:17.355: epoch 91:	0.02615079  	0.19246121  	0.10558381  
2023-05-18 09:53:17.355: Find a better model.
2023-05-18 09:53:26.505: [iter 92 : loss : 0.1339 = 0.0432 + 0.0857 + 0.0050, time: 9.148101]
2023-05-18 09:53:26.800: epoch 92:	0.02620019  	0.19287136  	0.10582226  
2023-05-18 09:53:26.800: Find a better model.
2023-05-18 09:53:34.373: [iter 93 : loss : 0.1346 = 0.0439 + 0.0856 + 0.0051, time: 7.572005]
2023-05-18 09:53:34.541: epoch 93:	0.02625664  	0.19301848  	0.10596541  
2023-05-18 09:53:34.541: Find a better model.
2023-05-18 09:53:42.802: [iter 94 : loss : 0.1323 = 0.0416 + 0.0856 + 0.0051, time: 8.260053]
2023-05-18 09:53:42.957: epoch 94:	0.02629192  	0.19356193  	0.10633668  
2023-05-18 09:53:42.957: Find a better model.
2023-05-18 09:53:51.263: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 8.305005]
2023-05-18 09:53:51.422: epoch 95:	0.02631309  	0.19377694  	0.10638677  
2023-05-18 09:53:51.422: Find a better model.
2023-05-18 09:53:59.406: [iter 96 : loss : 0.1315 = 0.0409 + 0.0854 + 0.0052, time: 7.983019]
2023-05-18 09:53:59.564: epoch 96:	0.02634132  	0.19389361  	0.10671397  
2023-05-18 09:53:59.564: Find a better model.
2023-05-18 09:54:08.886: [iter 97 : loss : 0.1301 = 0.0396 + 0.0853 + 0.0052, time: 9.319168]
2023-05-18 09:54:09.174: epoch 97:	0.02636248  	0.19418012  	0.10690847  
2023-05-18 09:54:09.174: Find a better model.
2023-05-18 09:54:16.826: [iter 98 : loss : 0.1307 = 0.0403 + 0.0852 + 0.0052, time: 7.651009]
2023-05-18 09:54:16.969: epoch 98:	0.02633425  	0.19390635  	0.10692139  
2023-05-18 09:54:24.516: [iter 99 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0053, time: 7.545842]
2023-05-18 09:54:24.671: epoch 99:	0.02641894  	0.19494452  	0.10729154  
2023-05-18 09:54:24.671: Find a better model.
2023-05-18 09:54:32.128: [iter 100 : loss : 0.1289 = 0.0385 + 0.0851 + 0.0053, time: 7.455330]
2023-05-18 09:54:32.284: epoch 100:	0.02644010  	0.19492090  	0.10727723  
2023-05-18 09:54:39.734: [iter 101 : loss : 0.1287 = 0.0383 + 0.0850 + 0.0054, time: 7.449158]
2023-05-18 09:54:39.892: epoch 101:	0.02641893  	0.19468422  	0.10732377  
2023-05-18 09:54:47.322: [iter 102 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 7.428777]
2023-05-18 09:54:47.465: epoch 102:	0.02642599  	0.19462165  	0.10754780  
2023-05-18 09:54:54.906: [iter 103 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 7.439325]
2023-05-18 09:54:55.062: epoch 103:	0.02653183  	0.19550170  	0.10783074  
2023-05-18 09:54:55.062: Find a better model.
2023-05-18 09:55:02.526: [iter 104 : loss : 0.1278 = 0.0376 + 0.0848 + 0.0055, time: 7.462953]
2023-05-18 09:55:02.684: epoch 104:	0.02655300  	0.19569890  	0.10816402  
2023-05-18 09:55:02.684: Find a better model.
2023-05-18 09:55:10.122: [iter 105 : loss : 0.1272 = 0.0370 + 0.0847 + 0.0055, time: 7.437761]
2023-05-18 09:55:10.276: epoch 105:	0.02650361  	0.19525988  	0.10810411  
2023-05-18 09:55:17.708: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 7.429686]
2023-05-18 09:55:17.860: epoch 106:	0.02653184  	0.19539770  	0.10821325  
2023-05-18 09:55:25.323: [iter 107 : loss : 0.1258 = 0.0356 + 0.0846 + 0.0056, time: 7.461708]
2023-05-18 09:55:25.477: epoch 107:	0.02657417  	0.19569780  	0.10840603  
2023-05-18 09:55:32.926: [iter 108 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 7.448023]
2023-05-18 09:55:33.080: epoch 108:	0.02657417  	0.19579902  	0.10851661  
2023-05-18 09:55:33.080: Find a better model.
2023-05-18 09:55:40.695: [iter 109 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 7.612800]
2023-05-18 09:55:40.839: epoch 109:	0.02649654  	0.19513586  	0.10827644  
2023-05-18 09:55:48.308: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 7.467212]
2023-05-18 09:55:48.464: epoch 110:	0.02655300  	0.19534867  	0.10834664  
2023-05-18 09:55:55.944: [iter 111 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 7.478190]
2023-05-18 09:55:56.099: epoch 111:	0.02658828  	0.19572681  	0.10854571  
2023-05-18 09:56:03.680: [iter 112 : loss : 0.1235 = 0.0334 + 0.0843 + 0.0057, time: 7.579871]
2023-05-18 09:56:03.824: epoch 112:	0.02658123  	0.19594403  	0.10845476  
2023-05-18 09:56:03.824: Find a better model.
2023-05-18 09:56:11.303: [iter 113 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0058, time: 7.478562]
2023-05-18 09:56:11.457: epoch 113:	0.02665179  	0.19635420  	0.10862922  
2023-05-18 09:56:11.457: Find a better model.
2023-05-18 09:56:18.892: [iter 114 : loss : 0.1225 = 0.0325 + 0.0842 + 0.0058, time: 7.433968]
2023-05-18 09:56:19.044: epoch 114:	0.02664474  	0.19627130  	0.10869151  
2023-05-18 09:56:26.525: [iter 115 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 7.477366]
2023-05-18 09:56:26.679: epoch 115:	0.02673647  	0.19670540  	0.10897669  
2023-05-18 09:56:26.679: Find a better model.
2023-05-18 09:56:34.101: [iter 116 : loss : 0.1212 = 0.0312 + 0.0841 + 0.0059, time: 7.419357]
2023-05-18 09:56:34.255: epoch 116:	0.02673647  	0.19691582  	0.10893397  
2023-05-18 09:56:34.255: Find a better model.
2023-05-18 09:56:41.692: [iter 117 : loss : 0.1209 = 0.0310 + 0.0841 + 0.0059, time: 7.435891]
2023-05-18 09:56:41.849: epoch 117:	0.02676470  	0.19722292  	0.10894299  
2023-05-18 09:56:41.849: Find a better model.
2023-05-18 09:56:49.293: [iter 118 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 7.443637]
2023-05-18 09:56:49.447: epoch 118:	0.02675059  	0.19685115  	0.10898907  
2023-05-18 09:56:56.887: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0060, time: 7.437948]
2023-05-18 09:56:57.042: epoch 119:	0.02681409  	0.19743656  	0.10927802  
2023-05-18 09:56:57.043: Find a better model.
2023-05-18 09:57:04.473: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 7.429184]
2023-05-18 09:57:04.619: epoch 120:	0.02676470  	0.19676259  	0.10926467  
2023-05-18 09:57:12.054: [iter 121 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 7.433607]
2023-05-18 09:57:12.209: epoch 121:	0.02677882  	0.19690824  	0.10923562  
2023-05-18 09:57:19.661: [iter 122 : loss : 0.1192 = 0.0294 + 0.0838 + 0.0060, time: 7.451038]
2023-05-18 09:57:19.819: epoch 122:	0.02667298  	0.19622882  	0.10904670  
2023-05-18 09:57:27.265: [iter 123 : loss : 0.1193 = 0.0295 + 0.0837 + 0.0061, time: 7.445329]
2023-05-18 09:57:27.421: epoch 123:	0.02667298  	0.19629991  	0.10910939  
2023-05-18 09:57:34.908: [iter 124 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0061, time: 7.485525]
2023-05-18 09:57:35.061: epoch 124:	0.02676471  	0.19676721  	0.10932244  
2023-05-18 09:57:42.655: [iter 125 : loss : 0.1178 = 0.0280 + 0.0836 + 0.0061, time: 7.593435]
2023-05-18 09:57:42.810: epoch 125:	0.02673649  	0.19692539  	0.10948305  
2023-05-18 09:57:50.237: [iter 126 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0062, time: 7.425251]
2023-05-18 09:57:50.392: epoch 126:	0.02682116  	0.19752972  	0.10972052  
2023-05-18 09:57:50.393: Find a better model.
2023-05-18 09:57:57.858: [iter 127 : loss : 0.1168 = 0.0270 + 0.0835 + 0.0062, time: 7.463573]
2023-05-18 09:57:58.013: epoch 127:	0.02678588  	0.19739859  	0.10959093  
2023-05-18 09:58:05.669: [iter 128 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 7.655618]
2023-05-18 09:58:05.823: epoch 128:	0.02674354  	0.19714788  	0.10968338  
2023-05-18 09:58:13.255: [iter 129 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 7.430440]
2023-05-18 09:58:13.410: epoch 129:	0.02674354  	0.19713375  	0.10965414  
2023-05-18 09:58:20.851: [iter 130 : loss : 0.1173 = 0.0276 + 0.0834 + 0.0063, time: 7.439845]
2023-05-18 09:58:21.006: epoch 130:	0.02679999  	0.19747841  	0.10966630  
2023-05-18 09:58:28.448: [iter 131 : loss : 0.1161 = 0.0265 + 0.0833 + 0.0063, time: 7.439543]
2023-05-18 09:58:28.602: epoch 131:	0.02680705  	0.19747907  	0.10973824  
2023-05-18 09:58:36.053: [iter 132 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0064, time: 7.450188]
2023-05-18 09:58:36.208: epoch 132:	0.02684939  	0.19746226  	0.10976328  
2023-05-18 09:58:43.639: [iter 133 : loss : 0.1152 = 0.0256 + 0.0833 + 0.0064, time: 7.428769]
2023-05-18 09:58:43.780: epoch 133:	0.02681410  	0.19735129  	0.10981797  
2023-05-18 09:58:51.216: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 7.434114]
2023-05-18 09:58:51.372: epoch 134:	0.02677882  	0.19688149  	0.10972517  
2023-05-18 09:58:58.855: [iter 135 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 7.482092]
2023-05-18 09:58:59.000: epoch 135:	0.02685644  	0.19730458  	0.10980942  
2023-05-18 09:59:06.428: [iter 136 : loss : 0.1154 = 0.0258 + 0.0831 + 0.0065, time: 7.426825]
2023-05-18 09:59:06.582: epoch 136:	0.02689878  	0.19767639  	0.10987081  
2023-05-18 09:59:06.582: Find a better model.
2023-05-18 09:59:13.848: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 7.265670]
2023-05-18 09:59:14.002: epoch 137:	0.02683527  	0.19711015  	0.10972493  
2023-05-18 09:59:21.422: [iter 138 : loss : 0.1143 = 0.0247 + 0.0831 + 0.0065, time: 7.417663]
2023-05-18 09:59:21.577: epoch 138:	0.02686350  	0.19729324  	0.10975433  
2023-05-18 09:59:29.019: [iter 139 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0066, time: 7.440790]
2023-05-18 09:59:29.174: epoch 139:	0.02679999  	0.19693691  	0.10974979  
2023-05-18 09:59:36.653: [iter 140 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 7.477316]
2023-05-18 09:59:36.806: epoch 140:	0.02685644  	0.19736087  	0.10997979  
2023-05-18 09:59:44.222: [iter 141 : loss : 0.1144 = 0.0248 + 0.0829 + 0.0066, time: 7.415347]
2023-05-18 09:59:44.379: epoch 141:	0.02685644  	0.19740224  	0.11018459  
2023-05-18 09:59:51.822: [iter 142 : loss : 0.1133 = 0.0237 + 0.0829 + 0.0066, time: 7.441319]
2023-05-18 09:59:51.980: epoch 142:	0.02681411  	0.19738604  	0.11010201  
2023-05-18 09:59:59.436: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 7.452760]
2023-05-18 09:59:59.590: epoch 143:	0.02684233  	0.19744301  	0.11017205  
2023-05-18 10:00:06.990: [iter 144 : loss : 0.1129 = 0.0233 + 0.0828 + 0.0067, time: 7.399007]
2023-05-18 10:00:07.147: epoch 144:	0.02682116  	0.19727309  	0.11016896  
2023-05-18 10:00:14.417: [iter 145 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.268653]
2023-05-18 10:00:14.574: epoch 145:	0.02694112  	0.19803083  	0.11059454  
2023-05-18 10:00:14.574: Find a better model.
2023-05-18 10:00:21.980: [iter 146 : loss : 0.1129 = 0.0234 + 0.0828 + 0.0067, time: 7.404221]
2023-05-18 10:00:22.134: epoch 146:	0.02685644  	0.19733807  	0.11028483  
2023-05-18 10:00:29.403: [iter 147 : loss : 0.1131 = 0.0236 + 0.0827 + 0.0068, time: 7.267373]
2023-05-18 10:00:29.557: epoch 147:	0.02692700  	0.19761521  	0.11043637  
2023-05-18 10:00:37.010: [iter 148 : loss : 0.1114 = 0.0219 + 0.0827 + 0.0068, time: 7.451624]
2023-05-18 10:00:37.167: epoch 148:	0.02689173  	0.19755150  	0.11045370  
2023-05-18 10:00:44.595: [iter 149 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 7.425799]
2023-05-18 10:00:44.753: epoch 149:	0.02690584  	0.19781005  	0.11051085  
2023-05-18 10:00:52.000: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0069, time: 7.246544]
2023-05-18 10:00:52.157: epoch 150:	0.02693406  	0.19799341  	0.11064002  
2023-05-18 10:00:59.571: [iter 151 : loss : 0.1116 = 0.0221 + 0.0826 + 0.0069, time: 7.411154]
2023-05-18 10:00:59.727: epoch 151:	0.02694818  	0.19803897  	0.11066429  
2023-05-18 10:00:59.727: Find a better model.
2023-05-18 10:01:06.998: [iter 152 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0069, time: 7.270175]
2023-05-18 10:01:07.157: epoch 152:	0.02695523  	0.19810542  	0.11069642  
2023-05-18 10:01:07.157: Find a better model.
2023-05-18 10:01:14.576: [iter 153 : loss : 0.1101 = 0.0206 + 0.0825 + 0.0069, time: 7.417883]
2023-05-18 10:01:14.733: epoch 153:	0.02695524  	0.19806759  	0.11083486  
2023-05-18 10:01:22.162: [iter 154 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0070, time: 7.426298]
2023-05-18 10:01:22.315: epoch 154:	0.02691289  	0.19746183  	0.11066771  
2023-05-18 10:01:29.767: [iter 155 : loss : 0.1110 = 0.0215 + 0.0825 + 0.0070, time: 7.450751]
2023-05-18 10:01:29.923: epoch 155:	0.02693406  	0.19765738  	0.11079757  
2023-05-18 10:01:37.183: [iter 156 : loss : 0.1107 = 0.0213 + 0.0825 + 0.0070, time: 7.258802]
2023-05-18 10:01:37.337: epoch 156:	0.02681410  	0.19670692  	0.11044379  
2023-05-18 10:01:44.768: [iter 157 : loss : 0.1105 = 0.0211 + 0.0824 + 0.0070, time: 7.428764]
2023-05-18 10:01:44.921: epoch 157:	0.02681410  	0.19691430  	0.11041818  
2023-05-18 10:01:52.350: [iter 158 : loss : 0.1097 = 0.0203 + 0.0824 + 0.0071, time: 7.427006]
2023-05-18 10:01:52.506: epoch 158:	0.02682116  	0.19696605  	0.11052064  
2023-05-18 10:01:59.975: [iter 159 : loss : 0.1100 = 0.0205 + 0.0824 + 0.0071, time: 7.468477]
2023-05-18 10:02:00.136: epoch 159:	0.02677176  	0.19651525  	0.11026000  
2023-05-18 10:02:07.544: [iter 160 : loss : 0.1096 = 0.0202 + 0.0823 + 0.0071, time: 7.406322]
2023-05-18 10:02:07.702: epoch 160:	0.02680704  	0.19658098  	0.11027463  
2023-05-18 10:02:14.987: [iter 161 : loss : 0.1091 = 0.0196 + 0.0823 + 0.0071, time: 7.283956]
2023-05-18 10:02:15.139: epoch 161:	0.02675765  	0.19632889  	0.11020584  
2023-05-18 10:02:22.564: [iter 162 : loss : 0.1085 = 0.0190 + 0.0823 + 0.0072, time: 7.422817]
2023-05-18 10:02:22.719: epoch 162:	0.02681410  	0.19677597  	0.11027458  
2023-05-18 10:02:29.965: [iter 163 : loss : 0.1089 = 0.0195 + 0.0823 + 0.0072, time: 7.244470]
2023-05-18 10:02:30.120: epoch 163:	0.02677176  	0.19632043  	0.11011020  
2023-05-18 10:02:37.371: [iter 164 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0072, time: 7.248632]
2023-05-18 10:02:37.528: epoch 164:	0.02673648  	0.19635156  	0.11008181  
2023-05-18 10:02:44.931: [iter 165 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.401144]
2023-05-18 10:02:45.090: epoch 165:	0.02671531  	0.19607507  	0.10987169  
2023-05-18 10:02:52.738: [iter 166 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0073, time: 7.645950]
2023-05-18 10:02:53.202: epoch 166:	0.02658123  	0.19495182  	0.10950411  
2023-05-18 10:03:01.018: [iter 167 : loss : 0.1086 = 0.0192 + 0.0821 + 0.0073, time: 7.812604]
2023-05-18 10:03:01.170: epoch 167:	0.02660946  	0.19514719  	0.10954811  
2023-05-18 10:03:08.792: [iter 168 : loss : 0.1080 = 0.0186 + 0.0821 + 0.0073, time: 7.620026]
2023-05-18 10:03:08.950: epoch 168:	0.02663063  	0.19550145  	0.10986011  
2023-05-18 10:03:17.069: [iter 169 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 8.117396]
2023-05-18 10:03:17.307: epoch 169:	0.02663768  	0.19551483  	0.10984157  
2023-05-18 10:03:25.453: [iter 170 : loss : 0.1078 = 0.0184 + 0.0821 + 0.0073, time: 8.143034]
2023-05-18 10:03:25.621: epoch 170:	0.02660946  	0.19535027  	0.10985147  
2023-05-18 10:03:34.057: [iter 171 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0074, time: 8.434320]
2023-05-18 10:03:34.254: epoch 171:	0.02667296  	0.19549547  	0.11005031  
2023-05-18 10:03:41.991: [iter 172 : loss : 0.1072 = 0.0178 + 0.0820 + 0.0074, time: 7.735059]
2023-05-18 10:03:42.146: epoch 172:	0.02666591  	0.19526424  	0.10989837  
2023-05-18 10:03:51.142: [iter 173 : loss : 0.1078 = 0.0183 + 0.0820 + 0.0074, time: 8.995012]
2023-05-18 10:03:51.429: epoch 173:	0.02665885  	0.19535993  	0.10998484  
2023-05-18 10:03:58.848: [iter 174 : loss : 0.1074 = 0.0180 + 0.0820 + 0.0074, time: 7.418659]
2023-05-18 10:03:59.010: epoch 174:	0.02662358  	0.19518404  	0.11006571  
2023-05-18 10:04:07.183: [iter 175 : loss : 0.1070 = 0.0176 + 0.0819 + 0.0075, time: 8.171270]
2023-05-18 10:04:07.340: epoch 175:	0.02659534  	0.19510204  	0.10996228  
2023-05-18 10:04:15.616: [iter 176 : loss : 0.1065 = 0.0170 + 0.0819 + 0.0075, time: 8.275010]
2023-05-18 10:04:15.776: epoch 176:	0.02653184  	0.19446178  	0.10985835  
2023-05-18 10:04:23.596: [iter 177 : loss : 0.1072 = 0.0178 + 0.0819 + 0.0075, time: 7.818016]
2023-05-18 10:04:23.758: epoch 177:	0.02651773  	0.19410154  	0.10963453  
2023-05-18 10:04:23.758: Early stopping is trigger at epoch: 177
2023-05-18 10:04:23.758: best_result@epoch 152:

2023-05-18 10:04:23.758: 		0.0270      	0.1981      	0.1107      
2023-05-18 10:12:11.538: my pid: 8220
2023-05-18 10:12:11.538: model: model.general_recommender.SGL
2023-05-18 10:12:11.538: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 10:12:11.538: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 10:12:15.588: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 10:12:25.013: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.423210]
2023-05-18 10:12:25.184: epoch 1:	0.00140418  	0.01015145  	0.00493255  
2023-05-18 10:12:25.184: Find a better model.
2023-05-18 10:12:34.967: [iter 2 : loss : 0.7712 = 0.6929 + 0.0784 + 0.0000, time: 9.781035]
2023-05-18 10:12:35.183: epoch 2:	0.00236382  	0.01848183  	0.00907417  
2023-05-18 10:12:35.183: Find a better model.
2023-05-18 10:12:44.010: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.826197]
2023-05-18 10:12:44.240: epoch 3:	0.00434658  	0.03315968  	0.01549178  
2023-05-18 10:12:44.240: Find a better model.
2023-05-18 10:12:54.309: [iter 4 : loss : 0.7707 = 0.6921 + 0.0785 + 0.0000, time: 10.059001]
2023-05-18 10:12:54.625: epoch 4:	0.00704906  	0.05145500  	0.02512015  
2023-05-18 10:12:54.625: Find a better model.
2023-05-18 10:13:03.488: [iter 5 : loss : 0.7699 = 0.6912 + 0.0787 + 0.0000, time: 8.861948]
2023-05-18 10:13:03.637: epoch 5:	0.01052779  	0.07601193  	0.03648599  
2023-05-18 10:13:03.637: Find a better model.
2023-05-18 10:13:11.889: [iter 6 : loss : 0.7681 = 0.6891 + 0.0790 + 0.0000, time: 8.249004]
2023-05-18 10:13:12.064: epoch 6:	0.01423242  	0.10148572  	0.04977792  
2023-05-18 10:13:12.064: Find a better model.
2023-05-18 10:13:21.031: [iter 7 : loss : 0.7633 = 0.6836 + 0.0796 + 0.0000, time: 8.964137]
2023-05-18 10:13:21.210: epoch 7:	0.01692797  	0.12263665  	0.06054414  
2023-05-18 10:13:21.211: Find a better model.
2023-05-18 10:13:30.643: [iter 8 : loss : 0.7514 = 0.6702 + 0.0812 + 0.0001, time: 9.430023]
2023-05-18 10:13:30.948: epoch 8:	0.01829690  	0.13264284  	0.06681849  
2023-05-18 10:13:30.948: Find a better model.
2023-05-18 10:13:39.729: [iter 9 : loss : 0.7230 = 0.6385 + 0.0844 + 0.0001, time: 8.780013]
2023-05-18 10:13:39.908: epoch 9:	0.01885438  	0.13815776  	0.06937932  
2023-05-18 10:13:39.908: Find a better model.
2023-05-18 10:13:48.631: [iter 10 : loss : 0.6693 = 0.5795 + 0.0896 + 0.0002, time: 8.722020]
2023-05-18 10:13:48.796: epoch 10:	0.01858623  	0.13685048  	0.06837405  
2023-05-18 10:13:57.435: [iter 11 : loss : 0.5948 = 0.4995 + 0.0950 + 0.0004, time: 8.636684]
2023-05-18 10:13:57.641: epoch 11:	0.01848038  	0.13634293  	0.06802258  
2023-05-18 10:14:05.555: [iter 12 : loss : 0.5217 = 0.4222 + 0.0990 + 0.0005, time: 7.912014]
2023-05-18 10:14:05.714: epoch 12:	0.01853684  	0.13726507  	0.06854641  
2023-05-18 10:14:15.293: [iter 13 : loss : 0.4660 = 0.3641 + 0.1013 + 0.0007, time: 9.572029]
2023-05-18 10:14:15.588: epoch 13:	0.01862151  	0.13796099  	0.06929109  
2023-05-18 10:14:23.718: [iter 14 : loss : 0.4242 = 0.3210 + 0.1024 + 0.0008, time: 8.128003]
2023-05-18 10:14:23.875: epoch 14:	0.01877675  	0.13904805  	0.06999139  
2023-05-18 10:14:23.875: Find a better model.
2023-05-18 10:14:31.956: [iter 15 : loss : 0.3955 = 0.2916 + 0.1029 + 0.0010, time: 8.079139]
2023-05-18 10:14:32.116: epoch 15:	0.01888260  	0.14047150  	0.07070912  
2023-05-18 10:14:32.116: Find a better model.
2023-05-18 10:14:40.892: [iter 16 : loss : 0.3718 = 0.2677 + 0.1030 + 0.0011, time: 8.774380]
2023-05-18 10:14:41.057: epoch 16:	0.01904490  	0.14145243  	0.07151961  
2023-05-18 10:14:41.057: Find a better model.
2023-05-18 10:14:50.532: [iter 17 : loss : 0.3545 = 0.2504 + 0.1029 + 0.0012, time: 9.474122]
2023-05-18 10:14:50.834: epoch 17:	0.01934127  	0.14309353  	0.07255592  
2023-05-18 10:14:50.834: Find a better model.
2023-05-18 10:15:00.464: [iter 18 : loss : 0.3384 = 0.2346 + 0.1026 + 0.0013, time: 9.626017]
2023-05-18 10:15:00.767: epoch 18:	0.01951769  	0.14401253  	0.07320236  
2023-05-18 10:15:00.767: Find a better model.
2023-05-18 10:15:09.338: [iter 19 : loss : 0.3239 = 0.2203 + 0.1023 + 0.0014, time: 8.569458]
2023-05-18 10:15:09.515: epoch 19:	0.01967999  	0.14505297  	0.07377472  
2023-05-18 10:15:09.515: Find a better model.
2023-05-18 10:15:17.855: [iter 20 : loss : 0.3141 = 0.2107 + 0.1019 + 0.0015, time: 8.339013]
2023-05-18 10:15:18.176: epoch 20:	0.01984229  	0.14626178  	0.07428333  
2023-05-18 10:15:18.176: Find a better model.
2023-05-18 10:15:26.516: [iter 21 : loss : 0.3042 = 0.2012 + 0.1015 + 0.0016, time: 8.338383]
2023-05-18 10:15:26.675: epoch 21:	0.02002576  	0.14750800  	0.07517772  
2023-05-18 10:15:26.675: Find a better model.
2023-05-18 10:15:36.183: [iter 22 : loss : 0.2959 = 0.1931 + 0.1012 + 0.0016, time: 9.506013]
2023-05-18 10:15:36.463: epoch 22:	0.02011750  	0.14799786  	0.07577546  
2023-05-18 10:15:36.463: Find a better model.
2023-05-18 10:15:44.355: [iter 23 : loss : 0.2872 = 0.1849 + 0.1006 + 0.0017, time: 7.890534]
2023-05-18 10:15:44.519: epoch 23:	0.02035037  	0.14970830  	0.07681086  
2023-05-18 10:15:44.519: Find a better model.
2023-05-18 10:15:52.739: [iter 24 : loss : 0.2807 = 0.1787 + 0.1001 + 0.0018, time: 8.218430]
2023-05-18 10:15:52.896: epoch 24:	0.02057617  	0.15100564  	0.07751399  
2023-05-18 10:15:52.897: Find a better model.
2023-05-18 10:16:01.549: [iter 25 : loss : 0.2739 = 0.1722 + 0.0998 + 0.0019, time: 8.650615]
2023-05-18 10:16:01.707: epoch 25:	0.02075964  	0.15203014  	0.07803544  
2023-05-18 10:16:01.707: Find a better model.
2023-05-18 10:16:10.829: [iter 26 : loss : 0.2703 = 0.1691 + 0.0993 + 0.0019, time: 9.120450]
2023-05-18 10:16:11.134: epoch 26:	0.02102074  	0.15391214  	0.07890692  
2023-05-18 10:16:11.134: Find a better model.
2023-05-18 10:16:20.592: [iter 27 : loss : 0.2624 = 0.1616 + 0.0988 + 0.0020, time: 9.454129]
2023-05-18 10:16:20.887: epoch 27:	0.02117598  	0.15508834  	0.07966682  
2023-05-18 10:16:20.887: Find a better model.
2023-05-18 10:16:29.446: [iter 28 : loss : 0.2574 = 0.1569 + 0.0984 + 0.0021, time: 8.557039]
2023-05-18 10:16:29.604: epoch 28:	0.02133123  	0.15612461  	0.08042811  
2023-05-18 10:16:29.604: Find a better model.
2023-05-18 10:16:37.519: [iter 29 : loss : 0.2528 = 0.1526 + 0.0980 + 0.0021, time: 7.913023]
2023-05-18 10:16:37.680: epoch 29:	0.02145119  	0.15700905  	0.08097308  
2023-05-18 10:16:37.680: Find a better model.
2023-05-18 10:16:46.353: [iter 30 : loss : 0.2463 = 0.1464 + 0.0976 + 0.0022, time: 8.670427]
2023-05-18 10:16:46.575: epoch 30:	0.02157821  	0.15852837  	0.08164284  
2023-05-18 10:16:46.575: Find a better model.
2023-05-18 10:16:55.902: [iter 31 : loss : 0.2428 = 0.1433 + 0.0972 + 0.0022, time: 9.322233]
2023-05-18 10:16:56.192: epoch 31:	0.02183225  	0.16085145  	0.08278304  
2023-05-18 10:16:56.192: Find a better model.
2023-05-18 10:17:04.913: [iter 32 : loss : 0.2370 = 0.1378 + 0.0969 + 0.0023, time: 8.719005]
2023-05-18 10:17:05.091: epoch 32:	0.02203688  	0.16243611  	0.08344247  
2023-05-18 10:17:05.091: Find a better model.
2023-05-18 10:17:13.765: [iter 33 : loss : 0.2346 = 0.1358 + 0.0965 + 0.0024, time: 8.673008]
2023-05-18 10:17:13.930: epoch 33:	0.02219918  	0.16395788  	0.08419938  
2023-05-18 10:17:13.930: Find a better model.
2023-05-18 10:17:22.584: [iter 34 : loss : 0.2302 = 0.1317 + 0.0961 + 0.0024, time: 8.653029]
2023-05-18 10:17:22.732: epoch 34:	0.02225563  	0.16408327  	0.08481663  
2023-05-18 10:17:22.732: Find a better model.
2023-05-18 10:17:30.697: [iter 35 : loss : 0.2269 = 0.1286 + 0.0958 + 0.0025, time: 7.963039]
2023-05-18 10:17:30.855: epoch 35:	0.02234737  	0.16437069  	0.08523865  
2023-05-18 10:17:30.855: Find a better model.
2023-05-18 10:17:40.183: [iter 36 : loss : 0.2233 = 0.1253 + 0.0955 + 0.0025, time: 9.322022]
2023-05-18 10:17:40.488: epoch 36:	0.02255200  	0.16620268  	0.08610626  
2023-05-18 10:17:40.488: Find a better model.
2023-05-18 10:17:48.540: [iter 37 : loss : 0.2192 = 0.1215 + 0.0951 + 0.0026, time: 8.051277]
2023-05-18 10:17:48.699: epoch 37:	0.02268608  	0.16729064  	0.08658884  
2023-05-18 10:17:48.699: Find a better model.
2023-05-18 10:17:56.899: [iter 38 : loss : 0.2179 = 0.1204 + 0.0949 + 0.0026, time: 8.198031]
2023-05-18 10:17:57.056: epoch 38:	0.02284838  	0.16799825  	0.08720648  
2023-05-18 10:17:57.056: Find a better model.
2023-05-18 10:18:05.694: [iter 39 : loss : 0.2134 = 0.1162 + 0.0945 + 0.0027, time: 8.636009]
2023-05-18 10:18:05.962: epoch 39:	0.02299656  	0.16927224  	0.08793642  
2023-05-18 10:18:05.963: Find a better model.
2023-05-18 10:18:15.340: [iter 40 : loss : 0.2099 = 0.1129 + 0.0942 + 0.0028, time: 9.372024]
2023-05-18 10:18:15.636: epoch 40:	0.02300362  	0.16901332  	0.08787831  
2023-05-18 10:18:25.059: [iter 41 : loss : 0.2083 = 0.1115 + 0.0939 + 0.0028, time: 9.420022]
2023-05-18 10:18:25.353: epoch 41:	0.02320826  	0.17124766  	0.08884114  
2023-05-18 10:18:25.354: Find a better model.
2023-05-18 10:18:33.644: [iter 42 : loss : 0.2062 = 0.1096 + 0.0937 + 0.0029, time: 8.289003]
2023-05-18 10:18:33.883: epoch 42:	0.02329999  	0.17176530  	0.08938141  
2023-05-18 10:18:33.883: Find a better model.
2023-05-18 10:18:41.678: [iter 43 : loss : 0.2021 = 0.1058 + 0.0934 + 0.0029, time: 7.793002]
2023-05-18 10:18:41.837: epoch 43:	0.02340584  	0.17231253  	0.08986580  
2023-05-18 10:18:41.837: Find a better model.
2023-05-18 10:18:50.124: [iter 44 : loss : 0.1987 = 0.1027 + 0.0930 + 0.0030, time: 8.285028]
2023-05-18 10:18:50.292: epoch 44:	0.02355402  	0.17338146  	0.09029413  
2023-05-18 10:18:50.292: Find a better model.
2023-05-18 10:18:59.600: [iter 45 : loss : 0.1966 = 0.1008 + 0.0928 + 0.0030, time: 9.307002]
2023-05-18 10:18:59.894: epoch 45:	0.02363164  	0.17374420  	0.09073084  
2023-05-18 10:18:59.894: Find a better model.
2023-05-18 10:19:08.531: [iter 46 : loss : 0.1940 = 0.0984 + 0.0925 + 0.0031, time: 8.636012]
2023-05-18 10:19:08.698: epoch 46:	0.02375866  	0.17483850  	0.09135947  
2023-05-18 10:19:08.698: Find a better model.
2023-05-18 10:19:17.503: [iter 47 : loss : 0.1932 = 0.0978 + 0.0923 + 0.0031, time: 8.802996]
2023-05-18 10:19:17.664: epoch 47:	0.02380100  	0.17505819  	0.09173666  
2023-05-18 10:19:17.664: Find a better model.
2023-05-18 10:19:26.302: [iter 48 : loss : 0.1894 = 0.0941 + 0.0921 + 0.0032, time: 8.636106]
2023-05-18 10:19:26.497: epoch 48:	0.02383628  	0.17520154  	0.09212226  
2023-05-18 10:19:26.498: Find a better model.
2023-05-18 10:19:34.438: [iter 49 : loss : 0.1862 = 0.0911 + 0.0919 + 0.0032, time: 7.937004]
2023-05-18 10:19:34.600: epoch 49:	0.02393507  	0.17565462  	0.09245330  
2023-05-18 10:19:34.600: Find a better model.
2023-05-18 10:19:44.061: [iter 50 : loss : 0.1854 = 0.0906 + 0.0916 + 0.0032, time: 9.457013]
2023-05-18 10:19:44.373: epoch 50:	0.02399857  	0.17604519  	0.09294114  
2023-05-18 10:19:44.373: Find a better model.
2023-05-18 10:19:52.375: [iter 51 : loss : 0.1821 = 0.0874 + 0.0914 + 0.0033, time: 8.000002]
2023-05-18 10:19:52.534: epoch 51:	0.02409736  	0.17663005  	0.09330422  
2023-05-18 10:19:52.535: Find a better model.
2023-05-18 10:20:00.632: [iter 52 : loss : 0.1821 = 0.0876 + 0.0912 + 0.0033, time: 8.095026]
2023-05-18 10:20:00.790: epoch 52:	0.02419615  	0.17756703  	0.09390219  
2023-05-18 10:20:00.790: Find a better model.
2023-05-18 10:20:09.328: [iter 53 : loss : 0.1801 = 0.0857 + 0.0910 + 0.0034, time: 8.536314]
2023-05-18 10:20:09.543: epoch 53:	0.02424555  	0.17803490  	0.09417059  
2023-05-18 10:20:09.543: Find a better model.
2023-05-18 10:20:19.035: [iter 54 : loss : 0.1779 = 0.0836 + 0.0908 + 0.0034, time: 9.486453]
2023-05-18 10:20:19.330: epoch 54:	0.02441490  	0.17925064  	0.09491788  
2023-05-18 10:20:19.330: Find a better model.
2023-05-18 10:20:28.799: [iter 55 : loss : 0.1761 = 0.0820 + 0.0906 + 0.0035, time: 9.461042]
2023-05-18 10:20:29.097: epoch 55:	0.02444312  	0.17918731  	0.09508365  
2023-05-18 10:20:37.652: [iter 56 : loss : 0.1743 = 0.0803 + 0.0904 + 0.0035, time: 8.554030]
2023-05-18 10:20:37.818: epoch 56:	0.02453485  	0.17980431  	0.09535997  
2023-05-18 10:20:37.818: Find a better model.
2023-05-18 10:20:45.873: [iter 57 : loss : 0.1725 = 0.0787 + 0.0902 + 0.0036, time: 8.054021]
2023-05-18 10:20:46.035: epoch 57:	0.02459130  	0.18020304  	0.09574378  
2023-05-18 10:20:46.035: Find a better model.
2023-05-18 10:20:54.421: [iter 58 : loss : 0.1703 = 0.0766 + 0.0900 + 0.0036, time: 8.384032]
2023-05-18 10:20:54.582: epoch 58:	0.02466187  	0.18068777  	0.09615924  
2023-05-18 10:20:54.582: Find a better model.
2023-05-18 10:21:03.916: [iter 59 : loss : 0.1696 = 0.0760 + 0.0899 + 0.0037, time: 9.329042]
2023-05-18 10:21:04.180: epoch 59:	0.02471832  	0.18138810  	0.09659424  
2023-05-18 10:21:04.180: Find a better model.
2023-05-18 10:21:11.996: [iter 60 : loss : 0.1681 = 0.0747 + 0.0897 + 0.0037, time: 7.814022]
2023-05-18 10:21:12.162: epoch 60:	0.02481711  	0.18228263  	0.09700927  
2023-05-18 10:21:12.163: Find a better model.
2023-05-18 10:21:20.703: [iter 61 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0038, time: 8.538365]
2023-05-18 10:21:20.869: epoch 61:	0.02493707  	0.18333714  	0.09755827  
2023-05-18 10:21:20.869: Find a better model.
2023-05-18 10:21:29.488: [iter 62 : loss : 0.1648 = 0.0716 + 0.0894 + 0.0038, time: 8.617012]
2023-05-18 10:21:29.660: epoch 62:	0.02500058  	0.18361551  	0.09770278  
2023-05-18 10:21:29.660: Find a better model.
2023-05-18 10:21:37.593: [iter 63 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 7.931432]
2023-05-18 10:21:37.751: epoch 63:	0.02507114  	0.18408896  	0.09812275  
2023-05-18 10:21:37.751: Find a better model.
2023-05-18 10:21:47.223: [iter 64 : loss : 0.1625 = 0.0696 + 0.0890 + 0.0039, time: 9.469150]
2023-05-18 10:21:47.526: epoch 64:	0.02516288  	0.18467636  	0.09852659  
2023-05-18 10:21:47.527: Find a better model.
2023-05-18 10:21:55.493: [iter 65 : loss : 0.1612 = 0.0684 + 0.0889 + 0.0039, time: 7.964013]
2023-05-18 10:21:55.651: epoch 65:	0.02519110  	0.18469778  	0.09877540  
2023-05-18 10:21:55.651: Find a better model.
2023-05-18 10:22:03.774: [iter 66 : loss : 0.1596 = 0.0669 + 0.0887 + 0.0040, time: 8.120295]
2023-05-18 10:22:03.931: epoch 66:	0.02531106  	0.18581283  	0.09936973  
2023-05-18 10:22:03.931: Find a better model.
2023-05-18 10:22:12.411: [iter 67 : loss : 0.1579 = 0.0654 + 0.0885 + 0.0040, time: 8.477995]
2023-05-18 10:22:12.569: epoch 67:	0.02532518  	0.18623462  	0.09976455  
2023-05-18 10:22:12.569: Find a better model.
2023-05-18 10:22:22.385: [iter 68 : loss : 0.1576 = 0.0651 + 0.0884 + 0.0041, time: 9.813007]
2023-05-18 10:22:22.656: epoch 68:	0.02541691  	0.18718050  	0.10017512  
2023-05-18 10:22:22.656: Find a better model.
2023-05-18 10:22:32.214: [iter 69 : loss : 0.1557 = 0.0633 + 0.0883 + 0.0041, time: 9.555084]
2023-05-18 10:22:32.486: epoch 69:	0.02544513  	0.18737808  	0.10053373  
2023-05-18 10:22:32.486: Find a better model.
2023-05-18 10:22:40.912: [iter 70 : loss : 0.1540 = 0.0617 + 0.0881 + 0.0041, time: 8.425134]
2023-05-18 10:22:41.131: epoch 70:	0.02543102  	0.18700330  	0.10048634  
2023-05-18 10:22:48.975: [iter 71 : loss : 0.1525 = 0.0603 + 0.0880 + 0.0042, time: 7.842166]
2023-05-18 10:22:49.137: epoch 71:	0.02542396  	0.18690114  	0.10066782  
2023-05-18 10:22:57.718: [iter 72 : loss : 0.1523 = 0.0602 + 0.0879 + 0.0042, time: 8.578008]
2023-05-18 10:22:57.885: epoch 72:	0.02539574  	0.18680276  	0.10077076  
2023-05-18 10:23:07.186: [iter 73 : loss : 0.1509 = 0.0589 + 0.0878 + 0.0043, time: 9.299369]
2023-05-18 10:23:07.483: epoch 73:	0.02552981  	0.18760554  	0.10121098  
2023-05-18 10:23:07.483: Find a better model.
2023-05-18 10:23:16.279: [iter 74 : loss : 0.1494 = 0.0575 + 0.0876 + 0.0043, time: 8.792025]
2023-05-18 10:23:16.484: epoch 74:	0.02560038  	0.18827616  	0.10154109  
2023-05-18 10:23:16.484: Find a better model.
2023-05-18 10:23:25.024: [iter 75 : loss : 0.1490 = 0.0571 + 0.0876 + 0.0043, time: 8.538008]
2023-05-18 10:23:25.201: epoch 75:	0.02560038  	0.18822375  	0.10175320  
2023-05-18 10:23:33.933: [iter 76 : loss : 0.1480 = 0.0562 + 0.0874 + 0.0044, time: 8.730003]
2023-05-18 10:23:34.093: epoch 76:	0.02564272  	0.18846442  	0.10195670  
2023-05-18 10:23:34.093: Find a better model.
2023-05-18 10:23:41.963: [iter 77 : loss : 0.1471 = 0.0553 + 0.0873 + 0.0044, time: 7.868994]
2023-05-18 10:23:42.121: epoch 77:	0.02567095  	0.18874590  	0.10207605  
2023-05-18 10:23:42.121: Find a better model.
2023-05-18 10:23:51.563: [iter 78 : loss : 0.1458 = 0.0542 + 0.0872 + 0.0045, time: 9.441023]
2023-05-18 10:23:51.864: epoch 78:	0.02576268  	0.18929772  	0.10252234  
2023-05-18 10:23:51.865: Find a better model.
2023-05-18 10:23:59.697: [iter 79 : loss : 0.1446 = 0.0531 + 0.0871 + 0.0045, time: 7.830964]
2023-05-18 10:23:59.857: epoch 79:	0.02576268  	0.18939416  	0.10251677  
2023-05-18 10:23:59.857: Find a better model.
2023-05-18 10:24:07.950: [iter 80 : loss : 0.1440 = 0.0525 + 0.0869 + 0.0045, time: 8.092023]
2023-05-18 10:24:08.108: epoch 80:	0.02578385  	0.18922949  	0.10257711  
2023-05-18 10:24:16.547: [iter 81 : loss : 0.1438 = 0.0524 + 0.0868 + 0.0046, time: 8.436003]
2023-05-18 10:24:16.705: epoch 81:	0.02586147  	0.19005990  	0.10307772  
2023-05-18 10:24:16.706: Find a better model.
2023-05-18 10:24:26.221: [iter 82 : loss : 0.1426 = 0.0512 + 0.0868 + 0.0046, time: 9.512029]
2023-05-18 10:24:26.488: epoch 82:	0.02583324  	0.18984772  	0.10306814  
2023-05-18 10:24:35.991: [iter 83 : loss : 0.1415 = 0.0502 + 0.0866 + 0.0047, time: 9.501954]
2023-05-18 10:24:36.271: epoch 83:	0.02591792  	0.19033472  	0.10357817  
2023-05-18 10:24:36.271: Find a better model.
2023-05-18 10:24:44.689: [iter 84 : loss : 0.1414 = 0.0501 + 0.0866 + 0.0047, time: 8.417016]
2023-05-18 10:24:44.906: epoch 84:	0.02592498  	0.19018948  	0.10349730  
2023-05-18 10:24:52.770: [iter 85 : loss : 0.1404 = 0.0492 + 0.0864 + 0.0047, time: 7.861004]
2023-05-18 10:24:52.931: epoch 85:	0.02593908  	0.19026369  	0.10354393  
2023-05-18 10:25:01.629: [iter 86 : loss : 0.1401 = 0.0490 + 0.0863 + 0.0048, time: 8.695037]
2023-05-18 10:25:01.785: epoch 86:	0.02602376  	0.19116639  	0.10380304  
2023-05-18 10:25:01.785: Find a better model.
2023-05-18 10:25:11.167: [iter 87 : loss : 0.1372 = 0.0462 + 0.0862 + 0.0048, time: 9.378001]
2023-05-18 10:25:11.456: epoch 87:	0.02609433  	0.19177665  	0.10418352  
2023-05-18 10:25:11.456: Find a better model.
2023-05-18 10:25:20.011: [iter 88 : loss : 0.1367 = 0.0456 + 0.0862 + 0.0049, time: 8.552540]
2023-05-18 10:25:20.181: epoch 88:	0.02608021  	0.19148971  	0.10421070  
2023-05-18 10:25:28.975: [iter 89 : loss : 0.1366 = 0.0456 + 0.0861 + 0.0049, time: 8.792003]
2023-05-18 10:25:29.140: epoch 89:	0.02617195  	0.19246070  	0.10453811  
2023-05-18 10:25:29.140: Find a better model.
2023-05-18 10:25:37.862: [iter 90 : loss : 0.1370 = 0.0461 + 0.0860 + 0.0049, time: 8.721012]
2023-05-18 10:25:38.024: epoch 90:	0.02622840  	0.19285324  	0.10473552  
2023-05-18 10:25:38.025: Find a better model.
2023-05-18 10:25:46.104: [iter 91 : loss : 0.1357 = 0.0449 + 0.0859 + 0.0050, time: 8.077133]
2023-05-18 10:25:46.261: epoch 91:	0.02626368  	0.19311902  	0.10496185  
2023-05-18 10:25:46.261: Find a better model.
2023-05-18 10:25:55.592: [iter 92 : loss : 0.1347 = 0.0439 + 0.0858 + 0.0050, time: 9.328271]
2023-05-18 10:25:55.894: epoch 92:	0.02620017  	0.19271527  	0.10483125  
2023-05-18 10:26:03.763: [iter 93 : loss : 0.1351 = 0.0443 + 0.0857 + 0.0050, time: 7.867381]
2023-05-18 10:26:03.922: epoch 93:	0.02618606  	0.19264229  	0.10485305  
2023-05-18 10:26:12.128: [iter 94 : loss : 0.1328 = 0.0420 + 0.0857 + 0.0051, time: 8.205023]
2023-05-18 10:26:12.288: epoch 94:	0.02627074  	0.19309264  	0.10517118  
2023-05-18 10:26:20.891: [iter 95 : loss : 0.1321 = 0.0415 + 0.0856 + 0.0051, time: 8.601991]
2023-05-18 10:26:21.051: epoch 95:	0.02628485  	0.19335647  	0.10533102  
2023-05-18 10:26:21.051: Find a better model.
2023-05-18 10:26:30.686: [iter 96 : loss : 0.1325 = 0.0418 + 0.0855 + 0.0052, time: 9.632014]
2023-05-18 10:26:30.941: epoch 96:	0.02633424  	0.19411278  	0.10552281  
2023-05-18 10:26:30.941: Find a better model.
2023-05-18 10:26:40.408: [iter 97 : loss : 0.1306 = 0.0400 + 0.0853 + 0.0052, time: 9.462011]
2023-05-18 10:26:40.657: epoch 97:	0.02635542  	0.19424751  	0.10569561  
2023-05-18 10:26:40.657: Find a better model.
2023-05-18 10:26:49.065: [iter 98 : loss : 0.1315 = 0.0409 + 0.0853 + 0.0052, time: 8.406954]
2023-05-18 10:26:49.225: epoch 98:	0.02633425  	0.19409606  	0.10579319  
2023-05-18 10:26:57.098: [iter 99 : loss : 0.1305 = 0.0400 + 0.0853 + 0.0053, time: 7.871179]
2023-05-18 10:26:57.260: epoch 99:	0.02639775  	0.19447690  	0.10591602  
2023-05-18 10:26:57.260: Find a better model.
2023-05-18 10:27:05.977: [iter 100 : loss : 0.1295 = 0.0391 + 0.0851 + 0.0053, time: 8.715285]
2023-05-18 10:27:06.142: epoch 100:	0.02641892  	0.19438155  	0.10586111  
2023-05-18 10:27:15.578: [iter 101 : loss : 0.1292 = 0.0388 + 0.0851 + 0.0053, time: 9.425061]
2023-05-18 10:27:15.868: epoch 101:	0.02641186  	0.19438703  	0.10596943  
2023-05-18 10:27:24.369: [iter 102 : loss : 0.1282 = 0.0378 + 0.0850 + 0.0054, time: 8.499613]
2023-05-18 10:27:24.561: epoch 102:	0.02650360  	0.19495867  	0.10618673  
2023-05-18 10:27:24.561: Find a better model.
2023-05-18 10:27:33.331: [iter 103 : loss : 0.1280 = 0.0376 + 0.0850 + 0.0054, time: 8.768007]
2023-05-18 10:27:33.502: epoch 103:	0.02650360  	0.19493943  	0.10623312  
2023-05-18 10:27:41.932: [iter 104 : loss : 0.1283 = 0.0380 + 0.0849 + 0.0054, time: 8.429001]
2023-05-18 10:27:42.093: epoch 104:	0.02655300  	0.19538751  	0.10651448  
2023-05-18 10:27:42.093: Find a better model.
2023-05-18 10:27:50.073: [iter 105 : loss : 0.1277 = 0.0374 + 0.0848 + 0.0055, time: 7.978999]
2023-05-18 10:27:50.242: epoch 105:	0.02651772  	0.19521667  	0.10643647  
2023-05-18 10:27:59.667: [iter 106 : loss : 0.1269 = 0.0367 + 0.0847 + 0.0055, time: 9.420835]
2023-05-18 10:27:59.971: epoch 106:	0.02658122  	0.19564506  	0.10667037  
2023-05-18 10:27:59.971: Find a better model.
2023-05-18 10:28:07.823: [iter 107 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 7.849003]
2023-05-18 10:28:07.981: epoch 107:	0.02653183  	0.19503374  	0.10647836  
2023-05-18 10:28:16.102: [iter 108 : loss : 0.1259 = 0.0357 + 0.0846 + 0.0056, time: 8.119029]
2023-05-18 10:28:16.258: epoch 108:	0.02653182  	0.19504260  	0.10655231  
2023-05-18 10:28:24.851: [iter 109 : loss : 0.1248 = 0.0347 + 0.0845 + 0.0056, time: 8.592007]
2023-05-18 10:28:25.103: epoch 109:	0.02656006  	0.19518572  	0.10656297  
2023-05-18 10:28:34.485: [iter 110 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 9.379037]
2023-05-18 10:28:34.795: epoch 110:	0.02656005  	0.19511384  	0.10650401  
2023-05-18 10:28:44.193: [iter 111 : loss : 0.1242 = 0.0340 + 0.0844 + 0.0057, time: 9.392018]
2023-05-18 10:28:44.490: epoch 111:	0.02658122  	0.19515802  	0.10665684  
2023-05-18 10:28:52.843: [iter 112 : loss : 0.1241 = 0.0340 + 0.0844 + 0.0057, time: 8.352063]
2023-05-18 10:28:53.073: epoch 112:	0.02656005  	0.19499141  	0.10655681  
2023-05-18 10:29:00.882: [iter 113 : loss : 0.1239 = 0.0338 + 0.0843 + 0.0057, time: 7.806847]
2023-05-18 10:29:01.044: epoch 113:	0.02656005  	0.19470543  	0.10642538  
2023-05-18 10:29:09.746: [iter 114 : loss : 0.1227 = 0.0326 + 0.0843 + 0.0058, time: 8.700388]
2023-05-18 10:29:09.922: epoch 114:	0.02659534  	0.19483316  	0.10677465  
2023-05-18 10:29:19.345: [iter 115 : loss : 0.1225 = 0.0325 + 0.0842 + 0.0058, time: 9.421389]
2023-05-18 10:29:19.649: epoch 115:	0.02659534  	0.19499925  	0.10680404  
2023-05-18 10:29:28.466: [iter 116 : loss : 0.1216 = 0.0316 + 0.0842 + 0.0058, time: 8.816010]
2023-05-18 10:29:28.630: epoch 116:	0.02663062  	0.19533812  	0.10689151  
2023-05-18 10:29:37.497: [iter 117 : loss : 0.1216 = 0.0316 + 0.0841 + 0.0059, time: 8.866048]
2023-05-18 10:29:37.658: epoch 117:	0.02657417  	0.19493189  	0.10684613  
2023-05-18 10:29:46.330: [iter 118 : loss : 0.1216 = 0.0317 + 0.0840 + 0.0059, time: 8.671026]
2023-05-18 10:29:46.549: epoch 118:	0.02667296  	0.19602835  	0.10717041  
2023-05-18 10:29:46.549: Find a better model.
2023-05-18 10:29:54.432: [iter 119 : loss : 0.1204 = 0.0305 + 0.0840 + 0.0059, time: 7.879091]
2023-05-18 10:29:54.590: epoch 119:	0.02665179  	0.19565076  	0.10720200  
2023-05-18 10:30:03.979: [iter 120 : loss : 0.1206 = 0.0307 + 0.0839 + 0.0060, time: 9.387110]
2023-05-18 10:30:04.290: epoch 120:	0.02663062  	0.19545348  	0.10721030  
2023-05-18 10:30:11.897: [iter 121 : loss : 0.1207 = 0.0308 + 0.0839 + 0.0060, time: 7.605973]
2023-05-18 10:30:12.053: epoch 121:	0.02663768  	0.19559513  	0.10738638  
2023-05-18 10:30:20.029: [iter 122 : loss : 0.1198 = 0.0299 + 0.0838 + 0.0060, time: 7.975150]
2023-05-18 10:30:20.186: epoch 122:	0.02656006  	0.19495788  	0.10716145  
2023-05-18 10:30:28.659: [iter 123 : loss : 0.1196 = 0.0298 + 0.0838 + 0.0061, time: 8.471002]
2023-05-18 10:30:28.817: epoch 123:	0.02656711  	0.19508976  	0.10707475  
2023-05-18 10:30:36.628: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 7.810044]
2023-05-18 10:30:36.803: epoch 124:	0.02653183  	0.19464265  	0.10703412  
2023-05-18 10:30:46.105: [iter 125 : loss : 0.1180 = 0.0281 + 0.0837 + 0.0061, time: 9.300013]
2023-05-18 10:30:46.404: epoch 125:	0.02658828  	0.19513191  	0.10732924  
2023-05-18 10:30:54.439: [iter 126 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0062, time: 8.033002]
2023-05-18 10:30:54.680: epoch 126:	0.02657417  	0.19506986  	0.10734604  
2023-05-18 10:31:02.604: [iter 127 : loss : 0.1173 = 0.0275 + 0.0836 + 0.0062, time: 7.922351]
2023-05-18 10:31:02.781: epoch 127:	0.02666590  	0.19593953  	0.10766816  
2023-05-18 10:31:11.555: [iter 128 : loss : 0.1184 = 0.0286 + 0.0835 + 0.0062, time: 8.771002]
2023-05-18 10:31:11.707: epoch 128:	0.02667296  	0.19573882  	0.10764416  
2023-05-18 10:31:20.984: [iter 129 : loss : 0.1175 = 0.0277 + 0.0835 + 0.0063, time: 9.268871]
2023-05-18 10:31:21.274: epoch 129:	0.02662356  	0.19542295  	0.10765886  
2023-05-18 10:31:30.544: [iter 130 : loss : 0.1176 = 0.0279 + 0.0835 + 0.0063, time: 9.266043]
2023-05-18 10:31:30.843: epoch 130:	0.02668707  	0.19555900  	0.10772687  
2023-05-18 10:31:39.048: [iter 131 : loss : 0.1167 = 0.0270 + 0.0834 + 0.0063, time: 8.203135]
2023-05-18 10:31:39.214: epoch 131:	0.02670824  	0.19556712  	0.10775039  
2023-05-18 10:31:47.206: [iter 132 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.991004]
2023-05-18 10:31:47.367: epoch 132:	0.02676469  	0.19602349  	0.10791577  
2023-05-18 10:31:55.860: [iter 133 : loss : 0.1158 = 0.0261 + 0.0833 + 0.0064, time: 8.491231]
2023-05-18 10:31:56.018: epoch 133:	0.02673646  	0.19593512  	0.10795136  
2023-05-18 10:32:05.239: [iter 134 : loss : 0.1164 = 0.0266 + 0.0833 + 0.0064, time: 9.217354]
2023-05-18 10:32:05.533: epoch 134:	0.02679292  	0.19625939  	0.10833116  
2023-05-18 10:32:05.533: Find a better model.
2023-05-18 10:32:13.919: [iter 135 : loss : 0.1159 = 0.0263 + 0.0832 + 0.0064, time: 8.384257]
2023-05-18 10:32:14.088: epoch 135:	0.02675057  	0.19597231  	0.10832132  
2023-05-18 10:32:22.638: [iter 136 : loss : 0.1156 = 0.0259 + 0.0832 + 0.0065, time: 8.548004]
2023-05-18 10:32:22.807: epoch 136:	0.02675057  	0.19600035  	0.10850197  
2023-05-18 10:32:31.541: [iter 137 : loss : 0.1151 = 0.0255 + 0.0831 + 0.0065, time: 8.732004]
2023-05-18 10:32:31.688: epoch 137:	0.02676469  	0.19603510  	0.10860997  
2023-05-18 10:32:39.608: [iter 138 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 7.919300]
2023-05-18 10:32:39.768: epoch 138:	0.02674351  	0.19580030  	0.10859300  
2023-05-18 10:32:49.170: [iter 139 : loss : 0.1145 = 0.0248 + 0.0831 + 0.0065, time: 9.401012]
2023-05-18 10:32:49.474: epoch 139:	0.02680703  	0.19637185  	0.10873904  
2023-05-18 10:32:49.474: Find a better model.
2023-05-18 10:32:57.176: [iter 140 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0066, time: 7.696055]
2023-05-18 10:32:57.336: epoch 140:	0.02678585  	0.19638507  	0.10875119  
2023-05-18 10:32:57.336: Find a better model.
2023-05-18 10:33:05.558: [iter 141 : loss : 0.1147 = 0.0251 + 0.0830 + 0.0066, time: 8.220791]
2023-05-18 10:33:05.715: epoch 141:	0.02677879  	0.19627017  	0.10877391  
2023-05-18 10:33:14.168: [iter 142 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 8.450497]
2023-05-18 10:33:14.326: epoch 142:	0.02675057  	0.19631101  	0.10887516  
2023-05-18 10:33:22.243: [iter 143 : loss : 0.1139 = 0.0243 + 0.0829 + 0.0067, time: 7.914173]
2023-05-18 10:33:22.500: epoch 143:	0.02672235  	0.19570220  	0.10880271  
2023-05-18 10:33:32.006: [iter 144 : loss : 0.1132 = 0.0236 + 0.0828 + 0.0067, time: 9.505021]
2023-05-18 10:33:32.264: epoch 144:	0.02676469  	0.19646738  	0.10909714  
2023-05-18 10:33:32.264: Find a better model.
2023-05-18 10:33:40.534: [iter 145 : loss : 0.1132 = 0.0236 + 0.0829 + 0.0067, time: 8.269005]
2023-05-18 10:33:40.680: epoch 145:	0.02673646  	0.19636923  	0.10906976  
2023-05-18 10:33:48.577: [iter 146 : loss : 0.1134 = 0.0238 + 0.0828 + 0.0067, time: 7.896533]
2023-05-18 10:33:48.738: epoch 146:	0.02678586  	0.19671325  	0.10902425  
2023-05-18 10:33:48.738: Find a better model.
2023-05-18 10:33:57.299: [iter 147 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0068, time: 8.560063]
2023-05-18 10:33:57.501: epoch 147:	0.02677881  	0.19678250  	0.10899682  
2023-05-18 10:33:57.501: Find a better model.
2023-05-18 10:34:06.724: [iter 148 : loss : 0.1120 = 0.0224 + 0.0827 + 0.0068, time: 9.218023]
2023-05-18 10:34:07.021: epoch 148:	0.02675763  	0.19652013  	0.10898519  
2023-05-18 10:34:16.304: [iter 149 : loss : 0.1122 = 0.0227 + 0.0827 + 0.0068, time: 9.277025]
2023-05-18 10:34:16.592: epoch 149:	0.02675057  	0.19628295  	0.10895554  
2023-05-18 10:34:24.986: [iter 150 : loss : 0.1117 = 0.0222 + 0.0827 + 0.0068, time: 8.392453]
2023-05-18 10:34:25.138: epoch 150:	0.02675763  	0.19622958  	0.10903005  
2023-05-18 10:34:32.943: [iter 151 : loss : 0.1119 = 0.0223 + 0.0826 + 0.0069, time: 7.804682]
2023-05-18 10:34:33.104: epoch 151:	0.02677879  	0.19611818  	0.10899200  
2023-05-18 10:34:41.628: [iter 152 : loss : 0.1112 = 0.0217 + 0.0826 + 0.0069, time: 8.521550]
2023-05-18 10:34:41.782: epoch 152:	0.02682113  	0.19624624  	0.10883484  
2023-05-18 10:34:50.900: [iter 153 : loss : 0.1105 = 0.0210 + 0.0826 + 0.0069, time: 9.112044]
2023-05-18 10:34:51.189: epoch 153:	0.02682819  	0.19645938  	0.10904288  
2023-05-18 10:34:59.868: [iter 154 : loss : 0.1109 = 0.0214 + 0.0826 + 0.0070, time: 8.677375]
2023-05-18 10:35:00.047: epoch 154:	0.02685642  	0.19641452  	0.10920840  
2023-05-18 10:35:08.373: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 8.324543]
2023-05-18 10:35:08.595: epoch 155:	0.02684230  	0.19632457  	0.10926461  
2023-05-18 10:35:16.833: [iter 156 : loss : 0.1108 = 0.0214 + 0.0825 + 0.0070, time: 8.236004]
2023-05-18 10:35:17.299: epoch 156:	0.02689875  	0.19685790  	0.10942923  
2023-05-18 10:35:17.299: Find a better model.
2023-05-18 10:35:25.127: [iter 157 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 7.825964]
2023-05-18 10:35:25.285: epoch 157:	0.02687053  	0.19688086  	0.10943237  
2023-05-18 10:35:25.285: Find a better model.
2023-05-18 10:35:34.491: [iter 158 : loss : 0.1099 = 0.0204 + 0.0824 + 0.0071, time: 9.204002]
2023-05-18 10:35:34.793: epoch 158:	0.02681408  	0.19646050  	0.10927820  
2023-05-18 10:35:42.423: [iter 159 : loss : 0.1105 = 0.0210 + 0.0824 + 0.0071, time: 7.629004]
2023-05-18 10:35:42.587: epoch 159:	0.02682114  	0.19636054  	0.10941651  
2023-05-18 10:35:50.903: [iter 160 : loss : 0.1101 = 0.0206 + 0.0824 + 0.0071, time: 8.315009]
2023-05-18 10:35:51.060: epoch 160:	0.02677880  	0.19611900  	0.10939812  
2023-05-18 10:35:59.681: [iter 161 : loss : 0.1093 = 0.0198 + 0.0823 + 0.0071, time: 8.620006]
2023-05-18 10:35:59.839: epoch 161:	0.02681408  	0.19628641  	0.10944486  
2023-05-18 10:36:07.519: [iter 162 : loss : 0.1089 = 0.0194 + 0.0823 + 0.0072, time: 7.678249]
2023-05-18 10:36:07.670: epoch 162:	0.02678586  	0.19614956  	0.10945491  
2023-05-18 10:36:16.912: [iter 163 : loss : 0.1090 = 0.0196 + 0.0823 + 0.0072, time: 9.232506]
2023-05-18 10:36:17.208: epoch 163:	0.02669412  	0.19563754  	0.10933790  
2023-05-18 10:36:25.047: [iter 164 : loss : 0.1090 = 0.0196 + 0.0822 + 0.0072, time: 7.838386]
2023-05-18 10:36:25.205: epoch 164:	0.02666589  	0.19544862  	0.10916655  
2023-05-18 10:36:33.302: [iter 165 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 8.095811]
2023-05-18 10:36:33.462: epoch 165:	0.02659533  	0.19481613  	0.10907618  
2023-05-18 10:36:42.088: [iter 166 : loss : 0.1086 = 0.0192 + 0.0822 + 0.0073, time: 8.625002]
2023-05-18 10:36:42.344: epoch 166:	0.02659533  	0.19502848  	0.10905982  
2023-05-18 10:36:51.689: [iter 167 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0073, time: 9.342025]
2023-05-18 10:36:51.960: epoch 167:	0.02656005  	0.19469385  	0.10879677  
2023-05-18 10:37:01.279: [iter 168 : loss : 0.1082 = 0.0188 + 0.0821 + 0.0073, time: 9.318445]
2023-05-18 10:37:01.542: epoch 168:	0.02659533  	0.19478127  	0.10895889  
2023-05-18 10:37:09.855: [iter 169 : loss : 0.1085 = 0.0191 + 0.0821 + 0.0073, time: 8.311506]
2023-05-18 10:37:10.013: epoch 169:	0.02660239  	0.19474223  	0.10903362  
2023-05-18 10:37:17.686: [iter 170 : loss : 0.1077 = 0.0183 + 0.0821 + 0.0073, time: 7.670058]
2023-05-18 10:37:17.852: epoch 170:	0.02663060  	0.19496416  	0.10900764  
2023-05-18 10:37:26.517: [iter 171 : loss : 0.1084 = 0.0189 + 0.0821 + 0.0074, time: 8.664026]
2023-05-18 10:37:26.685: epoch 171:	0.02661650  	0.19477272  	0.10901403  
2023-05-18 10:37:35.954: [iter 172 : loss : 0.1076 = 0.0181 + 0.0821 + 0.0074, time: 9.266002]
2023-05-18 10:37:36.224: epoch 172:	0.02660944  	0.19472376  	0.10888471  
2023-05-18 10:37:45.464: [iter 173 : loss : 0.1079 = 0.0185 + 0.0820 + 0.0074, time: 9.237081]
2023-05-18 10:37:45.762: epoch 173:	0.02663061  	0.19489658  	0.10908640  
2023-05-18 10:37:53.436: [iter 174 : loss : 0.1075 = 0.0181 + 0.0820 + 0.0074, time: 7.671979]
2023-05-18 10:37:53.593: epoch 174:	0.02657416  	0.19448005  	0.10888565  
2023-05-18 10:38:01.287: [iter 175 : loss : 0.1072 = 0.0177 + 0.0820 + 0.0075, time: 7.691541]
2023-05-18 10:38:01.442: epoch 175:	0.02659533  	0.19466376  	0.10897192  
2023-05-18 10:38:08.838: [iter 176 : loss : 0.1066 = 0.0172 + 0.0820 + 0.0075, time: 7.395473]
2023-05-18 10:38:08.994: epoch 176:	0.02657416  	0.19420893  	0.10896610  
2023-05-18 10:38:16.438: [iter 177 : loss : 0.1072 = 0.0177 + 0.0820 + 0.0075, time: 7.442800]
2023-05-18 10:38:16.594: epoch 177:	0.02658827  	0.19446853  	0.10896263  
2023-05-18 10:38:24.009: [iter 178 : loss : 0.1067 = 0.0173 + 0.0819 + 0.0075, time: 7.413513]
2023-05-18 10:38:24.166: epoch 178:	0.02653887  	0.19397651  	0.10878475  
2023-05-18 10:38:31.654: [iter 179 : loss : 0.1066 = 0.0171 + 0.0819 + 0.0076, time: 7.486724]
2023-05-18 10:38:31.811: epoch 179:	0.02653887  	0.19389951  	0.10873987  
2023-05-18 10:38:39.225: [iter 180 : loss : 0.1067 = 0.0173 + 0.0819 + 0.0076, time: 7.412574]
2023-05-18 10:38:39.382: epoch 180:	0.02656004  	0.19379088  	0.10873790  
2023-05-18 10:38:46.809: [iter 181 : loss : 0.1068 = 0.0174 + 0.0818 + 0.0076, time: 7.425615]
2023-05-18 10:38:46.966: epoch 181:	0.02654593  	0.19396803  	0.10879869  
2023-05-18 10:38:54.429: [iter 182 : loss : 0.1064 = 0.0170 + 0.0818 + 0.0076, time: 7.461308]
2023-05-18 10:38:54.586: epoch 182:	0.02655298  	0.19385031  	0.10861946  
2023-05-18 10:38:54.586: Early stopping is trigger at epoch: 182
2023-05-18 10:38:54.586: best_result@epoch 157:

2023-05-18 10:38:54.586: 		0.0269      	0.1969      	0.1094      
2023-05-18 10:47:46.926: my pid: 13596
2023-05-18 10:47:46.926: model: model.general_recommender.SGL
2023-05-18 10:47:46.926: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 10:47:46.926: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 10:47:50.263: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 10:47:59.092: [iter 1 : loss : 0.7716 = 0.6930 + 0.0786 + 0.0000, time: 8.828818]
2023-05-18 10:47:59.239: epoch 1:	0.00141829  	0.00955181  	0.00454986  
2023-05-18 10:47:59.239: Find a better model.
2023-05-18 10:48:07.961: [iter 2 : loss : 0.7712 = 0.6929 + 0.0784 + 0.0000, time: 8.719628]
2023-05-18 10:48:08.148: epoch 2:	0.00242733  	0.01764668  	0.00846975  
2023-05-18 10:48:08.149: Find a better model.
2023-05-18 10:48:17.040: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.889540]
2023-05-18 10:48:17.234: epoch 3:	0.00400083  	0.03002799  	0.01448964  
2023-05-18 10:48:17.234: Find a better model.
2023-05-18 10:48:26.266: [iter 4 : loss : 0.7707 = 0.6922 + 0.0785 + 0.0000, time: 9.029991]
2023-05-18 10:48:26.437: epoch 4:	0.00678093  	0.05003917  	0.02350559  
2023-05-18 10:48:26.437: Find a better model.
2023-05-18 10:48:35.447: [iter 5 : loss : 0.7700 = 0.6913 + 0.0787 + 0.0000, time: 9.009001]
2023-05-18 10:48:35.609: epoch 5:	0.01034432  	0.07439739  	0.03519470  
2023-05-18 10:48:35.609: Find a better model.
2023-05-18 10:48:45.617: [iter 6 : loss : 0.7684 = 0.6894 + 0.0790 + 0.0000, time: 10.007659]
2023-05-18 10:48:45.873: epoch 6:	0.01392900  	0.09868432  	0.04772816  
2023-05-18 10:48:45.873: Find a better model.
2023-05-18 10:48:55.649: [iter 7 : loss : 0.7641 = 0.6845 + 0.0796 + 0.0000, time: 9.773328]
2023-05-18 10:48:55.942: epoch 7:	0.01667393  	0.11965305  	0.05824601  
2023-05-18 10:48:55.942: Find a better model.
2023-05-18 10:49:04.680: [iter 8 : loss : 0.7533 = 0.6723 + 0.0809 + 0.0001, time: 8.737621]
2023-05-18 10:49:04.870: epoch 8:	0.01798642  	0.13056687  	0.06504581  
2023-05-18 10:49:04.870: Find a better model.
2023-05-18 10:49:13.058: [iter 9 : loss : 0.7272 = 0.6432 + 0.0839 + 0.0001, time: 8.184992]
2023-05-18 10:49:13.218: epoch 9:	0.01851565  	0.13473767  	0.06813452  
2023-05-18 10:49:13.219: Find a better model.
2023-05-18 10:49:21.622: [iter 10 : loss : 0.6765 = 0.5874 + 0.0890 + 0.0002, time: 8.402107]
2023-05-18 10:49:21.782: epoch 10:	0.01836747  	0.13506645  	0.06790643  
2023-05-18 10:49:21.783: Find a better model.
2023-05-18 10:49:31.182: [iter 11 : loss : 0.6035 = 0.5088 + 0.0944 + 0.0003, time: 9.396991]
2023-05-18 10:49:31.470: epoch 11:	0.01831103  	0.13541071  	0.06734817  
2023-05-18 10:49:31.470: Find a better model.
2023-05-18 10:49:39.198: [iter 12 : loss : 0.5290 = 0.4301 + 0.0985 + 0.0005, time: 7.725993]
2023-05-18 10:49:39.359: epoch 12:	0.01833219  	0.13553962  	0.06785900  
2023-05-18 10:49:39.359: Find a better model.
2023-05-18 10:49:48.013: [iter 13 : loss : 0.4715 = 0.3699 + 0.1010 + 0.0007, time: 8.652636]
2023-05-18 10:49:48.169: epoch 13:	0.01827574  	0.13538946  	0.06815986  
2023-05-18 10:49:56.608: [iter 14 : loss : 0.4279 = 0.3249 + 0.1022 + 0.0008, time: 8.437992]
2023-05-18 10:49:56.770: epoch 14:	0.01852977  	0.13766748  	0.06913114  
2023-05-18 10:49:56.777: Find a better model.
2023-05-18 10:50:04.630: [iter 15 : loss : 0.3978 = 0.2941 + 0.1027 + 0.0009, time: 7.850993]
2023-05-18 10:50:04.877: epoch 15:	0.01877676  	0.13953909  	0.07013415  
2023-05-18 10:50:04.878: Find a better model.
2023-05-18 10:50:14.380: [iter 16 : loss : 0.3734 = 0.2695 + 0.1028 + 0.0011, time: 9.500995]
2023-05-18 10:50:14.666: epoch 16:	0.01898140  	0.14074482  	0.07085612  
2023-05-18 10:50:14.666: Find a better model.
2023-05-18 10:50:23.238: [iter 17 : loss : 0.3554 = 0.2516 + 0.1027 + 0.0012, time: 8.569677]
2023-05-18 10:50:23.385: epoch 17:	0.01917192  	0.14180250  	0.07161401  
2023-05-18 10:50:23.385: Find a better model.
2023-05-18 10:50:31.429: [iter 18 : loss : 0.3393 = 0.2355 + 0.1024 + 0.0013, time: 8.042001]
2023-05-18 10:50:31.589: epoch 18:	0.01937656  	0.14314523  	0.07237860  
2023-05-18 10:50:31.589: Find a better model.
2023-05-18 10:50:40.267: [iter 19 : loss : 0.3244 = 0.2209 + 0.1022 + 0.0014, time: 8.676923]
2023-05-18 10:50:40.424: epoch 19:	0.01965882  	0.14529985  	0.07351997  
2023-05-18 10:50:40.424: Find a better model.
2023-05-18 10:50:49.785: [iter 20 : loss : 0.3145 = 0.2113 + 0.1018 + 0.0015, time: 9.359486]
2023-05-18 10:50:50.082: epoch 20:	0.01978584  	0.14621617  	0.07409568  
2023-05-18 10:50:50.082: Find a better model.
2023-05-18 10:50:59.579: [iter 21 : loss : 0.3042 = 0.2013 + 0.1014 + 0.0016, time: 9.495198]
2023-05-18 10:50:59.798: epoch 21:	0.01994109  	0.14718892  	0.07462490  
2023-05-18 10:50:59.799: Find a better model.
2023-05-18 10:51:08.400: [iter 22 : loss : 0.2958 = 0.1932 + 0.1010 + 0.0016, time: 8.599992]
2023-05-18 10:51:08.569: epoch 22:	0.02016690  	0.14873902  	0.07527428  
2023-05-18 10:51:08.569: Find a better model.
2023-05-18 10:51:17.344: [iter 23 : loss : 0.2870 = 0.1849 + 0.1004 + 0.0017, time: 8.772556]
2023-05-18 10:51:17.501: epoch 23:	0.02040682  	0.15082416  	0.07623569  
2023-05-18 10:51:17.501: Find a better model.
2023-05-18 10:51:25.587: [iter 24 : loss : 0.2806 = 0.1788 + 0.1000 + 0.0018, time: 8.084560]
2023-05-18 10:51:25.760: epoch 24:	0.02066086  	0.15265167  	0.07720756  
2023-05-18 10:51:25.760: Find a better model.
2023-05-18 10:51:35.211: [iter 25 : loss : 0.2738 = 0.1723 + 0.0996 + 0.0019, time: 9.446030]
2023-05-18 10:51:35.508: epoch 25:	0.02080904  	0.15354946  	0.07785951  
2023-05-18 10:51:35.508: Find a better model.
2023-05-18 10:51:43.496: [iter 26 : loss : 0.2699 = 0.1688 + 0.0991 + 0.0019, time: 7.987087]
2023-05-18 10:51:43.729: epoch 26:	0.02100662  	0.15477581  	0.07864403  
2023-05-18 10:51:43.729: Find a better model.
2023-05-18 10:51:51.787: [iter 27 : loss : 0.2621 = 0.1613 + 0.0987 + 0.0020, time: 8.054993]
2023-05-18 10:51:51.955: epoch 27:	0.02120421  	0.15607630  	0.07954019  
2023-05-18 10:51:51.955: Find a better model.
2023-05-18 10:52:00.719: [iter 28 : loss : 0.2570 = 0.1566 + 0.0983 + 0.0021, time: 8.762992]
2023-05-18 10:52:00.953: epoch 28:	0.02139473  	0.15762813  	0.08043338  
2023-05-18 10:52:00.953: Find a better model.
2023-05-18 10:52:10.217: [iter 29 : loss : 0.2522 = 0.1522 + 0.0979 + 0.0021, time: 9.261735]
2023-05-18 10:52:10.522: epoch 29:	0.02154292  	0.15854026  	0.08082888  
2023-05-18 10:52:10.522: Find a better model.
2023-05-18 10:52:19.856: [iter 30 : loss : 0.2458 = 0.1460 + 0.0976 + 0.0022, time: 9.332007]
2023-05-18 10:52:20.141: epoch 30:	0.02169111  	0.15963854  	0.08140697  
2023-05-18 10:52:20.141: Find a better model.
2023-05-18 10:52:28.413: [iter 31 : loss : 0.2423 = 0.1429 + 0.0971 + 0.0023, time: 8.271059]
2023-05-18 10:52:28.572: epoch 31:	0.02193102  	0.16154782  	0.08239657  
2023-05-18 10:52:28.572: Find a better model.
2023-05-18 10:52:36.934: [iter 32 : loss : 0.2364 = 0.1373 + 0.0968 + 0.0023, time: 8.359880]
2023-05-18 10:52:37.092: epoch 32:	0.02201570  	0.16217826  	0.08301869  
2023-05-18 10:52:37.092: Find a better model.
2023-05-18 10:52:45.372: [iter 33 : loss : 0.2341 = 0.1353 + 0.0963 + 0.0024, time: 8.278800]
2023-05-18 10:52:45.529: epoch 33:	0.02208627  	0.16244489  	0.08331025  
2023-05-18 10:52:45.529: Find a better model.
2023-05-18 10:52:54.836: [iter 34 : loss : 0.2299 = 0.1315 + 0.0960 + 0.0024, time: 9.298056]
2023-05-18 10:52:55.124: epoch 34:	0.02210743  	0.16290064  	0.08392078  
2023-05-18 10:52:55.124: Find a better model.
2023-05-18 10:53:02.812: [iter 35 : loss : 0.2264 = 0.1282 + 0.0957 + 0.0025, time: 7.685022]
2023-05-18 10:53:02.970: epoch 35:	0.02225562  	0.16427471  	0.08458489  
2023-05-18 10:53:02.971: Find a better model.
2023-05-18 10:53:11.446: [iter 36 : loss : 0.2227 = 0.1248 + 0.0954 + 0.0025, time: 8.473033]
2023-05-18 10:53:11.601: epoch 36:	0.02236852  	0.16459483  	0.08530067  
2023-05-18 10:53:11.601: Find a better model.
2023-05-18 10:53:20.349: [iter 37 : loss : 0.2187 = 0.1211 + 0.0950 + 0.0026, time: 8.747013]
2023-05-18 10:53:20.499: epoch 37:	0.02257316  	0.16639136  	0.08609644  
2023-05-18 10:53:20.499: Find a better model.
2023-05-18 10:53:28.377: [iter 38 : loss : 0.2170 = 0.1197 + 0.0947 + 0.0027, time: 7.876034]
2023-05-18 10:53:28.535: epoch 38:	0.02267196  	0.16719270  	0.08646178  
2023-05-18 10:53:28.535: Find a better model.
2023-05-18 10:53:37.969: [iter 39 : loss : 0.2126 = 0.1155 + 0.0943 + 0.0027, time: 9.425034]
2023-05-18 10:53:38.259: epoch 39:	0.02279192  	0.16803452  	0.08723587  
2023-05-18 10:53:38.259: Find a better model.
2023-05-18 10:53:46.624: [iter 40 : loss : 0.2094 = 0.1126 + 0.0941 + 0.0028, time: 8.363324]
2023-05-18 10:53:47.004: epoch 40:	0.02292600  	0.16899933  	0.08789974  
2023-05-18 10:53:47.004: Find a better model.
2023-05-18 10:53:54.983: [iter 41 : loss : 0.2077 = 0.1111 + 0.0938 + 0.0028, time: 7.977007]
2023-05-18 10:53:55.144: epoch 41:	0.02301067  	0.16933626  	0.08834586  
2023-05-18 10:53:55.144: Find a better model.
2023-05-18 10:54:03.760: [iter 42 : loss : 0.2053 = 0.1089 + 0.0935 + 0.0029, time: 8.614009]
2023-05-18 10:54:03.970: epoch 42:	0.02322236  	0.17054676  	0.08900221  
2023-05-18 10:54:03.970: Find a better model.
2023-05-18 10:54:13.423: [iter 43 : loss : 0.2015 = 0.1053 + 0.0932 + 0.0029, time: 9.451037]
2023-05-18 10:54:13.689: epoch 43:	0.02329293  	0.17121905  	0.08947024  
2023-05-18 10:54:13.690: Find a better model.
2023-05-18 10:54:23.127: [iter 44 : loss : 0.1978 = 0.1019 + 0.0929 + 0.0030, time: 9.433993]
2023-05-18 10:54:23.395: epoch 44:	0.02338466  	0.17188622  	0.08995093  
2023-05-18 10:54:23.396: Find a better model.
2023-05-18 10:54:31.730: [iter 45 : loss : 0.1958 = 0.1000 + 0.0927 + 0.0030, time: 8.332003]
2023-05-18 10:54:31.930: epoch 45:	0.02349756  	0.17235917  	0.09051739  
2023-05-18 10:54:31.930: Find a better model.
2023-05-18 10:54:40.332: [iter 46 : loss : 0.1933 = 0.0978 + 0.0924 + 0.0031, time: 8.399326]
2023-05-18 10:54:40.561: epoch 46:	0.02354696  	0.17262533  	0.09104988  
2023-05-18 10:54:40.561: Find a better model.
2023-05-18 10:54:48.529: [iter 47 : loss : 0.1926 = 0.0973 + 0.0922 + 0.0031, time: 7.967030]
2023-05-18 10:54:48.683: epoch 47:	0.02358224  	0.17275831  	0.09133824  
2023-05-18 10:54:48.684: Find a better model.
2023-05-18 10:54:57.993: [iter 48 : loss : 0.1890 = 0.0938 + 0.0920 + 0.0032, time: 9.306015]
2023-05-18 10:54:58.276: epoch 48:	0.02380100  	0.17429923  	0.09181800  
2023-05-18 10:54:58.276: Find a better model.
2023-05-18 10:55:06.263: [iter 49 : loss : 0.1857 = 0.0907 + 0.0918 + 0.0032, time: 7.986014]
2023-05-18 10:55:06.422: epoch 49:	0.02390684  	0.17519923  	0.09237360  
2023-05-18 10:55:06.422: Find a better model.
2023-05-18 10:55:14.506: [iter 50 : loss : 0.1846 = 0.0898 + 0.0915 + 0.0033, time: 8.082737]
2023-05-18 10:55:14.664: epoch 50:	0.02399857  	0.17563568  	0.09288484  
2023-05-18 10:55:14.664: Find a better model.
2023-05-18 10:55:23.128: [iter 51 : loss : 0.1816 = 0.0870 + 0.0913 + 0.0033, time: 8.462992]
2023-05-18 10:55:23.285: epoch 51:	0.02394917  	0.17494279  	0.09285040  
2023-05-18 10:55:32.707: [iter 52 : loss : 0.1813 = 0.0869 + 0.0911 + 0.0034, time: 9.421508]
2023-05-18 10:55:32.990: epoch 52:	0.02409736  	0.17620707  	0.09361546  
2023-05-18 10:55:32.991: Find a better model.
2023-05-18 10:55:42.501: [iter 53 : loss : 0.1794 = 0.0852 + 0.0909 + 0.0034, time: 9.502502]
2023-05-18 10:55:42.798: epoch 53:	0.02418203  	0.17678484  	0.09410937  
2023-05-18 10:55:42.798: Find a better model.
2023-05-18 10:55:51.319: [iter 54 : loss : 0.1774 = 0.0832 + 0.0907 + 0.0035, time: 8.520029]
2023-05-18 10:55:51.481: epoch 54:	0.02428788  	0.17792158  	0.09476387  
2023-05-18 10:55:51.481: Find a better model.
2023-05-18 10:55:59.511: [iter 55 : loss : 0.1753 = 0.0814 + 0.0905 + 0.0035, time: 8.029023]
2023-05-18 10:55:59.673: epoch 55:	0.02431611  	0.17839748  	0.09497076  
2023-05-18 10:55:59.674: Find a better model.
2023-05-18 10:56:08.127: [iter 56 : loss : 0.1736 = 0.0797 + 0.0903 + 0.0035, time: 8.450967]
2023-05-18 10:56:08.284: epoch 56:	0.02439373  	0.17877392  	0.09512749  
2023-05-18 10:56:08.285: Find a better model.
2023-05-18 10:56:17.571: [iter 57 : loss : 0.1717 = 0.0780 + 0.0901 + 0.0036, time: 9.283003]
2023-05-18 10:56:17.866: epoch 57:	0.02440784  	0.17890212  	0.09539184  
2023-05-18 10:56:17.866: Find a better model.
2023-05-18 10:56:25.672: [iter 58 : loss : 0.1697 = 0.0761 + 0.0900 + 0.0036, time: 7.804036]
2023-05-18 10:56:25.858: epoch 58:	0.02452075  	0.17990659  	0.09593148  
2023-05-18 10:56:25.858: Find a better model.
2023-05-18 10:56:34.330: [iter 59 : loss : 0.1688 = 0.0754 + 0.0898 + 0.0037, time: 8.471010]
2023-05-18 10:56:34.488: epoch 59:	0.02457015  	0.18071994  	0.09618440  
2023-05-18 10:56:34.488: Find a better model.
2023-05-18 10:56:42.841: [iter 60 : loss : 0.1673 = 0.0740 + 0.0896 + 0.0037, time: 8.352003]
2023-05-18 10:56:42.987: epoch 60:	0.02461248  	0.18095294  	0.09657346  
2023-05-18 10:56:42.987: Find a better model.
2023-05-18 10:56:51.075: [iter 61 : loss : 0.1659 = 0.0727 + 0.0894 + 0.0038, time: 8.087757]
2023-05-18 10:56:51.234: epoch 61:	0.02465482  	0.18132672  	0.09694749  
2023-05-18 10:56:51.234: Find a better model.
2023-05-18 10:57:00.675: [iter 62 : loss : 0.1642 = 0.0711 + 0.0892 + 0.0038, time: 9.432039]
2023-05-18 10:57:00.962: epoch 62:	0.02466188  	0.18124339  	0.09713140  
2023-05-18 10:57:09.119: [iter 63 : loss : 0.1630 = 0.0701 + 0.0891 + 0.0039, time: 8.156024]
2023-05-18 10:57:09.341: epoch 63:	0.02473244  	0.18211265  	0.09759201  
2023-05-18 10:57:09.341: Find a better model.
2023-05-18 10:57:17.281: [iter 64 : loss : 0.1619 = 0.0691 + 0.0889 + 0.0039, time: 7.938014]
2023-05-18 10:57:17.447: epoch 64:	0.02478184  	0.18264586  	0.09816208  
2023-05-18 10:57:17.447: Find a better model.
2023-05-18 10:57:26.170: [iter 65 : loss : 0.1609 = 0.0682 + 0.0888 + 0.0040, time: 8.720587]
2023-05-18 10:57:26.336: epoch 65:	0.02483829  	0.18276662  	0.09827644  
2023-05-18 10:57:26.336: Find a better model.
2023-05-18 10:57:35.621: [iter 66 : loss : 0.1590 = 0.0664 + 0.0886 + 0.0040, time: 9.283018]
2023-05-18 10:57:35.908: epoch 66:	0.02486651  	0.18281235  	0.09863588  
2023-05-18 10:57:35.908: Find a better model.
2023-05-18 10:57:45.329: [iter 67 : loss : 0.1577 = 0.0652 + 0.0885 + 0.0040, time: 9.420169]
2023-05-18 10:57:45.627: epoch 67:	0.02489473  	0.18284200  	0.09880941  
2023-05-18 10:57:45.628: Find a better model.
2023-05-18 10:57:54.078: [iter 68 : loss : 0.1572 = 0.0648 + 0.0883 + 0.0041, time: 8.449001]
2023-05-18 10:57:54.237: epoch 68:	0.02488768  	0.18267448  	0.09888332  
2023-05-18 10:58:02.304: [iter 69 : loss : 0.1553 = 0.0629 + 0.0882 + 0.0041, time: 8.064972]
2023-05-18 10:58:02.542: epoch 69:	0.02495119  	0.18358037  	0.09930111  
2023-05-18 10:58:02.542: Find a better model.
2023-05-18 10:58:10.824: [iter 70 : loss : 0.1534 = 0.0612 + 0.0880 + 0.0042, time: 8.281061]
2023-05-18 10:58:10.978: epoch 70:	0.02500764  	0.18397298  	0.09945261  
2023-05-18 10:58:10.978: Find a better model.
2023-05-18 10:58:20.346: [iter 71 : loss : 0.1523 = 0.0601 + 0.0880 + 0.0042, time: 9.365032]
2023-05-18 10:58:20.627: epoch 71:	0.02503586  	0.18413045  	0.09976180  
2023-05-18 10:58:20.627: Find a better model.
2023-05-18 10:58:28.188: [iter 72 : loss : 0.1520 = 0.0599 + 0.0878 + 0.0042, time: 7.560097]
2023-05-18 10:58:28.348: epoch 72:	0.02502880  	0.18372066  	0.09997184  
2023-05-18 10:58:36.845: [iter 73 : loss : 0.1507 = 0.0587 + 0.0877 + 0.0043, time: 8.495021]
2023-05-18 10:58:36.989: epoch 73:	0.02510642  	0.18425281  	0.10018774  
2023-05-18 10:58:36.989: Find a better model.
2023-05-18 10:58:45.437: [iter 74 : loss : 0.1489 = 0.0570 + 0.0876 + 0.0043, time: 8.446040]
2023-05-18 10:58:45.590: epoch 74:	0.02521227  	0.18499132  	0.10064732  
2023-05-18 10:58:45.590: Find a better model.
2023-05-18 10:58:53.440: [iter 75 : loss : 0.1484 = 0.0566 + 0.0875 + 0.0044, time: 7.849004]
2023-05-18 10:58:53.598: epoch 75:	0.02526167  	0.18562569  	0.10094981  
2023-05-18 10:58:53.598: Find a better model.
2023-05-18 10:59:02.888: [iter 76 : loss : 0.1475 = 0.0558 + 0.0873 + 0.0044, time: 9.286469]
2023-05-18 10:59:03.190: epoch 76:	0.02540280  	0.18688810  	0.10130303  
2023-05-18 10:59:03.190: Find a better model.
2023-05-18 10:59:11.335: [iter 77 : loss : 0.1465 = 0.0548 + 0.0872 + 0.0045, time: 8.141992]
2023-05-18 10:59:11.559: epoch 77:	0.02543103  	0.18681107  	0.10142722  
2023-05-18 10:59:19.446: [iter 78 : loss : 0.1456 = 0.0540 + 0.0871 + 0.0045, time: 7.881022]
2023-05-18 10:59:19.612: epoch 78:	0.02550865  	0.18722838  	0.10200905  
2023-05-18 10:59:19.612: Find a better model.
2023-05-18 10:59:28.224: [iter 79 : loss : 0.1442 = 0.0527 + 0.0870 + 0.0045, time: 8.611031]
2023-05-18 10:59:28.391: epoch 79:	0.02550159  	0.18732801  	0.10208259  
2023-05-18 10:59:28.391: Find a better model.
2023-05-18 10:59:37.767: [iter 80 : loss : 0.1436 = 0.0522 + 0.0869 + 0.0046, time: 9.371199]
2023-05-18 10:59:38.054: epoch 80:	0.02550865  	0.18763827  	0.10221685  
2023-05-18 10:59:38.054: Find a better model.
2023-05-18 10:59:47.518: [iter 81 : loss : 0.1433 = 0.0519 + 0.0868 + 0.0046, time: 9.461163]
2023-05-18 10:59:47.813: epoch 81:	0.02557215  	0.18801695  	0.10246529  
2023-05-18 10:59:47.813: Find a better model.
2023-05-18 10:59:56.222: [iter 82 : loss : 0.1421 = 0.0508 + 0.0867 + 0.0046, time: 8.408014]
2023-05-18 10:59:56.379: epoch 82:	0.02561450  	0.18843374  	0.10259132  
2023-05-18 10:59:56.379: Find a better model.
2023-05-18 11:00:04.433: [iter 83 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.053016]
2023-05-18 11:00:04.671: epoch 83:	0.02565683  	0.18868494  	0.10270179  
2023-05-18 11:00:04.671: Find a better model.
2023-05-18 11:00:12.801: [iter 84 : loss : 0.1410 = 0.0498 + 0.0865 + 0.0047, time: 8.128008]
2023-05-18 11:00:12.957: epoch 84:	0.02572740  	0.18949671  	0.10307221  
2023-05-18 11:00:12.957: Find a better model.
2023-05-18 11:00:22.436: [iter 85 : loss : 0.1400 = 0.0489 + 0.0864 + 0.0048, time: 9.476032]
2023-05-18 11:00:22.737: epoch 85:	0.02580502  	0.18998857  	0.10322747  
2023-05-18 11:00:22.737: Find a better model.
2023-05-18 11:00:30.315: [iter 86 : loss : 0.1398 = 0.0488 + 0.0862 + 0.0048, time: 7.576015]
2023-05-18 11:00:30.477: epoch 86:	0.02579091  	0.19021289  	0.10337908  
2023-05-18 11:00:30.477: Find a better model.
2023-05-18 11:00:38.999: [iter 87 : loss : 0.1370 = 0.0460 + 0.0862 + 0.0048, time: 8.520038]
2023-05-18 11:00:39.157: epoch 87:	0.02588971  	0.19044733  	0.10355346  
2023-05-18 11:00:39.157: Find a better model.
2023-05-18 11:00:47.627: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 8.468346]
2023-05-18 11:00:47.787: epoch 88:	0.02591087  	0.19089313  	0.10372013  
2023-05-18 11:00:47.787: Find a better model.
2023-05-18 11:00:55.804: [iter 89 : loss : 0.1360 = 0.0451 + 0.0860 + 0.0049, time: 8.016483]
2023-05-18 11:00:55.950: epoch 89:	0.02595321  	0.19085313  	0.10375979  
2023-05-18 11:01:05.212: [iter 90 : loss : 0.1367 = 0.0458 + 0.0859 + 0.0050, time: 9.258002]
2023-05-18 11:01:05.507: epoch 90:	0.02599555  	0.19094548  	0.10396305  
2023-05-18 11:01:05.507: Find a better model.
2023-05-18 11:01:13.622: [iter 91 : loss : 0.1356 = 0.0448 + 0.0858 + 0.0050, time: 8.114367]
2023-05-18 11:01:13.899: epoch 91:	0.02597438  	0.19075674  	0.10400757  
2023-05-18 11:01:21.829: [iter 92 : loss : 0.1343 = 0.0436 + 0.0857 + 0.0050, time: 7.928020]
2023-05-18 11:01:21.992: epoch 92:	0.02591793  	0.19023426  	0.10392053  
2023-05-18 11:01:30.350: [iter 93 : loss : 0.1348 = 0.0441 + 0.0857 + 0.0051, time: 8.356005]
2023-05-18 11:01:30.513: epoch 93:	0.02594615  	0.19046471  	0.10399348  
2023-05-18 11:01:39.802: [iter 94 : loss : 0.1324 = 0.0418 + 0.0856 + 0.0051, time: 9.282012]
2023-05-18 11:01:40.084: epoch 94:	0.02595321  	0.19031087  	0.10416760  
2023-05-18 11:01:49.520: [iter 95 : loss : 0.1321 = 0.0414 + 0.0855 + 0.0051, time: 9.434003]
2023-05-18 11:01:49.809: epoch 95:	0.02591087  	0.19015396  	0.10428122  
2023-05-18 11:01:58.035: [iter 96 : loss : 0.1320 = 0.0414 + 0.0854 + 0.0052, time: 8.223793]
2023-05-18 11:01:58.201: epoch 96:	0.02597438  	0.19074620  	0.10447095  
2023-05-18 11:02:06.224: [iter 97 : loss : 0.1303 = 0.0397 + 0.0853 + 0.0052, time: 8.021501]
2023-05-18 11:02:06.385: epoch 97:	0.02606611  	0.19145812  	0.10474699  
2023-05-18 11:02:06.385: Find a better model.
2023-05-18 11:02:14.803: [iter 98 : loss : 0.1312 = 0.0407 + 0.0853 + 0.0052, time: 8.417337]
2023-05-18 11:02:14.948: epoch 98:	0.02612256  	0.19164781  	0.10486495  
2023-05-18 11:02:14.948: Find a better model.
2023-05-18 11:02:24.152: [iter 99 : loss : 0.1301 = 0.0396 + 0.0852 + 0.0053, time: 9.201440]
2023-05-18 11:02:24.448: epoch 99:	0.02609434  	0.19177581  	0.10490976  
2023-05-18 11:02:24.448: Find a better model.
2023-05-18 11:02:32.205: [iter 100 : loss : 0.1293 = 0.0388 + 0.0851 + 0.0053, time: 7.756037]
2023-05-18 11:02:32.371: epoch 100:	0.02622135  	0.19243591  	0.10519310  
2023-05-18 11:02:32.371: Find a better model.
2023-05-18 11:02:40.845: [iter 101 : loss : 0.1291 = 0.0387 + 0.0850 + 0.0054, time: 8.472010]
2023-05-18 11:02:40.998: epoch 101:	0.02622841  	0.19275619  	0.10525883  
2023-05-18 11:02:40.998: Find a better model.
2023-05-18 11:02:49.534: [iter 102 : loss : 0.1278 = 0.0374 + 0.0850 + 0.0054, time: 8.535001]
2023-05-18 11:02:49.689: epoch 102:	0.02621429  	0.19261743  	0.10546159  
2023-05-18 11:02:57.553: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 7.862008]
2023-05-18 11:02:57.709: epoch 103:	0.02628485  	0.19315481  	0.10563271  
2023-05-18 11:02:57.709: Find a better model.
2023-05-18 11:03:06.941: [iter 104 : loss : 0.1283 = 0.0379 + 0.0848 + 0.0055, time: 9.228052]
2023-05-18 11:03:07.225: epoch 104:	0.02628486  	0.19323567  	0.10566095  
2023-05-18 11:03:07.225: Find a better model.
2023-05-18 11:03:15.046: [iter 105 : loss : 0.1273 = 0.0371 + 0.0847 + 0.0055, time: 7.820003]
2023-05-18 11:03:15.202: epoch 105:	0.02627780  	0.19303171  	0.10569739  
2023-05-18 11:03:23.163: [iter 106 : loss : 0.1267 = 0.0364 + 0.0847 + 0.0055, time: 7.960025]
2023-05-18 11:03:23.318: epoch 106:	0.02625663  	0.19311611  	0.10571035  
2023-05-18 11:03:31.737: [iter 107 : loss : 0.1258 = 0.0356 + 0.0846 + 0.0056, time: 8.418005]
2023-05-18 11:03:31.894: epoch 107:	0.02624252  	0.19308083  	0.10581300  
2023-05-18 11:03:41.216: [iter 108 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 9.317037]
2023-05-18 11:03:41.496: epoch 108:	0.02629897  	0.19338627  	0.10602824  
2023-05-18 11:03:41.496: Find a better model.
2023-05-18 11:03:50.830: [iter 109 : loss : 0.1244 = 0.0343 + 0.0845 + 0.0056, time: 9.333016]
2023-05-18 11:03:51.120: epoch 109:	0.02635542  	0.19359812  	0.10620745  
2023-05-18 11:03:51.120: Find a better model.
2023-05-18 11:03:59.383: [iter 110 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0057, time: 8.262476]
2023-05-18 11:03:59.539: epoch 110:	0.02633425  	0.19370741  	0.10608600  
2023-05-18 11:03:59.539: Find a better model.
2023-05-18 11:04:07.385: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 7.845002]
2023-05-18 11:04:07.545: epoch 111:	0.02636954  	0.19401042  	0.10620832  
2023-05-18 11:04:07.545: Find a better model.
2023-05-18 11:04:16.206: [iter 112 : loss : 0.1233 = 0.0333 + 0.0843 + 0.0057, time: 8.658010]
2023-05-18 11:04:16.364: epoch 112:	0.02636954  	0.19410540  	0.10623764  
2023-05-18 11:04:16.364: Find a better model.
2023-05-18 11:04:25.513: [iter 113 : loss : 0.1237 = 0.0336 + 0.0843 + 0.0058, time: 9.148133]
2023-05-18 11:04:25.789: epoch 113:	0.02648244  	0.19430098  	0.10639185  
2023-05-18 11:04:25.789: Find a better model.
2023-05-18 11:04:35.097: [iter 114 : loss : 0.1226 = 0.0325 + 0.0842 + 0.0058, time: 9.306025]
2023-05-18 11:04:35.345: epoch 114:	0.02646833  	0.19435987  	0.10648201  
2023-05-18 11:04:35.345: Find a better model.
2023-05-18 11:04:43.546: [iter 115 : loss : 0.1221 = 0.0321 + 0.0842 + 0.0058, time: 8.199507]
2023-05-18 11:04:43.706: epoch 115:	0.02646127  	0.19415528  	0.10648147  
2023-05-18 11:04:51.843: [iter 116 : loss : 0.1213 = 0.0313 + 0.0842 + 0.0059, time: 8.135996]
2023-05-18 11:04:52.013: epoch 116:	0.02657417  	0.19479802  	0.10668897  
2023-05-18 11:04:52.013: Find a better model.
2023-05-18 11:05:00.104: [iter 117 : loss : 0.1213 = 0.0313 + 0.0841 + 0.0059, time: 8.089057]
2023-05-18 11:05:00.248: epoch 117:	0.02660239  	0.19502479  	0.10693066  
2023-05-18 11:05:00.248: Find a better model.
2023-05-18 11:05:09.389: [iter 118 : loss : 0.1213 = 0.0313 + 0.0840 + 0.0059, time: 9.137143]
2023-05-18 11:05:09.682: epoch 118:	0.02663063  	0.19524378  	0.10709492  
2023-05-18 11:05:09.682: Find a better model.
2023-05-18 11:05:17.156: [iter 119 : loss : 0.1201 = 0.0302 + 0.0840 + 0.0060, time: 7.473004]
2023-05-18 11:05:17.317: epoch 119:	0.02660240  	0.19503993  	0.10713323  
2023-05-18 11:05:25.769: [iter 120 : loss : 0.1206 = 0.0307 + 0.0839 + 0.0060, time: 8.450007]
2023-05-18 11:05:25.918: epoch 120:	0.02662357  	0.19568507  	0.10737514  
2023-05-18 11:05:25.918: Find a better model.
2023-05-18 11:05:34.377: [iter 121 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 8.457992]
2023-05-18 11:05:34.531: epoch 121:	0.02658124  	0.19518591  	0.10725600  
2023-05-18 11:05:42.285: [iter 122 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0061, time: 7.753003]
2023-05-18 11:05:42.442: epoch 122:	0.02658829  	0.19499345  	0.10730914  
2023-05-18 11:05:51.544: [iter 123 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 9.101002]
2023-05-18 11:05:51.822: epoch 123:	0.02670825  	0.19591653  	0.10754530  
2023-05-18 11:05:51.822: Find a better model.
2023-05-18 11:05:59.263: [iter 124 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 7.440009]
2023-05-18 11:05:59.419: epoch 124:	0.02664474  	0.19541577  	0.10734361  
2023-05-18 11:06:07.667: [iter 125 : loss : 0.1181 = 0.0283 + 0.0836 + 0.0061, time: 8.246019]
2023-05-18 11:06:07.825: epoch 125:	0.02663063  	0.19524398  	0.10722188  
2023-05-18 11:06:16.136: [iter 126 : loss : 0.1183 = 0.0285 + 0.0836 + 0.0062, time: 8.310547]
2023-05-18 11:06:16.290: epoch 126:	0.02660240  	0.19529442  	0.10727818  
2023-05-18 11:06:24.096: [iter 127 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0062, time: 7.805009]
2023-05-18 11:06:24.252: epoch 127:	0.02668708  	0.19575392  	0.10742226  
2023-05-18 11:06:33.437: [iter 128 : loss : 0.1181 = 0.0284 + 0.0835 + 0.0062, time: 9.182574]
2023-05-18 11:06:33.723: epoch 128:	0.02669414  	0.19572929  	0.10730225  
2023-05-18 11:06:41.419: [iter 129 : loss : 0.1172 = 0.0275 + 0.0835 + 0.0063, time: 7.694993]
2023-05-18 11:06:41.575: epoch 129:	0.02665885  	0.19542313  	0.10722725  
2023-05-18 11:06:49.691: [iter 130 : loss : 0.1172 = 0.0275 + 0.0834 + 0.0063, time: 8.113767]
2023-05-18 11:06:49.847: epoch 130:	0.02665885  	0.19544411  	0.10737693  
2023-05-18 11:06:58.069: [iter 131 : loss : 0.1165 = 0.0268 + 0.0834 + 0.0063, time: 8.220002]
2023-05-18 11:06:58.226: epoch 131:	0.02670119  	0.19583614  	0.10757077  
2023-05-18 11:07:07.869: [iter 132 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0064, time: 9.639065]
2023-05-18 11:07:08.124: epoch 132:	0.02670118  	0.19555472  	0.10758527  
2023-05-18 11:07:17.361: [iter 133 : loss : 0.1156 = 0.0259 + 0.0833 + 0.0064, time: 9.236025]
2023-05-18 11:07:17.624: epoch 133:	0.02666590  	0.19558206  	0.10751178  
2023-05-18 11:07:25.957: [iter 134 : loss : 0.1160 = 0.0263 + 0.0832 + 0.0064, time: 8.331943]
2023-05-18 11:07:26.113: epoch 134:	0.02668001  	0.19539790  	0.10772124  
2023-05-18 11:07:33.849: [iter 135 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 7.734997]
2023-05-18 11:07:34.008: epoch 135:	0.02671529  	0.19531815  	0.10761975  
2023-05-18 11:07:42.499: [iter 136 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0065, time: 8.488997]
2023-05-18 11:07:42.658: epoch 136:	0.02675764  	0.19570883  	0.10787971  
2023-05-18 11:07:51.878: [iter 137 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0065, time: 9.218012]
2023-05-18 11:07:52.169: epoch 137:	0.02675058  	0.19563623  	0.10787702  
2023-05-18 11:08:01.363: [iter 138 : loss : 0.1147 = 0.0250 + 0.0831 + 0.0065, time: 9.192037]
2023-05-18 11:08:01.600: epoch 138:	0.02668002  	0.19526662  	0.10764122  
2023-05-18 11:08:09.858: [iter 139 : loss : 0.1145 = 0.0249 + 0.0831 + 0.0066, time: 8.256992]
2023-05-18 11:08:10.017: epoch 139:	0.02663063  	0.19481874  	0.10750108  
2023-05-18 11:08:18.092: [iter 140 : loss : 0.1141 = 0.0245 + 0.0830 + 0.0066, time: 8.073030]
2023-05-18 11:08:18.328: epoch 140:	0.02665885  	0.19495170  	0.10756335  
2023-05-18 11:08:26.238: [iter 141 : loss : 0.1145 = 0.0249 + 0.0830 + 0.0066, time: 7.909004]
2023-05-18 11:08:26.393: epoch 141:	0.02656712  	0.19420762  	0.10735136  
2023-05-18 11:08:35.481: [iter 142 : loss : 0.1134 = 0.0238 + 0.0829 + 0.0066, time: 9.084026]
2023-05-18 11:08:35.774: epoch 142:	0.02668707  	0.19520679  	0.10789730  
2023-05-18 11:08:43.278: [iter 143 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0067, time: 7.502016]
2023-05-18 11:08:43.442: epoch 143:	0.02671530  	0.19519913  	0.10779209  
2023-05-18 11:08:51.890: [iter 144 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0067, time: 8.446003]
2023-05-18 11:08:52.047: epoch 144:	0.02670119  	0.19510269  	0.10777380  
2023-05-18 11:09:00.507: [iter 145 : loss : 0.1130 = 0.0234 + 0.0828 + 0.0067, time: 8.458005]
2023-05-18 11:09:00.663: epoch 145:	0.02668002  	0.19521880  	0.10777584  
2023-05-18 11:09:08.416: [iter 146 : loss : 0.1134 = 0.0239 + 0.0828 + 0.0067, time: 7.751332]
2023-05-18 11:09:08.571: epoch 146:	0.02675059  	0.19561492  	0.10782511  
2023-05-18 11:09:17.629: [iter 147 : loss : 0.1131 = 0.0235 + 0.0828 + 0.0068, time: 9.057002]
2023-05-18 11:09:17.908: epoch 147:	0.02670826  	0.19541954  	0.10780681  
2023-05-18 11:09:25.395: [iter 148 : loss : 0.1119 = 0.0224 + 0.0827 + 0.0068, time: 7.486003]
2023-05-18 11:09:25.554: epoch 148:	0.02670825  	0.19527633  	0.10786469  
2023-05-18 11:09:25.554: Early stopping is trigger at epoch: 148
2023-05-18 11:09:25.554: best_result@epoch 123:

2023-05-18 11:09:25.554: 		0.0267      	0.1959      	0.1075      
2023-05-18 11:16:43.375: my pid: 2508
2023-05-18 11:16:43.375: model: model.general_recommender.SGL
2023-05-18 11:16:43.375: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 11:16:43.375: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 11:16:46.604: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 11:16:55.657: [iter 1 : loss : 0.7716 = 0.6930 + 0.0786 + 0.0000, time: 9.050547]
2023-05-18 11:16:55.812: epoch 1:	0.00130539  	0.00942579  	0.00470210  
2023-05-18 11:16:55.812: Find a better model.
2023-05-18 11:17:06.162: [iter 2 : loss : 0.7712 = 0.6929 + 0.0783 + 0.0000, time: 10.346977]
2023-05-18 11:17:06.501: epoch 2:	0.00230737  	0.01755356  	0.00857766  
2023-05-18 11:17:06.501: Find a better model.
2023-05-18 11:17:15.659: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 9.157924]
2023-05-18 11:17:15.978: epoch 3:	0.00431130  	0.03083565  	0.01459244  
2023-05-18 11:17:15.979: Find a better model.
2023-05-18 11:17:24.501: [iter 4 : loss : 0.7707 = 0.6922 + 0.0785 + 0.0000, time: 8.521021]
2023-05-18 11:17:24.666: epoch 4:	0.00680209  	0.05040428  	0.02392675  
2023-05-18 11:17:24.666: Find a better model.
2023-05-18 11:17:33.681: [iter 5 : loss : 0.7699 = 0.6913 + 0.0787 + 0.0000, time: 9.012150]
2023-05-18 11:17:33.859: epoch 5:	0.01072536  	0.07765550  	0.03679572  
2023-05-18 11:17:33.859: Find a better model.
2023-05-18 11:17:43.626: [iter 6 : loss : 0.7683 = 0.6893 + 0.0790 + 0.0000, time: 9.764030]
2023-05-18 11:17:43.905: epoch 6:	0.01403484  	0.10155275  	0.04917425  
2023-05-18 11:17:43.905: Find a better model.
2023-05-18 11:17:52.471: [iter 7 : loss : 0.7638 = 0.6843 + 0.0795 + 0.0000, time: 8.565015]
2023-05-18 11:17:52.638: epoch 7:	0.01706203  	0.12414414  	0.06103771  
2023-05-18 11:17:52.639: Find a better model.
2023-05-18 11:18:01.537: [iter 8 : loss : 0.7527 = 0.6717 + 0.0810 + 0.0001, time: 8.896150]
2023-05-18 11:18:01.698: epoch 8:	0.01855799  	0.13582906  	0.06787238  
2023-05-18 11:18:01.698: Find a better model.
2023-05-18 11:18:10.479: [iter 9 : loss : 0.7257 = 0.6415 + 0.0841 + 0.0001, time: 8.779998]
2023-05-18 11:18:10.634: epoch 9:	0.01867796  	0.13722730  	0.06894978  
2023-05-18 11:18:10.634: Find a better model.
2023-05-18 11:18:18.830: [iter 10 : loss : 0.6739 = 0.5845 + 0.0892 + 0.0002, time: 8.194987]
2023-05-18 11:18:18.993: epoch 10:	0.01852979  	0.13730444  	0.06801434  
2023-05-18 11:18:18.993: Find a better model.
2023-05-18 11:18:28.359: [iter 11 : loss : 0.6007 = 0.5057 + 0.0946 + 0.0003, time: 9.364021]
2023-05-18 11:18:28.642: epoch 11:	0.01846628  	0.13671210  	0.06779914  
2023-05-18 11:18:36.568: [iter 12 : loss : 0.5271 = 0.4280 + 0.0986 + 0.0005, time: 7.925002]
2023-05-18 11:18:36.721: epoch 12:	0.01843100  	0.13673528  	0.06811611  
2023-05-18 11:18:45.002: [iter 13 : loss : 0.4707 = 0.3691 + 0.1010 + 0.0007, time: 8.277757]
2023-05-18 11:18:45.155: epoch 13:	0.01845922  	0.13692781  	0.06843828  
2023-05-18 11:18:53.818: [iter 14 : loss : 0.4276 = 0.3245 + 0.1023 + 0.0008, time: 8.662352]
2023-05-18 11:18:53.972: epoch 14:	0.01868503  	0.13850962  	0.06945417  
2023-05-18 11:18:53.972: Find a better model.
2023-05-18 11:19:03.410: [iter 15 : loss : 0.3977 = 0.2941 + 0.1027 + 0.0009, time: 9.428005]
2023-05-18 11:19:03.707: epoch 15:	0.01893201  	0.14036401  	0.07052289  
2023-05-18 11:19:03.707: Find a better model.
2023-05-18 11:19:13.240: [iter 16 : loss : 0.3732 = 0.2694 + 0.1028 + 0.0011, time: 9.531050]
2023-05-18 11:19:13.522: epoch 16:	0.01914370  	0.14172527  	0.07116516  
2023-05-18 11:19:13.522: Find a better model.
2023-05-18 11:19:21.802: [iter 17 : loss : 0.3554 = 0.2516 + 0.1027 + 0.0012, time: 8.278007]
2023-05-18 11:19:21.957: epoch 17:	0.01927071  	0.14224844  	0.07175647  
2023-05-18 11:19:21.957: Find a better model.
2023-05-18 11:19:29.820: [iter 18 : loss : 0.3392 = 0.2355 + 0.1024 + 0.0013, time: 7.862035]
2023-05-18 11:19:29.984: epoch 18:	0.01953887  	0.14433560  	0.07281899  
2023-05-18 11:19:29.984: Find a better model.
2023-05-18 11:19:38.669: [iter 19 : loss : 0.3242 = 0.2208 + 0.1021 + 0.0014, time: 8.684022]
2023-05-18 11:19:38.838: epoch 19:	0.01965884  	0.14503099  	0.07336852  
2023-05-18 11:19:38.838: Find a better model.
2023-05-18 11:19:48.259: [iter 20 : loss : 0.3141 = 0.2109 + 0.1018 + 0.0015, time: 9.420058]
2023-05-18 11:19:48.550: epoch 20:	0.01991992  	0.14725907  	0.07432836  
2023-05-18 11:19:48.550: Find a better model.
2023-05-18 11:19:57.522: [iter 21 : loss : 0.3041 = 0.2013 + 0.1012 + 0.0016, time: 8.971012]
2023-05-18 11:19:57.696: epoch 21:	0.02015984  	0.14912271  	0.07539631  
2023-05-18 11:19:57.696: Find a better model.
2023-05-18 11:20:06.248: [iter 22 : loss : 0.2953 = 0.1928 + 0.1009 + 0.0016, time: 8.550000]
2023-05-18 11:20:06.421: epoch 22:	0.02051972  	0.15169346  	0.07659636  
2023-05-18 11:20:06.421: Find a better model.
2023-05-18 11:20:14.934: [iter 23 : loss : 0.2869 = 0.1848 + 0.1004 + 0.0017, time: 8.511021]
2023-05-18 11:20:15.315: epoch 23:	0.02066085  	0.15257275  	0.07735560  
2023-05-18 11:20:15.315: Find a better model.
2023-05-18 11:20:23.414: [iter 24 : loss : 0.2802 = 0.1785 + 0.0999 + 0.0018, time: 8.097015]
2023-05-18 11:20:23.568: epoch 24:	0.02087961  	0.15420227  	0.07835619  
2023-05-18 11:20:23.568: Find a better model.
2023-05-18 11:20:32.873: [iter 25 : loss : 0.2731 = 0.1717 + 0.0995 + 0.0019, time: 9.303025]
2023-05-18 11:20:33.157: epoch 25:	0.02109836  	0.15580274  	0.07903400  
2023-05-18 11:20:33.158: Find a better model.
2023-05-18 11:20:41.127: [iter 26 : loss : 0.2697 = 0.1686 + 0.0991 + 0.0019, time: 7.968020]
2023-05-18 11:20:41.281: epoch 26:	0.02126771  	0.15671551  	0.07968696  
2023-05-18 11:20:41.281: Find a better model.
2023-05-18 11:20:49.598: [iter 27 : loss : 0.2615 = 0.1609 + 0.0986 + 0.0020, time: 8.316078]
2023-05-18 11:20:49.752: epoch 27:	0.02137356  	0.15714714  	0.08014914  
2023-05-18 11:20:49.753: Find a better model.
2023-05-18 11:20:58.172: [iter 28 : loss : 0.2565 = 0.1563 + 0.0982 + 0.0021, time: 8.418000]
2023-05-18 11:20:58.326: epoch 28:	0.02158526  	0.15887749  	0.08106549  
2023-05-18 11:20:58.326: Find a better model.
2023-05-18 11:21:07.872: [iter 29 : loss : 0.2519 = 0.1519 + 0.0978 + 0.0021, time: 9.537033]
2023-05-18 11:21:08.162: epoch 29:	0.02170522  	0.15997015  	0.08177143  
2023-05-18 11:21:08.162: Find a better model.
2023-05-18 11:21:17.550: [iter 30 : loss : 0.2454 = 0.1457 + 0.0975 + 0.0022, time: 9.385005]
2023-05-18 11:21:17.834: epoch 30:	0.02185341  	0.16108513  	0.08259767  
2023-05-18 11:21:17.834: Find a better model.
2023-05-18 11:21:26.216: [iter 31 : loss : 0.2419 = 0.1425 + 0.0971 + 0.0023, time: 8.380014]
2023-05-18 11:21:26.371: epoch 31:	0.02205099  	0.16302022  	0.08336601  
2023-05-18 11:21:26.371: Find a better model.
2023-05-18 11:21:34.383: [iter 32 : loss : 0.2360 = 0.1370 + 0.0966 + 0.0023, time: 8.011019]
2023-05-18 11:21:34.545: epoch 32:	0.02211450  	0.16346306  	0.08397983  
2023-05-18 11:21:34.545: Find a better model.
2023-05-18 11:21:43.584: [iter 33 : loss : 0.2334 = 0.1348 + 0.0963 + 0.0024, time: 9.037039]
2023-05-18 11:21:43.746: epoch 33:	0.02219212  	0.16385499  	0.08420896  
2023-05-18 11:21:43.746: Find a better model.
2023-05-18 11:21:53.284: [iter 34 : loss : 0.2293 = 0.1309 + 0.0960 + 0.0024, time: 9.534275]
2023-05-18 11:21:53.577: epoch 34:	0.02241087  	0.16536851  	0.08497921  
2023-05-18 11:21:53.577: Find a better model.
2023-05-18 11:22:02.535: [iter 35 : loss : 0.2257 = 0.1277 + 0.0956 + 0.0025, time: 8.957006]
2023-05-18 11:22:02.708: epoch 35:	0.02260139  	0.16705120  	0.08568757  
2023-05-18 11:22:02.708: Find a better model.
2023-05-18 11:22:11.389: [iter 36 : loss : 0.2221 = 0.1243 + 0.0952 + 0.0025, time: 8.680007]
2023-05-18 11:22:11.563: epoch 36:	0.02264373  	0.16711000  	0.08620623  
2023-05-18 11:22:11.564: Find a better model.
2023-05-18 11:22:20.220: [iter 37 : loss : 0.2183 = 0.1207 + 0.0950 + 0.0026, time: 8.653998]
2023-05-18 11:22:20.521: epoch 37:	0.02277780  	0.16803619  	0.08682030  
2023-05-18 11:22:20.521: Find a better model.
2023-05-18 11:22:28.536: [iter 38 : loss : 0.2165 = 0.1192 + 0.0946 + 0.0027, time: 8.014021]
2023-05-18 11:22:28.689: epoch 38:	0.02296127  	0.16955489  	0.08764172  
2023-05-18 11:22:28.689: Find a better model.
2023-05-18 11:22:37.999: [iter 39 : loss : 0.2121 = 0.1151 + 0.0943 + 0.0027, time: 9.302006]
2023-05-18 11:22:38.283: epoch 39:	0.02304595  	0.17010455  	0.08840623  
2023-05-18 11:22:38.283: Find a better model.
2023-05-18 11:22:46.017: [iter 40 : loss : 0.2090 = 0.1122 + 0.0941 + 0.0028, time: 7.733052]
2023-05-18 11:22:46.169: epoch 40:	0.02308829  	0.17059124  	0.08899833  
2023-05-18 11:22:46.169: Find a better model.
2023-05-18 11:22:54.526: [iter 41 : loss : 0.2073 = 0.1107 + 0.0938 + 0.0028, time: 8.356005]
2023-05-18 11:22:54.678: epoch 41:	0.02321531  	0.17152084  	0.08975445  
2023-05-18 11:22:54.678: Find a better model.
2023-05-18 11:23:03.125: [iter 42 : loss : 0.2049 = 0.1086 + 0.0934 + 0.0029, time: 8.445992]
2023-05-18 11:23:03.280: epoch 42:	0.02332822  	0.17198382  	0.09030586  
2023-05-18 11:23:03.281: Find a better model.
2023-05-18 11:23:11.352: [iter 43 : loss : 0.2011 = 0.1050 + 0.0931 + 0.0029, time: 8.069013]
2023-05-18 11:23:11.523: epoch 43:	0.02348346  	0.17288338  	0.09094325  
2023-05-18 11:23:11.523: Find a better model.
2023-05-18 11:23:20.974: [iter 44 : loss : 0.1974 = 0.1016 + 0.0928 + 0.0030, time: 9.449020]
2023-05-18 11:23:21.226: epoch 44:	0.02353991  	0.17320561  	0.09128206  
2023-05-18 11:23:21.226: Find a better model.
2023-05-18 11:23:29.587: [iter 45 : loss : 0.1953 = 0.0997 + 0.0926 + 0.0030, time: 8.358999]
2023-05-18 11:23:29.814: epoch 45:	0.02372338  	0.17423959  	0.09206346  
2023-05-18 11:23:29.814: Find a better model.
2023-05-18 11:23:37.965: [iter 46 : loss : 0.1930 = 0.0976 + 0.0924 + 0.0031, time: 8.149016]
2023-05-18 11:23:38.128: epoch 46:	0.02376571  	0.17445792  	0.09237181  
2023-05-18 11:23:38.128: Find a better model.
2023-05-18 11:23:46.864: [iter 47 : loss : 0.1921 = 0.0968 + 0.0921 + 0.0031, time: 8.733999]
2023-05-18 11:23:47.027: epoch 47:	0.02383627  	0.17483872  	0.09271516  
2023-05-18 11:23:47.027: Find a better model.
2023-05-18 11:23:56.481: [iter 48 : loss : 0.1884 = 0.0933 + 0.0919 + 0.0032, time: 9.452025]
2023-05-18 11:23:56.766: epoch 48:	0.02394917  	0.17568322  	0.09319498  
2023-05-18 11:23:56.766: Find a better model.
2023-05-18 11:24:06.264: [iter 49 : loss : 0.1852 = 0.0903 + 0.0917 + 0.0032, time: 9.497017]
2023-05-18 11:24:06.554: epoch 49:	0.02410441  	0.17693196  	0.09397821  
2023-05-18 11:24:06.554: Find a better model.
2023-05-18 11:24:14.281: [iter 50 : loss : 0.1842 = 0.0895 + 0.0915 + 0.0033, time: 7.725398]
2023-05-18 11:24:14.433: epoch 50:	0.02420320  	0.17751412  	0.09442442  
2023-05-18 11:24:14.433: Find a better model.
2023-05-18 11:24:22.070: [iter 51 : loss : 0.1810 = 0.0864 + 0.0913 + 0.0033, time: 7.634963]
2023-05-18 11:24:22.220: epoch 51:	0.02419614  	0.17770566  	0.09472278  
2023-05-18 11:24:22.220: Find a better model.
2023-05-18 11:24:29.863: [iter 52 : loss : 0.1813 = 0.0869 + 0.0910 + 0.0034, time: 7.641862]
2023-05-18 11:24:30.015: epoch 52:	0.02424554  	0.17820650  	0.09514721  
2023-05-18 11:24:30.015: Find a better model.
2023-05-18 11:24:37.651: [iter 53 : loss : 0.1789 = 0.0847 + 0.0908 + 0.0034, time: 7.634240]
2023-05-18 11:24:37.802: epoch 53:	0.02439372  	0.17921999  	0.09575493  
2023-05-18 11:24:37.803: Find a better model.
2023-05-18 11:24:45.460: [iter 54 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0035, time: 7.656417]
2023-05-18 11:24:45.612: epoch 54:	0.02440784  	0.17930757  	0.09591011  
2023-05-18 11:24:45.612: Find a better model.
2023-05-18 11:24:53.235: [iter 55 : loss : 0.1749 = 0.0809 + 0.0905 + 0.0035, time: 7.622284]
2023-05-18 11:24:53.389: epoch 55:	0.02445018  	0.17956914  	0.09621443  
2023-05-18 11:24:53.389: Find a better model.
2023-05-18 11:25:01.037: [iter 56 : loss : 0.1733 = 0.0795 + 0.0903 + 0.0036, time: 7.647130]
2023-05-18 11:25:01.190: epoch 56:	0.02454191  	0.18040632  	0.09675062  
2023-05-18 11:25:01.190: Find a better model.
2023-05-18 11:25:08.654: [iter 57 : loss : 0.1714 = 0.0777 + 0.0901 + 0.0036, time: 7.463732]
2023-05-18 11:25:08.807: epoch 57:	0.02464776  	0.18150386  	0.09727269  
2023-05-18 11:25:08.807: Find a better model.
2023-05-18 11:25:16.451: [iter 58 : loss : 0.1694 = 0.0759 + 0.0899 + 0.0037, time: 7.643616]
2023-05-18 11:25:16.603: epoch 58:	0.02461248  	0.18126635  	0.09732531  
2023-05-18 11:25:24.454: [iter 59 : loss : 0.1684 = 0.0750 + 0.0897 + 0.0037, time: 7.849314]
2023-05-18 11:25:24.606: epoch 59:	0.02473243  	0.18206669  	0.09771298  
2023-05-18 11:25:24.606: Find a better model.
2023-05-18 11:25:32.248: [iter 60 : loss : 0.1670 = 0.0737 + 0.0895 + 0.0037, time: 7.641684]
2023-05-18 11:25:32.404: epoch 60:	0.02478888  	0.18255898  	0.09806684  
2023-05-18 11:25:32.405: Find a better model.
2023-05-18 11:25:40.024: [iter 61 : loss : 0.1655 = 0.0724 + 0.0894 + 0.0038, time: 7.617384]
2023-05-18 11:25:40.174: epoch 61:	0.02483122  	0.18293878  	0.09830993  
2023-05-18 11:25:40.175: Find a better model.
2023-05-18 11:25:47.646: [iter 62 : loss : 0.1641 = 0.0710 + 0.0892 + 0.0038, time: 7.469752]
2023-05-18 11:25:47.786: epoch 62:	0.02484534  	0.18336762  	0.09867717  
2023-05-18 11:25:47.786: Find a better model.
2023-05-18 11:25:55.445: [iter 63 : loss : 0.1627 = 0.0698 + 0.0890 + 0.0039, time: 7.657664]
2023-05-18 11:25:55.598: epoch 63:	0.02495118  	0.18375026  	0.09911462  
2023-05-18 11:25:55.598: Find a better model.
2023-05-18 11:26:03.286: [iter 64 : loss : 0.1616 = 0.0689 + 0.0888 + 0.0039, time: 7.686251]
2023-05-18 11:26:03.437: epoch 64:	0.02505703  	0.18472975  	0.09958718  
2023-05-18 11:26:03.437: Find a better model.
2023-05-18 11:26:11.008: [iter 65 : loss : 0.1603 = 0.0677 + 0.0887 + 0.0040, time: 7.570762]
2023-05-18 11:26:11.159: epoch 65:	0.02509937  	0.18502459  	0.09978502  
2023-05-18 11:26:11.159: Find a better model.
2023-05-18 11:26:18.648: [iter 66 : loss : 0.1587 = 0.0661 + 0.0886 + 0.0040, time: 7.487695]
2023-05-18 11:26:18.798: epoch 66:	0.02512759  	0.18504389  	0.10020518  
2023-05-18 11:26:18.798: Find a better model.
2023-05-18 11:26:26.433: [iter 67 : loss : 0.1571 = 0.0646 + 0.0884 + 0.0040, time: 7.633898]
2023-05-18 11:26:26.587: epoch 67:	0.02512760  	0.18533121  	0.10056956  
2023-05-18 11:26:26.587: Find a better model.
2023-05-18 11:26:34.262: [iter 68 : loss : 0.1569 = 0.0645 + 0.0883 + 0.0041, time: 7.673509]
2023-05-18 11:26:34.413: epoch 68:	0.02514876  	0.18585327  	0.10085474  
2023-05-18 11:26:34.414: Find a better model.
2023-05-18 11:26:42.058: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 7.642857]
2023-05-18 11:26:42.209: epoch 69:	0.02519817  	0.18606807  	0.10095005  
2023-05-18 11:26:42.209: Find a better model.
2023-05-18 11:26:49.826: [iter 70 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 7.615732]
2023-05-18 11:26:49.977: epoch 70:	0.02524051  	0.18661529  	0.10138217  
2023-05-18 11:26:49.977: Find a better model.
2023-05-18 11:26:57.418: [iter 71 : loss : 0.1520 = 0.0599 + 0.0879 + 0.0042, time: 7.439929]
2023-05-18 11:26:57.570: epoch 71:	0.02529695  	0.18698668  	0.10156485  
2023-05-18 11:26:57.570: Find a better model.
2023-05-18 11:27:05.018: [iter 72 : loss : 0.1515 = 0.0594 + 0.0878 + 0.0043, time: 7.446555]
2023-05-18 11:27:05.168: epoch 72:	0.02541691  	0.18760423  	0.10201462  
2023-05-18 11:27:05.168: Find a better model.
2023-05-18 11:27:12.821: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 7.652272]
2023-05-18 11:27:12.973: epoch 73:	0.02552276  	0.18832354  	0.10241748  
2023-05-18 11:27:12.973: Find a better model.
2023-05-18 11:27:20.426: [iter 74 : loss : 0.1488 = 0.0569 + 0.0876 + 0.0043, time: 7.451719]
2023-05-18 11:27:20.577: epoch 74:	0.02553687  	0.18830684  	0.10245521  
2023-05-18 11:27:28.203: [iter 75 : loss : 0.1483 = 0.0565 + 0.0874 + 0.0044, time: 7.625391]
2023-05-18 11:27:28.355: epoch 75:	0.02550864  	0.18825780  	0.10260717  
2023-05-18 11:27:35.797: [iter 76 : loss : 0.1474 = 0.0556 + 0.0873 + 0.0044, time: 7.441348]
2023-05-18 11:27:35.949: epoch 76:	0.02557921  	0.18867391  	0.10277992  
2023-05-18 11:27:35.950: Find a better model.
2023-05-18 11:27:43.602: [iter 77 : loss : 0.1463 = 0.0547 + 0.0872 + 0.0045, time: 7.651102]
2023-05-18 11:27:43.758: epoch 77:	0.02561449  	0.18886183  	0.10290799  
2023-05-18 11:27:43.758: Find a better model.
2023-05-18 11:27:51.206: [iter 78 : loss : 0.1452 = 0.0537 + 0.0871 + 0.0045, time: 7.447003]
2023-05-18 11:27:51.359: epoch 78:	0.02562154  	0.18890907  	0.10300134  
2023-05-18 11:27:51.359: Find a better model.
2023-05-18 11:27:58.816: [iter 79 : loss : 0.1439 = 0.0524 + 0.0869 + 0.0045, time: 7.456322]
2023-05-18 11:27:58.968: epoch 79:	0.02564977  	0.18921563  	0.10323146  
2023-05-18 11:27:58.968: Find a better model.
2023-05-18 11:28:06.650: [iter 80 : loss : 0.1433 = 0.0519 + 0.0868 + 0.0046, time: 7.680935]
2023-05-18 11:28:06.804: epoch 80:	0.02570622  	0.18963900  	0.10349387  
2023-05-18 11:28:06.804: Find a better model.
2023-05-18 11:28:14.192: [iter 81 : loss : 0.1431 = 0.0517 + 0.0867 + 0.0046, time: 7.387357]
2023-05-18 11:28:14.343: epoch 81:	0.02571328  	0.18979873  	0.10359839  
2023-05-18 11:28:14.343: Find a better model.
2023-05-18 11:28:21.788: [iter 82 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0047, time: 7.443442]
2023-05-18 11:28:21.929: epoch 82:	0.02576267  	0.19037211  	0.10379742  
2023-05-18 11:28:21.929: Find a better model.
2023-05-18 11:28:29.419: [iter 83 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 7.487540]
2023-05-18 11:28:29.570: epoch 83:	0.02596026  	0.19161636  	0.10444173  
2023-05-18 11:28:29.570: Find a better model.
2023-05-18 11:28:36.978: [iter 84 : loss : 0.1408 = 0.0496 + 0.0865 + 0.0047, time: 7.406844]
2023-05-18 11:28:37.130: epoch 84:	0.02596732  	0.19160941  	0.10455146  
2023-05-18 11:28:44.592: [iter 85 : loss : 0.1396 = 0.0485 + 0.0864 + 0.0048, time: 7.461359]
2023-05-18 11:28:44.743: epoch 85:	0.02599554  	0.19199412  	0.10483703  
2023-05-18 11:28:44.743: Find a better model.
2023-05-18 11:28:52.195: [iter 86 : loss : 0.1395 = 0.0485 + 0.0863 + 0.0048, time: 7.449206]
2023-05-18 11:28:52.348: epoch 86:	0.02603083  	0.19207893  	0.10509030  
2023-05-18 11:28:52.349: Find a better model.
2023-05-18 11:28:59.791: [iter 87 : loss : 0.1367 = 0.0457 + 0.0861 + 0.0048, time: 7.441272]
2023-05-18 11:28:59.946: epoch 87:	0.02612961  	0.19291162  	0.10533494  
2023-05-18 11:28:59.946: Find a better model.
2023-05-18 11:29:07.377: [iter 88 : loss : 0.1362 = 0.0453 + 0.0861 + 0.0049, time: 7.429867]
2023-05-18 11:29:07.529: epoch 88:	0.02615784  	0.19284837  	0.10530660  
2023-05-18 11:29:14.982: [iter 89 : loss : 0.1359 = 0.0450 + 0.0859 + 0.0049, time: 7.450735]
2023-05-18 11:29:15.134: epoch 89:	0.02623546  	0.19351213  	0.10550237  
2023-05-18 11:29:15.134: Find a better model.
2023-05-18 11:29:22.776: [iter 90 : loss : 0.1365 = 0.0457 + 0.0859 + 0.0050, time: 7.641286]
2023-05-18 11:29:22.926: epoch 90:	0.02626369  	0.19315566  	0.10569031  
2023-05-18 11:29:30.376: [iter 91 : loss : 0.1351 = 0.0444 + 0.0858 + 0.0050, time: 7.448825]
2023-05-18 11:29:30.530: epoch 91:	0.02635542  	0.19398370  	0.10608453  
2023-05-18 11:29:30.530: Find a better model.
2023-05-18 11:29:38.132: [iter 92 : loss : 0.1342 = 0.0435 + 0.0857 + 0.0050, time: 7.601297]
2023-05-18 11:29:38.283: epoch 92:	0.02629191  	0.19368376  	0.10601404  
2023-05-18 11:29:45.743: [iter 93 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0051, time: 7.458758]
2023-05-18 11:29:45.894: epoch 93:	0.02632719  	0.19413120  	0.10612379  
2023-05-18 11:29:45.894: Find a better model.
2023-05-18 11:29:53.383: [iter 94 : loss : 0.1323 = 0.0417 + 0.0855 + 0.0051, time: 7.487810]
2023-05-18 11:29:53.534: epoch 94:	0.02636248  	0.19430986  	0.10635535  
2023-05-18 11:29:53.534: Find a better model.
2023-05-18 11:30:00.957: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.422241]
2023-05-18 11:30:01.111: epoch 95:	0.02640481  	0.19470736  	0.10662119  
2023-05-18 11:30:01.111: Find a better model.
2023-05-18 11:30:08.537: [iter 96 : loss : 0.1317 = 0.0411 + 0.0854 + 0.0052, time: 7.425590]
2023-05-18 11:30:08.688: epoch 96:	0.02643304  	0.19483182  	0.10674294  
2023-05-18 11:30:08.688: Find a better model.
2023-05-18 11:30:16.150: [iter 97 : loss : 0.1301 = 0.0396 + 0.0853 + 0.0052, time: 7.461010]
2023-05-18 11:30:16.301: epoch 97:	0.02636248  	0.19417270  	0.10660624  
2023-05-18 11:30:23.744: [iter 98 : loss : 0.1311 = 0.0406 + 0.0853 + 0.0053, time: 7.441319]
2023-05-18 11:30:23.895: epoch 98:	0.02646127  	0.19501443  	0.10701825  
2023-05-18 11:30:23.895: Find a better model.
2023-05-18 11:30:31.343: [iter 99 : loss : 0.1299 = 0.0394 + 0.0852 + 0.0053, time: 7.446867]
2023-05-18 11:30:31.495: epoch 99:	0.02653889  	0.19531000  	0.10722824  
2023-05-18 11:30:31.495: Find a better model.
2023-05-18 11:30:38.949: [iter 100 : loss : 0.1291 = 0.0386 + 0.0851 + 0.0053, time: 7.452403]
2023-05-18 11:30:39.101: epoch 100:	0.02657418  	0.19556095  	0.10737529  
2023-05-18 11:30:39.101: Find a better model.
2023-05-18 11:30:46.533: [iter 101 : loss : 0.1288 = 0.0384 + 0.0850 + 0.0054, time: 7.430653]
2023-05-18 11:30:46.684: epoch 101:	0.02657418  	0.19551501  	0.10746120  
2023-05-18 11:30:54.127: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 7.441399]
2023-05-18 11:30:54.279: epoch 102:	0.02662357  	0.19615717  	0.10776608  
2023-05-18 11:30:54.279: Find a better model.
2023-05-18 11:31:01.752: [iter 103 : loss : 0.1273 = 0.0370 + 0.0849 + 0.0054, time: 7.472060]
2023-05-18 11:31:01.904: epoch 103:	0.02660239  	0.19583870  	0.10780466  
2023-05-18 11:31:09.317: [iter 104 : loss : 0.1280 = 0.0377 + 0.0848 + 0.0055, time: 7.410923]
2023-05-18 11:31:09.468: epoch 104:	0.02663062  	0.19606115  	0.10797213  
2023-05-18 11:31:16.913: [iter 105 : loss : 0.1274 = 0.0371 + 0.0847 + 0.0055, time: 7.443297]
2023-05-18 11:31:17.066: epoch 105:	0.02659534  	0.19568171  	0.10772439  
2023-05-18 11:31:24.529: [iter 106 : loss : 0.1267 = 0.0364 + 0.0847 + 0.0055, time: 7.461792]
2023-05-18 11:31:24.681: epoch 106:	0.02663768  	0.19582173  	0.10780232  
2023-05-18 11:31:32.113: [iter 107 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0056, time: 7.431104]
2023-05-18 11:31:32.265: epoch 107:	0.02663768  	0.19579004  	0.10766277  
2023-05-18 11:31:39.700: [iter 108 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 7.433733]
2023-05-18 11:31:39.856: epoch 108:	0.02667296  	0.19627734  	0.10802669  
2023-05-18 11:31:39.856: Find a better model.
2023-05-18 11:31:47.517: [iter 109 : loss : 0.1243 = 0.0341 + 0.0845 + 0.0056, time: 7.658904]
2023-05-18 11:31:47.667: epoch 109:	0.02662357  	0.19582157  	0.10795475  
2023-05-18 11:31:55.129: [iter 110 : loss : 0.1235 = 0.0334 + 0.0844 + 0.0057, time: 7.460300]
2023-05-18 11:31:55.281: epoch 110:	0.02661651  	0.19578895  	0.10790162  
2023-05-18 11:32:02.708: [iter 111 : loss : 0.1235 = 0.0335 + 0.0844 + 0.0057, time: 7.425957]
2023-05-18 11:32:02.861: epoch 111:	0.02662357  	0.19554476  	0.10802963  
2023-05-18 11:32:10.302: [iter 112 : loss : 0.1236 = 0.0335 + 0.0843 + 0.0057, time: 7.438993]
2023-05-18 11:32:10.455: epoch 112:	0.02662357  	0.19561526  	0.10812426  
2023-05-18 11:32:17.910: [iter 113 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0058, time: 7.454907]
2023-05-18 11:32:18.062: epoch 113:	0.02659534  	0.19541456  	0.10809337  
2023-05-18 11:32:25.513: [iter 114 : loss : 0.1225 = 0.0325 + 0.0842 + 0.0058, time: 7.449962]
2023-05-18 11:32:25.666: epoch 114:	0.02668708  	0.19624230  	0.10854003  
2023-05-18 11:32:33.110: [iter 115 : loss : 0.1220 = 0.0320 + 0.0841 + 0.0058, time: 7.441739]
2023-05-18 11:32:33.262: epoch 115:	0.02666591  	0.19589160  	0.10833010  
2023-05-18 11:32:40.701: [iter 116 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0059, time: 7.437459]
2023-05-18 11:32:40.854: epoch 116:	0.02667296  	0.19630267  	0.10832586  
2023-05-18 11:32:40.854: Find a better model.
2023-05-18 11:32:48.279: [iter 117 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 7.424107]
2023-05-18 11:32:48.431: epoch 117:	0.02664474  	0.19599099  	0.10835675  
2023-05-18 11:32:55.874: [iter 118 : loss : 0.1210 = 0.0311 + 0.0840 + 0.0059, time: 7.442291]
2023-05-18 11:32:56.026: epoch 118:	0.02668002  	0.19635127  	0.10846801  
2023-05-18 11:32:56.027: Find a better model.
2023-05-18 11:33:03.291: [iter 119 : loss : 0.1200 = 0.0301 + 0.0839 + 0.0060, time: 7.263634]
2023-05-18 11:33:03.445: epoch 119:	0.02666591  	0.19622655  	0.10856394  
2023-05-18 11:33:10.885: [iter 120 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 7.437884]
2023-05-18 11:33:11.038: epoch 120:	0.02663768  	0.19603860  	0.10862457  
2023-05-18 11:33:18.284: [iter 121 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0060, time: 7.245028]
2023-05-18 11:33:18.427: epoch 121:	0.02672236  	0.19650711  	0.10882170  
2023-05-18 11:33:18.427: Find a better model.
2023-05-18 11:33:25.874: [iter 122 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0061, time: 7.446446]
2023-05-18 11:33:26.026: epoch 122:	0.02661651  	0.19606309  	0.10870733  
2023-05-18 11:33:33.486: [iter 123 : loss : 0.1194 = 0.0295 + 0.0838 + 0.0061, time: 7.458169]
2023-05-18 11:33:33.639: epoch 123:	0.02670825  	0.19635470  	0.10869162  
2023-05-18 11:33:41.072: [iter 124 : loss : 0.1188 = 0.0289 + 0.0837 + 0.0061, time: 7.431110]
2023-05-18 11:33:41.224: epoch 124:	0.02670119  	0.19629617  	0.10863779  
2023-05-18 11:33:48.670: [iter 125 : loss : 0.1177 = 0.0279 + 0.0837 + 0.0062, time: 7.445339]
2023-05-18 11:33:48.821: epoch 125:	0.02669413  	0.19591561  	0.10877171  
2023-05-18 11:33:56.279: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 7.455388]
2023-05-18 11:33:56.429: epoch 126:	0.02664474  	0.19588788  	0.10887868  
2023-05-18 11:34:03.854: [iter 127 : loss : 0.1171 = 0.0273 + 0.0835 + 0.0062, time: 7.423813]
2023-05-18 11:34:04.006: epoch 127:	0.02664474  	0.19578254  	0.10883904  
2023-05-18 11:34:11.455: [iter 128 : loss : 0.1182 = 0.0284 + 0.0836 + 0.0062, time: 7.447973]
2023-05-18 11:34:11.606: epoch 128:	0.02660240  	0.19563526  	0.10883415  
2023-05-18 11:34:19.071: [iter 129 : loss : 0.1172 = 0.0275 + 0.0835 + 0.0063, time: 7.463504]
2023-05-18 11:34:19.223: epoch 129:	0.02672942  	0.19648239  	0.10903697  
2023-05-18 11:34:26.669: [iter 130 : loss : 0.1171 = 0.0273 + 0.0834 + 0.0063, time: 7.444031]
2023-05-18 11:34:26.820: epoch 130:	0.02668708  	0.19625187  	0.10911357  
2023-05-18 11:34:34.254: [iter 131 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 7.432223]
2023-05-18 11:34:34.405: epoch 131:	0.02663063  	0.19593018  	0.10916136  
2023-05-18 11:34:41.863: [iter 132 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0064, time: 7.455856]
2023-05-18 11:34:42.014: epoch 132:	0.02670119  	0.19643813  	0.10925239  
2023-05-18 11:34:49.449: [iter 133 : loss : 0.1153 = 0.0257 + 0.0833 + 0.0064, time: 7.434718]
2023-05-18 11:34:49.602: epoch 133:	0.02668708  	0.19641015  	0.10923672  
2023-05-18 11:34:57.042: [iter 134 : loss : 0.1159 = 0.0262 + 0.0833 + 0.0064, time: 7.438415]
2023-05-18 11:34:57.193: epoch 134:	0.02679998  	0.19734640  	0.10951554  
2023-05-18 11:34:57.193: Find a better model.
2023-05-18 11:35:04.659: [iter 135 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0065, time: 7.465055]
2023-05-18 11:35:04.812: epoch 135:	0.02673648  	0.19691578  	0.10923610  
2023-05-18 11:35:12.230: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 7.416795]
2023-05-18 11:35:12.381: epoch 136:	0.02666591  	0.19644439  	0.10911684  
2023-05-18 11:35:19.837: [iter 137 : loss : 0.1150 = 0.0253 + 0.0831 + 0.0065, time: 7.453978]
2023-05-18 11:35:19.988: epoch 137:	0.02674354  	0.19682142  	0.10918343  
2023-05-18 11:35:27.472: [iter 138 : loss : 0.1147 = 0.0250 + 0.0831 + 0.0065, time: 7.483281]
2023-05-18 11:35:27.623: epoch 138:	0.02673648  	0.19688928  	0.10910422  
2023-05-18 11:35:35.043: [iter 139 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0066, time: 7.418627]
2023-05-18 11:35:35.196: epoch 139:	0.02674354  	0.19686346  	0.10921016  
2023-05-18 11:35:42.828: [iter 140 : loss : 0.1136 = 0.0241 + 0.0830 + 0.0066, time: 7.630447]
2023-05-18 11:35:42.979: epoch 140:	0.02671531  	0.19653620  	0.10905400  
2023-05-18 11:35:50.433: [iter 141 : loss : 0.1145 = 0.0249 + 0.0830 + 0.0066, time: 7.452936]
2023-05-18 11:35:50.585: epoch 141:	0.02661652  	0.19578873  	0.10893358  
2023-05-18 11:35:58.229: [iter 142 : loss : 0.1137 = 0.0242 + 0.0829 + 0.0066, time: 7.641225]
2023-05-18 11:35:58.380: epoch 142:	0.02665885  	0.19600463  	0.10906828  
2023-05-18 11:36:05.860: [iter 143 : loss : 0.1136 = 0.0240 + 0.0829 + 0.0067, time: 7.477393]
2023-05-18 11:36:06.013: epoch 143:	0.02663768  	0.19586307  	0.10897042  
2023-05-18 11:36:13.428: [iter 144 : loss : 0.1130 = 0.0235 + 0.0829 + 0.0067, time: 7.414746]
2023-05-18 11:36:13.579: epoch 144:	0.02671531  	0.19631888  	0.10914180  
2023-05-18 11:36:21.016: [iter 145 : loss : 0.1129 = 0.0233 + 0.0828 + 0.0067, time: 7.436221]
2023-05-18 11:36:21.169: epoch 145:	0.02670120  	0.19631474  	0.10903262  
2023-05-18 11:36:28.659: [iter 146 : loss : 0.1133 = 0.0237 + 0.0828 + 0.0068, time: 7.489063]
2023-05-18 11:36:28.807: epoch 146:	0.02668708  	0.19620650  	0.10901330  
2023-05-18 11:36:36.217: [iter 147 : loss : 0.1130 = 0.0235 + 0.0828 + 0.0068, time: 7.409315]
2023-05-18 11:36:36.369: epoch 147:	0.02668708  	0.19642814  	0.10896680  
2023-05-18 11:36:43.821: [iter 148 : loss : 0.1115 = 0.0220 + 0.0827 + 0.0068, time: 7.449358]
2023-05-18 11:36:43.972: epoch 148:	0.02671530  	0.19661367  	0.10914557  
2023-05-18 11:36:51.444: [iter 149 : loss : 0.1122 = 0.0227 + 0.0827 + 0.0068, time: 7.469817]
2023-05-18 11:36:51.594: epoch 149:	0.02679292  	0.19681840  	0.10931942  
2023-05-18 11:36:59.007: [iter 150 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0069, time: 7.412180]
2023-05-18 11:36:59.159: epoch 150:	0.02678587  	0.19691263  	0.10919934  
2023-05-18 11:37:06.590: [iter 151 : loss : 0.1117 = 0.0222 + 0.0826 + 0.0069, time: 7.428405]
2023-05-18 11:37:06.742: epoch 151:	0.02684232  	0.19748071  	0.10953441  
2023-05-18 11:37:06.742: Find a better model.
2023-05-18 11:37:14.230: [iter 152 : loss : 0.1110 = 0.0215 + 0.0826 + 0.0069, time: 7.486509]
2023-05-18 11:37:14.381: epoch 152:	0.02689876  	0.19721176  	0.10951248  
2023-05-18 11:37:21.788: [iter 153 : loss : 0.1102 = 0.0206 + 0.0826 + 0.0069, time: 7.405788]
2023-05-18 11:37:21.939: epoch 153:	0.02689171  	0.19725657  	0.10955407  
2023-05-18 11:37:29.390: [iter 154 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 7.449335]
2023-05-18 11:37:29.541: epoch 154:	0.02682821  	0.19689730  	0.10954370  
2023-05-18 11:37:37.052: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 7.510153]
2023-05-18 11:37:37.206: epoch 155:	0.02679292  	0.19640145  	0.10940222  
2023-05-18 11:37:44.805: [iter 156 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0070, time: 7.598169]
2023-05-18 11:37:44.957: epoch 156:	0.02678586  	0.19635028  	0.10932198  
2023-05-18 11:37:52.388: [iter 157 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0071, time: 7.428705]
2023-05-18 11:37:52.539: epoch 157:	0.02678586  	0.19627228  	0.10915024  
2023-05-18 11:37:59.995: [iter 158 : loss : 0.1097 = 0.0202 + 0.0824 + 0.0071, time: 7.455742]
2023-05-18 11:38:00.154: epoch 158:	0.02689171  	0.19722360  	0.10942967  
2023-05-18 11:38:07.611: [iter 159 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0071, time: 7.454262]
2023-05-18 11:38:07.765: epoch 159:	0.02679292  	0.19654991  	0.10932615  
2023-05-18 11:38:15.171: [iter 160 : loss : 0.1098 = 0.0203 + 0.0823 + 0.0071, time: 7.405071]
2023-05-18 11:38:15.324: epoch 160:	0.02692699  	0.19756818  	0.10954117  
2023-05-18 11:38:15.324: Find a better model.
2023-05-18 11:38:22.591: [iter 161 : loss : 0.1091 = 0.0196 + 0.0823 + 0.0071, time: 7.266050]
2023-05-18 11:38:22.742: epoch 161:	0.02692699  	0.19728039  	0.10959659  
2023-05-18 11:38:30.182: [iter 162 : loss : 0.1087 = 0.0192 + 0.0823 + 0.0072, time: 7.439335]
2023-05-18 11:38:30.334: epoch 162:	0.02696227  	0.19764468  	0.10972472  
2023-05-18 11:38:30.334: Find a better model.
2023-05-18 11:38:37.779: [iter 163 : loss : 0.1092 = 0.0197 + 0.0823 + 0.0072, time: 7.444772]
2023-05-18 11:38:37.929: epoch 163:	0.02696932  	0.19768117  	0.10972228  
2023-05-18 11:38:37.929: Find a better model.
2023-05-18 11:38:45.338: [iter 164 : loss : 0.1091 = 0.0196 + 0.0822 + 0.0072, time: 7.406312]
2023-05-18 11:38:45.489: epoch 164:	0.02694816  	0.19727701  	0.10966370  
2023-05-18 11:38:52.955: [iter 165 : loss : 0.1086 = 0.0191 + 0.0822 + 0.0072, time: 7.464390]
2023-05-18 11:38:53.105: epoch 165:	0.02687759  	0.19665214  	0.10963012  
2023-05-18 11:39:00.541: [iter 166 : loss : 0.1084 = 0.0190 + 0.0822 + 0.0073, time: 7.434359]
2023-05-18 11:39:00.692: epoch 166:	0.02689170  	0.19727157  	0.10974882  
2023-05-18 11:39:08.190: [iter 167 : loss : 0.1085 = 0.0191 + 0.0821 + 0.0073, time: 7.496648]
2023-05-18 11:39:08.345: epoch 167:	0.02687053  	0.19705634  	0.10973208  
2023-05-18 11:39:15.749: [iter 168 : loss : 0.1080 = 0.0185 + 0.0821 + 0.0073, time: 7.403316]
2023-05-18 11:39:15.901: epoch 168:	0.02689170  	0.19744870  	0.10973404  
2023-05-18 11:39:23.335: [iter 169 : loss : 0.1083 = 0.0188 + 0.0821 + 0.0073, time: 7.432640]
2023-05-18 11:39:23.487: epoch 169:	0.02691287  	0.19734749  	0.10975670  
2023-05-18 11:39:30.965: [iter 170 : loss : 0.1080 = 0.0185 + 0.0821 + 0.0074, time: 7.475584]
2023-05-18 11:39:31.115: epoch 170:	0.02687759  	0.19700560  	0.10969187  
2023-05-18 11:39:38.547: [iter 171 : loss : 0.1082 = 0.0187 + 0.0821 + 0.0074, time: 7.430008]
2023-05-18 11:39:38.698: epoch 171:	0.02687054  	0.19695503  	0.10960639  
2023-05-18 11:39:46.155: [iter 172 : loss : 0.1071 = 0.0177 + 0.0820 + 0.0074, time: 7.454983]
2023-05-18 11:39:46.306: epoch 172:	0.02682820  	0.19637641  	0.10941102  
2023-05-18 11:39:53.729: [iter 173 : loss : 0.1080 = 0.0185 + 0.0820 + 0.0074, time: 7.422055]
2023-05-18 11:39:53.880: epoch 173:	0.02672940  	0.19572333  	0.10915036  
2023-05-18 11:40:01.340: [iter 174 : loss : 0.1077 = 0.0182 + 0.0820 + 0.0075, time: 7.458937]
2023-05-18 11:40:01.492: epoch 174:	0.02684231  	0.19630434  	0.10956448  
2023-05-18 11:40:08.933: [iter 175 : loss : 0.1071 = 0.0177 + 0.0820 + 0.0075, time: 7.440491]
2023-05-18 11:40:09.085: epoch 175:	0.02684231  	0.19639643  	0.10958128  
2023-05-18 11:40:16.561: [iter 176 : loss : 0.1067 = 0.0173 + 0.0820 + 0.0075, time: 7.474196]
2023-05-18 11:40:16.714: epoch 176:	0.02677880  	0.19588774  	0.10943405  
2023-05-18 11:40:24.147: [iter 177 : loss : 0.1071 = 0.0177 + 0.0819 + 0.0075, time: 7.430568]
2023-05-18 11:40:24.300: epoch 177:	0.02674352  	0.19557127  	0.10936968  
2023-05-18 11:40:31.732: [iter 178 : loss : 0.1063 = 0.0169 + 0.0819 + 0.0075, time: 7.430577]
2023-05-18 11:40:31.882: epoch 178:	0.02683525  	0.19606812  	0.10966397  
2023-05-18 11:40:39.368: [iter 179 : loss : 0.1064 = 0.0169 + 0.0819 + 0.0076, time: 7.484617]
2023-05-18 11:40:39.520: epoch 179:	0.02682114  	0.19629215  	0.10961632  
2023-05-18 11:40:46.918: [iter 180 : loss : 0.1064 = 0.0169 + 0.0819 + 0.0076, time: 7.395889]
2023-05-18 11:40:47.069: epoch 180:	0.02678586  	0.19605045  	0.10949507  
2023-05-18 11:40:54.336: [iter 181 : loss : 0.1068 = 0.0174 + 0.0818 + 0.0076, time: 7.265814]
2023-05-18 11:40:54.492: epoch 181:	0.02682819  	0.19614671  	0.10956783  
2023-05-18 11:41:01.928: [iter 182 : loss : 0.1062 = 0.0167 + 0.0818 + 0.0076, time: 7.434875]
2023-05-18 11:41:02.081: epoch 182:	0.02677174  	0.19587016  	0.10943691  
2023-05-18 11:41:09.508: [iter 183 : loss : 0.1064 = 0.0170 + 0.0818 + 0.0077, time: 7.425914]
2023-05-18 11:41:09.661: epoch 183:	0.02676469  	0.19560263  	0.10935653  
2023-05-18 11:41:17.126: [iter 184 : loss : 0.1061 = 0.0166 + 0.0818 + 0.0077, time: 7.463043]
2023-05-18 11:41:17.278: epoch 184:	0.02670117  	0.19491369  	0.10915349  
2023-05-18 11:41:24.714: [iter 185 : loss : 0.1055 = 0.0161 + 0.0817 + 0.0077, time: 7.435559]
2023-05-18 11:41:24.867: epoch 185:	0.02669412  	0.19476023  	0.10894957  
2023-05-18 11:41:32.328: [iter 186 : loss : 0.1058 = 0.0163 + 0.0817 + 0.0077, time: 7.458787]
2023-05-18 11:41:32.478: epoch 186:	0.02669412  	0.19467157  	0.10891768  
2023-05-18 11:41:39.918: [iter 187 : loss : 0.1057 = 0.0163 + 0.0817 + 0.0077, time: 7.437985]
2023-05-18 11:41:40.070: epoch 187:	0.02670823  	0.19476879  	0.10894250  
2023-05-18 11:41:47.522: [iter 188 : loss : 0.1050 = 0.0156 + 0.0817 + 0.0078, time: 7.450779]
2023-05-18 11:41:47.677: epoch 188:	0.02671529  	0.19500624  	0.10900080  
2023-05-18 11:41:47.677: Early stopping is trigger at epoch: 188
2023-05-18 11:41:47.677: best_result@epoch 163:

2023-05-18 11:41:47.677: 		0.0270      	0.1977      	0.1097      
2023-05-18 14:41:45.267: my pid: 2724
2023-05-18 14:41:45.268: model: model.general_recommender.SGL
2023-05-18 14:41:45.268: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 14:41:45.268: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 14:41:48.433: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 14:41:57.448: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.014817]
2023-05-18 14:41:57.614: epoch 1:	0.00151708  	0.01086469  	0.00548080  
2023-05-18 14:41:57.614: Find a better model.
2023-05-18 14:42:06.517: [iter 2 : loss : 0.7712 = 0.6929 + 0.0784 + 0.0000, time: 8.900615]
2023-05-18 14:42:06.721: epoch 2:	0.00246966  	0.01850643  	0.00914529  
2023-05-18 14:42:06.722: Find a better model.
2023-05-18 14:42:15.382: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.659536]
2023-05-18 14:42:15.550: epoch 3:	0.00444537  	0.03263672  	0.01584788  
2023-05-18 14:42:15.550: Find a better model.
2023-05-18 14:42:24.354: [iter 4 : loss : 0.7707 = 0.6922 + 0.0785 + 0.0000, time: 8.803151]
2023-05-18 14:42:24.523: epoch 4:	0.00723957  	0.05302750  	0.02515498  
2023-05-18 14:42:24.523: Find a better model.
2023-05-18 14:42:33.413: [iter 5 : loss : 0.7699 = 0.6912 + 0.0787 + 0.0000, time: 8.888256]
2023-05-18 14:42:33.574: epoch 5:	0.01080299  	0.07783169  	0.03742677  
2023-05-18 14:42:33.575: Find a better model.
2023-05-18 14:42:42.688: [iter 6 : loss : 0.7681 = 0.6891 + 0.0790 + 0.0000, time: 9.111570]
2023-05-18 14:42:42.852: epoch 6:	0.01454291  	0.10454502  	0.05080798  
2023-05-18 14:42:42.852: Find a better model.
2023-05-18 14:42:52.588: [iter 7 : loss : 0.7634 = 0.6837 + 0.0796 + 0.0000, time: 9.732345]
2023-05-18 14:42:52.871: epoch 7:	0.01700558  	0.12312500  	0.06098300  
2023-05-18 14:42:52.871: Find a better model.
2023-05-18 14:43:02.594: [iter 8 : loss : 0.7516 = 0.6704 + 0.0811 + 0.0001, time: 9.716036]
2023-05-18 14:43:02.886: epoch 8:	0.01848743  	0.13506109  	0.06749556  
2023-05-18 14:43:02.887: Find a better model.
2023-05-18 14:43:11.583: [iter 9 : loss : 0.7234 = 0.6390 + 0.0843 + 0.0001, time: 8.693348]
2023-05-18 14:43:11.742: epoch 9:	0.01884732  	0.13815486  	0.06878918  
2023-05-18 14:43:11.742: Find a better model.
2023-05-18 14:43:19.870: [iter 10 : loss : 0.6701 = 0.5804 + 0.0895 + 0.0002, time: 8.127006]
2023-05-18 14:43:20.191: epoch 10:	0.01854389  	0.13671155  	0.06792032  
2023-05-18 14:43:28.359: [iter 11 : loss : 0.5960 = 0.5007 + 0.0949 + 0.0003, time: 8.167003]
2023-05-18 14:43:28.516: epoch 11:	0.01831809  	0.13570382  	0.06768335  
2023-05-18 14:43:37.850: [iter 12 : loss : 0.5228 = 0.4233 + 0.0989 + 0.0005, time: 9.331011]
2023-05-18 14:43:38.130: epoch 12:	0.01829692  	0.13532187  	0.06769134  
2023-05-18 14:43:45.719: [iter 13 : loss : 0.4671 = 0.3652 + 0.1012 + 0.0007, time: 7.588032]
2023-05-18 14:43:45.881: epoch 13:	0.01830398  	0.13562101  	0.06801090  
2023-05-18 14:43:54.174: [iter 14 : loss : 0.4249 = 0.3218 + 0.1023 + 0.0008, time: 8.291005]
2023-05-18 14:43:54.330: epoch 14:	0.01846628  	0.13723066  	0.06900585  
2023-05-18 14:44:02.797: [iter 15 : loss : 0.3959 = 0.2922 + 0.1027 + 0.0009, time: 8.464034]
2023-05-18 14:44:02.954: epoch 15:	0.01867797  	0.13825366  	0.06976072  
2023-05-18 14:44:02.955: Find a better model.
2023-05-18 14:44:10.762: [iter 16 : loss : 0.3717 = 0.2678 + 0.1028 + 0.0011, time: 7.805846]
2023-05-18 14:44:10.920: epoch 16:	0.01888261  	0.13968457  	0.07067303  
2023-05-18 14:44:10.920: Find a better model.
2023-05-18 14:44:20.314: [iter 17 : loss : 0.3542 = 0.2503 + 0.1027 + 0.0012, time: 9.390858]
2023-05-18 14:44:20.604: epoch 17:	0.01923543  	0.14232676  	0.07196676  
2023-05-18 14:44:20.605: Find a better model.
2023-05-18 14:44:28.891: [iter 18 : loss : 0.3382 = 0.2345 + 0.1024 + 0.0013, time: 8.285026]
2023-05-18 14:44:29.039: epoch 18:	0.01934834  	0.14260612  	0.07244381  
2023-05-18 14:44:29.039: Find a better model.
2023-05-18 14:44:36.977: [iter 19 : loss : 0.3235 = 0.2200 + 0.1021 + 0.0014, time: 7.936042]
2023-05-18 14:44:37.141: epoch 19:	0.01958121  	0.14401183  	0.07336705  
2023-05-18 14:44:37.142: Find a better model.
2023-05-18 14:44:45.703: [iter 20 : loss : 0.3136 = 0.2104 + 0.1017 + 0.0015, time: 8.560234]
2023-05-18 14:44:45.869: epoch 20:	0.01973645  	0.14519037  	0.07397036  
2023-05-18 14:44:45.869: Find a better model.
2023-05-18 14:44:55.237: [iter 21 : loss : 0.3038 = 0.2009 + 0.1013 + 0.0016, time: 9.364703]
2023-05-18 14:44:55.538: epoch 21:	0.01995521  	0.14662893  	0.07489604  
2023-05-18 14:44:55.538: Find a better model.
2023-05-18 14:45:04.987: [iter 22 : loss : 0.2951 = 0.1926 + 0.1009 + 0.0016, time: 9.446005]
2023-05-18 14:45:05.287: epoch 22:	0.02022335  	0.14873885  	0.07576852  
2023-05-18 14:45:05.287: Find a better model.
2023-05-18 14:45:13.765: [iter 23 : loss : 0.2865 = 0.1844 + 0.1004 + 0.0017, time: 8.477006]
2023-05-18 14:45:13.923: epoch 23:	0.02044916  	0.14998856  	0.07659583  
2023-05-18 14:45:13.923: Find a better model.
2023-05-18 14:45:22.188: [iter 24 : loss : 0.2802 = 0.1784 + 0.1000 + 0.0018, time: 8.264333]
2023-05-18 14:45:22.357: epoch 24:	0.02063967  	0.15142980  	0.07727514  
2023-05-18 14:45:22.357: Find a better model.
2023-05-18 14:45:30.555: [iter 25 : loss : 0.2733 = 0.1718 + 0.0996 + 0.0019, time: 8.197031]
2023-05-18 14:45:30.711: epoch 25:	0.02083020  	0.15287085  	0.07791506  
2023-05-18 14:45:30.711: Find a better model.
2023-05-18 14:45:40.056: [iter 26 : loss : 0.2694 = 0.1683 + 0.0991 + 0.0019, time: 9.343009]
2023-05-18 14:45:40.350: epoch 26:	0.02083726  	0.15296139  	0.07818685  
2023-05-18 14:45:40.350: Find a better model.
2023-05-18 14:45:47.966: [iter 27 : loss : 0.2617 = 0.1611 + 0.0987 + 0.0020, time: 7.614993]
2023-05-18 14:45:48.127: epoch 27:	0.02109129  	0.15468869  	0.07924853  
2023-05-18 14:45:48.127: Find a better model.
2023-05-18 14:45:56.711: [iter 28 : loss : 0.2567 = 0.1562 + 0.0984 + 0.0021, time: 8.582131]
2023-05-18 14:45:56.869: epoch 28:	0.02129593  	0.15641735  	0.08003849  
2023-05-18 14:45:56.869: Find a better model.
2023-05-18 14:46:05.304: [iter 29 : loss : 0.2521 = 0.1521 + 0.0980 + 0.0021, time: 8.434008]
2023-05-18 14:46:05.460: epoch 29:	0.02143001  	0.15729479  	0.08069704  
2023-05-18 14:46:05.460: Find a better model.
2023-05-18 14:46:13.331: [iter 30 : loss : 0.2457 = 0.1461 + 0.0975 + 0.0022, time: 7.869385]
2023-05-18 14:46:13.526: epoch 30:	0.02165582  	0.15904944  	0.08166350  
2023-05-18 14:46:13.526: Find a better model.
2023-05-18 14:46:23.019: [iter 31 : loss : 0.2421 = 0.1427 + 0.0971 + 0.0023, time: 9.491827]
2023-05-18 14:46:23.310: epoch 31:	0.02191691  	0.16102976  	0.08233619  
2023-05-18 14:46:23.310: Find a better model.
2023-05-18 14:46:31.650: [iter 32 : loss : 0.2365 = 0.1375 + 0.0968 + 0.0023, time: 8.337015]
2023-05-18 14:46:31.803: epoch 32:	0.02207215  	0.16213870  	0.08301917  
2023-05-18 14:46:31.803: Find a better model.
2023-05-18 14:46:39.731: [iter 33 : loss : 0.2340 = 0.1353 + 0.0964 + 0.0024, time: 7.926993]
2023-05-18 14:46:39.892: epoch 33:	0.02221328  	0.16348736  	0.08382656  
2023-05-18 14:46:39.892: Find a better model.
2023-05-18 14:46:48.425: [iter 34 : loss : 0.2296 = 0.1312 + 0.0960 + 0.0024, time: 8.531495]
2023-05-18 14:46:48.665: epoch 34:	0.02237558  	0.16456188  	0.08443110  
2023-05-18 14:46:48.665: Find a better model.
2023-05-18 14:46:57.980: [iter 35 : loss : 0.2260 = 0.1278 + 0.0957 + 0.0025, time: 9.313991]
2023-05-18 14:46:58.275: epoch 35:	0.02246025  	0.16552109  	0.08494786  
2023-05-18 14:46:58.275: Find a better model.
2023-05-18 14:47:07.722: [iter 36 : loss : 0.2228 = 0.1248 + 0.0954 + 0.0025, time: 9.444312]
2023-05-18 14:47:08.003: epoch 36:	0.02254493  	0.16639881  	0.08556906  
2023-05-18 14:47:08.003: Find a better model.
2023-05-18 14:47:16.297: [iter 37 : loss : 0.2188 = 0.1211 + 0.0951 + 0.0026, time: 8.291992]
2023-05-18 14:47:16.463: epoch 37:	0.02260138  	0.16677660  	0.08609246  
2023-05-18 14:47:16.463: Find a better model.
2023-05-18 14:47:24.498: [iter 38 : loss : 0.2171 = 0.1197 + 0.0947 + 0.0027, time: 8.032993]
2023-05-18 14:47:24.656: epoch 38:	0.02280602  	0.16836599  	0.08692984  
2023-05-18 14:47:24.656: Find a better model.
2023-05-18 14:47:32.907: [iter 39 : loss : 0.2126 = 0.1155 + 0.0944 + 0.0027, time: 8.249155]
2023-05-18 14:47:33.061: epoch 39:	0.02288364  	0.16898100  	0.08751322  
2023-05-18 14:47:33.061: Find a better model.
2023-05-18 14:47:42.458: [iter 40 : loss : 0.2094 = 0.1125 + 0.0941 + 0.0028, time: 9.394396]
2023-05-18 14:47:42.739: epoch 40:	0.02300360  	0.16990525  	0.08802187  
2023-05-18 14:47:42.739: Find a better model.
2023-05-18 14:47:50.414: [iter 41 : loss : 0.2077 = 0.1110 + 0.0939 + 0.0028, time: 7.673993]
2023-05-18 14:47:50.582: epoch 41:	0.02319413  	0.17123865  	0.08871765  
2023-05-18 14:47:50.582: Find a better model.
2023-05-18 14:47:59.139: [iter 42 : loss : 0.2054 = 0.1090 + 0.0936 + 0.0029, time: 8.555960]
2023-05-18 14:47:59.284: epoch 42:	0.02330704  	0.17204694  	0.08939437  
2023-05-18 14:47:59.284: Find a better model.
2023-05-18 14:48:07.604: [iter 43 : loss : 0.2016 = 0.1054 + 0.0933 + 0.0029, time: 8.317992]
2023-05-18 14:48:07.750: epoch 43:	0.02336348  	0.17247948  	0.08973563  
2023-05-18 14:48:07.750: Find a better model.
2023-05-18 14:48:15.686: [iter 44 : loss : 0.1982 = 0.1022 + 0.0930 + 0.0030, time: 7.934993]
2023-05-18 14:48:15.843: epoch 44:	0.02340582  	0.17240071  	0.08996885  
2023-05-18 14:48:25.376: [iter 45 : loss : 0.1962 = 0.1004 + 0.0928 + 0.0030, time: 9.528991]
2023-05-18 14:48:25.667: epoch 45:	0.02358929  	0.17377529  	0.09072419  
2023-05-18 14:48:25.667: Find a better model.
2023-05-18 14:48:33.935: [iter 46 : loss : 0.1937 = 0.0982 + 0.0925 + 0.0031, time: 8.266955]
2023-05-18 14:48:34.163: epoch 46:	0.02361752  	0.17431781  	0.09113786  
2023-05-18 14:48:34.163: Find a better model.
2023-05-18 14:48:42.080: [iter 47 : loss : 0.1928 = 0.0975 + 0.0922 + 0.0031, time: 7.913992]
2023-05-18 14:48:42.245: epoch 47:	0.02377276  	0.17504314  	0.09177396  
2023-05-18 14:48:42.245: Find a better model.
2023-05-18 14:48:50.931: [iter 48 : loss : 0.1886 = 0.0934 + 0.0920 + 0.0032, time: 8.684992]
2023-05-18 14:48:51.098: epoch 48:	0.02385037  	0.17552759  	0.09211086  
2023-05-18 14:48:51.099: Find a better model.
2023-05-18 14:49:00.614: [iter 49 : loss : 0.1856 = 0.0906 + 0.0918 + 0.0032, time: 9.513021]
2023-05-18 14:49:00.904: epoch 49:	0.02394211  	0.17611332  	0.09270690  
2023-05-18 14:49:00.904: Find a better model.
2023-05-18 14:49:10.352: [iter 50 : loss : 0.1849 = 0.0901 + 0.0916 + 0.0033, time: 9.444053]
2023-05-18 14:49:10.636: epoch 50:	0.02402678  	0.17680638  	0.09310234  
2023-05-18 14:49:10.636: Find a better model.
2023-05-18 14:49:19.062: [iter 51 : loss : 0.1817 = 0.0870 + 0.0914 + 0.0033, time: 8.424143]
2023-05-18 14:49:19.220: epoch 51:	0.02406207  	0.17723830  	0.09347535  
2023-05-18 14:49:19.220: Find a better model.
2023-05-18 14:49:27.718: [iter 52 : loss : 0.1819 = 0.0874 + 0.0911 + 0.0034, time: 8.495020]
2023-05-18 14:49:28.161: epoch 52:	0.02412558  	0.17773561  	0.09409685  
2023-05-18 14:49:28.161: Find a better model.
2023-05-18 14:49:36.216: [iter 53 : loss : 0.1798 = 0.0854 + 0.0909 + 0.0034, time: 8.054324]
2023-05-18 14:49:36.373: epoch 53:	0.02418203  	0.17807281  	0.09456509  
2023-05-18 14:49:36.373: Find a better model.
2023-05-18 14:49:45.809: [iter 54 : loss : 0.1773 = 0.0832 + 0.0907 + 0.0035, time: 9.434001]
2023-05-18 14:49:46.095: epoch 54:	0.02432316  	0.17869630  	0.09494620  
2023-05-18 14:49:46.096: Find a better model.
2023-05-18 14:49:54.082: [iter 55 : loss : 0.1757 = 0.0816 + 0.0906 + 0.0035, time: 7.983862]
2023-05-18 14:49:54.240: epoch 55:	0.02437961  	0.17957638  	0.09508757  
2023-05-18 14:49:54.240: Find a better model.
2023-05-18 14:50:02.827: [iter 56 : loss : 0.1740 = 0.0801 + 0.0904 + 0.0035, time: 8.586009]
2023-05-18 14:50:02.983: epoch 56:	0.02442901  	0.18005317  	0.09551708  
2023-05-18 14:50:02.983: Find a better model.
2023-05-18 14:50:11.743: [iter 57 : loss : 0.1721 = 0.0784 + 0.0902 + 0.0036, time: 8.758198]
2023-05-18 14:50:11.955: epoch 57:	0.02445724  	0.18027751  	0.09587559  
2023-05-18 14:50:11.956: Find a better model.
2023-05-18 14:50:21.349: [iter 58 : loss : 0.1701 = 0.0765 + 0.0900 + 0.0036, time: 9.387030]
2023-05-18 14:50:21.639: epoch 58:	0.02451369  	0.18061548  	0.09620290  
2023-05-18 14:50:21.639: Find a better model.
2023-05-18 14:50:31.261: [iter 59 : loss : 0.1690 = 0.0756 + 0.0898 + 0.0037, time: 9.617989]
2023-05-18 14:50:31.570: epoch 59:	0.02449957  	0.18025413  	0.09630597  
2023-05-18 14:50:40.058: [iter 60 : loss : 0.1676 = 0.0742 + 0.0896 + 0.0037, time: 8.485992]
2023-05-18 14:50:40.222: epoch 60:	0.02459836  	0.18111147  	0.09684039  
2023-05-18 14:50:40.223: Find a better model.
2023-05-18 14:50:48.249: [iter 61 : loss : 0.1662 = 0.0730 + 0.0894 + 0.0038, time: 8.024532]
2023-05-18 14:50:48.409: epoch 61:	0.02464070  	0.18121859  	0.09711654  
2023-05-18 14:50:48.409: Find a better model.
2023-05-18 14:50:56.900: [iter 62 : loss : 0.1646 = 0.0715 + 0.0893 + 0.0038, time: 8.488703]
2023-05-18 14:50:57.067: epoch 62:	0.02464070  	0.18129769  	0.09721477  
2023-05-18 14:50:57.067: Find a better model.
2023-05-18 14:51:06.533: [iter 63 : loss : 0.1631 = 0.0702 + 0.0891 + 0.0039, time: 9.463319]
2023-05-18 14:51:06.829: epoch 63:	0.02472538  	0.18206136  	0.09773231  
2023-05-18 14:51:06.829: Find a better model.
2023-05-18 14:51:14.556: [iter 64 : loss : 0.1622 = 0.0694 + 0.0890 + 0.0039, time: 7.725003]
2023-05-18 14:51:14.719: epoch 64:	0.02479594  	0.18232076  	0.09802676  
2023-05-18 14:51:14.719: Find a better model.
2023-05-18 14:51:23.414: [iter 65 : loss : 0.1610 = 0.0683 + 0.0888 + 0.0039, time: 8.693517]
2023-05-18 14:51:23.578: epoch 65:	0.02480300  	0.18246111  	0.09824780  
2023-05-18 14:51:23.578: Find a better model.
2023-05-18 14:51:31.917: [iter 66 : loss : 0.1592 = 0.0665 + 0.0887 + 0.0040, time: 8.338037]
2023-05-18 14:51:32.073: epoch 66:	0.02484534  	0.18288723  	0.09877779  
2023-05-18 14:51:32.074: Find a better model.
2023-05-18 14:51:40.018: [iter 67 : loss : 0.1578 = 0.0653 + 0.0885 + 0.0040, time: 7.942072]
2023-05-18 14:51:40.174: epoch 67:	0.02484534  	0.18281752  	0.09885409  
2023-05-18 14:51:49.659: [iter 68 : loss : 0.1573 = 0.0649 + 0.0884 + 0.0041, time: 9.481895]
2023-05-18 14:51:49.945: epoch 68:	0.02492296  	0.18321739  	0.09919015  
2023-05-18 14:51:49.945: Find a better model.
2023-05-18 14:51:58.278: [iter 69 : loss : 0.1555 = 0.0631 + 0.0882 + 0.0041, time: 8.331418]
2023-05-18 14:51:58.502: epoch 69:	0.02495824  	0.18345755  	0.09941278  
2023-05-18 14:51:58.503: Find a better model.
2023-05-18 14:52:06.697: [iter 70 : loss : 0.1538 = 0.0616 + 0.0881 + 0.0041, time: 8.191063]
2023-05-18 14:52:06.860: epoch 70:	0.02497235  	0.18335798  	0.09958869  
2023-05-18 14:52:15.462: [iter 71 : loss : 0.1522 = 0.0600 + 0.0879 + 0.0042, time: 8.599993]
2023-05-18 14:52:15.683: epoch 71:	0.02505703  	0.18427572  	0.09984820  
2023-05-18 14:52:15.683: Find a better model.
2023-05-18 14:52:25.032: [iter 72 : loss : 0.1521 = 0.0600 + 0.0879 + 0.0042, time: 9.345996]
2023-05-18 14:52:25.317: epoch 72:	0.02521933  	0.18512756  	0.10019876  
2023-05-18 14:52:25.317: Find a better model.
2023-05-18 14:52:34.684: [iter 73 : loss : 0.1505 = 0.0585 + 0.0877 + 0.0043, time: 9.366011]
2023-05-18 14:52:34.967: epoch 73:	0.02524756  	0.18547575  	0.10034997  
2023-05-18 14:52:34.967: Find a better model.
2023-05-18 14:52:43.391: [iter 74 : loss : 0.1496 = 0.0577 + 0.0876 + 0.0043, time: 8.422060]
2023-05-18 14:52:43.555: epoch 74:	0.02537458  	0.18649621  	0.10079009  
2023-05-18 14:52:43.555: Find a better model.
2023-05-18 14:52:51.900: [iter 75 : loss : 0.1487 = 0.0569 + 0.0875 + 0.0044, time: 8.343992]
2023-05-18 14:52:52.359: epoch 75:	0.02539574  	0.18630293  	0.10098179  
2023-05-18 14:53:00.557: [iter 76 : loss : 0.1478 = 0.0560 + 0.0873 + 0.0044, time: 8.184160]
2023-05-18 14:53:00.714: epoch 76:	0.02540280  	0.18639614  	0.10125373  
2023-05-18 14:53:10.062: [iter 77 : loss : 0.1468 = 0.0551 + 0.0872 + 0.0044, time: 9.346014]
2023-05-18 14:53:10.314: epoch 77:	0.02543102  	0.18667731  	0.10137947  
2023-05-18 14:53:10.314: Find a better model.
2023-05-18 14:53:18.087: [iter 78 : loss : 0.1458 = 0.0542 + 0.0871 + 0.0045, time: 7.770996]
2023-05-18 14:53:18.245: epoch 78:	0.02543808  	0.18665530  	0.10163639  
2023-05-18 14:53:26.575: [iter 79 : loss : 0.1446 = 0.0531 + 0.0870 + 0.0045, time: 8.328001]
2023-05-18 14:53:26.729: epoch 79:	0.02548748  	0.18697733  	0.10193235  
2023-05-18 14:53:26.729: Find a better model.
2023-05-18 14:53:35.339: [iter 80 : loss : 0.1439 = 0.0525 + 0.0869 + 0.0046, time: 8.609478]
2023-05-18 14:53:35.500: epoch 80:	0.02562155  	0.18803239  	0.10252542  
2023-05-18 14:53:35.500: Find a better model.
2023-05-18 14:53:45.575: [iter 81 : loss : 0.1436 = 0.0522 + 0.0868 + 0.0046, time: 10.072027]
2023-05-18 14:53:45.834: epoch 81:	0.02564978  	0.18820979  	0.10267607  
2023-05-18 14:53:45.834: Find a better model.
2023-05-18 14:53:55.369: [iter 82 : loss : 0.1422 = 0.0509 + 0.0867 + 0.0046, time: 9.533016]
2023-05-18 14:53:55.660: epoch 82:	0.02574857  	0.18894885  	0.10317465  
2023-05-18 14:53:55.660: Find a better model.
2023-05-18 14:54:04.387: [iter 83 : loss : 0.1412 = 0.0499 + 0.0866 + 0.0047, time: 8.725727]
2023-05-18 14:54:04.587: epoch 83:	0.02579091  	0.18943407  	0.10345211  
2023-05-18 14:54:04.587: Find a better model.
2023-05-18 14:54:12.753: [iter 84 : loss : 0.1413 = 0.0501 + 0.0865 + 0.0047, time: 8.163604]
2023-05-18 14:54:12.917: epoch 84:	0.02579797  	0.18937103  	0.10354897  
2023-05-18 14:54:21.344: [iter 85 : loss : 0.1401 = 0.0489 + 0.0864 + 0.0048, time: 8.425951]
2023-05-18 14:54:21.506: epoch 85:	0.02584735  	0.18963513  	0.10371337  
2023-05-18 14:54:21.506: Find a better model.
2023-05-18 14:54:30.846: [iter 86 : loss : 0.1399 = 0.0489 + 0.0863 + 0.0048, time: 9.337331]
2023-05-18 14:54:31.132: epoch 86:	0.02585441  	0.18989553  	0.10371792  
2023-05-18 14:54:31.132: Find a better model.
2023-05-18 14:54:38.884: [iter 87 : loss : 0.1372 = 0.0462 + 0.0862 + 0.0048, time: 7.751349]
2023-05-18 14:54:39.045: epoch 87:	0.02579091  	0.18940982  	0.10368926  
2023-05-18 14:54:47.752: [iter 88 : loss : 0.1364 = 0.0454 + 0.0861 + 0.0049, time: 8.705032]
2023-05-18 14:54:47.907: epoch 88:	0.02588264  	0.19002873  	0.10377709  
2023-05-18 14:54:47.908: Find a better model.
2023-05-18 14:54:56.352: [iter 89 : loss : 0.1362 = 0.0453 + 0.0860 + 0.0049, time: 8.442004]
2023-05-18 14:54:56.513: epoch 89:	0.02587558  	0.19001588  	0.10409734  
2023-05-18 14:55:04.582: [iter 90 : loss : 0.1367 = 0.0458 + 0.0860 + 0.0049, time: 8.067010]
2023-05-18 14:55:04.731: epoch 90:	0.02608728  	0.19142601  	0.10461121  
2023-05-18 14:55:04.731: Find a better model.
2023-05-18 14:55:14.107: [iter 91 : loss : 0.1355 = 0.0447 + 0.0858 + 0.0050, time: 9.372438]
2023-05-18 14:55:14.389: epoch 91:	0.02598143  	0.19042245  	0.10433023  
2023-05-18 14:55:22.608: [iter 92 : loss : 0.1347 = 0.0439 + 0.0858 + 0.0050, time: 8.217002]
2023-05-18 14:55:22.756: epoch 92:	0.02598143  	0.19051282  	0.10432772  
2023-05-18 14:55:30.773: [iter 93 : loss : 0.1349 = 0.0442 + 0.0857 + 0.0051, time: 8.016007]
2023-05-18 14:55:30.942: epoch 93:	0.02595320  	0.19020148  	0.10463488  
2023-05-18 14:55:39.745: [iter 94 : loss : 0.1327 = 0.0420 + 0.0856 + 0.0051, time: 8.802007]
2023-05-18 14:55:39.914: epoch 94:	0.02598142  	0.19047943  	0.10451993  
2023-05-18 14:55:49.300: [iter 95 : loss : 0.1323 = 0.0417 + 0.0855 + 0.0051, time: 9.383021]
2023-05-18 14:55:49.589: epoch 95:	0.02600259  	0.19060770  	0.10471176  
2023-05-18 14:55:58.998: [iter 96 : loss : 0.1320 = 0.0414 + 0.0854 + 0.0052, time: 9.404721]
2023-05-18 14:55:59.280: epoch 96:	0.02605905  	0.19093964  	0.10490890  
2023-05-18 14:56:07.738: [iter 97 : loss : 0.1303 = 0.0398 + 0.0853 + 0.0052, time: 8.457181]
2023-05-18 14:56:07.904: epoch 97:	0.02607316  	0.19086117  	0.10499189  
2023-05-18 14:56:16.104: [iter 98 : loss : 0.1313 = 0.0408 + 0.0853 + 0.0052, time: 8.197993]
2023-05-18 14:56:16.259: epoch 98:	0.02609433  	0.19120185  	0.10511757  
2023-05-18 14:56:24.496: [iter 99 : loss : 0.1300 = 0.0395 + 0.0852 + 0.0053, time: 8.236055]
2023-05-18 14:56:24.653: epoch 99:	0.02612256  	0.19111350  	0.10512062  
2023-05-18 14:56:34.040: [iter 100 : loss : 0.1294 = 0.0390 + 0.0852 + 0.0053, time: 9.382012]
2023-05-18 14:56:34.329: epoch 100:	0.02612255  	0.19133522  	0.10535312  
2023-05-18 14:56:41.915: [iter 101 : loss : 0.1291 = 0.0386 + 0.0851 + 0.0053, time: 7.585088]
2023-05-18 14:56:42.077: epoch 101:	0.02612255  	0.19136952  	0.10526204  
2023-05-18 14:56:50.735: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 8.655992]
2023-05-18 14:56:50.891: epoch 102:	0.02612961  	0.19140661  	0.10545965  
2023-05-18 14:56:59.344: [iter 103 : loss : 0.1278 = 0.0375 + 0.0850 + 0.0054, time: 8.452407]
2023-05-18 14:56:59.500: epoch 103:	0.02615783  	0.19165954  	0.10569710  
2023-05-18 14:56:59.500: Find a better model.
2023-05-18 14:57:07.295: [iter 104 : loss : 0.1282 = 0.0379 + 0.0848 + 0.0055, time: 7.794017]
2023-05-18 14:57:07.454: epoch 104:	0.02621429  	0.19205666  	0.10586633  
2023-05-18 14:57:07.454: Find a better model.
2023-05-18 14:57:16.838: [iter 105 : loss : 0.1274 = 0.0372 + 0.0848 + 0.0055, time: 9.379039]
2023-05-18 14:57:17.126: epoch 105:	0.02615784  	0.19159101  	0.10561877  
2023-05-18 14:57:25.343: [iter 106 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 8.215508]
2023-05-18 14:57:25.505: epoch 106:	0.02617901  	0.19169754  	0.10574979  
2023-05-18 14:57:33.490: [iter 107 : loss : 0.1261 = 0.0358 + 0.0847 + 0.0055, time: 7.982255]
2023-05-18 14:57:33.671: epoch 107:	0.02614373  	0.19146876  	0.10573087  
2023-05-18 14:57:42.429: [iter 108 : loss : 0.1258 = 0.0356 + 0.0846 + 0.0056, time: 8.756025]
2023-05-18 14:57:42.670: epoch 108:	0.02609433  	0.19140001  	0.10571451  
2023-05-18 14:57:52.023: [iter 109 : loss : 0.1246 = 0.0344 + 0.0845 + 0.0056, time: 9.351097]
2023-05-18 14:57:52.310: epoch 109:	0.02608727  	0.19141905  	0.10573620  
2023-05-18 14:58:01.625: [iter 110 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0057, time: 9.313042]
2023-05-18 14:58:01.921: epoch 110:	0.02615784  	0.19163840  	0.10581785  
2023-05-18 14:58:10.282: [iter 111 : loss : 0.1239 = 0.0337 + 0.0844 + 0.0057, time: 8.359002]
2023-05-18 14:58:10.449: epoch 111:	0.02622135  	0.19251610  	0.10622290  
2023-05-18 14:58:10.449: Find a better model.
2023-05-18 14:58:18.493: [iter 112 : loss : 0.1236 = 0.0336 + 0.0843 + 0.0057, time: 8.042992]
2023-05-18 14:58:18.654: epoch 112:	0.02624252  	0.19270943  	0.10635817  
2023-05-18 14:58:18.654: Find a better model.
2023-05-18 14:58:26.879: [iter 113 : loss : 0.1238 = 0.0337 + 0.0843 + 0.0058, time: 8.224018]
2023-05-18 14:58:27.034: epoch 113:	0.02623546  	0.19274838  	0.10628431  
2023-05-18 14:58:27.034: Find a better model.
2023-05-18 14:58:36.368: [iter 114 : loss : 0.1227 = 0.0327 + 0.0842 + 0.0058, time: 9.331161]
2023-05-18 14:58:36.668: epoch 114:	0.02623546  	0.19240287  	0.10623452  
2023-05-18 14:58:44.300: [iter 115 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 7.631017]
2023-05-18 14:58:44.465: epoch 115:	0.02619312  	0.19236781  	0.10631313  
2023-05-18 14:58:53.097: [iter 116 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0058, time: 8.630037]
2023-05-18 14:58:53.250: epoch 116:	0.02619312  	0.19235821  	0.10631896  
2023-05-18 14:59:01.593: [iter 117 : loss : 0.1212 = 0.0313 + 0.0840 + 0.0059, time: 8.341991]
2023-05-18 14:59:01.768: epoch 117:	0.02614372  	0.19201435  	0.10636082  
2023-05-18 14:59:09.643: [iter 118 : loss : 0.1215 = 0.0315 + 0.0841 + 0.0059, time: 7.873855]
2023-05-18 14:59:09.811: epoch 118:	0.02619312  	0.19220057  	0.10649736  
2023-05-18 14:59:19.173: [iter 119 : loss : 0.1202 = 0.0304 + 0.0839 + 0.0059, time: 9.360006]
2023-05-18 14:59:19.470: epoch 119:	0.02620018  	0.19225359  	0.10670286  
2023-05-18 14:59:27.359: [iter 120 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0060, time: 7.888003]
2023-05-18 14:59:27.522: epoch 120:	0.02623546  	0.19280764  	0.10664228  
2023-05-18 14:59:27.523: Find a better model.
2023-05-18 14:59:35.628: [iter 121 : loss : 0.1200 = 0.0301 + 0.0838 + 0.0060, time: 8.104844]
2023-05-18 14:59:35.783: epoch 121:	0.02627075  	0.19284049  	0.10686969  
2023-05-18 14:59:35.783: Find a better model.
2023-05-18 14:59:44.226: [iter 122 : loss : 0.1197 = 0.0299 + 0.0838 + 0.0060, time: 8.441011]
2023-05-18 14:59:44.381: epoch 122:	0.02618607  	0.19263805  	0.10674581  
2023-05-18 14:59:54.096: [iter 123 : loss : 0.1197 = 0.0298 + 0.0838 + 0.0061, time: 9.710188]
2023-05-18 14:59:54.396: epoch 123:	0.02622841  	0.19266649  	0.10669762  
2023-05-18 15:00:03.675: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 9.277381]
2023-05-18 15:00:03.934: epoch 124:	0.02617901  	0.19249727  	0.10676373  
2023-05-18 15:00:12.309: [iter 125 : loss : 0.1180 = 0.0282 + 0.0837 + 0.0061, time: 8.374052]
2023-05-18 15:00:12.467: epoch 125:	0.02622135  	0.19307768  	0.10694100  
2023-05-18 15:00:12.467: Find a better model.
2023-05-18 15:00:20.401: [iter 126 : loss : 0.1182 = 0.0284 + 0.0837 + 0.0062, time: 7.933136]
2023-05-18 15:00:20.568: epoch 126:	0.02624252  	0.19325095  	0.10706343  
2023-05-18 15:00:20.568: Find a better model.
2023-05-18 15:00:29.035: [iter 127 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 8.464006]
2023-05-18 15:00:29.208: epoch 127:	0.02624252  	0.19328359  	0.10712718  
2023-05-18 15:00:29.208: Find a better model.
2023-05-18 15:00:38.563: [iter 128 : loss : 0.1185 = 0.0287 + 0.0835 + 0.0062, time: 9.353962]
2023-05-18 15:00:38.845: epoch 128:	0.02621429  	0.19275770  	0.10701032  
2023-05-18 15:00:47.870: [iter 129 : loss : 0.1171 = 0.0274 + 0.0835 + 0.0063, time: 9.023144]
2023-05-18 15:00:48.046: epoch 129:	0.02626369  	0.19324082  	0.10708521  
2023-05-18 15:00:56.462: [iter 130 : loss : 0.1174 = 0.0276 + 0.0834 + 0.0063, time: 8.413005]
2023-05-18 15:00:56.682: epoch 130:	0.02627074  	0.19328281  	0.10691377  
2023-05-18 15:01:05.313: [iter 131 : loss : 0.1166 = 0.0269 + 0.0834 + 0.0063, time: 8.630020]
2023-05-18 15:01:05.473: epoch 131:	0.02624957  	0.19294749  	0.10688309  
2023-05-18 15:01:13.395: [iter 132 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0063, time: 7.921041]
2023-05-18 15:01:13.554: epoch 132:	0.02626369  	0.19320194  	0.10704259  
2023-05-18 15:01:22.903: [iter 133 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 9.347001]
2023-05-18 15:01:23.170: epoch 133:	0.02623546  	0.19322373  	0.10703216  
2023-05-18 15:01:30.658: [iter 134 : loss : 0.1159 = 0.0263 + 0.0833 + 0.0064, time: 7.486168]
2023-05-18 15:01:30.821: epoch 134:	0.02626368  	0.19322297  	0.10734712  
2023-05-18 15:01:39.178: [iter 135 : loss : 0.1157 = 0.0260 + 0.0832 + 0.0064, time: 8.353022]
2023-05-18 15:01:39.333: epoch 135:	0.02624957  	0.19342704  	0.10728729  
2023-05-18 15:01:39.333: Find a better model.
2023-05-18 15:01:47.629: [iter 136 : loss : 0.1155 = 0.0259 + 0.0832 + 0.0065, time: 8.293001]
2023-05-18 15:01:47.787: epoch 136:	0.02627074  	0.19338077  	0.10746279  
2023-05-18 15:01:55.591: [iter 137 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 7.803319]
2023-05-18 15:01:55.738: epoch 137:	0.02626368  	0.19374624  	0.10761024  
2023-05-18 15:01:55.738: Find a better model.
2023-05-18 15:02:05.021: [iter 138 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 9.276481]
2023-05-18 15:02:05.313: epoch 138:	0.02630602  	0.19406076  	0.10764363  
2023-05-18 15:02:05.313: Find a better model.
2023-05-18 15:02:13.147: [iter 139 : loss : 0.1147 = 0.0250 + 0.0831 + 0.0066, time: 7.832993]
2023-05-18 15:02:13.310: epoch 139:	0.02626368  	0.19373876  	0.10770105  
2023-05-18 15:02:21.369: [iter 140 : loss : 0.1138 = 0.0242 + 0.0830 + 0.0066, time: 8.056286]
2023-05-18 15:02:21.530: epoch 140:	0.02628485  	0.19387132  	0.10773292  
2023-05-18 15:02:29.933: [iter 141 : loss : 0.1145 = 0.0249 + 0.0830 + 0.0066, time: 8.402004]
2023-05-18 15:02:30.192: epoch 141:	0.02622135  	0.19344085  	0.10778552  
2023-05-18 15:02:39.323: [iter 142 : loss : 0.1136 = 0.0240 + 0.0829 + 0.0066, time: 9.128032]
2023-05-18 15:02:39.572: epoch 142:	0.02619312  	0.19332032  	0.10780449  
2023-05-18 15:02:48.835: [iter 143 : loss : 0.1135 = 0.0240 + 0.0829 + 0.0067, time: 9.259522]
2023-05-18 15:02:49.139: epoch 143:	0.02616489  	0.19280258  	0.10774168  
2023-05-18 15:02:57.513: [iter 144 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 8.372992]
2023-05-18 15:02:57.669: epoch 144:	0.02613666  	0.19259305  	0.10758057  
2023-05-18 15:03:05.579: [iter 145 : loss : 0.1130 = 0.0234 + 0.0828 + 0.0067, time: 7.908528]
2023-05-18 15:03:05.738: epoch 145:	0.02612961  	0.19272731  	0.10781568  
2023-05-18 15:03:14.234: [iter 146 : loss : 0.1133 = 0.0237 + 0.0828 + 0.0067, time: 8.494030]
2023-05-18 15:03:14.405: epoch 146:	0.02617195  	0.19281876  	0.10778248  
2023-05-18 15:03:23.696: [iter 147 : loss : 0.1133 = 0.0238 + 0.0828 + 0.0068, time: 9.287415]
2023-05-18 15:03:23.992: epoch 147:	0.02613666  	0.19295079  	0.10764962  
2023-05-18 15:03:33.185: [iter 148 : loss : 0.1118 = 0.0223 + 0.0827 + 0.0068, time: 9.191439]
2023-05-18 15:03:33.360: epoch 148:	0.02610844  	0.19277297  	0.10767497  
2023-05-18 15:03:41.590: [iter 149 : loss : 0.1120 = 0.0225 + 0.0827 + 0.0068, time: 8.227991]
2023-05-18 15:03:41.750: epoch 149:	0.02616489  	0.19323817  	0.10778898  
2023-05-18 15:03:49.840: [iter 150 : loss : 0.1119 = 0.0224 + 0.0826 + 0.0069, time: 8.088012]
2023-05-18 15:03:50.001: epoch 150:	0.02613666  	0.19290718  	0.10781164  
2023-05-18 15:03:58.123: [iter 151 : loss : 0.1118 = 0.0223 + 0.0826 + 0.0069, time: 8.120016]
2023-05-18 15:03:58.278: epoch 151:	0.02615078  	0.19301078  	0.10781831  
2023-05-18 15:04:07.561: [iter 152 : loss : 0.1110 = 0.0215 + 0.0826 + 0.0069, time: 9.281488]
2023-05-18 15:04:07.845: epoch 152:	0.02620723  	0.19334634  	0.10786094  
2023-05-18 15:04:15.459: [iter 153 : loss : 0.1103 = 0.0208 + 0.0826 + 0.0069, time: 7.612931]
2023-05-18 15:04:15.628: epoch 153:	0.02614372  	0.19291407  	0.10765759  
2023-05-18 15:04:24.195: [iter 154 : loss : 0.1104 = 0.0209 + 0.0825 + 0.0070, time: 8.566028]
2023-05-18 15:04:24.349: epoch 154:	0.02617195  	0.19273655  	0.10771230  
2023-05-18 15:04:32.799: [iter 155 : loss : 0.1114 = 0.0219 + 0.0825 + 0.0070, time: 8.447992]
2023-05-18 15:04:32.953: epoch 155:	0.02614373  	0.19265872  	0.10755160  
2023-05-18 15:04:40.757: [iter 156 : loss : 0.1107 = 0.0212 + 0.0825 + 0.0070, time: 7.802022]
2023-05-18 15:04:40.915: epoch 156:	0.02619312  	0.19293346  	0.10756160  
2023-05-18 15:04:50.223: [iter 157 : loss : 0.1104 = 0.0209 + 0.0824 + 0.0070, time: 9.304059]
2023-05-18 15:04:50.515: epoch 157:	0.02616490  	0.19235267  	0.10761417  
2023-05-18 15:04:58.432: [iter 158 : loss : 0.1098 = 0.0204 + 0.0824 + 0.0071, time: 7.915336]
2023-05-18 15:04:58.589: epoch 158:	0.02611550  	0.19177392  	0.10745514  
2023-05-18 15:05:06.722: [iter 159 : loss : 0.1102 = 0.0207 + 0.0824 + 0.0071, time: 8.132030]
2023-05-18 15:05:06.877: epoch 159:	0.02615784  	0.19214636  	0.10764948  
2023-05-18 15:05:15.519: [iter 160 : loss : 0.1098 = 0.0203 + 0.0824 + 0.0071, time: 8.641017]
2023-05-18 15:05:15.772: epoch 160:	0.02612961  	0.19231218  	0.10753370  
2023-05-18 15:05:25.246: [iter 161 : loss : 0.1092 = 0.0197 + 0.0823 + 0.0071, time: 9.470971]
2023-05-18 15:05:25.507: epoch 161:	0.02615784  	0.19276179  	0.10751413  
2023-05-18 15:05:34.936: [iter 162 : loss : 0.1087 = 0.0192 + 0.0823 + 0.0072, time: 9.424001]
2023-05-18 15:05:35.210: epoch 162:	0.02608727  	0.19198705  	0.10751937  
2023-05-18 15:05:43.867: [iter 163 : loss : 0.1090 = 0.0196 + 0.0823 + 0.0072, time: 8.655172]
2023-05-18 15:05:44.023: epoch 163:	0.02605200  	0.19201706  	0.10753400  
2023-05-18 15:05:44.024: Early stopping is trigger at epoch: 163
2023-05-18 15:05:44.024: best_result@epoch 138:

2023-05-18 15:05:44.024: 		0.0263      	0.1941      	0.1076      
2023-05-18 15:07:17.304: my pid: 3900
2023-05-18 15:07:17.304: model: model.general_recommender.SGL
2023-05-18 15:07:17.304: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 15:07:17.304: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 15:07:20.593: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 15:07:31.026: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.432004]
2023-05-18 15:07:31.294: epoch 1:	0.00147474  	0.01057201  	0.00526402  
2023-05-18 15:07:31.295: Find a better model.
2023-05-18 15:07:40.430: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.134073]
2023-05-18 15:07:40.626: epoch 2:	0.00242732  	0.01781952  	0.00864640  
2023-05-18 15:07:40.627: Find a better model.
2023-05-18 15:07:49.746: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 9.118312]
2023-05-18 15:07:49.944: epoch 3:	0.00445242  	0.03317296  	0.01615252  
2023-05-18 15:07:49.944: Find a better model.
2023-05-18 15:07:59.877: [iter 4 : loss : 0.7707 = 0.6921 + 0.0785 + 0.0000, time: 9.931999]
2023-05-18 15:08:00.044: epoch 4:	0.00739480  	0.05448111  	0.02593000  
2023-05-18 15:08:00.044: Find a better model.
2023-05-18 15:08:09.984: [iter 5 : loss : 0.7698 = 0.6911 + 0.0787 + 0.0000, time: 9.937056]
2023-05-18 15:08:10.288: epoch 5:	0.01108524  	0.07998387  	0.03827893  
2023-05-18 15:08:10.288: Find a better model.
2023-05-18 15:08:19.247: [iter 6 : loss : 0.7679 = 0.6888 + 0.0790 + 0.0000, time: 8.958063]
2023-05-18 15:08:19.420: epoch 6:	0.01465581  	0.10538150  	0.05106553  
2023-05-18 15:08:19.420: Find a better model.
2023-05-18 15:08:28.540: [iter 7 : loss : 0.7626 = 0.6828 + 0.0797 + 0.0000, time: 9.118438]
2023-05-18 15:08:28.751: epoch 7:	0.01755598  	0.12720457  	0.06228248  
2023-05-18 15:08:28.751: Find a better model.
2023-05-18 15:08:37.729: [iter 8 : loss : 0.7493 = 0.6679 + 0.0814 + 0.0001, time: 8.977001]
2023-05-18 15:08:37.880: epoch 8:	0.01881204  	0.13753445  	0.06856149  
2023-05-18 15:08:37.880: Find a better model.
2023-05-18 15:08:46.079: [iter 9 : loss : 0.7182 = 0.6332 + 0.0849 + 0.0001, time: 8.197519]
2023-05-18 15:08:46.229: epoch 9:	0.01886144  	0.13817605  	0.06894682  
2023-05-18 15:08:46.229: Find a better model.
2023-05-18 15:08:55.766: [iter 10 : loss : 0.6615 = 0.5711 + 0.0902 + 0.0002, time: 9.534991]
2023-05-18 15:08:56.055: epoch 10:	0.01874148  	0.13852197  	0.06866112  
2023-05-18 15:08:56.055: Find a better model.
2023-05-18 15:09:03.969: [iter 11 : loss : 0.5866 = 0.4907 + 0.0955 + 0.0004, time: 7.912221]
2023-05-18 15:09:04.129: epoch 11:	0.01855095  	0.13724680  	0.06820042  
2023-05-18 15:09:12.646: [iter 12 : loss : 0.5154 = 0.4156 + 0.0992 + 0.0005, time: 8.515031]
2023-05-18 15:09:12.794: epoch 12:	0.01843099  	0.13680129  	0.06802398  
2023-05-18 15:09:21.612: [iter 13 : loss : 0.4618 = 0.3599 + 0.1013 + 0.0007, time: 8.816045]
2023-05-18 15:09:21.761: epoch 13:	0.01856506  	0.13720833  	0.06863619  
2023-05-18 15:09:30.920: [iter 14 : loss : 0.4212 = 0.3181 + 0.1023 + 0.0008, time: 9.156991]
2023-05-18 15:09:31.228: epoch 14:	0.01874148  	0.13862379  	0.06951428  
2023-05-18 15:09:31.228: Find a better model.
2023-05-18 15:09:40.741: [iter 15 : loss : 0.3931 = 0.2894 + 0.1027 + 0.0010, time: 9.511641]
2023-05-18 15:09:41.033: epoch 15:	0.01895317  	0.13964508  	0.07050476  
2023-05-18 15:09:41.033: Find a better model.
2023-05-18 15:09:49.744: [iter 16 : loss : 0.3696 = 0.2658 + 0.1027 + 0.0011, time: 8.708992]
2023-05-18 15:09:49.921: epoch 16:	0.01910136  	0.14095986  	0.07121940  
2023-05-18 15:09:49.921: Find a better model.
2023-05-18 15:09:57.883: [iter 17 : loss : 0.3526 = 0.2487 + 0.1026 + 0.0012, time: 7.959218]
2023-05-18 15:09:58.045: epoch 17:	0.01936951  	0.14302699  	0.07212707  
2023-05-18 15:09:58.046: Find a better model.
2023-05-18 15:10:06.725: [iter 18 : loss : 0.3366 = 0.2330 + 0.1024 + 0.0013, time: 8.677991]
2023-05-18 15:10:06.885: epoch 18:	0.01951770  	0.14370292  	0.07257009  
2023-05-18 15:10:06.885: Find a better model.
2023-05-18 15:10:16.330: [iter 19 : loss : 0.3223 = 0.2188 + 0.1020 + 0.0014, time: 9.442609]
2023-05-18 15:10:16.627: epoch 19:	0.01977879  	0.14555803  	0.07370070  
2023-05-18 15:10:16.628: Find a better model.
2023-05-18 15:10:26.120: [iter 20 : loss : 0.3123 = 0.2092 + 0.1016 + 0.0015, time: 9.489109]
2023-05-18 15:10:26.418: epoch 20:	0.01996932  	0.14693686  	0.07421307  
2023-05-18 15:10:26.418: Find a better model.
2023-05-18 15:10:35.083: [iter 21 : loss : 0.3026 = 0.1998 + 0.1012 + 0.0016, time: 8.663991]
2023-05-18 15:10:35.253: epoch 21:	0.02024452  	0.14894032  	0.07506238  
2023-05-18 15:10:35.254: Find a better model.
2023-05-18 15:10:43.259: [iter 22 : loss : 0.2940 = 0.1915 + 0.1008 + 0.0016, time: 8.002993]
2023-05-18 15:10:43.424: epoch 22:	0.02032920  	0.14950858  	0.07568670  
2023-05-18 15:10:43.424: Find a better model.
2023-05-18 15:10:51.926: [iter 23 : loss : 0.2854 = 0.1833 + 0.1004 + 0.0017, time: 8.499945]
2023-05-18 15:10:52.089: epoch 23:	0.02058323  	0.15154722  	0.07677603  
2023-05-18 15:10:52.089: Find a better model.
2023-05-18 15:11:01.425: [iter 24 : loss : 0.2791 = 0.1774 + 0.0999 + 0.0018, time: 9.331469]
2023-05-18 15:11:01.734: epoch 24:	0.02073142  	0.15283377  	0.07748582  
2023-05-18 15:11:01.735: Find a better model.
2023-05-18 15:11:10.314: [iter 25 : loss : 0.2726 = 0.1711 + 0.0996 + 0.0019, time: 8.577992]
2023-05-18 15:11:10.486: epoch 25:	0.02087961  	0.15402117  	0.07809906  
2023-05-18 15:11:10.486: Find a better model.
2023-05-18 15:11:19.020: [iter 26 : loss : 0.2686 = 0.1676 + 0.0991 + 0.0019, time: 8.532552]
2023-05-18 15:11:19.174: epoch 26:	0.02106308  	0.15503976  	0.07893436  
2023-05-18 15:11:19.174: Find a better model.
2023-05-18 15:11:27.260: [iter 27 : loss : 0.2609 = 0.1602 + 0.0987 + 0.0020, time: 8.083984]
2023-05-18 15:11:27.424: epoch 27:	0.02123949  	0.15627159  	0.07976607  
2023-05-18 15:11:27.424: Find a better model.
2023-05-18 15:11:35.617: [iter 28 : loss : 0.2558 = 0.1555 + 0.0983 + 0.0021, time: 8.192014]
2023-05-18 15:11:35.764: epoch 28:	0.02129594  	0.15668930  	0.08033224  
2023-05-18 15:11:35.764: Find a better model.
2023-05-18 15:11:45.057: [iter 29 : loss : 0.2513 = 0.1514 + 0.0978 + 0.0021, time: 9.289197]
2023-05-18 15:11:45.367: epoch 29:	0.02159938  	0.15880916  	0.08114963  
2023-05-18 15:11:45.367: Find a better model.
2023-05-18 15:11:53.025: [iter 30 : loss : 0.2448 = 0.1452 + 0.0975 + 0.0022, time: 7.656490]
2023-05-18 15:11:53.191: epoch 30:	0.02183225  	0.16067342  	0.08209918  
2023-05-18 15:11:53.192: Find a better model.
2023-05-18 15:12:01.697: [iter 31 : loss : 0.2413 = 0.1420 + 0.0970 + 0.0023, time: 8.503015]
2023-05-18 15:12:01.867: epoch 31:	0.02190986  	0.16109823  	0.08274480  
2023-05-18 15:12:01.867: Find a better model.
2023-05-18 15:12:10.252: [iter 32 : loss : 0.2354 = 0.1364 + 0.0967 + 0.0023, time: 8.381007]
2023-05-18 15:12:10.788: epoch 32:	0.02203688  	0.16197705  	0.08333899  
2023-05-18 15:12:10.790: Find a better model.
2023-05-18 15:12:18.792: [iter 33 : loss : 0.2331 = 0.1344 + 0.0963 + 0.0024, time: 7.988013]
2023-05-18 15:12:18.944: epoch 33:	0.02225563  	0.16377015  	0.08419921  
2023-05-18 15:12:18.944: Find a better model.
2023-05-18 15:12:28.208: [iter 34 : loss : 0.2291 = 0.1307 + 0.0960 + 0.0024, time: 9.261113]
2023-05-18 15:12:28.518: epoch 34:	0.02236853  	0.16489577  	0.08501918  
2023-05-18 15:12:28.519: Find a better model.
2023-05-18 15:12:36.083: [iter 35 : loss : 0.2256 = 0.1275 + 0.0956 + 0.0025, time: 7.563278]
2023-05-18 15:12:36.248: epoch 35:	0.02253788  	0.16630803  	0.08570598  
2023-05-18 15:12:36.248: Find a better model.
2023-05-18 15:12:44.631: [iter 36 : loss : 0.2220 = 0.1241 + 0.0953 + 0.0025, time: 8.381003]
2023-05-18 15:12:44.796: epoch 36:	0.02279192  	0.16789527  	0.08651098  
2023-05-18 15:12:44.796: Find a better model.
2023-05-18 15:12:53.321: [iter 37 : loss : 0.2182 = 0.1206 + 0.0950 + 0.0026, time: 8.522038]
2023-05-18 15:12:53.818: epoch 37:	0.02283426  	0.16832174  	0.08698943  
2023-05-18 15:12:53.818: Find a better model.
2023-05-18 15:13:01.797: [iter 38 : loss : 0.2165 = 0.1191 + 0.0947 + 0.0027, time: 7.977003]
2023-05-18 15:13:01.950: epoch 38:	0.02298950  	0.16979717  	0.08784418  
2023-05-18 15:13:01.950: Find a better model.
2023-05-18 15:13:11.216: [iter 39 : loss : 0.2120 = 0.1149 + 0.0944 + 0.0027, time: 9.265011]
2023-05-18 15:13:11.529: epoch 39:	0.02306006  	0.17031418  	0.08823413  
2023-05-18 15:13:11.529: Find a better model.
2023-05-18 15:13:19.187: [iter 40 : loss : 0.2087 = 0.1119 + 0.0941 + 0.0028, time: 7.656462]
2023-05-18 15:13:19.350: epoch 40:	0.02321531  	0.17139134  	0.08881587  
2023-05-18 15:13:19.350: Find a better model.
2023-05-18 15:13:27.866: [iter 41 : loss : 0.2071 = 0.1105 + 0.0938 + 0.0028, time: 8.513993]
2023-05-18 15:13:28.032: epoch 41:	0.02339172  	0.17286146  	0.08958782  
2023-05-18 15:13:28.032: Find a better model.
2023-05-18 15:13:36.730: [iter 42 : loss : 0.2048 = 0.1084 + 0.0934 + 0.0029, time: 8.697072]
2023-05-18 15:13:36.990: epoch 42:	0.02338466  	0.17276810  	0.08975628  
2023-05-18 15:13:45.136: [iter 43 : loss : 0.2009 = 0.1049 + 0.0932 + 0.0029, time: 8.145006]
2023-05-18 15:13:45.286: epoch 43:	0.02349051  	0.17325452  	0.09023087  
2023-05-18 15:13:45.287: Find a better model.
2023-05-18 15:13:54.615: [iter 44 : loss : 0.1975 = 0.1016 + 0.0929 + 0.0030, time: 9.325006]
2023-05-18 15:13:54.909: epoch 44:	0.02358930  	0.17403165  	0.09085055  
2023-05-18 15:13:54.909: Find a better model.
2023-05-18 15:14:02.514: [iter 45 : loss : 0.1954 = 0.0997 + 0.0927 + 0.0030, time: 7.602056]
2023-05-18 15:14:02.686: epoch 45:	0.02370926  	0.17473061  	0.09133722  
2023-05-18 15:14:02.686: Find a better model.
2023-05-18 15:14:11.259: [iter 46 : loss : 0.1929 = 0.0975 + 0.0924 + 0.0031, time: 8.572032]
2023-05-18 15:14:11.426: epoch 46:	0.02380099  	0.17565103  	0.09202295  
2023-05-18 15:14:11.426: Find a better model.
2023-05-18 15:14:20.329: [iter 47 : loss : 0.1921 = 0.0968 + 0.0922 + 0.0031, time: 8.902027]
2023-05-18 15:14:20.480: epoch 47:	0.02385744  	0.17553134  	0.09243212  
2023-05-18 15:14:28.568: [iter 48 : loss : 0.1884 = 0.0933 + 0.0919 + 0.0032, time: 8.087054]
2023-05-18 15:14:28.733: epoch 48:	0.02389272  	0.17576416  	0.09291158  
2023-05-18 15:14:28.733: Find a better model.
2023-05-18 15:14:38.156: [iter 49 : loss : 0.1851 = 0.0902 + 0.0917 + 0.0032, time: 9.421786]
2023-05-18 15:14:38.429: epoch 49:	0.02394917  	0.17589909  	0.09336194  
2023-05-18 15:14:38.429: Find a better model.
2023-05-18 15:14:46.175: [iter 50 : loss : 0.1842 = 0.0895 + 0.0915 + 0.0033, time: 7.745013]
2023-05-18 15:14:46.342: epoch 50:	0.02405502  	0.17703940  	0.09402969  
2023-05-18 15:14:46.342: Find a better model.
2023-05-18 15:14:54.745: [iter 51 : loss : 0.1811 = 0.0865 + 0.0913 + 0.0033, time: 8.401154]
2023-05-18 15:14:54.905: epoch 51:	0.02418203  	0.17792779  	0.09455466  
2023-05-18 15:14:54.905: Find a better model.
2023-05-18 15:15:03.641: [iter 52 : loss : 0.1811 = 0.0866 + 0.0911 + 0.0034, time: 8.734030]
2023-05-18 15:15:03.799: epoch 52:	0.02420320  	0.17801628  	0.09471472  
2023-05-18 15:15:03.799: Find a better model.
2023-05-18 15:15:11.720: [iter 53 : loss : 0.1793 = 0.0850 + 0.0908 + 0.0034, time: 7.919036]
2023-05-18 15:15:11.870: epoch 53:	0.02429493  	0.17880960  	0.09525141  
2023-05-18 15:15:11.870: Find a better model.
2023-05-18 15:15:21.111: [iter 54 : loss : 0.1771 = 0.0830 + 0.0907 + 0.0035, time: 9.238032]
2023-05-18 15:15:21.374: epoch 54:	0.02433726  	0.17883919  	0.09535871  
2023-05-18 15:15:21.374: Find a better model.
2023-05-18 15:15:29.044: [iter 55 : loss : 0.1750 = 0.0810 + 0.0905 + 0.0035, time: 7.668028]
2023-05-18 15:15:29.209: epoch 55:	0.02442194  	0.17952445  	0.09588833  
2023-05-18 15:15:29.209: Find a better model.
2023-05-18 15:15:37.563: [iter 56 : loss : 0.1735 = 0.0796 + 0.0903 + 0.0035, time: 8.352492]
2023-05-18 15:15:37.718: epoch 56:	0.02457012  	0.18046184  	0.09660788  
2023-05-18 15:15:37.718: Find a better model.
2023-05-18 15:15:46.619: [iter 57 : loss : 0.1718 = 0.0781 + 0.0901 + 0.0036, time: 8.898362]
2023-05-18 15:15:46.793: epoch 57:	0.02465481  	0.18127026  	0.09693552  
2023-05-18 15:15:46.793: Find a better model.
2023-05-18 15:15:54.711: [iter 58 : loss : 0.1695 = 0.0760 + 0.0899 + 0.0036, time: 7.916359]
2023-05-18 15:15:54.861: epoch 58:	0.02468303  	0.18123037  	0.09721096  
2023-05-18 15:16:04.193: [iter 59 : loss : 0.1685 = 0.0751 + 0.0898 + 0.0037, time: 9.330078]
2023-05-18 15:16:04.468: epoch 59:	0.02473243  	0.18174340  	0.09755277  
2023-05-18 15:16:04.469: Find a better model.
2023-05-18 15:16:12.149: [iter 60 : loss : 0.1671 = 0.0738 + 0.0896 + 0.0037, time: 7.679034]
2023-05-18 15:16:12.313: epoch 60:	0.02473948  	0.18163364  	0.09781297  
2023-05-18 15:16:20.919: [iter 61 : loss : 0.1654 = 0.0723 + 0.0894 + 0.0038, time: 8.603078]
2023-05-18 15:16:21.069: epoch 61:	0.02478182  	0.18206516  	0.09814835  
2023-05-18 15:16:21.069: Find a better model.
2023-05-18 15:16:29.807: [iter 62 : loss : 0.1640 = 0.0710 + 0.0892 + 0.0038, time: 8.736010]
2023-05-18 15:16:29.970: epoch 62:	0.02485238  	0.18262477  	0.09853056  
2023-05-18 15:16:29.970: Find a better model.
2023-05-18 15:16:37.907: [iter 63 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0039, time: 7.934029]
2023-05-18 15:16:38.070: epoch 63:	0.02488766  	0.18258058  	0.09871554  
2023-05-18 15:16:47.404: [iter 64 : loss : 0.1618 = 0.0691 + 0.0889 + 0.0039, time: 9.330244]
2023-05-18 15:16:47.673: epoch 64:	0.02497940  	0.18379101  	0.09930336  
2023-05-18 15:16:47.673: Find a better model.
2023-05-18 15:16:55.376: [iter 65 : loss : 0.1605 = 0.0678 + 0.0887 + 0.0039, time: 7.700931]
2023-05-18 15:16:55.541: epoch 65:	0.02498645  	0.18347387  	0.09960612  
2023-05-18 15:17:03.974: [iter 66 : loss : 0.1587 = 0.0661 + 0.0886 + 0.0040, time: 8.432009]
2023-05-18 15:17:04.129: epoch 66:	0.02508524  	0.18452927  	0.10022029  
2023-05-18 15:17:04.129: Find a better model.
2023-05-18 15:17:12.824: [iter 67 : loss : 0.1573 = 0.0648 + 0.0885 + 0.0040, time: 8.693838]
2023-05-18 15:17:12.992: epoch 67:	0.02511347  	0.18477254  	0.10061490  
2023-05-18 15:17:12.992: Find a better model.
2023-05-18 15:17:21.078: [iter 68 : loss : 0.1569 = 0.0645 + 0.0883 + 0.0041, time: 8.084006]
2023-05-18 15:17:21.240: epoch 68:	0.02512052  	0.18488711  	0.10089189  
2023-05-18 15:17:21.240: Find a better model.
2023-05-18 15:17:30.669: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 9.427012]
2023-05-18 15:17:30.988: epoch 69:	0.02525459  	0.18611595  	0.10132399  
2023-05-18 15:17:30.988: Find a better model.
2023-05-18 15:17:38.658: [iter 70 : loss : 0.1533 = 0.0610 + 0.0881 + 0.0042, time: 7.668017]
2023-05-18 15:17:38.824: epoch 70:	0.02533927  	0.18695973  	0.10150930  
2023-05-18 15:17:38.824: Find a better model.
2023-05-18 15:17:47.338: [iter 71 : loss : 0.1519 = 0.0598 + 0.0879 + 0.0042, time: 8.513030]
2023-05-18 15:17:47.502: epoch 71:	0.02535339  	0.18734087  	0.10197721  
2023-05-18 15:17:47.502: Find a better model.
2023-05-18 15:17:56.183: [iter 72 : loss : 0.1519 = 0.0598 + 0.0878 + 0.0042, time: 8.679009]
2023-05-18 15:17:56.346: epoch 72:	0.02541690  	0.18780445  	0.10240436  
2023-05-18 15:17:56.346: Find a better model.
2023-05-18 15:18:04.477: [iter 73 : loss : 0.1503 = 0.0584 + 0.0877 + 0.0043, time: 8.129006]
2023-05-18 15:18:04.637: epoch 73:	0.02541689  	0.18761939  	0.10243396  
2023-05-18 15:18:14.075: [iter 74 : loss : 0.1489 = 0.0570 + 0.0876 + 0.0043, time: 9.434012]
2023-05-18 15:18:14.376: epoch 74:	0.02543806  	0.18757221  	0.10248259  
2023-05-18 15:18:22.145: [iter 75 : loss : 0.1483 = 0.0565 + 0.0874 + 0.0044, time: 7.767054]
2023-05-18 15:18:22.313: epoch 75:	0.02552979  	0.18801245  	0.10290749  
2023-05-18 15:18:22.313: Find a better model.
2023-05-18 15:18:31.153: [iter 76 : loss : 0.1474 = 0.0556 + 0.0873 + 0.0044, time: 8.839172]
2023-05-18 15:18:31.305: epoch 76:	0.02554391  	0.18818310  	0.10325117  
2023-05-18 15:18:31.305: Find a better model.
2023-05-18 15:18:39.936: [iter 77 : loss : 0.1463 = 0.0547 + 0.0872 + 0.0044, time: 8.629225]
2023-05-18 15:18:40.103: epoch 77:	0.02571326  	0.18968394  	0.10385156  
2023-05-18 15:18:40.104: Find a better model.
2023-05-18 15:18:48.233: [iter 78 : loss : 0.1455 = 0.0540 + 0.0871 + 0.0045, time: 8.127006]
2023-05-18 15:18:48.381: epoch 78:	0.02573443  	0.18930039  	0.10368159  
2023-05-18 15:18:57.663: [iter 79 : loss : 0.1442 = 0.0527 + 0.0870 + 0.0045, time: 9.278020]
2023-05-18 15:18:57.934: epoch 79:	0.02579794  	0.18988168  	0.10377499  
2023-05-18 15:18:57.934: Find a better model.
2023-05-18 15:19:05.502: [iter 80 : loss : 0.1437 = 0.0522 + 0.0869 + 0.0046, time: 7.566093]
2023-05-18 15:19:05.670: epoch 80:	0.02580500  	0.19019049  	0.10416287  
2023-05-18 15:19:05.670: Find a better model.
2023-05-18 15:19:14.296: [iter 81 : loss : 0.1430 = 0.0516 + 0.0868 + 0.0046, time: 8.622318]
2023-05-18 15:19:14.461: epoch 81:	0.02582617  	0.19004026  	0.10419071  
2023-05-18 15:19:23.212: [iter 82 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0046, time: 8.750334]
2023-05-18 15:19:23.376: epoch 82:	0.02586144  	0.19048144  	0.10446521  
2023-05-18 15:19:23.377: Find a better model.
2023-05-18 15:19:31.480: [iter 83 : loss : 0.1407 = 0.0495 + 0.0866 + 0.0047, time: 8.102170]
2023-05-18 15:19:31.638: epoch 83:	0.02601669  	0.19222645  	0.10515649  
2023-05-18 15:19:31.638: Find a better model.
2023-05-18 15:19:40.920: [iter 84 : loss : 0.1405 = 0.0493 + 0.0865 + 0.0047, time: 9.278272]
2023-05-18 15:19:41.230: epoch 84:	0.02597435  	0.19202003  	0.10515843  
2023-05-18 15:19:48.781: [iter 85 : loss : 0.1397 = 0.0485 + 0.0864 + 0.0048, time: 7.550040]
2023-05-18 15:19:48.949: epoch 85:	0.02605904  	0.19253692  	0.10541463  
2023-05-18 15:19:48.949: Find a better model.
2023-05-18 15:19:57.524: [iter 86 : loss : 0.1397 = 0.0486 + 0.0862 + 0.0048, time: 8.572852]
2023-05-18 15:19:57.687: epoch 86:	0.02603787  	0.19261061  	0.10542798  
2023-05-18 15:19:57.687: Find a better model.
2023-05-18 15:20:06.392: [iter 87 : loss : 0.1367 = 0.0457 + 0.0862 + 0.0048, time: 8.703842]
2023-05-18 15:20:06.561: epoch 87:	0.02598847  	0.19219641  	0.10561748  
2023-05-18 15:20:14.621: [iter 88 : loss : 0.1361 = 0.0452 + 0.0861 + 0.0049, time: 8.056025]
2023-05-18 15:20:14.781: epoch 88:	0.02602375  	0.19231915  	0.10569499  
2023-05-18 15:20:24.036: [iter 89 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 9.253025]
2023-05-18 15:20:24.301: epoch 89:	0.02603787  	0.19250810  	0.10584979  
2023-05-18 15:20:31.909: [iter 90 : loss : 0.1365 = 0.0457 + 0.0859 + 0.0049, time: 7.607014]
2023-05-18 15:20:32.071: epoch 90:	0.02612961  	0.19343650  	0.10622775  
2023-05-18 15:20:32.071: Find a better model.
2023-05-18 15:20:40.481: [iter 91 : loss : 0.1353 = 0.0445 + 0.0858 + 0.0050, time: 8.409047]
2023-05-18 15:20:40.647: epoch 91:	0.02615077  	0.19317000  	0.10630705  
2023-05-18 15:20:49.348: [iter 92 : loss : 0.1344 = 0.0437 + 0.0857 + 0.0050, time: 8.699087]
2023-05-18 15:20:49.515: epoch 92:	0.02617900  	0.19334720  	0.10641807  
2023-05-18 15:20:57.620: [iter 93 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0051, time: 8.103403]
2023-05-18 15:20:57.768: epoch 93:	0.02612255  	0.19275047  	0.10634896  
2023-05-18 15:21:07.006: [iter 94 : loss : 0.1325 = 0.0418 + 0.0856 + 0.0051, time: 9.236020]
2023-05-18 15:21:07.302: epoch 94:	0.02617194  	0.19309235  	0.10654590  
2023-05-18 15:21:14.922: [iter 95 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 7.618045]
2023-05-18 15:21:15.087: epoch 95:	0.02605904  	0.19248632  	0.10623544  
2023-05-18 15:21:23.636: [iter 96 : loss : 0.1318 = 0.0412 + 0.0854 + 0.0052, time: 8.547014]
2023-05-18 15:21:23.784: epoch 96:	0.02615783  	0.19341111  	0.10666202  
2023-05-18 15:21:32.325: [iter 97 : loss : 0.1301 = 0.0396 + 0.0853 + 0.0052, time: 8.538033]
2023-05-18 15:21:32.598: epoch 97:	0.02625662  	0.19387071  	0.10707542  
2023-05-18 15:21:32.598: Find a better model.
2023-05-18 15:21:40.604: [iter 98 : loss : 0.1311 = 0.0406 + 0.0853 + 0.0052, time: 8.002095]
2023-05-18 15:21:40.765: epoch 98:	0.02625662  	0.19382291  	0.10715672  
2023-05-18 15:21:50.059: [iter 99 : loss : 0.1299 = 0.0394 + 0.0852 + 0.0053, time: 9.288050]
2023-05-18 15:21:50.351: epoch 99:	0.02632718  	0.19440141  	0.10743453  
2023-05-18 15:21:50.351: Find a better model.
2023-05-18 15:21:58.040: [iter 100 : loss : 0.1292 = 0.0388 + 0.0851 + 0.0053, time: 7.687888]
2023-05-18 15:21:58.201: epoch 100:	0.02628485  	0.19400957  	0.10760248  
2023-05-18 15:22:05.795: [iter 101 : loss : 0.1289 = 0.0386 + 0.0850 + 0.0053, time: 7.592705]
2023-05-18 15:22:05.944: epoch 101:	0.02636246  	0.19510898  	0.10806353  
2023-05-18 15:22:05.944: Find a better model.
2023-05-18 15:22:13.547: [iter 102 : loss : 0.1277 = 0.0374 + 0.0849 + 0.0054, time: 7.602248]
2023-05-18 15:22:13.698: epoch 102:	0.02638363  	0.19500773  	0.10804391  
2023-05-18 15:22:21.391: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 7.690678]
2023-05-18 15:22:21.540: epoch 103:	0.02645420  	0.19540027  	0.10821942  
2023-05-18 15:22:21.540: Find a better model.
2023-05-18 15:22:28.979: [iter 104 : loss : 0.1279 = 0.0377 + 0.0848 + 0.0055, time: 7.437117]
2023-05-18 15:22:29.126: epoch 104:	0.02646831  	0.19539808  	0.10835429  
2023-05-18 15:22:36.784: [iter 105 : loss : 0.1270 = 0.0368 + 0.0847 + 0.0055, time: 7.657581]
2023-05-18 15:22:36.933: epoch 105:	0.02647537  	0.19542229  	0.10838078  
2023-05-18 15:22:36.933: Find a better model.
2023-05-18 15:22:44.580: [iter 106 : loss : 0.1266 = 0.0364 + 0.0847 + 0.0055, time: 7.644254]
2023-05-18 15:22:44.745: epoch 106:	0.02653182  	0.19611868  	0.10888761  
2023-05-18 15:22:44.745: Find a better model.
2023-05-18 15:22:52.393: [iter 107 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0055, time: 7.647028]
2023-05-18 15:22:52.541: epoch 107:	0.02646126  	0.19543557  	0.10867669  
2023-05-18 15:22:59.963: [iter 108 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 7.421227]
2023-05-18 15:23:00.113: epoch 108:	0.02650360  	0.19571677  	0.10891686  
2023-05-18 15:23:07.724: [iter 109 : loss : 0.1241 = 0.0340 + 0.0845 + 0.0056, time: 7.609763]
2023-05-18 15:23:07.872: epoch 109:	0.02648243  	0.19535507  	0.10877282  
2023-05-18 15:23:15.510: [iter 110 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0057, time: 7.637569]
2023-05-18 15:23:15.664: epoch 110:	0.02651770  	0.19554485  	0.10897276  
2023-05-18 15:23:23.321: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 7.654686]
2023-05-18 15:23:23.486: epoch 111:	0.02651065  	0.19544236  	0.10898586  
2023-05-18 15:23:30.940: [iter 112 : loss : 0.1237 = 0.0336 + 0.0843 + 0.0057, time: 7.451082]
2023-05-18 15:23:31.089: epoch 112:	0.02649654  	0.19528162  	0.10904749  
2023-05-18 15:23:38.702: [iter 113 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0058, time: 7.610514]
2023-05-18 15:23:38.866: epoch 113:	0.02656711  	0.19534937  	0.10917529  
2023-05-18 15:23:46.560: [iter 114 : loss : 0.1225 = 0.0325 + 0.0842 + 0.0058, time: 7.693058]
2023-05-18 15:23:46.713: epoch 114:	0.02655299  	0.19538008  	0.10902248  
2023-05-18 15:23:54.126: [iter 115 : loss : 0.1221 = 0.0322 + 0.0841 + 0.0058, time: 7.409789]
2023-05-18 15:23:54.273: epoch 115:	0.02658827  	0.19571288  	0.10917875  
2023-05-18 15:24:01.745: [iter 116 : loss : 0.1213 = 0.0313 + 0.0841 + 0.0058, time: 7.470352]
2023-05-18 15:24:01.899: epoch 116:	0.02651064  	0.19513898  	0.10910886  
2023-05-18 15:24:09.534: [iter 117 : loss : 0.1212 = 0.0312 + 0.0840 + 0.0059, time: 7.632374]
2023-05-18 15:24:09.690: epoch 117:	0.02650359  	0.19517092  	0.10904212  
2023-05-18 15:24:17.583: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 7.892318]
2023-05-18 15:24:17.736: epoch 118:	0.02646830  	0.19484122  	0.10895612  
2023-05-18 15:24:25.342: [iter 119 : loss : 0.1199 = 0.0300 + 0.0839 + 0.0059, time: 7.603911]
2023-05-18 15:24:25.490: epoch 119:	0.02644714  	0.19478670  	0.10910060  
2023-05-18 15:24:32.922: [iter 120 : loss : 0.1204 = 0.0305 + 0.0839 + 0.0060, time: 7.429382]
2023-05-18 15:24:33.070: epoch 120:	0.02654593  	0.19524568  	0.10924627  
2023-05-18 15:24:40.523: [iter 121 : loss : 0.1202 = 0.0304 + 0.0838 + 0.0060, time: 7.451769]
2023-05-18 15:24:40.683: epoch 121:	0.02657416  	0.19534041  	0.10937829  
2023-05-18 15:24:48.108: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 7.423770]
2023-05-18 15:24:48.256: epoch 122:	0.02650359  	0.19474629  	0.10921249  
2023-05-18 15:24:55.924: [iter 123 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 7.666471]
2023-05-18 15:24:56.071: epoch 123:	0.02656710  	0.19532466  	0.10933344  
2023-05-18 15:25:03.735: [iter 124 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 7.661471]
2023-05-18 15:25:03.885: epoch 124:	0.02657416  	0.19557992  	0.10957174  
2023-05-18 15:25:11.766: [iter 125 : loss : 0.1177 = 0.0280 + 0.0836 + 0.0061, time: 7.879122]
2023-05-18 15:25:11.933: epoch 125:	0.02648948  	0.19497131  	0.10946076  
2023-05-18 15:25:19.531: [iter 126 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0062, time: 7.595380]
2023-05-18 15:25:19.682: epoch 126:	0.02648948  	0.19498065  	0.10937516  
2023-05-18 15:25:27.112: [iter 127 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0062, time: 7.429542]
2023-05-18 15:25:27.260: epoch 127:	0.02647536  	0.19465323  	0.10947131  
2023-05-18 15:25:34.932: [iter 128 : loss : 0.1182 = 0.0284 + 0.0835 + 0.0062, time: 7.669698]
2023-05-18 15:25:35.156: epoch 128:	0.02651065  	0.19492628  	0.10955950  
2023-05-18 15:25:42.726: [iter 129 : loss : 0.1171 = 0.0274 + 0.0834 + 0.0063, time: 7.568345]
2023-05-18 15:25:42.883: epoch 129:	0.02649653  	0.19480641  	0.10957089  
2023-05-18 15:25:50.691: [iter 130 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.805585]
2023-05-18 15:25:50.854: epoch 130:	0.02650359  	0.19477104  	0.10958466  
2023-05-18 15:25:58.696: [iter 131 : loss : 0.1163 = 0.0267 + 0.0834 + 0.0063, time: 7.840470]
2023-05-18 15:25:58.845: epoch 131:	0.02649653  	0.19485703  	0.10954593  
2023-05-18 15:25:58.845: Early stopping is trigger at epoch: 131
2023-05-18 15:25:58.845: best_result@epoch 106:

2023-05-18 15:25:58.845: 		0.0265      	0.1961      	0.1089      
2023-05-18 15:28:40.435: my pid: 10928
2023-05-18 15:28:40.435: model: model.general_recommender.SGL
2023-05-18 15:28:40.435: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 15:28:40.435: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 15:28:44.347: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 15:28:54.770: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 10.419893]
2023-05-18 15:28:55.040: epoch 1:	0.00134773  	0.01022602  	0.00496942  
2023-05-18 15:28:55.040: Find a better model.
2023-05-18 15:29:04.242: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 9.199366]
2023-05-18 15:29:04.458: epoch 2:	0.00256845  	0.01992306  	0.00940843  
2023-05-18 15:29:04.458: Find a better model.
2023-05-18 15:29:13.464: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 9.005353]
2023-05-18 15:29:13.624: epoch 3:	0.00451593  	0.03433756  	0.01646965  
2023-05-18 15:29:13.624: Find a better model.
2023-05-18 15:29:22.355: [iter 4 : loss : 0.7706 = 0.6921 + 0.0786 + 0.0000, time: 8.729388]
2023-05-18 15:29:22.555: epoch 4:	0.00750770  	0.05536206  	0.02659460  
2023-05-18 15:29:22.556: Find a better model.
2023-05-18 15:29:31.457: [iter 5 : loss : 0.7697 = 0.6910 + 0.0787 + 0.0000, time: 8.900087]
2023-05-18 15:29:31.609: epoch 5:	0.01105702  	0.07993345  	0.03841780  
2023-05-18 15:29:31.609: Find a better model.
2023-05-18 15:29:40.874: [iter 6 : loss : 0.7676 = 0.6885 + 0.0791 + 0.0000, time: 9.262628]
2023-05-18 15:29:41.131: epoch 6:	0.01485339  	0.10671280  	0.05184480  
2023-05-18 15:29:41.131: Find a better model.
2023-05-18 15:29:49.438: [iter 7 : loss : 0.7618 = 0.6820 + 0.0798 + 0.0000, time: 8.306028]
2023-05-18 15:29:49.601: epoch 7:	0.01723846  	0.12500387  	0.06185890  
2023-05-18 15:29:49.601: Find a better model.
2023-05-18 15:29:58.009: [iter 8 : loss : 0.7475 = 0.6659 + 0.0816 + 0.0001, time: 8.405677]
2023-05-18 15:29:58.167: epoch 8:	0.01863562  	0.13660097  	0.06806635  
2023-05-18 15:29:58.167: Find a better model.
2023-05-18 15:30:06.447: [iter 9 : loss : 0.7145 = 0.6291 + 0.0853 + 0.0001, time: 8.279028]
2023-05-18 15:30:06.611: epoch 9:	0.01879792  	0.13836396  	0.06916026  
2023-05-18 15:30:06.611: Find a better model.
2023-05-18 15:30:15.029: [iter 10 : loss : 0.6558 = 0.5649 + 0.0906 + 0.0002, time: 8.417032]
2023-05-18 15:30:15.209: epoch 10:	0.01860740  	0.13743100  	0.06875621  
2023-05-18 15:30:24.165: [iter 11 : loss : 0.5806 = 0.4845 + 0.0958 + 0.0004, time: 8.955024]
2023-05-18 15:30:24.428: epoch 11:	0.01860034  	0.13779297  	0.06843573  
2023-05-18 15:30:32.642: [iter 12 : loss : 0.5106 = 0.4107 + 0.0993 + 0.0005, time: 8.213002]
2023-05-18 15:30:32.792: epoch 12:	0.01852978  	0.13694862  	0.06846937  
2023-05-18 15:30:41.277: [iter 13 : loss : 0.4584 = 0.3565 + 0.1012 + 0.0007, time: 8.482126]
2023-05-18 15:30:41.504: epoch 13:	0.01856506  	0.13704138  	0.06865848  
2023-05-18 15:30:49.059: [iter 14 : loss : 0.4188 = 0.3158 + 0.1022 + 0.0008, time: 7.553014]
2023-05-18 15:30:49.220: epoch 14:	0.01873442  	0.13829017  	0.06956099  
2023-05-18 15:30:57.369: [iter 15 : loss : 0.3914 = 0.2877 + 0.1027 + 0.0010, time: 8.146240]
2023-05-18 15:30:57.532: epoch 15:	0.01897434  	0.14063469  	0.07052588  
2023-05-18 15:30:57.532: Find a better model.
2023-05-18 15:31:05.913: [iter 16 : loss : 0.3682 = 0.2645 + 0.1027 + 0.0011, time: 8.380027]
2023-05-18 15:31:06.159: epoch 16:	0.01916487  	0.14185721  	0.07119392  
2023-05-18 15:31:06.159: Find a better model.
2023-05-18 15:31:14.276: [iter 17 : loss : 0.3515 = 0.2478 + 0.1024 + 0.0012, time: 8.115023]
2023-05-18 15:31:14.475: epoch 17:	0.01940479  	0.14344828  	0.07214911  
2023-05-18 15:31:14.475: Find a better model.
2023-05-18 15:31:22.581: [iter 18 : loss : 0.3359 = 0.2324 + 0.1022 + 0.0013, time: 8.105020]
2023-05-18 15:31:22.741: epoch 18:	0.01967294  	0.14525573  	0.07324550  
2023-05-18 15:31:22.741: Find a better model.
2023-05-18 15:31:31.510: [iter 19 : loss : 0.3215 = 0.2181 + 0.1019 + 0.0014, time: 8.766046]
2023-05-18 15:31:31.790: epoch 19:	0.01988463  	0.14659551  	0.07421410  
2023-05-18 15:31:31.790: Find a better model.
2023-05-18 15:31:39.776: [iter 20 : loss : 0.3118 = 0.2088 + 0.1015 + 0.0015, time: 7.983450]
2023-05-18 15:31:39.934: epoch 20:	0.01999754  	0.14714596  	0.07490364  
2023-05-18 15:31:39.934: Find a better model.
2023-05-18 15:31:48.267: [iter 21 : loss : 0.3020 = 0.1994 + 0.1011 + 0.0016, time: 8.330003]
2023-05-18 15:31:48.500: epoch 21:	0.02017396  	0.14825816  	0.07548692  
2023-05-18 15:31:48.500: Find a better model.
2023-05-18 15:31:56.024: [iter 22 : loss : 0.2937 = 0.1913 + 0.1007 + 0.0016, time: 7.523510]
2023-05-18 15:31:56.186: epoch 22:	0.02042799  	0.15015635  	0.07639174  
2023-05-18 15:31:56.186: Find a better model.
2023-05-18 15:32:04.201: [iter 23 : loss : 0.2854 = 0.1834 + 0.1003 + 0.0017, time: 8.014008]
2023-05-18 15:32:04.363: epoch 23:	0.02058323  	0.15129641  	0.07706819  
2023-05-18 15:32:04.363: Find a better model.
2023-05-18 15:32:12.385: [iter 24 : loss : 0.2788 = 0.1772 + 0.0998 + 0.0018, time: 8.019068]
2023-05-18 15:32:12.630: epoch 24:	0.02076670  	0.15261082  	0.07775752  
2023-05-18 15:32:12.630: Find a better model.
2023-05-18 15:32:20.639: [iter 25 : loss : 0.2723 = 0.1710 + 0.0994 + 0.0019, time: 8.006636]
2023-05-18 15:32:20.801: epoch 25:	0.02092900  	0.15364709  	0.07823859  
2023-05-18 15:32:20.801: Find a better model.
2023-05-18 15:32:28.722: [iter 26 : loss : 0.2684 = 0.1675 + 0.0990 + 0.0019, time: 7.919999]
2023-05-18 15:32:28.898: epoch 26:	0.02108424  	0.15473944  	0.07903223  
2023-05-18 15:32:28.898: Find a better model.
2023-05-18 15:32:37.675: [iter 27 : loss : 0.2607 = 0.1601 + 0.0986 + 0.0020, time: 8.770277]
2023-05-18 15:32:37.959: epoch 27:	0.02125360  	0.15586676  	0.07956220  
2023-05-18 15:32:37.959: Find a better model.
2023-05-18 15:32:45.920: [iter 28 : loss : 0.2558 = 0.1556 + 0.0982 + 0.0021, time: 7.959002]
2023-05-18 15:32:46.080: epoch 28:	0.02140179  	0.15695585  	0.08045377  
2023-05-18 15:32:46.080: Find a better model.
2023-05-18 15:32:54.510: [iter 29 : loss : 0.2510 = 0.1512 + 0.0977 + 0.0021, time: 8.427009]
2023-05-18 15:32:54.664: epoch 29:	0.02161349  	0.15858287  	0.08128513  
2023-05-18 15:32:54.664: Find a better model.
2023-05-18 15:33:02.111: [iter 30 : loss : 0.2447 = 0.1451 + 0.0974 + 0.0022, time: 7.445399]
2023-05-18 15:33:02.290: epoch 30:	0.02185340  	0.16054541  	0.08219045  
2023-05-18 15:33:02.290: Find a better model.
2023-05-18 15:33:10.385: [iter 31 : loss : 0.2411 = 0.1419 + 0.0970 + 0.0023, time: 8.093010]
2023-05-18 15:33:10.545: epoch 31:	0.02196631  	0.16147467  	0.08272588  
2023-05-18 15:33:10.545: Find a better model.
2023-05-18 15:33:18.569: [iter 32 : loss : 0.2355 = 0.1366 + 0.0966 + 0.0023, time: 8.015023]
2023-05-18 15:33:18.838: epoch 32:	0.02212861  	0.16279545  	0.08341218  
2023-05-18 15:33:18.838: Find a better model.
2023-05-18 15:33:26.988: [iter 33 : loss : 0.2331 = 0.1344 + 0.0963 + 0.0024, time: 8.149012]
2023-05-18 15:33:27.153: epoch 33:	0.02230502  	0.16429374  	0.08414156  
2023-05-18 15:33:27.153: Find a better model.
2023-05-18 15:33:35.371: [iter 34 : loss : 0.2290 = 0.1307 + 0.0959 + 0.0024, time: 8.217014]
2023-05-18 15:33:35.533: epoch 34:	0.02241087  	0.16519119  	0.08490842  
2023-05-18 15:33:35.533: Find a better model.
2023-05-18 15:33:44.356: [iter 35 : loss : 0.2253 = 0.1272 + 0.0956 + 0.0025, time: 8.820000]
2023-05-18 15:33:44.623: epoch 35:	0.02255905  	0.16620448  	0.08552442  
2023-05-18 15:33:44.623: Find a better model.
2023-05-18 15:33:52.524: [iter 36 : loss : 0.2219 = 0.1241 + 0.0953 + 0.0025, time: 7.900009]
2023-05-18 15:33:52.687: epoch 36:	0.02272841  	0.16747661  	0.08628865  
2023-05-18 15:33:52.688: Find a better model.
2023-05-18 15:34:01.043: [iter 37 : loss : 0.2181 = 0.1206 + 0.0949 + 0.0026, time: 8.353440]
2023-05-18 15:34:01.201: epoch 37:	0.02279191  	0.16793285  	0.08676928  
2023-05-18 15:34:01.201: Find a better model.
2023-05-18 15:34:08.745: [iter 38 : loss : 0.2165 = 0.1192 + 0.0946 + 0.0027, time: 7.543017]
2023-05-18 15:34:08.902: epoch 38:	0.02299655  	0.16939692  	0.08757185  
2023-05-18 15:34:08.902: Find a better model.
2023-05-18 15:34:16.942: [iter 39 : loss : 0.2121 = 0.1151 + 0.0943 + 0.0027, time: 8.037295]
2023-05-18 15:34:17.102: epoch 39:	0.02320825  	0.17131875  	0.08839403  
2023-05-18 15:34:17.102: Find a better model.
2023-05-18 15:34:25.727: [iter 40 : loss : 0.2087 = 0.1119 + 0.0941 + 0.0028, time: 8.617202]
2023-05-18 15:34:25.989: epoch 40:	0.02331409  	0.17202818  	0.08897658  
2023-05-18 15:34:25.989: Find a better model.
2023-05-18 15:34:34.160: [iter 41 : loss : 0.2069 = 0.1103 + 0.0938 + 0.0028, time: 8.170292]
2023-05-18 15:34:34.328: epoch 41:	0.02339877  	0.17270045  	0.08963075  
2023-05-18 15:34:34.328: Find a better model.
2023-05-18 15:34:42.346: [iter 42 : loss : 0.2048 = 0.1085 + 0.0935 + 0.0029, time: 8.016182]
2023-05-18 15:34:42.496: epoch 42:	0.02348344  	0.17290843  	0.09013737  
2023-05-18 15:34:42.496: Find a better model.
2023-05-18 15:34:51.561: [iter 43 : loss : 0.2008 = 0.1047 + 0.0932 + 0.0029, time: 9.060169]
2023-05-18 15:34:51.835: epoch 43:	0.02352578  	0.17318779  	0.09039683  
2023-05-18 15:34:51.835: Find a better model.
2023-05-18 15:34:59.883: [iter 44 : loss : 0.1971 = 0.1013 + 0.0929 + 0.0030, time: 8.047375]
2023-05-18 15:35:00.035: epoch 44:	0.02363163  	0.17397425  	0.09088837  
2023-05-18 15:35:00.035: Find a better model.
2023-05-18 15:35:08.580: [iter 45 : loss : 0.1952 = 0.0995 + 0.0927 + 0.0030, time: 8.543656]
2023-05-18 15:35:08.744: epoch 45:	0.02374454  	0.17449723  	0.09124278  
2023-05-18 15:35:08.744: Find a better model.
2023-05-18 15:35:16.305: [iter 46 : loss : 0.1931 = 0.0976 + 0.0924 + 0.0031, time: 7.559236]
2023-05-18 15:35:16.466: epoch 46:	0.02375159  	0.17499772  	0.09171670  
2023-05-18 15:35:16.466: Find a better model.
2023-05-18 15:35:24.498: [iter 47 : loss : 0.1921 = 0.0969 + 0.0921 + 0.0031, time: 8.031000]
2023-05-18 15:35:24.653: epoch 47:	0.02390683  	0.17628962  	0.09206765  
2023-05-18 15:35:24.653: Find a better model.
2023-05-18 15:35:34.025: [iter 48 : loss : 0.1882 = 0.0931 + 0.0919 + 0.0032, time: 9.361233]
2023-05-18 15:35:34.292: epoch 48:	0.02392095  	0.17623243  	0.09247292  
2023-05-18 15:35:42.573: [iter 49 : loss : 0.1851 = 0.0902 + 0.0917 + 0.0032, time: 8.280010]
2023-05-18 15:35:42.752: epoch 49:	0.02401268  	0.17714491  	0.09283728  
2023-05-18 15:35:42.752: Find a better model.
2023-05-18 15:35:51.160: [iter 50 : loss : 0.1843 = 0.0896 + 0.0914 + 0.0033, time: 8.406008]
2023-05-18 15:35:51.384: epoch 50:	0.02416087  	0.17819053  	0.09346313  
2023-05-18 15:35:51.384: Find a better model.
2023-05-18 15:35:59.620: [iter 51 : loss : 0.1812 = 0.0866 + 0.0913 + 0.0033, time: 8.234735]
2023-05-18 15:35:59.781: epoch 51:	0.02421732  	0.17879692  	0.09417357  
2023-05-18 15:35:59.781: Find a better model.
2023-05-18 15:36:07.912: [iter 52 : loss : 0.1813 = 0.0869 + 0.0911 + 0.0034, time: 8.127951]
2023-05-18 15:36:08.073: epoch 52:	0.02427377  	0.17918000  	0.09455516  
2023-05-18 15:36:08.073: Find a better model.
2023-05-18 15:36:16.527: [iter 53 : loss : 0.1791 = 0.0849 + 0.0908 + 0.0034, time: 8.445000]
2023-05-18 15:36:16.806: epoch 53:	0.02433728  	0.17955193  	0.09503215  
2023-05-18 15:36:16.806: Find a better model.
2023-05-18 15:36:24.963: [iter 54 : loss : 0.1770 = 0.0829 + 0.0907 + 0.0035, time: 8.154364]
2023-05-18 15:36:25.127: epoch 54:	0.02443607  	0.18004467  	0.09544086  
2023-05-18 15:36:25.127: Find a better model.
2023-05-18 15:36:33.460: [iter 55 : loss : 0.1751 = 0.0811 + 0.0905 + 0.0035, time: 8.332162]
2023-05-18 15:36:33.610: epoch 55:	0.02440079  	0.18005963  	0.09564167  
2023-05-18 15:36:33.610: Find a better model.
2023-05-18 15:36:42.626: [iter 56 : loss : 0.1733 = 0.0794 + 0.0903 + 0.0035, time: 9.009207]
2023-05-18 15:36:42.884: epoch 56:	0.02456308  	0.18100868  	0.09618327  
2023-05-18 15:36:42.884: Find a better model.
2023-05-18 15:36:51.300: [iter 57 : loss : 0.1715 = 0.0779 + 0.0901 + 0.0036, time: 8.414431]
2023-05-18 15:36:51.468: epoch 57:	0.02469715  	0.18214700  	0.09656917  
2023-05-18 15:36:51.468: Find a better model.
2023-05-18 15:36:59.878: [iter 58 : loss : 0.1694 = 0.0759 + 0.0899 + 0.0036, time: 8.409009]
2023-05-18 15:37:00.047: epoch 58:	0.02472538  	0.18271951  	0.09691914  
2023-05-18 15:37:00.047: Find a better model.
2023-05-18 15:37:08.153: [iter 59 : loss : 0.1684 = 0.0750 + 0.0897 + 0.0037, time: 8.102111]
2023-05-18 15:37:08.516: epoch 59:	0.02474655  	0.18283606  	0.09732845  
2023-05-18 15:37:08.516: Find a better model.
2023-05-18 15:37:17.035: [iter 60 : loss : 0.1671 = 0.0738 + 0.0896 + 0.0037, time: 8.518016]
2023-05-18 15:37:17.223: epoch 60:	0.02485945  	0.18358761  	0.09790975  
2023-05-18 15:37:17.223: Find a better model.
2023-05-18 15:37:26.418: [iter 61 : loss : 0.1657 = 0.0725 + 0.0894 + 0.0038, time: 9.186012]
2023-05-18 15:37:26.698: epoch 61:	0.02483829  	0.18341111  	0.09814187  
2023-05-18 15:37:35.257: [iter 62 : loss : 0.1639 = 0.0709 + 0.0892 + 0.0038, time: 8.556898]
2023-05-18 15:37:35.411: epoch 62:	0.02482417  	0.18327662  	0.09821025  
2023-05-18 15:37:44.276: [iter 63 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0039, time: 8.863999]
2023-05-18 15:37:44.425: epoch 63:	0.02489474  	0.18386415  	0.09862361  
2023-05-18 15:37:44.425: Find a better model.
2023-05-18 15:37:52.252: [iter 64 : loss : 0.1617 = 0.0689 + 0.0889 + 0.0039, time: 7.825009]
2023-05-18 15:37:52.406: epoch 64:	0.02490885  	0.18404537  	0.09885097  
2023-05-18 15:37:52.406: Find a better model.
2023-05-18 15:38:00.878: [iter 65 : loss : 0.1605 = 0.0679 + 0.0887 + 0.0039, time: 8.470001]
2023-05-18 15:38:01.096: epoch 65:	0.02498647  	0.18462183  	0.09916084  
2023-05-18 15:38:01.096: Find a better model.
2023-05-18 15:38:10.208: [iter 66 : loss : 0.1587 = 0.0661 + 0.0886 + 0.0040, time: 9.109035]
2023-05-18 15:38:10.471: epoch 66:	0.02507114  	0.18518962  	0.09959495  
2023-05-18 15:38:10.471: Find a better model.
2023-05-18 15:38:18.628: [iter 67 : loss : 0.1571 = 0.0646 + 0.0885 + 0.0040, time: 8.156218]
2023-05-18 15:38:18.788: epoch 67:	0.02511348  	0.18554176  	0.09972839  
2023-05-18 15:38:18.788: Find a better model.
2023-05-18 15:38:27.535: [iter 68 : loss : 0.1566 = 0.0643 + 0.0883 + 0.0041, time: 8.744020]
2023-05-18 15:38:27.701: epoch 68:	0.02526167  	0.18680327  	0.10036387  
2023-05-18 15:38:27.701: Find a better model.
2023-05-18 15:38:35.392: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 7.689558]
2023-05-18 15:38:35.549: epoch 69:	0.02526872  	0.18724966  	0.10055742  
2023-05-18 15:38:35.549: Find a better model.
2023-05-18 15:38:43.652: [iter 70 : loss : 0.1532 = 0.0610 + 0.0881 + 0.0041, time: 8.101242]
2023-05-18 15:38:43.811: epoch 70:	0.02532518  	0.18732080  	0.10074797  
2023-05-18 15:38:43.811: Find a better model.
2023-05-18 15:38:53.604: [iter 71 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 9.787050]
2023-05-18 15:38:53.876: epoch 71:	0.02533929  	0.18732476  	0.10082863  
2023-05-18 15:38:53.876: Find a better model.
2023-05-18 15:39:02.133: [iter 72 : loss : 0.1517 = 0.0597 + 0.0878 + 0.0042, time: 8.256544]
2023-05-18 15:39:02.379: epoch 72:	0.02536046  	0.18755190  	0.10109657  
2023-05-18 15:39:02.379: Find a better model.
2023-05-18 15:39:10.752: [iter 73 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0043, time: 8.370042]
2023-05-18 15:39:10.926: epoch 73:	0.02540280  	0.18799196  	0.10121667  
2023-05-18 15:39:10.926: Find a better model.
2023-05-18 15:39:19.168: [iter 74 : loss : 0.1488 = 0.0569 + 0.0876 + 0.0043, time: 8.241006]
2023-05-18 15:39:19.348: epoch 74:	0.02548042  	0.18831335  	0.10148890  
2023-05-18 15:39:19.349: Find a better model.
2023-05-18 15:39:27.625: [iter 75 : loss : 0.1484 = 0.0566 + 0.0875 + 0.0044, time: 8.275091]
2023-05-18 15:39:27.785: epoch 75:	0.02551570  	0.18855114  	0.10179855  
2023-05-18 15:39:27.785: Find a better model.
2023-05-18 15:39:36.480: [iter 76 : loss : 0.1475 = 0.0558 + 0.0873 + 0.0044, time: 8.692000]
2023-05-18 15:39:36.757: epoch 76:	0.02560743  	0.18882124  	0.10205121  
2023-05-18 15:39:36.757: Find a better model.
2023-05-18 15:39:44.932: [iter 77 : loss : 0.1465 = 0.0549 + 0.0872 + 0.0044, time: 8.173019]
2023-05-18 15:39:45.156: epoch 77:	0.02564272  	0.18927924  	0.10214375  
2023-05-18 15:39:45.157: Find a better model.
2023-05-18 15:39:53.632: [iter 78 : loss : 0.1452 = 0.0537 + 0.0871 + 0.0045, time: 8.474008]
2023-05-18 15:39:53.783: epoch 78:	0.02570623  	0.18980999  	0.10248126  
2023-05-18 15:39:53.783: Find a better model.
2023-05-18 15:40:02.842: [iter 79 : loss : 0.1443 = 0.0528 + 0.0870 + 0.0045, time: 9.055019]
2023-05-18 15:40:03.120: epoch 79:	0.02567800  	0.18956567  	0.10235344  
2023-05-18 15:40:11.415: [iter 80 : loss : 0.1435 = 0.0520 + 0.0869 + 0.0046, time: 8.292016]
2023-05-18 15:40:11.574: epoch 80:	0.02579090  	0.19042559  	0.10265508  
2023-05-18 15:40:11.574: Find a better model.
2023-05-18 15:40:19.832: [iter 81 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 8.257526]
2023-05-18 15:40:19.983: epoch 81:	0.02575562  	0.18995751  	0.10258552  
2023-05-18 15:40:27.689: [iter 82 : loss : 0.1418 = 0.0505 + 0.0867 + 0.0046, time: 7.705012]
2023-05-18 15:40:27.900: epoch 82:	0.02583325  	0.19046211  	0.10293688  
2023-05-18 15:40:27.900: Find a better model.
2023-05-18 15:40:36.379: [iter 83 : loss : 0.1409 = 0.0497 + 0.0866 + 0.0047, time: 8.476003]
2023-05-18 15:40:36.528: epoch 83:	0.02588264  	0.19075651  	0.10326208  
2023-05-18 15:40:36.528: Find a better model.
2023-05-18 15:40:45.511: [iter 84 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.981778]
2023-05-18 15:40:45.776: epoch 84:	0.02597437  	0.19127381  	0.10351006  
2023-05-18 15:40:45.776: Find a better model.
2023-05-18 15:40:54.085: [iter 85 : loss : 0.1397 = 0.0486 + 0.0864 + 0.0048, time: 8.306211]
2023-05-18 15:40:54.251: epoch 85:	0.02600965  	0.19168909  	0.10402094  
2023-05-18 15:40:54.251: Find a better model.
2023-05-18 15:41:02.675: [iter 86 : loss : 0.1398 = 0.0488 + 0.0863 + 0.0048, time: 8.422992]
2023-05-18 15:41:02.825: epoch 86:	0.02596026  	0.19103342  	0.10391401  
2023-05-18 15:41:10.407: [iter 87 : loss : 0.1368 = 0.0457 + 0.0862 + 0.0048, time: 7.580944]
2023-05-18 15:41:10.569: epoch 87:	0.02600260  	0.19139278  	0.10423123  
2023-05-18 15:41:18.806: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 8.235572]
2023-05-18 15:41:18.966: epoch 88:	0.02610139  	0.19187133  	0.10463943  
2023-05-18 15:41:18.966: Find a better model.
2023-05-18 15:41:28.542: [iter 89 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 9.574239]
2023-05-18 15:41:28.810: epoch 89:	0.02608728  	0.19166140  	0.10448528  
2023-05-18 15:41:36.944: [iter 90 : loss : 0.1366 = 0.0458 + 0.0859 + 0.0049, time: 8.132993]
2023-05-18 15:41:37.114: epoch 90:	0.02610139  	0.19171245  	0.10471978  
2023-05-18 15:41:45.655: [iter 91 : loss : 0.1351 = 0.0443 + 0.0858 + 0.0050, time: 8.537737]
2023-05-18 15:41:45.822: epoch 91:	0.02610140  	0.19161956  	0.10471230  
2023-05-18 15:41:54.173: [iter 92 : loss : 0.1341 = 0.0434 + 0.0857 + 0.0050, time: 8.350278]
2023-05-18 15:41:54.349: epoch 92:	0.02612256  	0.19165803  	0.10482343  
2023-05-18 15:42:02.409: [iter 93 : loss : 0.1345 = 0.0438 + 0.0857 + 0.0051, time: 8.058173]
2023-05-18 15:42:02.569: epoch 93:	0.02615079  	0.19204566  	0.10510227  
2023-05-18 15:42:02.569: Find a better model.
2023-05-18 15:42:10.956: [iter 94 : loss : 0.1324 = 0.0418 + 0.0856 + 0.0051, time: 8.384993]
2023-05-18 15:42:11.159: epoch 94:	0.02622135  	0.19236970  	0.10518341  
2023-05-18 15:42:11.159: Find a better model.
2023-05-18 15:42:19.226: [iter 95 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 8.063992]
2023-05-18 15:42:19.395: epoch 95:	0.02620724  	0.19230530  	0.10539409  
2023-05-18 15:42:27.592: [iter 96 : loss : 0.1318 = 0.0412 + 0.0854 + 0.0052, time: 8.195993]
2023-05-18 15:42:27.753: epoch 96:	0.02624252  	0.19235794  	0.10560036  
2023-05-18 15:42:36.751: [iter 97 : loss : 0.1300 = 0.0395 + 0.0853 + 0.0052, time: 8.996498]
2023-05-18 15:42:37.040: epoch 97:	0.02627780  	0.19237629  	0.10566756  
2023-05-18 15:42:37.040: Find a better model.
2023-05-18 15:42:45.145: [iter 98 : loss : 0.1310 = 0.0405 + 0.0853 + 0.0052, time: 8.104341]
2023-05-18 15:42:45.310: epoch 98:	0.02632720  	0.19298534  	0.10594308  
2023-05-18 15:42:45.310: Find a better model.
2023-05-18 15:42:53.973: [iter 99 : loss : 0.1298 = 0.0394 + 0.0852 + 0.0053, time: 8.661202]
2023-05-18 15:42:54.138: epoch 99:	0.02630603  	0.19314100  	0.10610343  
2023-05-18 15:42:54.138: Find a better model.
2023-05-18 15:43:01.850: [iter 100 : loss : 0.1292 = 0.0387 + 0.0851 + 0.0053, time: 7.711268]
2023-05-18 15:43:02.003: epoch 100:	0.02640482  	0.19371621  	0.10627745  
2023-05-18 15:43:02.003: Find a better model.
2023-05-18 15:43:10.669: [iter 101 : loss : 0.1289 = 0.0385 + 0.0850 + 0.0053, time: 8.663991]
2023-05-18 15:43:10.819: epoch 101:	0.02636248  	0.19349129  	0.10632834  
2023-05-18 15:43:19.794: [iter 102 : loss : 0.1279 = 0.0375 + 0.0850 + 0.0054, time: 8.972519]
2023-05-18 15:43:20.083: epoch 102:	0.02635542  	0.19365630  	0.10630733  
2023-05-18 15:43:28.104: [iter 103 : loss : 0.1274 = 0.0371 + 0.0849 + 0.0054, time: 8.019992]
2023-05-18 15:43:28.262: epoch 103:	0.02641188  	0.19401985  	0.10658213  
2023-05-18 15:43:28.262: Find a better model.
2023-05-18 15:43:36.652: [iter 104 : loss : 0.1279 = 0.0376 + 0.0848 + 0.0054, time: 8.389002]
2023-05-18 15:43:36.816: epoch 104:	0.02646833  	0.19456317  	0.10696631  
2023-05-18 15:43:36.816: Find a better model.
2023-05-18 15:43:44.374: [iter 105 : loss : 0.1272 = 0.0370 + 0.0847 + 0.0055, time: 7.556499]
2023-05-18 15:43:44.535: epoch 105:	0.02656006  	0.19511846  	0.10716396  
2023-05-18 15:43:44.536: Find a better model.
2023-05-18 15:43:52.737: [iter 106 : loss : 0.1266 = 0.0363 + 0.0847 + 0.0055, time: 8.198992]
2023-05-18 15:43:52.898: epoch 106:	0.02651772  	0.19470173  	0.10695430  
2023-05-18 15:44:02.216: [iter 107 : loss : 0.1260 = 0.0359 + 0.0846 + 0.0055, time: 9.315215]
2023-05-18 15:44:02.481: epoch 107:	0.02653889  	0.19519161  	0.10712438  
2023-05-18 15:44:02.481: Find a better model.
2023-05-18 15:44:10.556: [iter 108 : loss : 0.1258 = 0.0356 + 0.0845 + 0.0056, time: 8.073074]
2023-05-18 15:44:10.725: epoch 108:	0.02648950  	0.19478707  	0.10700340  
2023-05-18 15:44:19.109: [iter 109 : loss : 0.1242 = 0.0341 + 0.0845 + 0.0056, time: 8.382221]
2023-05-18 15:44:19.267: epoch 109:	0.02644715  	0.19464102  	0.10690024  
2023-05-18 15:44:28.181: [iter 110 : loss : 0.1239 = 0.0338 + 0.0845 + 0.0056, time: 8.912352]
2023-05-18 15:44:28.357: epoch 110:	0.02644715  	0.19455007  	0.10707244  
2023-05-18 15:44:36.339: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 7.979002]
2023-05-18 15:44:36.498: epoch 111:	0.02649654  	0.19453073  	0.10712910  
2023-05-18 15:44:44.530: [iter 112 : loss : 0.1235 = 0.0334 + 0.0843 + 0.0057, time: 8.031008]
2023-05-18 15:44:44.688: epoch 112:	0.02653888  	0.19491747  	0.10724920  
2023-05-18 15:44:52.646: [iter 113 : loss : 0.1236 = 0.0335 + 0.0843 + 0.0057, time: 7.957057]
2023-05-18 15:44:52.819: epoch 113:	0.02656006  	0.19536442  	0.10729524  
2023-05-18 15:44:52.819: Find a better model.
2023-05-18 15:45:01.070: [iter 114 : loss : 0.1225 = 0.0324 + 0.0842 + 0.0058, time: 8.248996]
2023-05-18 15:45:01.279: epoch 114:	0.02662356  	0.19572157  	0.10755777  
2023-05-18 15:45:01.279: Find a better model.
2023-05-18 15:45:10.161: [iter 115 : loss : 0.1222 = 0.0323 + 0.0841 + 0.0058, time: 8.877010]
2023-05-18 15:45:10.400: epoch 115:	0.02667296  	0.19614668  	0.10774351  
2023-05-18 15:45:10.401: Find a better model.
2023-05-18 15:45:18.483: [iter 116 : loss : 0.1212 = 0.0312 + 0.0841 + 0.0058, time: 8.081128]
2023-05-18 15:45:18.644: epoch 116:	0.02665179  	0.19597659  	0.10752459  
2023-05-18 15:45:26.997: [iter 117 : loss : 0.1210 = 0.0310 + 0.0840 + 0.0059, time: 8.351003]
2023-05-18 15:45:27.157: epoch 117:	0.02668707  	0.19637154  	0.10790741  
2023-05-18 15:45:27.157: Find a better model.
2023-05-18 15:45:34.636: [iter 118 : loss : 0.1210 = 0.0311 + 0.0840 + 0.0059, time: 7.478101]
2023-05-18 15:45:34.794: epoch 118:	0.02666590  	0.19619803  	0.10802504  
2023-05-18 15:45:42.715: [iter 119 : loss : 0.1198 = 0.0300 + 0.0839 + 0.0059, time: 7.919003]
2023-05-18 15:45:42.875: epoch 119:	0.02663062  	0.19590703  	0.10790620  
2023-05-18 15:45:52.553: [iter 120 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 9.675339]
2023-05-18 15:45:52.818: epoch 120:	0.02658828  	0.19527970  	0.10776187  
2023-05-18 15:46:00.956: [iter 121 : loss : 0.1202 = 0.0304 + 0.0838 + 0.0060, time: 8.136529]
2023-05-18 15:46:01.128: epoch 121:	0.02665179  	0.19585119  	0.10794745  
2023-05-18 15:46:09.370: [iter 122 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 8.240992]
2023-05-18 15:46:09.531: epoch 122:	0.02667296  	0.19561020  	0.10809408  
2023-05-18 15:46:17.945: [iter 123 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0061, time: 8.412023]
2023-05-18 15:46:18.118: epoch 123:	0.02672235  	0.19584917  	0.10804119  
2023-05-18 15:46:26.126: [iter 124 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 8.005596]
2023-05-18 15:46:26.292: epoch 124:	0.02675764  	0.19596553  	0.10803845  
2023-05-18 15:46:34.513: [iter 125 : loss : 0.1181 = 0.0283 + 0.0836 + 0.0061, time: 8.218993]
2023-05-18 15:46:34.667: epoch 125:	0.02668707  	0.19526538  	0.10798385  
2023-05-18 15:46:42.570: [iter 126 : loss : 0.1179 = 0.0281 + 0.0836 + 0.0062, time: 7.901199]
2023-05-18 15:46:42.749: epoch 126:	0.02672235  	0.19556889  	0.10814211  
2023-05-18 15:46:50.848: [iter 127 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0062, time: 8.098002]
2023-05-18 15:46:51.011: epoch 127:	0.02665179  	0.19518311  	0.10800061  
2023-05-18 15:46:59.819: [iter 128 : loss : 0.1180 = 0.0283 + 0.0835 + 0.0062, time: 8.806043]
2023-05-18 15:47:00.105: epoch 128:	0.02668707  	0.19562799  	0.10825257  
2023-05-18 15:47:08.124: [iter 129 : loss : 0.1172 = 0.0275 + 0.0835 + 0.0063, time: 8.018013]
2023-05-18 15:47:08.288: epoch 129:	0.02665884  	0.19563505  	0.10820335  
2023-05-18 15:47:16.556: [iter 130 : loss : 0.1171 = 0.0274 + 0.0834 + 0.0063, time: 8.267002]
2023-05-18 15:47:16.724: epoch 130:	0.02664473  	0.19536659  	0.10818110  
2023-05-18 15:47:24.167: [iter 131 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 7.442233]
2023-05-18 15:47:24.348: epoch 131:	0.02670118  	0.19580257  	0.10812820  
2023-05-18 15:47:32.274: [iter 132 : loss : 0.1166 = 0.0269 + 0.0833 + 0.0063, time: 7.924013]
2023-05-18 15:47:32.433: epoch 132:	0.02672236  	0.19578257  	0.10818515  
2023-05-18 15:47:40.492: [iter 133 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 8.058006]
2023-05-18 15:47:40.769: epoch 133:	0.02672941  	0.19550554  	0.10824009  
2023-05-18 15:47:48.542: [iter 134 : loss : 0.1160 = 0.0264 + 0.0832 + 0.0064, time: 7.771161]
2023-05-18 15:47:48.704: epoch 134:	0.02673647  	0.19538574  	0.10826506  
2023-05-18 15:47:56.623: [iter 135 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 7.917020]
2023-05-18 15:47:56.796: epoch 135:	0.02672236  	0.19544111  	0.10827824  
2023-05-18 15:48:05.564: [iter 136 : loss : 0.1153 = 0.0257 + 0.0832 + 0.0065, time: 8.766025]
2023-05-18 15:48:05.843: epoch 136:	0.02666591  	0.19496408  	0.10813851  
2023-05-18 15:48:13.873: [iter 137 : loss : 0.1150 = 0.0254 + 0.0831 + 0.0065, time: 8.028003]
2023-05-18 15:48:14.034: epoch 137:	0.02673647  	0.19552709  	0.10829055  
2023-05-18 15:48:22.253: [iter 138 : loss : 0.1144 = 0.0248 + 0.0831 + 0.0065, time: 8.217012]
2023-05-18 15:48:22.433: epoch 138:	0.02674353  	0.19555564  	0.10828361  
2023-05-18 15:48:29.809: [iter 139 : loss : 0.1143 = 0.0247 + 0.0830 + 0.0065, time: 7.374322]
2023-05-18 15:48:29.969: epoch 139:	0.02676470  	0.19567448  	0.10835453  
2023-05-18 15:48:38.069: [iter 140 : loss : 0.1139 = 0.0243 + 0.0830 + 0.0066, time: 8.097030]
2023-05-18 15:48:38.234: epoch 140:	0.02670824  	0.19507842  	0.10828529  
2023-05-18 15:48:47.729: [iter 141 : loss : 0.1143 = 0.0248 + 0.0830 + 0.0066, time: 9.491002]
2023-05-18 15:48:47.990: epoch 141:	0.02668002  	0.19498636  	0.10829581  
2023-05-18 15:48:55.962: [iter 142 : loss : 0.1135 = 0.0239 + 0.0829 + 0.0066, time: 7.971013]
2023-05-18 15:48:56.135: epoch 142:	0.02674353  	0.19539173  	0.10852668  
2023-05-18 15:48:56.135: Early stopping is trigger at epoch: 142
2023-05-18 15:48:56.135: best_result@epoch 117:

2023-05-18 15:48:56.135: 		0.0267      	0.1964      	0.1079      
2023-05-18 16:32:37.837: my pid: 1612
2023-05-18 16:32:37.837: model: model.general_recommender.SGL
2023-05-18 16:32:37.837: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 16:32:37.837: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 16:32:41.325: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 16:32:50.355: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 9.028568]
2023-05-18 16:32:50.519: epoch 1:	0.00128422  	0.00919607  	0.00467490  
2023-05-18 16:32:50.519: Find a better model.
2023-05-18 16:33:00.914: [iter 2 : loss : 0.7713 = 0.6929 + 0.0784 + 0.0000, time: 10.391799]
2023-05-18 16:33:01.236: epoch 2:	0.00268134  	0.01941906  	0.00953243  
2023-05-18 16:33:01.236: Find a better model.
2023-05-18 16:33:10.117: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.877565]
2023-05-18 16:33:10.313: epoch 3:	0.00485462  	0.03572007  	0.01725365  
2023-05-18 16:33:10.313: Find a better model.
2023-05-18 16:33:19.240: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.925010]
2023-05-18 16:33:19.430: epoch 4:	0.00745831  	0.05455611  	0.02686206  
2023-05-18 16:33:19.430: Find a better model.
2023-05-18 16:33:28.387: [iter 5 : loss : 0.7697 = 0.6909 + 0.0787 + 0.0000, time: 8.956741]
2023-05-18 16:33:28.557: epoch 5:	0.01115581  	0.08240398  	0.03875608  
2023-05-18 16:33:28.557: Find a better model.
2023-05-18 16:33:36.931: [iter 6 : loss : 0.7674 = 0.6883 + 0.0791 + 0.0000, time: 8.373021]
2023-05-18 16:33:37.108: epoch 6:	0.01501568  	0.10892612  	0.05204058  
2023-05-18 16:33:37.108: Find a better model.
2023-05-18 16:33:45.539: [iter 7 : loss : 0.7614 = 0.6815 + 0.0798 + 0.0000, time: 8.430000]
2023-05-18 16:33:45.710: epoch 7:	0.01764771  	0.12772366  	0.06277381  
2023-05-18 16:33:45.710: Find a better model.
2023-05-18 16:33:53.721: [iter 8 : loss : 0.7463 = 0.6645 + 0.0817 + 0.0001, time: 8.010051]
2023-05-18 16:33:53.880: epoch 8:	0.01863561  	0.13615103  	0.06861093  
2023-05-18 16:33:53.880: Find a better model.
2023-05-18 16:34:02.381: [iter 9 : loss : 0.7119 = 0.6263 + 0.0854 + 0.0001, time: 8.498326]
2023-05-18 16:34:02.675: epoch 9:	0.01883321  	0.13842949  	0.06926411  
2023-05-18 16:34:02.675: Find a better model.
2023-05-18 16:34:12.125: [iter 10 : loss : 0.6518 = 0.5606 + 0.0909 + 0.0002, time: 9.443923]
2023-05-18 16:34:12.407: epoch 10:	0.01854389  	0.13688333  	0.06844150  
2023-05-18 16:34:20.823: [iter 11 : loss : 0.5758 = 0.4794 + 0.0960 + 0.0004, time: 8.414281]
2023-05-18 16:34:20.991: epoch 11:	0.01835337  	0.13594326  	0.06785688  
2023-05-18 16:34:29.456: [iter 12 : loss : 0.5062 = 0.4061 + 0.0995 + 0.0005, time: 8.463037]
2023-05-18 16:34:29.608: epoch 12:	0.01843805  	0.13646682  	0.06845834  
2023-05-18 16:34:38.738: [iter 13 : loss : 0.4550 = 0.3528 + 0.1014 + 0.0007, time: 9.127876]
2023-05-18 16:34:38.981: epoch 13:	0.01848039  	0.13696104  	0.06907103  
2023-05-18 16:34:47.252: [iter 14 : loss : 0.4163 = 0.3131 + 0.1024 + 0.0008, time: 8.269774]
2023-05-18 16:34:47.407: epoch 14:	0.01871326  	0.13894767  	0.07002751  
2023-05-18 16:34:47.408: Find a better model.
2023-05-18 16:34:56.082: [iter 15 : loss : 0.3892 = 0.2855 + 0.1027 + 0.0010, time: 8.673000]
2023-05-18 16:34:56.239: epoch 15:	0.01889673  	0.14017715  	0.07092628  
2023-05-18 16:34:56.239: Find a better model.
2023-05-18 16:35:03.817: [iter 16 : loss : 0.3669 = 0.2631 + 0.1027 + 0.0011, time: 7.576571]
2023-05-18 16:35:03.977: epoch 16:	0.01914370  	0.14154711  	0.07168294  
2023-05-18 16:35:03.977: Find a better model.
2023-05-18 16:35:12.104: [iter 17 : loss : 0.3503 = 0.2466 + 0.1026 + 0.0012, time: 8.126020]
2023-05-18 16:35:12.268: epoch 17:	0.01939068  	0.14330333  	0.07277896  
2023-05-18 16:35:12.269: Find a better model.
2023-05-18 16:35:20.481: [iter 18 : loss : 0.3349 = 0.2313 + 0.1023 + 0.0013, time: 8.211702]
2023-05-18 16:35:20.654: epoch 18:	0.01952476  	0.14406374  	0.07329693  
2023-05-18 16:35:20.655: Find a better model.
2023-05-18 16:35:28.470: [iter 19 : loss : 0.3208 = 0.2175 + 0.1019 + 0.0014, time: 7.813729]
2023-05-18 16:35:28.692: epoch 19:	0.01970117  	0.14527795  	0.07401281  
2023-05-18 16:35:28.693: Find a better model.
2023-05-18 16:35:37.236: [iter 20 : loss : 0.3112 = 0.2081 + 0.1015 + 0.0015, time: 8.538991]
2023-05-18 16:35:37.515: epoch 20:	0.01991993  	0.14704959  	0.07490968  
2023-05-18 16:35:37.515: Find a better model.
2023-05-18 16:35:46.787: [iter 21 : loss : 0.3016 = 0.1990 + 0.1011 + 0.0016, time: 9.269094]
2023-05-18 16:35:47.055: epoch 21:	0.02013868  	0.14855960  	0.07597543  
2023-05-18 16:35:47.056: Find a better model.
2023-05-18 16:35:55.408: [iter 22 : loss : 0.2931 = 0.1907 + 0.1008 + 0.0016, time: 8.349551]
2023-05-18 16:35:55.590: epoch 22:	0.02036449  	0.14997683  	0.07659942  
2023-05-18 16:35:55.590: Find a better model.
2023-05-18 16:36:04.131: [iter 23 : loss : 0.2848 = 0.1828 + 0.1002 + 0.0017, time: 8.539097]
2023-05-18 16:36:04.294: epoch 23:	0.02042094  	0.15050617  	0.07722858  
2023-05-18 16:36:04.294: Find a better model.
2023-05-18 16:36:13.346: [iter 24 : loss : 0.2785 = 0.1768 + 0.0999 + 0.0018, time: 9.048331]
2023-05-18 16:36:13.625: epoch 24:	0.02065380  	0.15213458  	0.07797451  
2023-05-18 16:36:13.625: Find a better model.
2023-05-18 16:36:22.099: [iter 25 : loss : 0.2717 = 0.1704 + 0.0994 + 0.0019, time: 8.472259]
2023-05-18 16:36:22.263: epoch 25:	0.02083727  	0.15352981  	0.07875110  
2023-05-18 16:36:22.263: Find a better model.
2023-05-18 16:36:30.664: [iter 26 : loss : 0.2680 = 0.1671 + 0.0990 + 0.0019, time: 8.399534]
2023-05-18 16:36:30.833: epoch 26:	0.02104191  	0.15533711  	0.07953889  
2023-05-18 16:36:30.833: Find a better model.
2023-05-18 16:36:38.582: [iter 27 : loss : 0.2604 = 0.1598 + 0.0986 + 0.0020, time: 7.748017]
2023-05-18 16:36:38.741: epoch 27:	0.02120421  	0.15639402  	0.08034513  
2023-05-18 16:36:38.742: Find a better model.
2023-05-18 16:36:47.049: [iter 28 : loss : 0.2555 = 0.1553 + 0.0982 + 0.0021, time: 8.306058]
2023-05-18 16:36:47.213: epoch 28:	0.02139474  	0.15731892  	0.08103777  
2023-05-18 16:36:47.213: Find a better model.
2023-05-18 16:36:56.378: [iter 29 : loss : 0.2509 = 0.1510 + 0.0977 + 0.0021, time: 9.162951]
2023-05-18 16:36:56.656: epoch 29:	0.02157821  	0.15858331  	0.08184560  
2023-05-18 16:36:56.656: Find a better model.
2023-05-18 16:37:04.796: [iter 30 : loss : 0.2445 = 0.1449 + 0.0974 + 0.0022, time: 8.138158]
2023-05-18 16:37:04.972: epoch 30:	0.02178990  	0.16003005  	0.08273128  
2023-05-18 16:37:04.972: Find a better model.
2023-05-18 16:37:13.256: [iter 31 : loss : 0.2410 = 0.1418 + 0.0969 + 0.0023, time: 8.281992]
2023-05-18 16:37:13.420: epoch 31:	0.02191692  	0.16101600  	0.08325044  
2023-05-18 16:37:13.421: Find a better model.
2023-05-18 16:37:22.640: [iter 32 : loss : 0.2353 = 0.1364 + 0.0966 + 0.0023, time: 9.217218]
2023-05-18 16:37:22.912: epoch 32:	0.02200160  	0.16196856  	0.08383195  
2023-05-18 16:37:22.912: Find a better model.
2023-05-18 16:37:31.197: [iter 33 : loss : 0.2327 = 0.1341 + 0.0962 + 0.0024, time: 8.284024]
2023-05-18 16:37:31.351: epoch 33:	0.02212156  	0.16262875  	0.08447040  
2023-05-18 16:37:31.351: Find a better model.
2023-05-18 16:37:39.696: [iter 34 : loss : 0.2288 = 0.1305 + 0.0959 + 0.0024, time: 8.344073]
2023-05-18 16:37:39.882: epoch 34:	0.02223447  	0.16329244  	0.08500116  
2023-05-18 16:37:39.882: Find a better model.
2023-05-18 16:37:48.136: [iter 35 : loss : 0.2252 = 0.1271 + 0.0956 + 0.0025, time: 8.253003]
2023-05-18 16:37:48.299: epoch 35:	0.02234031  	0.16424108  	0.08562994  
2023-05-18 16:37:48.299: Find a better model.
2023-05-18 16:37:56.215: [iter 36 : loss : 0.2220 = 0.1241 + 0.0953 + 0.0025, time: 7.915018]
2023-05-18 16:37:56.376: epoch 36:	0.02259434  	0.16620621  	0.08647076  
2023-05-18 16:37:56.376: Find a better model.
2023-05-18 16:38:04.685: [iter 37 : loss : 0.2177 = 0.1202 + 0.0949 + 0.0026, time: 8.306206]
2023-05-18 16:38:04.849: epoch 37:	0.02270019  	0.16718248  	0.08683956  
2023-05-18 16:38:04.849: Find a better model.
2023-05-18 16:38:12.371: [iter 38 : loss : 0.2162 = 0.1189 + 0.0946 + 0.0027, time: 7.520005]
2023-05-18 16:38:12.532: epoch 38:	0.02280604  	0.16787975  	0.08745251  
2023-05-18 16:38:12.532: Find a better model.
2023-05-18 16:38:20.631: [iter 39 : loss : 0.2118 = 0.1148 + 0.0943 + 0.0027, time: 8.098068]
2023-05-18 16:38:20.793: epoch 39:	0.02306007  	0.16982865  	0.08846593  
2023-05-18 16:38:20.793: Find a better model.
2023-05-18 16:38:29.023: [iter 40 : loss : 0.2086 = 0.1118 + 0.0940 + 0.0028, time: 8.228022]
2023-05-18 16:38:29.193: epoch 40:	0.02312358  	0.17024986  	0.08899929  
2023-05-18 16:38:29.193: Find a better model.
2023-05-18 16:38:36.977: [iter 41 : loss : 0.2069 = 0.1104 + 0.0937 + 0.0028, time: 7.782071]
2023-05-18 16:38:37.332: epoch 41:	0.02317298  	0.17070039  	0.08957300  
2023-05-18 16:38:37.332: Find a better model.
2023-05-18 16:38:45.341: [iter 42 : loss : 0.2045 = 0.1082 + 0.0934 + 0.0029, time: 8.005571]
2023-05-18 16:38:45.850: epoch 42:	0.02338467  	0.17201792  	0.09034567  
2023-05-18 16:38:45.850: Find a better model.
2023-05-18 16:38:54.930: [iter 43 : loss : 0.2007 = 0.1047 + 0.0931 + 0.0029, time: 9.078016]
2023-05-18 16:38:55.209: epoch 43:	0.02335644  	0.17188641  	0.09058265  
2023-05-18 16:39:03.389: [iter 44 : loss : 0.1974 = 0.1016 + 0.0929 + 0.0030, time: 8.179017]
2023-05-18 16:39:03.568: epoch 44:	0.02356108  	0.17315741  	0.09126142  
2023-05-18 16:39:03.568: Find a better model.
2023-05-18 16:39:11.961: [iter 45 : loss : 0.1954 = 0.0997 + 0.0927 + 0.0030, time: 8.392015]
2023-05-18 16:39:12.122: epoch 45:	0.02358931  	0.17370938  	0.09169360  
2023-05-18 16:39:12.122: Find a better model.
2023-05-18 16:39:21.174: [iter 46 : loss : 0.1928 = 0.0974 + 0.0924 + 0.0031, time: 9.050030]
2023-05-18 16:39:21.452: epoch 46:	0.02375161  	0.17471738  	0.09239100  
2023-05-18 16:39:21.452: Find a better model.
2023-05-18 16:39:29.377: [iter 47 : loss : 0.1919 = 0.0966 + 0.0922 + 0.0031, time: 7.924021]
2023-05-18 16:39:29.537: epoch 47:	0.02385040  	0.17586944  	0.09296210  
2023-05-18 16:39:29.537: Find a better model.
2023-05-18 16:39:37.831: [iter 48 : loss : 0.1882 = 0.0931 + 0.0920 + 0.0032, time: 8.292091]
2023-05-18 16:39:38.007: epoch 48:	0.02397742  	0.17676744  	0.09339048  
2023-05-18 16:39:38.007: Find a better model.
2023-05-18 16:39:46.140: [iter 49 : loss : 0.1852 = 0.0902 + 0.0917 + 0.0032, time: 8.131025]
2023-05-18 16:39:46.303: epoch 49:	0.02402681  	0.17699200  	0.09383710  
2023-05-18 16:39:46.304: Find a better model.
2023-05-18 16:39:54.180: [iter 50 : loss : 0.1842 = 0.0895 + 0.0915 + 0.0033, time: 7.875038]
2023-05-18 16:39:54.347: epoch 50:	0.02406914  	0.17745867  	0.09440774  
2023-05-18 16:39:54.348: Find a better model.
2023-05-18 16:40:02.571: [iter 51 : loss : 0.1812 = 0.0866 + 0.0913 + 0.0033, time: 8.221231]
2023-05-18 16:40:02.739: epoch 51:	0.02408325  	0.17757402  	0.09445629  
2023-05-18 16:40:02.739: Find a better model.
2023-05-18 16:40:10.175: [iter 52 : loss : 0.1810 = 0.0866 + 0.0911 + 0.0034, time: 7.432055]
2023-05-18 16:40:10.338: epoch 52:	0.02420321  	0.17859001  	0.09485489  
2023-05-18 16:40:10.338: Find a better model.
2023-05-18 16:40:18.187: [iter 53 : loss : 0.1792 = 0.0849 + 0.0909 + 0.0034, time: 7.848192]
2023-05-18 16:40:18.348: epoch 53:	0.02431612  	0.17963383  	0.09541973  
2023-05-18 16:40:18.354: Find a better model.
2023-05-18 16:40:26.366: [iter 54 : loss : 0.1768 = 0.0827 + 0.0906 + 0.0035, time: 8.011558]
2023-05-18 16:40:26.529: epoch 54:	0.02430906  	0.17947248  	0.09577107  
2023-05-18 16:40:34.051: [iter 55 : loss : 0.1749 = 0.0810 + 0.0904 + 0.0035, time: 7.519027]
2023-05-18 16:40:34.213: epoch 55:	0.02439374  	0.18003798  	0.09615763  
2023-05-18 16:40:34.213: Find a better model.
2023-05-18 16:40:42.388: [iter 56 : loss : 0.1733 = 0.0795 + 0.0903 + 0.0035, time: 8.174081]
2023-05-18 16:40:42.551: epoch 56:	0.02445725  	0.18031459  	0.09658372  
2023-05-18 16:40:42.551: Find a better model.
2023-05-18 16:40:52.120: [iter 57 : loss : 0.1716 = 0.0779 + 0.0901 + 0.0036, time: 9.564149]
2023-05-18 16:40:52.389: epoch 57:	0.02448547  	0.18053529  	0.09679636  
2023-05-18 16:40:52.389: Find a better model.
2023-05-18 16:41:00.353: [iter 58 : loss : 0.1696 = 0.0760 + 0.0899 + 0.0036, time: 7.963146]
2023-05-18 16:41:00.530: epoch 58:	0.02452075  	0.18057403  	0.09712517  
2023-05-18 16:41:00.530: Find a better model.
2023-05-18 16:41:08.555: [iter 59 : loss : 0.1685 = 0.0751 + 0.0897 + 0.0037, time: 8.023097]
2023-05-18 16:41:08.719: epoch 59:	0.02459837  	0.18137752  	0.09759684  
2023-05-18 16:41:08.719: Find a better model.
2023-05-18 16:41:17.667: [iter 60 : loss : 0.1672 = 0.0740 + 0.0896 + 0.0037, time: 8.942123]
2023-05-18 16:41:17.911: epoch 60:	0.02469011  	0.18202534  	0.09805342  
2023-05-18 16:41:17.911: Find a better model.
2023-05-18 16:41:26.090: [iter 61 : loss : 0.1657 = 0.0725 + 0.0894 + 0.0038, time: 8.177073]
2023-05-18 16:41:26.279: epoch 61:	0.02471127  	0.18248020  	0.09830203  
2023-05-18 16:41:26.279: Find a better model.
2023-05-18 16:41:34.337: [iter 62 : loss : 0.1640 = 0.0710 + 0.0892 + 0.0038, time: 8.056026]
2023-05-18 16:41:34.564: epoch 62:	0.02465482  	0.18250155  	0.09839380  
2023-05-18 16:41:34.565: Find a better model.
2023-05-18 16:41:43.387: [iter 63 : loss : 0.1627 = 0.0697 + 0.0891 + 0.0039, time: 8.819039]
2023-05-18 16:41:43.640: epoch 63:	0.02483124  	0.18356137  	0.09889238  
2023-05-18 16:41:43.640: Find a better model.
2023-05-18 16:41:51.519: [iter 64 : loss : 0.1616 = 0.0688 + 0.0889 + 0.0039, time: 7.877079]
2023-05-18 16:41:51.684: epoch 64:	0.02484535  	0.18368118  	0.09906919  
2023-05-18 16:41:51.684: Find a better model.
2023-05-18 16:41:59.977: [iter 65 : loss : 0.1606 = 0.0679 + 0.0887 + 0.0039, time: 8.290081]
2023-05-18 16:42:00.209: epoch 65:	0.02478890  	0.18311301  	0.09934679  
2023-05-18 16:42:08.382: [iter 66 : loss : 0.1588 = 0.0663 + 0.0886 + 0.0040, time: 8.170419]
2023-05-18 16:42:08.543: epoch 66:	0.02486652  	0.18348388  	0.09960598  
2023-05-18 16:42:16.603: [iter 67 : loss : 0.1573 = 0.0647 + 0.0885 + 0.0040, time: 8.058288]
2023-05-18 16:42:16.768: epoch 67:	0.02486653  	0.18369401  	0.09974732  
2023-05-18 16:42:16.768: Find a better model.
2023-05-18 16:42:24.953: [iter 68 : loss : 0.1569 = 0.0645 + 0.0883 + 0.0041, time: 8.182437]
2023-05-18 16:42:25.126: epoch 68:	0.02498649  	0.18431687  	0.09999322  
2023-05-18 16:42:25.127: Find a better model.
2023-05-18 16:42:32.625: [iter 69 : loss : 0.1550 = 0.0627 + 0.0882 + 0.0041, time: 7.497372]
2023-05-18 16:42:32.788: epoch 69:	0.02507116  	0.18504307  	0.10044591  
2023-05-18 16:42:32.788: Find a better model.
2023-05-18 16:42:40.741: [iter 70 : loss : 0.1532 = 0.0610 + 0.0880 + 0.0041, time: 7.952197]
2023-05-18 16:42:40.905: epoch 70:	0.02515583  	0.18553114  	0.10065840  
2023-05-18 16:42:40.905: Find a better model.
2023-05-18 16:42:49.135: [iter 71 : loss : 0.1519 = 0.0597 + 0.0880 + 0.0042, time: 8.229040]
2023-05-18 16:42:49.291: epoch 71:	0.02515583  	0.18544336  	0.10078154  
2023-05-18 16:42:56.816: [iter 72 : loss : 0.1516 = 0.0595 + 0.0878 + 0.0042, time: 7.524308]
2023-05-18 16:42:56.976: epoch 72:	0.02516288  	0.18566033  	0.10109068  
2023-05-18 16:42:56.976: Find a better model.
2023-05-18 16:43:04.953: [iter 73 : loss : 0.1504 = 0.0584 + 0.0877 + 0.0043, time: 7.975130]
2023-05-18 16:43:05.122: epoch 73:	0.02518405  	0.18561451  	0.10110696  
2023-05-18 16:43:13.623: [iter 74 : loss : 0.1490 = 0.0571 + 0.0876 + 0.0043, time: 8.497992]
2023-05-18 16:43:13.907: epoch 74:	0.02531106  	0.18645325  	0.10153259  
2023-05-18 16:43:13.907: Find a better model.
2023-05-18 16:43:21.820: [iter 75 : loss : 0.1485 = 0.0567 + 0.0874 + 0.0044, time: 7.912107]
2023-05-18 16:43:21.990: epoch 75:	0.02541691  	0.18737364  	0.10200689  
2023-05-18 16:43:21.990: Find a better model.
2023-05-18 16:43:30.406: [iter 76 : loss : 0.1474 = 0.0557 + 0.0873 + 0.0044, time: 8.415433]
2023-05-18 16:43:30.561: epoch 76:	0.02542397  	0.18727136  	0.10222210  
2023-05-18 16:43:39.530: [iter 77 : loss : 0.1465 = 0.0548 + 0.0872 + 0.0044, time: 8.965554]
2023-05-18 16:43:39.806: epoch 77:	0.02554393  	0.18806098  	0.10266697  
2023-05-18 16:43:39.806: Find a better model.
2023-05-18 16:43:47.889: [iter 78 : loss : 0.1453 = 0.0537 + 0.0871 + 0.0045, time: 8.082005]
2023-05-18 16:43:48.071: epoch 78:	0.02551570  	0.18791908  	0.10276196  
2023-05-18 16:43:56.329: [iter 79 : loss : 0.1440 = 0.0525 + 0.0869 + 0.0045, time: 8.252432]
2023-05-18 16:43:56.482: epoch 79:	0.02560744  	0.18850078  	0.10282575  
2023-05-18 16:43:56.483: Find a better model.
2023-05-18 16:44:05.333: [iter 80 : loss : 0.1436 = 0.0521 + 0.0869 + 0.0046, time: 8.844090]
2023-05-18 16:44:05.612: epoch 80:	0.02558626  	0.18851517  	0.10300896  
2023-05-18 16:44:05.612: Find a better model.
2023-05-18 16:44:13.678: [iter 81 : loss : 0.1432 = 0.0518 + 0.0868 + 0.0046, time: 8.064391]
2023-05-18 16:44:13.843: epoch 81:	0.02560038  	0.18875723  	0.10318477  
2023-05-18 16:44:13.843: Find a better model.
2023-05-18 16:44:21.946: [iter 82 : loss : 0.1418 = 0.0505 + 0.0867 + 0.0046, time: 8.101003]
2023-05-18 16:44:22.174: epoch 82:	0.02569212  	0.18952323  	0.10364058  
2023-05-18 16:44:22.174: Find a better model.
2023-05-18 16:44:30.728: [iter 83 : loss : 0.1409 = 0.0497 + 0.0865 + 0.0047, time: 8.550706]
2023-05-18 16:44:30.911: epoch 83:	0.02569917  	0.18962283  	0.10389604  
2023-05-18 16:44:30.911: Find a better model.
2023-05-18 16:44:38.886: [iter 84 : loss : 0.1407 = 0.0495 + 0.0865 + 0.0047, time: 7.973991]
2023-05-18 16:44:39.054: epoch 84:	0.02575563  	0.19003801  	0.10413626  
2023-05-18 16:44:39.054: Find a better model.
2023-05-18 16:44:47.530: [iter 85 : loss : 0.1396 = 0.0485 + 0.0863 + 0.0047, time: 8.474143]
2023-05-18 16:44:47.696: epoch 85:	0.02576974  	0.19002980  	0.10423013  
2023-05-18 16:44:55.225: [iter 86 : loss : 0.1395 = 0.0485 + 0.0862 + 0.0048, time: 7.527003]
2023-05-18 16:44:55.389: epoch 86:	0.02574151  	0.18988763  	0.10431094  
2023-05-18 16:45:03.511: [iter 87 : loss : 0.1368 = 0.0458 + 0.0862 + 0.0048, time: 8.120000]
2023-05-18 16:45:03.674: epoch 87:	0.02590381  	0.19098829  	0.10466367  
2023-05-18 16:45:03.674: Find a better model.
2023-05-18 16:45:11.878: [iter 88 : loss : 0.1363 = 0.0453 + 0.0861 + 0.0049, time: 8.203002]
2023-05-18 16:45:12.053: epoch 88:	0.02588969  	0.19091688  	0.10485386  
2023-05-18 16:45:19.799: [iter 89 : loss : 0.1360 = 0.0451 + 0.0860 + 0.0049, time: 7.744993]
2023-05-18 16:45:19.957: epoch 89:	0.02588969  	0.19071022  	0.10486336  
2023-05-18 16:45:28.094: [iter 90 : loss : 0.1363 = 0.0455 + 0.0859 + 0.0049, time: 8.134015]
2023-05-18 16:45:28.251: epoch 90:	0.02593203  	0.19090264  	0.10502975  
2023-05-18 16:45:37.591: [iter 91 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 9.332032]
2023-05-18 16:45:37.866: epoch 91:	0.02595320  	0.19084246  	0.10508659  
2023-05-18 16:45:45.831: [iter 92 : loss : 0.1343 = 0.0436 + 0.0857 + 0.0050, time: 7.963014]
2023-05-18 16:45:45.996: epoch 92:	0.02602376  	0.19154648  	0.10545599  
2023-05-18 16:45:45.996: Find a better model.
2023-05-18 16:45:54.101: [iter 93 : loss : 0.1345 = 0.0439 + 0.0856 + 0.0050, time: 8.104120]
2023-05-18 16:45:54.252: epoch 93:	0.02602376  	0.19131742  	0.10542695  
2023-05-18 16:46:03.203: [iter 94 : loss : 0.1324 = 0.0417 + 0.0856 + 0.0051, time: 8.949029]
2023-05-18 16:46:03.446: epoch 94:	0.02599554  	0.19130369  	0.10544055  
2023-05-18 16:46:11.584: [iter 95 : loss : 0.1318 = 0.0413 + 0.0854 + 0.0051, time: 8.135542]
2023-05-18 16:46:11.757: epoch 95:	0.02600965  	0.19135843  	0.10545347  
2023-05-18 16:46:19.859: [iter 96 : loss : 0.1321 = 0.0415 + 0.0854 + 0.0052, time: 8.100019]
2023-05-18 16:46:20.025: epoch 96:	0.02600259  	0.19136077  	0.10540967  
2023-05-18 16:46:29.120: [iter 97 : loss : 0.1301 = 0.0395 + 0.0853 + 0.0052, time: 9.091166]
2023-05-18 16:46:29.379: epoch 97:	0.02612962  	0.19233565  	0.10566972  
2023-05-18 16:46:29.379: Find a better model.
2023-05-18 16:46:37.416: [iter 98 : loss : 0.1311 = 0.0406 + 0.0852 + 0.0052, time: 8.034526]
2023-05-18 16:46:37.583: epoch 98:	0.02607316  	0.19188426  	0.10571642  
2023-05-18 16:46:45.904: [iter 99 : loss : 0.1300 = 0.0395 + 0.0852 + 0.0053, time: 8.320053]
2023-05-18 16:46:46.087: epoch 99:	0.02615785  	0.19244172  	0.10605283  
2023-05-18 16:46:46.087: Find a better model.
2023-05-18 16:46:54.128: [iter 100 : loss : 0.1291 = 0.0386 + 0.0851 + 0.0053, time: 8.037188]
2023-05-18 16:46:54.292: epoch 100:	0.02615079  	0.19242224  	0.10611933  
2023-05-18 16:47:02.294: [iter 101 : loss : 0.1287 = 0.0384 + 0.0850 + 0.0053, time: 8.001024]
2023-05-18 16:47:02.457: epoch 101:	0.02611550  	0.19196548  	0.10621669  
2023-05-18 16:47:10.656: [iter 102 : loss : 0.1277 = 0.0374 + 0.0850 + 0.0054, time: 8.197019]
2023-05-18 16:47:10.820: epoch 102:	0.02615078  	0.19224589  	0.10628477  
2023-05-18 16:47:18.273: [iter 103 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 7.452013]
2023-05-18 16:47:18.435: epoch 103:	0.02620724  	0.19303481  	0.10648806  
2023-05-18 16:47:18.435: Find a better model.
2023-05-18 16:47:26.470: [iter 104 : loss : 0.1280 = 0.0378 + 0.0848 + 0.0054, time: 8.034004]
2023-05-18 16:47:26.633: epoch 104:	0.02620018  	0.19307262  	0.10669978  
2023-05-18 16:47:26.633: Find a better model.
2023-05-18 16:47:34.805: [iter 105 : loss : 0.1272 = 0.0370 + 0.0847 + 0.0055, time: 8.170002]
2023-05-18 16:47:34.958: epoch 105:	0.02621429  	0.19305593  	0.10673713  
2023-05-18 16:47:42.513: [iter 106 : loss : 0.1265 = 0.0363 + 0.0847 + 0.0055, time: 7.554005]
2023-05-18 16:47:42.677: epoch 106:	0.02629191  	0.19364657  	0.10693855  
2023-05-18 16:47:42.677: Find a better model.
2023-05-18 16:47:50.620: [iter 107 : loss : 0.1259 = 0.0358 + 0.0846 + 0.0055, time: 7.942007]
2023-05-18 16:47:50.782: epoch 107:	0.02624957  	0.19298722  	0.10712768  
2023-05-18 16:47:59.347: [iter 108 : loss : 0.1256 = 0.0355 + 0.0846 + 0.0056, time: 8.562019]
2023-05-18 16:47:59.617: epoch 108:	0.02634130  	0.19365834  	0.10719344  
2023-05-18 16:47:59.617: Find a better model.
2023-05-18 16:48:07.624: [iter 109 : loss : 0.1243 = 0.0342 + 0.0845 + 0.0056, time: 8.005002]
2023-05-18 16:48:07.789: epoch 109:	0.02639070  	0.19408423  	0.10723512  
2023-05-18 16:48:07.790: Find a better model.
2023-05-18 16:48:15.954: [iter 110 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0056, time: 8.159486]
2023-05-18 16:48:16.232: epoch 110:	0.02641892  	0.19467407  	0.10728411  
2023-05-18 16:48:16.232: Find a better model.
2023-05-18 16:48:25.133: [iter 111 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0057, time: 8.898030]
2023-05-18 16:48:25.399: epoch 111:	0.02656005  	0.19564644  	0.10752617  
2023-05-18 16:48:25.399: Find a better model.
2023-05-18 16:48:33.376: [iter 112 : loss : 0.1235 = 0.0335 + 0.0843 + 0.0057, time: 7.976003]
2023-05-18 16:48:33.536: epoch 112:	0.02659534  	0.19615306  	0.10774986  
2023-05-18 16:48:33.536: Find a better model.
2023-05-18 16:48:41.630: [iter 113 : loss : 0.1232 = 0.0331 + 0.0843 + 0.0057, time: 8.093515]
2023-05-18 16:48:41.798: epoch 113:	0.02652478  	0.19565928  	0.10761944  
2023-05-18 16:48:50.620: [iter 114 : loss : 0.1225 = 0.0326 + 0.0842 + 0.0058, time: 8.821045]
2023-05-18 16:48:50.879: epoch 114:	0.02650361  	0.19550841  	0.10777806  
2023-05-18 16:48:58.783: [iter 115 : loss : 0.1222 = 0.0323 + 0.0841 + 0.0058, time: 7.903005]
2023-05-18 16:48:58.968: epoch 115:	0.02659534  	0.19609565  	0.10796940  
2023-05-18 16:49:07.202: [iter 116 : loss : 0.1211 = 0.0312 + 0.0841 + 0.0058, time: 8.232014]
2023-05-18 16:49:07.426: epoch 116:	0.02657417  	0.19603200  	0.10799702  
2023-05-18 16:49:16.179: [iter 117 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0059, time: 8.743126]
2023-05-18 16:49:16.455: epoch 117:	0.02658123  	0.19612603  	0.10812458  
2023-05-18 16:49:24.370: [iter 118 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 7.914003]
2023-05-18 16:49:24.534: epoch 118:	0.02653889  	0.19597571  	0.10803530  
2023-05-18 16:49:32.622: [iter 119 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0059, time: 8.086993]
2023-05-18 16:49:32.793: epoch 119:	0.02658122  	0.19615243  	0.10812647  
2023-05-18 16:49:41.052: [iter 120 : loss : 0.1201 = 0.0303 + 0.0839 + 0.0060, time: 8.257023]
2023-05-18 16:49:41.232: epoch 120:	0.02658123  	0.19615330  	0.10823526  
2023-05-18 16:49:41.232: Find a better model.
2023-05-18 16:49:49.195: [iter 121 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 7.962023]
2023-05-18 16:49:49.356: epoch 121:	0.02656006  	0.19634229  	0.10834875  
2023-05-18 16:49:49.356: Find a better model.
2023-05-18 16:49:57.601: [iter 122 : loss : 0.1193 = 0.0295 + 0.0838 + 0.0060, time: 8.243006]
2023-05-18 16:49:57.768: epoch 122:	0.02659534  	0.19677638  	0.10832050  
2023-05-18 16:49:57.769: Find a better model.
2023-05-18 16:50:05.287: [iter 123 : loss : 0.1193 = 0.0295 + 0.0837 + 0.0061, time: 7.516261]
2023-05-18 16:50:05.449: epoch 123:	0.02668002  	0.19741143  	0.10847634  
2023-05-18 16:50:05.449: Find a better model.
2023-05-18 16:50:13.384: [iter 124 : loss : 0.1186 = 0.0288 + 0.0837 + 0.0061, time: 7.933022]
2023-05-18 16:50:13.550: epoch 124:	0.02676469  	0.19771110  	0.10847784  
2023-05-18 16:50:13.551: Find a better model.
2023-05-18 16:50:21.579: [iter 125 : loss : 0.1178 = 0.0281 + 0.0836 + 0.0061, time: 8.027056]
2023-05-18 16:50:21.745: epoch 125:	0.02669413  	0.19716294  	0.10832110  
2023-05-18 16:50:29.288: [iter 126 : loss : 0.1181 = 0.0284 + 0.0836 + 0.0062, time: 7.540368]
2023-05-18 16:50:29.447: epoch 126:	0.02664473  	0.19692977  	0.10828697  
2023-05-18 16:50:37.396: [iter 127 : loss : 0.1170 = 0.0272 + 0.0835 + 0.0062, time: 7.947993]
2023-05-18 16:50:37.559: epoch 127:	0.02669413  	0.19715898  	0.10839240  
2023-05-18 16:50:45.771: [iter 128 : loss : 0.1181 = 0.0284 + 0.0835 + 0.0062, time: 8.211005]
2023-05-18 16:50:46.035: epoch 128:	0.02674352  	0.19719437  	0.10867006  
2023-05-18 16:50:54.005: [iter 129 : loss : 0.1169 = 0.0272 + 0.0834 + 0.0062, time: 7.968125]
2023-05-18 16:50:54.194: epoch 129:	0.02672941  	0.19753192  	0.10874870  
2023-05-18 16:51:02.537: [iter 130 : loss : 0.1171 = 0.0274 + 0.0834 + 0.0063, time: 8.341011]
2023-05-18 16:51:02.691: epoch 130:	0.02679292  	0.19803356  	0.10891104  
2023-05-18 16:51:02.691: Find a better model.
2023-05-18 16:51:11.671: [iter 131 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 8.978011]
2023-05-18 16:51:11.950: epoch 131:	0.02675059  	0.19812815  	0.10899091  
2023-05-18 16:51:11.950: Find a better model.
2023-05-18 16:51:19.701: [iter 132 : loss : 0.1165 = 0.0269 + 0.0833 + 0.0063, time: 7.748935]
2023-05-18 16:51:19.853: epoch 132:	0.02675057  	0.19787031  	0.10914039  
2023-05-18 16:51:27.345: [iter 133 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 7.490960]
2023-05-18 16:51:27.515: epoch 133:	0.02673646  	0.19761935  	0.10907751  
2023-05-18 16:51:35.109: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 7.593555]
2023-05-18 16:51:35.274: epoch 134:	0.02672940  	0.19758603  	0.10914671  
2023-05-18 16:51:42.929: [iter 135 : loss : 0.1157 = 0.0261 + 0.0832 + 0.0064, time: 7.653838]
2023-05-18 16:51:43.082: epoch 135:	0.02670824  	0.19757098  	0.10914738  
2023-05-18 16:51:50.719: [iter 136 : loss : 0.1153 = 0.0257 + 0.0831 + 0.0065, time: 7.634537]
2023-05-18 16:51:50.884: epoch 136:	0.02673646  	0.19774188  	0.10928658  
2023-05-18 16:51:58.497: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 7.611014]
2023-05-18 16:51:58.651: epoch 137:	0.02675763  	0.19756217  	0.10905346  
2023-05-18 16:52:06.118: [iter 138 : loss : 0.1146 = 0.0251 + 0.0830 + 0.0065, time: 7.464636]
2023-05-18 16:52:06.285: epoch 138:	0.02670118  	0.19737156  	0.10899827  
2023-05-18 16:52:13.928: [iter 139 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0065, time: 7.641187]
2023-05-18 16:52:14.079: epoch 139:	0.02672940  	0.19767767  	0.10918220  
2023-05-18 16:52:21.500: [iter 140 : loss : 0.1139 = 0.0244 + 0.0830 + 0.0066, time: 7.420113]
2023-05-18 16:52:21.653: epoch 140:	0.02679997  	0.19791153  	0.10927780  
2023-05-18 16:52:29.104: [iter 141 : loss : 0.1142 = 0.0247 + 0.0829 + 0.0066, time: 7.450327]
2023-05-18 16:52:29.259: epoch 141:	0.02674352  	0.19753586  	0.10928411  
2023-05-18 16:52:36.872: [iter 142 : loss : 0.1134 = 0.0239 + 0.0829 + 0.0066, time: 7.612592]
2023-05-18 16:52:37.025: epoch 142:	0.02677880  	0.19790424  	0.10945943  
2023-05-18 16:52:44.498: [iter 143 : loss : 0.1134 = 0.0240 + 0.0828 + 0.0066, time: 7.471048]
2023-05-18 16:52:44.652: epoch 143:	0.02667295  	0.19708876  	0.10925829  
2023-05-18 16:52:52.294: [iter 144 : loss : 0.1128 = 0.0233 + 0.0828 + 0.0067, time: 7.640679]
2023-05-18 16:52:52.446: epoch 144:	0.02669412  	0.19668837  	0.10935252  
2023-05-18 16:53:00.115: [iter 145 : loss : 0.1128 = 0.0234 + 0.0828 + 0.0067, time: 7.667425]
2023-05-18 16:53:00.271: epoch 145:	0.02670822  	0.19716839  	0.10952399  
2023-05-18 16:53:07.914: [iter 146 : loss : 0.1132 = 0.0237 + 0.0828 + 0.0067, time: 7.641769]
2023-05-18 16:53:08.069: epoch 146:	0.02677173  	0.19751884  	0.10963913  
2023-05-18 16:53:15.494: [iter 147 : loss : 0.1129 = 0.0235 + 0.0827 + 0.0068, time: 7.424264]
2023-05-18 16:53:15.645: epoch 147:	0.02670823  	0.19712824  	0.10937142  
2023-05-18 16:53:23.264: [iter 148 : loss : 0.1116 = 0.0221 + 0.0827 + 0.0068, time: 7.617335]
2023-05-18 16:53:23.433: epoch 148:	0.02672234  	0.19704369  	0.10939078  
2023-05-18 16:53:31.068: [iter 149 : loss : 0.1120 = 0.0225 + 0.0827 + 0.0068, time: 7.632839]
2023-05-18 16:53:31.221: epoch 149:	0.02681407  	0.19770318  	0.10953416  
2023-05-18 16:53:38.852: [iter 150 : loss : 0.1115 = 0.0220 + 0.0826 + 0.0068, time: 7.629279]
2023-05-18 16:53:39.018: epoch 150:	0.02680701  	0.19779710  	0.10972800  
2023-05-18 16:53:46.501: [iter 151 : loss : 0.1117 = 0.0222 + 0.0826 + 0.0069, time: 7.480812]
2023-05-18 16:53:46.653: epoch 151:	0.02683523  	0.19777411  	0.10967149  
2023-05-18 16:53:54.077: [iter 152 : loss : 0.1108 = 0.0214 + 0.0825 + 0.0069, time: 7.422677]
2023-05-18 16:53:54.235: epoch 152:	0.02679289  	0.19745030  	0.10972390  
2023-05-18 16:54:01.895: [iter 153 : loss : 0.1100 = 0.0206 + 0.0825 + 0.0069, time: 7.658623]
2023-05-18 16:54:02.046: epoch 153:	0.02686346  	0.19805807  	0.10990374  
2023-05-18 16:54:09.460: [iter 154 : loss : 0.1105 = 0.0210 + 0.0825 + 0.0069, time: 7.413058]
2023-05-18 16:54:09.611: epoch 154:	0.02684229  	0.19773242  	0.10986057  
2023-05-18 16:54:17.079: [iter 155 : loss : 0.1112 = 0.0217 + 0.0825 + 0.0070, time: 7.467089]
2023-05-18 16:54:17.246: epoch 155:	0.02684228  	0.19798294  	0.10984983  
2023-05-18 16:54:24.855: [iter 156 : loss : 0.1105 = 0.0211 + 0.0824 + 0.0070, time: 7.607555]
2023-05-18 16:54:25.006: epoch 156:	0.02677172  	0.19739269  	0.10967162  
2023-05-18 16:54:25.006: Early stopping is trigger at epoch: 156
2023-05-18 16:54:25.006: best_result@epoch 131:

2023-05-18 16:54:25.006: 		0.0268      	0.1981      	0.1090      
2023-05-18 17:14:45.193: my pid: 11216
2023-05-18 17:14:45.194: model: model.general_recommender.SGL
2023-05-18 17:14:45.194: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 17:14:45.194: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 17:14:48.410: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 17:14:57.285: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.875247]
2023-05-18 17:14:57.436: epoch 1:	0.00151002  	0.01087088  	0.00539393  
2023-05-18 17:14:57.436: Find a better model.
2023-05-18 17:15:05.845: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 8.406063]
2023-05-18 17:15:06.042: epoch 2:	0.00257550  	0.01894326  	0.00939621  
2023-05-18 17:15:06.042: Find a better model.
2023-05-18 17:15:14.897: [iter 3 : loss : 0.7710 = 0.6926 + 0.0784 + 0.0000, time: 8.853185]
2023-05-18 17:15:15.049: epoch 3:	0.00479817  	0.03601233  	0.01814734  
2023-05-18 17:15:15.049: Find a better model.
2023-05-18 17:15:23.973: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.922786]
2023-05-18 17:15:24.128: epoch 4:	0.00771233  	0.05600555  	0.02836130  
2023-05-18 17:15:24.128: Find a better model.
2023-05-18 17:15:32.825: [iter 5 : loss : 0.7696 = 0.6909 + 0.0788 + 0.0000, time: 8.696475]
2023-05-18 17:15:33.056: epoch 5:	0.01157214  	0.08333895  	0.04088349  
2023-05-18 17:15:33.056: Find a better model.
2023-05-18 17:15:42.559: [iter 6 : loss : 0.7674 = 0.6883 + 0.0791 + 0.0000, time: 9.501002]
2023-05-18 17:15:42.838: epoch 6:	0.01507213  	0.10834033  	0.05394423  
2023-05-18 17:15:42.838: Find a better model.
2023-05-18 17:15:51.267: [iter 7 : loss : 0.7613 = 0.6814 + 0.0798 + 0.0000, time: 8.427892]
2023-05-18 17:15:51.451: epoch 7:	0.01787352  	0.12864143  	0.06353781  
2023-05-18 17:15:51.451: Find a better model.
2023-05-18 17:16:00.055: [iter 8 : loss : 0.7461 = 0.6643 + 0.0817 + 0.0001, time: 8.602189]
2023-05-18 17:16:00.215: epoch 8:	0.01905196  	0.13842052  	0.06937522  
2023-05-18 17:16:00.215: Find a better model.
2023-05-18 17:16:09.438: [iter 9 : loss : 0.7116 = 0.6260 + 0.0855 + 0.0001, time: 9.215312]
2023-05-18 17:16:09.723: epoch 9:	0.01908019  	0.14009093  	0.07008808  
2023-05-18 17:16:09.723: Find a better model.
2023-05-18 17:16:18.190: [iter 10 : loss : 0.6514 = 0.5604 + 0.0908 + 0.0002, time: 8.466155]
2023-05-18 17:16:18.342: epoch 10:	0.01874148  	0.13842331  	0.06917702  
2023-05-18 17:16:26.893: [iter 11 : loss : 0.5759 = 0.4796 + 0.0959 + 0.0004, time: 8.549077]
2023-05-18 17:16:27.092: epoch 11:	0.01859329  	0.13740495  	0.06862764  
2023-05-18 17:16:35.230: [iter 12 : loss : 0.5064 = 0.4065 + 0.0993 + 0.0005, time: 8.136396]
2023-05-18 17:16:35.392: epoch 12:	0.01845922  	0.13609283  	0.06845979  
2023-05-18 17:16:43.464: [iter 13 : loss : 0.4550 = 0.3531 + 0.1012 + 0.0007, time: 8.068356]
2023-05-18 17:16:43.622: epoch 13:	0.01853683  	0.13692473  	0.06896369  
2023-05-18 17:16:51.830: [iter 14 : loss : 0.4161 = 0.3131 + 0.1022 + 0.0008, time: 8.206069]
2023-05-18 17:16:51.994: epoch 14:	0.01867091  	0.13799675  	0.06972543  
2023-05-18 17:16:59.555: [iter 15 : loss : 0.3891 = 0.2856 + 0.1026 + 0.0010, time: 7.560002]
2023-05-18 17:16:59.714: epoch 15:	0.01900962  	0.14057349  	0.07082703  
2023-05-18 17:16:59.714: Find a better model.
2023-05-18 17:17:07.848: [iter 16 : loss : 0.3665 = 0.2629 + 0.1026 + 0.0011, time: 8.133118]
2023-05-18 17:17:08.010: epoch 16:	0.01924954  	0.14227778  	0.07189962  
2023-05-18 17:17:08.010: Find a better model.
2023-05-18 17:17:16.191: [iter 17 : loss : 0.3499 = 0.2463 + 0.1024 + 0.0012, time: 8.179992]
2023-05-18 17:17:16.342: epoch 17:	0.01951064  	0.14413238  	0.07299028  
2023-05-18 17:17:16.342: Find a better model.
2023-05-18 17:17:23.900: [iter 18 : loss : 0.3344 = 0.2310 + 0.1021 + 0.0013, time: 7.557521]
2023-05-18 17:17:24.063: epoch 18:	0.01969411  	0.14549176  	0.07374205  
2023-05-18 17:17:24.063: Find a better model.
2023-05-18 17:17:32.038: [iter 19 : loss : 0.3202 = 0.2170 + 0.1017 + 0.0014, time: 7.973003]
2023-05-18 17:17:32.202: epoch 19:	0.01989169  	0.14699829  	0.07460634  
2023-05-18 17:17:32.202: Find a better model.
2023-05-18 17:17:40.407: [iter 20 : loss : 0.3105 = 0.2077 + 0.1013 + 0.0015, time: 8.203395]
2023-05-18 17:17:40.564: epoch 20:	0.02008927  	0.14846864  	0.07532709  
2023-05-18 17:17:40.564: Find a better model.
2023-05-18 17:17:48.384: [iter 21 : loss : 0.3008 = 0.1983 + 0.1009 + 0.0016, time: 7.819004]
2023-05-18 17:17:48.700: epoch 21:	0.02031508  	0.14991626  	0.07642597  
2023-05-18 17:17:48.700: Find a better model.
2023-05-18 17:17:56.677: [iter 22 : loss : 0.2925 = 0.1902 + 0.1006 + 0.0017, time: 7.976012]
2023-05-18 17:17:57.040: epoch 22:	0.02044916  	0.15119497  	0.07722317  
2023-05-18 17:17:57.041: Find a better model.
2023-05-18 17:18:06.076: [iter 23 : loss : 0.2840 = 0.1822 + 0.1001 + 0.0017, time: 9.027056]
2023-05-18 17:18:06.324: epoch 23:	0.02068202  	0.15262009  	0.07815840  
2023-05-18 17:18:06.325: Find a better model.
2023-05-18 17:18:14.370: [iter 24 : loss : 0.2777 = 0.1762 + 0.0997 + 0.0018, time: 8.043108]
2023-05-18 17:18:14.533: epoch 24:	0.02090783  	0.15410872  	0.07897791  
2023-05-18 17:18:14.533: Find a better model.
2023-05-18 17:18:22.366: [iter 25 : loss : 0.2709 = 0.1698 + 0.0992 + 0.0019, time: 7.831126]
2023-05-18 17:18:22.535: epoch 25:	0.02115482  	0.15605012  	0.07981379  
2023-05-18 17:18:22.535: Find a better model.
2023-05-18 17:18:31.422: [iter 26 : loss : 0.2672 = 0.1665 + 0.0988 + 0.0019, time: 8.883144]
2023-05-18 17:18:31.706: epoch 26:	0.02133123  	0.15717404  	0.08047011  
2023-05-18 17:18:31.706: Find a better model.
2023-05-18 17:18:39.736: [iter 27 : loss : 0.2597 = 0.1593 + 0.0984 + 0.0020, time: 8.029013]
2023-05-18 17:18:39.908: epoch 27:	0.02147942  	0.15822266  	0.08124653  
2023-05-18 17:18:39.909: Find a better model.
2023-05-18 17:18:48.175: [iter 28 : loss : 0.2546 = 0.1546 + 0.0980 + 0.0021, time: 8.262005]
2023-05-18 17:18:48.324: epoch 28:	0.02168405  	0.15992858  	0.08220730  
2023-05-18 17:18:48.325: Find a better model.
2023-05-18 17:18:57.098: [iter 29 : loss : 0.2501 = 0.1505 + 0.0975 + 0.0021, time: 8.769001]
2023-05-18 17:18:57.380: epoch 29:	0.02192397  	0.16149852  	0.08319064  
2023-05-18 17:18:57.380: Find a better model.
2023-05-18 17:19:05.356: [iter 30 : loss : 0.2439 = 0.1444 + 0.0973 + 0.0022, time: 7.975010]
2023-05-18 17:19:05.528: epoch 30:	0.02209333  	0.16241305  	0.08384486  
2023-05-18 17:19:05.528: Find a better model.
2023-05-18 17:19:13.622: [iter 31 : loss : 0.2404 = 0.1413 + 0.0968 + 0.0023, time: 8.092993]
2023-05-18 17:19:13.780: epoch 31:	0.02227680  	0.16370301  	0.08446074  
2023-05-18 17:19:13.780: Find a better model.
2023-05-18 17:19:22.589: [iter 32 : loss : 0.2344 = 0.1357 + 0.0964 + 0.0023, time: 8.807023]
2023-05-18 17:19:22.850: epoch 32:	0.02229091  	0.16369477  	0.08490758  
2023-05-18 17:19:30.942: [iter 33 : loss : 0.2322 = 0.1337 + 0.0961 + 0.0024, time: 8.090004]
2023-05-18 17:19:31.087: epoch 33:	0.02242499  	0.16487637  	0.08534448  
2023-05-18 17:19:31.087: Find a better model.
2023-05-18 17:19:39.234: [iter 34 : loss : 0.2279 = 0.1297 + 0.0957 + 0.0024, time: 8.146056]
2023-05-18 17:19:39.402: epoch 34:	0.02258023  	0.16625671  	0.08614347  
2023-05-18 17:19:39.402: Find a better model.
2023-05-18 17:19:48.122: [iter 35 : loss : 0.2244 = 0.1264 + 0.0954 + 0.0025, time: 8.718992]
2023-05-18 17:19:48.299: epoch 35:	0.02262256  	0.16693012  	0.08673555  
2023-05-18 17:19:48.299: Find a better model.
2023-05-18 17:19:56.177: [iter 36 : loss : 0.2209 = 0.1233 + 0.0951 + 0.0026, time: 7.877003]
2023-05-18 17:19:56.342: epoch 36:	0.02269313  	0.16744857  	0.08721244  
2023-05-18 17:19:56.342: Find a better model.
2023-05-18 17:20:04.614: [iter 37 : loss : 0.2172 = 0.1198 + 0.0948 + 0.0026, time: 8.269532]
2023-05-18 17:20:04.778: epoch 37:	0.02278486  	0.16797307  	0.08779150  
2023-05-18 17:20:04.778: Find a better model.
2023-05-18 17:20:12.523: [iter 38 : loss : 0.2158 = 0.1186 + 0.0945 + 0.0027, time: 7.744019]
2023-05-18 17:20:12.687: epoch 38:	0.02296128  	0.16925395  	0.08851718  
2023-05-18 17:20:12.687: Find a better model.
2023-05-18 17:20:20.763: [iter 39 : loss : 0.2110 = 0.1141 + 0.0942 + 0.0027, time: 8.075083]
2023-05-18 17:20:20.930: epoch 39:	0.02308830  	0.17048314  	0.08916936  
2023-05-18 17:20:20.930: Find a better model.
2023-05-18 17:20:29.141: [iter 40 : loss : 0.2079 = 0.1113 + 0.0939 + 0.0028, time: 8.209217]
2023-05-18 17:20:29.303: epoch 40:	0.02306006  	0.17039588  	0.08935396  
2023-05-18 17:20:36.927: [iter 41 : loss : 0.2062 = 0.1097 + 0.0936 + 0.0028, time: 7.623018]
2023-05-18 17:20:37.085: epoch 41:	0.02319415  	0.17115578  	0.09001897  
2023-05-18 17:20:37.085: Find a better model.
2023-05-18 17:20:45.167: [iter 42 : loss : 0.2038 = 0.1077 + 0.0933 + 0.0029, time: 8.081007]
2023-05-18 17:20:45.328: epoch 42:	0.02334938  	0.17240368  	0.09070214  
2023-05-18 17:20:45.328: Find a better model.
2023-05-18 17:20:53.533: [iter 43 : loss : 0.1999 = 0.1040 + 0.0930 + 0.0029, time: 8.203059]
2023-05-18 17:20:53.687: epoch 43:	0.02353991  	0.17392410  	0.09148090  
2023-05-18 17:20:53.687: Find a better model.
2023-05-18 17:21:01.377: [iter 44 : loss : 0.1967 = 0.1009 + 0.0928 + 0.0030, time: 7.687243]
2023-05-18 17:21:01.683: epoch 44:	0.02353285  	0.17360032  	0.09171401  
2023-05-18 17:21:09.544: [iter 45 : loss : 0.1946 = 0.0991 + 0.0925 + 0.0030, time: 7.847182]
2023-05-18 17:21:09.773: epoch 45:	0.02368103  	0.17451377  	0.09241787  
2023-05-18 17:21:09.773: Find a better model.
2023-05-18 17:21:19.297: [iter 46 : loss : 0.1920 = 0.0966 + 0.0923 + 0.0031, time: 9.522014]
2023-05-18 17:21:19.569: epoch 46:	0.02375866  	0.17519894  	0.09288829  
2023-05-18 17:21:19.569: Find a better model.
2023-05-18 17:21:27.515: [iter 47 : loss : 0.1914 = 0.0962 + 0.0920 + 0.0031, time: 7.943993]
2023-05-18 17:21:27.680: epoch 47:	0.02384333  	0.17561205  	0.09306192  
2023-05-18 17:21:27.680: Find a better model.
2023-05-18 17:21:35.937: [iter 48 : loss : 0.1874 = 0.0924 + 0.0918 + 0.0032, time: 8.255025]
2023-05-18 17:21:36.101: epoch 48:	0.02384334  	0.17559732  	0.09327656  
2023-05-18 17:21:45.187: [iter 49 : loss : 0.1845 = 0.0896 + 0.0916 + 0.0032, time: 9.084155]
2023-05-18 17:21:45.445: epoch 49:	0.02382922  	0.17544870  	0.09341042  
2023-05-18 17:21:53.534: [iter 50 : loss : 0.1835 = 0.0889 + 0.0914 + 0.0033, time: 8.087006]
2023-05-18 17:21:53.704: epoch 50:	0.02393507  	0.17637286  	0.09394487  
2023-05-18 17:21:53.704: Find a better model.
2023-05-18 17:22:01.980: [iter 51 : loss : 0.1804 = 0.0859 + 0.0912 + 0.0033, time: 8.275206]
2023-05-18 17:22:02.139: epoch 51:	0.02408326  	0.17767109  	0.09476357  
2023-05-18 17:22:02.139: Find a better model.
2023-05-18 17:22:11.110: [iter 52 : loss : 0.1806 = 0.0863 + 0.0910 + 0.0034, time: 8.969013]
2023-05-18 17:22:11.391: epoch 52:	0.02414676  	0.17813759  	0.09510729  
2023-05-18 17:22:11.391: Find a better model.
2023-05-18 17:22:19.494: [iter 53 : loss : 0.1785 = 0.0843 + 0.0908 + 0.0034, time: 8.100982]
2023-05-18 17:22:19.659: epoch 53:	0.02418910  	0.17832777  	0.09545713  
2023-05-18 17:22:19.659: Find a better model.
2023-05-18 17:22:28.146: [iter 54 : loss : 0.1764 = 0.0824 + 0.0906 + 0.0035, time: 8.485004]
2023-05-18 17:22:28.312: epoch 54:	0.02435845  	0.17992310  	0.09609532  
2023-05-18 17:22:28.312: Find a better model.
2023-05-18 17:22:35.827: [iter 55 : loss : 0.1743 = 0.0805 + 0.0904 + 0.0035, time: 7.514016]
2023-05-18 17:22:36.008: epoch 55:	0.02439373  	0.17984389  	0.09620995  
2023-05-18 17:22:44.112: [iter 56 : loss : 0.1727 = 0.0790 + 0.0902 + 0.0035, time: 8.101703]
2023-05-18 17:22:44.272: epoch 56:	0.02445723  	0.18049960  	0.09652484  
2023-05-18 17:22:44.272: Find a better model.
2023-05-18 17:22:52.499: [iter 57 : loss : 0.1708 = 0.0772 + 0.0900 + 0.0036, time: 8.225135]
2023-05-18 17:22:52.651: epoch 57:	0.02451369  	0.18068965  	0.09675650  
2023-05-18 17:22:52.651: Find a better model.
2023-05-18 17:23:00.283: [iter 58 : loss : 0.1691 = 0.0756 + 0.0898 + 0.0036, time: 7.631218]
2023-05-18 17:23:00.441: epoch 58:	0.02461953  	0.18162270  	0.09723204  
2023-05-18 17:23:00.441: Find a better model.
2023-05-18 17:23:08.491: [iter 59 : loss : 0.1677 = 0.0744 + 0.0896 + 0.0037, time: 8.049106]
2023-05-18 17:23:08.646: epoch 59:	0.02468305  	0.18223353  	0.09747741  
2023-05-18 17:23:08.646: Find a better model.
2023-05-18 17:23:17.785: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 9.133234]
2023-05-18 17:23:18.065: epoch 60:	0.02466188  	0.18169354  	0.09762850  
2023-05-18 17:23:26.208: [iter 61 : loss : 0.1651 = 0.0720 + 0.0893 + 0.0038, time: 8.140259]
2023-05-18 17:23:26.384: epoch 61:	0.02470422  	0.18234333  	0.09815972  
2023-05-18 17:23:26.384: Find a better model.
2023-05-18 17:23:34.531: [iter 62 : loss : 0.1636 = 0.0706 + 0.0891 + 0.0038, time: 8.146063]
2023-05-18 17:23:34.698: epoch 62:	0.02476067  	0.18262871  	0.09838852  
2023-05-18 17:23:34.698: Find a better model.
2023-05-18 17:23:43.727: [iter 63 : loss : 0.1623 = 0.0694 + 0.0890 + 0.0039, time: 9.021246]
2023-05-18 17:23:44.008: epoch 63:	0.02486651  	0.18351661  	0.09868855  
2023-05-18 17:23:44.008: Find a better model.
2023-05-18 17:23:52.250: [iter 64 : loss : 0.1612 = 0.0685 + 0.0888 + 0.0039, time: 8.239993]
2023-05-18 17:23:52.429: epoch 64:	0.02486652  	0.18344708  	0.09876344  
2023-05-18 17:24:00.624: [iter 65 : loss : 0.1599 = 0.0673 + 0.0887 + 0.0040, time: 8.193008]
2023-05-18 17:24:00.852: epoch 65:	0.02502175  	0.18482600  	0.09930465  
2023-05-18 17:24:00.852: Find a better model.
2023-05-18 17:24:09.950: [iter 66 : loss : 0.1583 = 0.0658 + 0.0886 + 0.0040, time: 9.094052]
2023-05-18 17:24:10.199: epoch 66:	0.02505703  	0.18484966  	0.09959929  
2023-05-18 17:24:10.199: Find a better model.
2023-05-18 17:24:18.425: [iter 67 : loss : 0.1569 = 0.0645 + 0.0884 + 0.0040, time: 8.225002]
2023-05-18 17:24:18.586: epoch 67:	0.02519816  	0.18601334  	0.09997930  
2023-05-18 17:24:18.586: Find a better model.
2023-05-18 17:24:27.124: [iter 68 : loss : 0.1565 = 0.0641 + 0.0882 + 0.0041, time: 8.537013]
2023-05-18 17:24:27.284: epoch 68:	0.02521933  	0.18572460  	0.10028358  
2023-05-18 17:24:35.138: [iter 69 : loss : 0.1545 = 0.0623 + 0.0881 + 0.0041, time: 7.853006]
2023-05-18 17:24:35.296: epoch 69:	0.02526872  	0.18602265  	0.10049924  
2023-05-18 17:24:35.296: Find a better model.
2023-05-18 17:24:43.275: [iter 70 : loss : 0.1530 = 0.0608 + 0.0880 + 0.0042, time: 7.978014]
2023-05-18 17:24:43.435: epoch 70:	0.02531107  	0.18648025  	0.10075271  
2023-05-18 17:24:43.435: Find a better model.
2023-05-18 17:24:51.862: [iter 71 : loss : 0.1514 = 0.0593 + 0.0879 + 0.0042, time: 8.425004]
2023-05-18 17:24:52.013: epoch 71:	0.02533929  	0.18703808  	0.10108437  
2023-05-18 17:24:52.013: Find a better model.
2023-05-18 17:24:59.743: [iter 72 : loss : 0.1511 = 0.0591 + 0.0877 + 0.0042, time: 7.728993]
2023-05-18 17:24:59.907: epoch 72:	0.02535341  	0.18716079  	0.10111640  
2023-05-18 17:24:59.908: Find a better model.
2023-05-18 17:25:08.060: [iter 73 : loss : 0.1500 = 0.0581 + 0.0876 + 0.0043, time: 8.151019]
2023-05-18 17:25:08.220: epoch 73:	0.02538163  	0.18729439  	0.10120028  
2023-05-18 17:25:08.220: Find a better model.
2023-05-18 17:25:17.137: [iter 74 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0043, time: 8.913023]
2023-05-18 17:25:17.412: epoch 74:	0.02546631  	0.18782064  	0.10157268  
2023-05-18 17:25:17.412: Find a better model.
2023-05-18 17:25:25.510: [iter 75 : loss : 0.1481 = 0.0563 + 0.0874 + 0.0044, time: 8.096295]
2023-05-18 17:25:25.661: epoch 75:	0.02552982  	0.18824576  	0.10177568  
2023-05-18 17:25:25.662: Find a better model.
2023-05-18 17:25:33.997: [iter 76 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 8.333015]
2023-05-18 17:25:34.170: epoch 76:	0.02552981  	0.18802039  	0.10201647  
2023-05-18 17:25:43.184: [iter 77 : loss : 0.1460 = 0.0544 + 0.0871 + 0.0044, time: 9.006009]
2023-05-18 17:25:43.465: epoch 77:	0.02555804  	0.18837988  	0.10221410  
2023-05-18 17:25:43.466: Find a better model.
2023-05-18 17:25:51.471: [iter 78 : loss : 0.1448 = 0.0533 + 0.0870 + 0.0045, time: 8.003165]
2023-05-18 17:25:51.634: epoch 78:	0.02567094  	0.18907423  	0.10270538  
2023-05-18 17:25:51.634: Find a better model.
2023-05-18 17:25:59.843: [iter 79 : loss : 0.1437 = 0.0523 + 0.0869 + 0.0045, time: 8.206529]
2023-05-18 17:25:59.996: epoch 79:	0.02563566  	0.18897061  	0.10260391  
2023-05-18 17:26:09.039: [iter 80 : loss : 0.1429 = 0.0515 + 0.0868 + 0.0046, time: 9.037002]
2023-05-18 17:26:09.313: epoch 80:	0.02568506  	0.18902898  	0.10288016  
2023-05-18 17:26:17.390: [iter 81 : loss : 0.1428 = 0.0515 + 0.0867 + 0.0046, time: 8.075139]
2023-05-18 17:26:17.553: epoch 81:	0.02572739  	0.18937175  	0.10314947  
2023-05-18 17:26:17.554: Find a better model.
2023-05-18 17:26:25.850: [iter 82 : loss : 0.1412 = 0.0500 + 0.0866 + 0.0046, time: 8.295004]
2023-05-18 17:26:26.074: epoch 82:	0.02572740  	0.18933859  	0.10312481  
2023-05-18 17:26:34.567: [iter 83 : loss : 0.1406 = 0.0494 + 0.0865 + 0.0047, time: 8.490036]
2023-05-18 17:26:34.731: epoch 83:	0.02575562  	0.18969518  	0.10338642  
2023-05-18 17:26:34.731: Find a better model.
2023-05-18 17:26:42.856: [iter 84 : loss : 0.1405 = 0.0494 + 0.0864 + 0.0047, time: 8.124003]
2023-05-18 17:26:43.031: epoch 84:	0.02581912  	0.18985766  	0.10367509  
2023-05-18 17:26:43.031: Find a better model.
2023-05-18 17:26:51.436: [iter 85 : loss : 0.1392 = 0.0482 + 0.0863 + 0.0048, time: 8.404558]
2023-05-18 17:26:51.601: epoch 85:	0.02584735  	0.18992189  	0.10367093  
2023-05-18 17:26:51.601: Find a better model.
2023-05-18 17:26:59.181: [iter 86 : loss : 0.1394 = 0.0484 + 0.0862 + 0.0048, time: 7.579005]
2023-05-18 17:26:59.338: epoch 86:	0.02588969  	0.19027860  	0.10392103  
2023-05-18 17:26:59.338: Find a better model.
2023-05-18 17:27:07.446: [iter 87 : loss : 0.1363 = 0.0454 + 0.0861 + 0.0048, time: 8.106019]
2023-05-18 17:27:07.605: epoch 87:	0.02598143  	0.19096279  	0.10428794  
2023-05-18 17:27:07.605: Find a better model.
2023-05-18 17:27:15.822: [iter 88 : loss : 0.1358 = 0.0449 + 0.0860 + 0.0049, time: 8.214517]
2023-05-18 17:27:16.033: epoch 88:	0.02603788  	0.19159678  	0.10445693  
2023-05-18 17:27:16.033: Find a better model.
2023-05-18 17:27:24.006: [iter 89 : loss : 0.1355 = 0.0446 + 0.0859 + 0.0049, time: 7.968758]
2023-05-18 17:27:24.271: epoch 89:	0.02609433  	0.19168723  	0.10451692  
2023-05-18 17:27:24.271: Find a better model.
2023-05-18 17:27:32.430: [iter 90 : loss : 0.1361 = 0.0453 + 0.0858 + 0.0050, time: 8.157394]
2023-05-18 17:27:32.811: epoch 90:	0.02611551  	0.19200070  	0.10476226  
2023-05-18 17:27:32.811: Find a better model.
2023-05-18 17:27:41.841: [iter 91 : loss : 0.1347 = 0.0440 + 0.0858 + 0.0050, time: 9.023034]
2023-05-18 17:27:42.131: epoch 91:	0.02622841  	0.19263618  	0.10510029  
2023-05-18 17:27:42.131: Find a better model.
2023-05-18 17:27:50.168: [iter 92 : loss : 0.1338 = 0.0431 + 0.0857 + 0.0050, time: 8.034993]
2023-05-18 17:27:50.338: epoch 92:	0.02624252  	0.19270010  	0.10532994  
2023-05-18 17:27:50.339: Find a better model.
2023-05-18 17:27:58.570: [iter 93 : loss : 0.1342 = 0.0435 + 0.0856 + 0.0051, time: 8.230099]
2023-05-18 17:27:58.730: epoch 93:	0.02627075  	0.19262309  	0.10533177  
2023-05-18 17:28:07.839: [iter 94 : loss : 0.1318 = 0.0412 + 0.0855 + 0.0051, time: 9.107118]
2023-05-18 17:28:08.115: epoch 94:	0.02632720  	0.19332096  	0.10575850  
2023-05-18 17:28:08.115: Find a better model.
2023-05-18 17:28:16.209: [iter 95 : loss : 0.1315 = 0.0409 + 0.0854 + 0.0051, time: 8.093011]
2023-05-18 17:28:16.373: epoch 95:	0.02647539  	0.19421905  	0.10616779  
2023-05-18 17:28:16.373: Find a better model.
2023-05-18 17:28:24.674: [iter 96 : loss : 0.1314 = 0.0409 + 0.0853 + 0.0052, time: 8.300022]
2023-05-18 17:28:24.839: epoch 96:	0.02649656  	0.19462301  	0.10640348  
2023-05-18 17:28:24.839: Find a better model.
2023-05-18 17:28:33.859: [iter 97 : loss : 0.1299 = 0.0395 + 0.0852 + 0.0052, time: 9.017037]
2023-05-18 17:28:34.080: epoch 97:	0.02653184  	0.19471984  	0.10639340  
2023-05-18 17:28:34.080: Find a better model.
2023-05-18 17:28:42.170: [iter 98 : loss : 0.1309 = 0.0405 + 0.0852 + 0.0052, time: 8.088239]
2023-05-18 17:28:42.335: epoch 98:	0.02650362  	0.19445333  	0.10641956  
2023-05-18 17:28:50.617: [iter 99 : loss : 0.1295 = 0.0390 + 0.0852 + 0.0053, time: 8.278993]
2023-05-18 17:28:50.779: epoch 99:	0.02651067  	0.19446805  	0.10658328  
2023-05-18 17:28:58.314: [iter 100 : loss : 0.1287 = 0.0384 + 0.0850 + 0.0053, time: 7.533493]
2023-05-18 17:28:58.473: epoch 100:	0.02662358  	0.19546857  	0.10682594  
2023-05-18 17:28:58.474: Find a better model.
2023-05-18 17:29:06.585: [iter 101 : loss : 0.1284 = 0.0381 + 0.0850 + 0.0054, time: 8.110097]
2023-05-18 17:29:06.745: epoch 101:	0.02663063  	0.19523829  	0.10672344  
2023-05-18 17:29:15.179: [iter 102 : loss : 0.1277 = 0.0374 + 0.0849 + 0.0054, time: 8.433015]
2023-05-18 17:29:15.331: epoch 102:	0.02663063  	0.19504970  	0.10681964  
2023-05-18 17:29:22.966: [iter 103 : loss : 0.1270 = 0.0367 + 0.0849 + 0.0054, time: 7.633003]
2023-05-18 17:29:23.125: epoch 103:	0.02673648  	0.19597848  	0.10723219  
2023-05-18 17:29:23.125: Find a better model.
2023-05-18 17:29:31.147: [iter 104 : loss : 0.1278 = 0.0375 + 0.0848 + 0.0055, time: 8.021083]
2023-05-18 17:29:31.304: epoch 104:	0.02667296  	0.19582288  	0.10726976  
2023-05-18 17:29:40.728: [iter 105 : loss : 0.1269 = 0.0367 + 0.0847 + 0.0055, time: 9.416117]
2023-05-18 17:29:41.009: epoch 105:	0.02665179  	0.19537346  	0.10723557  
2023-05-18 17:29:49.084: [iter 106 : loss : 0.1263 = 0.0361 + 0.0846 + 0.0055, time: 8.074080]
2023-05-18 17:29:49.254: epoch 106:	0.02666591  	0.19564901  	0.10731128  
2023-05-18 17:29:57.243: [iter 107 : loss : 0.1255 = 0.0353 + 0.0846 + 0.0056, time: 7.986002]
2023-05-18 17:29:57.406: epoch 107:	0.02667296  	0.19568306  	0.10727104  
2023-05-18 17:30:06.331: [iter 108 : loss : 0.1254 = 0.0353 + 0.0845 + 0.0056, time: 8.919032]
2023-05-18 17:30:06.614: epoch 108:	0.02665179  	0.19538270  	0.10715642  
2023-05-18 17:30:14.713: [iter 109 : loss : 0.1239 = 0.0338 + 0.0844 + 0.0056, time: 8.098456]
2023-05-18 17:30:14.875: epoch 109:	0.02667296  	0.19553660  	0.10721564  
2023-05-18 17:30:23.132: [iter 110 : loss : 0.1234 = 0.0333 + 0.0844 + 0.0057, time: 8.254002]
2023-05-18 17:30:23.367: epoch 110:	0.02670824  	0.19571866  	0.10740984  
2023-05-18 17:30:32.340: [iter 111 : loss : 0.1234 = 0.0334 + 0.0843 + 0.0057, time: 8.969033]
2023-05-18 17:30:32.587: epoch 111:	0.02671530  	0.19571683  	0.10756700  
2023-05-18 17:30:40.542: [iter 112 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 7.954002]
2023-05-18 17:30:40.702: epoch 112:	0.02678586  	0.19638753  	0.10774068  
2023-05-18 17:30:40.702: Find a better model.
2023-05-18 17:30:48.982: [iter 113 : loss : 0.1231 = 0.0331 + 0.0842 + 0.0058, time: 8.277008]
2023-05-18 17:30:49.192: epoch 113:	0.02675058  	0.19622274  	0.10770062  
2023-05-18 17:30:57.705: [iter 114 : loss : 0.1223 = 0.0324 + 0.0841 + 0.0058, time: 8.511006]
2023-05-18 17:30:57.874: epoch 114:	0.02671530  	0.19609120  	0.10772083  
2023-05-18 17:31:05.917: [iter 115 : loss : 0.1218 = 0.0319 + 0.0841 + 0.0058, time: 8.042002]
2023-05-18 17:31:06.074: epoch 115:	0.02670119  	0.19596179  	0.10756634  
2023-05-18 17:31:14.372: [iter 116 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 8.296992]
2023-05-18 17:31:14.537: epoch 116:	0.02666590  	0.19553258  	0.10757911  
2023-05-18 17:31:22.071: [iter 117 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 7.533027]
2023-05-18 17:31:22.232: epoch 117:	0.02667296  	0.19572900  	0.10754503  
2023-05-18 17:31:30.325: [iter 118 : loss : 0.1208 = 0.0309 + 0.0840 + 0.0059, time: 8.091522]
2023-05-18 17:31:30.482: epoch 118:	0.02664473  	0.19555536  	0.10751159  
2023-05-18 17:31:38.705: [iter 119 : loss : 0.1198 = 0.0300 + 0.0839 + 0.0060, time: 8.221423]
2023-05-18 17:31:38.865: epoch 119:	0.02666591  	0.19566767  	0.10765558  
2023-05-18 17:31:46.498: [iter 120 : loss : 0.1199 = 0.0301 + 0.0838 + 0.0060, time: 7.631992]
2023-05-18 17:31:46.655: epoch 120:	0.02663768  	0.19576532  	0.10767005  
2023-05-18 17:31:54.732: [iter 121 : loss : 0.1202 = 0.0304 + 0.0838 + 0.0060, time: 8.073844]
2023-05-18 17:31:54.892: epoch 121:	0.02661651  	0.19549151  	0.10762738  
2023-05-18 17:32:03.605: [iter 122 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0060, time: 8.708945]
2023-05-18 17:32:03.894: epoch 122:	0.02657418  	0.19528514  	0.10762689  
2023-05-18 17:32:11.940: [iter 123 : loss : 0.1191 = 0.0293 + 0.0837 + 0.0061, time: 8.043007]
2023-05-18 17:32:12.088: epoch 123:	0.02660240  	0.19542666  	0.10777076  
2023-05-18 17:32:20.514: [iter 124 : loss : 0.1182 = 0.0284 + 0.0836 + 0.0061, time: 8.424993]
2023-05-18 17:32:20.703: epoch 124:	0.02663063  	0.19535713  	0.10768674  
2023-05-18 17:32:29.660: [iter 125 : loss : 0.1174 = 0.0276 + 0.0836 + 0.0061, time: 8.953994]
2023-05-18 17:32:29.939: epoch 125:	0.02660240  	0.19504455  	0.10767008  
2023-05-18 17:32:37.886: [iter 126 : loss : 0.1179 = 0.0282 + 0.0836 + 0.0062, time: 7.946002]
2023-05-18 17:32:38.069: epoch 126:	0.02659534  	0.19485256  	0.10762028  
2023-05-18 17:32:46.317: [iter 127 : loss : 0.1167 = 0.0270 + 0.0835 + 0.0062, time: 8.247293]
2023-05-18 17:32:46.468: epoch 127:	0.02665885  	0.19555221  	0.10783774  
2023-05-18 17:32:55.435: [iter 128 : loss : 0.1178 = 0.0282 + 0.0835 + 0.0062, time: 8.960547]
2023-05-18 17:32:55.721: epoch 128:	0.02664474  	0.19551612  	0.10794397  
2023-05-18 17:33:03.706: [iter 129 : loss : 0.1170 = 0.0273 + 0.0834 + 0.0063, time: 7.982015]
2023-05-18 17:33:03.859: epoch 129:	0.02658123  	0.19507872  	0.10771699  
2023-05-18 17:33:11.987: [iter 130 : loss : 0.1170 = 0.0274 + 0.0833 + 0.0063, time: 8.127007]
2023-05-18 17:33:12.145: epoch 130:	0.02658123  	0.19492523  	0.10787848  
2023-05-18 17:33:21.014: [iter 131 : loss : 0.1161 = 0.0264 + 0.0833 + 0.0063, time: 8.866952]
2023-05-18 17:33:21.238: epoch 131:	0.02665179  	0.19523504  	0.10775995  
2023-05-18 17:33:29.336: [iter 132 : loss : 0.1166 = 0.0270 + 0.0833 + 0.0064, time: 8.095526]
2023-05-18 17:33:29.498: epoch 132:	0.02665885  	0.19543876  	0.10794549  
2023-05-18 17:33:37.908: [iter 133 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 8.408009]
2023-05-18 17:33:38.060: epoch 133:	0.02663062  	0.19535761  	0.10790922  
2023-05-18 17:33:45.608: [iter 134 : loss : 0.1160 = 0.0264 + 0.0832 + 0.0064, time: 7.547003]
2023-05-18 17:33:45.766: epoch 134:	0.02667295  	0.19558702  	0.10824466  
2023-05-18 17:33:53.896: [iter 135 : loss : 0.1156 = 0.0261 + 0.0831 + 0.0064, time: 8.128603]
2023-05-18 17:33:54.057: epoch 135:	0.02667295  	0.19589618  	0.10829738  
2023-05-18 17:34:02.256: [iter 136 : loss : 0.1150 = 0.0255 + 0.0831 + 0.0065, time: 8.197343]
2023-05-18 17:34:02.405: epoch 136:	0.02667296  	0.19560225  	0.10847702  
2023-05-18 17:34:09.957: [iter 137 : loss : 0.1148 = 0.0252 + 0.0831 + 0.0065, time: 7.549028]
2023-05-18 17:34:10.116: epoch 137:	0.02665178  	0.19571058  	0.10842162  
2023-05-18 17:34:10.116: Early stopping is trigger at epoch: 137
2023-05-18 17:34:10.116: best_result@epoch 112:

2023-05-18 17:34:10.116: 		0.0268      	0.1964      	0.1077      
2023-05-18 18:42:12.543: my pid: 7944
2023-05-18 18:42:12.543: model: model.general_recommender.SGL
2023-05-18 18:42:12.543: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 18:42:12.543: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 18:42:16.383: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 18:42:25.275: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.891026]
2023-05-18 18:42:25.439: epoch 1:	0.00134067  	0.00964266  	0.00491265  
2023-05-18 18:42:25.439: Find a better model.
2023-05-18 18:42:34.710: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 9.269169]
2023-05-18 18:42:34.927: epoch 2:	0.00283658  	0.02187197  	0.01058663  
2023-05-18 18:42:34.927: Find a better model.
2023-05-18 18:42:43.876: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.946899]
2023-05-18 18:42:44.040: epoch 3:	0.00474172  	0.03645347  	0.01698908  
2023-05-18 18:42:44.040: Find a better model.
2023-05-18 18:42:52.819: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.777323]
2023-05-18 18:42:53.016: epoch 4:	0.00778289  	0.05742294  	0.02769983  
2023-05-18 18:42:53.017: Find a better model.
2023-05-18 18:43:02.494: [iter 5 : loss : 0.7696 = 0.6909 + 0.0787 + 0.0000, time: 9.470126]
2023-05-18 18:43:02.796: epoch 5:	0.01156509  	0.08483408  	0.04067069  
2023-05-18 18:43:02.797: Find a better model.
2023-05-18 18:43:11.228: [iter 6 : loss : 0.7673 = 0.6882 + 0.0791 + 0.0000, time: 8.429381]
2023-05-18 18:43:11.401: epoch 6:	0.01519210  	0.11042298  	0.05363704  
2023-05-18 18:43:11.401: Find a better model.
2023-05-18 18:43:20.016: [iter 7 : loss : 0.7611 = 0.6812 + 0.0799 + 0.0000, time: 8.612992]
2023-05-18 18:43:20.176: epoch 7:	0.01766183  	0.12722443  	0.06327055  
2023-05-18 18:43:20.176: Find a better model.
2023-05-18 18:43:29.433: [iter 8 : loss : 0.7456 = 0.6638 + 0.0817 + 0.0001, time: 9.255973]
2023-05-18 18:43:29.734: epoch 8:	0.01878380  	0.13670480  	0.06893057  
2023-05-18 18:43:29.734: Find a better model.
2023-05-18 18:43:38.030: [iter 9 : loss : 0.7105 = 0.6248 + 0.0856 + 0.0001, time: 8.293012]
2023-05-18 18:43:38.195: epoch 9:	0.01873442  	0.13745899  	0.06935377  
2023-05-18 18:43:38.195: Find a better model.
2023-05-18 18:43:46.492: [iter 10 : loss : 0.6498 = 0.5587 + 0.0909 + 0.0002, time: 8.295514]
2023-05-18 18:43:46.647: epoch 10:	0.01837453  	0.13584700  	0.06785469  
2023-05-18 18:43:55.620: [iter 11 : loss : 0.5744 = 0.4780 + 0.0960 + 0.0004, time: 8.971020]
2023-05-18 18:43:55.840: epoch 11:	0.01851567  	0.13670051  	0.06842660  
2023-05-18 18:44:04.080: [iter 12 : loss : 0.5055 = 0.4057 + 0.0992 + 0.0005, time: 8.236993]
2023-05-18 18:44:04.253: epoch 12:	0.01838160  	0.13618889  	0.06859561  
2023-05-18 18:44:12.855: [iter 13 : loss : 0.4547 = 0.3529 + 0.1011 + 0.0007, time: 8.600048]
2023-05-18 18:44:13.008: epoch 13:	0.01856506  	0.13739882  	0.06933884  
2023-05-18 18:44:20.907: [iter 14 : loss : 0.4161 = 0.3132 + 0.1021 + 0.0008, time: 7.897885]
2023-05-18 18:44:21.068: epoch 14:	0.01864268  	0.13799262  	0.06996446  
2023-05-18 18:44:21.068: Find a better model.
2023-05-18 18:44:29.250: [iter 15 : loss : 0.3891 = 0.2858 + 0.1024 + 0.0010, time: 8.179987]
2023-05-18 18:44:29.414: epoch 15:	0.01882615  	0.13890700  	0.07069874  
2023-05-18 18:44:29.414: Find a better model.
2023-05-18 18:44:37.652: [iter 16 : loss : 0.3666 = 0.2631 + 0.1025 + 0.0011, time: 8.236065]
2023-05-18 18:44:37.815: epoch 16:	0.01898845  	0.14028566  	0.07146969  
2023-05-18 18:44:37.815: Find a better model.
2023-05-18 18:44:45.406: [iter 17 : loss : 0.3500 = 0.2466 + 0.1022 + 0.0012, time: 7.590072]
2023-05-18 18:44:45.568: epoch 17:	0.01924955  	0.14181589  	0.07233886  
2023-05-18 18:44:45.568: Find a better model.
2023-05-18 18:44:53.604: [iter 18 : loss : 0.3346 = 0.2313 + 0.1020 + 0.0013, time: 8.034190]
2023-05-18 18:44:53.765: epoch 18:	0.01937657  	0.14256710  	0.07304709  
2023-05-18 18:44:53.765: Find a better model.
2023-05-18 18:45:02.012: [iter 19 : loss : 0.3203 = 0.2173 + 0.1016 + 0.0014, time: 8.245981]
2023-05-18 18:45:02.166: epoch 19:	0.01965883  	0.14487311  	0.07420348  
2023-05-18 18:45:02.166: Find a better model.
2023-05-18 18:45:09.674: [iter 20 : loss : 0.3104 = 0.2077 + 0.1012 + 0.0015, time: 7.506993]
2023-05-18 18:45:09.848: epoch 20:	0.01983524  	0.14597897  	0.07493072  
2023-05-18 18:45:09.848: Find a better model.
2023-05-18 18:45:17.820: [iter 21 : loss : 0.3008 = 0.1984 + 0.1008 + 0.0016, time: 7.970609]
2023-05-18 18:45:17.983: epoch 21:	0.02006105  	0.14800116  	0.07593248  
2023-05-18 18:45:17.983: Find a better model.
2023-05-18 18:45:26.212: [iter 22 : loss : 0.2925 = 0.1904 + 0.1004 + 0.0017, time: 8.227009]
2023-05-18 18:45:26.362: epoch 22:	0.02032920  	0.14976870  	0.07668576  
2023-05-18 18:45:26.362: Find a better model.
2023-05-18 18:45:33.864: [iter 23 : loss : 0.2840 = 0.1823 + 0.1000 + 0.0017, time: 7.500002]
2023-05-18 18:45:34.025: epoch 23:	0.02047738  	0.15094247  	0.07744700  
2023-05-18 18:45:34.026: Find a better model.
2023-05-18 18:45:42.026: [iter 24 : loss : 0.2776 = 0.1762 + 0.0995 + 0.0018, time: 7.999003]
2023-05-18 18:45:42.185: epoch 24:	0.02069613  	0.15252233  	0.07843331  
2023-05-18 18:45:42.185: Find a better model.
2023-05-18 18:45:50.416: [iter 25 : loss : 0.2709 = 0.1698 + 0.0991 + 0.0019, time: 8.229286]
2023-05-18 18:45:50.576: epoch 25:	0.02088666  	0.15377262  	0.07911217  
2023-05-18 18:45:50.576: Find a better model.
2023-05-18 18:45:58.123: [iter 26 : loss : 0.2670 = 0.1664 + 0.0987 + 0.0019, time: 7.545356]
2023-05-18 18:45:58.286: epoch 26:	0.02109835  	0.15499771  	0.07971810  
2023-05-18 18:45:58.286: Find a better model.
2023-05-18 18:46:06.405: [iter 27 : loss : 0.2596 = 0.1592 + 0.0983 + 0.0020, time: 8.118114]
2023-05-18 18:46:06.567: epoch 27:	0.02123948  	0.15577862  	0.08035624  
2023-05-18 18:46:06.567: Find a better model.
2023-05-18 18:46:14.994: [iter 28 : loss : 0.2545 = 0.1545 + 0.0979 + 0.0021, time: 8.425008]
2023-05-18 18:46:15.146: epoch 28:	0.02145118  	0.15765160  	0.08130770  
2023-05-18 18:46:15.146: Find a better model.
2023-05-18 18:46:22.756: [iter 29 : loss : 0.2501 = 0.1505 + 0.0975 + 0.0021, time: 7.607584]
2023-05-18 18:46:22.916: epoch 29:	0.02165582  	0.15884803  	0.08215414  
2023-05-18 18:46:22.916: Find a better model.
2023-05-18 18:46:30.993: [iter 30 : loss : 0.2436 = 0.1442 + 0.0972 + 0.0022, time: 8.074003]
2023-05-18 18:46:31.157: epoch 30:	0.02173344  	0.15951832  	0.08257405  
2023-05-18 18:46:31.157: Find a better model.
2023-05-18 18:46:39.181: [iter 31 : loss : 0.2399 = 0.1409 + 0.0967 + 0.0023, time: 8.021003]
2023-05-18 18:46:39.350: epoch 31:	0.02183224  	0.16019264  	0.08310285  
2023-05-18 18:46:39.350: Find a better model.
2023-05-18 18:46:46.973: [iter 32 : loss : 0.2343 = 0.1355 + 0.0964 + 0.0023, time: 7.622003]
2023-05-18 18:46:47.132: epoch 32:	0.02201570  	0.16141661  	0.08386630  
2023-05-18 18:46:47.132: Find a better model.
2023-05-18 18:46:55.176: [iter 33 : loss : 0.2317 = 0.1333 + 0.0959 + 0.0024, time: 8.042650]
2023-05-18 18:46:55.339: epoch 33:	0.02212861  	0.16248609  	0.08442988  
2023-05-18 18:46:55.339: Find a better model.
2023-05-18 18:47:03.575: [iter 34 : loss : 0.2275 = 0.1294 + 0.0957 + 0.0024, time: 8.235013]
2023-05-18 18:47:03.745: epoch 34:	0.02226268  	0.16345663  	0.08513998  
2023-05-18 18:47:03.745: Find a better model.
2023-05-18 18:47:11.388: [iter 35 : loss : 0.2241 = 0.1262 + 0.0954 + 0.0025, time: 7.640991]
2023-05-18 18:47:11.549: epoch 35:	0.02246026  	0.16492118  	0.08586481  
2023-05-18 18:47:11.549: Find a better model.
2023-05-18 18:47:19.571: [iter 36 : loss : 0.2207 = 0.1231 + 0.0950 + 0.0026, time: 8.020004]
2023-05-18 18:47:19.728: epoch 36:	0.02260138  	0.16605499  	0.08653252  
2023-05-18 18:47:19.728: Find a better model.
2023-05-18 18:47:28.643: [iter 37 : loss : 0.2167 = 0.1194 + 0.0947 + 0.0026, time: 8.911023]
2023-05-18 18:47:28.940: epoch 37:	0.02260138  	0.16605020  	0.08696699  
2023-05-18 18:47:36.879: [iter 38 : loss : 0.2152 = 0.1181 + 0.0944 + 0.0027, time: 7.936992]
2023-05-18 18:47:37.030: epoch 38:	0.02278485  	0.16795027  	0.08781613  
2023-05-18 18:47:37.030: Find a better model.
2023-05-18 18:47:45.462: [iter 39 : loss : 0.2106 = 0.1138 + 0.0941 + 0.0027, time: 8.429003]
2023-05-18 18:47:45.626: epoch 39:	0.02290481  	0.16859739  	0.08834292  
2023-05-18 18:47:45.626: Find a better model.
2023-05-18 18:47:54.894: [iter 40 : loss : 0.2073 = 0.1108 + 0.0938 + 0.0028, time: 9.262463]
2023-05-18 18:47:55.191: epoch 40:	0.02297538  	0.16881979  	0.08865917  
2023-05-18 18:47:55.191: Find a better model.
2023-05-18 18:48:03.345: [iter 41 : loss : 0.2059 = 0.1095 + 0.0935 + 0.0028, time: 8.152003]
2023-05-18 18:48:03.507: epoch 41:	0.02313062  	0.16983089  	0.08926973  
2023-05-18 18:48:03.507: Find a better model.
2023-05-18 18:48:11.941: [iter 42 : loss : 0.2035 = 0.1074 + 0.0932 + 0.0029, time: 8.433003]
2023-05-18 18:48:12.094: epoch 42:	0.02323647  	0.17068493  	0.08972613  
2023-05-18 18:48:12.094: Find a better model.
2023-05-18 18:48:21.086: [iter 43 : loss : 0.1996 = 0.1038 + 0.0929 + 0.0029, time: 8.988004]
2023-05-18 18:48:21.371: epoch 43:	0.02339877  	0.17182551  	0.09028397  
2023-05-18 18:48:21.371: Find a better model.
2023-05-18 18:48:29.566: [iter 44 : loss : 0.1960 = 0.1003 + 0.0926 + 0.0030, time: 8.193008]
2023-05-18 18:48:29.734: epoch 44:	0.02332821  	0.17150906  	0.09063127  
2023-05-18 18:48:38.066: [iter 45 : loss : 0.1942 = 0.0987 + 0.0924 + 0.0030, time: 8.331009]
2023-05-18 18:48:38.222: epoch 45:	0.02341288  	0.17210829  	0.09130141  
2023-05-18 18:48:38.222: Find a better model.
2023-05-18 18:48:47.166: [iter 46 : loss : 0.1917 = 0.0964 + 0.0922 + 0.0031, time: 8.935655]
2023-05-18 18:48:47.447: epoch 46:	0.02353284  	0.17321128  	0.09186959  
2023-05-18 18:48:47.448: Find a better model.
2023-05-18 18:48:55.533: [iter 47 : loss : 0.1908 = 0.0956 + 0.0920 + 0.0031, time: 8.084005]
2023-05-18 18:48:55.700: epoch 47:	0.02353284  	0.17329679  	0.09243901  
2023-05-18 18:48:55.700: Find a better model.
2023-05-18 18:49:04.171: [iter 48 : loss : 0.1871 = 0.0922 + 0.0917 + 0.0032, time: 8.469006]
2023-05-18 18:49:04.329: epoch 48:	0.02361046  	0.17401330  	0.09299769  
2023-05-18 18:49:04.329: Find a better model.
2023-05-18 18:49:12.730: [iter 49 : loss : 0.1838 = 0.0891 + 0.0915 + 0.0032, time: 8.399183]
2023-05-18 18:49:12.912: epoch 49:	0.02370220  	0.17495465  	0.09340535  
2023-05-18 18:49:12.912: Find a better model.
2023-05-18 18:49:20.912: [iter 50 : loss : 0.1830 = 0.0884 + 0.0913 + 0.0033, time: 7.999940]
2023-05-18 18:49:21.072: epoch 50:	0.02386450  	0.17598201  	0.09396236  
2023-05-18 18:49:21.072: Find a better model.
2023-05-18 18:49:29.340: [iter 51 : loss : 0.1800 = 0.0855 + 0.0911 + 0.0033, time: 8.265079]
2023-05-18 18:49:29.508: epoch 51:	0.02386449  	0.17577773  	0.09411055  
2023-05-18 18:49:37.094: [iter 52 : loss : 0.1800 = 0.0857 + 0.0909 + 0.0034, time: 7.585004]
2023-05-18 18:49:37.258: epoch 52:	0.02401973  	0.17686829  	0.09455698  
2023-05-18 18:49:37.258: Find a better model.
2023-05-18 18:49:45.137: [iter 53 : loss : 0.1781 = 0.0839 + 0.0907 + 0.0034, time: 7.877016]
2023-05-18 18:49:45.300: epoch 53:	0.02409736  	0.17739315  	0.09499699  
2023-05-18 18:49:45.301: Find a better model.
2023-05-18 18:49:53.313: [iter 54 : loss : 0.1757 = 0.0817 + 0.0905 + 0.0035, time: 8.011020]
2023-05-18 18:49:53.481: epoch 54:	0.02415381  	0.17752717  	0.09542162  
2023-05-18 18:49:53.481: Find a better model.
2023-05-18 18:50:01.019: [iter 55 : loss : 0.1741 = 0.0803 + 0.0903 + 0.0035, time: 7.536200]
2023-05-18 18:50:01.177: epoch 55:	0.02417497  	0.17765023  	0.09573623  
2023-05-18 18:50:01.177: Find a better model.
2023-05-18 18:50:09.127: [iter 56 : loss : 0.1722 = 0.0786 + 0.0901 + 0.0036, time: 7.947679]
2023-05-18 18:50:09.287: epoch 56:	0.02432315  	0.17870219  	0.09624638  
2023-05-18 18:50:09.287: Find a better model.
2023-05-18 18:50:17.525: [iter 57 : loss : 0.1705 = 0.0770 + 0.0899 + 0.0036, time: 8.236033]
2023-05-18 18:50:17.689: epoch 57:	0.02437961  	0.17923027  	0.09636370  
2023-05-18 18:50:17.689: Find a better model.
2023-05-18 18:50:25.241: [iter 58 : loss : 0.1684 = 0.0750 + 0.0897 + 0.0037, time: 7.551003]
2023-05-18 18:50:25.405: epoch 58:	0.02448545  	0.17994839  	0.09673425  
2023-05-18 18:50:25.406: Find a better model.
2023-05-18 18:50:33.533: [iter 59 : loss : 0.1676 = 0.0744 + 0.0895 + 0.0037, time: 8.126026]
2023-05-18 18:50:33.697: epoch 59:	0.02463363  	0.18106805  	0.09730488  
2023-05-18 18:50:33.697: Find a better model.
2023-05-18 18:50:41.917: [iter 60 : loss : 0.1660 = 0.0729 + 0.0894 + 0.0037, time: 8.219014]
2023-05-18 18:50:42.070: epoch 60:	0.02452073  	0.18025945  	0.09742153  
2023-05-18 18:50:49.660: [iter 61 : loss : 0.1646 = 0.0717 + 0.0892 + 0.0038, time: 7.588003]
2023-05-18 18:50:49.827: epoch 61:	0.02454895  	0.18088515  	0.09790600  
2023-05-18 18:50:57.927: [iter 62 : loss : 0.1630 = 0.0701 + 0.0891 + 0.0038, time: 8.098002]
2023-05-18 18:50:58.087: epoch 62:	0.02464774  	0.18147221  	0.09854461  
2023-05-18 18:50:58.087: Find a better model.
2023-05-18 18:51:06.109: [iter 63 : loss : 0.1615 = 0.0687 + 0.0889 + 0.0039, time: 8.021033]
2023-05-18 18:51:06.394: epoch 63:	0.02466186  	0.18148173  	0.09863350  
2023-05-18 18:51:06.394: Find a better model.
2023-05-18 18:51:13.976: [iter 64 : loss : 0.1606 = 0.0679 + 0.0887 + 0.0039, time: 7.581186]
2023-05-18 18:51:14.197: epoch 64:	0.02482416  	0.18295011  	0.09919111  
2023-05-18 18:51:14.197: Find a better model.
2023-05-18 18:51:22.099: [iter 65 : loss : 0.1594 = 0.0668 + 0.0886 + 0.0040, time: 7.897979]
2023-05-18 18:51:22.256: epoch 65:	0.02488767  	0.18324621  	0.09962024  
2023-05-18 18:51:22.257: Find a better model.
2023-05-18 18:51:31.091: [iter 66 : loss : 0.1576 = 0.0651 + 0.0884 + 0.0040, time: 8.832006]
2023-05-18 18:51:31.379: epoch 66:	0.02492295  	0.18321571  	0.09991771  
2023-05-18 18:51:39.358: [iter 67 : loss : 0.1561 = 0.0638 + 0.0883 + 0.0040, time: 7.978004]
2023-05-18 18:51:39.510: epoch 67:	0.02495117  	0.18338148  	0.10012691  
2023-05-18 18:51:39.510: Find a better model.
2023-05-18 18:51:47.881: [iter 68 : loss : 0.1559 = 0.0636 + 0.0881 + 0.0041, time: 8.369013]
2023-05-18 18:51:48.031: epoch 68:	0.02500763  	0.18404609  	0.10041442  
2023-05-18 18:51:48.031: Find a better model.
2023-05-18 18:51:56.989: [iter 69 : loss : 0.1541 = 0.0619 + 0.0880 + 0.0041, time: 8.957020]
2023-05-18 18:51:57.277: epoch 69:	0.02517698  	0.18547429  	0.10090143  
2023-05-18 18:51:57.277: Find a better model.
2023-05-18 18:52:05.261: [iter 70 : loss : 0.1523 = 0.0602 + 0.0879 + 0.0042, time: 7.983128]
2023-05-18 18:52:05.417: epoch 70:	0.02526872  	0.18607149  	0.10124281  
2023-05-18 18:52:05.417: Find a better model.
2023-05-18 18:52:13.677: [iter 71 : loss : 0.1510 = 0.0590 + 0.0878 + 0.0042, time: 8.258002]
2023-05-18 18:52:13.841: epoch 71:	0.02524049  	0.18579696  	0.10111262  
2023-05-18 18:52:22.981: [iter 72 : loss : 0.1508 = 0.0588 + 0.0877 + 0.0043, time: 9.137022]
2023-05-18 18:52:23.250: epoch 72:	0.02531812  	0.18647742  	0.10159221  
2023-05-18 18:52:23.250: Find a better model.
2023-05-18 18:52:31.379: [iter 73 : loss : 0.1493 = 0.0575 + 0.0875 + 0.0043, time: 8.128013]
2023-05-18 18:52:31.548: epoch 73:	0.02542396  	0.18715572  	0.10190699  
2023-05-18 18:52:31.548: Find a better model.
2023-05-18 18:52:39.820: [iter 74 : loss : 0.1482 = 0.0564 + 0.0874 + 0.0043, time: 8.269019]
2023-05-18 18:52:40.071: epoch 74:	0.02548041  	0.18772846  	0.10227378  
2023-05-18 18:52:40.071: Find a better model.
2023-05-18 18:52:48.940: [iter 75 : loss : 0.1477 = 0.0560 + 0.0873 + 0.0044, time: 8.865832]
2023-05-18 18:52:49.230: epoch 75:	0.02549452  	0.18749878  	0.10238205  
2023-05-18 18:52:57.251: [iter 76 : loss : 0.1465 = 0.0549 + 0.0872 + 0.0044, time: 8.017976]
2023-05-18 18:52:57.410: epoch 76:	0.02557214  	0.18793420  	0.10265996  
2023-05-18 18:52:57.410: Find a better model.
2023-05-18 18:53:05.667: [iter 77 : loss : 0.1457 = 0.0541 + 0.0871 + 0.0045, time: 8.255176]
2023-05-18 18:53:05.887: epoch 77:	0.02566388  	0.18857965  	0.10295643  
2023-05-18 18:53:05.887: Find a better model.
2023-05-18 18:53:14.758: [iter 78 : loss : 0.1445 = 0.0531 + 0.0869 + 0.0045, time: 8.859478]
2023-05-18 18:53:14.953: epoch 78:	0.02567093  	0.18857534  	0.10296066  
2023-05-18 18:53:23.039: [iter 79 : loss : 0.1433 = 0.0519 + 0.0868 + 0.0045, time: 8.084212]
2023-05-18 18:53:23.209: epoch 79:	0.02570622  	0.18871047  	0.10309330  
2023-05-18 18:53:23.209: Find a better model.
2023-05-18 18:53:31.489: [iter 80 : loss : 0.1427 = 0.0514 + 0.0867 + 0.0046, time: 8.278012]
2023-05-18 18:53:31.656: epoch 80:	0.02572033  	0.18890345  	0.10323504  
2023-05-18 18:53:31.657: Find a better model.
2023-05-18 18:53:39.352: [iter 81 : loss : 0.1422 = 0.0509 + 0.0866 + 0.0046, time: 7.694003]
2023-05-18 18:53:39.515: epoch 81:	0.02575561  	0.18891266  	0.10330450  
2023-05-18 18:53:39.515: Find a better model.
2023-05-18 18:53:47.640: [iter 82 : loss : 0.1408 = 0.0496 + 0.0865 + 0.0047, time: 8.123012]
2023-05-18 18:53:47.818: epoch 82:	0.02578384  	0.18929048  	0.10348090  
2023-05-18 18:53:47.818: Find a better model.
2023-05-18 18:53:56.017: [iter 83 : loss : 0.1399 = 0.0488 + 0.0864 + 0.0047, time: 8.198013]
2023-05-18 18:53:56.185: epoch 83:	0.02589675  	0.19007829  	0.10394870  
2023-05-18 18:53:56.185: Find a better model.
2023-05-18 18:54:03.740: [iter 84 : loss : 0.1399 = 0.0489 + 0.0863 + 0.0047, time: 7.552993]
2023-05-18 18:54:03.910: epoch 84:	0.02587559  	0.19022736  	0.10403078  
2023-05-18 18:54:03.910: Find a better model.
2023-05-18 18:54:11.836: [iter 85 : loss : 0.1389 = 0.0479 + 0.0862 + 0.0048, time: 7.925003]
2023-05-18 18:54:12.000: epoch 85:	0.02595321  	0.19043888  	0.10417813  
2023-05-18 18:54:12.000: Find a better model.
2023-05-18 18:54:20.225: [iter 86 : loss : 0.1388 = 0.0479 + 0.0861 + 0.0048, time: 8.224314]
2023-05-18 18:54:20.390: epoch 86:	0.02602377  	0.19099568  	0.10430345  
2023-05-18 18:54:20.390: Find a better model.
2023-05-18 18:54:27.944: [iter 87 : loss : 0.1359 = 0.0450 + 0.0860 + 0.0049, time: 7.553045]
2023-05-18 18:54:28.103: epoch 87:	0.02608022  	0.19139276  	0.10456121  
2023-05-18 18:54:28.103: Find a better model.
2023-05-18 18:54:36.029: [iter 88 : loss : 0.1354 = 0.0446 + 0.0859 + 0.0049, time: 7.925004]
2023-05-18 18:54:36.192: epoch 88:	0.02612962  	0.19166602  	0.10498066  
2023-05-18 18:54:36.192: Find a better model.
2023-05-18 18:54:44.432: [iter 89 : loss : 0.1350 = 0.0443 + 0.0858 + 0.0049, time: 8.238991]
2023-05-18 18:54:44.600: epoch 89:	0.02612962  	0.19171445  	0.10520347  
2023-05-18 18:54:44.600: Find a better model.
2023-05-18 18:54:52.181: [iter 90 : loss : 0.1358 = 0.0451 + 0.0858 + 0.0050, time: 7.580018]
2023-05-18 18:54:52.340: epoch 90:	0.02612256  	0.19162452  	0.10517321  
2023-05-18 18:55:00.444: [iter 91 : loss : 0.1344 = 0.0437 + 0.0857 + 0.0050, time: 8.102567]
2023-05-18 18:55:00.603: epoch 91:	0.02620018  	0.19201858  	0.10530394  
2023-05-18 18:55:00.604: Find a better model.
2023-05-18 18:55:08.829: [iter 92 : loss : 0.1336 = 0.0430 + 0.0856 + 0.0050, time: 8.224015]
2023-05-18 18:55:08.982: epoch 92:	0.02621429  	0.19241931  	0.10545601  
2023-05-18 18:55:08.982: Find a better model.
2023-05-18 18:55:16.571: [iter 93 : loss : 0.1339 = 0.0433 + 0.0855 + 0.0051, time: 7.588161]
2023-05-18 18:55:16.727: epoch 93:	0.02622841  	0.19248615  	0.10558560  
2023-05-18 18:55:16.727: Find a better model.
2023-05-18 18:55:24.804: [iter 94 : loss : 0.1316 = 0.0411 + 0.0855 + 0.0051, time: 8.075016]
2023-05-18 18:55:24.963: epoch 94:	0.02622841  	0.19251682  	0.10570520  
2023-05-18 18:55:24.963: Find a better model.
2023-05-18 18:55:33.852: [iter 95 : loss : 0.1311 = 0.0406 + 0.0854 + 0.0051, time: 8.886002]
2023-05-18 18:55:34.139: epoch 95:	0.02622841  	0.19230215  	0.10569330  
2023-05-18 18:55:42.068: [iter 96 : loss : 0.1313 = 0.0408 + 0.0853 + 0.0052, time: 7.927003]
2023-05-18 18:55:42.221: epoch 96:	0.02616489  	0.19222850  	0.10569214  
2023-05-18 18:55:50.369: [iter 97 : loss : 0.1295 = 0.0391 + 0.0852 + 0.0052, time: 8.146013]
2023-05-18 18:55:50.534: epoch 97:	0.02622841  	0.19245280  	0.10574224  
2023-05-18 18:55:59.564: [iter 98 : loss : 0.1303 = 0.0399 + 0.0852 + 0.0053, time: 9.027057]
2023-05-18 18:55:59.862: epoch 98:	0.02621429  	0.19229139  	0.10590120  
2023-05-18 18:56:08.020: [iter 99 : loss : 0.1292 = 0.0388 + 0.0851 + 0.0053, time: 8.156848]
2023-05-18 18:56:08.191: epoch 99:	0.02622841  	0.19245617  	0.10592359  
2023-05-18 18:56:16.421: [iter 100 : loss : 0.1287 = 0.0384 + 0.0850 + 0.0053, time: 8.228003]
2023-05-18 18:56:16.586: epoch 100:	0.02628486  	0.19294773  	0.10615265  
2023-05-18 18:56:16.586: Find a better model.
2023-05-18 18:56:25.506: [iter 101 : loss : 0.1283 = 0.0380 + 0.0849 + 0.0054, time: 8.916016]
2023-05-18 18:56:25.775: epoch 101:	0.02630603  	0.19269896  	0.10640696  
2023-05-18 18:56:33.920: [iter 102 : loss : 0.1273 = 0.0371 + 0.0849 + 0.0054, time: 8.142057]
2023-05-18 18:56:34.093: epoch 102:	0.02627780  	0.19270580  	0.10629673  
2023-05-18 18:56:42.184: [iter 103 : loss : 0.1269 = 0.0366 + 0.0848 + 0.0054, time: 8.089993]
2023-05-18 18:56:42.347: epoch 103:	0.02632720  	0.19271339  	0.10644554  
2023-05-18 18:56:51.372: [iter 104 : loss : 0.1273 = 0.0371 + 0.0847 + 0.0055, time: 9.024051]
2023-05-18 18:56:51.660: epoch 104:	0.02631309  	0.19261420  	0.10640873  
2023-05-18 18:56:59.773: [iter 105 : loss : 0.1267 = 0.0365 + 0.0847 + 0.0055, time: 8.112026]
2023-05-18 18:56:59.928: epoch 105:	0.02636954  	0.19333796  	0.10663538  
2023-05-18 18:56:59.929: Find a better model.
2023-05-18 18:57:08.070: [iter 106 : loss : 0.1261 = 0.0359 + 0.0846 + 0.0055, time: 8.139011]
2023-05-18 18:57:08.239: epoch 106:	0.02629897  	0.19284914  	0.10667253  
2023-05-18 18:57:17.084: [iter 107 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 8.838014]
2023-05-18 18:57:17.369: epoch 107:	0.02636248  	0.19341007  	0.10680611  
2023-05-18 18:57:17.370: Find a better model.
2023-05-18 18:57:25.534: [iter 108 : loss : 0.1248 = 0.0348 + 0.0845 + 0.0056, time: 8.162996]
2023-05-18 18:57:25.688: epoch 108:	0.02633425  	0.19339913  	0.10684802  
2023-05-18 18:57:33.781: [iter 109 : loss : 0.1237 = 0.0336 + 0.0844 + 0.0056, time: 8.091018]
2023-05-18 18:57:33.997: epoch 109:	0.02636953  	0.19376418  	0.10704330  
2023-05-18 18:57:33.997: Find a better model.
2023-05-18 18:57:42.641: [iter 110 : loss : 0.1232 = 0.0332 + 0.0843 + 0.0057, time: 8.641010]
2023-05-18 18:57:42.842: epoch 110:	0.02641187  	0.19403169  	0.10719117  
2023-05-18 18:57:42.843: Find a better model.
2023-05-18 18:57:50.936: [iter 111 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 8.092220]
2023-05-18 18:57:51.104: epoch 111:	0.02636248  	0.19382140  	0.10702812  
2023-05-18 18:57:59.585: [iter 112 : loss : 0.1229 = 0.0329 + 0.0842 + 0.0057, time: 8.479007]
2023-05-18 18:57:59.746: epoch 112:	0.02640482  	0.19416636  	0.10717380  
2023-05-18 18:57:59.746: Find a better model.
2023-05-18 18:58:07.617: [iter 113 : loss : 0.1230 = 0.0331 + 0.0842 + 0.0058, time: 7.870027]
2023-05-18 18:58:07.794: epoch 113:	0.02647539  	0.19444510  	0.10738043  
2023-05-18 18:58:07.795: Find a better model.
2023-05-18 18:58:15.784: [iter 114 : loss : 0.1220 = 0.0321 + 0.0841 + 0.0058, time: 7.984020]
2023-05-18 18:58:15.953: epoch 114:	0.02644716  	0.19403583  	0.10739940  
2023-05-18 18:58:24.188: [iter 115 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0058, time: 8.234007]
2023-05-18 18:58:24.351: epoch 115:	0.02642599  	0.19382709  	0.10736744  
2023-05-18 18:58:31.921: [iter 116 : loss : 0.1206 = 0.0307 + 0.0840 + 0.0059, time: 7.569165]
2023-05-18 18:58:32.083: epoch 116:	0.02634837  	0.19305958  	0.10731473  
2023-05-18 18:58:40.141: [iter 117 : loss : 0.1205 = 0.0307 + 0.0839 + 0.0059, time: 8.056000]
2023-05-18 18:58:40.301: epoch 117:	0.02632014  	0.19295008  	0.10745707  
2023-05-18 18:58:48.397: [iter 118 : loss : 0.1205 = 0.0306 + 0.0839 + 0.0059, time: 8.094073]
2023-05-18 18:58:48.560: epoch 118:	0.02636953  	0.19314846  	0.10758747  
2023-05-18 18:58:56.065: [iter 119 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 7.504019]
2023-05-18 18:58:56.227: epoch 119:	0.02644716  	0.19372647  	0.10786220  
2023-05-18 18:59:04.141: [iter 120 : loss : 0.1198 = 0.0300 + 0.0838 + 0.0060, time: 7.912030]
2023-05-18 18:59:04.304: epoch 120:	0.02644010  	0.19365075  	0.10785159  
2023-05-18 18:59:12.371: [iter 121 : loss : 0.1197 = 0.0300 + 0.0838 + 0.0060, time: 8.066019]
2023-05-18 18:59:12.529: epoch 121:	0.02645422  	0.19383477  	0.10801558  
2023-05-18 18:59:20.353: [iter 122 : loss : 0.1190 = 0.0292 + 0.0837 + 0.0061, time: 7.823075]
2023-05-18 18:59:20.517: epoch 122:	0.02643304  	0.19360021  	0.10798644  
2023-05-18 18:59:28.306: [iter 123 : loss : 0.1187 = 0.0289 + 0.0837 + 0.0061, time: 7.786999]
2023-05-18 18:59:28.471: epoch 123:	0.02636248  	0.19283687  	0.10780917  
2023-05-18 18:59:36.941: [iter 124 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0061, time: 8.469079]
2023-05-18 18:59:37.110: epoch 124:	0.02636248  	0.19298777  	0.10800338  
2023-05-18 18:59:44.622: [iter 125 : loss : 0.1174 = 0.0276 + 0.0836 + 0.0061, time: 7.511000]
2023-05-18 18:59:44.801: epoch 125:	0.02635542  	0.19276190  	0.10807354  
2023-05-18 18:59:52.750: [iter 126 : loss : 0.1178 = 0.0281 + 0.0835 + 0.0062, time: 7.945992]
2023-05-18 18:59:52.923: epoch 126:	0.02629897  	0.19252832  	0.10791552  
2023-05-18 19:00:01.178: [iter 127 : loss : 0.1166 = 0.0270 + 0.0834 + 0.0062, time: 8.253007]
2023-05-18 19:00:01.344: epoch 127:	0.02640482  	0.19358981  	0.10828651  
2023-05-18 19:00:09.044: [iter 128 : loss : 0.1176 = 0.0279 + 0.0834 + 0.0062, time: 7.699021]
2023-05-18 19:00:09.202: epoch 128:	0.02636248  	0.19306718  	0.10807984  
2023-05-18 19:00:17.085: [iter 129 : loss : 0.1168 = 0.0272 + 0.0834 + 0.0063, time: 7.881002]
2023-05-18 19:00:17.247: epoch 129:	0.02634132  	0.19299613  	0.10795312  
2023-05-18 19:00:25.513: [iter 130 : loss : 0.1167 = 0.0270 + 0.0833 + 0.0063, time: 8.264993]
2023-05-18 19:00:25.680: epoch 130:	0.02637660  	0.19324318  	0.10797109  
2023-05-18 19:00:33.264: [iter 131 : loss : 0.1158 = 0.0262 + 0.0833 + 0.0063, time: 7.582054]
2023-05-18 19:00:33.428: epoch 131:	0.02643305  	0.19326404  	0.10802992  
2023-05-18 19:00:41.289: [iter 132 : loss : 0.1160 = 0.0264 + 0.0832 + 0.0064, time: 7.859033]
2023-05-18 19:00:41.454: epoch 132:	0.02644716  	0.19338875  	0.10823630  
2023-05-18 19:00:49.529: [iter 133 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0064, time: 8.074001]
2023-05-18 19:00:49.694: epoch 133:	0.02643305  	0.19297113  	0.10815787  
2023-05-18 19:00:57.268: [iter 134 : loss : 0.1159 = 0.0264 + 0.0832 + 0.0064, time: 7.571136]
2023-05-18 19:00:57.432: epoch 134:	0.02646127  	0.19310962  	0.10829487  
2023-05-18 19:01:05.279: [iter 135 : loss : 0.1154 = 0.0259 + 0.0831 + 0.0064, time: 7.844029]
2023-05-18 19:01:05.441: epoch 135:	0.02644716  	0.19306527  	0.10814345  
2023-05-18 19:01:13.687: [iter 136 : loss : 0.1150 = 0.0255 + 0.0831 + 0.0065, time: 8.243127]
2023-05-18 19:01:13.859: epoch 136:	0.02646128  	0.19313975  	0.10825660  
2023-05-18 19:01:21.462: [iter 137 : loss : 0.1146 = 0.0251 + 0.0830 + 0.0065, time: 7.601013]
2023-05-18 19:01:21.624: epoch 137:	0.02647539  	0.19321786  	0.10830452  
2023-05-18 19:01:29.471: [iter 138 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0065, time: 7.843993]
2023-05-18 19:01:29.634: epoch 138:	0.02656712  	0.19382527  	0.10846721  
2023-05-18 19:01:29.635: Early stopping is trigger at epoch: 138
2023-05-18 19:01:29.635: best_result@epoch 113:

2023-05-18 19:01:29.635: 		0.0265      	0.1944      	0.1074      
2023-05-18 19:22:36.065: my pid: 13540
2023-05-18 19:22:36.065: model: model.general_recommender.SGL
2023-05-18 19:22:36.065: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-18 19:22:36.065: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-18 19:22:39.198: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-18 19:22:47.622: [iter 1 : loss : 0.7717 = 0.6930 + 0.0787 + 0.0000, time: 8.422405]
2023-05-18 19:22:47.774: epoch 1:	0.00134773  	0.00985506  	0.00484203  
2023-05-18 19:22:47.774: Find a better model.
2023-05-18 19:22:56.222: [iter 2 : loss : 0.7713 = 0.6928 + 0.0784 + 0.0000, time: 8.446041]
2023-05-18 19:22:56.421: epoch 2:	0.00266723  	0.01954108  	0.00911522  
2023-05-18 19:22:56.421: Find a better model.
2023-05-18 19:23:04.847: [iter 3 : loss : 0.7710 = 0.6926 + 0.0785 + 0.0000, time: 8.425346]
2023-05-18 19:23:05.008: epoch 3:	0.00474877  	0.03497425  	0.01671907  
2023-05-18 19:23:05.008: Find a better model.
2023-05-18 19:23:13.243: [iter 4 : loss : 0.7706 = 0.6920 + 0.0786 + 0.0000, time: 8.233979]
2023-05-18 19:23:13.394: epoch 4:	0.00771232  	0.05703466  	0.02680217  
2023-05-18 19:23:13.394: Find a better model.
2023-05-18 19:23:21.441: [iter 5 : loss : 0.7696 = 0.6908 + 0.0788 + 0.0000, time: 8.045486]
2023-05-18 19:23:21.589: epoch 5:	0.01150158  	0.08419271  	0.03970315  
2023-05-18 19:23:21.589: Find a better model.
2023-05-18 19:23:29.599: [iter 6 : loss : 0.7673 = 0.6882 + 0.0791 + 0.0000, time: 8.008839]
2023-05-18 19:23:29.747: epoch 6:	0.01508624  	0.10922711  	0.05274729  
2023-05-18 19:23:29.747: Find a better model.
2023-05-18 19:23:37.620: [iter 7 : loss : 0.7610 = 0.6810 + 0.0799 + 0.0000, time: 7.871716]
2023-05-18 19:23:37.788: epoch 7:	0.01770417  	0.12826519  	0.06268690  
2023-05-18 19:23:37.789: Find a better model.
2023-05-18 19:23:45.599: [iter 8 : loss : 0.7452 = 0.6633 + 0.0818 + 0.0001, time: 7.808362]
2023-05-18 19:23:45.759: epoch 8:	0.01841686  	0.13396467  	0.06709253  
2023-05-18 19:23:45.759: Find a better model.
2023-05-18 19:23:53.605: [iter 9 : loss : 0.7095 = 0.6237 + 0.0857 + 0.0001, time: 7.844869]
2023-05-18 19:23:53.766: epoch 9:	0.01883321  	0.13798900  	0.06855808  
2023-05-18 19:23:53.767: Find a better model.
2023-05-18 19:24:01.393: [iter 10 : loss : 0.6483 = 0.5571 + 0.0910 + 0.0002, time: 7.625140]
2023-05-18 19:24:01.544: epoch 10:	0.01865679  	0.13803598  	0.06831359  
2023-05-18 19:24:01.544: Find a better model.
2023-05-18 19:24:09.156: [iter 11 : loss : 0.5730 = 0.4767 + 0.0959 + 0.0004, time: 7.610452]
2023-05-18 19:24:09.305: epoch 11:	0.01851567  	0.13704228  	0.06832898  
2023-05-18 19:24:17.016: [iter 12 : loss : 0.5046 = 0.4047 + 0.0993 + 0.0006, time: 7.709781]
2023-05-18 19:24:17.167: epoch 12:	0.01850861  	0.13700771  	0.06870419  
2023-05-18 19:24:24.765: [iter 13 : loss : 0.4540 = 0.3522 + 0.1011 + 0.0007, time: 7.597310]
2023-05-18 19:24:24.915: epoch 13:	0.01855801  	0.13740088  	0.06926779  
2023-05-18 19:24:32.591: [iter 14 : loss : 0.4153 = 0.3125 + 0.1020 + 0.0008, time: 7.675205]
2023-05-18 19:24:32.747: epoch 14:	0.01879793  	0.13901509  	0.07011826  
2023-05-18 19:24:32.747: Find a better model.
2023-05-18 19:24:40.365: [iter 15 : loss : 0.3885 = 0.2852 + 0.1024 + 0.0010, time: 7.616701]
2023-05-18 19:24:40.511: epoch 15:	0.01900963  	0.14123572  	0.07117548  
2023-05-18 19:24:40.511: Find a better model.
2023-05-18 19:24:48.012: [iter 16 : loss : 0.3658 = 0.2623 + 0.1023 + 0.0011, time: 7.499007]
2023-05-18 19:24:48.163: epoch 16:	0.01933422  	0.14342465  	0.07210692  
2023-05-18 19:24:48.163: Find a better model.
2023-05-18 19:24:55.755: [iter 17 : loss : 0.3490 = 0.2457 + 0.1022 + 0.0012, time: 7.590519]
2023-05-18 19:24:55.904: epoch 17:	0.01955298  	0.14472011  	0.07309315  
2023-05-18 19:24:55.904: Find a better model.
2023-05-18 19:25:03.575: [iter 18 : loss : 0.3340 = 0.2307 + 0.1020 + 0.0013, time: 7.669646]
2023-05-18 19:25:03.731: epoch 18:	0.01974351  	0.14585321  	0.07396003  
2023-05-18 19:25:03.732: Find a better model.
2023-05-18 19:25:11.372: [iter 19 : loss : 0.3197 = 0.2166 + 0.1017 + 0.0014, time: 7.638966]
2023-05-18 19:25:11.525: epoch 19:	0.01983524  	0.14610097  	0.07435312  
2023-05-18 19:25:11.525: Find a better model.
2023-05-18 19:25:19.171: [iter 20 : loss : 0.3099 = 0.2073 + 0.1012 + 0.0015, time: 7.645064]
2023-05-18 19:25:19.319: epoch 20:	0.02003283  	0.14806728  	0.07527723  
2023-05-18 19:25:19.319: Find a better model.
2023-05-18 19:25:26.958: [iter 21 : loss : 0.3002 = 0.1978 + 0.1008 + 0.0016, time: 7.636801]
2023-05-18 19:25:27.109: epoch 21:	0.02023747  	0.14972781  	0.07625549  
2023-05-18 19:25:27.109: Find a better model.
2023-05-18 19:25:34.560: [iter 22 : loss : 0.2918 = 0.1898 + 0.1004 + 0.0017, time: 7.449740]
2023-05-18 19:25:34.708: epoch 22:	0.02042094  	0.15080830  	0.07686883  
2023-05-18 19:25:34.708: Find a better model.
2023-05-18 19:25:42.335: [iter 23 : loss : 0.2838 = 0.1821 + 0.1000 + 0.0017, time: 7.625854]
2023-05-18 19:25:42.485: epoch 23:	0.02065380  	0.15251303  	0.07771470  
2023-05-18 19:25:42.485: Find a better model.
2023-05-18 19:25:50.133: [iter 24 : loss : 0.2773 = 0.1759 + 0.0995 + 0.0018, time: 7.647879]
2023-05-18 19:25:50.283: epoch 24:	0.02078787  	0.15355594  	0.07853699  
2023-05-18 19:25:50.283: Find a better model.
2023-05-18 19:25:57.925: [iter 25 : loss : 0.2706 = 0.1695 + 0.0992 + 0.0019, time: 7.639581]
2023-05-18 19:25:58.087: epoch 25:	0.02098546  	0.15485974  	0.07915872  
2023-05-18 19:25:58.087: Find a better model.
2023-05-18 19:26:05.721: [iter 26 : loss : 0.2667 = 0.1660 + 0.0987 + 0.0019, time: 7.632661]
2023-05-18 19:26:05.874: epoch 26:	0.02115482  	0.15565249  	0.07972922  
2023-05-18 19:26:05.874: Find a better model.
2023-05-18 19:26:13.352: [iter 27 : loss : 0.2593 = 0.1589 + 0.0983 + 0.0020, time: 7.476414]
2023-05-18 19:26:13.512: epoch 27:	0.02125360  	0.15627256  	0.08022460  
2023-05-18 19:26:13.513: Find a better model.
2023-05-18 19:26:21.112: [iter 28 : loss : 0.2539 = 0.1539 + 0.0979 + 0.0021, time: 7.597469]
2023-05-18 19:26:21.261: epoch 28:	0.02140179  	0.15680194  	0.08077861  
2023-05-18 19:26:21.261: Find a better model.
2023-05-18 19:26:28.750: [iter 29 : loss : 0.2496 = 0.1500 + 0.0975 + 0.0021, time: 7.486847]
2023-05-18 19:26:28.900: epoch 29:	0.02157115  	0.15855998  	0.08179077  
2023-05-18 19:26:28.901: Find a better model.
2023-05-18 19:26:36.551: [iter 30 : loss : 0.2432 = 0.1438 + 0.0972 + 0.0022, time: 7.648460]
2023-05-18 19:26:36.701: epoch 30:	0.02166288  	0.15937932  	0.08229895  
2023-05-18 19:26:36.701: Find a better model.
2023-05-18 19:26:44.323: [iter 31 : loss : 0.2398 = 0.1407 + 0.0967 + 0.0023, time: 7.621277]
2023-05-18 19:26:44.474: epoch 31:	0.02188869  	0.16074754  	0.08295217  
2023-05-18 19:26:44.474: Find a better model.
2023-05-18 19:26:52.126: [iter 32 : loss : 0.2340 = 0.1352 + 0.0964 + 0.0023, time: 7.649290]
2023-05-18 19:26:52.274: epoch 32:	0.02212155  	0.16210869  	0.08373681  
2023-05-18 19:26:52.274: Find a better model.
2023-05-18 19:26:59.921: [iter 33 : loss : 0.2313 = 0.1329 + 0.0960 + 0.0024, time: 7.644378]
2023-05-18 19:27:00.076: epoch 33:	0.02225563  	0.16306448  	0.08437160  
2023-05-18 19:27:00.076: Find a better model.
2023-05-18 19:27:07.740: [iter 34 : loss : 0.2274 = 0.1292 + 0.0957 + 0.0024, time: 7.663649]
2023-05-18 19:27:07.901: epoch 34:	0.02243204  	0.16470352  	0.08506436  
2023-05-18 19:27:07.901: Find a better model.
2023-05-18 19:27:15.753: [iter 35 : loss : 0.2239 = 0.1260 + 0.0954 + 0.0025, time: 7.849808]
2023-05-18 19:27:15.908: epoch 35:	0.02261550  	0.16597158  	0.08596438  
2023-05-18 19:27:15.908: Find a better model.
2023-05-18 19:27:23.898: [iter 36 : loss : 0.2206 = 0.1229 + 0.0951 + 0.0026, time: 7.988113]
2023-05-18 19:27:24.062: epoch 36:	0.02274957  	0.16691212  	0.08657666  
2023-05-18 19:27:24.062: Find a better model.
2023-05-18 19:27:31.927: [iter 37 : loss : 0.2165 = 0.1192 + 0.0947 + 0.0026, time: 7.862828]
2023-05-18 19:27:32.094: epoch 37:	0.02291893  	0.16806716  	0.08729483  
2023-05-18 19:27:32.094: Find a better model.
2023-05-18 19:27:39.908: [iter 38 : loss : 0.2150 = 0.1179 + 0.0944 + 0.0027, time: 7.813148]
2023-05-18 19:27:40.059: epoch 38:	0.02295421  	0.16861430  	0.08754135  
2023-05-18 19:27:40.059: Find a better model.
2023-05-18 19:27:47.908: [iter 39 : loss : 0.2106 = 0.1137 + 0.0942 + 0.0027, time: 7.848462]
2023-05-18 19:27:48.056: epoch 39:	0.02299656  	0.16883631  	0.08799594  
2023-05-18 19:27:48.056: Find a better model.
2023-05-18 19:27:55.920: [iter 40 : loss : 0.2071 = 0.1105 + 0.0938 + 0.0028, time: 7.862234]
2023-05-18 19:27:56.072: epoch 40:	0.02323648  	0.17072792  	0.08868778  
2023-05-18 19:27:56.072: Find a better model.
2023-05-18 19:28:03.901: [iter 41 : loss : 0.2057 = 0.1093 + 0.0935 + 0.0028, time: 7.828148]
2023-05-18 19:28:04.052: epoch 41:	0.02334939  	0.17199892  	0.08934101  
2023-05-18 19:28:04.052: Find a better model.
2023-05-18 19:28:11.915: [iter 42 : loss : 0.2036 = 0.1075 + 0.0933 + 0.0029, time: 7.862551]
2023-05-18 19:28:12.064: epoch 42:	0.02346229  	0.17303957  	0.08994892  
2023-05-18 19:28:12.065: Find a better model.
2023-05-18 19:28:20.105: [iter 43 : loss : 0.1996 = 0.1037 + 0.0930 + 0.0029, time: 8.037875]
2023-05-18 19:28:20.255: epoch 43:	0.02353285  	0.17333408  	0.09040166  
2023-05-18 19:28:20.255: Find a better model.
2023-05-18 19:28:28.137: [iter 44 : loss : 0.1962 = 0.1005 + 0.0927 + 0.0030, time: 7.881090]
2023-05-18 19:28:28.286: epoch 44:	0.02356108  	0.17354834  	0.09086116  
2023-05-18 19:28:28.286: Find a better model.
2023-05-18 19:28:36.309: [iter 45 : loss : 0.1942 = 0.0986 + 0.0925 + 0.0030, time: 8.020214]
2023-05-18 19:28:36.466: epoch 45:	0.02368810  	0.17460410  	0.09151384  
2023-05-18 19:28:36.466: Find a better model.
2023-05-18 19:28:44.308: [iter 46 : loss : 0.1917 = 0.0964 + 0.0922 + 0.0031, time: 7.840533]
2023-05-18 19:28:44.456: epoch 46:	0.02374454  	0.17494673  	0.09196988  
2023-05-18 19:28:44.456: Find a better model.
2023-05-18 19:28:52.325: [iter 47 : loss : 0.1911 = 0.0959 + 0.0920 + 0.0031, time: 7.867689]
2023-05-18 19:28:52.474: epoch 47:	0.02389273  	0.17590466  	0.09245136  
2023-05-18 19:28:52.474: Find a better model.
2023-05-18 19:29:00.289: [iter 48 : loss : 0.1871 = 0.0921 + 0.0918 + 0.0032, time: 7.813205]
2023-05-18 19:29:00.437: epoch 48:	0.02392096  	0.17619351  	0.09291387  
2023-05-18 19:29:00.437: Find a better model.
2023-05-18 19:29:08.294: [iter 49 : loss : 0.1840 = 0.0892 + 0.0916 + 0.0032, time: 7.855958]
2023-05-18 19:29:08.446: epoch 49:	0.02398447  	0.17644040  	0.09334683  
2023-05-18 19:29:08.446: Find a better model.
2023-05-18 19:29:16.312: [iter 50 : loss : 0.1833 = 0.0886 + 0.0914 + 0.0033, time: 7.865684]
2023-05-18 19:29:16.461: epoch 50:	0.02404798  	0.17699832  	0.09375177  
2023-05-18 19:29:16.461: Find a better model.
2023-05-18 19:29:24.280: [iter 51 : loss : 0.1801 = 0.0856 + 0.0912 + 0.0033, time: 7.817330]
2023-05-18 19:29:24.429: epoch 51:	0.02413266  	0.17766535  	0.09425799  
2023-05-18 19:29:24.429: Find a better model.
2023-05-18 19:29:32.482: [iter 52 : loss : 0.1802 = 0.0859 + 0.0910 + 0.0034, time: 8.052222]
2023-05-18 19:29:32.643: epoch 52:	0.02428789  	0.17861779  	0.09497046  
2023-05-18 19:29:32.643: Find a better model.
2023-05-18 19:29:40.459: [iter 53 : loss : 0.1783 = 0.0841 + 0.0907 + 0.0034, time: 7.814607]
2023-05-18 19:29:40.608: epoch 53:	0.02435846  	0.17923632  	0.09529997  
2023-05-18 19:29:40.608: Find a better model.
2023-05-18 19:29:48.485: [iter 54 : loss : 0.1760 = 0.0820 + 0.0905 + 0.0035, time: 7.874244]
2023-05-18 19:29:48.637: epoch 54:	0.02436551  	0.17938085  	0.09552142  
2023-05-18 19:29:48.637: Find a better model.
2023-05-18 19:29:56.495: [iter 55 : loss : 0.1742 = 0.0803 + 0.0903 + 0.0035, time: 7.856807]
2023-05-18 19:29:56.651: epoch 55:	0.02443607  	0.17959486  	0.09589352  
2023-05-18 19:29:56.651: Find a better model.
2023-05-18 19:30:04.454: [iter 56 : loss : 0.1723 = 0.0786 + 0.0901 + 0.0036, time: 7.801873]
2023-05-18 19:30:04.602: epoch 56:	0.02445018  	0.17957112  	0.09621926  
2023-05-18 19:30:12.264: [iter 57 : loss : 0.1705 = 0.0769 + 0.0900 + 0.0036, time: 7.660444]
2023-05-18 19:30:12.430: epoch 57:	0.02447135  	0.17971566  	0.09651916  
2023-05-18 19:30:12.430: Find a better model.
2023-05-18 19:30:20.272: [iter 58 : loss : 0.1689 = 0.0755 + 0.0898 + 0.0037, time: 7.839990]
2023-05-18 19:30:20.424: epoch 58:	0.02453485  	0.18023491  	0.09682231  
2023-05-18 19:30:20.424: Find a better model.
2023-05-18 19:30:28.069: [iter 59 : loss : 0.1679 = 0.0746 + 0.0896 + 0.0037, time: 7.642487]
2023-05-18 19:30:28.222: epoch 59:	0.02468304  	0.18117686  	0.09724113  
2023-05-18 19:30:28.223: Find a better model.
2023-05-18 19:30:35.882: [iter 60 : loss : 0.1663 = 0.0731 + 0.0895 + 0.0037, time: 7.657545]
2023-05-18 19:30:36.035: epoch 60:	0.02477478  	0.18205696  	0.09778965  
2023-05-18 19:30:36.035: Find a better model.
2023-05-18 19:30:43.885: [iter 61 : loss : 0.1647 = 0.0717 + 0.0893 + 0.0038, time: 7.848214]
2023-05-18 19:30:44.055: epoch 61:	0.02484535  	0.18273734  	0.09807452  
2023-05-18 19:30:44.056: Find a better model.
2023-05-18 19:30:51.849: [iter 62 : loss : 0.1630 = 0.0701 + 0.0891 + 0.0038, time: 7.791590]
2023-05-18 19:30:52.004: epoch 62:	0.02471127  	0.18190385  	0.09777449  
2023-05-18 19:30:59.628: [iter 63 : loss : 0.1619 = 0.0691 + 0.0889 + 0.0039, time: 7.623209]
2023-05-18 19:30:59.779: epoch 63:	0.02479595  	0.18224420  	0.09811363  
2023-05-18 19:31:07.445: [iter 64 : loss : 0.1606 = 0.0679 + 0.0888 + 0.0039, time: 7.663083]
2023-05-18 19:31:07.594: epoch 64:	0.02489474  	0.18279234  	0.09851211  
2023-05-18 19:31:07.594: Find a better model.
2023-05-18 19:31:15.254: [iter 65 : loss : 0.1598 = 0.0672 + 0.0886 + 0.0040, time: 7.658559]
2023-05-18 19:31:15.406: epoch 65:	0.02495825  	0.18345048  	0.09898295  
2023-05-18 19:31:15.406: Find a better model.
2023-05-18 19:31:23.255: [iter 66 : loss : 0.1579 = 0.0653 + 0.0885 + 0.0040, time: 7.848612]
2023-05-18 19:31:23.405: epoch 66:	0.02490885  	0.18299091  	0.09902999  
2023-05-18 19:31:30.976: [iter 67 : loss : 0.1564 = 0.0640 + 0.0884 + 0.0040, time: 7.570112]
2023-05-18 19:31:31.158: epoch 67:	0.02498647  	0.18387008  	0.09938078  
2023-05-18 19:31:31.158: Find a better model.
2023-05-18 19:31:38.788: [iter 68 : loss : 0.1560 = 0.0637 + 0.0882 + 0.0041, time: 7.628704]
2023-05-18 19:31:38.940: epoch 68:	0.02509232  	0.18439259  	0.09993265  
2023-05-18 19:31:38.940: Find a better model.
2023-05-18 19:31:46.861: [iter 69 : loss : 0.1541 = 0.0619 + 0.0881 + 0.0041, time: 7.920654]
2023-05-18 19:31:47.048: epoch 69:	0.02509231  	0.18459772  	0.10007218  
2023-05-18 19:31:47.048: Find a better model.
2023-05-18 19:31:54.843: [iter 70 : loss : 0.1524 = 0.0603 + 0.0880 + 0.0042, time: 7.792028]
2023-05-18 19:31:54.991: epoch 70:	0.02522638  	0.18536925  	0.10046126  
2023-05-18 19:31:54.992: Find a better model.
2023-05-18 19:32:03.104: [iter 71 : loss : 0.1512 = 0.0591 + 0.0878 + 0.0042, time: 8.109926]
2023-05-18 19:32:03.263: epoch 71:	0.02521933  	0.18527274  	0.10066840  
2023-05-18 19:32:11.186: [iter 72 : loss : 0.1512 = 0.0592 + 0.0877 + 0.0042, time: 7.921798]
2023-05-18 19:32:11.642: epoch 72:	0.02531812  	0.18574192  	0.10081361  
2023-05-18 19:32:11.642: Find a better model.
2023-05-18 19:32:19.851: [iter 73 : loss : 0.1497 = 0.0578 + 0.0876 + 0.0043, time: 8.207652]
2023-05-18 19:32:20.017: epoch 73:	0.02535339  	0.18559818  	0.10081364  
2023-05-18 19:32:28.250: [iter 74 : loss : 0.1483 = 0.0565 + 0.0875 + 0.0043, time: 8.230798]
2023-05-18 19:32:28.418: epoch 74:	0.02548041  	0.18634620  	0.10119680  
2023-05-18 19:32:28.419: Find a better model.
2023-05-18 19:32:36.722: [iter 75 : loss : 0.1477 = 0.0559 + 0.0874 + 0.0044, time: 8.301564]
2023-05-18 19:32:36.925: epoch 75:	0.02540279  	0.18609191  	0.10120959  
2023-05-18 19:32:45.604: [iter 76 : loss : 0.1468 = 0.0551 + 0.0872 + 0.0044, time: 8.678163]
2023-05-18 19:32:45.755: epoch 76:	0.02539574  	0.18605316  	0.10137311  
2023-05-18 19:32:54.665: [iter 77 : loss : 0.1457 = 0.0542 + 0.0871 + 0.0045, time: 8.902873]
2023-05-18 19:32:54.938: epoch 77:	0.02542397  	0.18640910  	0.10166459  
2023-05-18 19:32:54.938: Find a better model.
2023-05-18 19:33:03.024: [iter 78 : loss : 0.1446 = 0.0531 + 0.0870 + 0.0045, time: 8.082436]
2023-05-18 19:33:03.186: epoch 78:	0.02551570  	0.18686882  	0.10182057  
2023-05-18 19:33:03.186: Find a better model.
2023-05-18 19:33:11.428: [iter 79 : loss : 0.1436 = 0.0521 + 0.0869 + 0.0045, time: 8.241015]
2023-05-18 19:33:11.593: epoch 79:	0.02560743  	0.18764779  	0.10216902  
2023-05-18 19:33:11.593: Find a better model.
2023-05-18 19:33:19.630: [iter 80 : loss : 0.1428 = 0.0514 + 0.0868 + 0.0046, time: 8.035047]
2023-05-18 19:33:19.782: epoch 80:	0.02562154  	0.18779580  	0.10236707  
2023-05-18 19:33:19.782: Find a better model.
2023-05-18 19:33:28.148: [iter 81 : loss : 0.1424 = 0.0511 + 0.0867 + 0.0046, time: 8.365023]
2023-05-18 19:33:28.339: epoch 81:	0.02568505  	0.18835296  	0.10261781  
2023-05-18 19:33:28.339: Find a better model.
2023-05-18 19:33:37.130: [iter 82 : loss : 0.1413 = 0.0500 + 0.0866 + 0.0047, time: 8.786020]
2023-05-18 19:33:37.401: epoch 82:	0.02570622  	0.18847263  	0.10275107  
2023-05-18 19:33:37.401: Find a better model.
2023-05-18 19:33:45.590: [iter 83 : loss : 0.1401 = 0.0489 + 0.0864 + 0.0047, time: 8.187979]
2023-05-18 19:33:45.755: epoch 83:	0.02571328  	0.18863472  	0.10300310  
2023-05-18 19:33:45.755: Find a better model.
2023-05-18 19:33:54.265: [iter 84 : loss : 0.1400 = 0.0489 + 0.0864 + 0.0047, time: 8.508006]
2023-05-18 19:33:54.428: epoch 84:	0.02574856  	0.18895672  	0.10311687  
2023-05-18 19:33:54.428: Find a better model.
2023-05-18 19:34:01.988: [iter 85 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 7.559205]
2023-05-18 19:34:02.150: epoch 85:	0.02575562  	0.18866925  	0.10319968  
2023-05-18 19:34:10.015: [iter 86 : loss : 0.1389 = 0.0480 + 0.0861 + 0.0048, time: 7.863036]
2023-05-18 19:34:10.256: epoch 86:	0.02576267  	0.18886544  	0.10343985  
2023-05-18 19:34:19.293: [iter 87 : loss : 0.1362 = 0.0452 + 0.0861 + 0.0048, time: 9.027484]
2023-05-18 19:34:19.559: epoch 87:	0.02583324  	0.18936957  	0.10367578  
2023-05-18 19:34:19.559: Find a better model.
2023-05-18 19:34:27.741: [iter 88 : loss : 0.1357 = 0.0448 + 0.0860 + 0.0049, time: 8.180004]
2023-05-18 19:34:27.907: epoch 88:	0.02588263  	0.18968207  	0.10377461  
2023-05-18 19:34:27.907: Find a better model.
2023-05-18 19:34:36.081: [iter 89 : loss : 0.1354 = 0.0446 + 0.0859 + 0.0049, time: 8.171993]
2023-05-18 19:34:36.247: epoch 89:	0.02597437  	0.19052997  	0.10414303  
2023-05-18 19:34:36.248: Find a better model.
2023-05-18 19:34:43.843: [iter 90 : loss : 0.1360 = 0.0452 + 0.0858 + 0.0050, time: 7.594005]
2023-05-18 19:34:44.012: epoch 90:	0.02605904  	0.19113824  	0.10443571  
2023-05-18 19:34:44.012: Find a better model.
2023-05-18 19:34:52.007: [iter 91 : loss : 0.1346 = 0.0439 + 0.0857 + 0.0050, time: 7.991001]
2023-05-18 19:34:52.169: epoch 91:	0.02595320  	0.19003309  	0.10432277  
2023-05-18 19:35:00.446: [iter 92 : loss : 0.1335 = 0.0429 + 0.0856 + 0.0050, time: 8.265238]
2023-05-18 19:35:00.729: epoch 92:	0.02600965  	0.19055068  	0.10443345  
2023-05-18 19:35:08.754: [iter 93 : loss : 0.1340 = 0.0434 + 0.0856 + 0.0051, time: 8.023992]
2023-05-18 19:35:08.950: epoch 93:	0.02602377  	0.19105063  	0.10457972  
2023-05-18 19:35:17.148: [iter 94 : loss : 0.1317 = 0.0411 + 0.0855 + 0.0051, time: 8.196250]
2023-05-18 19:35:17.301: epoch 94:	0.02603082  	0.19103371  	0.10471619  
2023-05-18 19:35:26.124: [iter 95 : loss : 0.1312 = 0.0406 + 0.0854 + 0.0051, time: 8.818992]
2023-05-18 19:35:26.403: epoch 95:	0.02599554  	0.19053696  	0.10488316  
2023-05-18 19:35:34.616: [iter 96 : loss : 0.1313 = 0.0407 + 0.0853 + 0.0052, time: 8.211301]
2023-05-18 19:35:34.780: epoch 96:	0.02612961  	0.19156152  	0.10511110  
2023-05-18 19:35:34.780: Find a better model.
2023-05-18 19:35:43.209: [iter 97 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0052, time: 8.428300]
2023-05-18 19:35:43.362: epoch 97:	0.02613667  	0.19169138  	0.10527549  
2023-05-18 19:35:43.362: Find a better model.
2023-05-18 19:35:51.134: [iter 98 : loss : 0.1306 = 0.0402 + 0.0852 + 0.0052, time: 7.770057]
2023-05-18 19:35:51.445: epoch 98:	0.02620017  	0.19225982  	0.10549508  
2023-05-18 19:35:51.445: Find a better model.
2023-05-18 19:35:59.782: [iter 99 : loss : 0.1292 = 0.0388 + 0.0851 + 0.0053, time: 8.336032]
2023-05-18 19:35:59.967: epoch 99:	0.02624957  	0.19298775  	0.10572426  
2023-05-18 19:35:59.968: Find a better model.
2023-05-18 19:36:08.983: [iter 100 : loss : 0.1287 = 0.0383 + 0.0851 + 0.0053, time: 9.012223]
2023-05-18 19:36:09.265: epoch 100:	0.02621428  	0.19266112  	0.10571436  
2023-05-18 19:36:17.328: [iter 101 : loss : 0.1284 = 0.0381 + 0.0850 + 0.0054, time: 8.061714]
2023-05-18 19:36:17.493: epoch 101:	0.02637658  	0.19379544  	0.10612971  
2023-05-18 19:36:17.493: Find a better model.
2023-05-18 19:36:25.960: [iter 102 : loss : 0.1272 = 0.0369 + 0.0849 + 0.0054, time: 8.466014]
2023-05-18 19:36:26.167: epoch 102:	0.02644009  	0.19459037  	0.10650259  
2023-05-18 19:36:26.167: Find a better model.
2023-05-18 19:36:33.717: [iter 103 : loss : 0.1270 = 0.0368 + 0.0848 + 0.0054, time: 7.549009]
2023-05-18 19:36:33.876: epoch 103:	0.02643304  	0.19417945  	0.10651059  
2023-05-18 19:36:42.021: [iter 104 : loss : 0.1273 = 0.0372 + 0.0847 + 0.0055, time: 8.143013]
2023-05-18 19:36:42.323: epoch 104:	0.02653183  	0.19496807  	0.10678203  
2023-05-18 19:36:42.323: Find a better model.
2023-05-18 19:36:51.421: [iter 105 : loss : 0.1267 = 0.0366 + 0.0847 + 0.0055, time: 9.094033]
2023-05-18 19:36:51.712: epoch 105:	0.02656711  	0.19500090  	0.10683692  
2023-05-18 19:36:51.712: Find a better model.
2023-05-18 19:36:59.885: [iter 106 : loss : 0.1261 = 0.0359 + 0.0846 + 0.0055, time: 8.171652]
2023-05-18 19:37:00.058: epoch 106:	0.02654595  	0.19488621  	0.10674447  
2023-05-18 19:37:08.598: [iter 107 : loss : 0.1252 = 0.0351 + 0.0845 + 0.0056, time: 8.538057]
2023-05-18 19:37:08.752: epoch 107:	0.02654595  	0.19475414  	0.10662577  
2023-05-18 19:37:16.316: [iter 108 : loss : 0.1253 = 0.0352 + 0.0845 + 0.0056, time: 7.562062]
2023-05-18 19:37:16.479: epoch 108:	0.02654595  	0.19476160  	0.10674278  
2023-05-18 19:37:24.555: [iter 109 : loss : 0.1236 = 0.0335 + 0.0844 + 0.0056, time: 8.075053]
2023-05-18 19:37:24.709: epoch 109:	0.02656006  	0.19498733  	0.10694313  
2023-05-18 19:37:33.950: [iter 110 : loss : 0.1233 = 0.0333 + 0.0844 + 0.0057, time: 9.238014]
2023-05-18 19:37:34.218: epoch 110:	0.02660946  	0.19505796  	0.10690576  
2023-05-18 19:37:34.218: Find a better model.
2023-05-18 19:37:42.340: [iter 111 : loss : 0.1231 = 0.0331 + 0.0843 + 0.0057, time: 8.120001]
2023-05-18 19:37:42.502: epoch 111:	0.02661651  	0.19490327  	0.10691189  
2023-05-18 19:37:50.734: [iter 112 : loss : 0.1230 = 0.0330 + 0.0842 + 0.0057, time: 8.228477]
2023-05-18 19:37:50.893: epoch 112:	0.02660240  	0.19460572  	0.10661063  
2023-05-18 19:37:59.285: [iter 113 : loss : 0.1229 = 0.0330 + 0.0842 + 0.0058, time: 8.389995]
2023-05-18 19:37:59.467: epoch 113:	0.02661651  	0.19461973  	0.10659833  
2023-05-18 19:38:07.590: [iter 114 : loss : 0.1221 = 0.0322 + 0.0841 + 0.0058, time: 8.122061]
2023-05-18 19:38:07.753: epoch 114:	0.02661652  	0.19464439  	0.10689845  
2023-05-18 19:38:16.315: [iter 115 : loss : 0.1217 = 0.0318 + 0.0841 + 0.0058, time: 8.560443]
2023-05-18 19:38:16.594: epoch 115:	0.02660946  	0.19483683  	0.10695696  
2023-05-18 19:38:24.666: [iter 116 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 8.070056]
2023-05-18 19:38:24.844: epoch 116:	0.02661651  	0.19510132  	0.10712041  
2023-05-18 19:38:24.844: Find a better model.
2023-05-18 19:38:33.315: [iter 117 : loss : 0.1209 = 0.0310 + 0.0840 + 0.0059, time: 8.468969]
2023-05-18 19:38:33.468: epoch 117:	0.02657417  	0.19457404  	0.10681781  
2023-05-18 19:38:42.383: [iter 118 : loss : 0.1205 = 0.0307 + 0.0839 + 0.0059, time: 8.913062]
2023-05-18 19:38:42.560: epoch 118:	0.02663063  	0.19530788  	0.10712179  
2023-05-18 19:38:42.560: Find a better model.
2023-05-18 19:38:50.659: [iter 119 : loss : 0.1195 = 0.0297 + 0.0839 + 0.0060, time: 8.097052]
2023-05-18 19:38:50.833: epoch 119:	0.02670825  	0.19588324  	0.10744052  
2023-05-18 19:38:50.834: Find a better model.
2023-05-18 19:38:59.101: [iter 120 : loss : 0.1200 = 0.0302 + 0.0838 + 0.0060, time: 8.265182]
2023-05-18 19:38:59.264: epoch 120:	0.02670825  	0.19590196  	0.10744937  
2023-05-18 19:38:59.264: Find a better model.
2023-05-18 19:39:07.226: [iter 121 : loss : 0.1199 = 0.0301 + 0.0838 + 0.0060, time: 7.961398]
2023-05-18 19:39:07.389: epoch 121:	0.02670825  	0.19607624  	0.10746971  
2023-05-18 19:39:07.389: Find a better model.
2023-05-18 19:39:15.722: [iter 122 : loss : 0.1192 = 0.0294 + 0.0837 + 0.0060, time: 8.331318]
2023-05-18 19:39:15.924: epoch 122:	0.02674353  	0.19639575  	0.10769179  
2023-05-18 19:39:15.924: Find a better model.
2023-05-18 19:39:25.013: [iter 123 : loss : 0.1188 = 0.0290 + 0.0837 + 0.0061, time: 9.085599]
2023-05-18 19:39:25.287: epoch 123:	0.02668002  	0.19575523  	0.10761528  
2023-05-18 19:39:33.300: [iter 124 : loss : 0.1180 = 0.0283 + 0.0836 + 0.0061, time: 8.011056]
2023-05-18 19:39:33.484: epoch 124:	0.02672236  	0.19612618  	0.10768019  
2023-05-18 19:39:41.584: [iter 125 : loss : 0.1175 = 0.0278 + 0.0836 + 0.0061, time: 8.097813]
2023-05-18 19:39:41.804: epoch 125:	0.02666591  	0.19565812  	0.10777837  
2023-05-18 19:39:49.562: [iter 126 : loss : 0.1176 = 0.0279 + 0.0835 + 0.0062, time: 7.756092]
2023-05-18 19:39:49.730: epoch 126:	0.02671531  	0.19605221  	0.10780634  
2023-05-18 19:39:57.753: [iter 127 : loss : 0.1165 = 0.0269 + 0.0835 + 0.0062, time: 8.020624]
2023-05-18 19:39:57.920: epoch 127:	0.02673648  	0.19611514  	0.10798355  
2023-05-18 19:40:07.245: [iter 128 : loss : 0.1177 = 0.0280 + 0.0835 + 0.0062, time: 9.324406]
2023-05-18 19:40:07.520: epoch 128:	0.02667297  	0.19567442  	0.10781975  
2023-05-18 19:40:15.730: [iter 129 : loss : 0.1166 = 0.0270 + 0.0834 + 0.0063, time: 8.208532]
2023-05-18 19:40:15.899: epoch 129:	0.02663768  	0.19547363  	0.10772976  
2023-05-18 19:40:24.266: [iter 130 : loss : 0.1168 = 0.0272 + 0.0833 + 0.0063, time: 8.364584]
2023-05-18 19:40:24.491: epoch 130:	0.02673647  	0.19607042  	0.10799889  
2023-05-18 19:40:33.084: [iter 131 : loss : 0.1162 = 0.0265 + 0.0833 + 0.0063, time: 8.591953]
2023-05-18 19:40:33.253: epoch 131:	0.02672941  	0.19573039  	0.10796446  
2023-05-18 19:40:41.313: [iter 132 : loss : 0.1160 = 0.0264 + 0.0833 + 0.0064, time: 8.057558]
2023-05-18 19:40:41.475: epoch 132:	0.02670824  	0.19556573  	0.10806908  
2023-05-18 19:40:50.129: [iter 133 : loss : 0.1150 = 0.0254 + 0.0832 + 0.0064, time: 8.653075]
2023-05-18 19:40:50.379: epoch 133:	0.02670825  	0.19559136  	0.10806762  
2023-05-18 19:40:58.471: [iter 134 : loss : 0.1158 = 0.0262 + 0.0832 + 0.0064, time: 8.090168]
2023-05-18 19:40:58.639: epoch 134:	0.02667296  	0.19528581  	0.10791960  
2023-05-18 19:41:06.808: [iter 135 : loss : 0.1154 = 0.0258 + 0.0831 + 0.0064, time: 8.168269]
2023-05-18 19:41:06.970: epoch 135:	0.02665179  	0.19547823  	0.10794513  
2023-05-18 19:41:16.040: [iter 136 : loss : 0.1150 = 0.0255 + 0.0831 + 0.0065, time: 9.066679]
2023-05-18 19:41:16.323: epoch 136:	0.02677881  	0.19653592  	0.10833173  
2023-05-18 19:41:16.323: Find a better model.
2023-05-18 19:41:24.517: [iter 137 : loss : 0.1146 = 0.0250 + 0.0831 + 0.0065, time: 8.193564]
2023-05-18 19:41:24.688: epoch 137:	0.02669413  	0.19598907  	0.10822759  
2023-05-18 19:41:33.072: [iter 138 : loss : 0.1143 = 0.0248 + 0.0830 + 0.0065, time: 8.382394]
2023-05-18 19:41:33.254: epoch 138:	0.02670118  	0.19637915  	0.10820108  
2023-05-18 19:41:41.299: [iter 139 : loss : 0.1141 = 0.0246 + 0.0830 + 0.0066, time: 8.043405]
2023-05-18 19:41:41.466: epoch 139:	0.02672235  	0.19616136  	0.10820325  
2023-05-18 19:41:49.867: [iter 140 : loss : 0.1136 = 0.0241 + 0.0829 + 0.0066, time: 8.398899]
2023-05-18 19:41:50.061: epoch 140:	0.02669413  	0.19582818  	0.10818111  
2023-05-18 19:41:59.276: [iter 141 : loss : 0.1141 = 0.0246 + 0.0829 + 0.0066, time: 9.212091]
2023-05-18 19:41:59.568: epoch 141:	0.02674353  	0.19593985  	0.10821908  
2023-05-18 19:42:07.830: [iter 142 : loss : 0.1131 = 0.0236 + 0.0828 + 0.0066, time: 8.259362]
2023-05-18 19:42:07.996: epoch 142:	0.02677175  	0.19630790  	0.10840014  
2023-05-18 19:42:16.608: [iter 143 : loss : 0.1131 = 0.0237 + 0.0828 + 0.0067, time: 8.611182]
2023-05-18 19:42:16.763: epoch 143:	0.02678586  	0.19663848  	0.10862072  
2023-05-18 19:42:16.763: Find a better model.
2023-05-18 19:42:24.789: [iter 144 : loss : 0.1124 = 0.0229 + 0.0828 + 0.0067, time: 8.024045]
2023-05-18 19:42:25.193: epoch 144:	0.02673646  	0.19609195  	0.10838553  
2023-05-18 19:42:33.819: [iter 145 : loss : 0.1125 = 0.0230 + 0.0827 + 0.0067, time: 8.623748]
2023-05-18 19:42:34.027: epoch 145:	0.02677175  	0.19592391  	0.10841211  
2023-05-18 19:42:43.139: [iter 146 : loss : 0.1127 = 0.0232 + 0.0827 + 0.0067, time: 9.105106]
2023-05-18 19:42:43.401: epoch 146:	0.02674352  	0.19554232  	0.10841029  
2023-05-18 19:42:51.582: [iter 147 : loss : 0.1126 = 0.0232 + 0.0827 + 0.0068, time: 8.180146]
2023-05-18 19:42:51.746: epoch 147:	0.02668001  	0.19508708  	0.10837619  
2023-05-18 19:43:00.438: [iter 148 : loss : 0.1112 = 0.0218 + 0.0826 + 0.0068, time: 8.691053]
2023-05-18 19:43:00.590: epoch 148:	0.02676469  	0.19559832  	0.10846705  
2023-05-18 19:43:08.473: [iter 149 : loss : 0.1117 = 0.0223 + 0.0826 + 0.0068, time: 7.882121]
2023-05-18 19:43:08.629: epoch 149:	0.02674352  	0.19568941  	0.10855766  
2023-05-18 19:43:17.439: [iter 150 : loss : 0.1112 = 0.0218 + 0.0826 + 0.0069, time: 8.806418]
2023-05-18 19:43:17.647: epoch 150:	0.02675058  	0.19547179  	0.10852925  
2023-05-18 19:43:26.770: [iter 151 : loss : 0.1113 = 0.0219 + 0.0825 + 0.0069, time: 9.122076]
2023-05-18 19:43:27.050: epoch 151:	0.02670118  	0.19501683  	0.10830778  
2023-05-18 19:43:35.203: [iter 152 : loss : 0.1106 = 0.0211 + 0.0825 + 0.0069, time: 8.151353]
2023-05-18 19:43:35.371: epoch 152:	0.02665884  	0.19450870  	0.10816664  
2023-05-18 19:43:43.838: [iter 153 : loss : 0.1099 = 0.0205 + 0.0825 + 0.0069, time: 8.466081]
2023-05-18 19:43:44.000: epoch 153:	0.02654594  	0.19402002  	0.10800520  
2023-05-18 19:43:52.034: [iter 154 : loss : 0.1102 = 0.0208 + 0.0825 + 0.0070, time: 8.033121]
2023-05-18 19:43:52.189: epoch 154:	0.02657417  	0.19417818  	0.10808903  
2023-05-18 19:44:00.722: [iter 155 : loss : 0.1108 = 0.0214 + 0.0824 + 0.0070, time: 8.532093]
2023-05-18 19:44:00.940: epoch 155:	0.02658829  	0.19432361  	0.10806765  
2023-05-18 19:44:09.973: [iter 156 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 9.028615]
2023-05-18 19:44:10.227: epoch 156:	0.02657417  	0.19424742  	0.10811976  
2023-05-18 19:44:18.393: [iter 157 : loss : 0.1103 = 0.0209 + 0.0824 + 0.0070, time: 8.165324]
2023-05-18 19:44:18.561: epoch 157:	0.02653184  	0.19391787  	0.10789874  
2023-05-18 19:44:26.833: [iter 158 : loss : 0.1093 = 0.0199 + 0.0823 + 0.0071, time: 8.271036]
2023-05-18 19:44:26.987: epoch 158:	0.02658828  	0.19433311  	0.10815066  
2023-05-18 19:44:34.580: [iter 159 : loss : 0.1099 = 0.0205 + 0.0823 + 0.0071, time: 7.592021]
2023-05-18 19:44:34.753: epoch 159:	0.02660239  	0.19430657  	0.10801240  
2023-05-18 19:44:42.819: [iter 160 : loss : 0.1094 = 0.0201 + 0.0823 + 0.0071, time: 8.065047]
2023-05-18 19:44:42.984: epoch 160:	0.02660945  	0.19407588  	0.10794739  
2023-05-18 19:44:52.262: [iter 161 : loss : 0.1087 = 0.0193 + 0.0822 + 0.0071, time: 9.272496]
2023-05-18 19:44:52.532: epoch 161:	0.02658829  	0.19414149  	0.10796441  
2023-05-18 19:45:00.718: [iter 162 : loss : 0.1082 = 0.0188 + 0.0822 + 0.0072, time: 8.184047]
2023-05-18 19:45:00.879: epoch 162:	0.02647538  	0.19369788  	0.10771935  
2023-05-18 19:45:09.084: [iter 163 : loss : 0.1088 = 0.0194 + 0.0822 + 0.0072, time: 8.204024]
2023-05-18 19:45:09.249: epoch 163:	0.02651772  	0.19372801  	0.10761961  
2023-05-18 19:45:16.881: [iter 164 : loss : 0.1087 = 0.0193 + 0.0822 + 0.0072, time: 7.631042]
2023-05-18 19:45:17.067: epoch 164:	0.02648244  	0.19330037  	0.10772342  
2023-05-18 19:45:25.174: [iter 165 : loss : 0.1083 = 0.0189 + 0.0821 + 0.0072, time: 8.105008]
2023-05-18 19:45:25.340: epoch 165:	0.02643304  	0.19312370  	0.10750096  
2023-05-18 19:45:34.816: [iter 166 : loss : 0.1081 = 0.0187 + 0.0821 + 0.0073, time: 9.472019]
2023-05-18 19:45:35.053: epoch 166:	0.02649655  	0.19352941  	0.10745826  
2023-05-18 19:45:43.118: [iter 167 : loss : 0.1083 = 0.0189 + 0.0821 + 0.0073, time: 8.063012]
2023-05-18 19:45:43.281: epoch 167:	0.02647538  	0.19337393  	0.10765921  
2023-05-18 19:45:51.454: [iter 168 : loss : 0.1078 = 0.0184 + 0.0820 + 0.0073, time: 8.172023]
2023-05-18 19:45:51.626: epoch 168:	0.02648949  	0.19358611  	0.10776943  
2023-05-18 19:45:51.626: Early stopping is trigger at epoch: 168
2023-05-18 19:45:51.626: best_result@epoch 143:

2023-05-18 19:45:51.626: 		0.0268      	0.1966      	0.1086      
2023-05-19 10:17:12.339: my pid: 9312
2023-05-19 10:17:12.339: model: model.general_recommender.SGL
2023-05-19 10:17:12.339: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-19 10:17:12.339: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-19 10:17:16.155: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-19 10:17:23.984: [iter 1 : loss : 0.8510 = 0.6930 + 0.1580 + 0.0000, time: 7.828606]
2023-05-19 10:17:24.185: epoch 1:	0.00176405  	0.01179476  	0.00604932  
2023-05-19 10:17:24.185: Find a better model.
2023-05-19 10:17:32.386: [iter 2 : loss : 0.8504 = 0.6928 + 0.1576 + 0.0000, time: 8.198967]
2023-05-19 10:17:32.584: epoch 2:	0.00320349  	0.02207436  	0.01176652  
2023-05-19 10:17:32.584: Find a better model.
2023-05-19 10:17:41.225: [iter 3 : loss : 0.8502 = 0.6926 + 0.1576 + 0.0000, time: 8.640234]
2023-05-19 10:17:41.542: epoch 3:	0.00493929  	0.03508537  	0.01797207  
2023-05-19 10:17:41.542: Find a better model.
2023-05-19 10:17:49.179: [iter 4 : loss : 0.8500 = 0.6923 + 0.1577 + 0.0000, time: 7.635898]
2023-05-19 10:17:49.340: epoch 4:	0.00642107  	0.04446213  	0.02274492  
2023-05-19 10:17:49.341: Find a better model.
2023-05-19 10:17:57.151: [iter 5 : loss : 0.8497 = 0.6919 + 0.1578 + 0.0000, time: 7.808006]
2023-05-19 10:17:57.301: epoch 5:	0.00797340  	0.05666871  	0.02819389  
2023-05-19 10:17:57.301: Find a better model.
2023-05-19 10:18:05.831: [iter 6 : loss : 0.8492 = 0.6912 + 0.1580 + 0.0000, time: 8.526974]
2023-05-19 10:18:06.089: epoch 6:	0.00989270  	0.07044833  	0.03450021  
2023-05-19 10:18:06.089: Find a better model.
2023-05-19 10:18:13.463: [iter 7 : loss : 0.8482 = 0.6900 + 0.1582 + 0.0000, time: 7.373012]
2023-05-19 10:18:13.627: epoch 7:	0.01188970  	0.08504216  	0.04105857  
2023-05-19 10:18:13.627: Find a better model.
2023-05-19 10:18:20.701: [iter 8 : loss : 0.8467 = 0.6882 + 0.1585 + 0.0000, time: 7.071995]
2023-05-19 10:18:21.016: epoch 8:	0.01377376  	0.10048848  	0.04759316  
2023-05-19 10:18:21.016: Find a better model.
2023-05-19 10:18:27.996: [iter 9 : loss : 0.8436 = 0.6846 + 0.1589 + 0.0000, time: 6.979231]
2023-05-19 10:18:28.149: epoch 9:	0.01565077  	0.11315387  	0.05425087  
2023-05-19 10:18:28.149: Find a better model.
2023-05-19 10:18:34.670: [iter 10 : loss : 0.8378 = 0.6781 + 0.1596 + 0.0000, time: 6.518966]
2023-05-19 10:18:34.833: epoch 10:	0.01730195  	0.12483978  	0.06052527  
2023-05-19 10:18:34.833: Find a better model.
2023-05-19 10:18:41.615: [iter 11 : loss : 0.8269 = 0.6660 + 0.1608 + 0.0001, time: 6.781162]
2023-05-19 10:18:41.772: epoch 11:	0.01811344  	0.13138565  	0.06487189  
2023-05-19 10:18:41.772: Find a better model.
2023-05-19 10:18:49.033: [iter 12 : loss : 0.8068 = 0.6437 + 0.1630 + 0.0001, time: 7.259462]
2023-05-19 10:18:49.204: epoch 12:	0.01891788  	0.13804296  	0.06887684  
2023-05-19 10:18:49.204: Find a better model.
2023-05-19 10:18:57.118: [iter 13 : loss : 0.7747 = 0.6079 + 0.1667 + 0.0002, time: 7.908113]
2023-05-19 10:18:57.369: epoch 13:	0.01927777  	0.14013194  	0.07053162  
2023-05-19 10:18:57.370: Find a better model.
2023-05-19 10:19:04.411: [iter 14 : loss : 0.7268 = 0.5549 + 0.1717 + 0.0003, time: 7.040139]
2023-05-19 10:19:04.578: epoch 14:	0.01951064  	0.14271952  	0.07180583  
2023-05-19 10:19:04.578: Find a better model.
2023-05-19 10:19:11.769: [iter 15 : loss : 0.6693 = 0.4916 + 0.1773 + 0.0004, time: 7.190003]
2023-05-19 10:19:11.919: epoch 15:	0.01945418  	0.14325422  	0.07233779  
2023-05-19 10:19:11.920: Find a better model.
2023-05-19 10:19:19.716: [iter 16 : loss : 0.6105 = 0.4279 + 0.1819 + 0.0006, time: 7.794248]
2023-05-19 10:19:19.992: epoch 16:	0.01970822  	0.14494571  	0.07315896  
2023-05-19 10:19:19.992: Find a better model.
2023-05-19 10:19:26.985: [iter 17 : loss : 0.5596 = 0.3736 + 0.1853 + 0.0007, time: 6.990262]
2023-05-19 10:19:27.148: epoch 17:	0.01980701  	0.14559861  	0.07406708  
2023-05-19 10:19:27.148: Find a better model.
2023-05-19 10:19:34.184: [iter 18 : loss : 0.5175 = 0.3293 + 0.1873 + 0.0009, time: 7.034030]
2023-05-19 10:19:34.346: epoch 18:	0.01999048  	0.14723958  	0.07499404  
2023-05-19 10:19:34.346: Find a better model.
2023-05-19 10:19:41.354: [iter 19 : loss : 0.4835 = 0.2940 + 0.1885 + 0.0010, time: 7.006910]
2023-05-19 10:19:41.598: epoch 19:	0.02027274  	0.14933895  	0.07592934  
2023-05-19 10:19:41.598: Find a better model.
2023-05-19 10:19:48.074: [iter 20 : loss : 0.4582 = 0.2681 + 0.1889 + 0.0012, time: 6.474652]
2023-05-19 10:19:48.232: epoch 20:	0.02044915  	0.15031999  	0.07694348  
2023-05-19 10:19:48.232: Find a better model.
2023-05-19 10:19:54.999: [iter 21 : loss : 0.4362 = 0.2461 + 0.1888 + 0.0013, time: 6.765002]
2023-05-19 10:19:55.158: epoch 21:	0.02068202  	0.15216465  	0.07816622  
2023-05-19 10:19:55.158: Find a better model.
2023-05-19 10:20:02.213: [iter 22 : loss : 0.4184 = 0.2284 + 0.1886 + 0.0014, time: 7.053941]
2023-05-19 10:20:02.375: epoch 22:	0.02092900  	0.15367395  	0.07914211  
2023-05-19 10:20:02.375: Find a better model.
2023-05-19 10:20:10.155: [iter 23 : loss : 0.4028 = 0.2131 + 0.1881 + 0.0015, time: 7.776035]
2023-05-19 10:20:10.433: epoch 23:	0.02117598  	0.15569261  	0.08022690  
2023-05-19 10:20:10.433: Find a better model.
2023-05-19 10:20:17.354: [iter 24 : loss : 0.3903 = 0.2012 + 0.1874 + 0.0016, time: 6.918006]
2023-05-19 10:20:17.518: epoch 24:	0.02148648  	0.15782513  	0.08146224  
2023-05-19 10:20:17.518: Find a better model.
2023-05-19 10:20:24.567: [iter 25 : loss : 0.3785 = 0.1899 + 0.1868 + 0.0017, time: 7.048025]
2023-05-19 10:20:24.716: epoch 25:	0.02171933  	0.15934119  	0.08237559  
2023-05-19 10:20:24.717: Find a better model.
2023-05-19 10:20:32.447: [iter 26 : loss : 0.3697 = 0.1817 + 0.1861 + 0.0018, time: 7.726713]
2023-05-19 10:20:32.740: epoch 26:	0.02198042  	0.16090873  	0.08320960  
2023-05-19 10:20:32.740: Find a better model.
2023-05-19 10:20:39.617: [iter 27 : loss : 0.3589 = 0.1717 + 0.1854 + 0.0019, time: 6.876294]
2023-05-19 10:20:39.770: epoch 27:	0.02221329  	0.16281964  	0.08422250  
2023-05-19 10:20:39.770: Find a better model.
2023-05-19 10:20:46.355: [iter 28 : loss : 0.3508 = 0.1640 + 0.1847 + 0.0020, time: 6.584168]
2023-05-19 10:20:46.515: epoch 28:	0.02247437  	0.16463128  	0.08530287  
2023-05-19 10:20:46.515: Find a better model.
2023-05-19 10:20:53.546: [iter 29 : loss : 0.3433 = 0.1573 + 0.1839 + 0.0021, time: 7.029014]
2023-05-19 10:20:53.696: epoch 29:	0.02268607  	0.16645995  	0.08633395  
2023-05-19 10:20:53.696: Find a better model.
2023-05-19 10:21:00.349: [iter 30 : loss : 0.3346 = 0.1492 + 0.1833 + 0.0022, time: 6.650982]
2023-05-19 10:21:00.510: epoch 30:	0.02283426  	0.16800134  	0.08715595  
2023-05-19 10:21:00.510: Find a better model.
2023-05-19 10:21:07.531: [iter 31 : loss : 0.3287 = 0.1438 + 0.1826 + 0.0023, time: 7.019028]
2023-05-19 10:21:07.689: epoch 31:	0.02300362  	0.16950873  	0.08813282  
2023-05-19 10:21:07.689: Find a better model.
2023-05-19 10:21:14.977: [iter 32 : loss : 0.3216 = 0.1373 + 0.1819 + 0.0024, time: 7.286003]
2023-05-19 10:21:15.139: epoch 32:	0.02317298  	0.17048918  	0.08885626  
2023-05-19 10:21:15.139: Find a better model.
2023-05-19 10:21:22.896: [iter 33 : loss : 0.3170 = 0.1333 + 0.1812 + 0.0024, time: 7.755023]
2023-05-19 10:21:23.184: epoch 33:	0.02333528  	0.17149192  	0.08950557  
2023-05-19 10:21:23.184: Find a better model.
2023-05-19 10:21:30.131: [iter 34 : loss : 0.3111 = 0.1280 + 0.1806 + 0.0025, time: 6.944014]
2023-05-19 10:21:30.301: epoch 34:	0.02346229  	0.17238237  	0.09024969  
2023-05-19 10:21:30.301: Find a better model.
2023-05-19 10:21:37.553: [iter 35 : loss : 0.3066 = 0.1239 + 0.1801 + 0.0026, time: 7.251009]
2023-05-19 10:21:37.706: epoch 35:	0.02359637  	0.17345913  	0.09114583  
2023-05-19 10:21:37.706: Find a better model.
2023-05-19 10:21:45.496: [iter 36 : loss : 0.3019 = 0.1197 + 0.1796 + 0.0027, time: 7.782952]
2023-05-19 10:21:45.779: epoch 36:	0.02369515  	0.17394777  	0.09174003  
2023-05-19 10:21:45.779: Find a better model.
2023-05-19 10:21:52.664: [iter 37 : loss : 0.2970 = 0.1153 + 0.1790 + 0.0027, time: 6.882053]
2023-05-19 10:21:52.870: epoch 37:	0.02378688  	0.17463766  	0.09238586  
2023-05-19 10:21:52.870: Find a better model.
2023-05-19 10:21:59.704: [iter 38 : loss : 0.2941 = 0.1129 + 0.1784 + 0.0028, time: 6.832994]
2023-05-19 10:21:59.865: epoch 38:	0.02391390  	0.17548788  	0.09282796  
2023-05-19 10:21:59.865: Find a better model.
2023-05-19 10:22:07.106: [iter 39 : loss : 0.2890 = 0.1082 + 0.1779 + 0.0029, time: 7.239003]
2023-05-19 10:22:07.279: epoch 39:	0.02407619  	0.17673062  	0.09359036  
2023-05-19 10:22:07.279: Find a better model.
2023-05-19 10:22:13.848: [iter 40 : loss : 0.2850 = 0.1047 + 0.1774 + 0.0029, time: 6.566016]
2023-05-19 10:22:14.008: epoch 40:	0.02418204  	0.17747331  	0.09411353  
2023-05-19 10:22:14.008: Find a better model.
2023-05-19 10:22:20.933: [iter 41 : loss : 0.2822 = 0.1023 + 0.1769 + 0.0030, time: 6.923002]
2023-05-19 10:22:21.099: epoch 41:	0.02428789  	0.17815751  	0.09479290  
2023-05-19 10:22:21.099: Find a better model.
2023-05-19 10:22:28.544: [iter 42 : loss : 0.2788 = 0.0993 + 0.1764 + 0.0031, time: 7.443031]
2023-05-19 10:22:28.715: epoch 42:	0.02437963  	0.17911921  	0.09551568  
2023-05-19 10:22:28.715: Find a better model.
2023-05-19 10:22:36.519: [iter 43 : loss : 0.2748 = 0.0957 + 0.1760 + 0.0031, time: 7.801002]
2023-05-19 10:22:36.773: epoch 43:	0.02452076  	0.18036704  	0.09627411  
2023-05-19 10:22:36.773: Find a better model.
2023-05-19 10:22:43.893: [iter 44 : loss : 0.2711 = 0.0924 + 0.1755 + 0.0032, time: 7.119005]
2023-05-19 10:22:44.042: epoch 44:	0.02474657  	0.18179232  	0.09720115  
2023-05-19 10:22:44.042: Find a better model.
2023-05-19 10:22:51.302: [iter 45 : loss : 0.2681 = 0.0897 + 0.1751 + 0.0033, time: 7.258051]
2023-05-19 10:22:51.450: epoch 45:	0.02490180  	0.18307258  	0.09798797  
2023-05-19 10:22:51.451: Find a better model.
2023-05-19 10:22:59.315: [iter 46 : loss : 0.2656 = 0.0876 + 0.1748 + 0.0033, time: 7.859039]
2023-05-19 10:22:59.578: epoch 46:	0.02497942  	0.18370306  	0.09843673  
2023-05-19 10:22:59.579: Find a better model.
2023-05-19 10:23:06.510: [iter 47 : loss : 0.2640 = 0.0863 + 0.1743 + 0.0034, time: 6.930013]
2023-05-19 10:23:06.683: epoch 47:	0.02507821  	0.18459666  	0.09892616  
2023-05-19 10:23:06.683: Find a better model.
2023-05-19 10:23:13.834: [iter 48 : loss : 0.2602 = 0.0827 + 0.1740 + 0.0035, time: 7.146023]
2023-05-19 10:23:14.184: epoch 48:	0.02517700  	0.18525960  	0.09921177  
2023-05-19 10:23:14.184: Find a better model.
2023-05-19 10:23:22.005: [iter 49 : loss : 0.2572 = 0.0800 + 0.1737 + 0.0035, time: 7.819109]
2023-05-19 10:23:22.287: epoch 49:	0.02523345  	0.18568163  	0.09950093  
2023-05-19 10:23:22.288: Find a better model.
2023-05-19 10:23:29.133: [iter 50 : loss : 0.2553 = 0.0785 + 0.1733 + 0.0036, time: 6.843003]
2023-05-19 10:23:29.412: epoch 50:	0.02525461  	0.18604861  	0.09988730  
2023-05-19 10:23:29.412: Find a better model.
2023-05-19 10:23:36.089: [iter 51 : loss : 0.2521 = 0.0755 + 0.1729 + 0.0036, time: 6.675005]
2023-05-19 10:23:36.246: epoch 51:	0.02531106  	0.18662047  	0.10027806  
2023-05-19 10:23:36.246: Find a better model.
2023-05-19 10:23:43.297: [iter 52 : loss : 0.2518 = 0.0754 + 0.1727 + 0.0037, time: 7.050539]
2023-05-19 10:23:43.467: epoch 52:	0.02533222  	0.18691403  	0.10068255  
2023-05-19 10:23:43.467: Find a better model.
2023-05-19 10:23:50.619: [iter 53 : loss : 0.2494 = 0.0733 + 0.1723 + 0.0037, time: 7.149012]
2023-05-19 10:23:50.782: epoch 53:	0.02539573  	0.18788254  	0.10128940  
2023-05-19 10:23:50.782: Find a better model.
2023-05-19 10:23:57.691: [iter 54 : loss : 0.2474 = 0.0715 + 0.1720 + 0.0038, time: 6.908007]
2023-05-19 10:23:57.853: epoch 54:	0.02539573  	0.18765868  	0.10124909  
2023-05-19 10:24:04.920: [iter 55 : loss : 0.2454 = 0.0697 + 0.1718 + 0.0039, time: 7.065009]
2023-05-19 10:24:05.099: epoch 55:	0.02546630  	0.18834019  	0.10182628  
2023-05-19 10:24:05.100: Find a better model.
2023-05-19 10:24:12.804: [iter 56 : loss : 0.2433 = 0.0679 + 0.1715 + 0.0039, time: 7.699033]
2023-05-19 10:24:13.067: epoch 56:	0.02555803  	0.18937743  	0.10233867  
2023-05-19 10:24:13.067: Find a better model.
2023-05-19 10:24:20.021: [iter 57 : loss : 0.2412 = 0.0661 + 0.1712 + 0.0040, time: 6.953696]
2023-05-19 10:24:20.197: epoch 57:	0.02568504  	0.19022304  	0.10288965  
2023-05-19 10:24:20.197: Find a better model.
2023-05-19 10:24:27.248: [iter 58 : loss : 0.2395 = 0.0645 + 0.1710 + 0.0040, time: 7.050028]
2023-05-19 10:24:27.458: epoch 58:	0.02567799  	0.19016293  	0.10301042  
2023-05-19 10:24:35.135: [iter 59 : loss : 0.2381 = 0.0634 + 0.1707 + 0.0041, time: 7.668013]
2023-05-19 10:24:35.426: epoch 59:	0.02579795  	0.19099869  	0.10329379  
2023-05-19 10:24:35.426: Find a better model.
2023-05-19 10:24:42.103: [iter 60 : loss : 0.2366 = 0.0621 + 0.1704 + 0.0041, time: 6.675015]
2023-05-19 10:24:42.276: epoch 60:	0.02588969  	0.19171831  	0.10367692  
2023-05-19 10:24:42.277: Find a better model.
2023-05-19 10:24:48.870: [iter 61 : loss : 0.2352 = 0.0608 + 0.1702 + 0.0042, time: 6.590658]
2023-05-19 10:24:49.032: epoch 61:	0.02588969  	0.19145358  	0.10380612  
2023-05-19 10:24:56.067: [iter 62 : loss : 0.2337 = 0.0595 + 0.1700 + 0.0042, time: 7.033006]
2023-05-19 10:24:56.235: epoch 62:	0.02598847  	0.19215673  	0.10408013  
2023-05-19 10:24:56.235: Find a better model.
2023-05-19 10:25:03.449: [iter 63 : loss : 0.2321 = 0.0581 + 0.1697 + 0.0043, time: 7.211004]
2023-05-19 10:25:03.622: epoch 63:	0.02601670  	0.19214240  	0.10411892  
2023-05-19 10:25:10.637: [iter 64 : loss : 0.2310 = 0.0572 + 0.1695 + 0.0043, time: 7.013481]
2023-05-19 10:25:10.805: epoch 64:	0.02614371  	0.19284835  	0.10462895  
2023-05-19 10:25:10.805: Find a better model.
2023-05-19 10:25:17.898: [iter 65 : loss : 0.2296 = 0.0560 + 0.1692 + 0.0044, time: 7.091994]
2023-05-19 10:25:18.065: epoch 65:	0.02620722  	0.19329366  	0.10507204  
2023-05-19 10:25:18.066: Find a better model.
2023-05-19 10:25:25.717: [iter 66 : loss : 0.2283 = 0.0547 + 0.1691 + 0.0044, time: 7.648015]
2023-05-19 10:25:26.004: epoch 66:	0.02626367  	0.19375406  	0.10541738  
2023-05-19 10:25:26.004: Find a better model.
2023-05-19 10:25:32.879: [iter 67 : loss : 0.2267 = 0.0533 + 0.1689 + 0.0045, time: 6.874006]
2023-05-19 10:25:33.040: epoch 67:	0.02631307  	0.19442399  	0.10586768  
2023-05-19 10:25:33.040: Find a better model.
2023-05-19 10:25:40.255: [iter 68 : loss : 0.2262 = 0.0530 + 0.1686 + 0.0045, time: 7.213012]
2023-05-19 10:25:40.406: epoch 68:	0.02629190  	0.19391510  	0.10596166  
2023-05-19 10:25:48.305: [iter 69 : loss : 0.2244 = 0.0513 + 0.1685 + 0.0046, time: 7.891437]
2023-05-19 10:25:48.594: epoch 69:	0.02624251  	0.19372842  	0.10602728  
2023-05-19 10:25:55.387: [iter 70 : loss : 0.2229 = 0.0499 + 0.1684 + 0.0046, time: 6.788998]
2023-05-19 10:25:55.614: epoch 70:	0.02627073  	0.19358505  	0.10615911  
2023-05-19 10:26:02.448: [iter 71 : loss : 0.2218 = 0.0490 + 0.1682 + 0.0047, time: 6.831994]
2023-05-19 10:26:02.601: epoch 71:	0.02636953  	0.19434485  	0.10649811  
2023-05-19 10:26:09.638: [iter 72 : loss : 0.2213 = 0.0485 + 0.1680 + 0.0047, time: 7.036148]
2023-05-19 10:26:09.805: epoch 72:	0.02641186  	0.19474682  	0.10673829  
2023-05-19 10:26:09.805: Find a better model.
2023-05-19 10:26:16.345: [iter 73 : loss : 0.2198 = 0.0471 + 0.1678 + 0.0048, time: 6.538006]
2023-05-19 10:26:16.510: epoch 73:	0.02651066  	0.19511752  	0.10709538  
2023-05-19 10:26:16.510: Find a better model.
2023-05-19 10:26:23.446: [iter 74 : loss : 0.2188 = 0.0463 + 0.1677 + 0.0048, time: 6.934354]
2023-05-19 10:26:23.613: epoch 74:	0.02665178  	0.19618243  	0.10751235  
2023-05-19 10:26:23.613: Find a better model.
2023-05-19 10:26:30.894: [iter 75 : loss : 0.2181 = 0.0457 + 0.1675 + 0.0049, time: 7.279003]
2023-05-19 10:26:31.043: epoch 75:	0.02672941  	0.19675024  	0.10791682  
2023-05-19 10:26:31.043: Find a better model.
2023-05-19 10:26:38.848: [iter 76 : loss : 0.2169 = 0.0447 + 0.1673 + 0.0049, time: 7.803035]
2023-05-19 10:26:39.141: epoch 76:	0.02683526  	0.19810531  	0.10832231  
2023-05-19 10:26:39.141: Find a better model.
2023-05-19 10:26:46.178: [iter 77 : loss : 0.2161 = 0.0440 + 0.1672 + 0.0050, time: 7.035021]
2023-05-19 10:26:46.350: epoch 77:	0.02680703  	0.19752830  	0.10842115  
2023-05-19 10:26:53.461: [iter 78 : loss : 0.2153 = 0.0432 + 0.1671 + 0.0050, time: 7.109296]
2023-05-19 10:26:53.642: epoch 78:	0.02681408  	0.19744487  	0.10852021  
2023-05-19 10:27:01.571: [iter 79 : loss : 0.2144 = 0.0424 + 0.1669 + 0.0051, time: 7.924368]
2023-05-19 10:27:01.814: epoch 79:	0.02694110  	0.19827333  	0.10888825  
2023-05-19 10:27:01.814: Find a better model.
2023-05-19 10:27:08.731: [iter 80 : loss : 0.2133 = 0.0414 + 0.1668 + 0.0051, time: 6.915106]
2023-05-19 10:27:08.937: epoch 80:	0.02696933  	0.19847627  	0.10891981  
2023-05-19 10:27:08.937: Find a better model.
2023-05-19 10:27:15.615: [iter 81 : loss : 0.2130 = 0.0412 + 0.1667 + 0.0052, time: 6.677027]
2023-05-19 10:27:15.770: epoch 81:	0.02698344  	0.19871144  	0.10914812  
2023-05-19 10:27:15.770: Find a better model.
2023-05-19 10:27:22.819: [iter 82 : loss : 0.2117 = 0.0399 + 0.1665 + 0.0052, time: 7.047026]
2023-05-19 10:27:22.983: epoch 82:	0.02698344  	0.19880760  	0.10923631  
2023-05-19 10:27:22.983: Find a better model.
2023-05-19 10:27:29.583: [iter 83 : loss : 0.2112 = 0.0396 + 0.1664 + 0.0052, time: 6.598003]
2023-05-19 10:27:29.745: epoch 83:	0.02703284  	0.19958173  	0.10951690  
2023-05-19 10:27:29.745: Find a better model.
2023-05-19 10:27:36.796: [iter 84 : loss : 0.2107 = 0.0391 + 0.1663 + 0.0053, time: 7.049316]
2023-05-19 10:27:36.947: epoch 84:	0.02708929  	0.19983926  	0.10966097  
2023-05-19 10:27:36.947: Find a better model.
2023-05-19 10:27:44.082: [iter 85 : loss : 0.2103 = 0.0388 + 0.1662 + 0.0053, time: 7.133003]
2023-05-19 10:27:44.252: epoch 85:	0.02706812  	0.19967604  	0.10975593  
2023-05-19 10:27:52.000: [iter 86 : loss : 0.2096 = 0.0382 + 0.1660 + 0.0054, time: 7.743697]
2023-05-19 10:27:52.283: epoch 86:	0.02710341  	0.19983408  	0.10980561  
2023-05-19 10:27:59.217: [iter 87 : loss : 0.2074 = 0.0361 + 0.1659 + 0.0054, time: 6.932064]
2023-05-19 10:27:59.395: epoch 87:	0.02708224  	0.19954178  	0.10991422  
2023-05-19 10:28:06.407: [iter 88 : loss : 0.2072 = 0.0359 + 0.1659 + 0.0055, time: 7.010003]
2023-05-19 10:28:06.583: epoch 88:	0.02709635  	0.19966133  	0.11002069  
2023-05-19 10:28:14.374: [iter 89 : loss : 0.2065 = 0.0353 + 0.1656 + 0.0055, time: 7.788064]
2023-05-19 10:28:14.650: epoch 89:	0.02703284  	0.19926435  	0.10991112  
2023-05-19 10:28:21.526: [iter 90 : loss : 0.2069 = 0.0357 + 0.1656 + 0.0055, time: 6.874511]
2023-05-19 10:28:21.674: epoch 90:	0.02711751  	0.19975884  	0.11023441  
2023-05-19 10:28:28.378: [iter 91 : loss : 0.2062 = 0.0351 + 0.1655 + 0.0056, time: 6.700993]
2023-05-19 10:28:28.532: epoch 91:	0.02708929  	0.19931985  	0.11014561  
2023-05-19 10:28:35.395: [iter 92 : loss : 0.2052 = 0.0342 + 0.1654 + 0.0056, time: 6.861013]
2023-05-19 10:28:35.556: epoch 92:	0.02708223  	0.19935182  	0.11032379  
2023-05-19 10:28:42.399: [iter 93 : loss : 0.2052 = 0.0343 + 0.1652 + 0.0057, time: 6.842295]
2023-05-19 10:28:42.562: epoch 93:	0.02716690  	0.20010415  	0.11054239  
2023-05-19 10:28:42.562: Find a better model.
2023-05-19 10:28:49.600: [iter 94 : loss : 0.2035 = 0.0326 + 0.1652 + 0.0057, time: 7.036025]
2023-05-19 10:28:49.765: epoch 94:	0.02719513  	0.20020245  	0.11059760  
2023-05-19 10:28:49.765: Find a better model.
2023-05-19 10:28:56.839: [iter 95 : loss : 0.2030 = 0.0321 + 0.1651 + 0.0057, time: 7.073016]
2023-05-19 10:28:56.999: epoch 95:	0.02720219  	0.20015959  	0.11095704  
2023-05-19 10:29:04.834: [iter 96 : loss : 0.2029 = 0.0322 + 0.1650 + 0.0058, time: 7.834465]
2023-05-19 10:29:05.114: epoch 96:	0.02718808  	0.20028792  	0.11086524  
2023-05-19 10:29:05.114: Find a better model.
2023-05-19 10:29:12.125: [iter 97 : loss : 0.2016 = 0.0309 + 0.1649 + 0.0058, time: 7.010010]
2023-05-19 10:29:12.289: epoch 97:	0.02715280  	0.19995977  	0.11074785  
2023-05-19 10:29:19.329: [iter 98 : loss : 0.2020 = 0.0313 + 0.1648 + 0.0059, time: 7.039012]
2023-05-19 10:29:19.496: epoch 98:	0.02725864  	0.20109254  	0.11108990  
2023-05-19 10:29:19.496: Find a better model.
2023-05-19 10:29:27.477: [iter 99 : loss : 0.2012 = 0.0305 + 0.1647 + 0.0059, time: 7.977289]
2023-05-19 10:29:27.740: epoch 99:	0.02717396  	0.20016783  	0.11087064  
2023-05-19 10:29:34.416: [iter 100 : loss : 0.2006 = 0.0301 + 0.1646 + 0.0059, time: 6.674950]
2023-05-19 10:29:34.683: epoch 100:	0.02719514  	0.20065810  	0.11110371  
2023-05-19 10:29:41.371: [iter 101 : loss : 0.2004 = 0.0298 + 0.1646 + 0.0060, time: 6.686529]
2023-05-19 10:29:41.530: epoch 101:	0.02718807  	0.20057753  	0.11122034  
2023-05-19 10:29:48.584: [iter 102 : loss : 0.1997 = 0.0292 + 0.1645 + 0.0060, time: 7.052648]
2023-05-19 10:29:48.748: epoch 102:	0.02716691  	0.20039152  	0.11111965  
2023-05-19 10:29:55.822: [iter 103 : loss : 0.1995 = 0.0290 + 0.1645 + 0.0061, time: 7.073013]
2023-05-19 10:29:55.988: epoch 103:	0.02711045  	0.19973862  	0.11081521  
2023-05-19 10:30:02.936: [iter 104 : loss : 0.1995 = 0.0292 + 0.1643 + 0.0061, time: 6.947019]
2023-05-19 10:30:03.086: epoch 104:	0.02708222  	0.19947757  	0.11078708  
2023-05-19 10:30:10.382: [iter 105 : loss : 0.1992 = 0.0289 + 0.1642 + 0.0061, time: 7.293679]
2023-05-19 10:30:10.564: epoch 105:	0.02711045  	0.19975181  	0.11088091  
2023-05-19 10:30:18.406: [iter 106 : loss : 0.1982 = 0.0278 + 0.1642 + 0.0062, time: 7.834503]
2023-05-19 10:30:18.682: epoch 106:	0.02703283  	0.19938478  	0.11055434  
2023-05-19 10:30:25.714: [iter 107 : loss : 0.1977 = 0.0274 + 0.1641 + 0.0062, time: 7.031096]
2023-05-19 10:30:25.913: epoch 107:	0.02707517  	0.19971094  	0.11065078  
2023-05-19 10:30:32.967: [iter 108 : loss : 0.1975 = 0.0273 + 0.1640 + 0.0062, time: 7.051411]
2023-05-19 10:30:33.231: epoch 108:	0.02703989  	0.19944136  	0.11060277  
2023-05-19 10:30:41.545: [iter 109 : loss : 0.1963 = 0.0260 + 0.1640 + 0.0063, time: 8.304411]
2023-05-19 10:30:41.837: epoch 109:	0.02708928  	0.20006137  	0.11089339  
2023-05-19 10:30:48.583: [iter 110 : loss : 0.1961 = 0.0259 + 0.1639 + 0.0063, time: 6.744457]
2023-05-19 10:30:48.905: epoch 110:	0.02714573  	0.20018937  	0.11091728  
2023-05-19 10:30:55.526: [iter 111 : loss : 0.1959 = 0.0258 + 0.1638 + 0.0064, time: 6.620266]
2023-05-19 10:30:55.682: epoch 111:	0.02708222  	0.19961032  	0.11086038  
2023-05-19 10:31:02.746: [iter 112 : loss : 0.1956 = 0.0254 + 0.1638 + 0.0064, time: 7.063130]
2023-05-19 10:31:02.903: epoch 112:	0.02696932  	0.19894955  	0.11063489  
2023-05-19 10:31:09.667: [iter 113 : loss : 0.1957 = 0.0256 + 0.1637 + 0.0064, time: 6.763022]
2023-05-19 10:31:09.850: epoch 113:	0.02701872  	0.19931094  	0.11085360  
2023-05-19 10:31:16.745: [iter 114 : loss : 0.1947 = 0.0246 + 0.1636 + 0.0065, time: 6.893002]
2023-05-19 10:31:16.899: epoch 114:	0.02706812  	0.19966197  	0.11086048  
2023-05-19 10:31:24.128: [iter 115 : loss : 0.1947 = 0.0246 + 0.1636 + 0.0065, time: 7.227002]
2023-05-19 10:31:24.359: epoch 115:	0.02706811  	0.19960372  	0.11093885  
2023-05-19 10:31:31.950: [iter 116 : loss : 0.1940 = 0.0240 + 0.1635 + 0.0065, time: 7.588026]
2023-05-19 10:31:32.230: epoch 116:	0.02703284  	0.19946745  	0.11093675  
2023-05-19 10:31:39.083: [iter 117 : loss : 0.1940 = 0.0240 + 0.1634 + 0.0066, time: 6.850928]
2023-05-19 10:31:39.258: epoch 117:	0.02709634  	0.19996552  	0.11109809  
2023-05-19 10:31:45.794: [iter 118 : loss : 0.1935 = 0.0235 + 0.1634 + 0.0066, time: 6.533994]
2023-05-19 10:31:46.097: epoch 118:	0.02706812  	0.20011444  	0.11101282  
2023-05-19 10:31:52.914: [iter 119 : loss : 0.1928 = 0.0229 + 0.1633 + 0.0066, time: 6.816024]
2023-05-19 10:31:53.075: epoch 119:	0.02705400  	0.19983351  	0.11099575  
2023-05-19 10:31:59.384: [iter 120 : loss : 0.1933 = 0.0233 + 0.1633 + 0.0067, time: 6.307009]
2023-05-19 10:31:59.545: epoch 120:	0.02702578  	0.19974376  	0.11094755  
2023-05-19 10:32:06.480: [iter 121 : loss : 0.1932 = 0.0233 + 0.1632 + 0.0067, time: 6.933995]
2023-05-19 10:32:06.645: epoch 121:	0.02705400  	0.20006190  	0.11117503  
2023-05-19 10:32:13.576: [iter 122 : loss : 0.1926 = 0.0227 + 0.1631 + 0.0067, time: 6.928191]
2023-05-19 10:32:13.735: epoch 122:	0.02699050  	0.19904460  	0.11105865  
2023-05-19 10:32:21.335: [iter 123 : loss : 0.1923 = 0.0225 + 0.1631 + 0.0068, time: 7.597003]
2023-05-19 10:32:21.597: epoch 123:	0.02698344  	0.19907065  	0.11090800  
2023-05-19 10:32:21.598: Early stopping is trigger at epoch: 123
2023-05-19 10:32:21.598: best_result@epoch 98:

2023-05-19 10:32:21.598: 		0.0273      	0.2011      	0.1111      
2023-05-19 10:33:29.254: my pid: 11044
2023-05-19 10:33:29.254: model: model.general_recommender.SGL
2023-05-19 10:33:29.254: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-19 10:33:29.254: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-19 10:33:33.117: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-19 10:33:41.089: [iter 1 : loss : 0.9300 = 0.6930 + 0.2370 + 0.0000, time: 7.970167]
2023-05-19 10:33:41.258: epoch 1:	0.00163703  	0.01089388  	0.00560195  
2023-05-19 10:33:41.258: Find a better model.
2023-05-19 10:33:49.617: [iter 2 : loss : 0.9292 = 0.6929 + 0.2363 + 0.0000, time: 8.358160]
2023-05-19 10:33:49.821: epoch 2:	0.00279424  	0.01937302  	0.01032744  
2023-05-19 10:33:49.821: Find a better model.
2023-05-19 10:33:57.462: [iter 3 : loss : 0.9290 = 0.6927 + 0.2363 + 0.0000, time: 7.638101]
2023-05-19 10:33:57.657: epoch 3:	0.00419134  	0.02988452  	0.01539842  
2023-05-19 10:33:57.657: Find a better model.
2023-05-19 10:34:05.324: [iter 4 : loss : 0.9289 = 0.6925 + 0.2365 + 0.0000, time: 7.665017]
2023-05-19 10:34:05.492: epoch 4:	0.00531326  	0.03740989  	0.01929577  
2023-05-19 10:34:05.492: Find a better model.
2023-05-19 10:34:13.207: [iter 5 : loss : 0.9287 = 0.6922 + 0.2365 + 0.0000, time: 7.712735]
2023-05-19 10:34:13.371: epoch 5:	0.00640695  	0.04480568  	0.02301541  
2023-05-19 10:34:13.371: Find a better model.
2023-05-19 10:34:21.538: [iter 6 : loss : 0.9285 = 0.6918 + 0.2367 + 0.0000, time: 8.165046]
2023-05-19 10:34:21.716: epoch 6:	0.00743714  	0.05322213  	0.02719178  
2023-05-19 10:34:21.716: Find a better model.
2023-05-19 10:34:29.041: [iter 7 : loss : 0.9281 = 0.6913 + 0.2368 + 0.0000, time: 7.322993]
2023-05-19 10:34:29.203: epoch 7:	0.00853788  	0.06105692  	0.03091928  
2023-05-19 10:34:29.204: Find a better model.
2023-05-19 10:34:36.265: [iter 8 : loss : 0.9277 = 0.6907 + 0.2370 + 0.0000, time: 7.060002]
2023-05-19 10:34:36.493: epoch 8:	0.01014673  	0.07253014  	0.03669222  
2023-05-19 10:34:36.493: Find a better model.
2023-05-19 10:34:44.368: [iter 9 : loss : 0.9269 = 0.6897 + 0.2372 + 0.0000, time: 7.865023]
2023-05-19 10:34:44.630: epoch 9:	0.01139574  	0.08180506  	0.04066188  
2023-05-19 10:34:44.630: Find a better model.
2023-05-19 10:34:51.498: [iter 10 : loss : 0.9257 = 0.6883 + 0.2374 + 0.0000, time: 6.867001]
2023-05-19 10:34:51.672: epoch 10:	0.01304695  	0.09342115  	0.04530917  
2023-05-19 10:34:51.672: Find a better model.
2023-05-19 10:34:58.837: [iter 11 : loss : 0.9239 = 0.6861 + 0.2378 + 0.0000, time: 7.162001]
2023-05-19 10:34:59.160: epoch 11:	0.01426065  	0.10263355  	0.04896106  
2023-05-19 10:34:59.160: Find a better model.
2023-05-19 10:35:07.305: [iter 12 : loss : 0.9207 = 0.6826 + 0.2380 + 0.0000, time: 8.143014]
2023-05-19 10:35:07.593: epoch 12:	0.01549554  	0.11201502  	0.05371837  
2023-05-19 10:35:07.593: Find a better model.
2023-05-19 10:35:14.534: [iter 13 : loss : 0.9159 = 0.6771 + 0.2388 + 0.0001, time: 6.939020]
2023-05-19 10:35:14.688: epoch 13:	0.01654693  	0.12015222  	0.05791119  
2023-05-19 10:35:14.688: Find a better model.
2023-05-19 10:35:21.447: [iter 14 : loss : 0.9075 = 0.6679 + 0.2396 + 0.0001, time: 6.757008]
2023-05-19 10:35:21.604: epoch 14:	0.01761949  	0.12847155  	0.06248693  
2023-05-19 10:35:21.604: Find a better model.
2023-05-19 10:35:28.838: [iter 15 : loss : 0.8945 = 0.6533 + 0.2410 + 0.0001, time: 7.232000]
2023-05-19 10:35:29.000: epoch 15:	0.01866386  	0.13705370  	0.06702749  
2023-05-19 10:35:29.001: Find a better model.
2023-05-19 10:35:35.568: [iter 16 : loss : 0.8741 = 0.6306 + 0.2433 + 0.0002, time: 6.566018]
2023-05-19 10:35:35.732: epoch 16:	0.01935539  	0.14188632  	0.07046772  
2023-05-19 10:35:35.732: Find a better model.
2023-05-19 10:35:42.825: [iter 17 : loss : 0.8445 = 0.5978 + 0.2465 + 0.0002, time: 7.091008]
2023-05-19 10:35:42.977: epoch 17:	0.01963061  	0.14382097  	0.07260191  
2023-05-19 10:35:42.977: Find a better model.
2023-05-19 10:35:50.084: [iter 18 : loss : 0.8050 = 0.5540 + 0.2507 + 0.0003, time: 7.105003]
2023-05-19 10:35:50.246: epoch 18:	0.02018101  	0.14757904  	0.07466890  
2023-05-19 10:35:50.246: Find a better model.
2023-05-19 10:35:57.934: [iter 19 : loss : 0.7565 = 0.5003 + 0.2557 + 0.0004, time: 7.685126]
2023-05-19 10:35:58.221: epoch 19:	0.02037859  	0.14969328  	0.07554869  
2023-05-19 10:35:58.221: Find a better model.
2023-05-19 10:36:05.228: [iter 20 : loss : 0.7068 = 0.4457 + 0.2605 + 0.0006, time: 7.005003]
2023-05-19 10:36:05.398: epoch 20:	0.02056912  	0.15092060  	0.07649498  
2023-05-19 10:36:05.398: Find a better model.
2023-05-19 10:36:12.603: [iter 21 : loss : 0.6587 = 0.3937 + 0.2643 + 0.0007, time: 7.203020]
2023-05-19 10:36:12.758: epoch 21:	0.02070319  	0.15158120  	0.07752303  
2023-05-19 10:36:12.758: Find a better model.
2023-05-19 10:36:20.605: [iter 22 : loss : 0.6170 = 0.3490 + 0.2671 + 0.0009, time: 7.837017]
2023-05-19 10:36:20.888: epoch 22:	0.02088665  	0.15321854  	0.07867408  
2023-05-19 10:36:20.888: Find a better model.
2023-05-19 10:36:27.680: [iter 23 : loss : 0.5817 = 0.3118 + 0.2689 + 0.0010, time: 6.791133]
2023-05-19 10:36:28.031: epoch 23:	0.02123949  	0.15608054  	0.08007985  
2023-05-19 10:36:28.031: Find a better model.
2023-05-19 10:36:34.822: [iter 24 : loss : 0.5536 = 0.2828 + 0.2696 + 0.0012, time: 6.789002]
2023-05-19 10:36:34.978: epoch 24:	0.02154998  	0.15820466  	0.08116373  
2023-05-19 10:36:34.978: Find a better model.
2023-05-19 10:36:42.186: [iter 25 : loss : 0.5292 = 0.2578 + 0.2700 + 0.0013, time: 7.205009]
2023-05-19 10:36:42.350: epoch 25:	0.02178990  	0.15982880  	0.08232564  
2023-05-19 10:36:42.350: Find a better model.
2023-05-19 10:36:49.106: [iter 26 : loss : 0.5097 = 0.2384 + 0.2699 + 0.0014, time: 6.755001]
2023-05-19 10:36:49.267: epoch 26:	0.02212861  	0.16238642  	0.08378100  
2023-05-19 10:36:49.267: Find a better model.
2023-05-19 10:36:56.223: [iter 27 : loss : 0.4912 = 0.2203 + 0.2694 + 0.0016, time: 6.955002]
2023-05-19 10:36:56.393: epoch 27:	0.02236148  	0.16394320  	0.08468507  
2023-05-19 10:36:56.393: Find a better model.
2023-05-19 10:37:03.441: [iter 28 : loss : 0.4763 = 0.2057 + 0.2689 + 0.0017, time: 7.046000]
2023-05-19 10:37:03.614: epoch 28:	0.02263668  	0.16604939  	0.08605874  
2023-05-19 10:37:03.614: Find a better model.
2023-05-19 10:37:11.346: [iter 29 : loss : 0.4633 = 0.1934 + 0.2682 + 0.0018, time: 7.723024]
2023-05-19 10:37:11.602: epoch 29:	0.02284837  	0.16782869  	0.08709697  
2023-05-19 10:37:11.602: Find a better model.
2023-05-19 10:37:18.331: [iter 30 : loss : 0.4501 = 0.1807 + 0.2675 + 0.0019, time: 6.727288]
2023-05-19 10:37:18.498: epoch 30:	0.02298950  	0.16863054  	0.08776388  
2023-05-19 10:37:18.498: Find a better model.
2023-05-19 10:37:24.999: [iter 31 : loss : 0.4399 = 0.1713 + 0.2667 + 0.0020, time: 6.499194]
2023-05-19 10:37:25.150: epoch 31:	0.02307418  	0.16936803  	0.08853924  
2023-05-19 10:37:25.150: Find a better model.
2023-05-19 10:37:31.587: [iter 32 : loss : 0.4296 = 0.1618 + 0.2657 + 0.0021, time: 6.435986]
2023-05-19 10:37:31.737: epoch 32:	0.02334233  	0.17119780  	0.08994380  
2023-05-19 10:37:31.737: Find a better model.
2023-05-19 10:37:38.183: [iter 33 : loss : 0.4219 = 0.1548 + 0.2649 + 0.0022, time: 6.444458]
2023-05-19 10:37:38.331: epoch 33:	0.02344112  	0.17179741  	0.09072383  
2023-05-19 10:37:38.331: Find a better model.
2023-05-19 10:37:44.795: [iter 34 : loss : 0.4134 = 0.1470 + 0.2641 + 0.0023, time: 6.462449]
2023-05-19 10:37:44.950: epoch 34:	0.02369515  	0.17404652  	0.09184353  
2023-05-19 10:37:44.950: Find a better model.
2023-05-19 10:37:51.375: [iter 35 : loss : 0.4066 = 0.1408 + 0.2634 + 0.0024, time: 6.424709]
2023-05-19 10:37:51.522: epoch 35:	0.02379394  	0.17482896  	0.09247194  
2023-05-19 10:37:51.523: Find a better model.
2023-05-19 10:37:57.979: [iter 36 : loss : 0.3998 = 0.1347 + 0.2627 + 0.0025, time: 6.453843]
2023-05-19 10:37:58.145: epoch 36:	0.02394213  	0.17567854  	0.09310702  
2023-05-19 10:37:58.145: Find a better model.
2023-05-19 10:38:04.568: [iter 37 : loss : 0.3930 = 0.1286 + 0.2619 + 0.0026, time: 6.422770]
2023-05-19 10:38:04.722: epoch 37:	0.02407620  	0.17677723  	0.09375376  
2023-05-19 10:38:04.722: Find a better model.
2023-05-19 10:38:11.166: [iter 38 : loss : 0.3884 = 0.1246 + 0.2611 + 0.0027, time: 6.442165]
2023-05-19 10:38:11.315: epoch 38:	0.02429494  	0.17845766  	0.09484398  
2023-05-19 10:38:11.315: Find a better model.
2023-05-19 10:38:17.773: [iter 39 : loss : 0.3818 = 0.1187 + 0.2604 + 0.0027, time: 6.457632]
2023-05-19 10:38:17.924: epoch 39:	0.02446429  	0.17966256  	0.09556881  
2023-05-19 10:38:17.925: Find a better model.
2023-05-19 10:38:24.370: [iter 40 : loss : 0.3766 = 0.1141 + 0.2597 + 0.0028, time: 6.442563]
2023-05-19 10:38:24.516: epoch 40:	0.02463365  	0.18096073  	0.09633493  
2023-05-19 10:38:24.517: Find a better model.
2023-05-19 10:38:30.959: [iter 41 : loss : 0.3726 = 0.1106 + 0.2591 + 0.0029, time: 6.441387]
2023-05-19 10:38:31.107: epoch 41:	0.02468305  	0.18109988  	0.09697432  
2023-05-19 10:38:31.107: Find a better model.
2023-05-19 10:38:37.555: [iter 42 : loss : 0.3679 = 0.1064 + 0.2585 + 0.0030, time: 6.445894]
2023-05-19 10:38:37.701: epoch 42:	0.02490180  	0.18280536  	0.09783555  
2023-05-19 10:38:37.701: Find a better model.
2023-05-19 10:38:44.156: [iter 43 : loss : 0.3631 = 0.1022 + 0.2578 + 0.0031, time: 6.452905]
2023-05-19 10:38:44.306: epoch 43:	0.02495825  	0.18324648  	0.09842988  
2023-05-19 10:38:44.306: Find a better model.
2023-05-19 10:38:50.746: [iter 44 : loss : 0.3585 = 0.0982 + 0.2572 + 0.0031, time: 6.438953]
2023-05-19 10:38:50.899: epoch 44:	0.02509938  	0.18463951  	0.09909619  
2023-05-19 10:38:50.899: Find a better model.
2023-05-19 10:38:57.336: [iter 45 : loss : 0.3547 = 0.0948 + 0.2567 + 0.0032, time: 6.435631]
2023-05-19 10:38:57.483: epoch 45:	0.02522639  	0.18609267  	0.09986965  
2023-05-19 10:38:57.484: Find a better model.
2023-05-19 10:39:03.767: [iter 46 : loss : 0.3514 = 0.0920 + 0.2562 + 0.0033, time: 6.280472]
2023-05-19 10:39:03.930: epoch 46:	0.02524756  	0.18617341  	0.10008511  
2023-05-19 10:39:03.930: Find a better model.
2023-05-19 10:39:10.364: [iter 47 : loss : 0.3490 = 0.0900 + 0.2557 + 0.0033, time: 6.433085]
2023-05-19 10:39:10.530: epoch 47:	0.02526166  	0.18602736  	0.10016768  
2023-05-19 10:39:16.953: [iter 48 : loss : 0.3447 = 0.0861 + 0.2552 + 0.0034, time: 6.420789]
2023-05-19 10:39:17.100: epoch 48:	0.02533223  	0.18686894  	0.10065331  
2023-05-19 10:39:17.100: Find a better model.
2023-05-19 10:39:23.360: [iter 49 : loss : 0.3412 = 0.0829 + 0.2548 + 0.0035, time: 6.258915]
2023-05-19 10:39:23.508: epoch 49:	0.02552981  	0.18818349  	0.10129233  
2023-05-19 10:39:23.508: Find a better model.
2023-05-19 10:39:29.959: [iter 50 : loss : 0.3387 = 0.0809 + 0.2543 + 0.0036, time: 6.448844]
2023-05-19 10:39:30.122: epoch 50:	0.02562860  	0.18914908  	0.10177583  
2023-05-19 10:39:30.122: Find a better model.
2023-05-19 10:39:36.546: [iter 51 : loss : 0.3351 = 0.0776 + 0.2539 + 0.0036, time: 6.422946]
2023-05-19 10:39:36.693: epoch 51:	0.02564271  	0.18956381  	0.10214619  
2023-05-19 10:39:36.694: Find a better model.
2023-05-19 10:39:43.124: [iter 52 : loss : 0.3341 = 0.0769 + 0.2535 + 0.0037, time: 6.429541]
2023-05-19 10:39:43.272: epoch 52:	0.02560743  	0.18930797  	0.10219470  
2023-05-19 10:39:49.562: [iter 53 : loss : 0.3314 = 0.0746 + 0.2531 + 0.0038, time: 6.288579]
2023-05-19 10:39:49.710: epoch 53:	0.02566388  	0.18996426  	0.10253036  
2023-05-19 10:39:49.710: Find a better model.
2023-05-19 10:39:56.146: [iter 54 : loss : 0.3289 = 0.0724 + 0.2527 + 0.0038, time: 6.435022]
2023-05-19 10:39:56.309: epoch 54:	0.02576267  	0.19036588  	0.10301705  
2023-05-19 10:39:56.309: Find a better model.
2023-05-19 10:40:02.729: [iter 55 : loss : 0.3266 = 0.0704 + 0.2524 + 0.0039, time: 6.418083]
2023-05-19 10:40:02.880: epoch 55:	0.02582618  	0.19092916  	0.10357043  
2023-05-19 10:40:02.880: Find a better model.
2023-05-19 10:40:09.151: [iter 56 : loss : 0.3242 = 0.0683 + 0.2520 + 0.0039, time: 6.270240]
2023-05-19 10:40:09.314: epoch 56:	0.02588264  	0.19150226  	0.10405179  
2023-05-19 10:40:09.314: Find a better model.
2023-05-19 10:40:15.746: [iter 57 : loss : 0.3219 = 0.0663 + 0.2516 + 0.0040, time: 6.430780]
2023-05-19 10:40:15.906: epoch 57:	0.02588263  	0.19133775  	0.10424279  
2023-05-19 10:40:22.144: [iter 58 : loss : 0.3199 = 0.0645 + 0.2513 + 0.0041, time: 6.237278]
2023-05-19 10:40:22.306: epoch 58:	0.02596731  	0.19171168  	0.10444193  
2023-05-19 10:40:22.306: Find a better model.
2023-05-19 10:40:28.718: [iter 59 : loss : 0.3183 = 0.0632 + 0.2510 + 0.0041, time: 6.411037]
2023-05-19 10:40:28.869: epoch 59:	0.02604492  	0.19226564  	0.10467677  
2023-05-19 10:40:28.870: Find a better model.
2023-05-19 10:40:35.145: [iter 60 : loss : 0.3165 = 0.0617 + 0.2506 + 0.0042, time: 6.273037]
2023-05-19 10:40:35.299: epoch 60:	0.02609432  	0.19278997  	0.10512213  
2023-05-19 10:40:35.299: Find a better model.
2023-05-19 10:40:41.953: [iter 61 : loss : 0.3149 = 0.0603 + 0.2504 + 0.0043, time: 6.651993]
2023-05-19 10:40:42.104: epoch 61:	0.02616489  	0.19362129  	0.10545614  
2023-05-19 10:40:42.105: Find a better model.
2023-05-19 10:40:48.510: [iter 62 : loss : 0.3131 = 0.0587 + 0.2501 + 0.0043, time: 6.404298]
2023-05-19 10:40:48.659: epoch 62:	0.02629190  	0.19427329  	0.10605872  
2023-05-19 10:40:48.659: Find a better model.
2023-05-19 10:40:54.953: [iter 63 : loss : 0.3114 = 0.0572 + 0.2498 + 0.0044, time: 6.292160]
2023-05-19 10:40:55.113: epoch 63:	0.02644009  	0.19545652  	0.10653429  
2023-05-19 10:40:55.114: Find a better model.
2023-05-19 10:41:01.503: [iter 64 : loss : 0.3101 = 0.0561 + 0.2495 + 0.0044, time: 6.388309]
2023-05-19 10:41:01.652: epoch 64:	0.02652476  	0.19610973  	0.10694102  
2023-05-19 10:41:01.652: Find a better model.
2023-05-19 10:41:07.931: [iter 65 : loss : 0.3085 = 0.0549 + 0.2492 + 0.0045, time: 6.277489]
2023-05-19 10:41:08.090: epoch 65:	0.02662355  	0.19669080  	0.10732159  
2023-05-19 10:41:08.090: Find a better model.
2023-05-19 10:41:14.493: [iter 66 : loss : 0.3071 = 0.0535 + 0.2491 + 0.0045, time: 6.402136]
2023-05-19 10:41:14.642: epoch 66:	0.02665883  	0.19725989  	0.10768347  
2023-05-19 10:41:14.643: Find a better model.
2023-05-19 10:41:20.921: [iter 67 : loss : 0.3055 = 0.0521 + 0.2488 + 0.0046, time: 6.275255]
2023-05-19 10:41:21.071: epoch 67:	0.02663767  	0.19711339  	0.10778936  
2023-05-19 10:41:27.313: [iter 68 : loss : 0.3046 = 0.0514 + 0.2485 + 0.0047, time: 6.239582]
2023-05-19 10:41:27.462: epoch 68:	0.02664473  	0.19684276  	0.10779592  
2023-05-19 10:41:33.884: [iter 69 : loss : 0.3028 = 0.0498 + 0.2483 + 0.0047, time: 6.418849]
2023-05-19 10:41:34.039: epoch 69:	0.02676469  	0.19789901  	0.10827493  
2023-05-19 10:41:34.040: Find a better model.
2023-05-19 10:41:40.312: [iter 70 : loss : 0.3014 = 0.0485 + 0.2482 + 0.0048, time: 6.270092]
2023-05-19 10:41:40.460: epoch 70:	0.02683525  	0.19785015  	0.10836088  
2023-05-19 10:41:46.883: [iter 71 : loss : 0.3002 = 0.0474 + 0.2479 + 0.0048, time: 6.422276]
2023-05-19 10:41:47.037: epoch 71:	0.02685642  	0.19832285  	0.10862160  
2023-05-19 10:41:47.037: Find a better model.
2023-05-19 10:41:53.320: [iter 72 : loss : 0.2995 = 0.0468 + 0.2477 + 0.0049, time: 6.282503]
2023-05-19 10:41:53.469: epoch 72:	0.02691287  	0.19880678  	0.10904019  
2023-05-19 10:41:53.470: Find a better model.
2023-05-19 10:41:59.875: [iter 73 : loss : 0.2978 = 0.0453 + 0.2475 + 0.0049, time: 6.403800]
2023-05-19 10:42:00.026: epoch 73:	0.02697638  	0.19895229  	0.10913792  
2023-05-19 10:42:00.026: Find a better model.
2023-05-19 10:42:06.312: [iter 74 : loss : 0.2969 = 0.0446 + 0.2473 + 0.0050, time: 6.285266]
2023-05-19 10:42:06.459: epoch 74:	0.02699755  	0.19918458  	0.10933822  
2023-05-19 10:42:06.459: Find a better model.
2023-05-19 10:42:12.879: [iter 75 : loss : 0.2960 = 0.0438 + 0.2471 + 0.0050, time: 6.418839]
2023-05-19 10:42:13.026: epoch 75:	0.02703283  	0.19935729  	0.10953812  
2023-05-19 10:42:13.026: Find a better model.
2023-05-19 10:42:19.306: [iter 76 : loss : 0.2948 = 0.0428 + 0.2469 + 0.0051, time: 6.278210]
2023-05-19 10:42:19.473: epoch 76:	0.02711751  	0.20011608  	0.10986903  
2023-05-19 10:42:19.474: Find a better model.
2023-05-19 10:42:25.878: [iter 77 : loss : 0.2939 = 0.0420 + 0.2467 + 0.0051, time: 6.403200]
2023-05-19 10:42:26.049: epoch 77:	0.02711751  	0.20000513  	0.10999395  
2023-05-19 10:42:32.455: [iter 78 : loss : 0.2931 = 0.0412 + 0.2466 + 0.0052, time: 6.402797]
2023-05-19 10:42:32.603: epoch 78:	0.02720219  	0.20080411  	0.11039333  
2023-05-19 10:42:32.603: Find a better model.
2023-05-19 10:42:38.893: [iter 79 : loss : 0.2921 = 0.0404 + 0.2465 + 0.0052, time: 6.288852]
2023-05-19 10:42:39.058: epoch 79:	0.02722336  	0.20099384  	0.11032503  
2023-05-19 10:42:39.058: Find a better model.
2023-05-19 10:42:45.455: [iter 80 : loss : 0.2910 = 0.0394 + 0.2464 + 0.0053, time: 6.396023]
2023-05-19 10:42:45.603: epoch 80:	0.02721630  	0.20065030  	0.11021476  
2023-05-19 10:42:51.886: [iter 81 : loss : 0.2905 = 0.0390 + 0.2462 + 0.0053, time: 6.280493]
2023-05-19 10:42:52.035: epoch 81:	0.02725159  	0.20090033  	0.11033219  
2023-05-19 10:42:58.280: [iter 82 : loss : 0.2892 = 0.0378 + 0.2460 + 0.0054, time: 6.242596]
2023-05-19 10:42:58.429: epoch 82:	0.02726570  	0.20150176  	0.11053563  
2023-05-19 10:42:58.429: Find a better model.
2023-05-19 10:43:04.875: [iter 83 : loss : 0.2888 = 0.0375 + 0.2459 + 0.0054, time: 6.444659]
2023-05-19 10:43:05.023: epoch 83:	0.02720925  	0.20081213  	0.11048717  
2023-05-19 10:43:11.279: [iter 84 : loss : 0.2881 = 0.0369 + 0.2457 + 0.0055, time: 6.254502]
2023-05-19 10:43:11.427: epoch 84:	0.02717396  	0.20063035  	0.11073564  
2023-05-19 10:43:17.849: [iter 85 : loss : 0.2877 = 0.0366 + 0.2456 + 0.0055, time: 6.420642]
2023-05-19 10:43:17.998: epoch 85:	0.02721630  	0.20070316  	0.11078086  
2023-05-19 10:43:24.272: [iter 86 : loss : 0.2869 = 0.0360 + 0.2454 + 0.0056, time: 6.271980]
2023-05-19 10:43:24.420: epoch 86:	0.02729392  	0.20131348  	0.11114559  
2023-05-19 10:43:30.847: [iter 87 : loss : 0.2849 = 0.0341 + 0.2453 + 0.0056, time: 6.425508]
2023-05-19 10:43:30.995: epoch 87:	0.02722335  	0.20090051  	0.11122884  
2023-05-19 10:43:37.275: [iter 88 : loss : 0.2847 = 0.0338 + 0.2452 + 0.0057, time: 6.279227]
2023-05-19 10:43:37.423: epoch 88:	0.02723747  	0.20105995  	0.11117138  
2023-05-19 10:43:43.856: [iter 89 : loss : 0.2839 = 0.0332 + 0.2450 + 0.0057, time: 6.432005]
2023-05-19 10:43:44.024: epoch 89:	0.02736448  	0.20180687  	0.11135040  
2023-05-19 10:43:44.024: Find a better model.
2023-05-19 10:43:50.263: [iter 90 : loss : 0.2841 = 0.0334 + 0.2450 + 0.0057, time: 6.237391]
2023-05-19 10:43:50.414: epoch 90:	0.02733626  	0.20165521  	0.11140301  
2023-05-19 10:43:56.668: [iter 91 : loss : 0.2836 = 0.0329 + 0.2448 + 0.0058, time: 6.251598]
2023-05-19 10:43:56.816: epoch 91:	0.02732214  	0.20147642  	0.11139017  
2023-05-19 10:44:03.057: [iter 92 : loss : 0.2825 = 0.0320 + 0.2447 + 0.0058, time: 6.239583]
2023-05-19 10:44:03.207: epoch 92:	0.02725159  	0.20096706  	0.11122394  
2023-05-19 10:44:09.472: [iter 93 : loss : 0.2823 = 0.0319 + 0.2445 + 0.0059, time: 6.264065]
2023-05-19 10:44:09.618: epoch 93:	0.02718807  	0.20034741  	0.11097014  
2023-05-19 10:44:16.038: [iter 94 : loss : 0.2809 = 0.0304 + 0.2445 + 0.0059, time: 6.418225]
2023-05-19 10:44:16.187: epoch 94:	0.02720924  	0.20059958  	0.11097984  
2023-05-19 10:44:22.451: [iter 95 : loss : 0.2803 = 0.0300 + 0.2444 + 0.0060, time: 6.261284]
2023-05-19 10:44:22.602: epoch 95:	0.02715985  	0.20001973  	0.11104862  
2023-05-19 10:44:28.845: [iter 96 : loss : 0.2802 = 0.0299 + 0.2443 + 0.0060, time: 6.242088]
2023-05-19 10:44:28.992: epoch 96:	0.02718102  	0.19994329  	0.11103292  
2023-05-19 10:44:35.258: [iter 97 : loss : 0.2790 = 0.0287 + 0.2442 + 0.0061, time: 6.263060]
2023-05-19 10:44:35.406: epoch 97:	0.02718807  	0.20011228  	0.11107304  
2023-05-19 10:44:41.832: [iter 98 : loss : 0.2792 = 0.0290 + 0.2441 + 0.0061, time: 6.424166]
2023-05-19 10:44:41.979: epoch 98:	0.02711751  	0.19988520  	0.11097966  
2023-05-19 10:44:48.254: [iter 99 : loss : 0.2785 = 0.0284 + 0.2440 + 0.0061, time: 6.273603]
2023-05-19 10:44:48.402: epoch 99:	0.02716690  	0.20016146  	0.11121553  
2023-05-19 10:44:54.811: [iter 100 : loss : 0.2779 = 0.0279 + 0.2439 + 0.0062, time: 6.408252]
2023-05-19 10:44:54.960: epoch 100:	0.02710339  	0.19947037  	0.11112508  
2023-05-19 10:45:01.244: [iter 101 : loss : 0.2777 = 0.0277 + 0.2438 + 0.0062, time: 6.281415]
2023-05-19 10:45:01.392: epoch 101:	0.02711045  	0.19958919  	0.11135857  
2023-05-19 10:45:07.638: [iter 102 : loss : 0.2771 = 0.0271 + 0.2437 + 0.0063, time: 6.244637]
2023-05-19 10:45:07.786: epoch 102:	0.02708223  	0.19937253  	0.11119134  
2023-05-19 10:45:14.214: [iter 103 : loss : 0.2768 = 0.0268 + 0.2437 + 0.0063, time: 6.427552]
2023-05-19 10:45:14.362: epoch 103:	0.02707517  	0.19909187  	0.11109065  
2023-05-19 10:45:20.635: [iter 104 : loss : 0.2767 = 0.0269 + 0.2435 + 0.0063, time: 6.270584]
2023-05-19 10:45:20.783: epoch 104:	0.02693404  	0.19817631  	0.11083746  
2023-05-19 10:45:27.214: [iter 105 : loss : 0.2764 = 0.0266 + 0.2434 + 0.0064, time: 6.429528]
2023-05-19 10:45:27.361: epoch 105:	0.02701166  	0.19885843  	0.11094078  
2023-05-19 10:45:33.634: [iter 106 : loss : 0.2753 = 0.0256 + 0.2434 + 0.0064, time: 6.271996]
2023-05-19 10:45:33.782: epoch 106:	0.02701872  	0.19884744  	0.11082004  
2023-05-19 10:45:40.028: [iter 107 : loss : 0.2749 = 0.0252 + 0.2433 + 0.0065, time: 6.243690]
2023-05-19 10:45:40.180: epoch 107:	0.02699050  	0.19869308  	0.11087995  
2023-05-19 10:45:46.415: [iter 108 : loss : 0.2748 = 0.0251 + 0.2432 + 0.0065, time: 6.232641]
2023-05-19 10:45:46.563: epoch 108:	0.02698344  	0.19857374  	0.11083360  
2023-05-19 10:45:52.828: [iter 109 : loss : 0.2736 = 0.0239 + 0.2432 + 0.0065, time: 6.263824]
2023-05-19 10:45:52.976: epoch 109:	0.02701166  	0.19850232  	0.11096485  
2023-05-19 10:45:59.223: [iter 110 : loss : 0.2734 = 0.0238 + 0.2431 + 0.0066, time: 6.246609]
2023-05-19 10:45:59.373: epoch 110:	0.02700461  	0.19843419  	0.11080927  
2023-05-19 10:46:05.611: [iter 111 : loss : 0.2733 = 0.0236 + 0.2430 + 0.0066, time: 6.235324]
2023-05-19 10:46:05.759: epoch 111:	0.02701166  	0.19832151  	0.11088239  
2023-05-19 10:46:12.023: [iter 112 : loss : 0.2729 = 0.0233 + 0.2429 + 0.0066, time: 6.260846]
2023-05-19 10:46:12.177: epoch 112:	0.02700461  	0.19798911  	0.11071004  
2023-05-19 10:46:18.403: [iter 113 : loss : 0.2731 = 0.0235 + 0.2429 + 0.0067, time: 6.225359]
2023-05-19 10:46:18.554: epoch 113:	0.02700461  	0.19807242  	0.11072928  
2023-05-19 10:46:24.977: [iter 114 : loss : 0.2720 = 0.0225 + 0.2427 + 0.0067, time: 6.420757]
2023-05-19 10:46:25.133: epoch 114:	0.02700461  	0.19803259  	0.11075721  
2023-05-19 10:46:25.133: Early stopping is trigger at epoch: 114
2023-05-19 10:46:25.134: best_result@epoch 89:

2023-05-19 10:46:25.134: 		0.0274      	0.2018      	0.1114      
2023-05-19 10:49:32.249: my pid: 5224
2023-05-19 10:49:32.249: model: model.general_recommender.SGL
2023-05-19 10:49:32.249: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-19 10:49:32.249: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-19 10:49:35.338: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-19 10:49:42.762: [iter 1 : loss : 1.0090 = 0.6930 + 0.3160 + 0.0000, time: 7.423258]
2023-05-19 10:49:42.911: epoch 1:	0.00160175  	0.01062356  	0.00545124  
2023-05-19 10:49:42.911: Find a better model.
2023-05-19 10:49:50.332: [iter 2 : loss : 1.0080 = 0.6929 + 0.3151 + 0.0000, time: 7.419931]
2023-05-19 10:49:50.528: epoch 2:	0.00263195  	0.01817091  	0.00967005  
2023-05-19 10:49:50.528: Find a better model.
2023-05-19 10:49:57.913: [iter 3 : loss : 1.0078 = 0.6927 + 0.3151 + 0.0000, time: 7.384892]
2023-05-19 10:49:58.084: epoch 3:	0.00388088  	0.02728623  	0.01415621  
2023-05-19 10:49:58.085: Find a better model.
2023-05-19 10:50:05.140: [iter 4 : loss : 1.0078 = 0.6925 + 0.3152 + 0.0000, time: 7.053116]
2023-05-19 10:50:05.302: epoch 4:	0.00491106  	0.03468337  	0.01791905  
2023-05-19 10:50:05.302: Find a better model.
2023-05-19 10:50:12.130: [iter 5 : loss : 1.0076 = 0.6923 + 0.3153 + 0.0000, time: 6.827321]
2023-05-19 10:50:12.280: epoch 5:	0.00562373  	0.03909767  	0.02077439  
2023-05-19 10:50:12.280: Find a better model.
2023-05-19 10:50:19.129: [iter 6 : loss : 1.0075 = 0.6921 + 0.3154 + 0.0000, time: 6.847178]
2023-05-19 10:50:19.279: epoch 6:	0.00637873  	0.04579839  	0.02396832  
2023-05-19 10:50:19.279: Find a better model.
2023-05-19 10:50:25.937: [iter 7 : loss : 1.0072 = 0.6917 + 0.3155 + 0.0000, time: 6.656801]
2023-05-19 10:50:26.099: epoch 7:	0.00739480  	0.05295471  	0.02694052  
2023-05-19 10:50:26.100: Find a better model.
2023-05-19 10:50:32.699: [iter 8 : loss : 1.0070 = 0.6913 + 0.3157 + 0.0000, time: 6.597452]
2023-05-19 10:50:32.853: epoch 8:	0.00853788  	0.06104250  	0.03151040  
2023-05-19 10:50:32.853: Find a better model.
2023-05-19 10:50:39.330: [iter 9 : loss : 1.0066 = 0.6908 + 0.3158 + 0.0000, time: 6.475601]
2023-05-19 10:50:39.491: epoch 9:	0.00936347  	0.06687476  	0.03483722  
2023-05-19 10:50:39.491: Find a better model.
2023-05-19 10:50:46.105: [iter 10 : loss : 1.0060 = 0.6900 + 0.3160 + 0.0000, time: 6.611998]
2023-05-19 10:50:46.252: epoch 10:	0.01079593  	0.07760728  	0.03868939  
2023-05-19 10:50:46.252: Find a better model.
2023-05-19 10:50:52.892: [iter 11 : loss : 1.0054 = 0.6891 + 0.3163 + 0.0000, time: 6.637910]
2023-05-19 10:50:53.039: epoch 11:	0.01155804  	0.08274692  	0.04095947  
2023-05-19 10:50:53.039: Find a better model.
2023-05-19 10:50:59.509: [iter 12 : loss : 1.0042 = 0.6878 + 0.3163 + 0.0000, time: 6.467829]
2023-05-19 10:50:59.659: epoch 12:	0.01277175  	0.09133442  	0.04461279  
2023-05-19 10:50:59.659: Find a better model.
2023-05-19 10:51:06.108: [iter 13 : loss : 1.0028 = 0.6860 + 0.3168 + 0.0000, time: 6.447810]
2023-05-19 10:51:06.254: epoch 13:	0.01373847  	0.09932582  	0.04786384  
2023-05-19 10:51:06.254: Find a better model.
2023-05-19 10:51:12.878: [iter 14 : loss : 1.0004 = 0.6834 + 0.3170 + 0.0000, time: 6.622817]
2023-05-19 10:51:13.028: epoch 14:	0.01472637  	0.10701511  	0.05142676  
2023-05-19 10:51:13.028: Find a better model.
2023-05-19 10:51:19.704: [iter 15 : loss : 0.9971 = 0.6796 + 0.3174 + 0.0000, time: 6.674145]
2023-05-19 10:51:19.849: epoch 15:	0.01570722  	0.11387565  	0.05451258  
2023-05-19 10:51:19.849: Find a better model.
2023-05-19 10:51:26.295: [iter 16 : loss : 0.9919 = 0.6738 + 0.3181 + 0.0001, time: 6.443757]
2023-05-19 10:51:26.444: epoch 16:	0.01659633  	0.12076063  	0.05834392  
2023-05-19 10:51:26.444: Find a better model.
2023-05-19 10:51:33.076: [iter 17 : loss : 0.9842 = 0.6653 + 0.3188 + 0.0001, time: 6.631176]
2023-05-19 10:51:33.221: epoch 17:	0.01775357  	0.12891147  	0.06274827  
2023-05-19 10:51:33.221: Find a better model.
2023-05-19 10:51:39.692: [iter 18 : loss : 0.9728 = 0.6527 + 0.3200 + 0.0001, time: 6.468565]
2023-05-19 10:51:39.843: epoch 18:	0.01857917  	0.13515003  	0.06670865  
2023-05-19 10:51:39.843: Find a better model.
2023-05-19 10:51:46.468: [iter 19 : loss : 0.9558 = 0.6338 + 0.3218 + 0.0002, time: 6.623314]
2023-05-19 10:51:46.632: epoch 19:	0.01940479  	0.14239553  	0.07066190  
2023-05-19 10:51:46.632: Find a better model.
2023-05-19 10:51:53.095: [iter 20 : loss : 0.9329 = 0.6082 + 0.3245 + 0.0002, time: 6.462157]
2023-05-19 10:51:53.245: epoch 20:	0.01977879  	0.14503218  	0.07275771  
2023-05-19 10:51:53.245: Find a better model.
2023-05-19 10:51:59.878: [iter 21 : loss : 0.9018 = 0.5739 + 0.3276 + 0.0003, time: 6.631804]
2023-05-19 10:52:00.032: epoch 21:	0.02033626  	0.14862566  	0.07460366  
2023-05-19 10:52:00.032: Find a better model.
2023-05-19 10:52:06.688: [iter 22 : loss : 0.8640 = 0.5320 + 0.3317 + 0.0004, time: 6.654970]
2023-05-19 10:52:06.839: epoch 22:	0.02070319  	0.15105265  	0.07653595  
2023-05-19 10:52:06.839: Find a better model.
2023-05-19 10:52:13.282: [iter 23 : loss : 0.8214 = 0.4848 + 0.3361 + 0.0005, time: 6.442266]
2023-05-19 10:52:13.429: epoch 23:	0.02107719  	0.15400587  	0.07810313  
2023-05-19 10:52:13.429: Find a better model.
2023-05-19 10:52:20.061: [iter 24 : loss : 0.7779 = 0.4371 + 0.3401 + 0.0006, time: 6.629730]
2023-05-19 10:52:20.229: epoch 24:	0.02135240  	0.15652399  	0.07920890  
2023-05-19 10:52:20.229: Find a better model.
2023-05-19 10:52:26.685: [iter 25 : loss : 0.7357 = 0.3914 + 0.3435 + 0.0008, time: 6.455359]
2023-05-19 10:52:26.853: epoch 25:	0.02135240  	0.15637004  	0.08016051  
2023-05-19 10:52:33.288: [iter 26 : loss : 0.6985 = 0.3515 + 0.3461 + 0.0009, time: 6.433177]
2023-05-19 10:52:33.435: epoch 26:	0.02154998  	0.15835172  	0.08128155  
2023-05-19 10:52:33.435: Find a better model.
2023-05-19 10:52:40.077: [iter 27 : loss : 0.6650 = 0.3162 + 0.3477 + 0.0011, time: 6.640520]
2023-05-19 10:52:40.225: epoch 27:	0.02188164  	0.16065080  	0.08252700  
2023-05-19 10:52:40.225: Find a better model.
2023-05-19 10:52:46.679: [iter 28 : loss : 0.6369 = 0.2869 + 0.3488 + 0.0012, time: 6.452614]
2023-05-19 10:52:46.829: epoch 28:	0.02211450  	0.16242029  	0.08390921  
2023-05-19 10:52:46.829: Find a better model.
2023-05-19 10:52:53.271: [iter 29 : loss : 0.6131 = 0.2627 + 0.3491 + 0.0013, time: 6.439747]
2023-05-19 10:52:53.421: epoch 29:	0.02243910  	0.16506840  	0.08529361  
2023-05-19 10:52:53.421: Find a better model.
2023-05-19 10:52:59.867: [iter 30 : loss : 0.5911 = 0.2405 + 0.3492 + 0.0015, time: 6.445791]
2023-05-19 10:53:00.017: epoch 30:	0.02273547  	0.16678371  	0.08658323  
2023-05-19 10:53:00.017: Find a better model.
2023-05-19 10:53:06.647: [iter 31 : loss : 0.5733 = 0.2229 + 0.3488 + 0.0016, time: 6.627455]
2023-05-19 10:53:06.809: epoch 31:	0.02293305  	0.16896778  	0.08794235  
2023-05-19 10:53:06.809: Find a better model.
2023-05-19 10:53:13.269: [iter 32 : loss : 0.5570 = 0.2072 + 0.3481 + 0.0017, time: 6.458889]
2023-05-19 10:53:13.418: epoch 32:	0.02314474  	0.16995375  	0.08894308  
2023-05-19 10:53:13.418: Find a better model.
2023-05-19 10:53:20.032: [iter 33 : loss : 0.5440 = 0.1947 + 0.3475 + 0.0018, time: 6.613005]
2023-05-19 10:53:20.182: epoch 33:	0.02337055  	0.17143805  	0.09004647  
2023-05-19 10:53:20.182: Find a better model.
2023-05-19 10:53:26.847: [iter 34 : loss : 0.5311 = 0.1824 + 0.3468 + 0.0020, time: 6.662455]
2023-05-19 10:53:26.994: epoch 34:	0.02356813  	0.17269874  	0.09107699  
2023-05-19 10:53:26.994: Find a better model.
2023-05-19 10:53:33.657: [iter 35 : loss : 0.5204 = 0.1723 + 0.3461 + 0.0021, time: 6.661158]
2023-05-19 10:53:33.819: epoch 35:	0.02375866  	0.17424709  	0.09212452  
2023-05-19 10:53:33.819: Find a better model.
2023-05-19 10:53:40.261: [iter 36 : loss : 0.5103 = 0.1628 + 0.3453 + 0.0022, time: 6.441547]
2023-05-19 10:53:40.410: epoch 36:	0.02381511  	0.17496260  	0.09268211  
2023-05-19 10:53:40.410: Find a better model.
2023-05-19 10:53:47.058: [iter 37 : loss : 0.5006 = 0.1539 + 0.3444 + 0.0023, time: 6.645722]
2023-05-19 10:53:47.207: epoch 37:	0.02401269  	0.17587674  	0.09349109  
2023-05-19 10:53:47.207: Find a better model.
2023-05-19 10:53:53.850: [iter 38 : loss : 0.4933 = 0.1474 + 0.3435 + 0.0024, time: 6.641287]
2023-05-19 10:53:54.010: epoch 38:	0.02424555  	0.17786099  	0.09453182  
2023-05-19 10:53:54.010: Find a better model.
2023-05-19 10:54:00.643: [iter 39 : loss : 0.4844 = 0.1392 + 0.3426 + 0.0025, time: 6.632166]
2023-05-19 10:54:00.809: epoch 39:	0.02441490  	0.17879489  	0.09529626  
2023-05-19 10:54:00.809: Find a better model.
2023-05-19 10:54:07.432: [iter 40 : loss : 0.4773 = 0.1329 + 0.3418 + 0.0026, time: 6.621841]
2023-05-19 10:54:07.581: epoch 40:	0.02452075  	0.17971574  	0.09590020  
2023-05-19 10:54:07.581: Find a better model.
2023-05-19 10:54:14.232: [iter 41 : loss : 0.4715 = 0.1277 + 0.3411 + 0.0027, time: 6.646012]
2023-05-19 10:54:14.382: epoch 41:	0.02470422  	0.18110585  	0.09681621  
2023-05-19 10:54:14.382: Find a better model.
2023-05-19 10:54:21.037: [iter 42 : loss : 0.4650 = 0.1219 + 0.3403 + 0.0028, time: 6.653100]
2023-05-19 10:54:21.203: epoch 42:	0.02483829  	0.18212283  	0.09765442  
2023-05-19 10:54:21.203: Find a better model.
2023-05-19 10:54:27.837: [iter 43 : loss : 0.4589 = 0.1165 + 0.3396 + 0.0028, time: 6.633808]
2023-05-19 10:54:27.990: epoch 43:	0.02497236  	0.18353267  	0.09851448  
2023-05-19 10:54:27.990: Find a better model.
2023-05-19 10:54:34.638: [iter 44 : loss : 0.4531 = 0.1114 + 0.3388 + 0.0029, time: 6.645021]
2023-05-19 10:54:34.784: epoch 44:	0.02512761  	0.18493074  	0.09930801  
2023-05-19 10:54:34.784: Find a better model.
2023-05-19 10:54:41.250: [iter 45 : loss : 0.4481 = 0.1069 + 0.3382 + 0.0030, time: 6.464227]
2023-05-19 10:54:41.398: epoch 45:	0.02517700  	0.18551216  	0.09972032  
2023-05-19 10:54:41.398: Find a better model.
2023-05-19 10:54:48.040: [iter 46 : loss : 0.4437 = 0.1030 + 0.3376 + 0.0031, time: 6.638772]
2023-05-19 10:54:48.186: epoch 46:	0.02532518  	0.18655525  	0.10045321  
2023-05-19 10:54:48.186: Find a better model.
2023-05-19 10:54:54.830: [iter 47 : loss : 0.4402 = 0.1001 + 0.3369 + 0.0032, time: 6.641185]
2023-05-19 10:54:54.988: epoch 47:	0.02533223  	0.18636370  	0.10061938  
2023-05-19 10:55:01.623: [iter 48 : loss : 0.4351 = 0.0955 + 0.3363 + 0.0032, time: 6.634022]
2023-05-19 10:55:01.773: epoch 48:	0.02545219  	0.18710920  	0.10103179  
2023-05-19 10:55:01.773: Find a better model.
2023-05-19 10:55:08.241: [iter 49 : loss : 0.4308 = 0.0916 + 0.3359 + 0.0033, time: 6.465385]
2023-05-19 10:55:08.388: epoch 49:	0.02550863  	0.18736641  	0.10155217  
2023-05-19 10:55:08.388: Find a better model.
2023-05-19 10:55:15.033: [iter 50 : loss : 0.4275 = 0.0889 + 0.3352 + 0.0034, time: 6.644409]
2023-05-19 10:55:15.194: epoch 50:	0.02569915  	0.18886691  	0.10219824  
2023-05-19 10:55:15.194: Find a better model.
2023-05-19 10:55:21.821: [iter 51 : loss : 0.4232 = 0.0850 + 0.3347 + 0.0035, time: 6.625724]
2023-05-19 10:55:21.983: epoch 51:	0.02580500  	0.18980365  	0.10274733  
2023-05-19 10:55:21.983: Find a better model.
2023-05-19 10:55:28.613: [iter 52 : loss : 0.4215 = 0.0836 + 0.3343 + 0.0036, time: 6.629185]
2023-05-19 10:55:28.760: epoch 52:	0.02579794  	0.18990976  	0.10295974  
2023-05-19 10:55:28.760: Find a better model.
2023-05-19 10:55:35.231: [iter 53 : loss : 0.4182 = 0.0808 + 0.3338 + 0.0036, time: 6.469738]
2023-05-19 10:55:35.377: epoch 53:	0.02593202  	0.19087712  	0.10347275  
2023-05-19 10:55:35.377: Find a better model.
2023-05-19 10:55:41.819: [iter 54 : loss : 0.4150 = 0.0780 + 0.3333 + 0.0037, time: 6.440517]
2023-05-19 10:55:41.973: epoch 54:	0.02602375  	0.19176896  	0.10404898  
2023-05-19 10:55:41.974: Find a better model.
2023-05-19 10:55:48.412: [iter 55 : loss : 0.4124 = 0.0757 + 0.3329 + 0.0038, time: 6.436290]
2023-05-19 10:55:48.560: epoch 55:	0.02605904  	0.19216967  	0.10439079  
2023-05-19 10:55:48.560: Find a better model.
2023-05-19 10:55:55.189: [iter 56 : loss : 0.4095 = 0.0732 + 0.3324 + 0.0038, time: 6.628217]
2023-05-19 10:55:55.335: epoch 56:	0.02603787  	0.19223812  	0.10456032  
2023-05-19 10:55:55.335: Find a better model.
2023-05-19 10:56:01.819: [iter 57 : loss : 0.4068 = 0.0708 + 0.3320 + 0.0039, time: 6.481567]
2023-05-19 10:56:01.983: epoch 57:	0.02612254  	0.19287558  	0.10493520  
2023-05-19 10:56:01.983: Find a better model.
2023-05-19 10:56:08.580: [iter 58 : loss : 0.4044 = 0.0687 + 0.3317 + 0.0040, time: 6.596307]
2023-05-19 10:56:08.727: epoch 58:	0.02621427  	0.19347116  	0.10534997  
2023-05-19 10:56:08.727: Find a better model.
2023-05-19 10:56:15.219: [iter 59 : loss : 0.4024 = 0.0671 + 0.3313 + 0.0040, time: 6.489709]
2023-05-19 10:56:15.366: epoch 59:	0.02628483  	0.19418299  	0.10586116  
2023-05-19 10:56:15.366: Find a better model.
2023-05-19 10:56:22.003: [iter 60 : loss : 0.4003 = 0.0653 + 0.3308 + 0.0041, time: 6.636153]
2023-05-19 10:56:22.170: epoch 60:	0.02640480  	0.19519918  	0.10636828  
2023-05-19 10:56:22.170: Find a better model.
2023-05-19 10:56:28.777: [iter 61 : loss : 0.3984 = 0.0636 + 0.3306 + 0.0042, time: 6.604628]
2023-05-19 10:56:28.924: epoch 61:	0.02655298  	0.19623804  	0.10688198  
2023-05-19 10:56:28.925: Find a better model.
2023-05-19 10:56:35.398: [iter 62 : loss : 0.3961 = 0.0617 + 0.3302 + 0.0042, time: 6.472277]
2023-05-19 10:56:35.547: epoch 62:	0.02656710  	0.19637905  	0.10708253  
2023-05-19 10:56:35.547: Find a better model.
2023-05-19 10:56:42.010: [iter 63 : loss : 0.3942 = 0.0600 + 0.3299 + 0.0043, time: 6.461483]
2023-05-19 10:56:42.165: epoch 63:	0.02663766  	0.19646072  	0.10731293  
2023-05-19 10:56:42.165: Find a better model.
2023-05-19 10:56:48.590: [iter 64 : loss : 0.3927 = 0.0587 + 0.3295 + 0.0044, time: 6.424838]
2023-05-19 10:56:48.742: epoch 64:	0.02668706  	0.19694452  	0.10764151  
2023-05-19 10:56:48.742: Find a better model.
2023-05-19 10:56:55.197: [iter 65 : loss : 0.3908 = 0.0572 + 0.3291 + 0.0044, time: 6.454313]
2023-05-19 10:56:55.362: epoch 65:	0.02674351  	0.19735157  	0.10789786  
2023-05-19 10:56:55.362: Find a better model.
2023-05-19 10:57:01.965: [iter 66 : loss : 0.3892 = 0.0557 + 0.3290 + 0.0045, time: 6.602195]
2023-05-19 10:57:02.128: epoch 66:	0.02675762  	0.19757625  	0.10824528  
2023-05-19 10:57:02.128: Find a better model.
2023-05-19 10:57:08.787: [iter 67 : loss : 0.3874 = 0.0541 + 0.3287 + 0.0046, time: 6.656617]
2023-05-19 10:57:08.936: epoch 67:	0.02683524  	0.19809024  	0.10839546  
2023-05-19 10:57:08.936: Find a better model.
2023-05-19 10:57:15.381: [iter 68 : loss : 0.3862 = 0.0533 + 0.3283 + 0.0046, time: 6.444094]
2023-05-19 10:57:15.529: epoch 68:	0.02679997  	0.19767989  	0.10854314  
2023-05-19 10:57:21.990: [iter 69 : loss : 0.3843 = 0.0516 + 0.3281 + 0.0047, time: 6.458820]
2023-05-19 10:57:22.151: epoch 69:	0.02690581  	0.19883689  	0.10903371  
2023-05-19 10:57:22.151: Find a better model.
2023-05-19 10:57:28.786: [iter 70 : loss : 0.3828 = 0.0501 + 0.3280 + 0.0047, time: 6.633729]
2023-05-19 10:57:28.933: epoch 70:	0.02691286  	0.19849369  	0.10930531  
2023-05-19 10:57:35.383: [iter 71 : loss : 0.3814 = 0.0489 + 0.3277 + 0.0048, time: 6.449529]
2023-05-19 10:57:35.533: epoch 71:	0.02689170  	0.19824803  	0.10932899  
2023-05-19 10:57:41.978: [iter 72 : loss : 0.3805 = 0.0482 + 0.3275 + 0.0049, time: 6.442140]
2023-05-19 10:57:42.129: epoch 72:	0.02694814  	0.19863982  	0.10954725  
2023-05-19 10:57:48.552: [iter 73 : loss : 0.3786 = 0.0465 + 0.3272 + 0.0049, time: 6.422762]
2023-05-19 10:57:48.716: epoch 73:	0.02702576  	0.19916040  	0.10978288  
2023-05-19 10:57:48.716: Find a better model.
2023-05-19 10:57:55.161: [iter 74 : loss : 0.3777 = 0.0458 + 0.3270 + 0.0050, time: 6.442373]
2023-05-19 10:57:55.322: epoch 74:	0.02703988  	0.19929476  	0.10998808  
2023-05-19 10:57:55.322: Find a better model.
2023-05-19 10:58:01.763: [iter 75 : loss : 0.3766 = 0.0448 + 0.3268 + 0.0050, time: 6.440389]
2023-05-19 10:58:01.923: epoch 75:	0.02708927  	0.19935127  	0.11006844  
2023-05-19 10:58:01.924: Find a better model.
2023-05-19 10:58:08.358: [iter 76 : loss : 0.3753 = 0.0436 + 0.3265 + 0.0051, time: 6.432613]
2023-05-19 10:58:08.504: epoch 76:	0.02710338  	0.19967346  	0.11021287  
2023-05-19 10:58:08.504: Find a better model.
2023-05-19 10:58:15.133: [iter 77 : loss : 0.3743 = 0.0429 + 0.3263 + 0.0051, time: 6.628685]
2023-05-19 10:58:15.281: epoch 77:	0.02718101  	0.20011677  	0.11049536  
2023-05-19 10:58:15.281: Find a better model.
2023-05-19 10:58:21.748: [iter 78 : loss : 0.3734 = 0.0420 + 0.3262 + 0.0052, time: 6.465648]
2023-05-19 10:58:21.895: epoch 78:	0.02715278  	0.19984746  	0.11040671  
2023-05-19 10:58:28.363: [iter 79 : loss : 0.3724 = 0.0411 + 0.3260 + 0.0052, time: 6.466039]
2023-05-19 10:58:28.512: epoch 79:	0.02718807  	0.20024465  	0.11072425  
2023-05-19 10:58:28.512: Find a better model.
2023-05-19 10:58:34.961: [iter 80 : loss : 0.3712 = 0.0400 + 0.3259 + 0.0053, time: 6.447002]
2023-05-19 10:58:35.110: epoch 80:	0.02721629  	0.20021279  	0.11072703  
2023-05-19 10:58:41.566: [iter 81 : loss : 0.3705 = 0.0394 + 0.3258 + 0.0053, time: 6.455389]
2023-05-19 10:58:41.715: epoch 81:	0.02726569  	0.20040256  	0.11083990  
2023-05-19 10:58:41.716: Find a better model.
2023-05-19 10:58:48.162: [iter 82 : loss : 0.3692 = 0.0382 + 0.3256 + 0.0054, time: 6.445155]
2023-05-19 10:58:48.309: epoch 82:	0.02718101  	0.19965041  	0.11064817  
2023-05-19 10:58:54.761: [iter 83 : loss : 0.3686 = 0.0378 + 0.3253 + 0.0054, time: 6.450130]
2023-05-19 10:58:54.914: epoch 83:	0.02717396  	0.19980958  	0.11061618  
2023-05-19 10:59:01.346: [iter 84 : loss : 0.3678 = 0.0372 + 0.3252 + 0.0055, time: 6.430738]
2023-05-19 10:59:01.499: epoch 84:	0.02720924  	0.19963247  	0.11052947  
2023-05-19 10:59:07.939: [iter 85 : loss : 0.3674 = 0.0368 + 0.3251 + 0.0055, time: 6.438938]
2023-05-19 10:59:08.089: epoch 85:	0.02719513  	0.19958350  	0.11074576  
2023-05-19 10:59:14.538: [iter 86 : loss : 0.3665 = 0.0361 + 0.3248 + 0.0056, time: 6.448148]
2023-05-19 10:59:14.684: epoch 86:	0.02720924  	0.19962987  	0.11076834  
2023-05-19 10:59:21.136: [iter 87 : loss : 0.3646 = 0.0343 + 0.3247 + 0.0056, time: 6.450759]
2023-05-19 10:59:21.282: epoch 87:	0.02725864  	0.20005317  	0.11093947  
2023-05-19 10:59:27.736: [iter 88 : loss : 0.3642 = 0.0339 + 0.3247 + 0.0057, time: 6.453671]
2023-05-19 10:59:27.885: epoch 88:	0.02720924  	0.19962825  	0.11061481  
2023-05-19 10:59:34.331: [iter 89 : loss : 0.3634 = 0.0333 + 0.3244 + 0.0057, time: 6.445161]
2023-05-19 10:59:34.482: epoch 89:	0.02723746  	0.19968334  	0.11073548  
2023-05-19 10:59:40.938: [iter 90 : loss : 0.3635 = 0.0333 + 0.3244 + 0.0058, time: 6.455126]
2023-05-19 10:59:41.109: epoch 90:	0.02722335  	0.19948250  	0.11081716  
2023-05-19 10:59:47.721: [iter 91 : loss : 0.3630 = 0.0329 + 0.3242 + 0.0058, time: 6.611557]
2023-05-19 10:59:47.874: epoch 91:	0.02725158  	0.19968659  	0.11091793  
2023-05-19 10:59:54.386: [iter 92 : loss : 0.3618 = 0.0319 + 0.3241 + 0.0059, time: 6.511267]
2023-05-19 10:59:54.569: epoch 92:	0.02725158  	0.19966064  	0.11099901  
2023-05-19 11:00:01.142: [iter 93 : loss : 0.3615 = 0.0317 + 0.3239 + 0.0059, time: 6.571067]
2023-05-19 11:00:01.292: epoch 93:	0.02715985  	0.19886723  	0.11066177  
2023-05-19 11:00:07.929: [iter 94 : loss : 0.3602 = 0.0303 + 0.3239 + 0.0060, time: 6.636188]
2023-05-19 11:00:08.088: epoch 94:	0.02718807  	0.19924764  	0.11085821  
2023-05-19 11:00:14.704: [iter 95 : loss : 0.3595 = 0.0298 + 0.3237 + 0.0060, time: 6.614179]
2023-05-19 11:00:14.850: epoch 95:	0.02725158  	0.19960432  	0.11104544  
2023-05-19 11:00:21.285: [iter 96 : loss : 0.3593 = 0.0297 + 0.3236 + 0.0061, time: 6.432827]
2023-05-19 11:00:21.432: epoch 96:	0.02720924  	0.19901979  	0.11085718  
2023-05-19 11:00:27.934: [iter 97 : loss : 0.3582 = 0.0286 + 0.3235 + 0.0061, time: 6.500849]
2023-05-19 11:00:28.083: epoch 97:	0.02715984  	0.19920494  	0.11079388  
2023-05-19 11:00:34.529: [iter 98 : loss : 0.3583 = 0.0287 + 0.3234 + 0.0062, time: 6.442509]
2023-05-19 11:00:34.682: epoch 98:	0.02718807  	0.19904749  	0.11096924  
2023-05-19 11:00:41.048: [iter 99 : loss : 0.3576 = 0.0281 + 0.3233 + 0.0062, time: 6.364970]
2023-05-19 11:00:41.216: epoch 99:	0.02725864  	0.19963068  	0.11118022  
2023-05-19 11:00:47.680: [iter 100 : loss : 0.3569 = 0.0275 + 0.3231 + 0.0063, time: 6.461222]
2023-05-19 11:00:47.832: epoch 100:	0.02715279  	0.19888459  	0.11107709  
2023-05-19 11:00:54.301: [iter 101 : loss : 0.3567 = 0.0273 + 0.3231 + 0.0063, time: 6.468290]
2023-05-19 11:00:54.456: epoch 101:	0.02706105  	0.19831587  	0.11097992  
2023-05-19 11:01:00.924: [iter 102 : loss : 0.3561 = 0.0267 + 0.3230 + 0.0063, time: 6.465730]
2023-05-19 11:01:01.073: epoch 102:	0.02709634  	0.19873446  	0.11115832  
2023-05-19 11:01:07.502: [iter 103 : loss : 0.3558 = 0.0264 + 0.3230 + 0.0064, time: 6.427057]
2023-05-19 11:01:07.653: epoch 103:	0.02708223  	0.19858706  	0.11113559  
2023-05-19 11:01:14.094: [iter 104 : loss : 0.3557 = 0.0265 + 0.3227 + 0.0064, time: 6.439227]
2023-05-19 11:01:14.256: epoch 104:	0.02700460  	0.19786631  	0.11076591  
2023-05-19 11:01:20.683: [iter 105 : loss : 0.3552 = 0.0262 + 0.3226 + 0.0065, time: 6.425866]
2023-05-19 11:01:20.847: epoch 105:	0.02704694  	0.19804330  	0.11088854  
2023-05-19 11:01:27.298: [iter 106 : loss : 0.3542 = 0.0251 + 0.3226 + 0.0065, time: 6.449620]
2023-05-19 11:01:27.446: epoch 106:	0.02696932  	0.19745328  	0.11068030  
2023-05-19 11:01:27.447: Early stopping is trigger at epoch: 106
2023-05-19 11:01:27.447: best_result@epoch 81:

2023-05-19 11:01:27.447: 		0.0273      	0.2004      	0.1108      
2023-05-19 11:06:30.063: my pid: 3104
2023-05-19 11:06:30.063: model: model.general_recommender.SGL
2023-05-19 11:06:30.063: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-19 11:06:30.063: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-19 11:06:34.110: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-19 11:06:42.922: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 8.811611]
2023-05-19 11:06:43.093: epoch 1:	0.00145357  	0.01016506  	0.00542475  
2023-05-19 11:06:43.093: Find a better model.
2023-05-19 11:06:51.799: [iter 2 : loss : 0.9275 = 0.6929 + 0.2346 + 0.0000, time: 8.705091]
2023-05-19 11:06:51.993: epoch 2:	0.00234971  	0.01666871  	0.00856246  
2023-05-19 11:06:51.993: Find a better model.
2023-05-19 11:06:59.883: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.888029]
2023-05-19 11:07:00.065: epoch 3:	0.00347163  	0.02358160  	0.01221165  
2023-05-19 11:07:00.065: Find a better model.
2023-05-19 11:07:09.079: [iter 4 : loss : 0.9271 = 0.6926 + 0.2344 + 0.0000, time: 9.011315]
2023-05-19 11:07:09.376: epoch 4:	0.00448770  	0.03138259  	0.01610679  
2023-05-19 11:07:09.376: Find a better model.
2023-05-19 11:07:16.554: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.177006]
2023-05-19 11:07:16.717: epoch 5:	0.00522859  	0.03648443  	0.01901079  
2023-05-19 11:07:16.717: Find a better model.
2023-05-19 11:07:24.191: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 7.473332]
2023-05-19 11:07:24.343: epoch 6:	0.00638579  	0.04505668  	0.02337801  
2023-05-19 11:07:24.343: Find a better model.
2023-05-19 11:07:32.097: [iter 7 : loss : 0.9263 = 0.6917 + 0.2345 + 0.0000, time: 7.752993]
2023-05-19 11:07:32.319: epoch 7:	0.00778994  	0.05459175  	0.02831527  
2023-05-19 11:07:32.319: Find a better model.
2023-05-19 11:07:39.400: [iter 8 : loss : 0.9259 = 0.6912 + 0.2346 + 0.0000, time: 7.080014]
2023-05-19 11:07:39.567: epoch 8:	0.00889069  	0.06326780  	0.03263219  
2023-05-19 11:07:39.568: Find a better model.
2023-05-19 11:07:47.948: [iter 9 : loss : 0.9253 = 0.6905 + 0.2348 + 0.0000, time: 8.372453]
2023-05-19 11:07:48.248: epoch 9:	0.01013968  	0.07309359  	0.03691475  
2023-05-19 11:07:48.248: Find a better model.
2023-05-19 11:07:55.791: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 7.542002]
2023-05-19 11:07:55.967: epoch 10:	0.01150864  	0.08271958  	0.04048361  
2023-05-19 11:07:55.967: Find a better model.
2023-05-19 11:08:03.387: [iter 11 : loss : 0.9229 = 0.6877 + 0.2351 + 0.0000, time: 7.418003]
2023-05-19 11:08:03.544: epoch 11:	0.01279292  	0.09223437  	0.04496872  
2023-05-19 11:08:03.544: Find a better model.
2023-05-19 11:08:10.404: [iter 12 : loss : 0.9204 = 0.6850 + 0.2353 + 0.0000, time: 6.858993]
2023-05-19 11:08:10.569: epoch 12:	0.01393607  	0.09999800  	0.04843413  
2023-05-19 11:08:10.569: Find a better model.
2023-05-19 11:08:17.865: [iter 13 : loss : 0.9166 = 0.6807 + 0.2358 + 0.0000, time: 7.294003]
2023-05-19 11:08:18.024: epoch 13:	0.01541085  	0.11104336  	0.05407659  
2023-05-19 11:08:18.024: Find a better model.
2023-05-19 11:08:26.160: [iter 14 : loss : 0.9098 = 0.6733 + 0.2365 + 0.0001, time: 8.132009]
2023-05-19 11:08:26.458: epoch 14:	0.01673040  	0.12089839  	0.05901327  
2023-05-19 11:08:26.458: Find a better model.
2023-05-19 11:08:34.748: [iter 15 : loss : 0.8989 = 0.6613 + 0.2375 + 0.0001, time: 8.283025]
2023-05-19 11:08:35.041: epoch 15:	0.01764774  	0.12792999  	0.06345086  
2023-05-19 11:08:35.041: Find a better model.
2023-05-19 11:08:42.430: [iter 16 : loss : 0.8813 = 0.6419 + 0.2393 + 0.0001, time: 7.387011]
2023-05-19 11:08:42.609: epoch 16:	0.01881205  	0.13673264  	0.06875058  
2023-05-19 11:08:42.609: Find a better model.
2023-05-19 11:08:49.188: [iter 17 : loss : 0.8549 = 0.6126 + 0.2420 + 0.0002, time: 6.577005]
2023-05-19 11:08:49.356: epoch 17:	0.01943302  	0.14260554  	0.07251188  
2023-05-19 11:08:49.357: Find a better model.
2023-05-19 11:08:56.915: [iter 18 : loss : 0.8181 = 0.5720 + 0.2459 + 0.0003, time: 7.555525]
2023-05-19 11:08:57.086: epoch 18:	0.01999049  	0.14665136  	0.07473413  
2023-05-19 11:08:57.086: Find a better model.
2023-05-19 11:09:05.567: [iter 19 : loss : 0.7706 = 0.5194 + 0.2508 + 0.0004, time: 8.477790]
2023-05-19 11:09:05.834: epoch 19:	0.02023041  	0.14843787  	0.07537422  
2023-05-19 11:09:05.834: Find a better model.
2023-05-19 11:09:14.057: [iter 20 : loss : 0.7194 = 0.4632 + 0.2557 + 0.0005, time: 8.215359]
2023-05-19 11:09:14.354: epoch 20:	0.02038566  	0.14982666  	0.07630475  
2023-05-19 11:09:14.354: Find a better model.
2023-05-19 11:09:21.716: [iter 21 : loss : 0.6684 = 0.4078 + 0.2600 + 0.0007, time: 7.360499]
2023-05-19 11:09:21.870: epoch 21:	0.02070319  	0.15202875  	0.07746636  
2023-05-19 11:09:21.870: Find a better model.
2023-05-19 11:09:28.587: [iter 22 : loss : 0.6236 = 0.3595 + 0.2633 + 0.0008, time: 6.716003]
2023-05-19 11:09:28.736: epoch 22:	0.02075964  	0.15212846  	0.07833200  
2023-05-19 11:09:28.736: Find a better model.
2023-05-19 11:09:36.378: [iter 23 : loss : 0.5856 = 0.3192 + 0.2654 + 0.0010, time: 7.641001]
2023-05-19 11:09:36.531: epoch 23:	0.02114068  	0.15478700  	0.07963145  
2023-05-19 11:09:36.531: Find a better model.
2023-05-19 11:09:43.357: [iter 24 : loss : 0.5552 = 0.2876 + 0.2665 + 0.0011, time: 6.825017]
2023-05-19 11:09:43.567: epoch 24:	0.02137356  	0.15653075  	0.08081893  
2023-05-19 11:09:43.567: Find a better model.
2023-05-19 11:09:51.822: [iter 25 : loss : 0.5293 = 0.2609 + 0.2671 + 0.0013, time: 8.251992]
2023-05-19 11:09:52.123: epoch 25:	0.02172639  	0.15921845  	0.08207917  
2023-05-19 11:09:52.123: Find a better model.
2023-05-19 11:09:58.757: [iter 26 : loss : 0.5089 = 0.2405 + 0.2670 + 0.0014, time: 6.633016]
2023-05-19 11:09:58.919: epoch 26:	0.02197337  	0.16181356  	0.08319038  
2023-05-19 11:09:58.919: Find a better model.
2023-05-19 11:10:06.356: [iter 27 : loss : 0.4897 = 0.2215 + 0.2667 + 0.0015, time: 7.435384]
2023-05-19 11:10:06.520: epoch 27:	0.02205099  	0.16241378  	0.08399919  
2023-05-19 11:10:06.520: Find a better model.
2023-05-19 11:10:14.063: [iter 28 : loss : 0.4740 = 0.2061 + 0.2663 + 0.0017, time: 7.542003]
2023-05-19 11:10:14.281: epoch 28:	0.02241087  	0.16490930  	0.08554748  
2023-05-19 11:10:14.282: Find a better model.
2023-05-19 11:10:21.365: [iter 29 : loss : 0.4609 = 0.1937 + 0.2655 + 0.0018, time: 7.081002]
2023-05-19 11:10:21.516: epoch 29:	0.02260845  	0.16661283  	0.08654520  
2023-05-19 11:10:21.516: Find a better model.
2023-05-19 11:10:29.784: [iter 30 : loss : 0.4475 = 0.1807 + 0.2649 + 0.0019, time: 8.265940]
2023-05-19 11:10:30.050: epoch 30:	0.02282721  	0.16859905  	0.08752489  
2023-05-19 11:10:30.050: Find a better model.
2023-05-19 11:10:37.973: [iter 31 : loss : 0.4368 = 0.1707 + 0.2641 + 0.0020, time: 7.921311]
2023-05-19 11:10:38.162: epoch 31:	0.02307418  	0.17009199  	0.08838051  
2023-05-19 11:10:38.162: Find a better model.
2023-05-19 11:10:45.540: [iter 32 : loss : 0.4264 = 0.1610 + 0.2632 + 0.0021, time: 7.374015]
2023-05-19 11:10:45.694: epoch 32:	0.02325765  	0.17178144  	0.08957987  
2023-05-19 11:10:45.694: Find a better model.
2023-05-19 11:10:52.749: [iter 33 : loss : 0.4185 = 0.1539 + 0.2624 + 0.0022, time: 7.054016]
2023-05-19 11:10:52.915: epoch 33:	0.02347640  	0.17323914  	0.09069246  
2023-05-19 11:10:52.915: Find a better model.
2023-05-19 11:11:00.377: [iter 34 : loss : 0.4103 = 0.1465 + 0.2616 + 0.0023, time: 7.461027]
2023-05-19 11:11:00.541: epoch 34:	0.02365281  	0.17475036  	0.09166735  
2023-05-19 11:11:00.541: Find a better model.
2023-05-19 11:11:08.812: [iter 35 : loss : 0.4031 = 0.1398 + 0.2609 + 0.0024, time: 8.268608]
2023-05-19 11:11:09.128: epoch 35:	0.02385746  	0.17597274  	0.09249863  
2023-05-19 11:11:09.128: Find a better model.
2023-05-19 11:11:17.466: [iter 36 : loss : 0.3964 = 0.1338 + 0.2601 + 0.0025, time: 8.329219]
2023-05-19 11:11:17.773: epoch 36:	0.02409032  	0.17741880  	0.09350257  
2023-05-19 11:11:17.773: Find a better model.
2023-05-19 11:11:25.224: [iter 37 : loss : 0.3896 = 0.1276 + 0.2594 + 0.0026, time: 7.449169]
2023-05-19 11:11:25.381: epoch 37:	0.02426673  	0.17861846  	0.09423674  
2023-05-19 11:11:25.381: Find a better model.
2023-05-19 11:11:32.117: [iter 38 : loss : 0.3851 = 0.1238 + 0.2586 + 0.0026, time: 6.735005]
2023-05-19 11:11:32.282: epoch 38:	0.02447137  	0.18017924  	0.09509658  
2023-05-19 11:11:32.282: Find a better model.
2023-05-19 11:11:40.139: [iter 39 : loss : 0.3783 = 0.1177 + 0.2579 + 0.0027, time: 7.856003]
2023-05-19 11:11:40.305: epoch 39:	0.02451370  	0.18020074  	0.09572433  
2023-05-19 11:11:40.305: Find a better model.
2023-05-19 11:11:48.543: [iter 40 : loss : 0.3732 = 0.1132 + 0.2573 + 0.0028, time: 8.231515]
2023-05-19 11:11:48.839: epoch 40:	0.02451370  	0.18001118  	0.09615692  
2023-05-19 11:11:57.102: [iter 41 : loss : 0.3692 = 0.1098 + 0.2565 + 0.0029, time: 8.259992]
2023-05-19 11:11:57.413: epoch 41:	0.02473951  	0.18176138  	0.09695491  
2023-05-19 11:11:57.413: Find a better model.
2023-05-19 11:12:04.971: [iter 42 : loss : 0.3645 = 0.1056 + 0.2560 + 0.0030, time: 7.557025]
2023-05-19 11:12:05.134: epoch 42:	0.02478890  	0.18229933  	0.09744794  
2023-05-19 11:12:05.134: Find a better model.
2023-05-19 11:12:11.924: [iter 43 : loss : 0.3597 = 0.1013 + 0.2553 + 0.0031, time: 6.789017]
2023-05-19 11:12:12.093: epoch 43:	0.02493709  	0.18338880  	0.09822001  
2023-05-19 11:12:12.093: Find a better model.
2023-05-19 11:12:19.530: [iter 44 : loss : 0.3552 = 0.0975 + 0.2546 + 0.0031, time: 7.436003]
2023-05-19 11:12:19.770: epoch 44:	0.02497237  	0.18352246  	0.09856737  
2023-05-19 11:12:19.770: Find a better model.
2023-05-19 11:12:27.520: [iter 45 : loss : 0.3514 = 0.0940 + 0.2542 + 0.0032, time: 7.748030]
2023-05-19 11:12:27.825: epoch 45:	0.02504998  	0.18428056  	0.09916276  
2023-05-19 11:12:27.825: Find a better model.
2023-05-19 11:12:36.085: [iter 46 : loss : 0.3481 = 0.0912 + 0.2537 + 0.0033, time: 8.258003]
2023-05-19 11:12:36.383: epoch 46:	0.02516994  	0.18507265  	0.09972117  
2023-05-19 11:12:36.383: Find a better model.
2023-05-19 11:12:43.382: [iter 47 : loss : 0.3458 = 0.0893 + 0.2532 + 0.0034, time: 6.998136]
2023-05-19 11:12:43.546: epoch 47:	0.02537458  	0.18645765  	0.10031194  
2023-05-19 11:12:43.546: Find a better model.
2023-05-19 11:12:50.485: [iter 48 : loss : 0.3414 = 0.0853 + 0.2527 + 0.0034, time: 6.938009]
2023-05-19 11:12:50.636: epoch 48:	0.02546631  	0.18719994  	0.10066269  
2023-05-19 11:12:50.636: Find a better model.
2023-05-19 11:12:58.094: [iter 49 : loss : 0.3377 = 0.0819 + 0.2523 + 0.0035, time: 7.455993]
2023-05-19 11:12:58.255: epoch 49:	0.02553688  	0.18762110  	0.10106891  
2023-05-19 11:12:58.256: Find a better model.
2023-05-19 11:13:05.073: [iter 50 : loss : 0.3354 = 0.0800 + 0.2518 + 0.0036, time: 6.815014]
2023-05-19 11:13:05.231: epoch 50:	0.02560744  	0.18808974  	0.10151445  
2023-05-19 11:13:05.232: Find a better model.
2023-05-19 11:13:13.512: [iter 51 : loss : 0.3322 = 0.0771 + 0.2514 + 0.0036, time: 8.276457]
2023-05-19 11:13:13.803: epoch 51:	0.02563567  	0.18828610  	0.10177082  
2023-05-19 11:13:13.803: Find a better model.
2023-05-19 11:13:21.070: [iter 52 : loss : 0.3309 = 0.0762 + 0.2511 + 0.0037, time: 7.264272]
2023-05-19 11:13:21.269: epoch 52:	0.02580502  	0.18925989  	0.10248544  
2023-05-19 11:13:21.270: Find a better model.
2023-05-19 11:13:28.498: [iter 53 : loss : 0.3280 = 0.0737 + 0.2506 + 0.0038, time: 7.225321]
2023-05-19 11:13:28.650: epoch 53:	0.02592499  	0.19001505  	0.10290681  
2023-05-19 11:13:28.650: Find a better model.
2023-05-19 11:13:35.662: [iter 54 : loss : 0.3254 = 0.0714 + 0.2502 + 0.0038, time: 7.010993]
2023-05-19 11:13:35.827: epoch 54:	0.02591087  	0.19032413  	0.10319719  
2023-05-19 11:13:35.827: Find a better model.
2023-05-19 11:13:43.312: [iter 55 : loss : 0.3235 = 0.0698 + 0.2499 + 0.0039, time: 7.484038]
2023-05-19 11:13:43.464: epoch 55:	0.02599555  	0.19097523  	0.10348054  
2023-05-19 11:13:43.464: Find a better model.
2023-05-19 11:13:51.747: [iter 56 : loss : 0.3212 = 0.0677 + 0.2495 + 0.0040, time: 8.275242]
2023-05-19 11:13:52.039: epoch 56:	0.02615784  	0.19249333  	0.10412349  
2023-05-19 11:13:52.039: Find a better model.
2023-05-19 11:14:00.325: [iter 57 : loss : 0.3191 = 0.0659 + 0.2491 + 0.0040, time: 8.276328]
2023-05-19 11:14:00.619: epoch 57:	0.02622135  	0.19299239  	0.10455304  
2023-05-19 11:14:00.619: Find a better model.
2023-05-19 11:14:07.873: [iter 58 : loss : 0.3165 = 0.0636 + 0.2488 + 0.0041, time: 7.253002]
2023-05-19 11:14:08.030: epoch 58:	0.02624958  	0.19325605  	0.10498930  
2023-05-19 11:14:08.030: Find a better model.
2023-05-19 11:14:14.876: [iter 59 : loss : 0.3151 = 0.0625 + 0.2485 + 0.0041, time: 6.844025]
2023-05-19 11:14:15.037: epoch 59:	0.02631309  	0.19397257  	0.10527887  
2023-05-19 11:14:15.037: Find a better model.
2023-05-19 11:14:22.555: [iter 60 : loss : 0.3133 = 0.0609 + 0.2482 + 0.0042, time: 7.515993]
2023-05-19 11:14:22.730: epoch 60:	0.02636954  	0.19407481  	0.10547946  
2023-05-19 11:14:22.730: Find a better model.
2023-05-19 11:14:31.023: [iter 61 : loss : 0.3119 = 0.0597 + 0.2480 + 0.0043, time: 8.290493]
2023-05-19 11:14:31.297: epoch 61:	0.02638366  	0.19427426  	0.10569448  
2023-05-19 11:14:31.297: Find a better model.
2023-05-19 11:14:39.577: [iter 62 : loss : 0.3098 = 0.0579 + 0.2476 + 0.0043, time: 8.278076]
2023-05-19 11:14:39.881: epoch 62:	0.02641894  	0.19483423  	0.10603493  
2023-05-19 11:14:39.881: Find a better model.
2023-05-19 11:14:47.268: [iter 63 : loss : 0.3083 = 0.0566 + 0.2473 + 0.0044, time: 7.385993]
2023-05-19 11:14:47.416: epoch 63:	0.02646833  	0.19502012  	0.10635393  
2023-05-19 11:14:47.417: Find a better model.
2023-05-19 11:14:54.050: [iter 64 : loss : 0.3072 = 0.0557 + 0.2470 + 0.0044, time: 6.631016]
2023-05-19 11:14:54.209: epoch 64:	0.02645422  	0.19483159  	0.10648829  
2023-05-19 11:15:01.635: [iter 65 : loss : 0.3054 = 0.0541 + 0.2468 + 0.0045, time: 7.425003]
2023-05-19 11:15:01.784: epoch 65:	0.02649656  	0.19498868  	0.10672294  
2023-05-19 11:15:08.671: [iter 66 : loss : 0.3039 = 0.0528 + 0.2466 + 0.0046, time: 6.886115]
2023-05-19 11:15:08.824: epoch 66:	0.02653890  	0.19557169  	0.10687732  
2023-05-19 11:15:08.824: Find a better model.
2023-05-19 11:15:16.892: [iter 67 : loss : 0.3023 = 0.0514 + 0.2463 + 0.0046, time: 8.065433]
2023-05-19 11:15:17.211: epoch 67:	0.02660241  	0.19610819  	0.10704511  
2023-05-19 11:15:17.211: Find a better model.
2023-05-19 11:15:23.775: [iter 68 : loss : 0.3016 = 0.0509 + 0.2460 + 0.0047, time: 6.562301]
2023-05-19 11:15:23.941: epoch 68:	0.02664474  	0.19620873  	0.10725886  
2023-05-19 11:15:23.941: Find a better model.
2023-05-19 11:15:31.268: [iter 69 : loss : 0.2997 = 0.0492 + 0.2458 + 0.0047, time: 7.325994]
2023-05-19 11:15:31.446: epoch 69:	0.02665179  	0.19605738  	0.10743734  
2023-05-19 11:15:38.683: [iter 70 : loss : 0.2983 = 0.0478 + 0.2457 + 0.0048, time: 7.234993]
2023-05-19 11:15:38.931: epoch 70:	0.02673648  	0.19717033  	0.10781806  
2023-05-19 11:15:38.931: Find a better model.
2023-05-19 11:15:46.238: [iter 71 : loss : 0.2972 = 0.0469 + 0.2455 + 0.0048, time: 7.305371]
2023-05-19 11:15:46.386: epoch 71:	0.02671531  	0.19668207  	0.10784753  
2023-05-19 11:15:54.492: [iter 72 : loss : 0.2964 = 0.0463 + 0.2453 + 0.0049, time: 8.101887]
2023-05-19 11:15:54.802: epoch 72:	0.02672942  	0.19683285  	0.10792907  
2023-05-19 11:16:03.033: [iter 73 : loss : 0.2949 = 0.0448 + 0.2451 + 0.0049, time: 8.222375]
2023-05-19 11:16:03.332: epoch 73:	0.02672942  	0.19649020  	0.10805255  
2023-05-19 11:16:10.485: [iter 74 : loss : 0.2937 = 0.0439 + 0.2448 + 0.0050, time: 7.152045]
2023-05-19 11:16:10.654: epoch 74:	0.02673647  	0.19679244  	0.10841010  
2023-05-19 11:16:17.414: [iter 75 : loss : 0.2929 = 0.0431 + 0.2447 + 0.0050, time: 6.758015]
2023-05-19 11:16:17.575: epoch 75:	0.02672941  	0.19657865  	0.10853561  
2023-05-19 11:16:25.273: [iter 76 : loss : 0.2918 = 0.0422 + 0.2445 + 0.0051, time: 7.696027]
2023-05-19 11:16:25.435: epoch 76:	0.02683526  	0.19755207  	0.10895024  
2023-05-19 11:16:25.436: Find a better model.
2023-05-19 11:16:33.573: [iter 77 : loss : 0.2909 = 0.0415 + 0.2443 + 0.0051, time: 8.127670]
2023-05-19 11:16:33.875: epoch 77:	0.02678587  	0.19710629  	0.10883170  
2023-05-19 11:16:42.106: [iter 78 : loss : 0.2901 = 0.0408 + 0.2441 + 0.0052, time: 8.222370]
2023-05-19 11:16:42.399: epoch 78:	0.02684937  	0.19752607  	0.10880323  
2023-05-19 11:16:49.847: [iter 79 : loss : 0.2890 = 0.0398 + 0.2440 + 0.0053, time: 7.447014]
2023-05-19 11:16:50.022: epoch 79:	0.02689876  	0.19792219  	0.10880690  
2023-05-19 11:16:50.022: Find a better model.
2023-05-19 11:16:56.823: [iter 80 : loss : 0.2882 = 0.0390 + 0.2439 + 0.0053, time: 6.800022]
2023-05-19 11:16:56.991: epoch 80:	0.02693405  	0.19823988  	0.10904481  
2023-05-19 11:16:56.991: Find a better model.
2023-05-19 11:17:04.596: [iter 81 : loss : 0.2876 = 0.0385 + 0.2437 + 0.0053, time: 7.604004]
2023-05-19 11:17:04.758: epoch 81:	0.02690582  	0.19794276  	0.10927363  
2023-05-19 11:17:11.619: [iter 82 : loss : 0.2865 = 0.0375 + 0.2436 + 0.0054, time: 6.859366]
2023-05-19 11:17:11.903: epoch 82:	0.02694110  	0.19807303  	0.10932292  
2023-05-19 11:17:20.138: [iter 83 : loss : 0.2857 = 0.0369 + 0.2434 + 0.0054, time: 8.232158]
2023-05-19 11:17:20.442: epoch 83:	0.02694110  	0.19811583  	0.10936674  
2023-05-19 11:17:26.983: [iter 84 : loss : 0.2855 = 0.0367 + 0.2433 + 0.0055, time: 6.540156]
2023-05-19 11:17:27.149: epoch 84:	0.02696227  	0.19813323  	0.10936263  
2023-05-19 11:17:34.427: [iter 85 : loss : 0.2846 = 0.0360 + 0.2431 + 0.0055, time: 7.275484]
2023-05-19 11:17:34.588: epoch 85:	0.02683526  	0.19701928  	0.10908259  
2023-05-19 11:17:42.323: [iter 86 : loss : 0.2843 = 0.0357 + 0.2430 + 0.0056, time: 7.732993]
2023-05-19 11:17:42.473: epoch 86:	0.02690582  	0.19753458  	0.10924714  
2023-05-19 11:17:49.208: [iter 87 : loss : 0.2822 = 0.0337 + 0.2428 + 0.0056, time: 6.732015]
2023-05-19 11:17:49.355: epoch 87:	0.02683526  	0.19719686  	0.10919973  
2023-05-19 11:17:57.449: [iter 88 : loss : 0.2818 = 0.0333 + 0.2427 + 0.0057, time: 8.093023]
2023-05-19 11:17:57.753: epoch 88:	0.02689171  	0.19775137  	0.10952698  
2023-05-19 11:18:06.033: [iter 89 : loss : 0.2809 = 0.0326 + 0.2425 + 0.0057, time: 8.273008]
2023-05-19 11:18:06.253: epoch 89:	0.02691288  	0.19749765  	0.10971560  
2023-05-19 11:18:13.414: [iter 90 : loss : 0.2813 = 0.0330 + 0.2425 + 0.0058, time: 7.158993]
2023-05-19 11:18:13.580: epoch 90:	0.02687760  	0.19736953  	0.10984153  
2023-05-19 11:18:20.413: [iter 91 : loss : 0.2805 = 0.0323 + 0.2423 + 0.0058, time: 6.832007]
2023-05-19 11:18:20.578: epoch 91:	0.02694816  	0.19794360  	0.10999597  
2023-05-19 11:18:27.839: [iter 92 : loss : 0.2796 = 0.0315 + 0.2423 + 0.0059, time: 7.260003]
2023-05-19 11:18:28.008: epoch 92:	0.02694816  	0.19791439  	0.11011679  
2023-05-19 11:18:36.253: [iter 93 : loss : 0.2794 = 0.0315 + 0.2421 + 0.0059, time: 8.242013]
2023-05-19 11:18:36.554: epoch 93:	0.02698343  	0.19787741  	0.11018668  
2023-05-19 11:18:44.928: [iter 94 : loss : 0.2783 = 0.0303 + 0.2421 + 0.0060, time: 8.372002]
2023-05-19 11:18:45.204: epoch 94:	0.02695521  	0.19770901  	0.11029597  
2023-05-19 11:18:52.498: [iter 95 : loss : 0.2775 = 0.0296 + 0.2419 + 0.0060, time: 7.292993]
2023-05-19 11:18:52.661: epoch 95:	0.02692699  	0.19763987  	0.11022265  
2023-05-19 11:18:59.433: [iter 96 : loss : 0.2774 = 0.0296 + 0.2418 + 0.0060, time: 6.769029]
2023-05-19 11:18:59.598: epoch 96:	0.02695521  	0.19784562  	0.11029485  
2023-05-19 11:19:06.968: [iter 97 : loss : 0.2762 = 0.0285 + 0.2417 + 0.0061, time: 7.366993]
2023-05-19 11:19:07.131: epoch 97:	0.02691993  	0.19739126  	0.11025641  
2023-05-19 11:19:14.322: [iter 98 : loss : 0.2764 = 0.0287 + 0.2416 + 0.0061, time: 7.189026]
2023-05-19 11:19:14.629: epoch 98:	0.02699049  	0.19777906  	0.11044564  
2023-05-19 11:19:22.878: [iter 99 : loss : 0.2755 = 0.0279 + 0.2415 + 0.0062, time: 8.242017]
2023-05-19 11:19:23.173: epoch 99:	0.02692699  	0.19737177  	0.11044721  
2023-05-19 11:19:29.729: [iter 100 : loss : 0.2752 = 0.0276 + 0.2414 + 0.0062, time: 6.554127]
2023-05-19 11:19:29.893: epoch 100:	0.02691993  	0.19739856  	0.11052709  
2023-05-19 11:19:36.997: [iter 101 : loss : 0.2748 = 0.0272 + 0.2413 + 0.0063, time: 7.100042]
2023-05-19 11:19:37.166: epoch 101:	0.02692699  	0.19717714  	0.11046172  
2023-05-19 11:19:44.884: [iter 102 : loss : 0.2742 = 0.0266 + 0.2413 + 0.0063, time: 7.716993]
2023-05-19 11:19:45.050: epoch 102:	0.02694110  	0.19720173  	0.11050171  
2023-05-19 11:19:51.774: [iter 103 : loss : 0.2737 = 0.0262 + 0.2412 + 0.0063, time: 6.722022]
2023-05-19 11:19:51.935: epoch 103:	0.02691288  	0.19656517  	0.11030665  
2023-05-19 11:20:00.046: [iter 104 : loss : 0.2740 = 0.0266 + 0.2410 + 0.0064, time: 8.108993]
2023-05-19 11:20:00.349: epoch 104:	0.02691287  	0.19644144  	0.11039916  
2023-05-19 11:20:08.503: [iter 105 : loss : 0.2735 = 0.0262 + 0.2410 + 0.0064, time: 8.153439]
2023-05-19 11:20:08.797: epoch 105:	0.02689876  	0.19637319  	0.11032185  
2023-05-19 11:20:08.797: Early stopping is trigger at epoch: 105
2023-05-19 11:20:08.797: best_result@epoch 80:

2023-05-19 11:20:08.797: 		0.0269      	0.1982      	0.1090      
2023-05-19 11:21:16.683: my pid: 6840
2023-05-19 11:21:16.683: model: model.general_recommender.SGL
2023-05-19 11:21:16.683: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-19 11:21:16.683: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-19 11:21:20.761: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-19 11:21:27.809: [iter 1 : loss : 0.9318 = 0.6930 + 0.2389 + 0.0000, time: 7.047527]
2023-05-19 11:21:27.968: epoch 1:	0.00146063  	0.01038354  	0.00519509  
2023-05-19 11:21:27.968: Find a better model.
2023-05-19 11:21:35.963: [iter 2 : loss : 0.9316 = 0.6928 + 0.2387 + 0.0000, time: 7.993203]
2023-05-19 11:21:36.162: epoch 2:	0.00279424  	0.01964746  	0.01032857  
2023-05-19 11:21:36.163: Find a better model.
2023-05-19 11:21:43.957: [iter 3 : loss : 0.9314 = 0.6926 + 0.2388 + 0.0000, time: 7.790992]
2023-05-19 11:21:44.143: epoch 3:	0.00432541  	0.03033157  	0.01621298  
2023-05-19 11:21:44.143: Find a better model.
2023-05-19 11:21:51.304: [iter 4 : loss : 0.9314 = 0.6924 + 0.2390 + 0.0000, time: 7.158025]
2023-05-19 11:21:51.467: epoch 4:	0.00571546  	0.04155910  	0.02147043  
2023-05-19 11:21:51.468: Find a better model.
2023-05-19 11:21:59.667: [iter 5 : loss : 0.9313 = 0.6920 + 0.2392 + 0.0000, time: 8.197002]
2023-05-19 11:21:59.968: epoch 5:	0.00686560  	0.04834820  	0.02500837  
2023-05-19 11:21:59.968: Find a better model.
2023-05-19 11:22:07.374: [iter 6 : loss : 0.9311 = 0.6917 + 0.2394 + 0.0000, time: 7.404763]
2023-05-19 11:22:07.544: epoch 6:	0.00838971  	0.05966394  	0.02958132  
2023-05-19 11:22:07.545: Find a better model.
2023-05-19 11:22:14.860: [iter 7 : loss : 0.9307 = 0.6911 + 0.2396 + 0.0000, time: 7.313004]
2023-05-19 11:22:15.015: epoch 7:	0.00960339  	0.06820834  	0.03439871  
2023-05-19 11:22:15.015: Find a better model.
2023-05-19 11:22:21.681: [iter 8 : loss : 0.9303 = 0.6904 + 0.2399 + 0.0000, time: 6.664910]
2023-05-19 11:22:21.840: epoch 8:	0.01090178  	0.07856100  	0.03873756  
2023-05-19 11:22:21.840: Find a better model.
2023-05-19 11:22:29.000: [iter 9 : loss : 0.9296 = 0.6895 + 0.2401 + 0.0000, time: 7.158012]
2023-05-19 11:22:29.155: epoch 9:	0.01239070  	0.08938300  	0.04452292  
2023-05-19 11:22:29.155: Find a better model.
2023-05-19 11:22:37.017: [iter 10 : loss : 0.9285 = 0.6881 + 0.2404 + 0.0000, time: 7.857993]
2023-05-19 11:22:37.263: epoch 10:	0.01360440  	0.09777357  	0.04839029  
2023-05-19 11:22:37.264: Find a better model.
2023-05-19 11:22:45.060: [iter 11 : loss : 0.9270 = 0.6861 + 0.2408 + 0.0000, time: 7.792742]
2023-05-19 11:22:45.347: epoch 11:	0.01478988  	0.10592580  	0.05196536  
2023-05-19 11:22:45.347: Find a better model.
2023-05-19 11:22:52.284: [iter 12 : loss : 0.9243 = 0.6831 + 0.2412 + 0.0000, time: 6.936012]
2023-05-19 11:22:52.434: epoch 12:	0.01603885  	0.11551867  	0.05608582  
2023-05-19 11:22:52.434: Find a better model.
2023-05-19 11:22:58.840: [iter 13 : loss : 0.9205 = 0.6785 + 0.2419 + 0.0000, time: 6.405005]
2023-05-19 11:22:59.008: epoch 13:	0.01734428  	0.12583160  	0.06127381  
2023-05-19 11:22:59.008: Find a better model.
2023-05-19 11:23:06.216: [iter 14 : loss : 0.9137 = 0.6711 + 0.2425 + 0.0001, time: 7.206993]
2023-05-19 11:23:06.366: epoch 14:	0.01848743  	0.13478521  	0.06534862  
2023-05-19 11:23:06.366: Find a better model.
2023-05-19 11:23:12.812: [iter 15 : loss : 0.9037 = 0.6598 + 0.2438 + 0.0001, time: 6.445099]
2023-05-19 11:23:12.963: epoch 15:	0.01899551  	0.13870202  	0.06835251  
2023-05-19 11:23:12.964: Find a better model.
2023-05-19 11:23:20.890: [iter 16 : loss : 0.8878 = 0.6421 + 0.2457 + 0.0001, time: 7.923013]
2023-05-19 11:23:21.187: epoch 16:	0.01934833  	0.14139372  	0.07123085  
2023-05-19 11:23:21.187: Find a better model.
2023-05-19 11:23:27.451: [iter 17 : loss : 0.8644 = 0.6158 + 0.2484 + 0.0002, time: 6.263005]
2023-05-19 11:23:27.610: epoch 17:	0.01972233  	0.14396082  	0.07312602  
2023-05-19 11:23:27.610: Find a better model.
2023-05-19 11:23:34.694: [iter 18 : loss : 0.8321 = 0.5797 + 0.2521 + 0.0003, time: 7.080994]
2023-05-19 11:23:34.847: epoch 18:	0.01995520  	0.14580047  	0.07386860  
2023-05-19 11:23:34.847: Find a better model.
2023-05-19 11:23:41.465: [iter 19 : loss : 0.7894 = 0.5324 + 0.2567 + 0.0004, time: 6.617025]
2023-05-19 11:23:41.622: epoch 19:	0.02023041  	0.14856607  	0.07463343  
2023-05-19 11:23:41.622: Find a better model.
2023-05-19 11:23:48.650: [iter 20 : loss : 0.7427 = 0.4808 + 0.2614 + 0.0005, time: 7.027000]
2023-05-19 11:23:48.817: epoch 20:	0.02040682  	0.14949167  	0.07546980  
2023-05-19 11:23:48.817: Find a better model.
2023-05-19 11:23:56.654: [iter 21 : loss : 0.6945 = 0.4281 + 0.2657 + 0.0006, time: 7.833012]
2023-05-19 11:23:56.939: epoch 21:	0.02048444  	0.14996998  	0.07624645  
2023-05-19 11:23:56.939: Find a better model.
2023-05-19 11:24:04.866: [iter 22 : loss : 0.6501 = 0.3803 + 0.2691 + 0.0008, time: 7.923721]
2023-05-19 11:24:05.154: epoch 22:	0.02063968  	0.15107605  	0.07701518  
2023-05-19 11:24:05.154: Find a better model.
2023-05-19 11:24:11.999: [iter 23 : loss : 0.6113 = 0.3391 + 0.2713 + 0.0009, time: 6.842993]
2023-05-19 11:24:12.190: epoch 23:	0.02082315  	0.15272757  	0.07817141  
2023-05-19 11:24:12.191: Find a better model.
2023-05-19 11:24:18.624: [iter 24 : loss : 0.5797 = 0.3062 + 0.2725 + 0.0011, time: 6.430012]
2023-05-19 11:24:18.791: epoch 24:	0.02102779  	0.15452622  	0.07930660  
2023-05-19 11:24:18.791: Find a better model.
2023-05-19 11:24:26.000: [iter 25 : loss : 0.5526 = 0.2781 + 0.2732 + 0.0012, time: 7.207002]
2023-05-19 11:24:26.152: epoch 25:	0.02121126  	0.15584923  	0.08015624  
2023-05-19 11:24:26.153: Find a better model.
2023-05-19 11:24:32.813: [iter 26 : loss : 0.5309 = 0.2562 + 0.2734 + 0.0013, time: 6.659005]
2023-05-19 11:24:32.968: epoch 26:	0.02152175  	0.15817840  	0.08152234  
2023-05-19 11:24:32.968: Find a better model.
2023-05-19 11:24:40.901: [iter 27 : loss : 0.5103 = 0.2357 + 0.2731 + 0.0015, time: 7.932047]
2023-05-19 11:24:41.189: epoch 27:	0.02185340  	0.16018739  	0.08260362  
2023-05-19 11:24:41.189: Find a better model.
2023-05-19 11:24:47.467: [iter 28 : loss : 0.4938 = 0.2195 + 0.2727 + 0.0016, time: 6.276153]
2023-05-19 11:24:47.625: epoch 28:	0.02214272  	0.16283484  	0.08396567  
2023-05-19 11:24:47.625: Find a better model.
2023-05-19 11:24:54.629: [iter 29 : loss : 0.4796 = 0.2059 + 0.2720 + 0.0017, time: 7.001004]
2023-05-19 11:24:54.788: epoch 29:	0.02236852  	0.16492718  	0.08508535  
2023-05-19 11:24:54.788: Find a better model.
2023-05-19 11:25:01.423: [iter 30 : loss : 0.4651 = 0.1920 + 0.2713 + 0.0018, time: 6.632942]
2023-05-19 11:25:01.581: epoch 30:	0.02250259  	0.16568273  	0.08609866  
2023-05-19 11:25:01.581: Find a better model.
2023-05-19 11:25:08.632: [iter 31 : loss : 0.4540 = 0.1817 + 0.2705 + 0.0019, time: 7.050003]
2023-05-19 11:25:08.788: epoch 31:	0.02280603  	0.16814335  	0.08732315  
2023-05-19 11:25:08.789: Find a better model.
2023-05-19 11:25:16.547: [iter 32 : loss : 0.4426 = 0.1710 + 0.2696 + 0.0020, time: 7.752539]
2023-05-19 11:25:16.833: epoch 32:	0.02307418  	0.17011608  	0.08857527  
2023-05-19 11:25:16.833: Find a better model.
2023-05-19 11:25:24.716: [iter 33 : loss : 0.4342 = 0.1634 + 0.2688 + 0.0021, time: 7.880313]
2023-05-19 11:25:24.996: epoch 33:	0.02313063  	0.17017803  	0.08912622  
2023-05-19 11:25:24.996: Find a better model.
2023-05-19 11:25:32.115: [iter 34 : loss : 0.4253 = 0.1551 + 0.2680 + 0.0022, time: 7.117296]
2023-05-19 11:25:32.279: epoch 34:	0.02327882  	0.17117219  	0.08984619  
2023-05-19 11:25:32.280: Find a better model.
2023-05-19 11:25:38.576: [iter 35 : loss : 0.4179 = 0.1483 + 0.2674 + 0.0023, time: 6.295004]
2023-05-19 11:25:38.741: epoch 35:	0.02341995  	0.17205840  	0.09062526  
2023-05-19 11:25:38.741: Find a better model.
2023-05-19 11:25:45.769: [iter 36 : loss : 0.4108 = 0.1419 + 0.2665 + 0.0024, time: 7.026013]
2023-05-19 11:25:45.920: epoch 36:	0.02369515  	0.17405969  	0.09145810  
2023-05-19 11:25:45.920: Find a better model.
2023-05-19 11:25:52.398: [iter 37 : loss : 0.4032 = 0.1350 + 0.2657 + 0.0025, time: 6.477170]
2023-05-19 11:25:52.551: epoch 37:	0.02384334  	0.17530805  	0.09219883  
2023-05-19 11:25:52.552: Find a better model.
2023-05-19 11:26:00.574: [iter 38 : loss : 0.3984 = 0.1310 + 0.2648 + 0.0026, time: 8.020049]
2023-05-19 11:26:00.856: epoch 38:	0.02405504  	0.17686723  	0.09330061  
2023-05-19 11:26:00.856: Find a better model.
2023-05-19 11:26:07.247: [iter 39 : loss : 0.3914 = 0.1246 + 0.2641 + 0.0026, time: 6.388999]
2023-05-19 11:26:07.404: epoch 39:	0.02426673  	0.17858723  	0.09416775  
2023-05-19 11:26:07.404: Find a better model.
2023-05-19 11:26:14.380: [iter 40 : loss : 0.3859 = 0.1198 + 0.2634 + 0.0027, time: 6.973994]
2023-05-19 11:26:14.539: epoch 40:	0.02442197  	0.17938687  	0.09468566  
2023-05-19 11:26:14.539: Find a better model.
2023-05-19 11:26:20.994: [iter 41 : loss : 0.3815 = 0.1159 + 0.2629 + 0.0028, time: 6.453994]
2023-05-19 11:26:21.154: epoch 41:	0.02449960  	0.17992797  	0.09520353  
2023-05-19 11:26:21.154: Find a better model.
2023-05-19 11:26:28.179: [iter 42 : loss : 0.3769 = 0.1118 + 0.2622 + 0.0029, time: 7.022917]
2023-05-19 11:26:28.342: epoch 42:	0.02464072  	0.18123288  	0.09596888  
2023-05-19 11:26:28.342: Find a better model.
2023-05-19 11:26:36.244: [iter 43 : loss : 0.3715 = 0.1071 + 0.2615 + 0.0030, time: 7.898993]
2023-05-19 11:26:36.525: epoch 43:	0.02463367  	0.18125851  	0.09635980  
2023-05-19 11:26:36.526: Find a better model.
2023-05-19 11:26:44.411: [iter 44 : loss : 0.3667 = 0.1028 + 0.2609 + 0.0030, time: 7.883564]
2023-05-19 11:26:44.691: epoch 44:	0.02481008  	0.18250363  	0.09715714  
2023-05-19 11:26:44.691: Find a better model.
2023-05-19 11:26:51.303: [iter 45 : loss : 0.3629 = 0.0994 + 0.2604 + 0.0031, time: 6.610994]
2023-05-19 11:26:51.528: epoch 45:	0.02486653  	0.18289876  	0.09765288  
2023-05-19 11:26:51.529: Find a better model.
2023-05-19 11:26:57.960: [iter 46 : loss : 0.3594 = 0.0964 + 0.2599 + 0.0032, time: 6.427994]
2023-05-19 11:26:58.110: epoch 46:	0.02496532  	0.18361320  	0.09834993  
2023-05-19 11:26:58.110: Find a better model.
2023-05-19 11:27:04.992: [iter 47 : loss : 0.3568 = 0.0943 + 0.2592 + 0.0033, time: 6.880007]
2023-05-19 11:27:05.144: epoch 47:	0.02506411  	0.18454385  	0.09871184  
2023-05-19 11:27:05.144: Find a better model.
2023-05-19 11:27:11.539: [iter 48 : loss : 0.3523 = 0.0903 + 0.2588 + 0.0033, time: 6.394006]
2023-05-19 11:27:11.689: epoch 48:	0.02514173  	0.18516086  	0.09933252  
2023-05-19 11:27:11.689: Find a better model.
2023-05-19 11:27:19.483: [iter 49 : loss : 0.3484 = 0.0865 + 0.2584 + 0.0034, time: 7.783015]
2023-05-19 11:27:19.766: epoch 49:	0.02523346  	0.18539271  	0.09974998  
2023-05-19 11:27:19.766: Find a better model.
2023-05-19 11:27:27.686: [iter 50 : loss : 0.3460 = 0.0847 + 0.2578 + 0.0035, time: 7.917147]
2023-05-19 11:27:27.941: epoch 50:	0.02534637  	0.18651950  	0.10044678  
2023-05-19 11:27:27.941: Find a better model.
2023-05-19 11:27:34.588: [iter 51 : loss : 0.3423 = 0.0814 + 0.2574 + 0.0035, time: 6.643993]
2023-05-19 11:27:34.744: epoch 51:	0.02545926  	0.18747115  	0.10091307  
2023-05-19 11:27:34.744: Find a better model.
2023-05-19 11:27:40.963: [iter 52 : loss : 0.3410 = 0.0804 + 0.2570 + 0.0036, time: 6.218003]
2023-05-19 11:27:41.126: epoch 52:	0.02550159  	0.18707797  	0.10132623  
2023-05-19 11:27:47.939: [iter 53 : loss : 0.3380 = 0.0777 + 0.2566 + 0.0037, time: 6.810163]
2023-05-19 11:27:48.092: epoch 53:	0.02568506  	0.18861605  	0.10210011  
2023-05-19 11:27:48.093: Find a better model.
2023-05-19 11:27:54.619: [iter 54 : loss : 0.3353 = 0.0753 + 0.2562 + 0.0037, time: 6.524004]
2023-05-19 11:27:54.871: epoch 54:	0.02581207  	0.18973935  	0.10280513  
2023-05-19 11:27:54.871: Find a better model.
2023-05-19 11:28:02.733: [iter 55 : loss : 0.3330 = 0.0734 + 0.2558 + 0.0038, time: 7.859102]
2023-05-19 11:28:03.009: epoch 55:	0.02584030  	0.19012009  	0.10306533  
2023-05-19 11:28:03.009: Find a better model.
2023-05-19 11:28:09.101: [iter 56 : loss : 0.3306 = 0.0713 + 0.2554 + 0.0039, time: 6.091004]
2023-05-19 11:28:09.268: epoch 56:	0.02591792  	0.19078892  	0.10348400  
2023-05-19 11:28:09.268: Find a better model.
2023-05-19 11:28:16.177: [iter 57 : loss : 0.3284 = 0.0695 + 0.2550 + 0.0039, time: 6.907030]
2023-05-19 11:28:16.365: epoch 57:	0.02596732  	0.19151971  	0.10377461  
2023-05-19 11:28:16.365: Find a better model.
2023-05-19 11:28:22.955: [iter 58 : loss : 0.3259 = 0.0671 + 0.2548 + 0.0040, time: 6.588993]
2023-05-19 11:28:23.114: epoch 58:	0.02603788  	0.19187668  	0.10431280  
2023-05-19 11:28:23.114: Find a better model.
2023-05-19 11:28:30.185: [iter 59 : loss : 0.3240 = 0.0656 + 0.2544 + 0.0040, time: 7.069993]
2023-05-19 11:28:30.390: epoch 59:	0.02614373  	0.19250293  	0.10488988  
2023-05-19 11:28:30.390: Find a better model.
2023-05-19 11:28:38.278: [iter 60 : loss : 0.3223 = 0.0642 + 0.2541 + 0.0041, time: 7.885388]
2023-05-19 11:28:38.565: epoch 60:	0.02615784  	0.19253400  	0.10511321  
2023-05-19 11:28:38.565: Find a better model.
2023-05-19 11:28:46.528: [iter 61 : loss : 0.3206 = 0.0627 + 0.2538 + 0.0042, time: 7.960992]
2023-05-19 11:28:46.809: epoch 61:	0.02620018  	0.19248867  	0.10517560  
2023-05-19 11:28:53.979: [iter 62 : loss : 0.3188 = 0.0611 + 0.2535 + 0.0042, time: 7.167004]
2023-05-19 11:28:54.130: epoch 62:	0.02627075  	0.19323887  	0.10547305  
2023-05-19 11:28:54.131: Find a better model.
2023-05-19 11:29:00.503: [iter 63 : loss : 0.3170 = 0.0595 + 0.2532 + 0.0043, time: 6.370994]
2023-05-19 11:29:00.670: epoch 63:	0.02632014  	0.19353193  	0.10563280  
2023-05-19 11:29:00.670: Find a better model.
2023-05-19 11:29:07.905: [iter 64 : loss : 0.3156 = 0.0583 + 0.2529 + 0.0043, time: 7.232993]
2023-05-19 11:29:08.057: epoch 64:	0.02641188  	0.19441898  	0.10622280  
2023-05-19 11:29:08.058: Find a better model.
2023-05-19 11:29:14.517: [iter 65 : loss : 0.3142 = 0.0572 + 0.2526 + 0.0044, time: 6.457042]
2023-05-19 11:29:14.682: epoch 65:	0.02646128  	0.19502044  	0.10654685  
2023-05-19 11:29:14.682: Find a better model.
2023-05-19 11:29:22.755: [iter 66 : loss : 0.3123 = 0.0555 + 0.2524 + 0.0044, time: 8.071154]
2023-05-19 11:29:23.042: epoch 66:	0.02645422  	0.19478722  	0.10657132  
2023-05-19 11:29:29.533: [iter 67 : loss : 0.3108 = 0.0541 + 0.2522 + 0.0045, time: 6.489994]
2023-05-19 11:29:29.693: epoch 67:	0.02653889  	0.19564608  	0.10692709  
2023-05-19 11:29:29.693: Find a better model.
2023-05-19 11:29:36.725: [iter 68 : loss : 0.3098 = 0.0535 + 0.2518 + 0.0046, time: 7.030993]
2023-05-19 11:29:36.888: epoch 68:	0.02666590  	0.19646683  	0.10739896  
2023-05-19 11:29:36.888: Find a better model.
2023-05-19 11:29:43.337: [iter 69 : loss : 0.3076 = 0.0514 + 0.2516 + 0.0046, time: 6.447995]
2023-05-19 11:29:43.496: epoch 69:	0.02661651  	0.19604801  	0.10738461  
2023-05-19 11:29:50.543: [iter 70 : loss : 0.3065 = 0.0503 + 0.2515 + 0.0047, time: 7.045993]
2023-05-19 11:29:50.710: epoch 70:	0.02668002  	0.19629325  	0.10767534  
2023-05-19 11:29:58.639: [iter 71 : loss : 0.3051 = 0.0491 + 0.2513 + 0.0047, time: 7.926849]
2023-05-19 11:29:58.920: epoch 71:	0.02674352  	0.19667500  	0.10789012  
2023-05-19 11:29:58.920: Find a better model.
2023-05-19 11:30:06.798: [iter 72 : loss : 0.3044 = 0.0486 + 0.2511 + 0.0048, time: 7.873830]
2023-05-19 11:30:07.076: epoch 72:	0.02675763  	0.19670062  	0.10795529  
2023-05-19 11:30:07.076: Find a better model.
2023-05-19 11:30:13.636: [iter 73 : loss : 0.3028 = 0.0471 + 0.2508 + 0.0048, time: 6.559005]
2023-05-19 11:30:13.779: epoch 73:	0.02678586  	0.19691870  	0.10810342  
2023-05-19 11:30:13.779: Find a better model.
2023-05-19 11:30:20.296: [iter 74 : loss : 0.3018 = 0.0463 + 0.2507 + 0.0049, time: 6.516004]
2023-05-19 11:30:20.449: epoch 74:	0.02678586  	0.19693217  	0.10838829  
2023-05-19 11:30:20.449: Find a better model.
2023-05-19 11:30:27.463: [iter 75 : loss : 0.3006 = 0.0452 + 0.2505 + 0.0049, time: 7.012993]
2023-05-19 11:30:27.616: epoch 75:	0.02687759  	0.19762091  	0.10872596  
2023-05-19 11:30:27.616: Find a better model.
2023-05-19 11:30:34.076: [iter 76 : loss : 0.2997 = 0.0445 + 0.2502 + 0.0050, time: 6.459045]
2023-05-19 11:30:34.230: epoch 76:	0.02689170  	0.19777943  	0.10877937  
2023-05-19 11:30:34.230: Find a better model.
2023-05-19 11:30:41.938: [iter 77 : loss : 0.2985 = 0.0434 + 0.2501 + 0.0050, time: 7.704002]
2023-05-19 11:30:42.219: epoch 77:	0.02696227  	0.19840601  	0.10911277  
2023-05-19 11:30:42.219: Find a better model.
2023-05-19 11:30:50.013: [iter 78 : loss : 0.2975 = 0.0425 + 0.2499 + 0.0051, time: 7.791002]
2023-05-19 11:30:50.300: epoch 78:	0.02706812  	0.19937922  	0.10956466  
2023-05-19 11:30:50.300: Find a better model.
2023-05-19 11:30:57.059: [iter 79 : loss : 0.2967 = 0.0417 + 0.2498 + 0.0051, time: 6.757497]
2023-05-19 11:30:57.241: epoch 79:	0.02700461  	0.19882348  	0.10947543  
2023-05-19 11:31:03.647: [iter 80 : loss : 0.2957 = 0.0408 + 0.2497 + 0.0052, time: 6.403994]
2023-05-19 11:31:03.808: epoch 80:	0.02706106  	0.19944596  	0.10962878  
2023-05-19 11:31:03.809: Find a better model.
2023-05-19 11:31:10.822: [iter 81 : loss : 0.2952 = 0.0404 + 0.2495 + 0.0052, time: 7.010993]
2023-05-19 11:31:10.974: epoch 81:	0.02705400  	0.19946362  	0.10973094  
2023-05-19 11:31:10.974: Find a better model.
2023-05-19 11:31:17.510: [iter 82 : loss : 0.2940 = 0.0394 + 0.2493 + 0.0053, time: 6.533994]
2023-05-19 11:31:17.766: epoch 82:	0.02707517  	0.19939013  	0.10998002  
2023-05-19 11:31:25.564: [iter 83 : loss : 0.2932 = 0.0387 + 0.2492 + 0.0053, time: 7.794628]
2023-05-19 11:31:25.850: epoch 83:	0.02709634  	0.19910592  	0.10991383  
2023-05-19 11:31:31.985: [iter 84 : loss : 0.2928 = 0.0384 + 0.2490 + 0.0054, time: 6.133995]
2023-05-19 11:31:32.149: epoch 84:	0.02713162  	0.19955540  	0.11018603  
2023-05-19 11:31:32.150: Find a better model.
2023-05-19 11:31:39.097: [iter 85 : loss : 0.2920 = 0.0377 + 0.2488 + 0.0054, time: 6.945993]
2023-05-19 11:31:39.303: epoch 85:	0.02715279  	0.19955173  	0.11017750  
2023-05-19 11:31:45.675: [iter 86 : loss : 0.2916 = 0.0374 + 0.2488 + 0.0055, time: 6.369994]
2023-05-19 11:31:45.837: epoch 86:	0.02720220  	0.20031300  	0.11045811  
2023-05-19 11:31:45.837: Find a better model.
2023-05-19 11:31:52.677: [iter 87 : loss : 0.2896 = 0.0355 + 0.2486 + 0.0055, time: 6.838968]
2023-05-19 11:31:52.834: epoch 87:	0.02720926  	0.20047903  	0.11061275  
2023-05-19 11:31:52.834: Find a better model.
2023-05-19 11:32:00.683: [iter 88 : loss : 0.2891 = 0.0350 + 0.2486 + 0.0056, time: 7.844889]
2023-05-19 11:32:00.966: epoch 88:	0.02715986  	0.19994448  	0.11048907  
2023-05-19 11:32:08.863: [iter 89 : loss : 0.2882 = 0.0343 + 0.2482 + 0.0056, time: 7.893992]
2023-05-19 11:32:09.142: epoch 89:	0.02719514  	0.20037706  	0.11077929  
2023-05-19 11:32:16.107: [iter 90 : loss : 0.2886 = 0.0347 + 0.2483 + 0.0057, time: 6.964330]
2023-05-19 11:32:16.297: epoch 90:	0.02724454  	0.20064753  	0.11085737  
2023-05-19 11:32:16.297: Find a better model.
2023-05-19 11:32:22.658: [iter 91 : loss : 0.2877 = 0.0338 + 0.2481 + 0.0057, time: 6.358994]
2023-05-19 11:32:22.811: epoch 91:	0.02728687  	0.20056313  	0.11082861  
2023-05-19 11:32:30.234: [iter 92 : loss : 0.2866 = 0.0329 + 0.2480 + 0.0057, time: 7.420992]
2023-05-19 11:32:30.386: epoch 92:	0.02715986  	0.19981201  	0.11072505  
2023-05-19 11:32:36.843: [iter 93 : loss : 0.2866 = 0.0330 + 0.2478 + 0.0058, time: 6.456016]
2023-05-19 11:32:36.995: epoch 93:	0.02715280  	0.19959778  	0.11080476  
2023-05-19 11:32:44.888: [iter 94 : loss : 0.2852 = 0.0316 + 0.2477 + 0.0058, time: 7.889996]
2023-05-19 11:32:45.186: epoch 94:	0.02713868  	0.19931492  	0.11075304  
2023-05-19 11:32:52.203: [iter 95 : loss : 0.2847 = 0.0312 + 0.2476 + 0.0059, time: 7.015994]
2023-05-19 11:32:52.366: epoch 95:	0.02713163  	0.19910917  	0.11068288  
2023-05-19 11:32:59.481: [iter 96 : loss : 0.2841 = 0.0307 + 0.2475 + 0.0059, time: 7.113994]
2023-05-19 11:32:59.646: epoch 96:	0.02723042  	0.20003040  	0.11095896  
2023-05-19 11:33:06.209: [iter 97 : loss : 0.2831 = 0.0297 + 0.2475 + 0.0060, time: 6.562076]
2023-05-19 11:33:06.368: epoch 97:	0.02720925  	0.19993830  	0.11107251  
2023-05-19 11:33:13.282: [iter 98 : loss : 0.2833 = 0.0300 + 0.2473 + 0.0060, time: 6.911624]
2023-05-19 11:33:13.428: epoch 98:	0.02723042  	0.20003340  	0.11091860  
2023-05-19 11:33:21.261: [iter 99 : loss : 0.2826 = 0.0294 + 0.2472 + 0.0060, time: 7.828006]
2023-05-19 11:33:21.540: epoch 99:	0.02715280  	0.19958295  	0.11078622  
2023-05-19 11:33:29.439: [iter 100 : loss : 0.2821 = 0.0289 + 0.2471 + 0.0061, time: 7.893992]
2023-05-19 11:33:29.724: epoch 100:	0.02720926  	0.19987863  	0.11089648  
2023-05-19 11:33:36.210: [iter 101 : loss : 0.2818 = 0.0286 + 0.2471 + 0.0061, time: 6.484309]
2023-05-19 11:33:36.360: epoch 101:	0.02720220  	0.19976494  	0.11083611  
2023-05-19 11:33:43.022: [iter 102 : loss : 0.2809 = 0.0277 + 0.2470 + 0.0062, time: 6.660993]
2023-05-19 11:33:43.178: epoch 102:	0.02724453  	0.20000111  	0.11098281  
2023-05-19 11:33:50.249: [iter 103 : loss : 0.2806 = 0.0275 + 0.2470 + 0.0062, time: 7.070003]
2023-05-19 11:33:50.400: epoch 103:	0.02722337  	0.19930537  	0.11073534  
2023-05-19 11:33:56.964: [iter 104 : loss : 0.2810 = 0.0280 + 0.2468 + 0.0062, time: 6.562310]
2023-05-19 11:33:57.116: epoch 104:	0.02725864  	0.19971544  	0.11098073  
2023-05-19 11:34:04.835: [iter 105 : loss : 0.2803 = 0.0274 + 0.2466 + 0.0063, time: 7.716869]
2023-05-19 11:34:05.116: epoch 105:	0.02723042  	0.19984171  	0.11085165  
2023-05-19 11:34:12.977: [iter 106 : loss : 0.2793 = 0.0265 + 0.2465 + 0.0063, time: 7.858277]
2023-05-19 11:34:13.260: epoch 106:	0.02720925  	0.19951245  	0.11072300  
2023-05-19 11:34:19.989: [iter 107 : loss : 0.2790 = 0.0262 + 0.2465 + 0.0064, time: 6.727993]
2023-05-19 11:34:20.204: epoch 107:	0.02725158  	0.19972476  	0.11088222  
2023-05-19 11:34:26.429: [iter 108 : loss : 0.2788 = 0.0260 + 0.2464 + 0.0064, time: 6.221071]
2023-05-19 11:34:26.586: epoch 108:	0.02722335  	0.19927320  	0.11082201  
2023-05-19 11:34:33.593: [iter 109 : loss : 0.2773 = 0.0245 + 0.2464 + 0.0064, time: 7.005994]
2023-05-19 11:34:33.747: epoch 109:	0.02729392  	0.20006405  	0.11100075  
2023-05-19 11:34:40.236: [iter 110 : loss : 0.2773 = 0.0246 + 0.2463 + 0.0065, time: 6.487993]
2023-05-19 11:34:40.381: epoch 110:	0.02726569  	0.19980089  	0.11084634  
2023-05-19 11:34:48.136: [iter 111 : loss : 0.2773 = 0.0245 + 0.2463 + 0.0065, time: 7.753378]
2023-05-19 11:34:48.383: epoch 111:	0.02727275  	0.19988270  	0.11093424  
2023-05-19 11:34:54.508: [iter 112 : loss : 0.2769 = 0.0242 + 0.2462 + 0.0065, time: 6.123994]
2023-05-19 11:34:54.670: epoch 112:	0.02728686  	0.19968273  	0.11067948  
2023-05-19 11:35:01.642: [iter 113 : loss : 0.2771 = 0.0243 + 0.2461 + 0.0066, time: 6.969993]
2023-05-19 11:35:01.806: epoch 113:	0.02730803  	0.19972436  	0.11071230  
2023-05-19 11:35:08.226: [iter 114 : loss : 0.2758 = 0.0232 + 0.2460 + 0.0066, time: 6.418994]
2023-05-19 11:35:08.384: epoch 114:	0.02723040  	0.19908178  	0.11062087  
2023-05-19 11:35:15.241: [iter 115 : loss : 0.2762 = 0.0236 + 0.2459 + 0.0067, time: 6.855994]
2023-05-19 11:35:15.415: epoch 115:	0.02722335  	0.19894278  	0.11051954  
2023-05-19 11:35:15.415: Early stopping is trigger at epoch: 115
2023-05-19 11:35:15.415: best_result@epoch 90:

2023-05-19 11:35:15.415: 		0.0272      	0.2006      	0.1109      
2023-05-23 10:22:32.879: my pid: 7116
2023-05-23 10:22:32.879: model: model.general_recommender.SGL
2023-05-23 10:22:32.879: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 10:22:32.879: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 10:22:36.315: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 10:22:57.170: my pid: 11496
2023-05-23 10:22:57.170: model: model.general_recommender.SGL
2023-05-23 10:22:57.170: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 10:22:57.170: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 10:23:00.392: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 10:23:07.606: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.213155]
2023-05-23 10:23:07.761: epoch 1:	0.00219447  	0.01496531  	0.00748102  
2023-05-23 10:23:07.761: Find a better model.
2023-05-23 10:23:15.147: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.384244]
2023-05-23 10:23:15.352: epoch 2:	0.00450887  	0.03260074  	0.01587814  
2023-05-23 10:23:15.352: Find a better model.
2023-05-23 10:23:22.534: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.181580]
2023-05-23 10:23:22.721: epoch 3:	0.00751476  	0.05354359  	0.02572613  
2023-05-23 10:23:22.721: Find a better model.
2023-05-23 10:23:29.749: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.025455]
2023-05-23 10:23:29.912: epoch 4:	0.01105702  	0.07865824  	0.03831830  
2023-05-23 10:23:29.912: Find a better model.
2023-05-23 10:23:36.764: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 6.851223]
2023-05-23 10:23:36.924: epoch 5:	0.01448645  	0.10407475  	0.05032710  
2023-05-23 10:23:36.924: Find a better model.
2023-05-23 10:23:43.565: [iter 6 : loss : 0.7640 = 0.6839 + 0.0800 + 0.0000, time: 6.639421]
2023-05-23 10:23:43.719: epoch 6:	0.01720316  	0.12390268  	0.06132286  
2023-05-23 10:23:43.719: Find a better model.
2023-05-23 10:23:50.321: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.600591]
2023-05-23 10:23:50.463: epoch 7:	0.01851566  	0.13476665  	0.06762696  
2023-05-23 10:23:50.463: Find a better model.
2023-05-23 10:23:56.941: [iter 8 : loss : 0.7244 = 0.6399 + 0.0844 + 0.0001, time: 6.476993]
2023-05-23 10:23:57.083: epoch 8:	0.01879792  	0.13887651  	0.06950285  
2023-05-23 10:23:57.083: Find a better model.
2023-05-23 10:24:03.554: [iter 9 : loss : 0.6724 = 0.5829 + 0.0893 + 0.0002, time: 6.469919]
2023-05-23 10:24:03.711: epoch 9:	0.01862857  	0.13838257  	0.06898044  
2023-05-23 10:24:10.132: [iter 10 : loss : 0.6010 = 0.5062 + 0.0945 + 0.0003, time: 6.419252]
2023-05-23 10:24:10.287: epoch 10:	0.01850860  	0.13749495  	0.06824411  
2023-05-23 10:24:16.720: [iter 11 : loss : 0.5294 = 0.4306 + 0.0984 + 0.0005, time: 6.432268]
2023-05-23 10:24:16.872: epoch 11:	0.01845216  	0.13686992  	0.06811326  
2023-05-23 10:24:23.335: [iter 12 : loss : 0.4717 = 0.3705 + 0.1006 + 0.0006, time: 6.460319]
2023-05-23 10:24:23.487: epoch 12:	0.01841688  	0.13648726  	0.06841396  
2023-05-23 10:24:29.926: [iter 13 : loss : 0.4303 = 0.3278 + 0.1017 + 0.0008, time: 6.437617]
2023-05-23 10:24:30.068: epoch 13:	0.01868503  	0.13860039  	0.06965493  
2023-05-23 10:24:36.528: [iter 14 : loss : 0.3983 = 0.2952 + 0.1022 + 0.0009, time: 6.458498]
2023-05-23 10:24:36.669: epoch 14:	0.01883321  	0.13973816  	0.07057494  
2023-05-23 10:24:36.670: Find a better model.
2023-05-23 10:24:43.130: [iter 15 : loss : 0.3758 = 0.2724 + 0.1023 + 0.0010, time: 6.458934]
2023-05-23 10:24:43.288: epoch 15:	0.01910841  	0.14122047  	0.07152203  
2023-05-23 10:24:43.288: Find a better model.
2023-05-23 10:24:49.728: [iter 16 : loss : 0.3561 = 0.2527 + 0.1022 + 0.0012, time: 6.439131]
2023-05-23 10:24:49.879: epoch 16:	0.01940479  	0.14313924  	0.07263112  
2023-05-23 10:24:49.880: Find a better model.
2023-05-23 10:24:56.322: [iter 17 : loss : 0.3414 = 0.2382 + 0.1019 + 0.0013, time: 6.439714]
2023-05-23 10:24:56.473: epoch 17:	0.01955298  	0.14444721  	0.07345884  
2023-05-23 10:24:56.473: Find a better model.
2023-05-23 10:25:03.102: [iter 18 : loss : 0.3272 = 0.2242 + 0.1017 + 0.0014, time: 6.627341]
2023-05-23 10:25:03.262: epoch 18:	0.01978585  	0.14606181  	0.07422780  
2023-05-23 10:25:03.262: Find a better model.
2023-05-23 10:25:09.713: [iter 19 : loss : 0.3140 = 0.2113 + 0.1013 + 0.0015, time: 6.449601]
2023-05-23 10:25:09.866: epoch 19:	0.01992698  	0.14689828  	0.07479379  
2023-05-23 10:25:09.866: Find a better model.
2023-05-23 10:25:16.307: [iter 20 : loss : 0.3050 = 0.2025 + 0.1009 + 0.0015, time: 6.440269]
2023-05-23 10:25:16.460: epoch 20:	0.02010340  	0.14820848  	0.07556479  
2023-05-23 10:25:16.460: Find a better model.
2023-05-23 10:25:23.072: [iter 21 : loss : 0.2959 = 0.1938 + 0.1005 + 0.0016, time: 6.609732]
2023-05-23 10:25:23.214: epoch 21:	0.02037154  	0.15006965  	0.07646536  
2023-05-23 10:25:23.214: Find a better model.
2023-05-23 10:25:29.708: [iter 22 : loss : 0.2879 = 0.1862 + 0.1000 + 0.0017, time: 6.492860]
2023-05-23 10:25:29.850: epoch 22:	0.02044916  	0.15091182  	0.07708754  
2023-05-23 10:25:29.850: Find a better model.
2023-05-23 10:25:36.303: [iter 23 : loss : 0.2800 = 0.1785 + 0.0997 + 0.0018, time: 6.451658]
2023-05-23 10:25:36.444: epoch 23:	0.02068908  	0.15252203  	0.07796793  
2023-05-23 10:25:36.444: Find a better model.
2023-05-23 10:25:43.091: [iter 24 : loss : 0.2738 = 0.1728 + 0.0992 + 0.0018, time: 6.646172]
2023-05-23 10:25:43.241: epoch 24:	0.02083021  	0.15373340  	0.07857785  
2023-05-23 10:25:43.241: Find a better model.
2023-05-23 10:25:49.696: [iter 25 : loss : 0.2671 = 0.1664 + 0.0988 + 0.0019, time: 6.453202]
2023-05-23 10:25:49.849: epoch 25:	0.02099956  	0.15440534  	0.07918990  
2023-05-23 10:25:49.849: Find a better model.
2023-05-23 10:25:56.312: [iter 26 : loss : 0.2638 = 0.1634 + 0.0984 + 0.0020, time: 6.461298]
2023-05-23 10:25:56.464: epoch 26:	0.02126066  	0.15653497  	0.08002759  
2023-05-23 10:25:56.465: Find a better model.
2023-05-23 10:26:02.906: [iter 27 : loss : 0.2563 = 0.1563 + 0.0979 + 0.0021, time: 6.439243]
2023-05-23 10:26:03.057: epoch 27:	0.02145119  	0.15753983  	0.08081672  
2023-05-23 10:26:03.057: Find a better model.
2023-05-23 10:26:09.486: [iter 28 : loss : 0.2515 = 0.1519 + 0.0976 + 0.0021, time: 6.426877]
2023-05-23 10:26:09.638: epoch 28:	0.02162054  	0.15884486  	0.08168899  
2023-05-23 10:26:09.638: Find a better model.
2023-05-23 10:26:16.097: [iter 29 : loss : 0.2473 = 0.1480 + 0.0972 + 0.0022, time: 6.457085]
2023-05-23 10:26:16.250: epoch 29:	0.02180401  	0.16027670  	0.08250630  
2023-05-23 10:26:16.251: Find a better model.
2023-05-23 10:26:22.687: [iter 30 : loss : 0.2407 = 0.1417 + 0.0968 + 0.0022, time: 6.435143]
2023-05-23 10:26:22.840: epoch 30:	0.02195925  	0.16134718  	0.08312695  
2023-05-23 10:26:22.840: Find a better model.
2023-05-23 10:26:29.267: [iter 31 : loss : 0.2374 = 0.1387 + 0.0964 + 0.0023, time: 6.425788]
2023-05-23 10:26:29.409: epoch 31:	0.02217800  	0.16285877  	0.08388746  
2023-05-23 10:26:29.409: Find a better model.
2023-05-23 10:26:35.696: [iter 32 : loss : 0.2319 = 0.1335 + 0.0961 + 0.0024, time: 6.284003]
2023-05-23 10:26:35.847: epoch 32:	0.02229091  	0.16391738  	0.08458436  
2023-05-23 10:26:35.847: Find a better model.
2023-05-23 10:26:42.304: [iter 33 : loss : 0.2294 = 0.1313 + 0.0957 + 0.0024, time: 6.455432]
2023-05-23 10:26:42.458: epoch 33:	0.02233324  	0.16378936  	0.08486261  
2023-05-23 10:26:48.879: [iter 34 : loss : 0.2253 = 0.1274 + 0.0954 + 0.0025, time: 6.420342]
2023-05-23 10:26:49.023: epoch 34:	0.02248143  	0.16524568  	0.08575539  
2023-05-23 10:26:49.023: Find a better model.
2023-05-23 10:26:55.486: [iter 35 : loss : 0.2219 = 0.1243 + 0.0951 + 0.0025, time: 6.460789]
2023-05-23 10:26:55.639: epoch 35:	0.02268606  	0.16680916  	0.08645907  
2023-05-23 10:26:55.639: Find a better model.
2023-05-23 10:27:02.258: [iter 36 : loss : 0.2185 = 0.1212 + 0.0948 + 0.0026, time: 6.617472]
2023-05-23 10:27:02.415: epoch 36:	0.02274252  	0.16747569  	0.08710002  
2023-05-23 10:27:02.415: Find a better model.
2023-05-23 10:27:09.084: [iter 37 : loss : 0.2147 = 0.1176 + 0.0944 + 0.0026, time: 6.668408]
2023-05-23 10:27:09.238: epoch 37:	0.02289776  	0.16867183  	0.08777628  
2023-05-23 10:27:09.238: Find a better model.
2023-05-23 10:27:15.664: [iter 38 : loss : 0.2134 = 0.1165 + 0.0942 + 0.0027, time: 6.425187]
2023-05-23 10:27:15.818: epoch 38:	0.02295421  	0.16928858  	0.08799481  
2023-05-23 10:27:15.818: Find a better model.
2023-05-23 10:27:22.269: [iter 39 : loss : 0.2089 = 0.1122 + 0.0939 + 0.0028, time: 6.449722]
2023-05-23 10:27:22.424: epoch 39:	0.02301772  	0.16931660  	0.08849691  
2023-05-23 10:27:22.424: Find a better model.
2023-05-23 10:27:28.867: [iter 40 : loss : 0.2055 = 0.1092 + 0.0935 + 0.0028, time: 6.441833]
2023-05-23 10:27:29.012: epoch 40:	0.02310239  	0.16996214  	0.08891060  
2023-05-23 10:27:29.012: Find a better model.
2023-05-23 10:27:35.482: [iter 41 : loss : 0.2042 = 0.1080 + 0.0933 + 0.0029, time: 6.467959]
2023-05-23 10:27:35.625: epoch 41:	0.02318707  	0.17069615  	0.08936232  
2023-05-23 10:27:35.625: Find a better model.
2023-05-23 10:27:42.229: [iter 42 : loss : 0.2021 = 0.1061 + 0.0930 + 0.0029, time: 6.602602]
2023-05-23 10:27:42.373: epoch 42:	0.02334937  	0.17194477  	0.09002267  
2023-05-23 10:27:42.374: Find a better model.
2023-05-23 10:27:48.850: [iter 43 : loss : 0.1980 = 0.1023 + 0.0928 + 0.0030, time: 6.474849]
2023-05-23 10:27:48.994: epoch 43:	0.02341289  	0.17228547  	0.09060477  
2023-05-23 10:27:48.994: Find a better model.
2023-05-23 10:27:55.460: [iter 44 : loss : 0.1947 = 0.0992 + 0.0925 + 0.0030, time: 6.465288]
2023-05-23 10:27:55.613: epoch 44:	0.02355401  	0.17344868  	0.09131846  
2023-05-23 10:27:55.613: Find a better model.
2023-05-23 10:28:02.052: [iter 45 : loss : 0.1925 = 0.0971 + 0.0923 + 0.0031, time: 6.436147]
2023-05-23 10:28:02.190: epoch 45:	0.02363163  	0.17410374  	0.09194092  
2023-05-23 10:28:02.191: Find a better model.
2023-05-23 10:28:08.629: [iter 46 : loss : 0.1900 = 0.0949 + 0.0920 + 0.0031, time: 6.436907]
2023-05-23 10:28:08.779: epoch 46:	0.02380805  	0.17565490  	0.09253009  
2023-05-23 10:28:08.779: Find a better model.
2023-05-23 10:28:15.250: [iter 47 : loss : 0.1895 = 0.0945 + 0.0918 + 0.0032, time: 6.469644]
2023-05-23 10:28:15.405: epoch 47:	0.02385039  	0.17577286  	0.09285864  
2023-05-23 10:28:15.409: Find a better model.
2023-05-23 10:28:21.854: [iter 48 : loss : 0.1856 = 0.0908 + 0.0916 + 0.0032, time: 6.442808]
2023-05-23 10:28:22.005: epoch 48:	0.02384333  	0.17581546  	0.09304612  
2023-05-23 10:28:22.005: Find a better model.
2023-05-23 10:28:28.446: [iter 49 : loss : 0.1826 = 0.0880 + 0.0913 + 0.0033, time: 6.440147]
2023-05-23 10:28:28.602: epoch 49:	0.02393506  	0.17638996  	0.09350349  
2023-05-23 10:28:28.602: Find a better model.
2023-05-23 10:28:35.226: [iter 50 : loss : 0.1818 = 0.0873 + 0.0912 + 0.0033, time: 6.623020]
2023-05-23 10:28:35.384: epoch 50:	0.02399152  	0.17695977  	0.09394597  
2023-05-23 10:28:35.384: Find a better model.
2023-05-23 10:28:41.831: [iter 51 : loss : 0.1788 = 0.0845 + 0.0910 + 0.0034, time: 6.445962]
2023-05-23 10:28:41.973: epoch 51:	0.02408325  	0.17786019  	0.09433331  
2023-05-23 10:28:41.974: Find a better model.
2023-05-23 10:28:48.627: [iter 52 : loss : 0.1787 = 0.0845 + 0.0908 + 0.0034, time: 6.651456]
2023-05-23 10:28:48.781: epoch 52:	0.02418204  	0.17861386  	0.09508760  
2023-05-23 10:28:48.781: Find a better model.
2023-05-23 10:28:55.248: [iter 53 : loss : 0.1766 = 0.0826 + 0.0906 + 0.0035, time: 6.466062]
2023-05-23 10:28:55.405: epoch 53:	0.02432317  	0.17947309  	0.09535567  
2023-05-23 10:28:55.405: Find a better model.
2023-05-23 10:29:01.836: [iter 54 : loss : 0.1748 = 0.0809 + 0.0904 + 0.0035, time: 6.429640]
2023-05-23 10:29:01.988: epoch 54:	0.02440784  	0.17997016  	0.09576814  
2023-05-23 10:29:01.988: Find a better model.
2023-05-23 10:29:08.444: [iter 55 : loss : 0.1729 = 0.0791 + 0.0902 + 0.0035, time: 6.455122]
2023-05-23 10:29:08.598: epoch 55:	0.02437961  	0.18001673  	0.09595073  
2023-05-23 10:29:08.598: Find a better model.
2023-05-23 10:29:15.032: [iter 56 : loss : 0.1710 = 0.0774 + 0.0900 + 0.0036, time: 6.433188]
2023-05-23 10:29:15.188: epoch 56:	0.02440784  	0.18003163  	0.09616116  
2023-05-23 10:29:15.188: Find a better model.
2023-05-23 10:29:21.629: [iter 57 : loss : 0.1692 = 0.0757 + 0.0899 + 0.0036, time: 6.439327]
2023-05-23 10:29:21.782: epoch 57:	0.02450663  	0.18095824  	0.09664267  
2023-05-23 10:29:21.782: Find a better model.
2023-05-23 10:29:28.233: [iter 58 : loss : 0.1675 = 0.0742 + 0.0897 + 0.0037, time: 6.450241]
2023-05-23 10:29:28.390: epoch 58:	0.02452075  	0.18118314  	0.09699208  
2023-05-23 10:29:28.390: Find a better model.
2023-05-23 10:29:34.800: [iter 59 : loss : 0.1663 = 0.0732 + 0.0895 + 0.0037, time: 6.408983]
2023-05-23 10:29:34.943: epoch 59:	0.02462660  	0.18175729  	0.09724008  
2023-05-23 10:29:34.943: Find a better model.
2023-05-23 10:29:41.425: [iter 60 : loss : 0.1647 = 0.0716 + 0.0894 + 0.0038, time: 6.481467]
2023-05-23 10:29:41.579: epoch 60:	0.02477478  	0.18331970  	0.09813381  
2023-05-23 10:29:41.579: Find a better model.
2023-05-23 10:29:48.022: [iter 61 : loss : 0.1635 = 0.0705 + 0.0892 + 0.0038, time: 6.441725]
2023-05-23 10:29:48.178: epoch 61:	0.02478890  	0.18326527  	0.09840510  
2023-05-23 10:29:54.636: [iter 62 : loss : 0.1621 = 0.0692 + 0.0890 + 0.0039, time: 6.456981]
2023-05-23 10:29:54.792: epoch 62:	0.02475361  	0.18323268  	0.09843725  
2023-05-23 10:30:01.231: [iter 63 : loss : 0.1607 = 0.0680 + 0.0888 + 0.0039, time: 6.437989]
2023-05-23 10:30:01.374: epoch 63:	0.02481006  	0.18361074  	0.09876278  
2023-05-23 10:30:01.374: Find a better model.
2023-05-23 10:30:07.800: [iter 64 : loss : 0.1595 = 0.0669 + 0.0887 + 0.0039, time: 6.423141]
2023-05-23 10:30:07.942: epoch 64:	0.02486651  	0.18431261  	0.09913419  
2023-05-23 10:30:07.943: Find a better model.
2023-05-23 10:30:14.424: [iter 65 : loss : 0.1585 = 0.0660 + 0.0885 + 0.0040, time: 6.479380]
2023-05-23 10:30:14.575: epoch 65:	0.02492296  	0.18465033  	0.09960341  
2023-05-23 10:30:14.575: Find a better model.
2023-05-23 10:30:21.006: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.428790]
2023-05-23 10:30:21.156: epoch 66:	0.02495118  	0.18462418  	0.09970965  
2023-05-23 10:30:27.609: [iter 67 : loss : 0.1554 = 0.0631 + 0.0882 + 0.0041, time: 6.451066]
2023-05-23 10:30:27.761: epoch 67:	0.02499352  	0.18502405  	0.09990944  
2023-05-23 10:30:27.761: Find a better model.
2023-05-23 10:30:34.208: [iter 68 : loss : 0.1551 = 0.0629 + 0.0881 + 0.0041, time: 6.445955]
2023-05-23 10:30:34.362: epoch 68:	0.02507820  	0.18568143  	0.10038646  
2023-05-23 10:30:34.362: Find a better model.
2023-05-23 10:30:40.783: [iter 69 : loss : 0.1532 = 0.0611 + 0.0880 + 0.0042, time: 6.419342]
2023-05-23 10:30:40.940: epoch 69:	0.02514877  	0.18610674  	0.10071371  
2023-05-23 10:30:40.940: Find a better model.
2023-05-23 10:30:47.406: [iter 70 : loss : 0.1517 = 0.0596 + 0.0879 + 0.0042, time: 6.465484]
2023-05-23 10:30:47.560: epoch 70:	0.02524050  	0.18669811  	0.10124697  
2023-05-23 10:30:47.560: Find a better model.
2023-05-23 10:30:53.988: [iter 71 : loss : 0.1503 = 0.0583 + 0.0877 + 0.0042, time: 6.426793]
2023-05-23 10:30:54.142: epoch 71:	0.02521227  	0.18670790  	0.10127712  
2023-05-23 10:30:54.142: Find a better model.
2023-05-23 10:31:00.598: [iter 72 : loss : 0.1498 = 0.0578 + 0.0877 + 0.0043, time: 6.454743]
2023-05-23 10:31:00.740: epoch 72:	0.02531106  	0.18752110  	0.10167784  
2023-05-23 10:31:00.740: Find a better model.
2023-05-23 10:31:07.189: [iter 73 : loss : 0.1485 = 0.0567 + 0.0875 + 0.0043, time: 6.446872]
2023-05-23 10:31:07.345: epoch 73:	0.02529695  	0.18759274  	0.10186799  
2023-05-23 10:31:07.345: Find a better model.
2023-05-23 10:31:13.784: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.436710]
2023-05-23 10:31:13.939: epoch 74:	0.02535341  	0.18787012  	0.10213735  
2023-05-23 10:31:13.939: Find a better model.
2023-05-23 10:31:20.393: [iter 75 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 6.452330]
2023-05-23 10:31:20.552: epoch 75:	0.02545925  	0.18882735  	0.10250088  
2023-05-23 10:31:20.552: Find a better model.
2023-05-23 10:31:27.173: [iter 76 : loss : 0.1457 = 0.0541 + 0.0872 + 0.0044, time: 6.619730]
2023-05-23 10:31:27.325: epoch 76:	0.02550865  	0.18925975  	0.10286850  
2023-05-23 10:31:27.325: Find a better model.
2023-05-23 10:31:33.768: [iter 77 : loss : 0.1448 = 0.0533 + 0.0871 + 0.0045, time: 6.440969]
2023-05-23 10:31:33.909: epoch 77:	0.02555804  	0.18939911  	0.10314842  
2023-05-23 10:31:33.910: Find a better model.
2023-05-23 10:31:40.559: [iter 78 : loss : 0.1440 = 0.0525 + 0.0870 + 0.0045, time: 6.648114]
2023-05-23 10:31:40.714: epoch 78:	0.02560038  	0.18975727  	0.10351176  
2023-05-23 10:31:40.714: Find a better model.
2023-05-23 10:31:47.357: [iter 79 : loss : 0.1425 = 0.0511 + 0.0868 + 0.0046, time: 6.642131]
2023-05-23 10:31:47.516: epoch 79:	0.02557215  	0.18919539  	0.10347496  
2023-05-23 10:31:53.960: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.443253]
2023-05-23 10:31:54.101: epoch 80:	0.02567799  	0.18994208  	0.10376848  
2023-05-23 10:31:54.101: Find a better model.
2023-05-23 10:32:00.573: [iter 81 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 6.469066]
2023-05-23 10:32:00.716: epoch 81:	0.02567094  	0.18953492  	0.10389230  
2023-05-23 10:32:07.165: [iter 82 : loss : 0.1403 = 0.0491 + 0.0866 + 0.0047, time: 6.446384]
2023-05-23 10:32:07.304: epoch 82:	0.02569211  	0.18996041  	0.10424467  
2023-05-23 10:32:07.305: Find a better model.
2023-05-23 10:32:13.767: [iter 83 : loss : 0.1395 = 0.0483 + 0.0865 + 0.0047, time: 6.461218]
2023-05-23 10:32:13.920: epoch 83:	0.02574856  	0.19052882  	0.10441539  
2023-05-23 10:32:13.920: Find a better model.
2023-05-23 10:32:20.379: [iter 84 : loss : 0.1394 = 0.0483 + 0.0864 + 0.0048, time: 6.457734]
2023-05-23 10:32:20.535: epoch 84:	0.02577679  	0.19083849  	0.10454544  
2023-05-23 10:32:20.535: Find a better model.
2023-05-23 10:32:26.956: [iter 85 : loss : 0.1385 = 0.0474 + 0.0863 + 0.0048, time: 6.418970]
2023-05-23 10:32:27.110: epoch 85:	0.02586853  	0.19171010  	0.10494760  
2023-05-23 10:32:27.111: Find a better model.
2023-05-23 10:32:33.549: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.436500]
2023-05-23 10:32:33.702: epoch 86:	0.02587558  	0.19188835  	0.10530102  
2023-05-23 10:32:33.702: Find a better model.
2023-05-23 10:32:40.159: [iter 87 : loss : 0.1356 = 0.0446 + 0.0861 + 0.0049, time: 6.456171]
2023-05-23 10:32:40.315: epoch 87:	0.02583324  	0.19171403  	0.10536170  
2023-05-23 10:32:46.764: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.447830]
2023-05-23 10:32:46.916: epoch 88:	0.02582618  	0.19161096  	0.10538793  
2023-05-23 10:32:53.353: [iter 89 : loss : 0.1347 = 0.0439 + 0.0859 + 0.0050, time: 6.434841]
2023-05-23 10:32:53.512: epoch 89:	0.02582618  	0.19144329  	0.10538241  
2023-05-23 10:32:59.947: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.434142]
2023-05-23 10:33:00.101: epoch 90:	0.02597437  	0.19243182  	0.10581627  
2023-05-23 10:33:00.102: Find a better model.
2023-05-23 10:33:06.547: [iter 91 : loss : 0.1337 = 0.0430 + 0.0857 + 0.0050, time: 6.444620]
2023-05-23 10:33:06.699: epoch 91:	0.02608022  	0.19323111  	0.10616956  
2023-05-23 10:33:06.699: Find a better model.
2023-05-23 10:33:13.163: [iter 92 : loss : 0.1329 = 0.0422 + 0.0856 + 0.0051, time: 6.462950]
2023-05-23 10:33:13.317: epoch 92:	0.02608727  	0.19315986  	0.10628635  
2023-05-23 10:33:19.750: [iter 93 : loss : 0.1333 = 0.0427 + 0.0856 + 0.0051, time: 6.431674]
2023-05-23 10:33:19.902: epoch 93:	0.02605905  	0.19311354  	0.10627341  
2023-05-23 10:33:26.343: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.439942]
2023-05-23 10:33:26.504: epoch 94:	0.02603788  	0.19269854  	0.10622407  
2023-05-23 10:33:32.929: [iter 95 : loss : 0.1306 = 0.0400 + 0.0854 + 0.0052, time: 6.423474]
2023-05-23 10:33:33.086: epoch 95:	0.02607316  	0.19294307  	0.10643047  
2023-05-23 10:33:39.515: [iter 96 : loss : 0.1306 = 0.0400 + 0.0854 + 0.0052, time: 6.428268]
2023-05-23 10:33:39.656: epoch 96:	0.02610844  	0.19293974  	0.10647980  
2023-05-23 10:33:45.928: [iter 97 : loss : 0.1289 = 0.0385 + 0.0852 + 0.0052, time: 6.269958]
2023-05-23 10:33:46.070: epoch 97:	0.02612961  	0.19342087  	0.10647827  
2023-05-23 10:33:46.070: Find a better model.
2023-05-23 10:33:52.330: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.259264]
2023-05-23 10:33:52.473: epoch 98:	0.02613667  	0.19346215  	0.10667180  
2023-05-23 10:33:52.473: Find a better model.
2023-05-23 10:33:58.755: [iter 99 : loss : 0.1285 = 0.0381 + 0.0851 + 0.0053, time: 6.279788]
2023-05-23 10:33:58.911: epoch 99:	0.02623546  	0.19414806  	0.10711538  
2023-05-23 10:33:58.911: Find a better model.
2023-05-23 10:34:05.318: [iter 100 : loss : 0.1281 = 0.0377 + 0.0850 + 0.0054, time: 6.406255]
2023-05-23 10:34:05.460: epoch 100:	0.02624252  	0.19410077  	0.10712471  
2023-05-23 10:34:11.724: [iter 101 : loss : 0.1276 = 0.0372 + 0.0850 + 0.0054, time: 6.260808]
2023-05-23 10:34:11.881: epoch 101:	0.02618607  	0.19373509  	0.10700625  
2023-05-23 10:34:18.308: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.426002]
2023-05-23 10:34:18.450: epoch 102:	0.02622135  	0.19413018  	0.10710574  
2023-05-23 10:34:24.729: [iter 103 : loss : 0.1264 = 0.0361 + 0.0848 + 0.0055, time: 6.276708]
2023-05-23 10:34:24.867: epoch 103:	0.02622840  	0.19422662  	0.10702184  
2023-05-23 10:34:24.867: Find a better model.
2023-05-23 10:34:31.295: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.426028]
2023-05-23 10:34:31.434: epoch 104:	0.02623546  	0.19417456  	0.10710137  
2023-05-23 10:34:37.914: [iter 105 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 6.479334]
2023-05-23 10:34:38.067: epoch 105:	0.02632013  	0.19496851  	0.10749390  
2023-05-23 10:34:38.067: Find a better model.
2023-05-23 10:34:44.518: [iter 106 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 6.449610]
2023-05-23 10:34:44.677: epoch 106:	0.02635542  	0.19518578  	0.10746876  
2023-05-23 10:34:44.678: Find a better model.
2023-05-23 10:34:50.924: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.245456]
2023-05-23 10:34:51.080: epoch 107:	0.02628485  	0.19433624  	0.10727468  
2023-05-23 10:34:57.310: [iter 108 : loss : 0.1244 = 0.0342 + 0.0846 + 0.0056, time: 6.227784]
2023-05-23 10:34:57.450: epoch 108:	0.02632719  	0.19459181  	0.10761749  
2023-05-23 10:35:03.719: [iter 109 : loss : 0.1232 = 0.0330 + 0.0845 + 0.0057, time: 6.268018]
2023-05-23 10:35:03.874: epoch 109:	0.02634130  	0.19478881  	0.10769986  
2023-05-23 10:35:10.310: [iter 110 : loss : 0.1226 = 0.0324 + 0.0845 + 0.0057, time: 6.435223]
2023-05-23 10:35:10.464: epoch 110:	0.02640481  	0.19517668  	0.10754643  
2023-05-23 10:35:16.706: [iter 111 : loss : 0.1226 = 0.0325 + 0.0844 + 0.0057, time: 6.241301]
2023-05-23 10:35:16.847: epoch 111:	0.02641892  	0.19567034  	0.10763628  
2023-05-23 10:35:16.848: Find a better model.
2023-05-23 10:35:23.290: [iter 112 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.440109]
2023-05-23 10:35:23.432: epoch 112:	0.02636953  	0.19540073  	0.10767949  
2023-05-23 10:35:29.696: [iter 113 : loss : 0.1223 = 0.0323 + 0.0843 + 0.0058, time: 6.262604]
2023-05-23 10:35:29.838: epoch 113:	0.02638365  	0.19523986  	0.10763821  
2023-05-23 10:35:36.296: [iter 114 : loss : 0.1215 = 0.0315 + 0.0842 + 0.0058, time: 6.457002]
2023-05-23 10:35:36.454: epoch 114:	0.02638365  	0.19566113  	0.10770228  
2023-05-23 10:35:42.694: [iter 115 : loss : 0.1210 = 0.0310 + 0.0842 + 0.0059, time: 6.239892]
2023-05-23 10:35:42.835: epoch 115:	0.02641893  	0.19604790  	0.10782196  
2023-05-23 10:35:42.836: Find a better model.
2023-05-23 10:35:49.287: [iter 116 : loss : 0.1205 = 0.0305 + 0.0841 + 0.0059, time: 6.448704]
2023-05-23 10:35:49.442: epoch 116:	0.02643304  	0.19586755  	0.10778053  
2023-05-23 10:35:55.892: [iter 117 : loss : 0.1202 = 0.0302 + 0.0841 + 0.0059, time: 6.447492]
2023-05-23 10:35:56.046: epoch 117:	0.02631308  	0.19487911  	0.10748003  
2023-05-23 10:36:02.485: [iter 118 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0060, time: 6.436989]
2023-05-23 10:36:02.643: epoch 118:	0.02636248  	0.19516174  	0.10774532  
2023-05-23 10:36:09.081: [iter 119 : loss : 0.1194 = 0.0294 + 0.0839 + 0.0060, time: 6.435995]
2023-05-23 10:36:09.222: epoch 119:	0.02634837  	0.19521669  	0.10771304  
2023-05-23 10:36:15.689: [iter 120 : loss : 0.1196 = 0.0297 + 0.0839 + 0.0060, time: 6.466050]
2023-05-23 10:36:15.847: epoch 120:	0.02636248  	0.19523561  	0.10781680  
2023-05-23 10:36:22.303: [iter 121 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0061, time: 6.455544]
2023-05-23 10:36:22.457: epoch 121:	0.02634837  	0.19509174  	0.10784267  
2023-05-23 10:36:28.885: [iter 122 : loss : 0.1186 = 0.0288 + 0.0838 + 0.0061, time: 6.426027]
2023-05-23 10:36:29.039: epoch 122:	0.02632720  	0.19491860  	0.10782340  
2023-05-23 10:36:35.477: [iter 123 : loss : 0.1185 = 0.0286 + 0.0838 + 0.0061, time: 6.435145]
2023-05-23 10:36:35.633: epoch 123:	0.02626369  	0.19471167  	0.10771310  
2023-05-23 10:36:42.089: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.454379]
2023-05-23 10:36:42.243: epoch 124:	0.02629192  	0.19507563  	0.10779690  
2023-05-23 10:36:48.683: [iter 125 : loss : 0.1170 = 0.0272 + 0.0837 + 0.0062, time: 6.437094]
2023-05-23 10:36:48.835: epoch 125:	0.02633426  	0.19498892  	0.10785729  
2023-05-23 10:36:55.274: [iter 126 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0062, time: 6.438413]
2023-05-23 10:36:55.429: epoch 126:	0.02630603  	0.19533892  	0.10803797  
2023-05-23 10:37:01.667: [iter 127 : loss : 0.1163 = 0.0265 + 0.0836 + 0.0062, time: 6.236669]
2023-05-23 10:37:01.809: epoch 127:	0.02641188  	0.19596669  	0.10835758  
2023-05-23 10:37:08.066: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.256065]
2023-05-23 10:37:08.210: epoch 128:	0.02641188  	0.19586672  	0.10829908  
2023-05-23 10:37:14.482: [iter 129 : loss : 0.1165 = 0.0267 + 0.0835 + 0.0063, time: 6.271135]
2023-05-23 10:37:14.623: epoch 129:	0.02641894  	0.19572686  	0.10834001  
2023-05-23 10:37:20.870: [iter 130 : loss : 0.1165 = 0.0267 + 0.0834 + 0.0063, time: 6.244792]
2023-05-23 10:37:21.025: epoch 130:	0.02641188  	0.19565102  	0.10845412  
2023-05-23 10:37:27.450: [iter 131 : loss : 0.1156 = 0.0258 + 0.0834 + 0.0064, time: 6.423501]
2023-05-23 10:37:27.592: epoch 131:	0.02639071  	0.19573005  	0.10854689  
2023-05-23 10:37:33.864: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.270499]
2023-05-23 10:37:34.017: epoch 132:	0.02644011  	0.19615470  	0.10875936  
2023-05-23 10:37:34.018: Find a better model.
2023-05-23 10:37:40.265: [iter 133 : loss : 0.1145 = 0.0247 + 0.0833 + 0.0064, time: 6.245112]
2023-05-23 10:37:40.406: epoch 133:	0.02642599  	0.19573353  	0.10871930  
2023-05-23 10:37:46.678: [iter 134 : loss : 0.1152 = 0.0255 + 0.0833 + 0.0064, time: 6.270801]
2023-05-23 10:37:46.832: epoch 134:	0.02641188  	0.19579181  	0.10886282  
2023-05-23 10:37:53.066: [iter 135 : loss : 0.1150 = 0.0253 + 0.0832 + 0.0065, time: 6.233214]
2023-05-23 10:37:53.219: epoch 135:	0.02648245  	0.19633362  	0.10904266  
2023-05-23 10:37:53.219: Find a better model.
2023-05-23 10:37:59.459: [iter 136 : loss : 0.1146 = 0.0249 + 0.0832 + 0.0065, time: 6.239356]
2023-05-23 10:37:59.613: epoch 136:	0.02636248  	0.19513454  	0.10873459  
2023-05-23 10:38:05.861: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.247271]
2023-05-23 10:38:06.016: epoch 137:	0.02638365  	0.19522220  	0.10855449  
2023-05-23 10:38:12.246: [iter 138 : loss : 0.1140 = 0.0243 + 0.0831 + 0.0066, time: 6.228805]
2023-05-23 10:38:12.388: epoch 138:	0.02630603  	0.19435556  	0.10828874  
2023-05-23 10:38:18.643: [iter 139 : loss : 0.1137 = 0.0240 + 0.0831 + 0.0066, time: 6.253556]
2023-05-23 10:38:18.797: epoch 139:	0.02631309  	0.19433214  	0.10843049  
2023-05-23 10:38:25.044: [iter 140 : loss : 0.1131 = 0.0234 + 0.0830 + 0.0066, time: 6.244828]
2023-05-23 10:38:25.188: epoch 140:	0.02635542  	0.19464660  	0.10866207  
2023-05-23 10:38:31.447: [iter 141 : loss : 0.1137 = 0.0240 + 0.0830 + 0.0066, time: 6.257788]
2023-05-23 10:38:31.602: epoch 141:	0.02634837  	0.19475988  	0.10874350  
2023-05-23 10:38:37.842: [iter 142 : loss : 0.1128 = 0.0231 + 0.0830 + 0.0067, time: 6.238996]
2023-05-23 10:38:37.996: epoch 142:	0.02642599  	0.19523944  	0.10886835  
2023-05-23 10:38:44.241: [iter 143 : loss : 0.1130 = 0.0234 + 0.0829 + 0.0067, time: 6.244006]
2023-05-23 10:38:44.395: epoch 143:	0.02641188  	0.19539982  	0.10897110  
2023-05-23 10:38:50.637: [iter 144 : loss : 0.1122 = 0.0226 + 0.0829 + 0.0067, time: 6.240906]
2023-05-23 10:38:50.791: epoch 144:	0.02644716  	0.19544739  	0.10913327  
2023-05-23 10:38:57.056: [iter 145 : loss : 0.1123 = 0.0227 + 0.0829 + 0.0068, time: 6.263597]
2023-05-23 10:38:57.209: epoch 145:	0.02646833  	0.19562741  	0.10921341  
2023-05-23 10:39:03.437: [iter 146 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0068, time: 6.226904]
2023-05-23 10:39:03.591: epoch 146:	0.02646128  	0.19585565  	0.10906826  
2023-05-23 10:39:09.836: [iter 147 : loss : 0.1123 = 0.0227 + 0.0828 + 0.0068, time: 6.244849]
2023-05-23 10:39:09.993: epoch 147:	0.02653184  	0.19613092  	0.10937246  
2023-05-23 10:39:16.235: [iter 148 : loss : 0.1111 = 0.0215 + 0.0828 + 0.0068, time: 6.240398]
2023-05-23 10:39:16.387: epoch 148:	0.02657418  	0.19637801  	0.10953997  
2023-05-23 10:39:16.387: Find a better model.
2023-05-23 10:39:22.627: [iter 149 : loss : 0.1114 = 0.0218 + 0.0827 + 0.0069, time: 6.238963]
2023-05-23 10:39:22.783: epoch 149:	0.02655301  	0.19618298  	0.10963072  
2023-05-23 10:39:29.013: [iter 150 : loss : 0.1109 = 0.0213 + 0.0827 + 0.0069, time: 6.228668]
2023-05-23 10:39:29.157: epoch 150:	0.02648244  	0.19565302  	0.10935033  
2023-05-23 10:39:35.419: [iter 151 : loss : 0.1111 = 0.0215 + 0.0827 + 0.0069, time: 6.260119]
2023-05-23 10:39:35.572: epoch 151:	0.02649656  	0.19586597  	0.10944873  
2023-05-23 10:39:41.819: [iter 152 : loss : 0.1104 = 0.0209 + 0.0826 + 0.0069, time: 6.245332]
2023-05-23 10:39:41.963: epoch 152:	0.02652478  	0.19612734  	0.10942905  
2023-05-23 10:39:48.197: [iter 153 : loss : 0.1094 = 0.0198 + 0.0826 + 0.0070, time: 6.232169]
2023-05-23 10:39:48.351: epoch 153:	0.02644717  	0.19547828  	0.10933179  
2023-05-23 10:39:54.858: [iter 154 : loss : 0.1103 = 0.0207 + 0.0826 + 0.0070, time: 6.506046]
2023-05-23 10:39:55.021: epoch 154:	0.02648951  	0.19573396  	0.10957053  
2023-05-23 10:40:01.215: [iter 155 : loss : 0.1107 = 0.0211 + 0.0826 + 0.0070, time: 6.192777]
2023-05-23 10:40:01.357: epoch 155:	0.02646128  	0.19538212  	0.10937937  
2023-05-23 10:40:07.663: [iter 156 : loss : 0.1100 = 0.0204 + 0.0825 + 0.0070, time: 6.305099]
2023-05-23 10:40:07.821: epoch 156:	0.02653184  	0.19597274  	0.10943419  
2023-05-23 10:40:14.201: [iter 157 : loss : 0.1099 = 0.0204 + 0.0825 + 0.0071, time: 6.378617]
2023-05-23 10:40:14.354: epoch 157:	0.02644716  	0.19545785  	0.10935736  
2023-05-23 10:40:20.623: [iter 158 : loss : 0.1092 = 0.0196 + 0.0825 + 0.0071, time: 6.268134]
2023-05-23 10:40:20.779: epoch 158:	0.02646128  	0.19521572  	0.10942965  
2023-05-23 10:40:27.010: [iter 159 : loss : 0.1094 = 0.0198 + 0.0824 + 0.0071, time: 6.228839]
2023-05-23 10:40:27.162: epoch 159:	0.02646833  	0.19556305  	0.10941932  
2023-05-23 10:40:33.398: [iter 160 : loss : 0.1092 = 0.0196 + 0.0824 + 0.0071, time: 6.234859]
2023-05-23 10:40:33.549: epoch 160:	0.02634837  	0.19477709  	0.10907757  
2023-05-23 10:40:39.804: [iter 161 : loss : 0.1086 = 0.0191 + 0.0824 + 0.0072, time: 6.253739]
2023-05-23 10:40:39.962: epoch 161:	0.02644011  	0.19530267  	0.10912907  
2023-05-23 10:40:46.189: [iter 162 : loss : 0.1081 = 0.0186 + 0.0823 + 0.0072, time: 6.224946]
2023-05-23 10:40:46.343: epoch 162:	0.02639072  	0.19503050  	0.10918958  
2023-05-23 10:40:52.613: [iter 163 : loss : 0.1086 = 0.0190 + 0.0823 + 0.0072, time: 6.268208]
2023-05-23 10:40:52.765: epoch 163:	0.02642599  	0.19516133  	0.10912133  
2023-05-23 10:40:58.990: [iter 164 : loss : 0.1085 = 0.0190 + 0.0823 + 0.0072, time: 6.223797]
2023-05-23 10:40:59.144: epoch 164:	0.02632720  	0.19463459  	0.10903699  
2023-05-23 10:41:05.396: [iter 165 : loss : 0.1082 = 0.0186 + 0.0823 + 0.0073, time: 6.250350]
2023-05-23 10:41:05.551: epoch 165:	0.02628486  	0.19436286  	0.10894073  
2023-05-23 10:41:11.784: [iter 166 : loss : 0.1080 = 0.0185 + 0.0823 + 0.0073, time: 6.232046]
2023-05-23 10:41:11.938: epoch 166:	0.02624253  	0.19423573  	0.10883279  
2023-05-23 10:41:18.191: [iter 167 : loss : 0.1082 = 0.0187 + 0.0822 + 0.0073, time: 6.251874]
2023-05-23 10:41:18.346: epoch 167:	0.02628487  	0.19442256  	0.10889976  
2023-05-23 10:41:24.567: [iter 168 : loss : 0.1078 = 0.0183 + 0.0822 + 0.0073, time: 6.219389]
2023-05-23 10:41:24.720: epoch 168:	0.02625665  	0.19440201  	0.10883843  
2023-05-23 10:41:30.975: [iter 169 : loss : 0.1081 = 0.0185 + 0.0822 + 0.0074, time: 6.253809]
2023-05-23 10:41:31.131: epoch 169:	0.02617196  	0.19335997  	0.10857707  
2023-05-23 10:41:37.367: [iter 170 : loss : 0.1074 = 0.0179 + 0.0821 + 0.0074, time: 6.233942]
2023-05-23 10:41:37.520: epoch 170:	0.02614373  	0.19310217  	0.10847367  
2023-05-23 10:41:43.777: [iter 171 : loss : 0.1077 = 0.0182 + 0.0821 + 0.0074, time: 6.255373]
2023-05-23 10:41:43.919: epoch 171:	0.02615785  	0.19342375  	0.10869838  
2023-05-23 10:41:50.182: [iter 172 : loss : 0.1067 = 0.0172 + 0.0821 + 0.0074, time: 6.262266]
2023-05-23 10:41:50.325: epoch 172:	0.02617902  	0.19356567  	0.10873103  
2023-05-23 10:41:56.576: [iter 173 : loss : 0.1076 = 0.0181 + 0.0821 + 0.0075, time: 6.249945]
2023-05-23 10:41:56.731: epoch 173:	0.02618608  	0.19353132  	0.10881574  
2023-05-23 10:41:56.731: Early stopping is trigger at epoch: 173
2023-05-23 10:41:56.731: best_result@epoch 148:

2023-05-23 10:41:56.731: 		0.0266      	0.1964      	0.1095      
2023-05-23 10:42:45.233: my pid: 2832
2023-05-23 10:42:45.233: model: model.general_recommender.SGL
2023-05-23 10:42:45.233: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 10:42:45.233: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 10:42:48.475: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 10:42:55.618: [iter 1 : loss : 0.7726 = 0.6930 + 0.0797 + 0.0000, time: 7.143009]
2023-05-23 10:42:55.774: epoch 1:	0.00213802  	0.01480261  	0.00758521  
2023-05-23 10:42:55.775: Find a better model.
2023-05-23 10:43:02.961: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.184046]
2023-05-23 10:43:03.164: epoch 2:	0.00449476  	0.03232634  	0.01647924  
2023-05-23 10:43:03.165: Find a better model.
2023-05-23 10:43:10.172: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.006220]
2023-05-23 10:43:10.350: epoch 3:	0.00791695  	0.05585476  	0.02787890  
2023-05-23 10:43:10.350: Find a better model.
2023-05-23 10:43:17.178: [iter 4 : loss : 0.7713 = 0.6914 + 0.0800 + 0.0000, time: 6.826383]
2023-05-23 10:43:17.337: epoch 4:	0.01164976  	0.08183579  	0.03991807  
2023-05-23 10:43:17.337: Find a better model.
2023-05-23 10:43:24.174: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 6.835621]
2023-05-23 10:43:24.325: epoch 5:	0.01528383  	0.10885779  	0.05302422  
2023-05-23 10:43:24.325: Find a better model.
2023-05-23 10:43:30.947: [iter 6 : loss : 0.7660 = 0.6850 + 0.0809 + 0.0000, time: 6.621070]
2023-05-23 10:43:31.099: epoch 6:	0.01747838  	0.12563334  	0.06237180  
2023-05-23 10:43:31.099: Find a better model.
2023-05-23 10:43:37.533: [iter 7 : loss : 0.7561 = 0.6739 + 0.0822 + 0.0000, time: 6.433309]
2023-05-23 10:43:37.688: epoch 7:	0.01874854  	0.13652717  	0.06791873  
2023-05-23 10:43:37.688: Find a better model.
2023-05-23 10:43:44.150: [iter 8 : loss : 0.7333 = 0.6482 + 0.0849 + 0.0001, time: 6.460804]
2023-05-23 10:43:44.304: epoch 8:	0.01904491  	0.13989700  	0.06953277  
2023-05-23 10:43:44.304: Find a better model.
2023-05-23 10:43:50.732: [iter 9 : loss : 0.6874 = 0.5976 + 0.0896 + 0.0002, time: 6.426831]
2023-05-23 10:43:50.884: epoch 9:	0.01857212  	0.13723305  	0.06869281  
2023-05-23 10:43:57.141: [iter 10 : loss : 0.6191 = 0.5240 + 0.0948 + 0.0003, time: 6.255542]
2023-05-23 10:43:57.294: epoch 10:	0.01846627  	0.13660975  	0.06781724  
2023-05-23 10:44:03.529: [iter 11 : loss : 0.5461 = 0.4466 + 0.0990 + 0.0005, time: 6.234008]
2023-05-23 10:44:03.681: epoch 11:	0.01826869  	0.13503055  	0.06699735  
2023-05-23 10:44:09.929: [iter 12 : loss : 0.4852 = 0.3831 + 0.1015 + 0.0006, time: 6.246953]
2023-05-23 10:44:10.085: epoch 12:	0.01833221  	0.13566184  	0.06763762  
2023-05-23 10:44:16.153: [iter 13 : loss : 0.4412 = 0.3376 + 0.1028 + 0.0008, time: 6.067325]
2023-05-23 10:44:16.304: epoch 13:	0.01840982  	0.13624473  	0.06822358  
2023-05-23 10:44:22.536: [iter 14 : loss : 0.4073 = 0.3031 + 0.1034 + 0.0009, time: 6.231298]
2023-05-23 10:44:22.691: epoch 14:	0.01863563  	0.13797729  	0.06915853  
2023-05-23 10:44:28.906: [iter 15 : loss : 0.3834 = 0.2789 + 0.1035 + 0.0010, time: 6.212274]
2023-05-23 10:44:29.051: epoch 15:	0.01883321  	0.13970858  	0.07010984  
2023-05-23 10:44:35.318: [iter 16 : loss : 0.3629 = 0.2584 + 0.1034 + 0.0011, time: 6.266766]
2023-05-23 10:44:35.470: epoch 16:	0.01910136  	0.14138052  	0.07115285  
2023-05-23 10:44:35.470: Find a better model.
2023-05-23 10:44:41.721: [iter 17 : loss : 0.3476 = 0.2432 + 0.1031 + 0.0012, time: 6.249010]
2023-05-23 10:44:41.865: epoch 17:	0.01922837  	0.14213152  	0.07191791  
2023-05-23 10:44:41.866: Find a better model.
2023-05-23 10:44:47.929: [iter 18 : loss : 0.3330 = 0.2288 + 0.1028 + 0.0013, time: 6.062256]
2023-05-23 10:44:48.084: epoch 18:	0.01940479  	0.14348605  	0.07273367  
2023-05-23 10:44:48.084: Find a better model.
2023-05-23 10:44:54.336: [iter 19 : loss : 0.3194 = 0.2155 + 0.1024 + 0.0014, time: 6.249704]
2023-05-23 10:44:54.489: epoch 19:	0.01962354  	0.14475881  	0.07346391  
2023-05-23 10:44:54.489: Find a better model.
2023-05-23 10:45:00.719: [iter 20 : loss : 0.3100 = 0.2065 + 0.1020 + 0.0015, time: 6.227860]
2023-05-23 10:45:00.872: epoch 20:	0.01995521  	0.14727144  	0.07482393  
2023-05-23 10:45:00.872: Find a better model.
2023-05-23 10:45:07.111: [iter 21 : loss : 0.3008 = 0.1976 + 0.1016 + 0.0016, time: 6.237391]
2023-05-23 10:45:07.261: epoch 21:	0.02015984  	0.14881289  	0.07551429  
2023-05-23 10:45:07.261: Find a better model.
2023-05-23 10:45:13.511: [iter 22 : loss : 0.2925 = 0.1897 + 0.1012 + 0.0017, time: 6.247525]
2023-05-23 10:45:13.653: epoch 22:	0.02033626  	0.15033545  	0.07620153  
2023-05-23 10:45:13.653: Find a better model.
2023-05-23 10:45:19.881: [iter 23 : loss : 0.2845 = 0.1820 + 0.1008 + 0.0017, time: 6.226746]
2023-05-23 10:45:20.023: epoch 23:	0.02049856  	0.15123284  	0.07708446  
2023-05-23 10:45:20.023: Find a better model.
2023-05-23 10:45:26.277: [iter 24 : loss : 0.2780 = 0.1760 + 0.1003 + 0.0018, time: 6.253029]
2023-05-23 10:45:26.428: epoch 24:	0.02071025  	0.15272692  	0.07784516  
2023-05-23 10:45:26.428: Find a better model.
2023-05-23 10:45:32.692: [iter 25 : loss : 0.2714 = 0.1697 + 0.0999 + 0.0019, time: 6.262971]
2023-05-23 10:45:32.836: epoch 25:	0.02090783  	0.15435879  	0.07863277  
2023-05-23 10:45:32.836: Find a better model.
2023-05-23 10:45:39.118: [iter 26 : loss : 0.2679 = 0.1665 + 0.0994 + 0.0020, time: 6.280819]
2023-05-23 10:45:39.273: epoch 26:	0.02114070  	0.15613763  	0.07935271  
2023-05-23 10:45:39.273: Find a better model.
2023-05-23 10:45:45.513: [iter 27 : loss : 0.2600 = 0.1590 + 0.0990 + 0.0020, time: 6.239298]
2023-05-23 10:45:45.666: epoch 27:	0.02133122  	0.15680772  	0.08008822  
2023-05-23 10:45:45.666: Find a better model.
2023-05-23 10:45:51.888: [iter 28 : loss : 0.2553 = 0.1546 + 0.0986 + 0.0021, time: 6.221287]
2023-05-23 10:45:52.031: epoch 28:	0.02152880  	0.15828677  	0.08113311  
2023-05-23 10:45:52.031: Find a better model.
2023-05-23 10:45:58.117: [iter 29 : loss : 0.2509 = 0.1506 + 0.0982 + 0.0021, time: 6.084417]
2023-05-23 10:45:58.270: epoch 29:	0.02171228  	0.16021928  	0.08185125  
2023-05-23 10:45:58.271: Find a better model.
2023-05-23 10:46:04.490: [iter 30 : loss : 0.2443 = 0.1443 + 0.0978 + 0.0022, time: 6.218381]
2023-05-23 10:46:04.644: epoch 30:	0.02190986  	0.16156237  	0.08272063  
2023-05-23 10:46:04.644: Find a better model.
2023-05-23 10:46:10.865: [iter 31 : loss : 0.2409 = 0.1412 + 0.0974 + 0.0023, time: 6.218505]
2023-05-23 10:46:11.017: epoch 31:	0.02205805  	0.16268608  	0.08324085  
2023-05-23 10:46:11.017: Find a better model.
2023-05-23 10:46:17.293: [iter 32 : loss : 0.2352 = 0.1357 + 0.0971 + 0.0023, time: 6.275485]
2023-05-23 10:46:17.443: epoch 32:	0.02212155  	0.16262680  	0.08373206  
2023-05-23 10:46:23.690: [iter 33 : loss : 0.2328 = 0.1337 + 0.0967 + 0.0024, time: 6.244833]
2023-05-23 10:46:23.844: epoch 33:	0.02221329  	0.16351135  	0.08425453  
2023-05-23 10:46:23.844: Find a better model.
2023-05-23 10:46:30.085: [iter 34 : loss : 0.2284 = 0.1296 + 0.0964 + 0.0024, time: 6.238982]
2023-05-23 10:46:30.229: epoch 34:	0.02233324  	0.16477019  	0.08501509  
2023-05-23 10:46:30.229: Find a better model.
2023-05-23 10:46:36.473: [iter 35 : loss : 0.2251 = 0.1265 + 0.0961 + 0.0025, time: 6.241911]
2023-05-23 10:46:36.625: epoch 35:	0.02241087  	0.16510691  	0.08569680  
2023-05-23 10:46:36.625: Find a better model.
2023-05-23 10:46:42.889: [iter 36 : loss : 0.2218 = 0.1235 + 0.0958 + 0.0026, time: 6.262125]
2023-05-23 10:46:43.043: epoch 36:	0.02252377  	0.16603518  	0.08638398  
2023-05-23 10:46:43.043: Find a better model.
2023-05-23 10:46:49.280: [iter 37 : loss : 0.2178 = 0.1197 + 0.0955 + 0.0026, time: 6.235185]
2023-05-23 10:46:49.433: epoch 37:	0.02264373  	0.16741671  	0.08693644  
2023-05-23 10:46:49.433: Find a better model.
2023-05-23 10:46:55.876: [iter 38 : loss : 0.2164 = 0.1185 + 0.0952 + 0.0027, time: 6.441957]
2023-05-23 10:46:56.029: epoch 38:	0.02282720  	0.16879678  	0.08776180  
2023-05-23 10:46:56.029: Find a better model.
2023-05-23 10:47:02.446: [iter 39 : loss : 0.2118 = 0.1142 + 0.0949 + 0.0027, time: 6.416138]
2023-05-23 10:47:02.600: epoch 39:	0.02298245  	0.17002791  	0.08845052  
2023-05-23 10:47:02.600: Find a better model.
2023-05-23 10:47:09.071: [iter 40 : loss : 0.2084 = 0.1111 + 0.0945 + 0.0028, time: 6.470583]
2023-05-23 10:47:09.227: epoch 40:	0.02302479  	0.17017686  	0.08877540  
2023-05-23 10:47:09.227: Find a better model.
2023-05-23 10:47:15.467: [iter 41 : loss : 0.2069 = 0.1098 + 0.0943 + 0.0028, time: 6.239010]
2023-05-23 10:47:15.608: epoch 41:	0.02319415  	0.17122239  	0.08936951  
2023-05-23 10:47:15.608: Find a better model.
2023-05-23 10:47:22.038: [iter 42 : loss : 0.2047 = 0.1078 + 0.0940 + 0.0029, time: 6.427838]
2023-05-23 10:47:22.197: epoch 42:	0.02328588  	0.17211519  	0.09010873  
2023-05-23 10:47:22.197: Find a better model.
2023-05-23 10:47:28.463: [iter 43 : loss : 0.2008 = 0.1042 + 0.0938 + 0.0029, time: 6.265230]
2023-05-23 10:47:28.614: epoch 43:	0.02337055  	0.17295277  	0.09056968  
2023-05-23 10:47:28.614: Find a better model.
2023-05-23 10:47:35.079: [iter 44 : loss : 0.1973 = 0.1008 + 0.0935 + 0.0030, time: 6.463619]
2023-05-23 10:47:35.236: epoch 44:	0.02340583  	0.17317195  	0.09099051  
2023-05-23 10:47:35.236: Find a better model.
2023-05-23 10:47:41.463: [iter 45 : loss : 0.1950 = 0.0987 + 0.0933 + 0.0030, time: 6.226607]
2023-05-23 10:47:41.615: epoch 45:	0.02351168  	0.17350066  	0.09128917  
2023-05-23 10:47:41.616: Find a better model.
2023-05-23 10:47:48.061: [iter 46 : loss : 0.1927 = 0.0967 + 0.0930 + 0.0031, time: 6.444102]
2023-05-23 10:47:48.213: epoch 46:	0.02363870  	0.17416908  	0.09192325  
2023-05-23 10:47:48.213: Find a better model.
2023-05-23 10:47:54.625: [iter 47 : loss : 0.1920 = 0.0961 + 0.0928 + 0.0031, time: 6.411170]
2023-05-23 10:47:54.777: epoch 47:	0.02367398  	0.17465204  	0.09230921  
2023-05-23 10:47:54.777: Find a better model.
2023-05-23 10:48:01.054: [iter 48 : loss : 0.1882 = 0.0925 + 0.0926 + 0.0032, time: 6.276292]
2023-05-23 10:48:01.196: epoch 48:	0.02375865  	0.17503250  	0.09266145  
2023-05-23 10:48:01.196: Find a better model.
2023-05-23 10:48:07.443: [iter 49 : loss : 0.1850 = 0.0895 + 0.0923 + 0.0032, time: 6.246013]
2023-05-23 10:48:07.597: epoch 49:	0.02387156  	0.17542054  	0.09315541  
2023-05-23 10:48:07.597: Find a better model.
2023-05-23 10:48:14.044: [iter 50 : loss : 0.1846 = 0.0892 + 0.0921 + 0.0033, time: 6.445955]
2023-05-23 10:48:14.185: epoch 50:	0.02392095  	0.17604350  	0.09357381  
2023-05-23 10:48:14.185: Find a better model.
2023-05-23 10:48:20.466: [iter 51 : loss : 0.1814 = 0.0861 + 0.0920 + 0.0033, time: 6.279030]
2023-05-23 10:48:20.621: epoch 51:	0.02394212  	0.17599304  	0.09375850  
2023-05-23 10:48:27.055: [iter 52 : loss : 0.1809 = 0.0858 + 0.0918 + 0.0034, time: 6.432106]
2023-05-23 10:48:27.207: epoch 52:	0.02410442  	0.17717031  	0.09437963  
2023-05-23 10:48:27.207: Find a better model.
2023-05-23 10:48:33.634: [iter 53 : loss : 0.1790 = 0.0841 + 0.0915 + 0.0034, time: 6.426527]
2023-05-23 10:48:33.790: epoch 53:	0.02418909  	0.17786519  	0.09460431  
2023-05-23 10:48:33.790: Find a better model.
2023-05-23 10:48:40.227: [iter 54 : loss : 0.1772 = 0.0824 + 0.0914 + 0.0035, time: 6.435603]
2023-05-23 10:48:40.383: epoch 54:	0.02437255  	0.17963798  	0.09532920  
2023-05-23 10:48:40.383: Find a better model.
2023-05-23 10:48:46.630: [iter 55 : loss : 0.1751 = 0.0805 + 0.0912 + 0.0035, time: 6.245675]
2023-05-23 10:48:46.770: epoch 55:	0.02441489  	0.17965724  	0.09568354  
2023-05-23 10:48:46.770: Find a better model.
2023-05-23 10:48:53.049: [iter 56 : loss : 0.1732 = 0.0787 + 0.0909 + 0.0035, time: 6.277296]
2023-05-23 10:48:53.202: epoch 56:	0.02450662  	0.18032795  	0.09624207  
2023-05-23 10:48:53.202: Find a better model.
2023-05-23 10:48:59.448: [iter 57 : loss : 0.1715 = 0.0770 + 0.0908 + 0.0036, time: 6.245021]
2023-05-23 10:48:59.601: epoch 57:	0.02464070  	0.18146811  	0.09664170  
2023-05-23 10:48:59.601: Find a better model.
2023-05-23 10:49:06.035: [iter 58 : loss : 0.1695 = 0.0752 + 0.0906 + 0.0036, time: 6.432761]
2023-05-23 10:49:06.188: epoch 58:	0.02469009  	0.18168686  	0.09691638  
2023-05-23 10:49:06.188: Find a better model.
2023-05-23 10:49:12.447: [iter 59 : loss : 0.1685 = 0.0744 + 0.0904 + 0.0037, time: 6.258044]
2023-05-23 10:49:12.600: epoch 59:	0.02474655  	0.18234250  	0.09731191  
2023-05-23 10:49:12.600: Find a better model.
2023-05-23 10:49:19.035: [iter 60 : loss : 0.1670 = 0.0730 + 0.0903 + 0.0037, time: 6.432421]
2023-05-23 10:49:19.187: epoch 60:	0.02474655  	0.18247296  	0.09760020  
2023-05-23 10:49:19.187: Find a better model.
2023-05-23 10:49:25.433: [iter 61 : loss : 0.1657 = 0.0718 + 0.0901 + 0.0038, time: 6.245643]
2023-05-23 10:49:25.588: epoch 61:	0.02488062  	0.18357188  	0.09816659  
2023-05-23 10:49:25.588: Find a better model.
2023-05-23 10:49:32.013: [iter 62 : loss : 0.1641 = 0.0703 + 0.0900 + 0.0038, time: 6.423469]
2023-05-23 10:49:32.166: epoch 62:	0.02497941  	0.18431877  	0.09882064  
2023-05-23 10:49:32.167: Find a better model.
2023-05-23 10:49:38.396: [iter 63 : loss : 0.1627 = 0.0691 + 0.0898 + 0.0039, time: 6.227734]
2023-05-23 10:49:38.539: epoch 63:	0.02502174  	0.18431544  	0.09892137  
2023-05-23 10:49:44.834: [iter 64 : loss : 0.1617 = 0.0682 + 0.0897 + 0.0039, time: 6.293943]
2023-05-23 10:49:44.986: epoch 64:	0.02502880  	0.18431069  	0.09913629  
2023-05-23 10:49:51.383: [iter 65 : loss : 0.1604 = 0.0669 + 0.0895 + 0.0039, time: 6.396381]
2023-05-23 10:49:51.532: epoch 65:	0.02507114  	0.18464693  	0.09942710  
2023-05-23 10:49:51.532: Find a better model.
2023-05-23 10:49:57.810: [iter 66 : loss : 0.1587 = 0.0654 + 0.0893 + 0.0040, time: 6.275597]
2023-05-23 10:49:57.960: epoch 66:	0.02520521  	0.18568054  	0.10004828  
2023-05-23 10:49:57.960: Find a better model.
2023-05-23 10:50:04.233: [iter 67 : loss : 0.1573 = 0.0641 + 0.0893 + 0.0040, time: 6.272285]
2023-05-23 10:50:04.388: epoch 67:	0.02522638  	0.18607382  	0.10024683  
2023-05-23 10:50:04.388: Find a better model.
2023-05-23 10:50:10.607: [iter 68 : loss : 0.1573 = 0.0641 + 0.0891 + 0.0041, time: 6.218014]
2023-05-23 10:50:10.762: epoch 68:	0.02530401  	0.18683086  	0.10041448  
2023-05-23 10:50:10.762: Find a better model.
2023-05-23 10:50:17.192: [iter 69 : loss : 0.1553 = 0.0622 + 0.0890 + 0.0041, time: 6.429707]
2023-05-23 10:50:17.345: epoch 69:	0.02534634  	0.18711789  	0.10085959  
2023-05-23 10:50:17.346: Find a better model.
2023-05-23 10:50:23.595: [iter 70 : loss : 0.1534 = 0.0604 + 0.0889 + 0.0042, time: 6.247267]
2023-05-23 10:50:23.748: epoch 70:	0.02533929  	0.18718107  	0.10098972  
2023-05-23 10:50:23.748: Find a better model.
2023-05-23 10:50:29.985: [iter 71 : loss : 0.1521 = 0.0592 + 0.0887 + 0.0042, time: 6.236914]
2023-05-23 10:50:30.138: epoch 71:	0.02531106  	0.18712817  	0.10106750  
2023-05-23 10:50:36.421: [iter 72 : loss : 0.1518 = 0.0589 + 0.0886 + 0.0042, time: 6.281325]
2023-05-23 10:50:36.578: epoch 72:	0.02542397  	0.18782194  	0.10135408  
2023-05-23 10:50:36.578: Find a better model.
2023-05-23 10:50:42.806: [iter 73 : loss : 0.1504 = 0.0577 + 0.0885 + 0.0043, time: 6.226787]
2023-05-23 10:50:42.960: epoch 73:	0.02550158  	0.18799752  	0.10152238  
2023-05-23 10:50:42.960: Find a better model.
2023-05-23 10:50:49.200: [iter 74 : loss : 0.1491 = 0.0564 + 0.0884 + 0.0043, time: 6.239513]
2023-05-23 10:50:49.342: epoch 74:	0.02555098  	0.18844335  	0.10178738  
2023-05-23 10:50:49.342: Find a better model.
2023-05-23 10:50:55.606: [iter 75 : loss : 0.1486 = 0.0559 + 0.0883 + 0.0044, time: 6.263024]
2023-05-23 10:50:55.761: epoch 75:	0.02566388  	0.18957938  	0.10244468  
2023-05-23 10:50:55.761: Find a better model.
2023-05-23 10:51:01.994: [iter 76 : loss : 0.1475 = 0.0549 + 0.0881 + 0.0044, time: 6.230846]
2023-05-23 10:51:02.147: epoch 76:	0.02563566  	0.18909147  	0.10252058  
2023-05-23 10:51:08.405: [iter 77 : loss : 0.1465 = 0.0541 + 0.0880 + 0.0044, time: 6.257195]
2023-05-23 10:51:08.560: epoch 77:	0.02577679  	0.19015053  	0.10289069  
2023-05-23 10:51:08.560: Find a better model.
2023-05-23 10:51:14.795: [iter 78 : loss : 0.1458 = 0.0534 + 0.0880 + 0.0045, time: 6.234037]
2023-05-23 10:51:14.947: epoch 78:	0.02583324  	0.19043507  	0.10313188  
2023-05-23 10:51:14.947: Find a better model.
2023-05-23 10:51:21.173: [iter 79 : loss : 0.1444 = 0.0521 + 0.0878 + 0.0045, time: 6.224229]
2023-05-23 10:51:21.328: epoch 79:	0.02582619  	0.19062619  	0.10341746  
2023-05-23 10:51:21.328: Find a better model.
2023-05-23 10:51:27.597: [iter 80 : loss : 0.1435 = 0.0512 + 0.0878 + 0.0046, time: 6.267069]
2023-05-23 10:51:27.751: epoch 80:	0.02584735  	0.19085880  	0.10359376  
2023-05-23 10:51:27.751: Find a better model.
2023-05-23 10:51:33.983: [iter 81 : loss : 0.1438 = 0.0516 + 0.0876 + 0.0046, time: 6.230438]
2023-05-23 10:51:34.136: epoch 81:	0.02589675  	0.19103383  	0.10348843  
2023-05-23 10:51:34.136: Find a better model.
2023-05-23 10:51:40.384: [iter 82 : loss : 0.1421 = 0.0499 + 0.0875 + 0.0046, time: 6.246251]
2023-05-23 10:51:40.525: epoch 82:	0.02592497  	0.19086345  	0.10386594  
2023-05-23 10:51:46.574: [iter 83 : loss : 0.1412 = 0.0491 + 0.0875 + 0.0047, time: 6.047683]
2023-05-23 10:51:46.717: epoch 83:	0.02594614  	0.19112036  	0.10414889  
2023-05-23 10:51:46.717: Find a better model.
2023-05-23 10:51:52.981: [iter 84 : loss : 0.1411 = 0.0491 + 0.0874 + 0.0047, time: 6.262742]
2023-05-23 10:51:53.134: epoch 84:	0.02596731  	0.19172823  	0.10450102  
2023-05-23 10:51:53.135: Find a better model.
2023-05-23 10:51:59.359: [iter 85 : loss : 0.1401 = 0.0481 + 0.0873 + 0.0047, time: 6.222605]
2023-05-23 10:51:59.514: epoch 85:	0.02592497  	0.19128658  	0.10443469  
2023-05-23 10:52:05.762: [iter 86 : loss : 0.1399 = 0.0480 + 0.0871 + 0.0048, time: 6.246493]
2023-05-23 10:52:05.918: epoch 86:	0.02596026  	0.19174747  	0.10452656  
2023-05-23 10:52:05.919: Find a better model.
2023-05-23 10:52:12.135: [iter 87 : loss : 0.1373 = 0.0454 + 0.0871 + 0.0048, time: 6.213609]
2023-05-23 10:52:12.288: epoch 87:	0.02594614  	0.19144776  	0.10448187  
2023-05-23 10:52:18.557: [iter 88 : loss : 0.1366 = 0.0447 + 0.0870 + 0.0049, time: 6.268599]
2023-05-23 10:52:18.699: epoch 88:	0.02593203  	0.19143486  	0.10469142  
2023-05-23 10:52:24.783: [iter 89 : loss : 0.1362 = 0.0444 + 0.0869 + 0.0049, time: 6.081137]
2023-05-23 10:52:24.939: epoch 89:	0.02593203  	0.19149399  	0.10469703  
2023-05-23 10:52:31.158: [iter 90 : loss : 0.1368 = 0.0450 + 0.0868 + 0.0049, time: 6.218414]
2023-05-23 10:52:31.312: epoch 90:	0.02604493  	0.19210018  	0.10504318  
2023-05-23 10:52:31.312: Find a better model.
2023-05-23 10:52:37.576: [iter 91 : loss : 0.1357 = 0.0440 + 0.0867 + 0.0050, time: 6.263218]
2023-05-23 10:52:37.735: epoch 91:	0.02600965  	0.19217347  	0.10511360  
2023-05-23 10:52:37.735: Find a better model.
2023-05-23 10:52:43.947: [iter 92 : loss : 0.1347 = 0.0431 + 0.0866 + 0.0050, time: 6.210383]
2023-05-23 10:52:44.101: epoch 92:	0.02612961  	0.19316466  	0.10545766  
2023-05-23 10:52:44.101: Find a better model.
2023-05-23 10:52:50.352: [iter 93 : loss : 0.1347 = 0.0430 + 0.0866 + 0.0051, time: 6.248338]
2023-05-23 10:52:50.497: epoch 93:	0.02614372  	0.19305995  	0.10548288  
2023-05-23 10:52:56.740: [iter 94 : loss : 0.1329 = 0.0413 + 0.0865 + 0.0051, time: 6.241000]
2023-05-23 10:52:56.895: epoch 94:	0.02619312  	0.19338588  	0.10568425  
2023-05-23 10:52:56.895: Find a better model.
2023-05-23 10:53:03.130: [iter 95 : loss : 0.1323 = 0.0407 + 0.0864 + 0.0051, time: 6.234029]
2023-05-23 10:53:03.283: epoch 95:	0.02622841  	0.19354168  	0.10594104  
2023-05-23 10:53:03.284: Find a better model.
2023-05-23 10:53:09.550: [iter 96 : loss : 0.1323 = 0.0408 + 0.0864 + 0.0052, time: 6.263732]
2023-05-23 10:53:09.708: epoch 96:	0.02620723  	0.19316681  	0.10592502  
2023-05-23 10:53:15.938: [iter 97 : loss : 0.1305 = 0.0390 + 0.0863 + 0.0052, time: 6.228809]
2023-05-23 10:53:16.095: epoch 97:	0.02625663  	0.19333951  	0.10605664  
2023-05-23 10:53:22.347: [iter 98 : loss : 0.1314 = 0.0400 + 0.0862 + 0.0052, time: 6.251445]
2023-05-23 10:53:22.489: epoch 98:	0.02624252  	0.19354977  	0.10619956  
2023-05-23 10:53:22.489: Find a better model.
2023-05-23 10:53:28.725: [iter 99 : loss : 0.1302 = 0.0388 + 0.0861 + 0.0053, time: 6.234379]
2023-05-23 10:53:28.877: epoch 99:	0.02634131  	0.19451152  	0.10654825  
2023-05-23 10:53:28.877: Find a better model.
2023-05-23 10:53:34.949: [iter 100 : loss : 0.1296 = 0.0383 + 0.0860 + 0.0053, time: 6.070233]
2023-05-23 10:53:35.106: epoch 100:	0.02642598  	0.19503194  	0.10681748  
2023-05-23 10:53:35.106: Find a better model.
2023-05-23 10:53:41.333: [iter 101 : loss : 0.1292 = 0.0379 + 0.0860 + 0.0053, time: 6.226447]
2023-05-23 10:53:41.486: epoch 101:	0.02638365  	0.19474700  	0.10675281  
2023-05-23 10:53:47.730: [iter 102 : loss : 0.1282 = 0.0370 + 0.0859 + 0.0054, time: 6.243160]
2023-05-23 10:53:47.886: epoch 102:	0.02644715  	0.19510698  	0.10692525  
2023-05-23 10:53:47.886: Find a better model.
2023-05-23 10:53:54.089: [iter 103 : loss : 0.1279 = 0.0366 + 0.0859 + 0.0054, time: 6.201693]
2023-05-23 10:53:54.244: epoch 103:	0.02654595  	0.19602011  	0.10729779  
2023-05-23 10:53:54.244: Find a better model.
2023-05-23 10:54:00.532: [iter 104 : loss : 0.1284 = 0.0372 + 0.0858 + 0.0054, time: 6.286892]
2023-05-23 10:54:00.674: epoch 104:	0.02648949  	0.19587612  	0.10735025  
2023-05-23 10:54:06.728: [iter 105 : loss : 0.1279 = 0.0367 + 0.0857 + 0.0055, time: 6.053350]
2023-05-23 10:54:06.870: epoch 105:	0.02653183  	0.19599035  	0.10769311  
2023-05-23 10:54:12.940: [iter 106 : loss : 0.1272 = 0.0361 + 0.0857 + 0.0055, time: 6.068752]
2023-05-23 10:54:13.080: epoch 106:	0.02658829  	0.19657961  	0.10776249  
2023-05-23 10:54:13.081: Find a better model.
2023-05-23 10:54:19.140: [iter 107 : loss : 0.1263 = 0.0352 + 0.0856 + 0.0055, time: 6.057876]
2023-05-23 10:54:19.294: epoch 107:	0.02659534  	0.19643411  	0.10788900  
2023-05-23 10:54:25.505: [iter 108 : loss : 0.1260 = 0.0349 + 0.0856 + 0.0056, time: 6.209462]
2023-05-23 10:54:25.648: epoch 108:	0.02662356  	0.19655541  	0.10784834  
2023-05-23 10:54:31.715: [iter 109 : loss : 0.1248 = 0.0337 + 0.0855 + 0.0056, time: 6.066167]
2023-05-23 10:54:31.871: epoch 109:	0.02668002  	0.19689316  	0.10786375  
2023-05-23 10:54:31.871: Find a better model.
2023-05-23 10:54:38.106: [iter 110 : loss : 0.1242 = 0.0330 + 0.0855 + 0.0056, time: 6.234657]
2023-05-23 10:54:38.260: epoch 110:	0.02660945  	0.19654767  	0.10784566  
2023-05-23 10:54:44.490: [iter 111 : loss : 0.1243 = 0.0332 + 0.0854 + 0.0057, time: 6.226885]
2023-05-23 10:54:44.642: epoch 111:	0.02658828  	0.19660062  	0.10805639  
2023-05-23 10:54:50.720: [iter 112 : loss : 0.1239 = 0.0328 + 0.0853 + 0.0057, time: 6.076428]
2023-05-23 10:54:50.876: epoch 112:	0.02665179  	0.19700469  	0.10820360  
2023-05-23 10:54:50.877: Find a better model.
2023-05-23 10:54:57.107: [iter 113 : loss : 0.1237 = 0.0327 + 0.0853 + 0.0057, time: 6.228503]
2023-05-23 10:54:57.262: epoch 113:	0.02669413  	0.19727209  	0.10828373  
2023-05-23 10:54:57.262: Find a better model.
2023-05-23 10:55:03.504: [iter 114 : loss : 0.1229 = 0.0319 + 0.0852 + 0.0058, time: 6.241240]
2023-05-23 10:55:03.659: epoch 114:	0.02675763  	0.19761603  	0.10848629  
2023-05-23 10:55:03.659: Find a better model.
2023-05-23 10:55:09.900: [iter 115 : loss : 0.1226 = 0.0316 + 0.0852 + 0.0058, time: 6.240035]
2023-05-23 10:55:10.055: epoch 115:	0.02672941  	0.19773921  	0.10861433  
2023-05-23 10:55:10.055: Find a better model.
2023-05-23 10:55:16.297: [iter 116 : loss : 0.1217 = 0.0307 + 0.0851 + 0.0058, time: 6.240357]
2023-05-23 10:55:16.450: epoch 116:	0.02670824  	0.19722079  	0.10839334  
2023-05-23 10:55:22.696: [iter 117 : loss : 0.1217 = 0.0307 + 0.0851 + 0.0059, time: 6.245254]
2023-05-23 10:55:22.842: epoch 117:	0.02670825  	0.19737591  	0.10852651  
2023-05-23 10:55:29.089: [iter 118 : loss : 0.1215 = 0.0306 + 0.0850 + 0.0059, time: 6.245829]
2023-05-23 10:55:29.245: epoch 118:	0.02676469  	0.19782366  	0.10889346  
2023-05-23 10:55:29.245: Find a better model.
2023-05-23 10:55:35.481: [iter 119 : loss : 0.1207 = 0.0298 + 0.0850 + 0.0059, time: 6.235752]
2023-05-23 10:55:35.635: epoch 119:	0.02671530  	0.19780320  	0.10900028  
2023-05-23 10:55:41.909: [iter 120 : loss : 0.1209 = 0.0300 + 0.0849 + 0.0060, time: 6.272177]
2023-05-23 10:55:42.063: epoch 120:	0.02670823  	0.19747400  	0.10917621  
2023-05-23 10:55:48.267: [iter 121 : loss : 0.1210 = 0.0301 + 0.0849 + 0.0060, time: 6.203047]
2023-05-23 10:55:48.421: epoch 121:	0.02673646  	0.19751768  	0.10920221  
2023-05-23 10:55:54.678: [iter 122 : loss : 0.1199 = 0.0291 + 0.0848 + 0.0060, time: 6.255523]
2023-05-23 10:55:54.821: epoch 122:	0.02676468  	0.19795409  	0.10922337  
2023-05-23 10:55:54.821: Find a better model.
2023-05-23 10:56:00.896: [iter 123 : loss : 0.1199 = 0.0291 + 0.0848 + 0.0061, time: 6.073165]
2023-05-23 10:56:01.038: epoch 123:	0.02677174  	0.19759706  	0.10919062  
2023-05-23 10:56:07.102: [iter 124 : loss : 0.1190 = 0.0282 + 0.0847 + 0.0061, time: 6.063619]
2023-05-23 10:56:07.247: epoch 124:	0.02682113  	0.19803955  	0.10943695  
2023-05-23 10:56:07.248: Find a better model.
2023-05-23 10:56:13.364: [iter 125 : loss : 0.1185 = 0.0277 + 0.0847 + 0.0061, time: 6.114579]
2023-05-23 10:56:13.513: epoch 125:	0.02680702  	0.19773503  	0.10938598  
2023-05-23 10:56:19.704: [iter 126 : loss : 0.1186 = 0.0278 + 0.0846 + 0.0061, time: 6.190096]
2023-05-23 10:56:19.857: epoch 126:	0.02673646  	0.19730610  	0.10929900  
2023-05-23 10:56:26.060: [iter 127 : loss : 0.1177 = 0.0269 + 0.0846 + 0.0062, time: 6.201481]
2023-05-23 10:56:26.216: epoch 127:	0.02678585  	0.19760144  	0.10943091  
2023-05-23 10:56:32.287: [iter 128 : loss : 0.1185 = 0.0278 + 0.0846 + 0.0062, time: 6.069746]
2023-05-23 10:56:32.443: epoch 128:	0.02680703  	0.19759296  	0.10948166  
2023-05-23 10:56:38.672: [iter 129 : loss : 0.1179 = 0.0271 + 0.0845 + 0.0062, time: 6.228371]
2023-05-23 10:56:38.817: epoch 129:	0.02678585  	0.19726971  	0.10940562  
2023-05-23 10:56:44.899: [iter 130 : loss : 0.1178 = 0.0271 + 0.0845 + 0.0063, time: 6.080079]
2023-05-23 10:56:45.053: epoch 130:	0.02685642  	0.19765779  	0.10952124  
2023-05-23 10:56:51.284: [iter 131 : loss : 0.1171 = 0.0264 + 0.0844 + 0.0063, time: 6.229959]
2023-05-23 10:56:51.440: epoch 131:	0.02679291  	0.19753681  	0.10955943  
2023-05-23 10:56:57.674: [iter 132 : loss : 0.1173 = 0.0266 + 0.0844 + 0.0063, time: 6.231614]
2023-05-23 10:56:57.829: epoch 132:	0.02676469  	0.19729343  	0.10951761  
2023-05-23 10:57:04.079: [iter 133 : loss : 0.1160 = 0.0253 + 0.0843 + 0.0064, time: 6.247820]
2023-05-23 10:57:04.234: epoch 133:	0.02669412  	0.19666418  	0.10934480  
2023-05-23 10:57:10.489: [iter 134 : loss : 0.1167 = 0.0261 + 0.0843 + 0.0064, time: 6.253228]
2023-05-23 10:57:10.647: epoch 134:	0.02670822  	0.19690782  	0.10958500  
2023-05-23 10:57:16.845: [iter 135 : loss : 0.1163 = 0.0256 + 0.0843 + 0.0064, time: 6.196500]
2023-05-23 10:57:17.006: epoch 135:	0.02668706  	0.19701958  	0.10957050  
2023-05-23 10:57:23.259: [iter 136 : loss : 0.1159 = 0.0252 + 0.0842 + 0.0064, time: 6.252492]
2023-05-23 10:57:23.399: epoch 136:	0.02668001  	0.19684854  	0.10969114  
2023-05-23 10:57:29.659: [iter 137 : loss : 0.1155 = 0.0248 + 0.0842 + 0.0065, time: 6.258202]
2023-05-23 10:57:29.812: epoch 137:	0.02669412  	0.19679104  	0.10956164  
2023-05-23 10:57:36.011: [iter 138 : loss : 0.1154 = 0.0247 + 0.0841 + 0.0065, time: 6.198293]
2023-05-23 10:57:36.167: epoch 138:	0.02674351  	0.19703212  	0.10962304  
2023-05-23 10:57:42.270: [iter 139 : loss : 0.1152 = 0.0246 + 0.0841 + 0.0065, time: 6.101509]
2023-05-23 10:57:42.423: epoch 139:	0.02677879  	0.19692606  	0.10972549  
2023-05-23 10:57:48.647: [iter 140 : loss : 0.1145 = 0.0239 + 0.0841 + 0.0066, time: 6.222944]
2023-05-23 10:57:48.801: epoch 140:	0.02674351  	0.19688615  	0.10955845  
2023-05-23 10:57:55.045: [iter 141 : loss : 0.1152 = 0.0246 + 0.0840 + 0.0066, time: 6.243714]
2023-05-23 10:57:55.199: epoch 141:	0.02679291  	0.19758242  	0.10981604  
2023-05-23 10:58:01.263: [iter 142 : loss : 0.1141 = 0.0235 + 0.0840 + 0.0066, time: 6.062787]
2023-05-23 10:58:01.418: epoch 142:	0.02675762  	0.19727172  	0.10991187  
2023-05-23 10:58:07.614: [iter 143 : loss : 0.1143 = 0.0237 + 0.0840 + 0.0066, time: 6.194214]
2023-05-23 10:58:07.777: epoch 143:	0.02667294  	0.19649749  	0.10976178  
2023-05-23 10:58:14.042: [iter 144 : loss : 0.1136 = 0.0230 + 0.0839 + 0.0067, time: 6.263236]
2023-05-23 10:58:14.201: epoch 144:	0.02670117  	0.19648698  	0.10991681  
2023-05-23 10:58:20.397: [iter 145 : loss : 0.1134 = 0.0229 + 0.0839 + 0.0067, time: 6.194092]
2023-05-23 10:58:20.550: epoch 145:	0.02664471  	0.19565929  	0.10978112  
2023-05-23 10:58:26.836: [iter 146 : loss : 0.1139 = 0.0233 + 0.0839 + 0.0067, time: 6.284715]
2023-05-23 10:58:26.988: epoch 146:	0.02665883  	0.19568072  	0.10987496  
2023-05-23 10:58:33.216: [iter 147 : loss : 0.1136 = 0.0230 + 0.0838 + 0.0067, time: 6.226497]
2023-05-23 10:58:33.370: epoch 147:	0.02668000  	0.19572906  	0.10992343  
2023-05-23 10:58:39.629: [iter 148 : loss : 0.1125 = 0.0220 + 0.0838 + 0.0068, time: 6.256735]
2023-05-23 10:58:39.785: epoch 148:	0.02665178  	0.19570181  	0.10986847  
2023-05-23 10:58:45.834: [iter 149 : loss : 0.1130 = 0.0224 + 0.0838 + 0.0068, time: 6.047819]
2023-05-23 10:58:45.979: epoch 149:	0.02660944  	0.19540834  	0.10990880  
2023-05-23 10:58:45.979: Early stopping is trigger at epoch: 149
2023-05-23 10:58:45.979: best_result@epoch 124:

2023-05-23 10:58:45.979: 		0.0268      	0.1980      	0.1094      
2023-05-23 11:00:09.551: my pid: 7412
2023-05-23 11:00:09.552: model: model.general_recommender.SGL
2023-05-23 11:00:09.552: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 11:00:09.552: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 11:00:12.955: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 11:00:20.529: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.574134]
2023-05-23 11:00:20.685: epoch 1:	0.00219447  	0.01488481  	0.00736860  
2023-05-23 11:00:20.685: Find a better model.
2023-05-23 11:00:28.204: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.518027]
2023-05-23 11:00:28.403: epoch 2:	0.00417018  	0.02896117  	0.01436441  
2023-05-23 11:00:28.403: Find a better model.
2023-05-23 11:00:35.902: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.496747]
2023-05-23 11:00:36.088: epoch 3:	0.00712667  	0.05116382  	0.02477876  
2023-05-23 11:00:36.088: Find a better model.
2023-05-23 11:00:43.301: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.211745]
2023-05-23 11:00:43.448: epoch 4:	0.01042194  	0.07332193  	0.03601383  
2023-05-23 11:00:43.448: Find a better model.
2023-05-23 11:00:50.609: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.160317]
2023-05-23 11:00:50.755: epoch 5:	0.01356912  	0.09656737  	0.04707512  
2023-05-23 11:00:50.755: Find a better model.
2023-05-23 11:00:57.614: [iter 6 : loss : 0.7644 = 0.6854 + 0.0790 + 0.0000, time: 6.858374]
2023-05-23 11:00:57.775: epoch 6:	0.01676567  	0.12068769  	0.05943846  
2023-05-23 11:00:57.775: Find a better model.
2023-05-23 11:01:04.607: [iter 7 : loss : 0.7539 = 0.6738 + 0.0801 + 0.0000, time: 6.831227]
2023-05-23 11:01:04.751: epoch 7:	0.01831101  	0.13329040  	0.06665688  
2023-05-23 11:01:04.751: Find a better model.
2023-05-23 11:01:11.585: [iter 8 : loss : 0.7294 = 0.6466 + 0.0828 + 0.0001, time: 6.831873]
2023-05-23 11:01:11.740: epoch 8:	0.01894611  	0.13890725  	0.06967957  
2023-05-23 11:01:11.740: Find a better model.
2023-05-23 11:01:18.394: [iter 9 : loss : 0.6808 = 0.5932 + 0.0875 + 0.0002, time: 6.651125]
2023-05-23 11:01:18.548: epoch 9:	0.01852978  	0.13666509  	0.06882491  
2023-05-23 11:01:25.190: [iter 10 : loss : 0.6104 = 0.5173 + 0.0928 + 0.0003, time: 6.641004]
2023-05-23 11:01:25.345: epoch 10:	0.01859329  	0.13728596  	0.06873360  
2023-05-23 11:01:32.001: [iter 11 : loss : 0.5364 = 0.4389 + 0.0970 + 0.0005, time: 6.653774]
2023-05-23 11:01:32.155: epoch 11:	0.01857212  	0.13732257  	0.06876736  
2023-05-23 11:01:38.775: [iter 12 : loss : 0.4759 = 0.3758 + 0.0995 + 0.0006, time: 6.616667]
2023-05-23 11:01:38.929: epoch 12:	0.01848039  	0.13674702  	0.06886252  
2023-05-23 11:01:45.392: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.461387]
2023-05-23 11:01:45.547: epoch 13:	0.01861446  	0.13811485  	0.06965742  
2023-05-23 11:01:51.999: [iter 14 : loss : 0.3994 = 0.2970 + 0.1014 + 0.0009, time: 6.451365]
2023-05-23 11:01:52.153: epoch 14:	0.01885438  	0.14012522  	0.07090805  
2023-05-23 11:01:52.153: Find a better model.
2023-05-23 11:01:58.590: [iter 15 : loss : 0.3760 = 0.2734 + 0.1016 + 0.0010, time: 6.436225]
2023-05-23 11:01:58.748: epoch 15:	0.01911547  	0.14217909  	0.07189768  
2023-05-23 11:01:58.748: Find a better model.
2023-05-23 11:02:05.185: [iter 16 : loss : 0.3558 = 0.2532 + 0.1015 + 0.0012, time: 6.434731]
2023-05-23 11:02:05.336: epoch 16:	0.01935540  	0.14363608  	0.07299397  
2023-05-23 11:02:05.337: Find a better model.
2023-05-23 11:02:11.758: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.420435]
2023-05-23 11:02:11.900: epoch 17:	0.01956004  	0.14455517  	0.07361299  
2023-05-23 11:02:11.900: Find a better model.
2023-05-23 11:02:18.202: [iter 18 : loss : 0.3266 = 0.2242 + 0.1010 + 0.0014, time: 6.301174]
2023-05-23 11:02:18.356: epoch 18:	0.01967294  	0.14515981  	0.07424305  
2023-05-23 11:02:18.357: Find a better model.
2023-05-23 11:02:24.962: [iter 19 : loss : 0.3132 = 0.2111 + 0.1006 + 0.0014, time: 6.602621]
2023-05-23 11:02:25.118: epoch 19:	0.01977173  	0.14569281  	0.07490546  
2023-05-23 11:02:25.119: Find a better model.
2023-05-23 11:02:31.758: [iter 20 : loss : 0.3041 = 0.2023 + 0.1002 + 0.0015, time: 6.636739]
2023-05-23 11:02:31.900: epoch 20:	0.02006811  	0.14791818  	0.07591460  
2023-05-23 11:02:31.900: Find a better model.
2023-05-23 11:02:38.560: [iter 21 : loss : 0.2949 = 0.1935 + 0.0998 + 0.0016, time: 6.659743]
2023-05-23 11:02:38.720: epoch 21:	0.02028686  	0.14937481  	0.07657098  
2023-05-23 11:02:38.720: Find a better model.
2023-05-23 11:02:45.348: [iter 22 : loss : 0.2870 = 0.1860 + 0.0994 + 0.0017, time: 6.626124]
2023-05-23 11:02:45.502: epoch 22:	0.02043505  	0.15026695  	0.07726041  
2023-05-23 11:02:45.502: Find a better model.
2023-05-23 11:02:51.959: [iter 23 : loss : 0.2791 = 0.1783 + 0.0990 + 0.0018, time: 6.456725]
2023-05-23 11:02:52.114: epoch 23:	0.02069614  	0.15243974  	0.07827086  
2023-05-23 11:02:52.114: Find a better model.
2023-05-23 11:02:58.755: [iter 24 : loss : 0.2726 = 0.1722 + 0.0985 + 0.0018, time: 6.639489]
2023-05-23 11:02:58.909: epoch 24:	0.02079493  	0.15298933  	0.07878936  
2023-05-23 11:02:58.909: Find a better model.
2023-05-23 11:03:05.553: [iter 25 : loss : 0.2661 = 0.1660 + 0.0981 + 0.0019, time: 6.642811]
2023-05-23 11:03:05.711: epoch 25:	0.02096429  	0.15387738  	0.07929014  
2023-05-23 11:03:05.711: Find a better model.
2023-05-23 11:03:12.356: [iter 26 : loss : 0.2626 = 0.1629 + 0.0977 + 0.0020, time: 6.644901]
2023-05-23 11:03:12.512: epoch 26:	0.02114775  	0.15486278  	0.08000695  
2023-05-23 11:03:12.512: Find a better model.
2023-05-23 11:03:19.140: [iter 27 : loss : 0.2550 = 0.1557 + 0.0973 + 0.0021, time: 6.626982]
2023-05-23 11:03:19.281: epoch 27:	0.02124655  	0.15579160  	0.08066536  
2023-05-23 11:03:19.281: Find a better model.
2023-05-23 11:03:25.916: [iter 28 : loss : 0.2503 = 0.1513 + 0.0969 + 0.0021, time: 6.632233]
2023-05-23 11:03:26.070: epoch 28:	0.02146530  	0.15725362  	0.08146570  
2023-05-23 11:03:26.071: Find a better model.
2023-05-23 11:03:32.738: [iter 29 : loss : 0.2462 = 0.1475 + 0.0965 + 0.0022, time: 6.666579]
2023-05-23 11:03:32.880: epoch 29:	0.02162760  	0.15827273  	0.08224175  
2023-05-23 11:03:32.880: Find a better model.
2023-05-23 11:03:39.353: [iter 30 : loss : 0.2395 = 0.1411 + 0.0961 + 0.0022, time: 6.471458]
2023-05-23 11:03:39.497: epoch 30:	0.02171228  	0.15886539  	0.08269992  
2023-05-23 11:03:39.497: Find a better model.
2023-05-23 11:03:46.168: [iter 31 : loss : 0.2362 = 0.1381 + 0.0958 + 0.0023, time: 6.670601]
2023-05-23 11:03:46.323: epoch 31:	0.02182519  	0.15999256  	0.08320720  
2023-05-23 11:03:46.323: Find a better model.
2023-05-23 11:03:52.946: [iter 32 : loss : 0.2308 = 0.1330 + 0.0954 + 0.0024, time: 6.620596]
2023-05-23 11:03:53.101: epoch 32:	0.02200865  	0.16142061  	0.08391787  
2023-05-23 11:03:53.101: Find a better model.
2023-05-23 11:03:59.718: [iter 33 : loss : 0.2281 = 0.1306 + 0.0950 + 0.0024, time: 6.615070]
2023-05-23 11:03:59.876: epoch 33:	0.02217800  	0.16286652  	0.08471173  
2023-05-23 11:03:59.876: Find a better model.
2023-05-23 11:04:06.547: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.670368]
2023-05-23 11:04:06.702: epoch 34:	0.02231207  	0.16388267  	0.08550876  
2023-05-23 11:04:06.702: Find a better model.
2023-05-23 11:04:13.322: [iter 35 : loss : 0.2208 = 0.1238 + 0.0944 + 0.0025, time: 6.618861]
2023-05-23 11:04:13.476: epoch 35:	0.02238970  	0.16463855  	0.08598113  
2023-05-23 11:04:13.476: Find a better model.
2023-05-23 11:04:20.113: [iter 36 : loss : 0.2175 = 0.1208 + 0.0941 + 0.0026, time: 6.636613]
2023-05-23 11:04:20.257: epoch 36:	0.02256611  	0.16615678  	0.08679208  
2023-05-23 11:04:20.257: Find a better model.
2023-05-23 11:04:26.908: [iter 37 : loss : 0.2135 = 0.1171 + 0.0938 + 0.0026, time: 6.649768]
2023-05-23 11:04:27.052: epoch 37:	0.02267195  	0.16695157  	0.08728772  
2023-05-23 11:04:27.052: Find a better model.
2023-05-23 11:04:33.717: [iter 38 : loss : 0.2121 = 0.1159 + 0.0935 + 0.0027, time: 6.664172]
2023-05-23 11:04:33.873: epoch 38:	0.02276369  	0.16787721  	0.08790784  
2023-05-23 11:04:33.873: Find a better model.
2023-05-23 11:04:40.514: [iter 39 : loss : 0.2076 = 0.1117 + 0.0932 + 0.0028, time: 6.640201]
2023-05-23 11:04:40.657: epoch 39:	0.02291187  	0.16907983  	0.08858876  
2023-05-23 11:04:40.658: Find a better model.
2023-05-23 11:04:47.316: [iter 40 : loss : 0.2044 = 0.1087 + 0.0929 + 0.0028, time: 6.656103]
2023-05-23 11:04:47.471: epoch 40:	0.02298949  	0.16964334  	0.08908501  
2023-05-23 11:04:47.471: Find a better model.
2023-05-23 11:04:54.112: [iter 41 : loss : 0.2029 = 0.1074 + 0.0926 + 0.0029, time: 6.639563]
2023-05-23 11:04:54.266: epoch 41:	0.02306712  	0.17024824  	0.08981743  
2023-05-23 11:04:54.266: Find a better model.
2023-05-23 11:05:00.921: [iter 42 : loss : 0.2009 = 0.1057 + 0.0923 + 0.0029, time: 6.654669]
2023-05-23 11:05:01.077: epoch 42:	0.02322236  	0.17160676  	0.09061166  
2023-05-23 11:05:01.077: Find a better model.
2023-05-23 11:05:07.715: [iter 43 : loss : 0.1968 = 0.1018 + 0.0921 + 0.0030, time: 6.636849]
2023-05-23 11:05:07.875: epoch 43:	0.02341289  	0.17285123  	0.09123547  
2023-05-23 11:05:07.875: Find a better model.
2023-05-23 11:05:14.530: [iter 44 : loss : 0.1934 = 0.0986 + 0.0918 + 0.0030, time: 6.654398]
2023-05-23 11:05:14.684: epoch 44:	0.02350462  	0.17318669  	0.09194936  
2023-05-23 11:05:14.684: Find a better model.
2023-05-23 11:05:21.294: [iter 45 : loss : 0.1912 = 0.0965 + 0.0916 + 0.0031, time: 6.607966]
2023-05-23 11:05:21.437: epoch 45:	0.02358225  	0.17371498  	0.09233250  
2023-05-23 11:05:21.437: Find a better model.
2023-05-23 11:05:28.086: [iter 46 : loss : 0.1889 = 0.0944 + 0.0913 + 0.0031, time: 6.647622]
2023-05-23 11:05:28.240: epoch 46:	0.02357519  	0.17376406  	0.09278033  
2023-05-23 11:05:28.240: Find a better model.
2023-05-23 11:05:34.880: [iter 47 : loss : 0.1882 = 0.0940 + 0.0911 + 0.0032, time: 6.638436]
2023-05-23 11:05:35.034: epoch 47:	0.02365281  	0.17406590  	0.09301489  
2023-05-23 11:05:35.034: Find a better model.
2023-05-23 11:05:41.658: [iter 48 : loss : 0.1845 = 0.0904 + 0.0908 + 0.0032, time: 6.623655]
2023-05-23 11:05:41.800: epoch 48:	0.02373043  	0.17498031  	0.09346680  
2023-05-23 11:05:41.800: Find a better model.
2023-05-23 11:05:48.299: [iter 49 : loss : 0.1813 = 0.0874 + 0.0907 + 0.0033, time: 6.496294]
2023-05-23 11:05:48.453: epoch 49:	0.02373749  	0.17458767  	0.09345058  
2023-05-23 11:05:55.082: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.627884]
2023-05-23 11:05:55.236: epoch 50:	0.02384333  	0.17542097  	0.09391881  
2023-05-23 11:05:55.236: Find a better model.
2023-05-23 11:06:01.874: [iter 51 : loss : 0.1775 = 0.0839 + 0.0903 + 0.0034, time: 6.636697]
2023-05-23 11:06:02.016: epoch 51:	0.02396329  	0.17635524  	0.09441360  
2023-05-23 11:06:02.016: Find a better model.
2023-05-23 11:06:08.691: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.674057]
2023-05-23 11:06:08.844: epoch 52:	0.02400563  	0.17671473  	0.09465763  
2023-05-23 11:06:08.844: Find a better model.
2023-05-23 11:06:15.290: [iter 53 : loss : 0.1753 = 0.0821 + 0.0898 + 0.0035, time: 6.445159]
2023-05-23 11:06:15.444: epoch 53:	0.02413264  	0.17779019  	0.09509913  
2023-05-23 11:06:15.444: Find a better model.
2023-05-23 11:06:22.079: [iter 54 : loss : 0.1734 = 0.0803 + 0.0896 + 0.0035, time: 6.632987]
2023-05-23 11:06:22.232: epoch 54:	0.02428083  	0.17872083  	0.09565997  
2023-05-23 11:06:22.232: Find a better model.
2023-05-23 11:06:28.986: [iter 55 : loss : 0.1715 = 0.0785 + 0.0895 + 0.0036, time: 6.753496]
2023-05-23 11:06:29.127: epoch 55:	0.02436550  	0.17930125  	0.09621983  
2023-05-23 11:06:29.127: Find a better model.
2023-05-23 11:06:35.703: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.574260]
2023-05-23 11:06:35.866: epoch 56:	0.02440078  	0.17966528  	0.09638862  
2023-05-23 11:06:35.866: Find a better model.
2023-05-23 11:06:42.310: [iter 57 : loss : 0.1679 = 0.0751 + 0.0891 + 0.0036, time: 6.443650]
2023-05-23 11:06:42.451: epoch 57:	0.02442196  	0.17988072  	0.09669757  
2023-05-23 11:06:42.451: Find a better model.
2023-05-23 11:06:48.876: [iter 58 : loss : 0.1663 = 0.0736 + 0.0890 + 0.0037, time: 6.424115]
2023-05-23 11:06:49.029: epoch 58:	0.02450663  	0.18038569  	0.09706306  
2023-05-23 11:06:49.029: Find a better model.
2023-05-23 11:06:55.482: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.452261]
2023-05-23 11:06:55.639: epoch 59:	0.02455603  	0.18062618  	0.09743509  
2023-05-23 11:06:55.639: Find a better model.
2023-05-23 11:07:02.263: [iter 60 : loss : 0.1636 = 0.0712 + 0.0886 + 0.0038, time: 6.623135]
2023-05-23 11:07:02.416: epoch 60:	0.02462660  	0.18101285  	0.09768119  
2023-05-23 11:07:02.416: Find a better model.
2023-05-23 11:07:09.064: [iter 61 : loss : 0.1622 = 0.0699 + 0.0884 + 0.0038, time: 6.647178]
2023-05-23 11:07:09.220: epoch 61:	0.02461248  	0.18099423  	0.09784648  
2023-05-23 11:07:15.843: [iter 62 : loss : 0.1608 = 0.0687 + 0.0883 + 0.0039, time: 6.622330]
2023-05-23 11:07:16.001: epoch 62:	0.02469716  	0.18165450  	0.09821446  
2023-05-23 11:07:16.001: Find a better model.
2023-05-23 11:07:22.487: [iter 63 : loss : 0.1595 = 0.0674 + 0.0881 + 0.0039, time: 6.484780]
2023-05-23 11:07:22.643: epoch 63:	0.02482417  	0.18256810  	0.09877138  
2023-05-23 11:07:22.644: Find a better model.
2023-05-23 11:07:29.075: [iter 64 : loss : 0.1583 = 0.0664 + 0.0879 + 0.0040, time: 6.429024]
2023-05-23 11:07:29.230: epoch 64:	0.02487356  	0.18310437  	0.09919558  
2023-05-23 11:07:29.230: Find a better model.
2023-05-23 11:07:35.858: [iter 65 : loss : 0.1572 = 0.0654 + 0.0878 + 0.0040, time: 6.627249]
2023-05-23 11:07:36.014: epoch 65:	0.02495824  	0.18370496  	0.09948500  
2023-05-23 11:07:36.014: Find a better model.
2023-05-23 11:07:42.475: [iter 66 : loss : 0.1554 = 0.0637 + 0.0876 + 0.0040, time: 6.459349]
2023-05-23 11:07:42.628: epoch 66:	0.02509937  	0.18491806  	0.09997395  
2023-05-23 11:07:42.628: Find a better model.
2023-05-23 11:07:49.068: [iter 67 : loss : 0.1543 = 0.0627 + 0.0875 + 0.0041, time: 6.438869]
2023-05-23 11:07:49.222: epoch 67:	0.02513465  	0.18506235  	0.10032652  
2023-05-23 11:07:49.222: Find a better model.
2023-05-23 11:07:55.871: [iter 68 : loss : 0.1539 = 0.0624 + 0.0874 + 0.0041, time: 6.647497]
2023-05-23 11:07:56.030: epoch 68:	0.02524756  	0.18570288  	0.10067445  
2023-05-23 11:07:56.030: Find a better model.
2023-05-23 11:08:02.646: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.614734]
2023-05-23 11:08:02.800: epoch 69:	0.02519816  	0.18507026  	0.10084824  
2023-05-23 11:08:09.279: [iter 70 : loss : 0.1503 = 0.0590 + 0.0871 + 0.0042, time: 6.478790]
2023-05-23 11:08:09.434: epoch 70:	0.02529695  	0.18582603  	0.10109586  
2023-05-23 11:08:09.434: Find a better model.
2023-05-23 11:08:16.057: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.621719]
2023-05-23 11:08:16.215: epoch 71:	0.02533929  	0.18589358  	0.10139895  
2023-05-23 11:08:16.215: Find a better model.
2023-05-23 11:08:22.816: [iter 72 : loss : 0.1487 = 0.0575 + 0.0869 + 0.0043, time: 6.599368]
2023-05-23 11:08:22.964: epoch 72:	0.02536752  	0.18608458  	0.10153396  
2023-05-23 11:08:22.965: Find a better model.
2023-05-23 11:08:29.449: [iter 73 : loss : 0.1474 = 0.0563 + 0.0867 + 0.0043, time: 6.483293]
2023-05-23 11:08:29.601: epoch 73:	0.02535341  	0.18596329  	0.10166050  
2023-05-23 11:08:36.215: [iter 74 : loss : 0.1459 = 0.0549 + 0.0867 + 0.0044, time: 6.612609]
2023-05-23 11:08:36.370: epoch 74:	0.02543809  	0.18691701  	0.10207256  
2023-05-23 11:08:36.370: Find a better model.
2023-05-23 11:08:42.845: [iter 75 : loss : 0.1454 = 0.0544 + 0.0865 + 0.0044, time: 6.474640]
2023-05-23 11:08:43.004: epoch 75:	0.02544514  	0.18685783  	0.10212766  
2023-05-23 11:08:49.445: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.437847]
2023-05-23 11:08:49.599: epoch 76:	0.02555805  	0.18746291  	0.10251476  
2023-05-23 11:08:49.599: Find a better model.
2023-05-23 11:08:56.021: [iter 77 : loss : 0.1437 = 0.0529 + 0.0863 + 0.0045, time: 6.420541]
2023-05-23 11:08:56.164: epoch 77:	0.02556510  	0.18750054  	0.10260258  
2023-05-23 11:08:56.164: Find a better model.
2023-05-23 11:09:02.625: [iter 78 : loss : 0.1428 = 0.0520 + 0.0862 + 0.0045, time: 6.459045]
2023-05-23 11:09:02.766: epoch 78:	0.02564977  	0.18806311  	0.10301189  
2023-05-23 11:09:02.766: Find a better model.
2023-05-23 11:09:09.226: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.458860]
2023-05-23 11:09:09.379: epoch 79:	0.02564978  	0.18785538  	0.10300737  
2023-05-23 11:09:15.841: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.459890]
2023-05-23 11:09:15.998: epoch 80:	0.02562861  	0.18757166  	0.10303473  
2023-05-23 11:09:22.432: [iter 81 : loss : 0.1406 = 0.0501 + 0.0859 + 0.0047, time: 6.433198]
2023-05-23 11:09:22.586: epoch 81:	0.02564272  	0.18784498  	0.10319614  
2023-05-23 11:09:29.033: [iter 82 : loss : 0.1393 = 0.0488 + 0.0858 + 0.0047, time: 6.445660]
2023-05-23 11:09:29.188: epoch 82:	0.02567800  	0.18823460  	0.10353021  
2023-05-23 11:09:29.188: Find a better model.
2023-05-23 11:09:35.657: [iter 83 : loss : 0.1383 = 0.0478 + 0.0857 + 0.0047, time: 6.468042]
2023-05-23 11:09:35.811: epoch 83:	0.02574151  	0.18863639  	0.10366400  
2023-05-23 11:09:35.811: Find a better model.
2023-05-23 11:09:42.225: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.412169]
2023-05-23 11:09:42.380: epoch 84:	0.02580502  	0.18922122  	0.10390957  
2023-05-23 11:09:42.380: Find a better model.
2023-05-23 11:09:48.818: [iter 85 : loss : 0.1372 = 0.0469 + 0.0855 + 0.0048, time: 6.437098]
2023-05-23 11:09:48.977: epoch 85:	0.02586853  	0.18975811  	0.10406948  
2023-05-23 11:09:48.977: Find a better model.
2023-05-23 11:09:55.397: [iter 86 : loss : 0.1369 = 0.0467 + 0.0854 + 0.0049, time: 6.419055]
2023-05-23 11:09:55.539: epoch 86:	0.02586852  	0.18979573  	0.10420477  
2023-05-23 11:09:55.539: Find a better model.
2023-05-23 11:10:01.999: [iter 87 : loss : 0.1344 = 0.0441 + 0.0853 + 0.0049, time: 6.459144]
2023-05-23 11:10:02.140: epoch 87:	0.02596731  	0.19054329  	0.10449725  
2023-05-23 11:10:02.140: Find a better model.
2023-05-23 11:10:08.605: [iter 88 : loss : 0.1338 = 0.0436 + 0.0852 + 0.0049, time: 6.462489]
2023-05-23 11:10:08.760: epoch 88:	0.02601670  	0.19096905  	0.10474895  
2023-05-23 11:10:08.760: Find a better model.
2023-05-23 11:10:15.207: [iter 89 : loss : 0.1336 = 0.0435 + 0.0851 + 0.0050, time: 6.446052]
2023-05-23 11:10:15.362: epoch 89:	0.02607315  	0.19120462  	0.10480651  
2023-05-23 11:10:15.363: Find a better model.
2023-05-23 11:10:21.794: [iter 90 : loss : 0.1341 = 0.0440 + 0.0850 + 0.0050, time: 6.429663]
2023-05-23 11:10:21.939: epoch 90:	0.02605904  	0.19108397  	0.10494454  
2023-05-23 11:10:28.390: [iter 91 : loss : 0.1326 = 0.0427 + 0.0849 + 0.0050, time: 6.450559]
2023-05-23 11:10:28.546: epoch 91:	0.02612255  	0.19186124  	0.10523716  
2023-05-23 11:10:28.546: Find a better model.
2023-05-23 11:10:34.996: [iter 92 : loss : 0.1316 = 0.0416 + 0.0849 + 0.0051, time: 6.448850]
2023-05-23 11:10:35.140: epoch 92:	0.02608727  	0.19181442  	0.10528719  
2023-05-23 11:10:41.583: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.439780]
2023-05-23 11:10:41.738: epoch 93:	0.02611550  	0.19200478  	0.10532615  
2023-05-23 11:10:41.738: Find a better model.
2023-05-23 11:10:48.205: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.465945]
2023-05-23 11:10:48.361: epoch 94:	0.02612961  	0.19199675  	0.10533213  
2023-05-23 11:10:54.781: [iter 95 : loss : 0.1293 = 0.0395 + 0.0847 + 0.0052, time: 6.418580]
2023-05-23 11:10:54.924: epoch 95:	0.02612961  	0.19164066  	0.10541593  
2023-05-23 11:11:01.374: [iter 96 : loss : 0.1294 = 0.0396 + 0.0846 + 0.0052, time: 6.449314]
2023-05-23 11:11:01.518: epoch 96:	0.02617195  	0.19220002  	0.10562925  
2023-05-23 11:11:01.518: Find a better model.
2023-05-23 11:11:07.989: [iter 97 : loss : 0.1278 = 0.0381 + 0.0845 + 0.0053, time: 6.469620]
2023-05-23 11:11:08.146: epoch 97:	0.02622134  	0.19300807  	0.10573474  
2023-05-23 11:11:08.146: Find a better model.
2023-05-23 11:11:14.602: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.454327]
2023-05-23 11:11:14.758: epoch 98:	0.02631308  	0.19349094  	0.10613471  
2023-05-23 11:11:14.758: Find a better model.
2023-05-23 11:11:21.378: [iter 99 : loss : 0.1274 = 0.0377 + 0.0844 + 0.0053, time: 6.618607]
2023-05-23 11:11:21.534: epoch 99:	0.02636953  	0.19397253  	0.10633684  
2023-05-23 11:11:21.534: Find a better model.
2023-05-23 11:11:27.990: [iter 100 : loss : 0.1270 = 0.0374 + 0.0843 + 0.0054, time: 6.453434]
2023-05-23 11:11:28.146: epoch 100:	0.02638364  	0.19368596  	0.10620884  
2023-05-23 11:11:34.584: [iter 101 : loss : 0.1265 = 0.0369 + 0.0842 + 0.0054, time: 6.436280]
2023-05-23 11:11:34.738: epoch 101:	0.02638364  	0.19358686  	0.10627765  
2023-05-23 11:11:41.209: [iter 102 : loss : 0.1256 = 0.0360 + 0.0841 + 0.0055, time: 6.470419]
2023-05-23 11:11:41.363: epoch 102:	0.02645420  	0.19418427  	0.10662796  
2023-05-23 11:11:41.363: Find a better model.
2023-05-23 11:11:47.952: [iter 103 : loss : 0.1254 = 0.0358 + 0.0841 + 0.0055, time: 6.587343]
2023-05-23 11:11:48.098: epoch 103:	0.02652477  	0.19486903  	0.10686688  
2023-05-23 11:11:48.099: Find a better model.
2023-05-23 11:11:54.574: [iter 104 : loss : 0.1257 = 0.0361 + 0.0840 + 0.0055, time: 6.473567]
2023-05-23 11:11:54.729: epoch 104:	0.02653888  	0.19513002  	0.10689881  
2023-05-23 11:11:54.729: Find a better model.
2023-05-23 11:12:01.177: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 6.445871]
2023-05-23 11:12:01.333: epoch 105:	0.02658828  	0.19575846  	0.10713873  
2023-05-23 11:12:01.333: Find a better model.
2023-05-23 11:12:07.952: [iter 106 : loss : 0.1245 = 0.0350 + 0.0839 + 0.0056, time: 6.617517]
2023-05-23 11:12:08.109: epoch 106:	0.02656711  	0.19544825  	0.10697599  
2023-05-23 11:12:14.584: [iter 107 : loss : 0.1236 = 0.0341 + 0.0838 + 0.0056, time: 6.472968]
2023-05-23 11:12:14.739: epoch 107:	0.02661651  	0.19594897  	0.10727055  
2023-05-23 11:12:14.739: Find a better model.
2023-05-23 11:12:21.157: [iter 108 : loss : 0.1234 = 0.0340 + 0.0838 + 0.0057, time: 6.416840]
2023-05-23 11:12:21.302: epoch 108:	0.02670118  	0.19621935  	0.10739153  
2023-05-23 11:12:21.302: Find a better model.
2023-05-23 11:12:27.781: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.476895]
2023-05-23 11:12:27.938: epoch 109:	0.02670118  	0.19629322  	0.10746083  
2023-05-23 11:12:27.938: Find a better model.
2023-05-23 11:12:34.371: [iter 110 : loss : 0.1215 = 0.0321 + 0.0837 + 0.0057, time: 6.432113]
2023-05-23 11:12:34.529: epoch 110:	0.02659534  	0.19560142  	0.10722767  
2023-05-23 11:12:41.143: [iter 111 : loss : 0.1216 = 0.0322 + 0.0836 + 0.0058, time: 6.613561]
2023-05-23 11:12:41.301: epoch 111:	0.02662355  	0.19564274  	0.10727712  
2023-05-23 11:12:47.766: [iter 112 : loss : 0.1214 = 0.0320 + 0.0835 + 0.0058, time: 6.463205]
2023-05-23 11:12:47.921: epoch 112:	0.02670823  	0.19628538  	0.10749765  
2023-05-23 11:12:54.358: [iter 113 : loss : 0.1212 = 0.0319 + 0.0835 + 0.0058, time: 6.436635]
2023-05-23 11:12:54.513: epoch 113:	0.02668707  	0.19630834  	0.10754781  
2023-05-23 11:12:54.514: Find a better model.
2023-05-23 11:13:00.948: [iter 114 : loss : 0.1204 = 0.0311 + 0.0834 + 0.0059, time: 6.433154]
2023-05-23 11:13:01.092: epoch 114:	0.02677174  	0.19696628  	0.10781773  
2023-05-23 11:13:01.092: Find a better model.
2023-05-23 11:13:07.567: [iter 115 : loss : 0.1200 = 0.0308 + 0.0834 + 0.0059, time: 6.474648]
2023-05-23 11:13:07.710: epoch 115:	0.02672940  	0.19645868  	0.10755356  
2023-05-23 11:13:14.146: [iter 116 : loss : 0.1193 = 0.0300 + 0.0833 + 0.0059, time: 6.434859]
2023-05-23 11:13:14.305: epoch 116:	0.02677879  	0.19683829  	0.10775827  
2023-05-23 11:13:20.743: [iter 117 : loss : 0.1194 = 0.0301 + 0.0833 + 0.0060, time: 6.437132]
2023-05-23 11:13:20.899: epoch 117:	0.02666589  	0.19621463  	0.10753245  
2023-05-23 11:13:27.345: [iter 118 : loss : 0.1192 = 0.0300 + 0.0832 + 0.0060, time: 6.444685]
2023-05-23 11:13:27.502: epoch 118:	0.02677880  	0.19725415  	0.10795815  
2023-05-23 11:13:27.502: Find a better model.
2023-05-23 11:13:33.935: [iter 119 : loss : 0.1181 = 0.0289 + 0.0831 + 0.0060, time: 6.431019]
2023-05-23 11:13:34.092: epoch 119:	0.02678585  	0.19731760  	0.10796317  
2023-05-23 11:13:34.092: Find a better model.
2023-05-23 11:13:40.703: [iter 120 : loss : 0.1186 = 0.0294 + 0.0831 + 0.0061, time: 6.610161]
2023-05-23 11:13:40.858: epoch 120:	0.02677880  	0.19725314  	0.10803879  
2023-05-23 11:13:47.334: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.474971]
2023-05-23 11:13:47.488: epoch 121:	0.02673646  	0.19679496  	0.10788509  
2023-05-23 11:13:53.941: [iter 122 : loss : 0.1177 = 0.0286 + 0.0830 + 0.0061, time: 6.450838]
2023-05-23 11:13:54.083: epoch 122:	0.02665884  	0.19645454  	0.10783079  
2023-05-23 11:14:00.516: [iter 123 : loss : 0.1175 = 0.0284 + 0.0830 + 0.0061, time: 6.431679]
2023-05-23 11:14:00.658: epoch 123:	0.02671529  	0.19675645  	0.10786640  
2023-05-23 11:14:07.131: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.470990]
2023-05-23 11:14:07.289: epoch 124:	0.02665884  	0.19644643  	0.10783972  
2023-05-23 11:14:13.729: [iter 125 : loss : 0.1160 = 0.0269 + 0.0829 + 0.0062, time: 6.438377]
2023-05-23 11:14:13.883: epoch 125:	0.02662355  	0.19601245  	0.10776889  
2023-05-23 11:14:20.322: [iter 126 : loss : 0.1161 = 0.0271 + 0.0828 + 0.0062, time: 6.437160]
2023-05-23 11:14:20.465: epoch 126:	0.02670824  	0.19629604  	0.10802691  
2023-05-23 11:14:26.935: [iter 127 : loss : 0.1151 = 0.0260 + 0.0828 + 0.0063, time: 6.468920]
2023-05-23 11:14:27.093: epoch 127:	0.02669412  	0.19646488  	0.10815098  
2023-05-23 11:14:33.533: [iter 128 : loss : 0.1163 = 0.0272 + 0.0827 + 0.0063, time: 6.439272]
2023-05-23 11:14:33.690: epoch 128:	0.02674352  	0.19714811  	0.10835914  
2023-05-23 11:14:40.118: [iter 129 : loss : 0.1153 = 0.0263 + 0.0827 + 0.0063, time: 6.427542]
2023-05-23 11:14:40.275: epoch 129:	0.02679292  	0.19769703  	0.10845064  
2023-05-23 11:14:40.275: Find a better model.
2023-05-23 11:14:46.723: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.446567]
2023-05-23 11:14:46.878: epoch 130:	0.02675763  	0.19735259  	0.10834403  
2023-05-23 11:14:53.309: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.428641]
2023-05-23 11:14:53.466: epoch 131:	0.02682820  	0.19762991  	0.10850566  
2023-05-23 11:14:59.907: [iter 132 : loss : 0.1148 = 0.0258 + 0.0826 + 0.0064, time: 6.439181]
2023-05-23 11:15:00.055: epoch 132:	0.02682114  	0.19766261  	0.10857891  
2023-05-23 11:15:06.513: [iter 133 : loss : 0.1134 = 0.0244 + 0.0825 + 0.0064, time: 6.456918]
2023-05-23 11:15:06.667: epoch 133:	0.02685643  	0.19803609  	0.10880266  
2023-05-23 11:15:06.667: Find a better model.
2023-05-23 11:15:13.184: [iter 134 : loss : 0.1143 = 0.0253 + 0.0825 + 0.0065, time: 6.515787]
2023-05-23 11:15:13.348: epoch 134:	0.02689171  	0.19821988  	0.10887195  
2023-05-23 11:15:13.348: Find a better model.
2023-05-23 11:15:19.948: [iter 135 : loss : 0.1139 = 0.0249 + 0.0824 + 0.0065, time: 6.599015]
2023-05-23 11:15:20.117: epoch 135:	0.02689171  	0.19807243  	0.10869563  
2023-05-23 11:15:27.135: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 7.017003]
2023-05-23 11:15:27.281: epoch 136:	0.02688465  	0.19819187  	0.10889875  
2023-05-23 11:15:34.129: [iter 137 : loss : 0.1133 = 0.0244 + 0.0824 + 0.0066, time: 6.846795]
2023-05-23 11:15:34.273: epoch 137:	0.02685643  	0.19796126  	0.10872332  
2023-05-23 11:15:40.969: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.694603]
2023-05-23 11:15:41.137: epoch 138:	0.02683526  	0.19772017  	0.10872532  
2023-05-23 11:15:47.926: [iter 139 : loss : 0.1126 = 0.0237 + 0.0823 + 0.0066, time: 6.788104]
2023-05-23 11:15:48.136: epoch 139:	0.02689876  	0.19797650  	0.10893255  
2023-05-23 11:15:54.909: [iter 140 : loss : 0.1121 = 0.0232 + 0.0822 + 0.0067, time: 6.771167]
2023-05-23 11:15:55.103: epoch 140:	0.02684937  	0.19748825  	0.10876751  
2023-05-23 11:16:02.134: [iter 141 : loss : 0.1127 = 0.0238 + 0.0822 + 0.0067, time: 7.029013]
2023-05-23 11:16:02.340: epoch 141:	0.02687054  	0.19750014  	0.10885753  
2023-05-23 11:16:09.631: [iter 142 : loss : 0.1118 = 0.0229 + 0.0822 + 0.0067, time: 7.286486]
2023-05-23 11:16:09.865: epoch 142:	0.02693404  	0.19802593  	0.10905962  
2023-05-23 11:16:17.204: [iter 143 : loss : 0.1119 = 0.0230 + 0.0821 + 0.0067, time: 7.336323]
2023-05-23 11:16:17.410: epoch 143:	0.02691288  	0.19779566  	0.10872684  
2023-05-23 11:16:24.664: [iter 144 : loss : 0.1114 = 0.0225 + 0.0821 + 0.0068, time: 7.252924]
2023-05-23 11:16:24.835: epoch 144:	0.02695521  	0.19815089  	0.10896729  
2023-05-23 11:16:32.134: [iter 145 : loss : 0.1114 = 0.0225 + 0.0821 + 0.0068, time: 7.295929]
2023-05-23 11:16:32.343: epoch 145:	0.02699050  	0.19841687  	0.10910691  
2023-05-23 11:16:32.343: Find a better model.
2023-05-23 11:16:39.384: [iter 146 : loss : 0.1116 = 0.0228 + 0.0821 + 0.0068, time: 7.037823]
2023-05-23 11:16:39.592: epoch 146:	0.02696228  	0.19806254  	0.10897037  
2023-05-23 11:16:46.933: [iter 147 : loss : 0.1113 = 0.0225 + 0.0820 + 0.0068, time: 7.332512]
2023-05-23 11:16:47.141: epoch 147:	0.02687760  	0.19771481  	0.10887386  
2023-05-23 11:16:54.374: [iter 148 : loss : 0.1101 = 0.0213 + 0.0820 + 0.0069, time: 7.232057]
2023-05-23 11:16:54.551: epoch 148:	0.02691994  	0.19822353  	0.10912406  
2023-05-23 11:17:01.470: [iter 149 : loss : 0.1106 = 0.0218 + 0.0819 + 0.0069, time: 6.914054]
2023-05-23 11:17:01.674: epoch 149:	0.02684937  	0.19750141  	0.10886090  
2023-05-23 11:17:08.700: [iter 150 : loss : 0.1100 = 0.0211 + 0.0819 + 0.0069, time: 7.024460]
2023-05-23 11:17:08.905: epoch 150:	0.02687760  	0.19759177  	0.10883610  
2023-05-23 11:17:16.259: [iter 151 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 7.352480]
2023-05-23 11:17:16.461: epoch 151:	0.02691287  	0.19786817  	0.10906934  
2023-05-23 11:17:23.459: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.995004]
2023-05-23 11:17:23.631: epoch 152:	0.02687759  	0.19701919  	0.10896834  
2023-05-23 11:17:30.455: [iter 153 : loss : 0.1086 = 0.0198 + 0.0818 + 0.0070, time: 6.819080]
2023-05-23 11:17:30.660: epoch 153:	0.02688465  	0.19709095  	0.10891405  
2023-05-23 11:17:37.974: [iter 154 : loss : 0.1091 = 0.0203 + 0.0818 + 0.0070, time: 7.311143]
2023-05-23 11:17:38.182: epoch 154:	0.02686348  	0.19725999  	0.10898627  
2023-05-23 11:17:45.359: [iter 155 : loss : 0.1098 = 0.0210 + 0.0818 + 0.0070, time: 7.176039]
2023-05-23 11:17:45.529: epoch 155:	0.02691993  	0.19754340  	0.10907652  
2023-05-23 11:17:52.377: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.844994]
2023-05-23 11:17:52.573: epoch 156:	0.02686348  	0.19706514  	0.10887185  
2023-05-23 11:17:59.459: [iter 157 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.885003]
2023-05-23 11:17:59.665: epoch 157:	0.02689170  	0.19709925  	0.10891226  
2023-05-23 11:18:06.880: [iter 158 : loss : 0.1082 = 0.0194 + 0.0817 + 0.0071, time: 7.213098]
2023-05-23 11:18:07.092: epoch 158:	0.02682820  	0.19661212  	0.10904434  
2023-05-23 11:18:14.197: [iter 159 : loss : 0.1086 = 0.0198 + 0.0816 + 0.0072, time: 7.104071]
2023-05-23 11:18:14.365: epoch 159:	0.02686348  	0.19691986  	0.10901783  
2023-05-23 11:18:21.179: [iter 160 : loss : 0.1082 = 0.0194 + 0.0816 + 0.0072, time: 6.812420]
2023-05-23 11:18:21.384: epoch 160:	0.02685642  	0.19668671  	0.10889472  
2023-05-23 11:18:28.435: [iter 161 : loss : 0.1076 = 0.0188 + 0.0816 + 0.0072, time: 7.048053]
2023-05-23 11:18:28.635: epoch 161:	0.02682114  	0.19656461  	0.10867000  
2023-05-23 11:18:35.810: [iter 162 : loss : 0.1072 = 0.0184 + 0.0816 + 0.0072, time: 7.173042]
2023-05-23 11:18:36.015: epoch 162:	0.02673646  	0.19601460  	0.10861342  
2023-05-23 11:18:43.038: [iter 163 : loss : 0.1075 = 0.0187 + 0.0815 + 0.0073, time: 7.021020]
2023-05-23 11:18:43.204: epoch 163:	0.02679292  	0.19647728  	0.10876143  
2023-05-23 11:18:49.958: [iter 164 : loss : 0.1076 = 0.0188 + 0.0815 + 0.0073, time: 6.752186]
2023-05-23 11:18:50.160: epoch 164:	0.02677175  	0.19631501  	0.10876326  
2023-05-23 11:18:56.956: [iter 165 : loss : 0.1072 = 0.0184 + 0.0815 + 0.0073, time: 6.794598]
2023-05-23 11:18:57.167: epoch 165:	0.02674352  	0.19618650  	0.10869005  
2023-05-23 11:19:04.344: [iter 166 : loss : 0.1070 = 0.0182 + 0.0815 + 0.0073, time: 7.173032]
2023-05-23 11:19:04.553: epoch 166:	0.02671530  	0.19572760  	0.10857585  
2023-05-23 11:19:11.695: [iter 167 : loss : 0.1073 = 0.0185 + 0.0814 + 0.0073, time: 7.139393]
2023-05-23 11:19:11.882: epoch 167:	0.02670824  	0.19572474  	0.10851083  
2023-05-23 11:19:18.807: [iter 168 : loss : 0.1068 = 0.0181 + 0.0814 + 0.0074, time: 6.922778]
2023-05-23 11:19:18.979: epoch 168:	0.02676469  	0.19592996  	0.10848794  
2023-05-23 11:19:25.704: [iter 169 : loss : 0.1070 = 0.0182 + 0.0814 + 0.0074, time: 6.723176]
2023-05-23 11:19:25.916: epoch 169:	0.02679997  	0.19637683  	0.10860917  
2023-05-23 11:19:32.950: [iter 170 : loss : 0.1065 = 0.0178 + 0.0813 + 0.0074, time: 7.027101]
2023-05-23 11:19:33.157: epoch 170:	0.02680703  	0.19615251  	0.10853791  
2023-05-23 11:19:33.157: Early stopping is trigger at epoch: 170
2023-05-23 11:19:33.157: best_result@epoch 145:

2023-05-23 11:19:33.157: 		0.0270      	0.1984      	0.1091      
2023-05-23 11:25:06.505: my pid: 6860
2023-05-23 11:25:06.505: model: model.general_recommender.SGL
2023-05-23 11:25:06.505: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 11:25:06.505: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 11:25:10.039: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 11:25:17.964: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.925045]
2023-05-23 11:25:18.171: epoch 1:	0.00226503  	0.01516262  	0.00779834  
2023-05-23 11:25:18.171: Find a better model.
2023-05-23 11:25:26.137: [iter 2 : loss : 0.7706 = 0.6928 + 0.0777 + 0.0000, time: 7.963697]
2023-05-23 11:25:26.370: epoch 2:	0.00393733  	0.02799021  	0.01412130  
2023-05-23 11:25:26.370: Find a better model.
2023-05-23 11:25:34.415: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 8.041630]
2023-05-23 11:25:34.608: epoch 3:	0.00682326  	0.04839914  	0.02418543  
2023-05-23 11:25:34.608: Find a better model.
2023-05-23 11:25:42.515: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.905000]
2023-05-23 11:25:42.728: epoch 4:	0.00965279  	0.06787138  	0.03417659  
2023-05-23 11:25:42.728: Find a better model.
2023-05-23 11:25:50.263: [iter 5 : loss : 0.7685 = 0.6906 + 0.0779 + 0.0000, time: 7.533046]
2023-05-23 11:25:50.470: epoch 5:	0.01253183  	0.08944841  	0.04377132  
2023-05-23 11:25:50.470: Find a better model.
2023-05-23 11:25:58.183: [iter 6 : loss : 0.7655 = 0.6873 + 0.0782 + 0.0000, time: 7.711355]
2023-05-23 11:25:58.357: epoch 6:	0.01545317  	0.11151357  	0.05484092  
2023-05-23 11:25:58.357: Find a better model.
2023-05-23 11:26:05.701: [iter 7 : loss : 0.7576 = 0.6786 + 0.0789 + 0.0000, time: 7.341549]
2023-05-23 11:26:05.902: epoch 7:	0.01797937  	0.13048427  	0.06445743  
2023-05-23 11:26:05.902: Find a better model.
2023-05-23 11:26:13.452: [iter 8 : loss : 0.7386 = 0.6576 + 0.0809 + 0.0001, time: 7.549398]
2023-05-23 11:26:13.626: epoch 8:	0.01876264  	0.13740146  	0.06884794  
2023-05-23 11:26:13.626: Find a better model.
2023-05-23 11:26:20.801: [iter 9 : loss : 0.6984 = 0.6134 + 0.0849 + 0.0002, time: 7.173173]
2023-05-23 11:26:21.005: epoch 9:	0.01881910  	0.13920641  	0.07001633  
2023-05-23 11:26:21.005: Find a better model.
2023-05-23 11:26:28.471: [iter 10 : loss : 0.6338 = 0.5433 + 0.0901 + 0.0003, time: 7.463387]
2023-05-23 11:26:28.676: epoch 10:	0.01881204  	0.13986766  	0.06974576  
2023-05-23 11:26:28.676: Find a better model.
2023-05-23 11:26:35.752: [iter 11 : loss : 0.5582 = 0.4629 + 0.0949 + 0.0004, time: 7.075141]
2023-05-23 11:26:35.952: epoch 11:	0.01869914  	0.13849024  	0.06919299  
2023-05-23 11:26:43.360: [iter 12 : loss : 0.4919 = 0.3934 + 0.0979 + 0.0006, time: 7.403402]
2023-05-23 11:26:43.562: epoch 12:	0.01857212  	0.13758136  	0.06913489  
2023-05-23 11:26:50.866: [iter 13 : loss : 0.4436 = 0.3432 + 0.0997 + 0.0007, time: 7.301701]
2023-05-23 11:26:51.026: epoch 13:	0.01870620  	0.13848414  	0.06987349  
2023-05-23 11:26:58.250: [iter 14 : loss : 0.4070 = 0.3056 + 0.1005 + 0.0009, time: 7.215977]
2023-05-23 11:26:58.455: epoch 14:	0.01874854  	0.13929610  	0.07058212  
2023-05-23 11:27:05.944: [iter 15 : loss : 0.3812 = 0.2794 + 0.1008 + 0.0010, time: 7.488343]
2023-05-23 11:27:06.114: epoch 15:	0.01900257  	0.14115477  	0.07146453  
2023-05-23 11:27:06.114: Find a better model.
2023-05-23 11:27:13.250: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 7.133035]
2023-05-23 11:27:13.452: epoch 16:	0.01920721  	0.14205097  	0.07227033  
2023-05-23 11:27:13.452: Find a better model.
2023-05-23 11:27:20.877: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 7.420991]
2023-05-23 11:27:21.084: epoch 17:	0.01947536  	0.14390595  	0.07344931  
2023-05-23 11:27:21.084: Find a better model.
2023-05-23 11:27:28.183: [iter 18 : loss : 0.3285 = 0.2268 + 0.1004 + 0.0013, time: 7.097357]
2023-05-23 11:27:28.348: epoch 18:	0.01964471  	0.14477333  	0.07401408  
2023-05-23 11:27:28.349: Find a better model.
2023-05-23 11:27:35.410: [iter 19 : loss : 0.3146 = 0.2132 + 0.1000 + 0.0014, time: 7.060039]
2023-05-23 11:27:35.615: epoch 19:	0.01999049  	0.14743656  	0.07515564  
2023-05-23 11:27:35.616: Find a better model.
2023-05-23 11:27:42.971: [iter 20 : loss : 0.3051 = 0.2040 + 0.0996 + 0.0015, time: 7.347024]
2023-05-23 11:27:43.177: epoch 20:	0.02018807  	0.14855683  	0.07586826  
2023-05-23 11:27:43.177: Find a better model.
2023-05-23 11:27:50.220: [iter 21 : loss : 0.2955 = 0.1946 + 0.0992 + 0.0016, time: 7.042270]
2023-05-23 11:27:50.427: epoch 21:	0.02048444  	0.15107743  	0.07697838  
2023-05-23 11:27:50.427: Find a better model.
2023-05-23 11:27:57.675: [iter 22 : loss : 0.2874 = 0.1869 + 0.0988 + 0.0017, time: 7.245367]
2023-05-23 11:27:57.880: epoch 22:	0.02052678  	0.15130964  	0.07765212  
2023-05-23 11:27:57.880: Find a better model.
2023-05-23 11:28:05.208: [iter 23 : loss : 0.2793 = 0.1791 + 0.0984 + 0.0018, time: 7.326191]
2023-05-23 11:28:05.401: epoch 23:	0.02075259  	0.15308866  	0.07862877  
2023-05-23 11:28:05.402: Find a better model.
2023-05-23 11:28:12.339: [iter 24 : loss : 0.2727 = 0.1729 + 0.0980 + 0.0018, time: 6.936235]
2023-05-23 11:28:12.539: epoch 24:	0.02095017  	0.15436852  	0.07931756  
2023-05-23 11:28:12.539: Find a better model.
2023-05-23 11:28:19.525: [iter 25 : loss : 0.2660 = 0.1665 + 0.0976 + 0.0019, time: 6.983433]
2023-05-23 11:28:19.732: epoch 25:	0.02109130  	0.15515654  	0.07970235  
2023-05-23 11:28:19.732: Find a better model.
2023-05-23 11:28:27.015: [iter 26 : loss : 0.2624 = 0.1632 + 0.0971 + 0.0020, time: 7.282041]
2023-05-23 11:28:27.222: epoch 26:	0.02130300  	0.15710044  	0.08075352  
2023-05-23 11:28:27.222: Find a better model.
2023-05-23 11:28:34.327: [iter 27 : loss : 0.2548 = 0.1560 + 0.0967 + 0.0021, time: 7.103005]
2023-05-23 11:28:34.498: epoch 27:	0.02138768  	0.15774029  	0.08124165  
2023-05-23 11:28:34.498: Find a better model.
2023-05-23 11:28:41.539: [iter 28 : loss : 0.2499 = 0.1515 + 0.0963 + 0.0021, time: 7.037454]
2023-05-23 11:28:41.745: epoch 28:	0.02152175  	0.15831998  	0.08190703  
2023-05-23 11:28:41.745: Find a better model.
2023-05-23 11:28:49.087: [iter 29 : loss : 0.2456 = 0.1474 + 0.0959 + 0.0022, time: 7.340514]
2023-05-23 11:28:49.294: epoch 29:	0.02180401  	0.16074765  	0.08282644  
2023-05-23 11:28:49.294: Find a better model.
2023-05-23 11:28:56.363: [iter 30 : loss : 0.2389 = 0.1411 + 0.0956 + 0.0022, time: 7.067035]
2023-05-23 11:28:56.517: epoch 30:	0.02191691  	0.16154686  	0.08350454  
2023-05-23 11:28:56.517: Find a better model.
2023-05-23 11:29:03.481: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 6.954640]
2023-05-23 11:29:03.677: epoch 31:	0.02212860  	0.16340527  	0.08445874  
2023-05-23 11:29:03.677: Find a better model.
2023-05-23 11:29:11.000: [iter 32 : loss : 0.2299 = 0.1327 + 0.0949 + 0.0024, time: 7.321333]
2023-05-23 11:29:11.203: epoch 32:	0.02225561  	0.16450532  	0.08516029  
2023-05-23 11:29:11.204: Find a better model.
2023-05-23 11:29:18.237: [iter 33 : loss : 0.2272 = 0.1303 + 0.0945 + 0.0024, time: 7.031352]
2023-05-23 11:29:18.438: epoch 33:	0.02232618  	0.16499774  	0.08548972  
2023-05-23 11:29:18.439: Find a better model.
2023-05-23 11:29:25.570: [iter 34 : loss : 0.2233 = 0.1267 + 0.0941 + 0.0025, time: 7.130515]
2023-05-23 11:29:25.762: epoch 34:	0.02251670  	0.16600043  	0.08625174  
2023-05-23 11:29:25.762: Find a better model.
2023-05-23 11:29:33.156: [iter 35 : loss : 0.2200 = 0.1236 + 0.0938 + 0.0025, time: 7.392040]
2023-05-23 11:29:33.325: epoch 35:	0.02260138  	0.16641490  	0.08671010  
2023-05-23 11:29:33.325: Find a better model.
2023-05-23 11:29:40.213: [iter 36 : loss : 0.2165 = 0.1204 + 0.0935 + 0.0026, time: 6.881185]
2023-05-23 11:29:40.416: epoch 36:	0.02274250  	0.16733912  	0.08739322  
2023-05-23 11:29:40.416: Find a better model.
2023-05-23 11:29:47.850: [iter 37 : loss : 0.2126 = 0.1168 + 0.0932 + 0.0027, time: 7.432101]
2023-05-23 11:29:48.053: epoch 37:	0.02286953  	0.16819064  	0.08794739  
2023-05-23 11:29:48.054: Find a better model.
2023-05-23 11:29:55.186: [iter 38 : loss : 0.2111 = 0.1154 + 0.0929 + 0.0027, time: 7.130463]
2023-05-23 11:29:55.366: epoch 38:	0.02295421  	0.16900292  	0.08859240  
2023-05-23 11:29:55.366: Find a better model.
2023-05-23 11:30:02.395: [iter 39 : loss : 0.2067 = 0.1113 + 0.0926 + 0.0028, time: 7.023046]
2023-05-23 11:30:02.589: epoch 39:	0.02310945  	0.16987517  	0.08933360  
2023-05-23 11:30:02.589: Find a better model.
2023-05-23 11:30:09.907: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 7.316023]
2023-05-23 11:30:10.107: epoch 40:	0.02329292  	0.17168348  	0.08997434  
2023-05-23 11:30:10.107: Find a better model.
2023-05-23 11:30:17.059: [iter 41 : loss : 0.2020 = 0.1070 + 0.0921 + 0.0029, time: 6.951286]
2023-05-23 11:30:17.247: epoch 41:	0.02346228  	0.17275435  	0.09061714  
2023-05-23 11:30:17.247: Find a better model.
2023-05-23 11:30:24.172: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.918345]
2023-05-23 11:30:24.374: epoch 42:	0.02346229  	0.17282155  	0.09100375  
2023-05-23 11:30:24.374: Find a better model.
2023-05-23 11:30:31.639: [iter 43 : loss : 0.1957 = 0.1013 + 0.0915 + 0.0030, time: 7.261680]
2023-05-23 11:30:31.840: epoch 43:	0.02356814  	0.17355233  	0.09143542  
2023-05-23 11:30:31.840: Find a better model.
2023-05-23 11:30:38.923: [iter 44 : loss : 0.1924 = 0.0982 + 0.0912 + 0.0030, time: 7.080096]
2023-05-23 11:30:39.077: epoch 44:	0.02365987  	0.17412505  	0.09196777  
2023-05-23 11:30:39.078: Find a better model.
2023-05-23 11:30:45.971: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.891089]
2023-05-23 11:30:46.179: epoch 45:	0.02373043  	0.17494076  	0.09253443  
2023-05-23 11:30:46.179: Find a better model.
2023-05-23 11:30:53.477: [iter 46 : loss : 0.1880 = 0.0941 + 0.0907 + 0.0031, time: 7.295023]
2023-05-23 11:30:53.680: epoch 46:	0.02385039  	0.17547162  	0.09305882  
2023-05-23 11:30:53.680: Find a better model.
2023-05-23 11:31:00.773: [iter 47 : loss : 0.1871 = 0.0934 + 0.0905 + 0.0032, time: 7.092139]
2023-05-23 11:31:00.941: epoch 47:	0.02387862  	0.17581308  	0.09327468  
2023-05-23 11:31:00.941: Find a better model.
2023-05-23 11:31:07.878: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.935739]
2023-05-23 11:31:08.077: epoch 48:	0.02405502  	0.17718969  	0.09384834  
2023-05-23 11:31:08.077: Find a better model.
2023-05-23 11:31:15.440: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 7.361023]
2023-05-23 11:31:15.640: epoch 49:	0.02416793  	0.17793846  	0.09426921  
2023-05-23 11:31:15.640: Find a better model.
2023-05-23 11:31:22.639: [iter 50 : loss : 0.1795 = 0.0863 + 0.0899 + 0.0033, time: 6.996645]
2023-05-23 11:31:22.844: epoch 50:	0.02419615  	0.17847063  	0.09495719  
2023-05-23 11:31:22.844: Find a better model.
2023-05-23 11:31:30.003: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 7.156096]
2023-05-23 11:31:30.202: epoch 51:	0.02430200  	0.17912990  	0.09506986  
2023-05-23 11:31:30.202: Find a better model.
2023-05-23 11:31:37.602: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 7.397635]
2023-05-23 11:31:37.777: epoch 52:	0.02433728  	0.17959909  	0.09548930  
2023-05-23 11:31:37.777: Find a better model.
2023-05-23 11:31:44.711: [iter 53 : loss : 0.1744 = 0.0816 + 0.0893 + 0.0035, time: 6.931234]
2023-05-23 11:31:44.914: epoch 53:	0.02450664  	0.18099219  	0.09630223  
2023-05-23 11:31:44.914: Find a better model.
2023-05-23 11:31:52.058: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 7.141170]
2023-05-23 11:31:52.262: epoch 54:	0.02457014  	0.18139185  	0.09661812  
2023-05-23 11:31:52.262: Find a better model.
2023-05-23 11:31:59.624: [iter 55 : loss : 0.1704 = 0.0780 + 0.0889 + 0.0036, time: 7.359233]
2023-05-23 11:31:59.796: epoch 55:	0.02468304  	0.18213764  	0.09709402  
2023-05-23 11:31:59.796: Find a better model.
2023-05-23 11:32:06.801: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 7.000931]
2023-05-23 11:32:07.003: epoch 56:	0.02473949  	0.18231598  	0.09750762  
2023-05-23 11:32:07.003: Find a better model.
2023-05-23 11:32:14.328: [iter 57 : loss : 0.1671 = 0.0749 + 0.0885 + 0.0037, time: 7.319276]
2023-05-23 11:32:14.534: epoch 57:	0.02474655  	0.18269460  	0.09785272  
2023-05-23 11:32:14.534: Find a better model.
2023-05-23 11:32:21.774: [iter 58 : loss : 0.1652 = 0.0731 + 0.0884 + 0.0037, time: 7.236951]
2023-05-23 11:32:21.937: epoch 58:	0.02476066  	0.18265121  	0.09809833  
2023-05-23 11:32:28.876: [iter 59 : loss : 0.1640 = 0.0721 + 0.0881 + 0.0038, time: 6.930293]
2023-05-23 11:32:29.077: epoch 59:	0.02487356  	0.18324964  	0.09854422  
2023-05-23 11:32:29.077: Find a better model.
2023-05-23 11:32:36.302: [iter 60 : loss : 0.1627 = 0.0709 + 0.0880 + 0.0038, time: 7.222011]
2023-05-23 11:32:36.502: epoch 60:	0.02486651  	0.18349573  	0.09887529  
2023-05-23 11:32:36.502: Find a better model.
2023-05-23 11:32:43.766: [iter 61 : loss : 0.1613 = 0.0696 + 0.0878 + 0.0038, time: 7.263009]
2023-05-23 11:32:43.935: epoch 61:	0.02481006  	0.18310416  	0.09897175  
2023-05-23 11:32:50.831: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 6.888005]
2023-05-23 11:32:51.034: epoch 62:	0.02483828  	0.18380608  	0.09924914  
2023-05-23 11:32:51.034: Find a better model.
2023-05-23 11:32:58.199: [iter 63 : loss : 0.1584 = 0.0669 + 0.0875 + 0.0039, time: 7.156443]
2023-05-23 11:32:58.402: epoch 63:	0.02494412  	0.18448684  	0.09964348  
2023-05-23 11:32:58.403: Find a better model.
2023-05-23 11:33:05.728: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 7.323853]
2023-05-23 11:33:05.900: epoch 64:	0.02500058  	0.18486513  	0.09990744  
2023-05-23 11:33:05.900: Find a better model.
2023-05-23 11:33:12.807: [iter 65 : loss : 0.1563 = 0.0651 + 0.0872 + 0.0040, time: 6.900359]
2023-05-23 11:33:13.008: epoch 65:	0.02501469  	0.18476124  	0.10011818  
2023-05-23 11:33:20.098: [iter 66 : loss : 0.1547 = 0.0636 + 0.0871 + 0.0041, time: 7.087038]
2023-05-23 11:33:20.299: epoch 66:	0.02512760  	0.18601304  	0.10063750  
2023-05-23 11:33:20.299: Find a better model.
2023-05-23 11:33:27.640: [iter 67 : loss : 0.1531 = 0.0621 + 0.0869 + 0.0041, time: 7.339266]
2023-05-23 11:33:27.810: epoch 67:	0.02505703  	0.18567032  	0.10076292  
2023-05-23 11:33:34.738: [iter 68 : loss : 0.1529 = 0.0619 + 0.0868 + 0.0042, time: 6.925523]
2023-05-23 11:33:34.935: epoch 68:	0.02514877  	0.18616883  	0.10093731  
2023-05-23 11:33:34.935: Find a better model.
2023-05-23 11:33:42.342: [iter 69 : loss : 0.1510 = 0.0602 + 0.0867 + 0.0042, time: 7.403045]
2023-05-23 11:33:42.550: epoch 69:	0.02522639  	0.18641087  	0.10120648  
2023-05-23 11:33:42.550: Find a better model.
2023-05-23 11:33:49.688: [iter 70 : loss : 0.1496 = 0.0588 + 0.0865 + 0.0042, time: 7.137002]
2023-05-23 11:33:49.855: epoch 70:	0.02530401  	0.18721178  	0.10151754  
2023-05-23 11:33:49.856: Find a better model.
2023-05-23 11:33:56.912: [iter 71 : loss : 0.1479 = 0.0572 + 0.0864 + 0.0043, time: 7.050662]
2023-05-23 11:33:57.115: epoch 71:	0.02538869  	0.18779744  	0.10189156  
2023-05-23 11:33:57.115: Find a better model.
2023-05-23 11:34:04.479: [iter 72 : loss : 0.1478 = 0.0572 + 0.0863 + 0.0043, time: 7.360995]
2023-05-23 11:34:04.660: epoch 72:	0.02543103  	0.18843186  	0.10215918  
2023-05-23 11:34:04.660: Find a better model.
2023-05-23 11:34:11.663: [iter 73 : loss : 0.1464 = 0.0559 + 0.0862 + 0.0044, time: 7.001321]
2023-05-23 11:34:11.865: epoch 73:	0.02550159  	0.18889964  	0.10252998  
2023-05-23 11:34:11.865: Find a better model.
2023-05-23 11:34:19.300: [iter 74 : loss : 0.1449 = 0.0544 + 0.0861 + 0.0044, time: 7.433003]
2023-05-23 11:34:19.500: epoch 74:	0.02548748  	0.18856163  	0.10258968  
2023-05-23 11:34:26.739: [iter 75 : loss : 0.1445 = 0.0541 + 0.0860 + 0.0044, time: 7.237046]
2023-05-23 11:34:26.898: epoch 75:	0.02557216  	0.18937315  	0.10295429  
2023-05-23 11:34:26.898: Find a better model.
2023-05-23 11:34:34.306: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 7.402040]
2023-05-23 11:34:34.487: epoch 76:	0.02560744  	0.18967374  	0.10318409  
2023-05-23 11:34:34.487: Find a better model.
2023-05-23 11:34:41.381: [iter 77 : loss : 0.1427 = 0.0525 + 0.0857 + 0.0045, time: 6.887039]
2023-05-23 11:34:41.580: epoch 77:	0.02569918  	0.19046521  	0.10359307  
2023-05-23 11:34:41.580: Find a better model.
2023-05-23 11:34:48.858: [iter 78 : loss : 0.1416 = 0.0514 + 0.0856 + 0.0046, time: 7.276122]
2023-05-23 11:34:49.061: epoch 78:	0.02577680  	0.19091605  	0.10383335  
2023-05-23 11:34:49.062: Find a better model.
2023-05-23 11:34:56.347: [iter 79 : loss : 0.1404 = 0.0503 + 0.0855 + 0.0046, time: 7.283014]
2023-05-23 11:34:56.515: epoch 79:	0.02576973  	0.19101126  	0.10386705  
2023-05-23 11:34:56.515: Find a better model.
2023-05-23 11:35:03.458: [iter 80 : loss : 0.1399 = 0.0498 + 0.0854 + 0.0046, time: 6.936622]
2023-05-23 11:35:03.656: epoch 80:	0.02582619  	0.19146577  	0.10401358  
2023-05-23 11:35:03.656: Find a better model.
2023-05-23 11:35:10.160: [iter 81 : loss : 0.1395 = 0.0495 + 0.0853 + 0.0047, time: 6.503230]
2023-05-23 11:35:10.303: epoch 81:	0.02582619  	0.19145969  	0.10416625  
2023-05-23 11:35:16.890: [iter 82 : loss : 0.1383 = 0.0484 + 0.0852 + 0.0047, time: 6.584100]
2023-05-23 11:35:17.040: epoch 82:	0.02578384  	0.19109236  	0.10427538  
2023-05-23 11:35:23.519: [iter 83 : loss : 0.1373 = 0.0474 + 0.0851 + 0.0048, time: 6.477350]
2023-05-23 11:35:23.667: epoch 83:	0.02579796  	0.19132081  	0.10437614  
2023-05-23 11:35:30.089: [iter 84 : loss : 0.1373 = 0.0475 + 0.0850 + 0.0048, time: 6.420052]
2023-05-23 11:35:30.240: epoch 84:	0.02585441  	0.19172844  	0.10467459  
2023-05-23 11:35:30.240: Find a better model.
2023-05-23 11:35:36.696: [iter 85 : loss : 0.1363 = 0.0465 + 0.0849 + 0.0048, time: 6.455109]
2023-05-23 11:35:36.846: epoch 85:	0.02591086  	0.19226670  	0.10497555  
2023-05-23 11:35:36.846: Find a better model.
2023-05-23 11:35:43.299: [iter 86 : loss : 0.1360 = 0.0464 + 0.0848 + 0.0049, time: 6.452874]
2023-05-23 11:35:43.450: epoch 86:	0.02594614  	0.19252504  	0.10525595  
2023-05-23 11:35:43.450: Find a better model.
2023-05-23 11:35:49.902: [iter 87 : loss : 0.1334 = 0.0437 + 0.0847 + 0.0049, time: 6.449103]
2023-05-23 11:35:50.054: epoch 87:	0.02601671  	0.19321288  	0.10556572  
2023-05-23 11:35:50.054: Find a better model.
2023-05-23 11:35:56.677: [iter 88 : loss : 0.1328 = 0.0432 + 0.0846 + 0.0050, time: 6.622530]
2023-05-23 11:35:56.828: epoch 88:	0.02599554  	0.19287191  	0.10563983  
2023-05-23 11:36:03.310: [iter 89 : loss : 0.1326 = 0.0430 + 0.0845 + 0.0050, time: 6.479611]
2023-05-23 11:36:03.459: epoch 89:	0.02609432  	0.19374205  	0.10586925  
2023-05-23 11:36:03.460: Find a better model.
2023-05-23 11:36:09.885: [iter 90 : loss : 0.1331 = 0.0437 + 0.0844 + 0.0050, time: 6.422855]
2023-05-23 11:36:10.035: epoch 90:	0.02620017  	0.19437258  	0.10608195  
2023-05-23 11:36:10.035: Find a better model.
2023-05-23 11:36:16.471: [iter 91 : loss : 0.1318 = 0.0424 + 0.0844 + 0.0051, time: 6.434299]
2023-05-23 11:36:16.625: epoch 91:	0.02616489  	0.19431578  	0.10599958  
2023-05-23 11:36:23.081: [iter 92 : loss : 0.1307 = 0.0413 + 0.0843 + 0.0051, time: 6.454193]
2023-05-23 11:36:23.232: epoch 92:	0.02624251  	0.19481359  	0.10629053  
2023-05-23 11:36:23.232: Find a better model.
2023-05-23 11:36:29.669: [iter 93 : loss : 0.1314 = 0.0421 + 0.0842 + 0.0052, time: 6.436164]
2023-05-23 11:36:29.820: epoch 93:	0.02627779  	0.19489454  	0.10644723  
2023-05-23 11:36:29.820: Find a better model.
2023-05-23 11:36:36.274: [iter 94 : loss : 0.1293 = 0.0400 + 0.0841 + 0.0052, time: 6.453464]
2023-05-23 11:36:36.424: epoch 94:	0.02626367  	0.19475633  	0.10641580  
2023-05-23 11:36:42.877: [iter 95 : loss : 0.1284 = 0.0391 + 0.0841 + 0.0052, time: 6.451637]
2023-05-23 11:36:43.027: epoch 95:	0.02623545  	0.19516486  	0.10659046  
2023-05-23 11:36:43.027: Find a better model.
2023-05-23 11:36:49.468: [iter 96 : loss : 0.1286 = 0.0394 + 0.0840 + 0.0053, time: 6.439660]
2023-05-23 11:36:49.618: epoch 96:	0.02636247  	0.19617184  	0.10693878  
2023-05-23 11:36:49.618: Find a better model.
2023-05-23 11:36:56.064: [iter 97 : loss : 0.1269 = 0.0377 + 0.0839 + 0.0053, time: 6.443130]
2023-05-23 11:36:56.215: epoch 97:	0.02639775  	0.19633450  	0.10700933  
2023-05-23 11:36:56.215: Find a better model.
2023-05-23 11:37:02.671: [iter 98 : loss : 0.1277 = 0.0385 + 0.0838 + 0.0053, time: 6.455381]
2023-05-23 11:37:02.821: epoch 98:	0.02639775  	0.19648604  	0.10716520  
2023-05-23 11:37:02.821: Find a better model.
2023-05-23 11:37:09.265: [iter 99 : loss : 0.1267 = 0.0375 + 0.0838 + 0.0054, time: 6.443541]
2023-05-23 11:37:09.415: epoch 99:	0.02641892  	0.19658460  	0.10733530  
2023-05-23 11:37:09.415: Find a better model.
2023-05-23 11:37:15.866: [iter 100 : loss : 0.1262 = 0.0371 + 0.0837 + 0.0054, time: 6.449080]
2023-05-23 11:37:16.016: epoch 100:	0.02642598  	0.19663128  	0.10733031  
2023-05-23 11:37:16.017: Find a better model.
2023-05-23 11:37:22.486: [iter 101 : loss : 0.1257 = 0.0367 + 0.0836 + 0.0054, time: 6.468177]
2023-05-23 11:37:22.635: epoch 101:	0.02653888  	0.19760203  	0.10758762  
2023-05-23 11:37:22.635: Find a better model.
2023-05-23 11:37:29.046: [iter 102 : loss : 0.1247 = 0.0357 + 0.0836 + 0.0055, time: 6.409680]
2023-05-23 11:37:29.196: epoch 102:	0.02653888  	0.19742012  	0.10767547  
2023-05-23 11:37:35.627: [iter 103 : loss : 0.1246 = 0.0356 + 0.0835 + 0.0055, time: 6.429620]
2023-05-23 11:37:35.781: epoch 103:	0.02657417  	0.19787310  	0.10791385  
2023-05-23 11:37:35.782: Find a better model.
2023-05-23 11:37:42.247: [iter 104 : loss : 0.1248 = 0.0358 + 0.0834 + 0.0056, time: 6.464636]
2023-05-23 11:37:42.398: epoch 104:	0.02658122  	0.19780655  	0.10803959  
2023-05-23 11:37:48.855: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.454856]
2023-05-23 11:37:49.005: epoch 105:	0.02659533  	0.19795996  	0.10822846  
2023-05-23 11:37:49.006: Find a better model.
2023-05-23 11:37:55.622: [iter 106 : loss : 0.1237 = 0.0348 + 0.0833 + 0.0056, time: 6.613579]
2023-05-23 11:37:55.772: epoch 106:	0.02653182  	0.19750491  	0.10811138  
2023-05-23 11:38:02.255: [iter 107 : loss : 0.1229 = 0.0340 + 0.0832 + 0.0056, time: 6.482132]
2023-05-23 11:38:02.406: epoch 107:	0.02648243  	0.19726619  	0.10808327  
2023-05-23 11:38:08.833: [iter 108 : loss : 0.1225 = 0.0336 + 0.0832 + 0.0057, time: 6.425798]
2023-05-23 11:38:08.983: epoch 108:	0.02653183  	0.19753180  	0.10831321  
2023-05-23 11:38:15.617: [iter 109 : loss : 0.1213 = 0.0325 + 0.0831 + 0.0057, time: 6.632304]
2023-05-23 11:38:15.767: epoch 109:	0.02651772  	0.19734982  	0.10826147  
2023-05-23 11:38:22.228: [iter 110 : loss : 0.1208 = 0.0319 + 0.0831 + 0.0058, time: 6.460181]
2023-05-23 11:38:22.378: epoch 110:	0.02655300  	0.19730105  	0.10848189  
2023-05-23 11:38:28.831: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 6.452585]
2023-05-23 11:38:28.981: epoch 111:	0.02653889  	0.19733679  	0.10851821  
2023-05-23 11:38:35.436: [iter 112 : loss : 0.1206 = 0.0319 + 0.0829 + 0.0058, time: 6.454032]
2023-05-23 11:38:35.586: epoch 112:	0.02657417  	0.19762725  	0.10876442  
2023-05-23 11:38:42.044: [iter 113 : loss : 0.1206 = 0.0319 + 0.0829 + 0.0059, time: 6.457090]
2023-05-23 11:38:42.194: epoch 113:	0.02662356  	0.19779475  	0.10872575  
2023-05-23 11:38:48.620: [iter 114 : loss : 0.1197 = 0.0310 + 0.0828 + 0.0059, time: 6.424330]
2023-05-23 11:38:48.769: epoch 114:	0.02660945  	0.19766675  	0.10874251  
2023-05-23 11:38:55.222: [iter 115 : loss : 0.1193 = 0.0306 + 0.0828 + 0.0059, time: 6.451985]
2023-05-23 11:38:55.363: epoch 115:	0.02653183  	0.19693515  	0.10850098  
2023-05-23 11:39:01.811: [iter 116 : loss : 0.1184 = 0.0297 + 0.0827 + 0.0060, time: 6.447792]
2023-05-23 11:39:01.963: epoch 116:	0.02657416  	0.19700341  	0.10860664  
2023-05-23 11:39:08.426: [iter 117 : loss : 0.1185 = 0.0298 + 0.0827 + 0.0060, time: 6.462120]
2023-05-23 11:39:08.577: epoch 117:	0.02650360  	0.19674200  	0.10851395  
2023-05-23 11:39:15.012: [iter 118 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 6.434054]
2023-05-23 11:39:15.162: epoch 118:	0.02653888  	0.19691014  	0.10878552  
2023-05-23 11:39:21.643: [iter 119 : loss : 0.1175 = 0.0289 + 0.0825 + 0.0061, time: 6.479378]
2023-05-23 11:39:21.795: epoch 119:	0.02655299  	0.19685258  	0.10860133  
2023-05-23 11:39:28.196: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 6.400660]
2023-05-23 11:39:28.346: epoch 120:	0.02656006  	0.19689074  	0.10880924  
2023-05-23 11:39:34.804: [iter 121 : loss : 0.1175 = 0.0290 + 0.0824 + 0.0061, time: 6.455417]
2023-05-23 11:39:34.957: epoch 121:	0.02655300  	0.19698299  	0.10884243  
2023-05-23 11:39:41.397: [iter 122 : loss : 0.1167 = 0.0281 + 0.0824 + 0.0061, time: 6.439502]
2023-05-23 11:39:41.547: epoch 122:	0.02661650  	0.19753680  	0.10904107  
2023-05-23 11:39:48.006: [iter 123 : loss : 0.1165 = 0.0280 + 0.0824 + 0.0062, time: 6.458102]
2023-05-23 11:39:48.157: epoch 123:	0.02668001  	0.19783901  	0.10904793  
2023-05-23 11:39:54.601: [iter 124 : loss : 0.1157 = 0.0271 + 0.0823 + 0.0062, time: 6.442833]
2023-05-23 11:39:54.750: epoch 124:	0.02668002  	0.19789407  	0.10912733  
2023-05-23 11:40:01.207: [iter 125 : loss : 0.1150 = 0.0265 + 0.0823 + 0.0062, time: 6.454726]
2023-05-23 11:40:01.357: epoch 125:	0.02672235  	0.19826195  	0.10928743  
2023-05-23 11:40:01.357: Find a better model.
2023-05-23 11:40:07.794: [iter 126 : loss : 0.1154 = 0.0269 + 0.0822 + 0.0063, time: 6.436538]
2023-05-23 11:40:07.945: epoch 126:	0.02672236  	0.19804157  	0.10929041  
2023-05-23 11:40:14.383: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.437112]
2023-05-23 11:40:14.533: epoch 127:	0.02671530  	0.19820404  	0.10930543  
2023-05-23 11:40:20.996: [iter 128 : loss : 0.1155 = 0.0270 + 0.0821 + 0.0063, time: 6.462260]
2023-05-23 11:40:21.146: epoch 128:	0.02675058  	0.19812444  	0.10949606  
2023-05-23 11:40:27.577: [iter 129 : loss : 0.1145 = 0.0261 + 0.0821 + 0.0064, time: 6.430590]
2023-05-23 11:40:27.726: epoch 129:	0.02670824  	0.19799612  	0.10943288  
2023-05-23 11:40:34.198: [iter 130 : loss : 0.1147 = 0.0263 + 0.0820 + 0.0064, time: 6.470196]
2023-05-23 11:40:34.350: epoch 130:	0.02679291  	0.19827786  	0.10961453  
2023-05-23 11:40:34.350: Find a better model.
2023-05-23 11:40:40.815: [iter 131 : loss : 0.1137 = 0.0253 + 0.0820 + 0.0064, time: 6.463997]
2023-05-23 11:40:40.965: epoch 131:	0.02687053  	0.19894838  	0.10980734  
2023-05-23 11:40:40.965: Find a better model.
2023-05-23 11:40:47.371: [iter 132 : loss : 0.1140 = 0.0256 + 0.0820 + 0.0064, time: 6.405721]
2023-05-23 11:40:47.520: epoch 132:	0.02686347  	0.19863111  	0.10981014  
2023-05-23 11:40:53.971: [iter 133 : loss : 0.1127 = 0.0243 + 0.0819 + 0.0065, time: 6.449847]
2023-05-23 11:40:54.123: epoch 133:	0.02689170  	0.19892561  	0.10981856  
2023-05-23 11:41:00.562: [iter 134 : loss : 0.1134 = 0.0251 + 0.0819 + 0.0065, time: 6.437408]
2023-05-23 11:41:00.702: epoch 134:	0.02688465  	0.19874263  	0.11005224  
2023-05-23 11:41:07.181: [iter 135 : loss : 0.1132 = 0.0249 + 0.0818 + 0.0065, time: 6.477392]
2023-05-23 11:41:07.333: epoch 135:	0.02691993  	0.19924773  	0.11018529  
2023-05-23 11:41:07.333: Find a better model.
2023-05-23 11:41:13.765: [iter 136 : loss : 0.1128 = 0.0245 + 0.0818 + 0.0066, time: 6.431036]
2023-05-23 11:41:13.916: epoch 136:	0.02691993  	0.19910873  	0.11007661  
2023-05-23 11:41:20.383: [iter 137 : loss : 0.1125 = 0.0241 + 0.0818 + 0.0066, time: 6.464867]
2023-05-23 11:41:20.532: epoch 137:	0.02693405  	0.19942315  	0.11018766  
2023-05-23 11:41:20.532: Find a better model.
2023-05-23 11:41:26.941: [iter 138 : loss : 0.1122 = 0.0239 + 0.0817 + 0.0066, time: 6.406215]
2023-05-23 11:41:27.080: epoch 138:	0.02692699  	0.19932050  	0.11017661  
2023-05-23 11:41:33.538: [iter 139 : loss : 0.1119 = 0.0236 + 0.0817 + 0.0067, time: 6.456330]
2023-05-23 11:41:33.689: epoch 139:	0.02686349  	0.19895168  	0.11008886  
2023-05-23 11:41:40.144: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.452945]
2023-05-23 11:41:40.295: epoch 140:	0.02687054  	0.19871488  	0.11006680  
2023-05-23 11:41:46.759: [iter 141 : loss : 0.1120 = 0.0237 + 0.0816 + 0.0067, time: 6.462871]
2023-05-23 11:41:46.909: epoch 141:	0.02686348  	0.19856107  	0.11000506  
2023-05-23 11:41:53.357: [iter 142 : loss : 0.1110 = 0.0227 + 0.0816 + 0.0067, time: 6.447315]
2023-05-23 11:41:53.508: epoch 142:	0.02680703  	0.19803329  	0.10990341  
2023-05-23 11:41:59.962: [iter 143 : loss : 0.1111 = 0.0228 + 0.0815 + 0.0068, time: 6.452956]
2023-05-23 11:42:00.113: epoch 143:	0.02685642  	0.19870368  	0.11002755  
2023-05-23 11:42:06.555: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.441136]
2023-05-23 11:42:06.705: epoch 144:	0.02686348  	0.19884823  	0.11008152  
2023-05-23 11:42:13.149: [iter 145 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.443071]
2023-05-23 11:42:13.304: epoch 145:	0.02681408  	0.19834688  	0.11002761  
2023-05-23 11:42:19.740: [iter 146 : loss : 0.1109 = 0.0226 + 0.0814 + 0.0068, time: 6.434952]
2023-05-23 11:42:19.890: epoch 146:	0.02677880  	0.19806507  	0.10997132  
2023-05-23 11:42:26.334: [iter 147 : loss : 0.1106 = 0.0223 + 0.0814 + 0.0069, time: 6.441691]
2023-05-23 11:42:26.486: epoch 147:	0.02671528  	0.19763008  	0.10972989  
2023-05-23 11:42:32.933: [iter 148 : loss : 0.1094 = 0.0211 + 0.0814 + 0.0069, time: 6.444982]
2023-05-23 11:42:33.083: epoch 148:	0.02669412  	0.19731914  	0.10995752  
2023-05-23 11:42:39.564: [iter 149 : loss : 0.1098 = 0.0216 + 0.0813 + 0.0069, time: 6.479872]
2023-05-23 11:42:39.713: epoch 149:	0.02670823  	0.19719699  	0.10987827  
2023-05-23 11:42:46.133: [iter 150 : loss : 0.1090 = 0.0208 + 0.0813 + 0.0070, time: 6.418056]
2023-05-23 11:42:46.283: epoch 150:	0.02675763  	0.19770093  	0.10986824  
2023-05-23 11:42:52.719: [iter 151 : loss : 0.1093 = 0.0211 + 0.0813 + 0.0070, time: 6.434646]
2023-05-23 11:42:52.868: epoch 151:	0.02673646  	0.19791412  	0.10990223  
2023-05-23 11:42:59.333: [iter 152 : loss : 0.1086 = 0.0203 + 0.0812 + 0.0070, time: 6.464009]
2023-05-23 11:42:59.483: epoch 152:	0.02680703  	0.19836493  	0.11006343  
2023-05-23 11:43:05.918: [iter 153 : loss : 0.1079 = 0.0197 + 0.0812 + 0.0070, time: 6.433324]
2023-05-23 11:43:06.068: epoch 153:	0.02675763  	0.19766241  	0.10973657  
2023-05-23 11:43:12.529: [iter 154 : loss : 0.1083 = 0.0200 + 0.0812 + 0.0071, time: 6.459701]
2023-05-23 11:43:12.679: epoch 154:	0.02677174  	0.19782320  	0.10981584  
2023-05-23 11:43:19.125: [iter 155 : loss : 0.1092 = 0.0210 + 0.0812 + 0.0071, time: 6.444906]
2023-05-23 11:43:19.273: epoch 155:	0.02665178  	0.19678326  	0.10950247  
2023-05-23 11:43:25.695: [iter 156 : loss : 0.1083 = 0.0200 + 0.0811 + 0.0071, time: 6.421474]
2023-05-23 11:43:25.845: epoch 156:	0.02672941  	0.19747965  	0.10981417  
2023-05-23 11:43:32.307: [iter 157 : loss : 0.1082 = 0.0199 + 0.0811 + 0.0071, time: 6.460293]
2023-05-23 11:43:32.457: epoch 157:	0.02675058  	0.19760185  	0.10986272  
2023-05-23 11:43:38.733: [iter 158 : loss : 0.1074 = 0.0192 + 0.0811 + 0.0072, time: 6.274661]
2023-05-23 11:43:38.881: epoch 158:	0.02672941  	0.19720307  	0.10985400  
2023-05-23 11:43:45.322: [iter 159 : loss : 0.1078 = 0.0196 + 0.0810 + 0.0072, time: 6.440066]
2023-05-23 11:43:45.472: epoch 159:	0.02679292  	0.19767727  	0.10984524  
2023-05-23 11:43:51.889: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.415791]
2023-05-23 11:43:52.038: epoch 160:	0.02675057  	0.19727987  	0.10971367  
2023-05-23 11:43:58.538: [iter 161 : loss : 0.1070 = 0.0188 + 0.0810 + 0.0072, time: 6.497464]
2023-05-23 11:43:58.689: epoch 161:	0.02672940  	0.19707853  	0.10957196  
2023-05-23 11:44:05.118: [iter 162 : loss : 0.1064 = 0.0182 + 0.0810 + 0.0073, time: 6.425698]
2023-05-23 11:44:05.267: epoch 162:	0.02669412  	0.19673835  	0.10950442  
2023-05-23 11:44:05.268: Early stopping is trigger at epoch: 162
2023-05-23 11:44:05.268: best_result@epoch 137:

2023-05-23 11:44:05.268: 		0.0269      	0.1994      	0.1102      
2023-05-23 14:26:09.192: my pid: 8812
2023-05-23 14:26:09.192: model: model.general_recommender.SGL
2023-05-23 14:26:09.192: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 14:26:09.192: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 14:26:12.434: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 14:26:19.926: [iter 1 : loss : 0.7707 = 0.6930 + 0.0777 + 0.0000, time: 7.490952]
2023-05-23 14:26:20.080: epoch 1:	0.00184166  	0.01263301  	0.00654013  
2023-05-23 14:26:20.081: Find a better model.
2023-05-23 14:26:27.703: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.621249]
2023-05-23 14:26:27.906: epoch 2:	0.00337284  	0.02299904  	0.01204654  
2023-05-23 14:26:27.906: Find a better model.
2023-05-23 14:26:35.482: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.575094]
2023-05-23 14:26:35.646: epoch 3:	0.00572957  	0.03984051  	0.01999145  
2023-05-23 14:26:35.647: Find a better model.
2023-05-23 14:26:43.104: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.456154]
2023-05-23 14:26:43.264: epoch 4:	0.00829093  	0.05818607  	0.02891807  
2023-05-23 14:26:43.264: Find a better model.
2023-05-23 14:26:50.697: [iter 5 : loss : 0.7685 = 0.6911 + 0.0773 + 0.0000, time: 7.432484]
2023-05-23 14:26:50.861: epoch 5:	0.01097234  	0.07813116  	0.03792636  
2023-05-23 14:26:50.861: Find a better model.
2023-05-23 14:26:58.059: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.197069]
2023-05-23 14:26:58.206: epoch 6:	0.01390782  	0.09964009  	0.04869604  
2023-05-23 14:26:58.206: Find a better model.
2023-05-23 14:27:05.449: [iter 7 : loss : 0.7603 = 0.6821 + 0.0781 + 0.0000, time: 7.241386]
2023-05-23 14:27:05.601: epoch 7:	0.01662453  	0.12055860  	0.06001072  
2023-05-23 14:27:05.601: Find a better model.
2023-05-23 14:27:12.657: [iter 8 : loss : 0.7458 = 0.6661 + 0.0796 + 0.0001, time: 7.053994]
2023-05-23 14:27:12.809: epoch 8:	0.01809933  	0.13272350  	0.06665342  
2023-05-23 14:27:12.809: Find a better model.
2023-05-23 14:27:19.857: [iter 9 : loss : 0.7136 = 0.6307 + 0.0828 + 0.0001, time: 7.046185]
2023-05-23 14:27:20.010: epoch 9:	0.01896023  	0.13956262  	0.06984499  
2023-05-23 14:27:20.011: Find a better model.
2023-05-23 14:27:26.861: [iter 10 : loss : 0.6572 = 0.5693 + 0.0877 + 0.0002, time: 6.848880]
2023-05-23 14:27:27.014: epoch 10:	0.01879792  	0.13888215  	0.06953159  
2023-05-23 14:27:33.848: [iter 11 : loss : 0.5830 = 0.4899 + 0.0927 + 0.0004, time: 6.833510]
2023-05-23 14:27:33.990: epoch 11:	0.01874853  	0.13853832  	0.06938243  
2023-05-23 14:27:40.851: [iter 12 : loss : 0.5118 = 0.4148 + 0.0964 + 0.0005, time: 6.859317]
2023-05-23 14:27:41.002: epoch 12:	0.01862858  	0.13779764  	0.06936896  
2023-05-23 14:27:47.884: [iter 13 : loss : 0.4579 = 0.3586 + 0.0986 + 0.0007, time: 6.880344]
2023-05-23 14:27:48.036: epoch 13:	0.01868503  	0.13837290  	0.07009313  
2023-05-23 14:27:54.866: [iter 14 : loss : 0.4168 = 0.3163 + 0.0997 + 0.0008, time: 6.828459]
2023-05-23 14:27:55.018: epoch 14:	0.01879793  	0.13970174  	0.07082270  
2023-05-23 14:27:55.018: Find a better model.
2023-05-23 14:28:01.843: [iter 15 : loss : 0.3882 = 0.2870 + 0.1002 + 0.0010, time: 6.823570]
2023-05-23 14:28:01.993: epoch 15:	0.01908019  	0.14162889  	0.07195254  
2023-05-23 14:28:01.994: Find a better model.
2023-05-23 14:28:08.649: [iter 16 : loss : 0.3646 = 0.2632 + 0.1003 + 0.0011, time: 6.652690]
2023-05-23 14:28:08.799: epoch 16:	0.01920720  	0.14229302  	0.07251367  
2023-05-23 14:28:08.799: Find a better model.
2023-05-23 14:28:15.625: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 6.824571]
2023-05-23 14:28:15.776: epoch 17:	0.01946830  	0.14392185  	0.07326841  
2023-05-23 14:28:15.776: Find a better model.
2023-05-23 14:28:22.658: [iter 18 : loss : 0.3315 = 0.2302 + 0.1000 + 0.0013, time: 6.880776]
2023-05-23 14:28:22.810: epoch 18:	0.01965177  	0.14478464  	0.07387745  
2023-05-23 14:28:22.810: Find a better model.
2023-05-23 14:28:29.633: [iter 19 : loss : 0.3170 = 0.2159 + 0.0997 + 0.0014, time: 6.821121]
2023-05-23 14:28:29.784: epoch 19:	0.01985642  	0.14602862  	0.07471439  
2023-05-23 14:28:29.784: Find a better model.
2023-05-23 14:28:36.610: [iter 20 : loss : 0.3070 = 0.2062 + 0.0993 + 0.0015, time: 6.824626]
2023-05-23 14:28:36.760: epoch 20:	0.02001871  	0.14702585  	0.07524761  
2023-05-23 14:28:36.760: Find a better model.
2023-05-23 14:28:43.606: [iter 21 : loss : 0.2970 = 0.1965 + 0.0989 + 0.0016, time: 6.844297]
2023-05-23 14:28:43.758: epoch 21:	0.02023746  	0.14898494  	0.07622320  
2023-05-23 14:28:43.758: Find a better model.
2023-05-23 14:28:50.600: [iter 22 : loss : 0.2887 = 0.1885 + 0.0986 + 0.0017, time: 6.841014]
2023-05-23 14:28:50.752: epoch 22:	0.02044211  	0.15050206  	0.07692098  
2023-05-23 14:28:50.752: Find a better model.
2023-05-23 14:28:57.423: [iter 23 : loss : 0.2803 = 0.1804 + 0.0982 + 0.0018, time: 6.669652]
2023-05-23 14:28:57.574: epoch 23:	0.02063968  	0.15207136  	0.07775033  
2023-05-23 14:28:57.574: Find a better model.
2023-05-23 14:29:04.398: [iter 24 : loss : 0.2737 = 0.1741 + 0.0977 + 0.0018, time: 6.821542]
2023-05-23 14:29:04.547: epoch 24:	0.02072436  	0.15233544  	0.07821469  
2023-05-23 14:29:04.547: Find a better model.
2023-05-23 14:29:11.232: [iter 25 : loss : 0.2668 = 0.1676 + 0.0973 + 0.0019, time: 6.684098]
2023-05-23 14:29:11.386: epoch 25:	0.02086550  	0.15294945  	0.07885315  
2023-05-23 14:29:11.387: Find a better model.
2023-05-23 14:29:18.044: [iter 26 : loss : 0.2631 = 0.1642 + 0.0969 + 0.0020, time: 6.654039]
2023-05-23 14:29:18.193: epoch 26:	0.02112658  	0.15472722  	0.07983322  
2023-05-23 14:29:18.193: Find a better model.
2023-05-23 14:29:24.828: [iter 27 : loss : 0.2553 = 0.1568 + 0.0965 + 0.0020, time: 6.632046]
2023-05-23 14:29:24.978: epoch 27:	0.02136651  	0.15666816  	0.08087270  
2023-05-23 14:29:24.978: Find a better model.
2023-05-23 14:29:31.639: [iter 28 : loss : 0.2505 = 0.1523 + 0.0961 + 0.0021, time: 6.660089]
2023-05-23 14:29:31.789: epoch 28:	0.02154998  	0.15827820  	0.08174153  
2023-05-23 14:29:31.790: Find a better model.
2023-05-23 14:29:38.420: [iter 29 : loss : 0.2459 = 0.1481 + 0.0957 + 0.0022, time: 6.629514]
2023-05-23 14:29:38.572: epoch 29:	0.02172640  	0.15971377  	0.08249741  
2023-05-23 14:29:38.572: Find a better model.
2023-05-23 14:29:45.207: [iter 30 : loss : 0.2394 = 0.1418 + 0.0953 + 0.0022, time: 6.634449]
2023-05-23 14:29:45.359: epoch 30:	0.02190986  	0.16095780  	0.08317903  
2023-05-23 14:29:45.359: Find a better model.
2023-05-23 14:29:52.024: [iter 31 : loss : 0.2358 = 0.1386 + 0.0949 + 0.0023, time: 6.663173]
2023-05-23 14:29:52.177: epoch 31:	0.02190986  	0.16110072  	0.08350351  
2023-05-23 14:29:52.177: Find a better model.
2023-05-23 14:29:58.800: [iter 32 : loss : 0.2302 = 0.1332 + 0.0946 + 0.0024, time: 6.622036]
2023-05-23 14:29:58.951: epoch 32:	0.02198041  	0.16151007  	0.08403222  
2023-05-23 14:29:58.951: Find a better model.
2023-05-23 14:30:05.603: [iter 33 : loss : 0.2275 = 0.1309 + 0.0942 + 0.0024, time: 6.651575]
2023-05-23 14:30:05.755: epoch 33:	0.02222739  	0.16329829  	0.08491320  
2023-05-23 14:30:05.756: Find a better model.
2023-05-23 14:30:12.402: [iter 34 : loss : 0.2235 = 0.1272 + 0.0939 + 0.0025, time: 6.644687]
2023-05-23 14:30:12.554: epoch 34:	0.02239674  	0.16472049  	0.08579855  
2023-05-23 14:30:12.555: Find a better model.
2023-05-23 14:30:19.368: [iter 35 : loss : 0.2202 = 0.1241 + 0.0936 + 0.0025, time: 6.812179]
2023-05-23 14:30:19.521: epoch 35:	0.02249553  	0.16545883  	0.08639324  
2023-05-23 14:30:19.521: Find a better model.
2023-05-23 14:30:26.203: [iter 36 : loss : 0.2167 = 0.1208 + 0.0932 + 0.0026, time: 6.679416]
2023-05-23 14:30:26.353: epoch 36:	0.02268607  	0.16692373  	0.08713873  
2023-05-23 14:30:26.353: Find a better model.
2023-05-23 14:30:32.997: [iter 37 : loss : 0.2127 = 0.1172 + 0.0929 + 0.0027, time: 6.643178]
2023-05-23 14:30:33.147: epoch 37:	0.02285542  	0.16781949  	0.08779534  
2023-05-23 14:30:33.148: Find a better model.
2023-05-23 14:30:39.975: [iter 38 : loss : 0.2112 = 0.1158 + 0.0926 + 0.0027, time: 6.825849]
2023-05-23 14:30:40.126: epoch 38:	0.02303183  	0.16904332  	0.08840193  
2023-05-23 14:30:40.126: Find a better model.
2023-05-23 14:30:46.819: [iter 39 : loss : 0.2067 = 0.1116 + 0.0923 + 0.0028, time: 6.692325]
2023-05-23 14:30:46.958: epoch 39:	0.02309535  	0.16942576  	0.08908097  
2023-05-23 14:30:46.958: Find a better model.
2023-05-23 14:30:53.836: [iter 40 : loss : 0.2035 = 0.1087 + 0.0920 + 0.0028, time: 6.877885]
2023-05-23 14:30:53.977: epoch 40:	0.02313768  	0.17027912  	0.08937012  
2023-05-23 14:30:53.977: Find a better model.
2023-05-23 14:31:00.617: [iter 41 : loss : 0.2020 = 0.1073 + 0.0918 + 0.0029, time: 6.637066]
2023-05-23 14:31:00.756: epoch 41:	0.02330704  	0.17165153  	0.09020279  
2023-05-23 14:31:00.756: Find a better model.
2023-05-23 14:31:07.392: [iter 42 : loss : 0.1997 = 0.1053 + 0.0915 + 0.0029, time: 6.634098]
2023-05-23 14:31:07.544: epoch 42:	0.02327176  	0.17193711  	0.09038866  
2023-05-23 14:31:07.544: Find a better model.
2023-05-23 14:31:14.181: [iter 43 : loss : 0.1957 = 0.1015 + 0.0912 + 0.0030, time: 6.636593]
2023-05-23 14:31:14.332: epoch 43:	0.02344817  	0.17299117  	0.09104364  
2023-05-23 14:31:14.333: Find a better model.
2023-05-23 14:31:21.004: [iter 44 : loss : 0.1923 = 0.0983 + 0.0909 + 0.0030, time: 6.668674]
2023-05-23 14:31:21.154: epoch 44:	0.02351168  	0.17349999  	0.09145813  
2023-05-23 14:31:21.154: Find a better model.
2023-05-23 14:31:27.961: [iter 45 : loss : 0.1902 = 0.0964 + 0.0907 + 0.0031, time: 6.805413]
2023-05-23 14:31:28.112: epoch 45:	0.02358225  	0.17399858  	0.09204414  
2023-05-23 14:31:28.112: Find a better model.
2023-05-23 14:31:34.779: [iter 46 : loss : 0.1878 = 0.0943 + 0.0904 + 0.0031, time: 6.665981]
2023-05-23 14:31:34.930: epoch 46:	0.02370221  	0.17504273  	0.09257882  
2023-05-23 14:31:34.930: Find a better model.
2023-05-23 14:31:41.733: [iter 47 : loss : 0.1870 = 0.0936 + 0.0902 + 0.0032, time: 6.800755]
2023-05-23 14:31:41.883: epoch 47:	0.02379394  	0.17580071  	0.09319530  
2023-05-23 14:31:41.883: Find a better model.
2023-05-23 14:31:48.574: [iter 48 : loss : 0.1832 = 0.0900 + 0.0900 + 0.0032, time: 6.690214]
2023-05-23 14:31:48.730: epoch 48:	0.02389979  	0.17678928  	0.09387034  
2023-05-23 14:31:48.730: Find a better model.
2023-05-23 14:31:55.376: [iter 49 : loss : 0.1801 = 0.0870 + 0.0898 + 0.0033, time: 6.643849]
2023-05-23 14:31:55.528: epoch 49:	0.02398446  	0.17699817  	0.09416573  
2023-05-23 14:31:55.528: Find a better model.
2023-05-23 14:32:02.154: [iter 50 : loss : 0.1793 = 0.0864 + 0.0896 + 0.0033, time: 6.624559]
2023-05-23 14:32:02.304: epoch 50:	0.02393507  	0.17674609  	0.09433962  
2023-05-23 14:32:08.973: [iter 51 : loss : 0.1763 = 0.0835 + 0.0894 + 0.0034, time: 6.667974]
2023-05-23 14:32:09.125: epoch 51:	0.02402679  	0.17735709  	0.09457123  
2023-05-23 14:32:09.126: Find a better model.
2023-05-23 14:32:15.962: [iter 52 : loss : 0.1762 = 0.0837 + 0.0891 + 0.0034, time: 6.835113]
2023-05-23 14:32:16.114: epoch 52:	0.02416086  	0.17792709  	0.09512957  
2023-05-23 14:32:16.114: Find a better model.
2023-05-23 14:32:22.785: [iter 53 : loss : 0.1741 = 0.0817 + 0.0889 + 0.0035, time: 6.669734]
2023-05-23 14:32:22.938: epoch 53:	0.02423849  	0.17857713  	0.09544121  
2023-05-23 14:32:22.938: Find a better model.
2023-05-23 14:32:29.765: [iter 54 : loss : 0.1721 = 0.0799 + 0.0887 + 0.0035, time: 6.825666]
2023-05-23 14:32:29.919: epoch 54:	0.02445018  	0.18001950  	0.09610868  
2023-05-23 14:32:29.919: Find a better model.
2023-05-23 14:32:36.741: [iter 55 : loss : 0.1702 = 0.0780 + 0.0885 + 0.0036, time: 6.820829]
2023-05-23 14:32:36.890: epoch 55:	0.02445018  	0.18010218  	0.09634014  
2023-05-23 14:32:36.891: Find a better model.
2023-05-23 14:32:43.553: [iter 56 : loss : 0.1686 = 0.0766 + 0.0883 + 0.0036, time: 6.661311]
2023-05-23 14:32:43.706: epoch 56:	0.02449957  	0.18050979  	0.09665351  
2023-05-23 14:32:43.706: Find a better model.
2023-05-23 14:32:50.372: [iter 57 : loss : 0.1668 = 0.0749 + 0.0882 + 0.0037, time: 6.664501]
2023-05-23 14:32:50.522: epoch 57:	0.02448545  	0.18041222  	0.09686062  
2023-05-23 14:32:57.146: [iter 58 : loss : 0.1648 = 0.0730 + 0.0880 + 0.0037, time: 6.623455]
2023-05-23 14:32:57.298: epoch 58:	0.02458424  	0.18139713  	0.09738103  
2023-05-23 14:32:57.298: Find a better model.
2023-05-23 14:33:03.957: [iter 59 : loss : 0.1638 = 0.0722 + 0.0878 + 0.0038, time: 6.658132]
2023-05-23 14:33:04.109: epoch 59:	0.02474654  	0.18239968  	0.09800763  
2023-05-23 14:33:04.109: Find a better model.
2023-05-23 14:33:10.746: [iter 60 : loss : 0.1623 = 0.0708 + 0.0877 + 0.0038, time: 6.636812]
2023-05-23 14:33:10.899: epoch 60:	0.02478888  	0.18276311  	0.09829921  
2023-05-23 14:33:10.899: Find a better model.
2023-05-23 14:33:17.543: [iter 61 : loss : 0.1611 = 0.0697 + 0.0875 + 0.0039, time: 6.642373]
2023-05-23 14:33:17.694: epoch 61:	0.02480299  	0.18274090  	0.09839930  
2023-05-23 14:33:24.323: [iter 62 : loss : 0.1594 = 0.0681 + 0.0873 + 0.0039, time: 6.627462]
2023-05-23 14:33:24.476: epoch 62:	0.02495823  	0.18368578  	0.09888104  
2023-05-23 14:33:24.476: Find a better model.
2023-05-23 14:33:31.304: [iter 63 : loss : 0.1582 = 0.0670 + 0.0872 + 0.0039, time: 6.826526]
2023-05-23 14:33:31.455: epoch 63:	0.02495823  	0.18373223  	0.09928072  
2023-05-23 14:33:31.455: Find a better model.
2023-05-23 14:33:38.138: [iter 64 : loss : 0.1571 = 0.0661 + 0.0870 + 0.0040, time: 6.682083]
2023-05-23 14:33:38.290: epoch 64:	0.02511347  	0.18521522  	0.09983912  
2023-05-23 14:33:38.290: Find a better model.
2023-05-23 14:33:44.939: [iter 65 : loss : 0.1561 = 0.0652 + 0.0868 + 0.0040, time: 6.647560]
2023-05-23 14:33:45.092: epoch 65:	0.02519110  	0.18581724  	0.10010979  
2023-05-23 14:33:45.092: Find a better model.
2023-05-23 14:33:51.756: [iter 66 : loss : 0.1543 = 0.0636 + 0.0867 + 0.0041, time: 6.662180]
2023-05-23 14:33:51.911: epoch 66:	0.02512758  	0.18536921  	0.10015307  
2023-05-23 14:33:58.546: [iter 67 : loss : 0.1528 = 0.0621 + 0.0866 + 0.0041, time: 6.634133]
2023-05-23 14:33:58.698: epoch 67:	0.02527577  	0.18646969  	0.10065993  
2023-05-23 14:33:58.698: Find a better model.
2023-05-23 14:34:05.335: [iter 68 : loss : 0.1526 = 0.0620 + 0.0864 + 0.0042, time: 6.635886]
2023-05-23 14:34:05.487: epoch 68:	0.02533222  	0.18680799  	0.10104673  
2023-05-23 14:34:05.487: Find a better model.
2023-05-23 14:34:12.306: [iter 69 : loss : 0.1506 = 0.0601 + 0.0863 + 0.0042, time: 6.817946]
2023-05-23 14:34:12.458: epoch 69:	0.02545218  	0.18783037  	0.10150159  
2023-05-23 14:34:12.458: Find a better model.
2023-05-23 14:34:19.143: [iter 70 : loss : 0.1491 = 0.0587 + 0.0862 + 0.0042, time: 6.683796]
2023-05-23 14:34:19.294: epoch 70:	0.02550158  	0.18795571  	0.10166833  
2023-05-23 14:34:19.295: Find a better model.
2023-05-23 14:34:26.095: [iter 71 : loss : 0.1476 = 0.0572 + 0.0861 + 0.0043, time: 6.798857]
2023-05-23 14:34:26.247: epoch 71:	0.02555097  	0.18840747  	0.10190415  
2023-05-23 14:34:26.247: Find a better model.
2023-05-23 14:34:33.099: [iter 72 : loss : 0.1475 = 0.0573 + 0.0859 + 0.0043, time: 6.848897]
2023-05-23 14:34:33.252: epoch 72:	0.02555098  	0.18818295  	0.10214444  
2023-05-23 14:34:40.104: [iter 73 : loss : 0.1461 = 0.0559 + 0.0858 + 0.0044, time: 6.850148]
2023-05-23 14:34:40.257: epoch 73:	0.02556509  	0.18860507  	0.10232600  
2023-05-23 14:34:40.257: Find a better model.
2023-05-23 14:34:46.901: [iter 74 : loss : 0.1447 = 0.0545 + 0.0857 + 0.0044, time: 6.641646]
2023-05-23 14:34:47.042: epoch 74:	0.02566388  	0.18957463  	0.10264485  
2023-05-23 14:34:47.042: Find a better model.
2023-05-23 14:34:53.692: [iter 75 : loss : 0.1442 = 0.0541 + 0.0856 + 0.0045, time: 6.649376]
2023-05-23 14:34:53.844: epoch 75:	0.02569916  	0.18970859  	0.10295956  
2023-05-23 14:34:53.844: Find a better model.
2023-05-23 14:35:00.519: [iter 76 : loss : 0.1432 = 0.0533 + 0.0854 + 0.0045, time: 6.673758]
2023-05-23 14:35:00.672: epoch 76:	0.02570622  	0.18993632  	0.10320146  
2023-05-23 14:35:00.672: Find a better model.
2023-05-23 14:35:07.310: [iter 77 : loss : 0.1422 = 0.0524 + 0.0853 + 0.0045, time: 6.635874]
2023-05-23 14:35:07.462: epoch 77:	0.02581207  	0.19102865  	0.10366350  
2023-05-23 14:35:07.462: Find a better model.
2023-05-23 14:35:14.132: [iter 78 : loss : 0.1413 = 0.0515 + 0.0852 + 0.0046, time: 6.669104]
2023-05-23 14:35:14.282: epoch 78:	0.02577679  	0.19058476  	0.10369552  
2023-05-23 14:35:20.909: [iter 79 : loss : 0.1402 = 0.0505 + 0.0851 + 0.0046, time: 6.626329]
2023-05-23 14:35:21.061: epoch 79:	0.02579090  	0.19047703  	0.10376827  
2023-05-23 14:35:27.698: [iter 80 : loss : 0.1394 = 0.0498 + 0.0850 + 0.0047, time: 6.634978]
2023-05-23 14:35:27.848: epoch 80:	0.02581913  	0.19053502  	0.10398530  
2023-05-23 14:35:34.487: [iter 81 : loss : 0.1392 = 0.0496 + 0.0849 + 0.0047, time: 6.637411]
2023-05-23 14:35:34.638: epoch 81:	0.02589675  	0.19103403  	0.10434877  
2023-05-23 14:35:34.639: Find a better model.
2023-05-23 14:35:41.267: [iter 82 : loss : 0.1379 = 0.0484 + 0.0848 + 0.0047, time: 6.627492]
2023-05-23 14:35:41.419: epoch 82:	0.02595320  	0.19154775  	0.10447999  
2023-05-23 14:35:41.419: Find a better model.
2023-05-23 14:35:47.903: [iter 83 : loss : 0.1370 = 0.0475 + 0.0847 + 0.0048, time: 6.481782]
2023-05-23 14:35:48.054: epoch 83:	0.02597437  	0.19171475  	0.10469096  
2023-05-23 14:35:48.054: Find a better model.
2023-05-23 14:35:54.484: [iter 84 : loss : 0.1369 = 0.0474 + 0.0846 + 0.0048, time: 6.429215]
2023-05-23 14:35:54.636: epoch 84:	0.02602376  	0.19198214  	0.10483064  
2023-05-23 14:35:54.637: Find a better model.
2023-05-23 14:36:01.248: [iter 85 : loss : 0.1359 = 0.0465 + 0.0845 + 0.0049, time: 6.610222]
2023-05-23 14:36:01.401: epoch 85:	0.02602376  	0.19199826  	0.10497855  
2023-05-23 14:36:01.401: Find a better model.
2023-05-23 14:36:07.876: [iter 86 : loss : 0.1357 = 0.0464 + 0.0844 + 0.0049, time: 6.474410]
2023-05-23 14:36:08.015: epoch 86:	0.02598848  	0.19143395  	0.10499699  
2023-05-23 14:36:14.474: [iter 87 : loss : 0.1330 = 0.0438 + 0.0843 + 0.0049, time: 6.456918]
2023-05-23 14:36:14.626: epoch 87:	0.02609432  	0.19207972  	0.10513329  
2023-05-23 14:36:14.627: Find a better model.
2023-05-23 14:36:21.259: [iter 88 : loss : 0.1324 = 0.0432 + 0.0843 + 0.0050, time: 6.631441]
2023-05-23 14:36:21.412: epoch 88:	0.02601670  	0.19175535  	0.10508548  
2023-05-23 14:36:28.064: [iter 89 : loss : 0.1322 = 0.0430 + 0.0842 + 0.0050, time: 6.649483]
2023-05-23 14:36:28.213: epoch 89:	0.02598848  	0.19124922  	0.10497590  
2023-05-23 14:36:34.855: [iter 90 : loss : 0.1328 = 0.0436 + 0.0841 + 0.0050, time: 6.640407]
2023-05-23 14:36:35.006: epoch 90:	0.02603787  	0.19169606  	0.10527247  
2023-05-23 14:36:41.681: [iter 91 : loss : 0.1315 = 0.0424 + 0.0840 + 0.0051, time: 6.673882]
2023-05-23 14:36:41.821: epoch 91:	0.02610138  	0.19248967  	0.10553043  
2023-05-23 14:36:41.821: Find a better model.
2023-05-23 14:36:48.477: [iter 92 : loss : 0.1306 = 0.0415 + 0.0839 + 0.0051, time: 6.653923]
2023-05-23 14:36:48.627: epoch 92:	0.02610844  	0.19245870  	0.10550124  
2023-05-23 14:36:55.275: [iter 93 : loss : 0.1311 = 0.0421 + 0.0838 + 0.0052, time: 6.646879]
2023-05-23 14:36:55.427: epoch 93:	0.02615784  	0.19274428  	0.10580050  
2023-05-23 14:36:55.428: Find a better model.
2023-05-23 14:37:02.052: [iter 94 : loss : 0.1288 = 0.0398 + 0.0837 + 0.0052, time: 6.622515]
2023-05-23 14:37:02.204: epoch 94:	0.02611550  	0.19279721  	0.10571918  
2023-05-23 14:37:02.205: Find a better model.
2023-05-23 14:37:08.860: [iter 95 : loss : 0.1281 = 0.0392 + 0.0837 + 0.0052, time: 6.653279]
2023-05-23 14:37:09.020: epoch 95:	0.02619312  	0.19288202  	0.10603604  
2023-05-23 14:37:09.020: Find a better model.
2023-05-23 14:37:15.670: [iter 96 : loss : 0.1283 = 0.0394 + 0.0836 + 0.0053, time: 6.646317]
2023-05-23 14:37:15.819: epoch 96:	0.02624252  	0.19354908  	0.10634750  
2023-05-23 14:37:15.820: Find a better model.
2023-05-23 14:37:22.452: [iter 97 : loss : 0.1265 = 0.0377 + 0.0835 + 0.0053, time: 6.630516]
2023-05-23 14:37:22.603: epoch 97:	0.02634131  	0.19393566  	0.10658161  
2023-05-23 14:37:22.603: Find a better model.
2023-05-23 14:37:29.430: [iter 98 : loss : 0.1273 = 0.0385 + 0.0834 + 0.0053, time: 6.826439]
2023-05-23 14:37:29.583: epoch 98:	0.02636953  	0.19416632  	0.10665710  
2023-05-23 14:37:29.583: Find a better model.
2023-05-23 14:37:36.243: [iter 99 : loss : 0.1263 = 0.0375 + 0.0834 + 0.0054, time: 6.659238]
2023-05-23 14:37:36.396: epoch 99:	0.02636953  	0.19434892  	0.10684960  
2023-05-23 14:37:36.396: Find a better model.
2023-05-23 14:37:43.035: [iter 100 : loss : 0.1258 = 0.0371 + 0.0833 + 0.0054, time: 6.638697]
2023-05-23 14:37:43.186: epoch 100:	0.02643304  	0.19508776  	0.10705281  
2023-05-23 14:37:43.187: Find a better model.
2023-05-23 14:37:49.835: [iter 101 : loss : 0.1253 = 0.0366 + 0.0832 + 0.0055, time: 6.646884]
2023-05-23 14:37:49.988: epoch 101:	0.02644010  	0.19493788  	0.10708686  
2023-05-23 14:37:56.651: [iter 102 : loss : 0.1244 = 0.0358 + 0.0832 + 0.0055, time: 6.660769]
2023-05-23 14:37:56.802: epoch 102:	0.02646832  	0.19503488  	0.10711724  
2023-05-23 14:38:03.440: [iter 103 : loss : 0.1241 = 0.0355 + 0.0831 + 0.0055, time: 6.636396]
2023-05-23 14:38:03.592: epoch 103:	0.02646832  	0.19493988  	0.10711057  
2023-05-23 14:38:10.230: [iter 104 : loss : 0.1245 = 0.0359 + 0.0830 + 0.0056, time: 6.635450]
2023-05-23 14:38:10.381: epoch 104:	0.02641892  	0.19491729  	0.10716453  
2023-05-23 14:38:16.868: [iter 105 : loss : 0.1237 = 0.0352 + 0.0829 + 0.0056, time: 6.483957]
2023-05-23 14:38:17.022: epoch 105:	0.02644009  	0.19505996  	0.10717744  
2023-05-23 14:38:23.644: [iter 106 : loss : 0.1234 = 0.0349 + 0.0829 + 0.0056, time: 6.619792]
2023-05-23 14:38:23.784: epoch 106:	0.02639070  	0.19478516  	0.10705109  
2023-05-23 14:38:30.416: [iter 107 : loss : 0.1225 = 0.0340 + 0.0828 + 0.0057, time: 6.630930]
2023-05-23 14:38:30.567: epoch 107:	0.02633424  	0.19429716  	0.10695946  
2023-05-23 14:38:37.204: [iter 108 : loss : 0.1222 = 0.0337 + 0.0828 + 0.0057, time: 6.635855]
2023-05-23 14:38:37.354: epoch 108:	0.02638364  	0.19465120  	0.10714453  
2023-05-23 14:38:44.042: [iter 109 : loss : 0.1210 = 0.0326 + 0.0827 + 0.0057, time: 6.681604]
2023-05-23 14:38:44.193: epoch 109:	0.02646831  	0.19513279  	0.10738988  
2023-05-23 14:38:44.194: Find a better model.
2023-05-23 14:38:50.816: [iter 110 : loss : 0.1203 = 0.0319 + 0.0827 + 0.0058, time: 6.621546]
2023-05-23 14:38:50.966: epoch 110:	0.02647537  	0.19517443  	0.10731808  
2023-05-23 14:38:50.967: Find a better model.
2023-05-23 14:38:57.633: [iter 111 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 6.664517]
2023-05-23 14:38:57.785: epoch 111:	0.02644715  	0.19513763  	0.10732418  
2023-05-23 14:39:04.409: [iter 112 : loss : 0.1202 = 0.0318 + 0.0825 + 0.0058, time: 6.622343]
2023-05-23 14:39:04.559: epoch 112:	0.02651771  	0.19531879  	0.10739703  
2023-05-23 14:39:04.559: Find a better model.
2023-05-23 14:39:11.205: [iter 113 : loss : 0.1201 = 0.0318 + 0.0825 + 0.0059, time: 6.645381]
2023-05-23 14:39:11.356: epoch 113:	0.02653182  	0.19521794  	0.10748562  
2023-05-23 14:39:18.012: [iter 114 : loss : 0.1193 = 0.0310 + 0.0824 + 0.0059, time: 6.654335]
2023-05-23 14:39:18.163: epoch 114:	0.02656711  	0.19559601  	0.10755963  
2023-05-23 14:39:18.163: Find a better model.
2023-05-23 14:39:24.816: [iter 115 : loss : 0.1188 = 0.0305 + 0.0824 + 0.0059, time: 6.652434]
2023-05-23 14:39:24.969: epoch 115:	0.02658122  	0.19568148  	0.10773084  
2023-05-23 14:39:24.969: Find a better model.
2023-05-23 14:39:31.788: [iter 116 : loss : 0.1179 = 0.0296 + 0.0823 + 0.0060, time: 6.818724]
2023-05-23 14:39:31.940: epoch 116:	0.02661651  	0.19571282  	0.10785745  
2023-05-23 14:39:31.940: Find a better model.
2023-05-23 14:39:38.619: [iter 117 : loss : 0.1180 = 0.0297 + 0.0823 + 0.0060, time: 6.676968]
2023-05-23 14:39:38.770: epoch 117:	0.02668002  	0.19648065  	0.10798045  
2023-05-23 14:39:38.770: Find a better model.
2023-05-23 14:39:45.398: [iter 118 : loss : 0.1179 = 0.0297 + 0.0822 + 0.0060, time: 6.626686]
2023-05-23 14:39:45.550: epoch 118:	0.02658828  	0.19554131  	0.10787883  
2023-05-23 14:39:52.212: [iter 119 : loss : 0.1171 = 0.0289 + 0.0821 + 0.0061, time: 6.661513]
2023-05-23 14:39:52.365: epoch 119:	0.02661650  	0.19585483  	0.10802308  
2023-05-23 14:39:58.982: [iter 120 : loss : 0.1173 = 0.0291 + 0.0821 + 0.0061, time: 6.614760]
2023-05-23 14:39:59.133: epoch 120:	0.02665178  	0.19593610  	0.10803103  
2023-05-23 14:40:05.795: [iter 121 : loss : 0.1170 = 0.0289 + 0.0821 + 0.0061, time: 6.661341]
2023-05-23 14:40:05.950: epoch 121:	0.02652477  	0.19509086  	0.10779587  
2023-05-23 14:40:12.610: [iter 122 : loss : 0.1163 = 0.0282 + 0.0820 + 0.0062, time: 6.658437]
2023-05-23 14:40:12.761: epoch 122:	0.02659534  	0.19565137  	0.10800689  
2023-05-23 14:40:19.379: [iter 123 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 6.615573]
2023-05-23 14:40:19.530: epoch 123:	0.02659534  	0.19571209  	0.10807741  
2023-05-23 14:40:26.179: [iter 124 : loss : 0.1153 = 0.0272 + 0.0819 + 0.0062, time: 6.648042]
2023-05-23 14:40:26.330: epoch 124:	0.02665179  	0.19621380  	0.10825136  
2023-05-23 14:40:32.983: [iter 125 : loss : 0.1146 = 0.0265 + 0.0819 + 0.0062, time: 6.650913]
2023-05-23 14:40:33.134: epoch 125:	0.02663062  	0.19601887  	0.10829545  
2023-05-23 14:40:39.970: [iter 126 : loss : 0.1151 = 0.0270 + 0.0818 + 0.0063, time: 6.833694]
2023-05-23 14:40:40.121: epoch 126:	0.02662357  	0.19634855  	0.10841046  
2023-05-23 14:40:46.770: [iter 127 : loss : 0.1140 = 0.0259 + 0.0818 + 0.0063, time: 6.648329]
2023-05-23 14:40:46.924: epoch 127:	0.02660945  	0.19607460  	0.10836141  
2023-05-23 14:40:53.586: [iter 128 : loss : 0.1151 = 0.0270 + 0.0817 + 0.0063, time: 6.660136]
2023-05-23 14:40:53.737: epoch 128:	0.02663768  	0.19619887  	0.10846068  
2023-05-23 14:41:00.381: [iter 129 : loss : 0.1142 = 0.0261 + 0.0817 + 0.0064, time: 6.642699]
2023-05-23 14:41:00.522: epoch 129:	0.02665179  	0.19587550  	0.10846239  
2023-05-23 14:41:07.193: [iter 130 : loss : 0.1143 = 0.0263 + 0.0816 + 0.0064, time: 6.670886]
2023-05-23 14:41:07.344: epoch 130:	0.02657417  	0.19547075  	0.10829233  
2023-05-23 14:41:13.994: [iter 131 : loss : 0.1133 = 0.0252 + 0.0816 + 0.0064, time: 6.649184]
2023-05-23 14:41:14.148: epoch 131:	0.02661651  	0.19599949  	0.10870804  
2023-05-23 14:41:20.966: [iter 132 : loss : 0.1135 = 0.0255 + 0.0816 + 0.0065, time: 6.815910]
2023-05-23 14:41:21.120: epoch 132:	0.02663062  	0.19604106  	0.10876323  
2023-05-23 14:41:27.774: [iter 133 : loss : 0.1124 = 0.0244 + 0.0815 + 0.0065, time: 6.652869]
2023-05-23 14:41:27.928: epoch 133:	0.02664473  	0.19625099  	0.10878634  
2023-05-23 14:41:34.557: [iter 134 : loss : 0.1130 = 0.0250 + 0.0815 + 0.0065, time: 6.627977]
2023-05-23 14:41:34.709: epoch 134:	0.02664474  	0.19621377  	0.10883278  
2023-05-23 14:41:41.368: [iter 135 : loss : 0.1128 = 0.0248 + 0.0814 + 0.0066, time: 6.658055]
2023-05-23 14:41:41.519: epoch 135:	0.02658123  	0.19547364  	0.10862806  
2023-05-23 14:41:48.149: [iter 136 : loss : 0.1125 = 0.0245 + 0.0814 + 0.0066, time: 6.628791]
2023-05-23 14:41:48.303: epoch 136:	0.02651772  	0.19501103  	0.10857944  
2023-05-23 14:41:54.954: [iter 137 : loss : 0.1121 = 0.0241 + 0.0814 + 0.0066, time: 6.649265]
2023-05-23 14:41:55.108: epoch 137:	0.02650361  	0.19462039  	0.10833659  
2023-05-23 14:42:01.748: [iter 138 : loss : 0.1117 = 0.0237 + 0.0813 + 0.0066, time: 6.637165]
2023-05-23 14:42:01.899: epoch 138:	0.02660240  	0.19562271  	0.10886768  
2023-05-23 14:42:08.529: [iter 139 : loss : 0.1115 = 0.0235 + 0.0813 + 0.0067, time: 6.628296]
2023-05-23 14:42:08.682: epoch 139:	0.02658828  	0.19535647  	0.10871115  
2023-05-23 14:42:15.340: [iter 140 : loss : 0.1108 = 0.0228 + 0.0812 + 0.0067, time: 6.656281]
2023-05-23 14:42:15.490: epoch 140:	0.02656711  	0.19520280  	0.10882542  
2023-05-23 14:42:22.132: [iter 141 : loss : 0.1116 = 0.0236 + 0.0812 + 0.0067, time: 6.639805]
2023-05-23 14:42:22.284: epoch 141:	0.02658123  	0.19552436  	0.10897480  
2023-05-23 14:42:28.938: [iter 142 : loss : 0.1107 = 0.0227 + 0.0812 + 0.0068, time: 6.653447]
2023-05-23 14:42:29.090: epoch 142:	0.02665179  	0.19613795  	0.10906079  
2023-05-23 14:42:29.090: Early stopping is trigger at epoch: 142
2023-05-23 14:42:29.090: best_result@epoch 117:

2023-05-23 14:42:29.090: 		0.0267      	0.1965      	0.1080      
2023-05-23 18:37:23.117: my pid: 4108
2023-05-23 18:37:23.117: model: model.general_recommender.SGL
2023-05-23 18:37:23.117: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 18:37:23.117: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 18:37:26.821: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 18:37:33.915: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.093018]
2023-05-23 18:37:34.071: epoch 1:	0.00203924  	0.01432136  	0.00729454  
2023-05-23 18:37:34.071: Find a better model.
2023-05-23 18:37:41.278: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.205919]
2023-05-23 18:37:41.480: epoch 2:	0.00478406  	0.03443001  	0.01690566  
2023-05-23 18:37:41.480: Find a better model.
2023-05-23 18:37:48.496: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.014234]
2023-05-23 18:37:48.671: epoch 3:	0.00788873  	0.05646078  	0.02796516  
2023-05-23 18:37:48.671: Find a better model.
2023-05-23 18:37:55.656: [iter 4 : loss : 0.7713 = 0.6914 + 0.0800 + 0.0000, time: 6.984088]
2023-05-23 18:37:55.802: epoch 4:	0.01172033  	0.08282045  	0.03980501  
2023-05-23 18:37:55.802: Find a better model.
2023-05-23 18:38:02.498: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 6.694999]
2023-05-23 18:38:02.651: epoch 5:	0.01521326  	0.10884760  	0.05229084  
2023-05-23 18:38:02.651: Find a better model.
2023-05-23 18:38:09.287: [iter 6 : loss : 0.7660 = 0.6850 + 0.0809 + 0.0000, time: 6.633299]
2023-05-23 18:38:09.438: epoch 6:	0.01762655  	0.12596598  	0.06164180  
2023-05-23 18:38:09.438: Find a better model.
2023-05-23 18:38:16.050: [iter 7 : loss : 0.7561 = 0.6739 + 0.0822 + 0.0000, time: 6.610972]
2023-05-23 18:38:16.203: epoch 7:	0.01864268  	0.13527347  	0.06688826  
2023-05-23 18:38:16.203: Find a better model.
2023-05-23 18:38:22.657: [iter 8 : loss : 0.7333 = 0.6483 + 0.0849 + 0.0001, time: 6.452977]
2023-05-23 18:38:22.802: epoch 8:	0.01890378  	0.13831645  	0.06872977  
2023-05-23 18:38:22.802: Find a better model.
2023-05-23 18:38:29.275: [iter 9 : loss : 0.6876 = 0.5979 + 0.0895 + 0.0002, time: 6.471217]
2023-05-23 18:38:29.426: epoch 9:	0.01873442  	0.13818790  	0.06860495  
2023-05-23 18:38:35.860: [iter 10 : loss : 0.6197 = 0.5246 + 0.0948 + 0.0003, time: 6.433259]
2023-05-23 18:38:36.004: epoch 10:	0.01829691  	0.13509032  	0.06706029  
2023-05-23 18:38:42.265: [iter 11 : loss : 0.5468 = 0.4473 + 0.0990 + 0.0005, time: 6.259311]
2023-05-23 18:38:42.410: epoch 11:	0.01835337  	0.13575500  	0.06715121  
2023-05-23 18:38:48.834: [iter 12 : loss : 0.4859 = 0.3837 + 0.1016 + 0.0006, time: 6.422683]
2023-05-23 18:38:48.981: epoch 12:	0.01828986  	0.13479917  	0.06730105  
2023-05-23 18:38:55.255: [iter 13 : loss : 0.4417 = 0.3380 + 0.1029 + 0.0008, time: 6.272493]
2023-05-23 18:38:55.410: epoch 13:	0.01848745  	0.13685237  	0.06832035  
2023-05-23 18:39:01.862: [iter 14 : loss : 0.4077 = 0.3034 + 0.1034 + 0.0009, time: 6.451199]
2023-05-23 18:39:02.021: epoch 14:	0.01874854  	0.13879488  	0.06923629  
2023-05-23 18:39:02.021: Find a better model.
2023-05-23 18:39:08.427: [iter 15 : loss : 0.3837 = 0.2792 + 0.1035 + 0.0010, time: 6.404811]
2023-05-23 18:39:08.583: epoch 15:	0.01882615  	0.13954487  	0.06991188  
2023-05-23 18:39:08.583: Find a better model.
2023-05-23 18:39:15.038: [iter 16 : loss : 0.3631 = 0.2585 + 0.1035 + 0.0011, time: 6.453176]
2023-05-23 18:39:15.196: epoch 16:	0.01905196  	0.14125791  	0.07095956  
2023-05-23 18:39:15.196: Find a better model.
2023-05-23 18:39:21.613: [iter 17 : loss : 0.3477 = 0.2434 + 0.1032 + 0.0012, time: 6.415978]
2023-05-23 18:39:21.769: epoch 17:	0.01922837  	0.14225909  	0.07166037  
2023-05-23 18:39:21.769: Find a better model.
2023-05-23 18:39:28.231: [iter 18 : loss : 0.3331 = 0.2289 + 0.1029 + 0.0013, time: 6.461385]
2023-05-23 18:39:28.385: epoch 18:	0.01936245  	0.14336030  	0.07235111  
2023-05-23 18:39:28.385: Find a better model.
2023-05-23 18:39:34.831: [iter 19 : loss : 0.3195 = 0.2156 + 0.1025 + 0.0014, time: 6.445214]
2023-05-23 18:39:34.972: epoch 19:	0.01962354  	0.14525086  	0.07337818  
2023-05-23 18:39:34.972: Find a better model.
2023-05-23 18:39:41.253: [iter 20 : loss : 0.3101 = 0.2065 + 0.1021 + 0.0015, time: 6.278766]
2023-05-23 18:39:41.408: epoch 20:	0.01988464  	0.14728081  	0.07441803  
2023-05-23 18:39:41.408: Find a better model.
2023-05-23 18:39:47.860: [iter 21 : loss : 0.3008 = 0.1975 + 0.1017 + 0.0016, time: 6.451446]
2023-05-23 18:39:48.015: epoch 21:	0.02006811  	0.14867450  	0.07526683  
2023-05-23 18:39:48.015: Find a better model.
2023-05-23 18:39:54.435: [iter 22 : loss : 0.2926 = 0.1897 + 0.1012 + 0.0017, time: 6.418435]
2023-05-23 18:39:54.589: epoch 22:	0.02030803  	0.15070923  	0.07621783  
2023-05-23 18:39:54.590: Find a better model.
2023-05-23 18:40:01.020: [iter 23 : loss : 0.2845 = 0.1819 + 0.1008 + 0.0017, time: 6.428780]
2023-05-23 18:40:01.176: epoch 23:	0.02044915  	0.15141676  	0.07680257  
2023-05-23 18:40:01.176: Find a better model.
2023-05-23 18:40:07.629: [iter 24 : loss : 0.2781 = 0.1759 + 0.1004 + 0.0018, time: 6.450729]
2023-05-23 18:40:07.782: epoch 24:	0.02060440  	0.15200818  	0.07732188  
2023-05-23 18:40:07.783: Find a better model.
2023-05-23 18:40:14.248: [iter 25 : loss : 0.2715 = 0.1696 + 0.1000 + 0.0019, time: 6.464472]
2023-05-23 18:40:14.402: epoch 25:	0.02083021  	0.15347055  	0.07818237  
2023-05-23 18:40:14.402: Find a better model.
2023-05-23 18:40:21.013: [iter 26 : loss : 0.2678 = 0.1663 + 0.0995 + 0.0020, time: 6.609412]
2023-05-23 18:40:21.157: epoch 26:	0.02100662  	0.15437225  	0.07877313  
2023-05-23 18:40:21.157: Find a better model.
2023-05-23 18:40:27.440: [iter 27 : loss : 0.2602 = 0.1590 + 0.0991 + 0.0020, time: 6.281512]
2023-05-23 18:40:27.594: epoch 27:	0.02123243  	0.15572694  	0.07970133  
2023-05-23 18:40:27.594: Find a better model.
2023-05-23 18:40:34.042: [iter 28 : loss : 0.2553 = 0.1546 + 0.0987 + 0.0021, time: 6.445776]
2023-05-23 18:40:34.198: epoch 28:	0.02148647  	0.15756127  	0.08083389  
2023-05-23 18:40:34.198: Find a better model.
2023-05-23 18:40:40.622: [iter 29 : loss : 0.2510 = 0.1506 + 0.0983 + 0.0021, time: 6.422996]
2023-05-23 18:40:40.766: epoch 29:	0.02165583  	0.15919425  	0.08170892  
2023-05-23 18:40:40.766: Find a better model.
2023-05-23 18:40:47.217: [iter 30 : loss : 0.2442 = 0.1441 + 0.0979 + 0.0022, time: 6.448544]
2023-05-23 18:40:47.371: epoch 30:	0.02184635  	0.16071603  	0.08260520  
2023-05-23 18:40:47.372: Find a better model.
2023-05-23 18:40:53.800: [iter 31 : loss : 0.2410 = 0.1412 + 0.0975 + 0.0023, time: 6.427164]
2023-05-23 18:40:53.957: epoch 31:	0.02209333  	0.16248375  	0.08326704  
2023-05-23 18:40:53.957: Find a better model.
2023-05-23 18:41:00.410: [iter 32 : loss : 0.2353 = 0.1358 + 0.0972 + 0.0023, time: 6.452121]
2023-05-23 18:41:00.555: epoch 32:	0.02215683  	0.16332962  	0.08395989  
2023-05-23 18:41:00.555: Find a better model.
2023-05-23 18:41:07.026: [iter 33 : loss : 0.2328 = 0.1336 + 0.0968 + 0.0024, time: 6.469550]
2023-05-23 18:41:07.174: epoch 33:	0.02236852  	0.16472344  	0.08467601  
2023-05-23 18:41:07.174: Find a better model.
2023-05-23 18:41:13.610: [iter 34 : loss : 0.2284 = 0.1295 + 0.0965 + 0.0024, time: 6.434445]
2023-05-23 18:41:13.764: epoch 34:	0.02248142  	0.16563728  	0.08530647  
2023-05-23 18:41:13.764: Find a better model.
2023-05-23 18:41:20.205: [iter 35 : loss : 0.2251 = 0.1265 + 0.0962 + 0.0025, time: 6.439549]
2023-05-23 18:41:20.359: epoch 35:	0.02263667  	0.16659069  	0.08599351  
2023-05-23 18:41:20.359: Find a better model.
2023-05-23 18:41:26.984: [iter 36 : loss : 0.2217 = 0.1233 + 0.0959 + 0.0026, time: 6.623748]
2023-05-23 18:41:27.129: epoch 36:	0.02267901  	0.16679229  	0.08641277  
2023-05-23 18:41:27.129: Find a better model.
2023-05-23 18:41:33.590: [iter 37 : loss : 0.2178 = 0.1197 + 0.0955 + 0.0026, time: 6.458636]
2023-05-23 18:41:33.747: epoch 37:	0.02274957  	0.16762532  	0.08684597  
2023-05-23 18:41:33.748: Find a better model.
2023-05-23 18:41:40.388: [iter 38 : loss : 0.2165 = 0.1185 + 0.0953 + 0.0027, time: 6.638498]
2023-05-23 18:41:40.543: epoch 38:	0.02300361  	0.16974261  	0.08761356  
2023-05-23 18:41:40.543: Find a better model.
2023-05-23 18:41:46.993: [iter 39 : loss : 0.2119 = 0.1142 + 0.0949 + 0.0027, time: 6.449508]
2023-05-23 18:41:47.146: epoch 39:	0.02306712  	0.17032199  	0.08814044  
2023-05-23 18:41:47.146: Find a better model.
2023-05-23 18:41:53.762: [iter 40 : loss : 0.2085 = 0.1111 + 0.0946 + 0.0028, time: 6.615465]
2023-05-23 18:41:53.919: epoch 40:	0.02316591  	0.17131597  	0.08862084  
2023-05-23 18:41:53.919: Find a better model.
2023-05-23 18:42:00.403: [iter 41 : loss : 0.2070 = 0.1098 + 0.0944 + 0.0028, time: 6.482345]
2023-05-23 18:42:00.546: epoch 41:	0.02318708  	0.17120029  	0.08892763  
2023-05-23 18:42:06.995: [iter 42 : loss : 0.2047 = 0.1078 + 0.0941 + 0.0029, time: 6.447667]
2023-05-23 18:42:07.139: epoch 42:	0.02320119  	0.17143442  	0.08931787  
2023-05-23 18:42:07.139: Find a better model.
2023-05-23 18:42:13.578: [iter 43 : loss : 0.2010 = 0.1042 + 0.0938 + 0.0029, time: 6.435287]
2023-05-23 18:42:13.732: epoch 43:	0.02328587  	0.17195295  	0.08973392  
2023-05-23 18:42:13.732: Find a better model.
2023-05-23 18:42:20.206: [iter 44 : loss : 0.1973 = 0.1008 + 0.0936 + 0.0030, time: 6.471861]
2023-05-23 18:42:20.361: epoch 44:	0.02339171  	0.17289244  	0.09023273  
2023-05-23 18:42:20.361: Find a better model.
2023-05-23 18:42:26.793: [iter 45 : loss : 0.1952 = 0.0988 + 0.0933 + 0.0030, time: 6.430656]
2023-05-23 18:42:26.948: epoch 45:	0.02352579  	0.17378782  	0.09092207  
2023-05-23 18:42:26.948: Find a better model.
2023-05-23 18:42:33.369: [iter 46 : loss : 0.1928 = 0.0967 + 0.0930 + 0.0031, time: 6.418586]
2023-05-23 18:42:33.512: epoch 46:	0.02358930  	0.17413798  	0.09128740  
2023-05-23 18:42:33.512: Find a better model.
2023-05-23 18:42:39.956: [iter 47 : loss : 0.1922 = 0.0963 + 0.0928 + 0.0031, time: 6.442992]
2023-05-23 18:42:40.111: epoch 47:	0.02367398  	0.17438143  	0.09157982  
2023-05-23 18:42:40.111: Find a better model.
2023-05-23 18:42:46.535: [iter 48 : loss : 0.1883 = 0.0925 + 0.0926 + 0.0032, time: 6.421817]
2023-05-23 18:42:46.688: epoch 48:	0.02374454  	0.17486846  	0.09202965  
2023-05-23 18:42:46.689: Find a better model.
2023-05-23 18:42:53.159: [iter 49 : loss : 0.1852 = 0.0896 + 0.0924 + 0.0032, time: 6.469100]
2023-05-23 18:42:53.304: epoch 49:	0.02388567  	0.17609003  	0.09272396  
2023-05-23 18:42:53.304: Find a better model.
2023-05-23 18:42:59.753: [iter 50 : loss : 0.1846 = 0.0891 + 0.0922 + 0.0033, time: 6.447823]
2023-05-23 18:42:59.911: epoch 50:	0.02396329  	0.17698787  	0.09332760  
2023-05-23 18:42:59.911: Find a better model.
2023-05-23 18:43:06.355: [iter 51 : loss : 0.1813 = 0.0859 + 0.0920 + 0.0033, time: 6.442350]
2023-05-23 18:43:06.509: epoch 51:	0.02408325  	0.17744924  	0.09368711  
2023-05-23 18:43:06.509: Find a better model.
2023-05-23 18:43:12.966: [iter 52 : loss : 0.1811 = 0.0859 + 0.0918 + 0.0034, time: 6.455535]
2023-05-23 18:43:13.109: epoch 52:	0.02416086  	0.17771770  	0.09417638  
2023-05-23 18:43:13.109: Find a better model.
2023-05-23 18:43:19.382: [iter 53 : loss : 0.1793 = 0.0843 + 0.0916 + 0.0034, time: 6.271807]
2023-05-23 18:43:19.534: epoch 53:	0.02433022  	0.17879848  	0.09487104  
2023-05-23 18:43:19.534: Find a better model.
2023-05-23 18:43:25.956: [iter 54 : loss : 0.1771 = 0.0823 + 0.0914 + 0.0035, time: 6.419735]
2023-05-23 18:43:26.098: epoch 54:	0.02440079  	0.17928819  	0.09526451  
2023-05-23 18:43:26.098: Find a better model.
2023-05-23 18:43:32.538: [iter 55 : loss : 0.1753 = 0.0806 + 0.0912 + 0.0035, time: 6.438660]
2023-05-23 18:43:32.695: epoch 55:	0.02453486  	0.18025234  	0.09566356  
2023-05-23 18:43:32.695: Find a better model.
2023-05-23 18:43:39.149: [iter 56 : loss : 0.1734 = 0.0788 + 0.0910 + 0.0035, time: 6.452822]
2023-05-23 18:43:39.306: epoch 56:	0.02460542  	0.18085532  	0.09608176  
2023-05-23 18:43:39.307: Find a better model.
2023-05-23 18:43:45.735: [iter 57 : loss : 0.1717 = 0.0772 + 0.0909 + 0.0036, time: 6.427456]
2023-05-23 18:43:45.883: epoch 57:	0.02480300  	0.18248290  	0.09678154  
2023-05-23 18:43:45.883: Find a better model.
2023-05-23 18:43:52.347: [iter 58 : loss : 0.1697 = 0.0754 + 0.0907 + 0.0036, time: 6.462389]
2023-05-23 18:43:52.502: epoch 58:	0.02481006  	0.18246661  	0.09700285  
2023-05-23 18:43:58.959: [iter 59 : loss : 0.1685 = 0.0744 + 0.0905 + 0.0037, time: 6.455074]
2023-05-23 18:43:59.115: epoch 59:	0.02490884  	0.18311858  	0.09757935  
2023-05-23 18:43:59.115: Find a better model.
2023-05-23 18:44:05.565: [iter 60 : loss : 0.1670 = 0.0729 + 0.0904 + 0.0037, time: 6.447401]
2023-05-23 18:44:05.718: epoch 60:	0.02495824  	0.18366934  	0.09796051  
2023-05-23 18:44:05.718: Find a better model.
2023-05-23 18:44:12.170: [iter 61 : loss : 0.1658 = 0.0719 + 0.0902 + 0.0038, time: 6.449659]
2023-05-23 18:44:12.326: epoch 61:	0.02502174  	0.18423937  	0.09836213  
2023-05-23 18:44:12.326: Find a better model.
2023-05-23 18:44:18.755: [iter 62 : loss : 0.1642 = 0.0704 + 0.0900 + 0.0038, time: 6.428423]
2023-05-23 18:44:18.910: epoch 62:	0.02505702  	0.18448728  	0.09861389  
2023-05-23 18:44:18.910: Find a better model.
2023-05-23 18:44:25.518: [iter 63 : loss : 0.1628 = 0.0691 + 0.0899 + 0.0039, time: 6.606828]
2023-05-23 18:44:25.674: epoch 63:	0.02512053  	0.18477893  	0.09885200  
2023-05-23 18:44:25.674: Find a better model.
2023-05-23 18:44:32.296: [iter 64 : loss : 0.1618 = 0.0682 + 0.0897 + 0.0039, time: 6.621231]
2023-05-23 18:44:32.451: epoch 64:	0.02519110  	0.18531586  	0.09913474  
2023-05-23 18:44:32.452: Find a better model.
2023-05-23 18:44:38.954: [iter 65 : loss : 0.1604 = 0.0670 + 0.0895 + 0.0039, time: 6.501098]
2023-05-23 18:44:39.110: epoch 65:	0.02528989  	0.18582559  	0.09949189  
2023-05-23 18:44:39.110: Find a better model.
2023-05-23 18:44:45.548: [iter 66 : loss : 0.1590 = 0.0656 + 0.0894 + 0.0040, time: 6.437793]
2023-05-23 18:44:45.693: epoch 66:	0.02527577  	0.18600659  	0.09982549  
2023-05-23 18:44:45.693: Find a better model.
2023-05-23 18:44:52.150: [iter 67 : loss : 0.1575 = 0.0642 + 0.0893 + 0.0040, time: 6.455718]
2023-05-23 18:44:52.302: epoch 67:	0.02534634  	0.18650654  	0.10019246  
2023-05-23 18:44:52.302: Find a better model.
2023-05-23 18:44:58.721: [iter 68 : loss : 0.1573 = 0.0641 + 0.0891 + 0.0041, time: 6.417195]
2023-05-23 18:44:58.872: epoch 68:	0.02532517  	0.18634009  	0.10026655  
2023-05-23 18:45:05.335: [iter 69 : loss : 0.1553 = 0.0622 + 0.0890 + 0.0041, time: 6.461575]
2023-05-23 18:45:05.478: epoch 69:	0.02528283  	0.18604864  	0.10030070  
2023-05-23 18:45:11.928: [iter 70 : loss : 0.1535 = 0.0605 + 0.0889 + 0.0042, time: 6.448375]
2023-05-23 18:45:12.081: epoch 70:	0.02533929  	0.18661562  	0.10063095  
2023-05-23 18:45:12.081: Find a better model.
2023-05-23 18:45:18.484: [iter 71 : loss : 0.1523 = 0.0593 + 0.0887 + 0.0042, time: 6.402346]
2023-05-23 18:45:18.638: epoch 71:	0.02540985  	0.18716040  	0.10084125  
2023-05-23 18:45:18.639: Find a better model.
2023-05-23 18:45:25.290: [iter 72 : loss : 0.1519 = 0.0590 + 0.0887 + 0.0042, time: 6.650823]
2023-05-23 18:45:25.451: epoch 72:	0.02548041  	0.18792009  	0.10125958  
2023-05-23 18:45:25.451: Find a better model.
2023-05-23 18:45:31.890: [iter 73 : loss : 0.1506 = 0.0578 + 0.0885 + 0.0043, time: 6.438190]
2023-05-23 18:45:32.035: epoch 73:	0.02556509  	0.18796811  	0.10149755  
2023-05-23 18:45:32.035: Find a better model.
2023-05-23 18:45:38.510: [iter 74 : loss : 0.1491 = 0.0563 + 0.0884 + 0.0043, time: 6.472285]
2023-05-23 18:45:38.664: epoch 74:	0.02565683  	0.18864259  	0.10181564  
2023-05-23 18:45:38.664: Find a better model.
2023-05-23 18:45:45.112: [iter 75 : loss : 0.1486 = 0.0560 + 0.0883 + 0.0044, time: 6.446959]
2023-05-23 18:45:45.252: epoch 75:	0.02564271  	0.18824854  	0.10185554  
2023-05-23 18:45:51.699: [iter 76 : loss : 0.1476 = 0.0550 + 0.0882 + 0.0044, time: 6.444448]
2023-05-23 18:45:51.851: epoch 76:	0.02565683  	0.18863107  	0.10216448  
2023-05-23 18:45:58.320: [iter 77 : loss : 0.1466 = 0.0541 + 0.0880 + 0.0044, time: 6.468103]
2023-05-23 18:45:58.474: epoch 77:	0.02574856  	0.18938510  	0.10247061  
2023-05-23 18:45:58.474: Find a better model.
2023-05-23 18:46:04.913: [iter 78 : loss : 0.1460 = 0.0536 + 0.0880 + 0.0045, time: 6.438294]
2023-05-23 18:46:05.066: epoch 78:	0.02579090  	0.18967761  	0.10286859  
2023-05-23 18:46:05.066: Find a better model.
2023-05-23 18:46:11.479: [iter 79 : loss : 0.1443 = 0.0520 + 0.0878 + 0.0045, time: 6.411814]
2023-05-23 18:46:11.637: epoch 79:	0.02584029  	0.18997407  	0.10317799  
2023-05-23 18:46:11.637: Find a better model.
2023-05-23 18:46:18.101: [iter 80 : loss : 0.1435 = 0.0512 + 0.0878 + 0.0046, time: 6.463508]
2023-05-23 18:46:18.256: epoch 80:	0.02591086  	0.19076154  	0.10348532  
2023-05-23 18:46:18.256: Find a better model.
2023-05-23 18:46:24.699: [iter 81 : loss : 0.1438 = 0.0515 + 0.0877 + 0.0046, time: 6.441228]
2023-05-23 18:46:24.852: epoch 81:	0.02585441  	0.19062573  	0.10364163  
2023-05-23 18:46:31.285: [iter 82 : loss : 0.1421 = 0.0499 + 0.0876 + 0.0046, time: 6.431680]
2023-05-23 18:46:31.427: epoch 82:	0.02591086  	0.19114816  	0.10383965  
2023-05-23 18:46:31.427: Find a better model.
2023-05-23 18:46:37.876: [iter 83 : loss : 0.1413 = 0.0492 + 0.0875 + 0.0047, time: 6.446935]
2023-05-23 18:46:38.032: epoch 83:	0.02589674  	0.19103372  	0.10390976  
2023-05-23 18:46:44.509: [iter 84 : loss : 0.1413 = 0.0492 + 0.0874 + 0.0047, time: 6.476103]
2023-05-23 18:46:44.666: epoch 84:	0.02598848  	0.19168083  	0.10421749  
2023-05-23 18:46:44.666: Find a better model.
2023-05-23 18:46:51.097: [iter 85 : loss : 0.1402 = 0.0482 + 0.0873 + 0.0048, time: 6.429600]
2023-05-23 18:46:51.253: epoch 85:	0.02610138  	0.19230056  	0.10459109  
2023-05-23 18:46:51.253: Find a better model.
2023-05-23 18:46:57.703: [iter 86 : loss : 0.1398 = 0.0478 + 0.0872 + 0.0048, time: 6.448369]
2023-05-23 18:46:57.860: epoch 86:	0.02608021  	0.19241497  	0.10466553  
2023-05-23 18:46:57.861: Find a better model.
2023-05-23 18:47:04.261: [iter 87 : loss : 0.1373 = 0.0453 + 0.0871 + 0.0048, time: 6.399368]
2023-05-23 18:47:04.406: epoch 87:	0.02612255  	0.19297056  	0.10494141  
2023-05-23 18:47:04.406: Find a better model.
2023-05-23 18:47:10.881: [iter 88 : loss : 0.1365 = 0.0446 + 0.0870 + 0.0049, time: 6.472859]
2023-05-23 18:47:11.033: epoch 88:	0.02612961  	0.19322871  	0.10516411  
2023-05-23 18:47:11.034: Find a better model.
2023-05-23 18:47:17.496: [iter 89 : loss : 0.1362 = 0.0444 + 0.0869 + 0.0049, time: 6.460508]
2023-05-23 18:47:17.641: epoch 89:	0.02620017  	0.19358332  	0.10523101  
2023-05-23 18:47:17.641: Find a better model.
2023-05-23 18:47:24.085: [iter 90 : loss : 0.1369 = 0.0451 + 0.0868 + 0.0049, time: 6.442670]
2023-05-23 18:47:24.239: epoch 90:	0.02625662  	0.19409741  	0.10566785  
2023-05-23 18:47:24.239: Find a better model.
2023-05-23 18:47:30.664: [iter 91 : loss : 0.1357 = 0.0440 + 0.0867 + 0.0050, time: 6.423835]
2023-05-23 18:47:30.816: epoch 91:	0.02630601  	0.19423726  	0.10568868  
2023-05-23 18:47:30.816: Find a better model.
2023-05-23 18:47:37.273: [iter 92 : loss : 0.1347 = 0.0431 + 0.0866 + 0.0050, time: 6.454421]
2023-05-23 18:47:37.415: epoch 92:	0.02641186  	0.19518231  	0.10610586  
2023-05-23 18:47:37.415: Find a better model.
2023-05-23 18:47:43.879: [iter 93 : loss : 0.1348 = 0.0431 + 0.0866 + 0.0051, time: 6.462891]
2023-05-23 18:47:44.032: epoch 93:	0.02637657  	0.19489065  	0.10600370  
2023-05-23 18:47:50.476: [iter 94 : loss : 0.1329 = 0.0413 + 0.0865 + 0.0051, time: 6.441816]
2023-05-23 18:47:50.633: epoch 94:	0.02631306  	0.19407007  	0.10604251  
2023-05-23 18:47:57.041: [iter 95 : loss : 0.1323 = 0.0407 + 0.0864 + 0.0051, time: 6.406142]
2023-05-23 18:47:57.195: epoch 95:	0.02639069  	0.19467376  	0.10639199  
2023-05-23 18:48:03.657: [iter 96 : loss : 0.1323 = 0.0407 + 0.0864 + 0.0052, time: 6.459674]
2023-05-23 18:48:03.798: epoch 96:	0.02636952  	0.19462070  	0.10660001  
2023-05-23 18:48:10.279: [iter 97 : loss : 0.1306 = 0.0391 + 0.0863 + 0.0052, time: 6.480284]
2023-05-23 18:48:10.420: epoch 97:	0.02641186  	0.19509977  	0.10657820  
2023-05-23 18:48:16.861: [iter 98 : loss : 0.1314 = 0.0399 + 0.0862 + 0.0052, time: 6.439056]
2023-05-23 18:48:17.003: epoch 98:	0.02642597  	0.19502743  	0.10679405  
2023-05-23 18:48:23.452: [iter 99 : loss : 0.1303 = 0.0388 + 0.0862 + 0.0053, time: 6.447720]
2023-05-23 18:48:23.610: epoch 99:	0.02639068  	0.19468530  	0.10672148  
2023-05-23 18:48:30.071: [iter 100 : loss : 0.1298 = 0.0384 + 0.0861 + 0.0053, time: 6.458596]
2023-05-23 18:48:30.224: epoch 100:	0.02638363  	0.19468419  	0.10680231  
2023-05-23 18:48:36.638: [iter 101 : loss : 0.1294 = 0.0381 + 0.0860 + 0.0053, time: 6.413279]
2023-05-23 18:48:36.793: epoch 101:	0.02641891  	0.19487555  	0.10691416  
2023-05-23 18:48:43.258: [iter 102 : loss : 0.1283 = 0.0370 + 0.0859 + 0.0054, time: 6.462734]
2023-05-23 18:48:43.410: epoch 102:	0.02644714  	0.19501792  	0.10693567  
2023-05-23 18:48:49.811: [iter 103 : loss : 0.1279 = 0.0367 + 0.0859 + 0.0054, time: 6.399640]
2023-05-23 18:48:49.962: epoch 103:	0.02640480  	0.19497724  	0.10688642  
2023-05-23 18:48:56.441: [iter 104 : loss : 0.1285 = 0.0372 + 0.0858 + 0.0054, time: 6.477399]
2023-05-23 18:48:56.582: epoch 104:	0.02648948  	0.19552684  	0.10707011  
2023-05-23 18:48:56.582: Find a better model.
2023-05-23 18:49:03.027: [iter 105 : loss : 0.1279 = 0.0366 + 0.0857 + 0.0055, time: 6.443006]
2023-05-23 18:49:03.180: epoch 105:	0.02651065  	0.19567844  	0.10708752  
2023-05-23 18:49:03.180: Find a better model.
2023-05-23 18:49:09.641: [iter 106 : loss : 0.1272 = 0.0361 + 0.0857 + 0.0055, time: 6.459846]
2023-05-23 18:49:09.796: epoch 106:	0.02653182  	0.19576341  	0.10719435  
2023-05-23 18:49:09.796: Find a better model.
2023-05-23 18:49:16.062: [iter 107 : loss : 0.1264 = 0.0353 + 0.0856 + 0.0055, time: 6.263833]
2023-05-23 18:49:16.214: epoch 107:	0.02652477  	0.19580968  	0.10730539  
2023-05-23 18:49:16.214: Find a better model.
2023-05-23 18:49:22.445: [iter 108 : loss : 0.1261 = 0.0350 + 0.0856 + 0.0056, time: 6.229656]
2023-05-23 18:49:22.589: epoch 108:	0.02657416  	0.19624951  	0.10746736  
2023-05-23 18:49:22.589: Find a better model.
2023-05-23 18:49:28.844: [iter 109 : loss : 0.1248 = 0.0337 + 0.0855 + 0.0056, time: 6.253794]
2023-05-23 18:49:28.998: epoch 109:	0.02657416  	0.19617473  	0.10748088  
2023-05-23 18:49:35.432: [iter 110 : loss : 0.1242 = 0.0331 + 0.0855 + 0.0056, time: 6.431088]
2023-05-23 18:49:35.589: epoch 110:	0.02662355  	0.19633657  	0.10751821  
2023-05-23 18:49:35.589: Find a better model.
2023-05-23 18:49:42.009: [iter 111 : loss : 0.1243 = 0.0332 + 0.0854 + 0.0057, time: 6.418150]
2023-05-23 18:49:42.164: epoch 111:	0.02654593  	0.19571580  	0.10744832  
2023-05-23 18:49:48.625: [iter 112 : loss : 0.1240 = 0.0329 + 0.0853 + 0.0057, time: 6.460781]
2023-05-23 18:49:48.784: epoch 112:	0.02660944  	0.19608821  	0.10761943  
2023-05-23 18:49:55.218: [iter 113 : loss : 0.1237 = 0.0327 + 0.0853 + 0.0057, time: 6.431218]
2023-05-23 18:49:55.375: epoch 113:	0.02665884  	0.19652590  	0.10778297  
2023-05-23 18:49:55.375: Find a better model.
2023-05-23 18:50:01.828: [iter 114 : loss : 0.1230 = 0.0320 + 0.0852 + 0.0058, time: 6.452732]
2023-05-23 18:50:01.984: epoch 114:	0.02663767  	0.19634119  	0.10777142  
2023-05-23 18:50:08.432: [iter 115 : loss : 0.1226 = 0.0316 + 0.0852 + 0.0058, time: 6.445477]
2023-05-23 18:50:08.587: epoch 115:	0.02656710  	0.19607198  	0.10771398  
2023-05-23 18:50:15.258: [iter 116 : loss : 0.1218 = 0.0308 + 0.0852 + 0.0058, time: 6.670504]
2023-05-23 18:50:15.401: epoch 116:	0.02665884  	0.19666164  	0.10783599  
2023-05-23 18:50:15.402: Find a better model.
2023-05-23 18:50:21.817: [iter 117 : loss : 0.1217 = 0.0307 + 0.0851 + 0.0059, time: 6.413699]
2023-05-23 18:50:21.972: epoch 117:	0.02658827  	0.19617693  	0.10773107  
2023-05-23 18:50:28.415: [iter 118 : loss : 0.1215 = 0.0306 + 0.0850 + 0.0059, time: 6.440348]
2023-05-23 18:50:28.569: epoch 118:	0.02666590  	0.19684578  	0.10802675  
2023-05-23 18:50:28.569: Find a better model.
2023-05-23 18:50:34.981: [iter 119 : loss : 0.1205 = 0.0296 + 0.0850 + 0.0059, time: 6.410573]
2023-05-23 18:50:35.137: epoch 119:	0.02668001  	0.19681902  	0.10818139  
2023-05-23 18:50:41.581: [iter 120 : loss : 0.1209 = 0.0301 + 0.0849 + 0.0060, time: 6.443371]
2023-05-23 18:50:41.739: epoch 120:	0.02665884  	0.19669801  	0.10824426  
2023-05-23 18:50:48.015: [iter 121 : loss : 0.1208 = 0.0299 + 0.0849 + 0.0060, time: 6.274423]
2023-05-23 18:50:48.158: epoch 121:	0.02665179  	0.19668472  	0.10820951  
2023-05-23 18:50:54.588: [iter 122 : loss : 0.1199 = 0.0290 + 0.0848 + 0.0060, time: 6.429629]
2023-05-23 18:50:54.731: epoch 122:	0.02663768  	0.19633299  	0.10815319  
2023-05-23 18:51:01.013: [iter 123 : loss : 0.1199 = 0.0291 + 0.0848 + 0.0061, time: 6.279142]
2023-05-23 18:51:01.153: epoch 123:	0.02676469  	0.19731322  	0.10841570  
2023-05-23 18:51:01.153: Find a better model.
2023-05-23 18:51:07.604: [iter 124 : loss : 0.1191 = 0.0283 + 0.0847 + 0.0061, time: 6.448978]
2023-05-23 18:51:07.759: epoch 124:	0.02667296  	0.19650745  	0.10829034  
2023-05-23 18:51:14.006: [iter 125 : loss : 0.1185 = 0.0276 + 0.0847 + 0.0061, time: 6.244940]
2023-05-23 18:51:14.153: epoch 125:	0.02666590  	0.19617887  	0.10820966  
2023-05-23 18:51:20.600: [iter 126 : loss : 0.1187 = 0.0279 + 0.0846 + 0.0061, time: 6.446006]
2023-05-23 18:51:20.757: epoch 126:	0.02663768  	0.19599155  	0.10799299  
2023-05-23 18:51:26.978: [iter 127 : loss : 0.1179 = 0.0271 + 0.0846 + 0.0062, time: 6.219656]
2023-05-23 18:51:27.133: epoch 127:	0.02667295  	0.19661090  	0.10806918  
2023-05-23 18:51:33.404: [iter 128 : loss : 0.1186 = 0.0278 + 0.0845 + 0.0062, time: 6.269266]
2023-05-23 18:51:33.558: epoch 128:	0.02665178  	0.19616567  	0.10807190  
2023-05-23 18:51:39.951: [iter 129 : loss : 0.1179 = 0.0271 + 0.0845 + 0.0062, time: 6.392175]
2023-05-23 18:51:40.105: epoch 129:	0.02668707  	0.19628072  	0.10820188  
2023-05-23 18:51:46.405: [iter 130 : loss : 0.1179 = 0.0271 + 0.0844 + 0.0063, time: 6.298514]
2023-05-23 18:51:46.545: epoch 130:	0.02675058  	0.19700910  	0.10843383  
2023-05-23 18:51:52.802: [iter 131 : loss : 0.1170 = 0.0263 + 0.0844 + 0.0063, time: 6.255130]
2023-05-23 18:51:52.960: epoch 131:	0.02672235  	0.19655861  	0.10846874  
2023-05-23 18:51:59.190: [iter 132 : loss : 0.1173 = 0.0266 + 0.0844 + 0.0063, time: 6.227689]
2023-05-23 18:51:59.344: epoch 132:	0.02666590  	0.19588198  	0.10835224  
2023-05-23 18:52:05.606: [iter 133 : loss : 0.1159 = 0.0252 + 0.0843 + 0.0064, time: 6.260419]
2023-05-23 18:52:05.759: epoch 133:	0.02664473  	0.19584554  	0.10856718  
2023-05-23 18:52:11.982: [iter 134 : loss : 0.1168 = 0.0261 + 0.0843 + 0.0064, time: 6.222776]
2023-05-23 18:52:12.137: epoch 134:	0.02669412  	0.19628881  	0.10855246  
2023-05-23 18:52:18.359: [iter 135 : loss : 0.1164 = 0.0257 + 0.0843 + 0.0064, time: 6.220138]
2023-05-23 18:52:18.504: epoch 135:	0.02670118  	0.19595341  	0.10856868  
2023-05-23 18:52:24.775: [iter 136 : loss : 0.1160 = 0.0253 + 0.0842 + 0.0064, time: 6.269845]
2023-05-23 18:52:24.929: epoch 136:	0.02667295  	0.19575396  	0.10850704  
2023-05-23 18:52:31.190: [iter 137 : loss : 0.1155 = 0.0249 + 0.0842 + 0.0065, time: 6.259519]
2023-05-23 18:52:31.343: epoch 137:	0.02666589  	0.19580798  	0.10847550  
2023-05-23 18:52:37.566: [iter 138 : loss : 0.1154 = 0.0248 + 0.0841 + 0.0065, time: 6.221701]
2023-05-23 18:52:37.720: epoch 138:	0.02672235  	0.19613601  	0.10887600  
2023-05-23 18:52:43.952: [iter 139 : loss : 0.1153 = 0.0247 + 0.0841 + 0.0065, time: 6.230453]
2023-05-23 18:52:44.101: epoch 139:	0.02665884  	0.19571933  	0.10867237  
2023-05-23 18:52:50.369: [iter 140 : loss : 0.1145 = 0.0239 + 0.0841 + 0.0066, time: 6.266944]
2023-05-23 18:52:50.524: epoch 140:	0.02668707  	0.19590053  	0.10870714  
2023-05-23 18:52:56.761: [iter 141 : loss : 0.1151 = 0.0245 + 0.0840 + 0.0066, time: 6.235957]
2023-05-23 18:52:56.915: epoch 141:	0.02664472  	0.19570099  	0.10869256  
2023-05-23 18:53:03.163: [iter 142 : loss : 0.1141 = 0.0235 + 0.0840 + 0.0066, time: 6.246883]
2023-05-23 18:53:03.314: epoch 142:	0.02662355  	0.19522038  	0.10852783  
2023-05-23 18:53:09.733: [iter 143 : loss : 0.1142 = 0.0236 + 0.0839 + 0.0066, time: 6.416775]
2023-05-23 18:53:09.875: epoch 143:	0.02665883  	0.19562340  	0.10876554  
2023-05-23 18:53:16.158: [iter 144 : loss : 0.1135 = 0.0229 + 0.0839 + 0.0067, time: 6.281256]
2023-05-23 18:53:16.312: epoch 144:	0.02664472  	0.19527824  	0.10863903  
2023-05-23 18:53:22.574: [iter 145 : loss : 0.1134 = 0.0228 + 0.0839 + 0.0067, time: 6.259456]
2023-05-23 18:53:22.729: epoch 145:	0.02662355  	0.19526428  	0.10868534  
2023-05-23 18:53:28.967: [iter 146 : loss : 0.1140 = 0.0234 + 0.0839 + 0.0067, time: 6.236956]
2023-05-23 18:53:29.126: epoch 146:	0.02665883  	0.19558811  	0.10877245  
2023-05-23 18:53:35.353: [iter 147 : loss : 0.1136 = 0.0230 + 0.0838 + 0.0067, time: 6.225242]
2023-05-23 18:53:35.506: epoch 147:	0.02668000  	0.19566275  	0.10898876  
2023-05-23 18:53:41.750: [iter 148 : loss : 0.1125 = 0.0219 + 0.0838 + 0.0068, time: 6.243161]
2023-05-23 18:53:41.905: epoch 148:	0.02664473  	0.19544233  	0.10893419  
2023-05-23 18:53:41.905: Early stopping is trigger at epoch: 148
2023-05-23 18:53:41.905: best_result@epoch 123:

2023-05-23 18:53:41.905: 		0.0268      	0.1973      	0.1084      
2023-05-23 19:00:55.666: my pid: 12400
2023-05-23 19:00:55.666: model: model.general_recommender.SGL
2023-05-23 19:00:55.666: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 19:00:55.666: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 19:00:59.299: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 19:01:06.601: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.301648]
2023-05-23 19:01:06.756: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-23 19:01:06.756: Find a better model.
2023-05-23 19:01:14.002: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.244730]
2023-05-23 19:01:14.203: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-23 19:01:14.204: Find a better model.
2023-05-23 19:01:21.387: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.180715]
2023-05-23 19:01:21.574: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-23 19:01:21.574: Find a better model.
2023-05-23 19:01:28.588: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.011527]
2023-05-23 19:01:28.745: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-23 19:01:28.745: Find a better model.
2023-05-23 19:01:35.581: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 6.835212]
2023-05-23 19:01:35.736: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-23 19:01:35.736: Find a better model.
2023-05-23 19:01:42.378: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.640996]
2023-05-23 19:01:42.538: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-23 19:01:42.538: Find a better model.
2023-05-23 19:01:49.161: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.621588]
2023-05-23 19:01:49.314: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-23 19:01:49.314: Find a better model.
2023-05-23 19:01:55.953: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.636803]
2023-05-23 19:01:56.096: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-23 19:01:56.096: Find a better model.
2023-05-23 19:02:02.576: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.479149]
2023-05-23 19:02:02.718: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-23 19:02:09.143: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.422481]
2023-05-23 19:02:09.287: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-23 19:02:15.590: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.302856]
2023-05-23 19:02:15.743: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-23 19:02:22.152: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.406711]
2023-05-23 19:02:22.304: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-23 19:02:28.574: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.267918]
2023-05-23 19:02:28.728: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-23 19:02:28.729: Find a better model.
2023-05-23 19:02:35.145: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.413568]
2023-05-23 19:02:35.287: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-23 19:02:35.287: Find a better model.
2023-05-23 19:02:41.749: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.461712]
2023-05-23 19:02:41.902: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-23 19:02:41.903: Find a better model.
2023-05-23 19:02:48.363: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.457786]
2023-05-23 19:02:48.519: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-23 19:02:48.519: Find a better model.
2023-05-23 19:02:54.949: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.428789]
2023-05-23 19:02:55.103: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-23 19:02:55.103: Find a better model.
2023-05-23 19:03:01.531: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.427166]
2023-05-23 19:03:01.687: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-23 19:03:01.688: Find a better model.
2023-05-23 19:03:07.959: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.264899]
2023-05-23 19:03:08.115: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-23 19:03:08.115: Find a better model.
2023-05-23 19:03:14.548: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.431542]
2023-05-23 19:03:14.707: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-23 19:03:14.707: Find a better model.
2023-05-23 19:03:21.133: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.425400]
2023-05-23 19:03:21.286: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-23 19:03:21.286: Find a better model.
2023-05-23 19:03:27.734: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.447613]
2023-05-23 19:03:27.887: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-23 19:03:27.887: Find a better model.
2023-05-23 19:03:34.346: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.458054]
2023-05-23 19:03:34.500: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-23 19:03:34.500: Find a better model.
2023-05-23 19:03:40.937: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.435235]
2023-05-23 19:03:41.094: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-23 19:03:41.095: Find a better model.
2023-05-23 19:03:47.531: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.435883]
2023-05-23 19:03:47.674: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-23 19:03:47.675: Find a better model.
2023-05-23 19:03:54.116: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.439809]
2023-05-23 19:03:54.271: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-23 19:03:54.271: Find a better model.
2023-05-23 19:04:00.732: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.458201]
2023-05-23 19:04:00.890: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-23 19:04:00.890: Find a better model.
2023-05-23 19:04:07.326: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.435301]
2023-05-23 19:04:07.484: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-23 19:04:07.484: Find a better model.
2023-05-23 19:04:13.931: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.446442]
2023-05-23 19:04:14.087: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-23 19:04:14.087: Find a better model.
2023-05-23 19:04:20.510: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.421785]
2023-05-23 19:04:20.654: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-23 19:04:20.654: Find a better model.
2023-05-23 19:04:27.119: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.462774]
2023-05-23 19:04:27.278: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-23 19:04:27.279: Find a better model.
2023-05-23 19:04:33.908: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.627429]
2023-05-23 19:04:34.065: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-23 19:04:34.065: Find a better model.
2023-05-23 19:04:40.699: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.632115]
2023-05-23 19:04:40.859: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-23 19:04:40.859: Find a better model.
2023-05-23 19:04:47.491: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.631914]
2023-05-23 19:04:47.646: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-23 19:04:47.647: Find a better model.
2023-05-23 19:04:54.120: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.472351]
2023-05-23 19:04:54.263: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-23 19:04:54.263: Find a better model.
2023-05-23 19:05:00.893: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.626404]
2023-05-23 19:05:01.050: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-23 19:05:01.050: Find a better model.
2023-05-23 19:05:07.707: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.656266]
2023-05-23 19:05:07.866: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-23 19:05:07.867: Find a better model.
2023-05-23 19:05:14.517: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.648552]
2023-05-23 19:05:14.659: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-23 19:05:14.659: Find a better model.
2023-05-23 19:05:21.307: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.646770]
2023-05-23 19:05:21.463: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-23 19:05:21.463: Find a better model.
2023-05-23 19:05:28.103: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.638080]
2023-05-23 19:05:28.257: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-23 19:05:28.257: Find a better model.
2023-05-23 19:05:34.922: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.664506]
2023-05-23 19:05:35.075: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-23 19:05:35.075: Find a better model.
2023-05-23 19:05:41.694: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.617238]
2023-05-23 19:05:41.836: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-23 19:05:41.836: Find a better model.
2023-05-23 19:05:48.487: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.650175]
2023-05-23 19:05:48.644: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-23 19:05:55.314: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.668110]
2023-05-23 19:05:55.468: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-23 19:05:55.468: Find a better model.
2023-05-23 19:06:02.096: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.625727]
2023-05-23 19:06:02.251: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-23 19:06:02.251: Find a better model.
2023-05-23 19:06:09.094: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.841780]
2023-05-23 19:06:09.248: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-23 19:06:09.249: Find a better model.
2023-05-23 19:06:15.901: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.650965]
2023-05-23 19:06:16.055: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-23 19:06:16.056: Find a better model.
2023-05-23 19:06:22.668: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.610776]
2023-05-23 19:06:22.812: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-23 19:06:22.812: Find a better model.
2023-05-23 19:06:29.465: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.652390]
2023-05-23 19:06:29.606: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-23 19:06:29.606: Find a better model.
2023-05-23 19:06:36.085: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.477839]
2023-05-23 19:06:36.239: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-23 19:06:42.883: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0034, time: 6.642895]
2023-05-23 19:06:43.036: epoch 51:	0.02385745  	0.17556633  	0.09347075  
2023-05-23 19:06:43.036: Find a better model.
2023-05-23 19:06:49.687: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.649712]
2023-05-23 19:06:49.840: epoch 52:	0.02396329  	0.17615600  	0.09392820  
2023-05-23 19:06:49.840: Find a better model.
2023-05-23 19:06:56.477: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.636019]
2023-05-23 19:06:56.632: epoch 53:	0.02406913  	0.17702526  	0.09434863  
2023-05-23 19:06:56.633: Find a better model.
2023-05-23 19:07:03.078: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.444228]
2023-05-23 19:07:03.234: epoch 54:	0.02419615  	0.17792241  	0.09494144  
2023-05-23 19:07:03.234: Find a better model.
2023-05-23 19:07:09.876: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.639559]
2023-05-23 19:07:10.029: epoch 55:	0.02423849  	0.17839193  	0.09532860  
2023-05-23 19:07:10.029: Find a better model.
2023-05-23 19:07:16.683: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.653242]
2023-05-23 19:07:16.826: epoch 56:	0.02433728  	0.17909700  	0.09573369  
2023-05-23 19:07:16.826: Find a better model.
2023-05-23 19:07:23.444: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.615056]
2023-05-23 19:07:23.598: epoch 57:	0.02446430  	0.18026286  	0.09629583  
2023-05-23 19:07:23.598: Find a better model.
2023-05-23 19:07:30.068: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.468713]
2023-05-23 19:07:30.222: epoch 58:	0.02450663  	0.18062960  	0.09664251  
2023-05-23 19:07:30.222: Find a better model.
2023-05-23 19:07:36.857: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.634318]
2023-05-23 19:07:37.006: epoch 59:	0.02455603  	0.18130884  	0.09686511  
2023-05-23 19:07:37.006: Find a better model.
2023-05-23 19:07:43.631: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.623410]
2023-05-23 19:07:43.792: epoch 60:	0.02457720  	0.18123862  	0.09715549  
2023-05-23 19:07:50.455: [iter 61 : loss : 0.1636 = 0.0705 + 0.0892 + 0.0038, time: 6.661216]
2023-05-23 19:07:50.614: epoch 61:	0.02474656  	0.18253747  	0.09781680  
2023-05-23 19:07:50.614: Find a better model.
2023-05-23 19:07:57.059: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.443976]
2023-05-23 19:07:57.214: epoch 62:	0.02473244  	0.18249248  	0.09802019  
2023-05-23 19:08:03.854: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.639600]
2023-05-23 19:08:04.013: epoch 63:	0.02485240  	0.18354045  	0.09855148  
2023-05-23 19:08:04.014: Find a better model.
2023-05-23 19:08:10.648: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.632923]
2023-05-23 19:08:10.794: epoch 64:	0.02490885  	0.18378471  	0.09903330  
2023-05-23 19:08:10.794: Find a better model.
2023-05-23 19:08:17.250: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.454526]
2023-05-23 19:08:17.405: epoch 65:	0.02485945  	0.18354057  	0.09913395  
2023-05-23 19:08:24.038: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.632361]
2023-05-23 19:08:24.195: epoch 66:	0.02493708  	0.18397158  	0.09932361  
2023-05-23 19:08:24.195: Find a better model.
2023-05-23 19:08:30.838: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.642342]
2023-05-23 19:08:30.997: epoch 67:	0.02504998  	0.18468159  	0.09978308  
2023-05-23 19:08:30.998: Find a better model.
2023-05-23 19:08:37.616: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.616809]
2023-05-23 19:08:37.759: epoch 68:	0.02510642  	0.18502969  	0.10012835  
2023-05-23 19:08:37.759: Find a better model.
2023-05-23 19:08:44.238: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.477455]
2023-05-23 19:08:44.394: epoch 69:	0.02512054  	0.18508086  	0.10032206  
2023-05-23 19:08:44.394: Find a better model.
2023-05-23 19:08:51.034: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.639283]
2023-05-23 19:08:51.193: epoch 70:	0.02521933  	0.18603894  	0.10070904  
2023-05-23 19:08:51.193: Find a better model.
2023-05-23 19:08:57.814: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.620440]
2023-05-23 19:08:57.970: epoch 71:	0.02525461  	0.18614230  	0.10090048  
2023-05-23 19:08:57.970: Find a better model.
2023-05-23 19:09:04.431: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.458685]
2023-05-23 19:09:04.586: epoch 72:	0.02532518  	0.18680170  	0.10119528  
2023-05-23 19:09:04.586: Find a better model.
2023-05-23 19:09:11.214: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.626995]
2023-05-23 19:09:11.370: epoch 73:	0.02535341  	0.18726511  	0.10137676  
2023-05-23 19:09:11.370: Find a better model.
2023-05-23 19:09:18.020: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.648962]
2023-05-23 19:09:18.173: epoch 74:	0.02542397  	0.18757991  	0.10174557  
2023-05-23 19:09:18.173: Find a better model.
2023-05-23 19:09:24.809: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.634161]
2023-05-23 19:09:24.952: epoch 75:	0.02547337  	0.18816072  	0.10190730  
2023-05-23 19:09:24.952: Find a better model.
2023-05-23 19:09:31.406: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.451057]
2023-05-23 19:09:31.548: epoch 76:	0.02557922  	0.18915337  	0.10234687  
2023-05-23 19:09:31.548: Find a better model.
2023-05-23 19:09:38.206: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.657010]
2023-05-23 19:09:38.348: epoch 77:	0.02549453  	0.18842891  	0.10214259  
2023-05-23 19:09:45.032: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.682717]
2023-05-23 19:09:45.178: epoch 78:	0.02557921  	0.18915769  	0.10253035  
2023-05-23 19:09:45.178: Find a better model.
2023-05-23 19:09:51.809: [iter 79 : loss : 0.1425 = 0.0511 + 0.0869 + 0.0046, time: 6.630226]
2023-05-23 19:09:51.965: epoch 79:	0.02564978  	0.18960856  	0.10280474  
2023-05-23 19:09:51.965: Find a better model.
2023-05-23 19:09:58.614: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.646682]
2023-05-23 19:09:58.768: epoch 80:	0.02565683  	0.18977816  	0.10304097  
2023-05-23 19:09:58.768: Find a better model.
2023-05-23 19:10:05.426: [iter 81 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0046, time: 6.656458]
2023-05-23 19:10:05.582: epoch 81:	0.02568506  	0.18989682  	0.10328542  
2023-05-23 19:10:05.582: Find a better model.
2023-05-23 19:10:12.211: [iter 82 : loss : 0.1402 = 0.0490 + 0.0866 + 0.0047, time: 6.628067]
2023-05-23 19:10:12.367: epoch 82:	0.02567800  	0.18979020  	0.10337701  
2023-05-23 19:10:19.004: [iter 83 : loss : 0.1395 = 0.0483 + 0.0865 + 0.0047, time: 6.636362]
2023-05-23 19:10:19.163: epoch 83:	0.02574857  	0.19041438  	0.10361630  
2023-05-23 19:10:19.163: Find a better model.
2023-05-23 19:10:25.781: [iter 84 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 6.616966]
2023-05-23 19:10:25.924: epoch 84:	0.02564272  	0.18948308  	0.10349984  
2023-05-23 19:10:32.395: [iter 85 : loss : 0.1384 = 0.0473 + 0.0863 + 0.0048, time: 6.469481]
2023-05-23 19:10:32.542: epoch 85:	0.02574151  	0.19035104  	0.10382067  
2023-05-23 19:10:39.180: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.636349]
2023-05-23 19:10:39.338: epoch 86:	0.02583325  	0.19120090  	0.10410055  
2023-05-23 19:10:39.338: Find a better model.
2023-05-23 19:10:45.790: [iter 87 : loss : 0.1355 = 0.0445 + 0.0861 + 0.0049, time: 6.451445]
2023-05-23 19:10:45.934: epoch 87:	0.02592498  	0.19165075  	0.10435608  
2023-05-23 19:10:45.934: Find a better model.
2023-05-23 19:10:52.374: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.439433]
2023-05-23 19:10:52.515: epoch 88:	0.02598143  	0.19216737  	0.10469663  
2023-05-23 19:10:52.515: Find a better model.
2023-05-23 19:10:59.002: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.485622]
2023-05-23 19:10:59.158: epoch 89:	0.02593909  	0.19168027  	0.10474261  
2023-05-23 19:11:05.591: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.430434]
2023-05-23 19:11:05.745: epoch 90:	0.02598143  	0.19210102  	0.10495852  
2023-05-23 19:11:12.360: [iter 91 : loss : 0.1337 = 0.0429 + 0.0857 + 0.0050, time: 6.613810]
2023-05-23 19:11:12.515: epoch 91:	0.02607316  	0.19301951  	0.10521194  
2023-05-23 19:11:12.515: Find a better model.
2023-05-23 19:11:18.980: [iter 92 : loss : 0.1328 = 0.0421 + 0.0857 + 0.0051, time: 6.464611]
2023-05-23 19:11:19.141: epoch 92:	0.02606611  	0.19320604  	0.10531200  
2023-05-23 19:11:19.141: Find a better model.
2023-05-23 19:11:25.578: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.435332]
2023-05-23 19:11:25.727: epoch 93:	0.02607316  	0.19364491  	0.10542238  
2023-05-23 19:11:25.727: Find a better model.
2023-05-23 19:11:32.367: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.639566]
2023-05-23 19:11:32.521: epoch 94:	0.02604493  	0.19334863  	0.10543600  
2023-05-23 19:11:39.160: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.637380]
2023-05-23 19:11:39.316: epoch 95:	0.02602377  	0.19293091  	0.10547489  
2023-05-23 19:11:45.943: [iter 96 : loss : 0.1305 = 0.0400 + 0.0854 + 0.0052, time: 6.626051]
2023-05-23 19:11:46.084: epoch 96:	0.02607316  	0.19358504  	0.10575362  
2023-05-23 19:11:52.547: [iter 97 : loss : 0.1289 = 0.0384 + 0.0853 + 0.0052, time: 6.462450]
2023-05-23 19:11:52.689: epoch 97:	0.02608727  	0.19345793  	0.10576922  
2023-05-23 19:11:59.173: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.481527]
2023-05-23 19:11:59.329: epoch 98:	0.02606610  	0.19350217  	0.10580727  
2023-05-23 19:12:05.947: [iter 99 : loss : 0.1285 = 0.0380 + 0.0851 + 0.0053, time: 6.616481]
2023-05-23 19:12:06.103: epoch 99:	0.02612255  	0.19398789  	0.10604306  
2023-05-23 19:12:06.104: Find a better model.
2023-05-23 19:12:12.568: [iter 100 : loss : 0.1280 = 0.0376 + 0.0851 + 0.0053, time: 6.462667]
2023-05-23 19:12:12.723: epoch 100:	0.02615078  	0.19422464  	0.10611188  
2023-05-23 19:12:12.723: Find a better model.
2023-05-23 19:12:19.335: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.610922]
2023-05-23 19:12:19.492: epoch 101:	0.02622134  	0.19465888  	0.10637175  
2023-05-23 19:12:19.492: Find a better model.
2023-05-23 19:12:25.958: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.465340]
2023-05-23 19:12:26.114: epoch 102:	0.02623546  	0.19469464  	0.10644804  
2023-05-23 19:12:26.114: Find a better model.
2023-05-23 19:12:32.544: [iter 103 : loss : 0.1264 = 0.0361 + 0.0849 + 0.0055, time: 6.428852]
2023-05-23 19:12:32.700: epoch 103:	0.02622135  	0.19479854  	0.10662238  
2023-05-23 19:12:32.700: Find a better model.
2023-05-23 19:12:39.170: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.469419]
2023-05-23 19:12:39.326: epoch 104:	0.02623546  	0.19487023  	0.10676966  
2023-05-23 19:12:39.327: Find a better model.
2023-05-23 19:12:45.942: [iter 105 : loss : 0.1262 = 0.0359 + 0.0847 + 0.0055, time: 6.613896]
2023-05-23 19:12:46.095: epoch 105:	0.02619312  	0.19447325  	0.10677120  
2023-05-23 19:12:52.556: [iter 106 : loss : 0.1256 = 0.0354 + 0.0847 + 0.0056, time: 6.458789]
2023-05-23 19:12:52.713: epoch 106:	0.02616490  	0.19423872  	0.10656431  
2023-05-23 19:12:59.154: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.440179]
2023-05-23 19:12:59.309: epoch 107:	0.02622135  	0.19466639  	0.10668222  
2023-05-23 19:13:05.756: [iter 108 : loss : 0.1245 = 0.0343 + 0.0846 + 0.0056, time: 6.444764]
2023-05-23 19:13:05.911: epoch 108:	0.02624957  	0.19508272  	0.10680859  
2023-05-23 19:13:05.912: Find a better model.
2023-05-23 19:13:12.343: [iter 109 : loss : 0.1231 = 0.0329 + 0.0845 + 0.0057, time: 6.430662]
2023-05-23 19:13:12.502: epoch 109:	0.02626369  	0.19530113  	0.10692968  
2023-05-23 19:13:12.502: Find a better model.
2023-05-23 19:13:18.956: [iter 110 : loss : 0.1226 = 0.0324 + 0.0845 + 0.0057, time: 6.452458]
2023-05-23 19:13:19.113: epoch 110:	0.02632720  	0.19582899  	0.10706321  
2023-05-23 19:13:19.113: Find a better model.
2023-05-23 19:13:25.560: [iter 111 : loss : 0.1225 = 0.0324 + 0.0844 + 0.0057, time: 6.444999]
2023-05-23 19:13:25.714: epoch 111:	0.02634131  	0.19594513  	0.10723428  
2023-05-23 19:13:25.714: Find a better model.
2023-05-23 19:13:32.324: [iter 112 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.608693]
2023-05-23 19:13:32.477: epoch 112:	0.02635542  	0.19584881  	0.10718022  
2023-05-23 19:13:39.108: [iter 113 : loss : 0.1223 = 0.0322 + 0.0843 + 0.0058, time: 6.629625]
2023-05-23 19:13:39.255: epoch 113:	0.02634131  	0.19574182  	0.10715908  
2023-05-23 19:13:45.735: [iter 114 : loss : 0.1215 = 0.0315 + 0.0842 + 0.0058, time: 6.477907]
2023-05-23 19:13:45.879: epoch 114:	0.02634837  	0.19544581  	0.10715339  
2023-05-23 19:13:52.523: [iter 115 : loss : 0.1211 = 0.0310 + 0.0841 + 0.0059, time: 6.643687]
2023-05-23 19:13:52.677: epoch 115:	0.02636954  	0.19601227  	0.10713723  
2023-05-23 19:13:52.678: Find a better model.
2023-05-23 19:13:59.135: [iter 116 : loss : 0.1204 = 0.0304 + 0.0841 + 0.0059, time: 6.455370]
2023-05-23 19:13:59.281: epoch 116:	0.02639071  	0.19604219  	0.10712626  
2023-05-23 19:13:59.281: Find a better model.
2023-05-23 19:14:05.722: [iter 117 : loss : 0.1202 = 0.0302 + 0.0841 + 0.0059, time: 6.440320]
2023-05-23 19:14:05.876: epoch 117:	0.02646127  	0.19668077  	0.10736928  
2023-05-23 19:14:05.876: Find a better model.
2023-05-23 19:14:12.325: [iter 118 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0060, time: 6.446463]
2023-05-23 19:14:12.482: epoch 118:	0.02653184  	0.19714965  	0.10758931  
2023-05-23 19:14:12.483: Find a better model.
2023-05-23 19:14:18.929: [iter 119 : loss : 0.1192 = 0.0292 + 0.0839 + 0.0060, time: 6.444265]
2023-05-23 19:14:19.085: epoch 119:	0.02656712  	0.19702321  	0.10768340  
2023-05-23 19:14:25.541: [iter 120 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 6.454771]
2023-05-23 19:14:25.694: epoch 120:	0.02645421  	0.19586237  	0.10738175  
2023-05-23 19:14:32.119: [iter 121 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 6.424020]
2023-05-23 19:14:32.274: epoch 121:	0.02643304  	0.19591689  	0.10749327  
2023-05-23 19:14:38.703: [iter 122 : loss : 0.1187 = 0.0288 + 0.0838 + 0.0061, time: 6.428122]
2023-05-23 19:14:38.847: epoch 122:	0.02645422  	0.19611099  	0.10758454  
2023-05-23 19:14:45.299: [iter 123 : loss : 0.1184 = 0.0285 + 0.0838 + 0.0061, time: 6.450797]
2023-05-23 19:14:45.457: epoch 123:	0.02640482  	0.19571245  	0.10747675  
2023-05-23 19:14:51.906: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.447578]
2023-05-23 19:14:52.063: epoch 124:	0.02648950  	0.19631831  	0.10760234  
2023-05-23 19:14:58.511: [iter 125 : loss : 0.1170 = 0.0272 + 0.0837 + 0.0062, time: 6.446529]
2023-05-23 19:14:58.666: epoch 125:	0.02650362  	0.19663538  	0.10769241  
2023-05-23 19:15:05.105: [iter 126 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 6.436554]
2023-05-23 19:15:05.261: epoch 126:	0.02650362  	0.19636890  	0.10769665  
2023-05-23 19:15:11.701: [iter 127 : loss : 0.1162 = 0.0264 + 0.0836 + 0.0062, time: 6.438762]
2023-05-23 19:15:11.842: epoch 127:	0.02643305  	0.19601271  	0.10763802  
2023-05-23 19:15:18.283: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.439836]
2023-05-23 19:15:18.427: epoch 128:	0.02648244  	0.19569370  	0.10749701  
2023-05-23 19:15:24.898: [iter 129 : loss : 0.1164 = 0.0266 + 0.0835 + 0.0063, time: 6.470493]
2023-05-23 19:15:25.056: epoch 129:	0.02647538  	0.19601797  	0.10765814  
2023-05-23 19:15:31.487: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.429349]
2023-05-23 19:15:31.632: epoch 130:	0.02644010  	0.19566351  	0.10765804  
2023-05-23 19:15:38.099: [iter 131 : loss : 0.1155 = 0.0258 + 0.0834 + 0.0064, time: 6.466163]
2023-05-23 19:15:38.256: epoch 131:	0.02648244  	0.19605905  	0.10773812  
2023-05-23 19:15:44.693: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.435853]
2023-05-23 19:15:44.850: epoch 132:	0.02642599  	0.19570170  	0.10768952  
2023-05-23 19:15:51.276: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.425422]
2023-05-23 19:15:51.419: epoch 133:	0.02636953  	0.19515875  	0.10763110  
2023-05-23 19:15:57.886: [iter 134 : loss : 0.1153 = 0.0256 + 0.0833 + 0.0064, time: 6.465296]
2023-05-23 19:15:58.041: epoch 134:	0.02634837  	0.19498560  	0.10761535  
2023-05-23 19:16:04.460: [iter 135 : loss : 0.1150 = 0.0253 + 0.0832 + 0.0065, time: 6.416233]
2023-05-23 19:16:04.615: epoch 135:	0.02642599  	0.19554129  	0.10776508  
2023-05-23 19:16:11.099: [iter 136 : loss : 0.1146 = 0.0249 + 0.0832 + 0.0065, time: 6.482206]
2023-05-23 19:16:11.255: epoch 136:	0.02644010  	0.19584434  	0.10782064  
2023-05-23 19:16:17.649: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.393287]
2023-05-23 19:16:17.794: epoch 137:	0.02644010  	0.19564781  	0.10778730  
2023-05-23 19:16:24.081: [iter 138 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.285411]
2023-05-23 19:16:24.235: epoch 138:	0.02644009  	0.19594814  	0.10790730  
2023-05-23 19:16:30.673: [iter 139 : loss : 0.1138 = 0.0241 + 0.0831 + 0.0066, time: 6.436792]
2023-05-23 19:16:30.831: epoch 139:	0.02643304  	0.19571061  	0.10785444  
2023-05-23 19:16:37.276: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.443235]
2023-05-23 19:16:37.435: epoch 140:	0.02641893  	0.19564450  	0.10793334  
2023-05-23 19:16:43.866: [iter 141 : loss : 0.1136 = 0.0239 + 0.0830 + 0.0066, time: 6.428321]
2023-05-23 19:16:44.024: epoch 141:	0.02642598  	0.19569747  	0.10784296  
2023-05-23 19:16:50.449: [iter 142 : loss : 0.1127 = 0.0230 + 0.0830 + 0.0067, time: 6.424189]
2023-05-23 19:16:50.592: epoch 142:	0.02635542  	0.19550958  	0.10794367  
2023-05-23 19:16:56.865: [iter 143 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 6.272279]
2023-05-23 19:16:57.009: epoch 143:	0.02638364  	0.19570020  	0.10820227  
2023-05-23 19:16:57.009: Early stopping is trigger at epoch: 143
2023-05-23 19:16:57.009: best_result@epoch 118:

2023-05-23 19:16:57.009: 		0.0265      	0.1971      	0.1076      
2023-05-23 19:18:38.970: my pid: 2188
2023-05-23 19:18:38.970: model: model.general_recommender.SGL
2023-05-23 19:18:38.970: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 19:18:38.970: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 19:18:42.654: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 19:18:50.128: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.474035]
2023-05-23 19:18:50.288: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-23 19:18:50.289: Find a better model.
2023-05-23 19:18:57.857: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.565949]
2023-05-23 19:18:58.063: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-23 19:18:58.063: Find a better model.
2023-05-23 19:19:05.275: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.209447]
2023-05-23 19:19:05.453: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-23 19:19:05.453: Find a better model.
2023-05-23 19:19:12.636: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.181833]
2023-05-23 19:19:12.802: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-23 19:19:12.802: Find a better model.
2023-05-23 19:19:19.860: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.056625]
2023-05-23 19:19:20.016: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-23 19:19:20.016: Find a better model.
2023-05-23 19:19:27.023: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 7.005566]
2023-05-23 19:19:27.179: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-23 19:19:27.179: Find a better model.
2023-05-23 19:19:34.030: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.850346]
2023-05-23 19:19:34.185: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-23 19:19:34.185: Find a better model.
2023-05-23 19:19:41.001: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.814825]
2023-05-23 19:19:41.157: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-23 19:19:41.158: Find a better model.
2023-05-23 19:19:47.821: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.662260]
2023-05-23 19:19:47.967: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-23 19:19:54.635: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.666877]
2023-05-23 19:19:54.792: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-23 19:20:01.439: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.645517]
2023-05-23 19:20:01.595: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-23 19:20:08.218: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.621727]
2023-05-23 19:20:08.373: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-23 19:20:15.016: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.642215]
2023-05-23 19:20:15.168: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-23 19:20:21.620: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.449011]
2023-05-23 19:20:21.772: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-23 19:20:28.211: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.436897]
2023-05-23 19:20:28.354: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-23 19:20:28.354: Find a better model.
2023-05-23 19:20:34.823: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.467871]
2023-05-23 19:20:34.978: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-23 19:20:34.978: Find a better model.
2023-05-23 19:20:41.594: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.613524]
2023-05-23 19:20:41.735: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-23 19:20:41.735: Find a better model.
2023-05-23 19:20:48.219: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.482828]
2023-05-23 19:20:48.369: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-23 19:20:48.369: Find a better model.
2023-05-23 19:20:55.017: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.646355]
2023-05-23 19:20:55.170: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-23 19:20:55.170: Find a better model.
2023-05-23 19:21:01.815: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.644768]
2023-05-23 19:21:01.970: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-23 19:21:01.970: Find a better model.
2023-05-23 19:21:08.596: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.624385]
2023-05-23 19:21:08.740: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-23 19:21:08.740: Find a better model.
2023-05-23 19:21:15.204: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.463268]
2023-05-23 19:21:15.347: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-23 19:21:15.347: Find a better model.
2023-05-23 19:21:21.815: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.466762]
2023-05-23 19:21:21.974: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-23 19:21:21.974: Find a better model.
2023-05-23 19:21:28.439: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.463390]
2023-05-23 19:21:28.593: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-23 19:21:28.593: Find a better model.
2023-05-23 19:21:34.981: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.386509]
2023-05-23 19:21:35.122: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-23 19:21:35.122: Find a better model.
2023-05-23 19:21:41.586: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.463377]
2023-05-23 19:21:41.734: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-23 19:21:41.734: Find a better model.
2023-05-23 19:21:48.207: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.470586]
2023-05-23 19:21:48.361: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-23 19:21:48.361: Find a better model.
2023-05-23 19:21:54.785: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.423123]
2023-05-23 19:21:54.939: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-23 19:21:54.939: Find a better model.
2023-05-23 19:22:01.370: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.430247]
2023-05-23 19:22:01.513: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-23 19:22:01.513: Find a better model.
2023-05-23 19:22:07.980: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.466583]
2023-05-23 19:22:08.133: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-23 19:22:08.133: Find a better model.
2023-05-23 19:22:14.605: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.470937]
2023-05-23 19:22:14.746: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-23 19:22:14.747: Find a better model.
2023-05-23 19:22:21.177: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.429200]
2023-05-23 19:22:21.329: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-23 19:22:21.329: Find a better model.
2023-05-23 19:22:27.779: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.449054]
2023-05-23 19:22:27.920: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-23 19:22:27.920: Find a better model.
2023-05-23 19:22:34.347: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.426204]
2023-05-23 19:22:34.502: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-23 19:22:34.502: Find a better model.
2023-05-23 19:22:40.955: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.452148]
2023-05-23 19:22:41.111: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-23 19:22:41.111: Find a better model.
2023-05-23 19:22:47.569: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.456435]
2023-05-23 19:22:47.722: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-23 19:22:47.722: Find a better model.
2023-05-23 19:22:54.189: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.465951]
2023-05-23 19:22:54.342: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-23 19:22:54.342: Find a better model.
2023-05-23 19:23:00.766: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.423214]
2023-05-23 19:23:00.920: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-23 19:23:00.920: Find a better model.
2023-05-23 19:23:07.370: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.448653]
2023-05-23 19:23:07.523: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-23 19:23:07.523: Find a better model.
2023-05-23 19:23:13.960: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.435795]
2023-05-23 19:23:14.118: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-23 19:23:20.559: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.439935]
2023-05-23 19:23:20.713: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-23 19:23:20.713: Find a better model.
2023-05-23 19:23:27.157: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.443316]
2023-05-23 19:23:27.310: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-23 19:23:27.310: Find a better model.
2023-05-23 19:23:33.751: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.439802]
2023-05-23 19:23:33.893: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-23 19:23:33.893: Find a better model.
2023-05-23 19:23:40.367: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.473132]
2023-05-23 19:23:40.519: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-23 19:23:40.519: Find a better model.
2023-05-23 19:23:46.946: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.426237]
2023-05-23 19:23:47.102: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-23 19:23:47.102: Find a better model.
2023-05-23 19:23:53.546: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.442261]
2023-05-23 19:23:53.697: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-23 19:23:53.698: Find a better model.
2023-05-23 19:24:00.152: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.453575]
2023-05-23 19:24:00.292: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-23 19:24:00.292: Find a better model.
2023-05-23 19:24:06.740: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.446806]
2023-05-23 19:24:06.893: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-23 19:24:06.893: Find a better model.
2023-05-23 19:24:13.336: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.441669]
2023-05-23 19:24:13.490: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-23 19:24:13.490: Find a better model.
2023-05-23 19:24:19.952: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.461708]
2023-05-23 19:24:20.106: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-23 19:24:20.106: Find a better model.
2023-05-23 19:24:26.531: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.423427]
2023-05-23 19:24:26.683: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-23 19:24:33.148: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.463393]
2023-05-23 19:24:33.303: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-23 19:24:33.304: Find a better model.
2023-05-23 19:24:39.920: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.614820]
2023-05-23 19:24:40.072: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-23 19:24:40.072: Find a better model.
2023-05-23 19:24:46.516: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.443480]
2023-05-23 19:24:46.669: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-23 19:24:46.669: Find a better model.
2023-05-23 19:24:53.322: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.651923]
2023-05-23 19:24:53.476: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-23 19:24:53.476: Find a better model.
2023-05-23 19:25:00.115: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.637509]
2023-05-23 19:25:00.270: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-23 19:25:00.271: Find a better model.
2023-05-23 19:25:06.759: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.485901]
2023-05-23 19:25:06.911: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-23 19:25:06.911: Find a better model.
2023-05-23 19:25:13.326: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.414243]
2023-05-23 19:25:13.479: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-23 19:25:13.479: Find a better model.
2023-05-23 19:25:20.086: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.606023]
2023-05-23 19:25:20.231: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-23 19:25:20.231: Find a better model.
2023-05-23 19:25:26.714: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.481978]
2023-05-23 19:25:26.867: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-23 19:25:26.867: Find a better model.
2023-05-23 19:25:33.298: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.429788]
2023-05-23 19:25:33.440: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-23 19:25:33.440: Find a better model.
2023-05-23 19:25:39.914: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.472587]
2023-05-23 19:25:40.066: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-23 19:25:40.066: Find a better model.
2023-05-23 19:25:46.689: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.622702]
2023-05-23 19:25:46.842: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-23 19:25:53.479: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.636059]
2023-05-23 19:25:53.631: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-23 19:25:53.631: Find a better model.
2023-05-23 19:26:00.101: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.468969]
2023-05-23 19:26:00.246: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-23 19:26:00.246: Find a better model.
2023-05-23 19:26:06.713: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.463963]
2023-05-23 19:26:06.870: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-23 19:26:06.870: Find a better model.
2023-05-23 19:26:13.287: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.416688]
2023-05-23 19:26:13.428: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-23 19:26:13.429: Find a better model.
2023-05-23 19:26:20.085: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.654490]
2023-05-23 19:26:20.242: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-23 19:26:20.243: Find a better model.
2023-05-23 19:26:26.694: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.449277]
2023-05-23 19:26:26.835: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-23 19:26:26.835: Find a better model.
2023-05-23 19:26:33.325: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.488198]
2023-05-23 19:26:33.477: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-23 19:26:33.477: Find a better model.
2023-05-23 19:26:40.085: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.607421]
2023-05-23 19:26:40.238: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-23 19:26:46.683: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.444502]
2023-05-23 19:26:46.825: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-23 19:26:46.825: Find a better model.
2023-05-23 19:26:53.482: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.655695]
2023-05-23 19:26:53.635: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-23 19:26:53.635: Find a better model.
2023-05-23 19:27:00.084: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.447843]
2023-05-23 19:27:00.226: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-23 19:27:06.650: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.422801]
2023-05-23 19:27:06.792: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-23 19:27:13.286: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.493469]
2023-05-23 19:27:13.439: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-23 19:27:13.439: Find a better model.
2023-05-23 19:27:19.879: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.438831]
2023-05-23 19:27:20.032: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-23 19:27:20.032: Find a better model.
2023-05-23 19:27:26.482: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.448089]
2023-05-23 19:27:26.634: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-23 19:27:26.635: Find a better model.
2023-05-23 19:27:33.249: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.613193]
2023-05-23 19:27:33.404: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-23 19:27:39.847: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.442173]
2023-05-23 19:27:39.988: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-23 19:27:39.988: Find a better model.
2023-05-23 19:27:46.462: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.472589]
2023-05-23 19:27:46.614: epoch 81:	0.02575562  	0.19010241  	0.10375397  
2023-05-23 19:27:46.614: Find a better model.
2023-05-23 19:27:53.064: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.449771]
2023-05-23 19:27:53.216: epoch 82:	0.02593909  	0.19127873  	0.10442533  
2023-05-23 19:27:53.216: Find a better model.
2023-05-23 19:27:59.671: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.454133]
2023-05-23 19:27:59.824: epoch 83:	0.02591792  	0.19122753  	0.10434162  
2023-05-23 19:28:06.249: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.424504]
2023-05-23 19:28:06.405: epoch 84:	0.02591792  	0.19129056  	0.10438651  
2023-05-23 19:28:06.405: Find a better model.
2023-05-23 19:28:12.827: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.419996]
2023-05-23 19:28:12.981: epoch 85:	0.02591087  	0.19136642  	0.10479141  
2023-05-23 19:28:12.981: Find a better model.
2023-05-23 19:28:19.432: [iter 86 : loss : 0.1368 = 0.0466 + 0.0854 + 0.0049, time: 6.450077]
2023-05-23 19:28:19.578: epoch 86:	0.02597438  	0.19166841  	0.10489704  
2023-05-23 19:28:19.578: Find a better model.
2023-05-23 19:28:26.024: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.443633]
2023-05-23 19:28:26.167: epoch 87:	0.02607317  	0.19224219  	0.10512664  
2023-05-23 19:28:26.168: Find a better model.
2023-05-23 19:28:32.629: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.460702]
2023-05-23 19:28:32.782: epoch 88:	0.02608023  	0.19226837  	0.10511711  
2023-05-23 19:28:32.782: Find a better model.
2023-05-23 19:28:39.245: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.460291]
2023-05-23 19:28:39.391: epoch 89:	0.02603083  	0.19170186  	0.10493099  
2023-05-23 19:28:45.821: [iter 90 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 6.429309]
2023-05-23 19:28:45.975: epoch 90:	0.02620724  	0.19286238  	0.10541573  
2023-05-23 19:28:45.975: Find a better model.
2023-05-23 19:28:52.437: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.460884]
2023-05-23 19:28:52.590: epoch 91:	0.02622136  	0.19309144  	0.10551340  
2023-05-23 19:28:52.590: Find a better model.
2023-05-23 19:28:59.032: [iter 92 : loss : 0.1315 = 0.0415 + 0.0849 + 0.0051, time: 6.440814]
2023-05-23 19:28:59.186: epoch 92:	0.02627075  	0.19332008  	0.10576107  
2023-05-23 19:28:59.186: Find a better model.
2023-05-23 19:29:05.638: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.451341]
2023-05-23 19:29:05.789: epoch 93:	0.02626370  	0.19348286  	0.10588794  
2023-05-23 19:29:05.789: Find a better model.
2023-05-23 19:29:12.245: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.455029]
2023-05-23 19:29:12.403: epoch 94:	0.02635543  	0.19406378  	0.10619074  
2023-05-23 19:29:12.403: Find a better model.
2023-05-23 19:29:18.829: [iter 95 : loss : 0.1292 = 0.0394 + 0.0847 + 0.0052, time: 6.425083]
2023-05-23 19:29:18.981: epoch 95:	0.02632015  	0.19381511  	0.10616567  
2023-05-23 19:29:25.448: [iter 96 : loss : 0.1293 = 0.0395 + 0.0846 + 0.0052, time: 6.464499]
2023-05-23 19:29:25.600: epoch 96:	0.02631309  	0.19380218  	0.10632121  
2023-05-23 19:29:32.021: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 6.419943]
2023-05-23 19:29:32.163: epoch 97:	0.02635543  	0.19422498  	0.10641174  
2023-05-23 19:29:32.163: Find a better model.
2023-05-23 19:29:38.608: [iter 98 : loss : 0.1284 = 0.0386 + 0.0844 + 0.0053, time: 6.443882]
2023-05-23 19:29:38.760: epoch 98:	0.02649656  	0.19535162  	0.10685667  
2023-05-23 19:29:38.761: Find a better model.
2023-05-23 19:29:45.227: [iter 99 : loss : 0.1274 = 0.0377 + 0.0844 + 0.0053, time: 6.465793]
2023-05-23 19:29:45.380: epoch 99:	0.02656006  	0.19601974  	0.10707307  
2023-05-23 19:29:45.380: Find a better model.
2023-05-23 19:29:51.827: [iter 100 : loss : 0.1269 = 0.0373 + 0.0843 + 0.0054, time: 6.444715]
2023-05-23 19:29:51.980: epoch 100:	0.02658829  	0.19632106  	0.10702197  
2023-05-23 19:29:51.980: Find a better model.
2023-05-23 19:29:58.416: [iter 101 : loss : 0.1265 = 0.0369 + 0.0842 + 0.0054, time: 6.435379]
2023-05-23 19:29:58.570: epoch 101:	0.02660946  	0.19651890  	0.10707858  
2023-05-23 19:29:58.570: Find a better model.
2023-05-23 19:30:05.020: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0055, time: 6.449109]
2023-05-23 19:30:05.162: epoch 102:	0.02668002  	0.19689581  	0.10739435  
2023-05-23 19:30:05.162: Find a better model.
2023-05-23 19:30:11.594: [iter 103 : loss : 0.1254 = 0.0359 + 0.0841 + 0.0055, time: 6.430208]
2023-05-23 19:30:11.747: epoch 103:	0.02672942  	0.19708845  	0.10746172  
2023-05-23 19:30:11.747: Find a better model.
2023-05-23 19:30:18.213: [iter 104 : loss : 0.1257 = 0.0361 + 0.0840 + 0.0055, time: 6.465070]
2023-05-23 19:30:18.367: epoch 104:	0.02676470  	0.19758858  	0.10781977  
2023-05-23 19:30:18.367: Find a better model.
2023-05-23 19:30:24.814: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 6.445138]
2023-05-23 19:30:24.968: epoch 105:	0.02670825  	0.19723174  	0.10779316  
2023-05-23 19:30:31.398: [iter 106 : loss : 0.1245 = 0.0351 + 0.0839 + 0.0056, time: 6.428597]
2023-05-23 19:30:31.555: epoch 106:	0.02668708  	0.19672938  	0.10751413  
2023-05-23 19:30:37.995: [iter 107 : loss : 0.1236 = 0.0341 + 0.0838 + 0.0056, time: 6.437889]
2023-05-23 19:30:38.147: epoch 107:	0.02674353  	0.19700524  	0.10766010  
2023-05-23 19:30:44.420: [iter 108 : loss : 0.1234 = 0.0339 + 0.0838 + 0.0057, time: 6.272025]
2023-05-23 19:30:44.578: epoch 108:	0.02674353  	0.19727808  	0.10775302  
2023-05-23 19:30:51.023: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.443482]
2023-05-23 19:30:51.177: epoch 109:	0.02679998  	0.19769494  	0.10778759  
2023-05-23 19:30:51.177: Find a better model.
2023-05-23 19:30:57.584: [iter 110 : loss : 0.1215 = 0.0321 + 0.0837 + 0.0057, time: 6.405956]
2023-05-23 19:30:57.738: epoch 110:	0.02684937  	0.19792853  	0.10786643  
2023-05-23 19:30:57.738: Find a better model.
2023-05-23 19:31:04.003: [iter 111 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0058, time: 6.264518]
2023-05-23 19:31:04.158: epoch 111:	0.02684232  	0.19815508  	0.10798685  
2023-05-23 19:31:04.158: Find a better model.
2023-05-23 19:31:10.572: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.412424]
2023-05-23 19:31:10.713: epoch 112:	0.02690582  	0.19857737  	0.10814612  
2023-05-23 19:31:10.713: Find a better model.
2023-05-23 19:31:17.183: [iter 113 : loss : 0.1212 = 0.0319 + 0.0835 + 0.0058, time: 6.468475]
2023-05-23 19:31:17.337: epoch 113:	0.02694816  	0.19922990  	0.10829959  
2023-05-23 19:31:17.337: Find a better model.
2023-05-23 19:31:23.783: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.444564]
2023-05-23 19:31:23.936: epoch 114:	0.02696227  	0.19918688  	0.10845876  
2023-05-23 19:31:30.364: [iter 115 : loss : 0.1201 = 0.0308 + 0.0834 + 0.0059, time: 6.426527]
2023-05-23 19:31:30.506: epoch 115:	0.02693404  	0.19841936  	0.10839956  
2023-05-23 19:31:36.955: [iter 116 : loss : 0.1193 = 0.0300 + 0.0833 + 0.0059, time: 6.446027]
2023-05-23 19:31:37.096: epoch 116:	0.02691287  	0.19813544  	0.10830959  
2023-05-23 19:31:43.559: [iter 117 : loss : 0.1193 = 0.0300 + 0.0833 + 0.0060, time: 6.461131]
2023-05-23 19:31:43.712: epoch 117:	0.02690581  	0.19810393  	0.10820207  
2023-05-23 19:31:50.180: [iter 118 : loss : 0.1191 = 0.0299 + 0.0832 + 0.0060, time: 6.466673]
2023-05-23 19:31:50.331: epoch 118:	0.02695521  	0.19845442  	0.10837909  
2023-05-23 19:31:56.764: [iter 119 : loss : 0.1181 = 0.0289 + 0.0831 + 0.0060, time: 6.431795]
2023-05-23 19:31:56.915: epoch 119:	0.02694109  	0.19837591  	0.10855760  
2023-05-23 19:32:03.359: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.442560]
2023-05-23 19:32:03.500: epoch 120:	0.02700461  	0.19884144  	0.10875380  
2023-05-23 19:32:09.953: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.452243]
2023-05-23 19:32:10.095: epoch 121:	0.02697637  	0.19854870  	0.10880199  
2023-05-23 19:32:16.573: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.475937]
2023-05-23 19:32:16.727: epoch 122:	0.02702577  	0.19889085  	0.10889190  
2023-05-23 19:32:23.149: [iter 123 : loss : 0.1175 = 0.0284 + 0.0830 + 0.0061, time: 6.420050]
2023-05-23 19:32:23.303: epoch 123:	0.02698343  	0.19856900  	0.10857955  
2023-05-23 19:32:29.561: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.257138]
2023-05-23 19:32:29.702: epoch 124:	0.02703988  	0.19914351  	0.10869006  
2023-05-23 19:32:36.153: [iter 125 : loss : 0.1160 = 0.0269 + 0.0829 + 0.0062, time: 6.450748]
2023-05-23 19:32:36.307: epoch 125:	0.02708222  	0.19945495  	0.10879414  
2023-05-23 19:32:36.307: Find a better model.
2023-05-23 19:32:42.745: [iter 126 : loss : 0.1161 = 0.0270 + 0.0828 + 0.0062, time: 6.437050]
2023-05-23 19:32:42.888: epoch 126:	0.02699754  	0.19873321  	0.10862701  
2023-05-23 19:32:49.342: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.452428]
2023-05-23 19:32:49.484: epoch 127:	0.02699754  	0.19923885  	0.10891034  
2023-05-23 19:32:55.793: [iter 128 : loss : 0.1163 = 0.0272 + 0.0827 + 0.0063, time: 6.308363]
2023-05-23 19:32:55.945: epoch 128:	0.02706811  	0.19974394  	0.10904109  
2023-05-23 19:32:55.946: Find a better model.
2023-05-23 19:33:02.349: [iter 129 : loss : 0.1153 = 0.0262 + 0.0827 + 0.0063, time: 6.402068]
2023-05-23 19:33:02.490: epoch 129:	0.02711045  	0.19985773  	0.10919988  
2023-05-23 19:33:02.490: Find a better model.
2023-05-23 19:33:08.754: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.261388]
2023-05-23 19:33:08.896: epoch 130:	0.02713162  	0.20036437  	0.10946644  
2023-05-23 19:33:08.896: Find a better model.
2023-05-23 19:33:15.342: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.444366]
2023-05-23 19:33:15.496: epoch 131:	0.02713163  	0.20026566  	0.10958119  
2023-05-23 19:33:21.921: [iter 132 : loss : 0.1147 = 0.0258 + 0.0826 + 0.0064, time: 6.424247]
2023-05-23 19:33:22.075: epoch 132:	0.02716690  	0.20065944  	0.10956684  
2023-05-23 19:33:22.075: Find a better model.
2023-05-23 19:33:28.545: [iter 133 : loss : 0.1134 = 0.0244 + 0.0825 + 0.0064, time: 6.468347]
2023-05-23 19:33:28.700: epoch 133:	0.02710339  	0.20018265  	0.10957763  
2023-05-23 19:33:35.123: [iter 134 : loss : 0.1143 = 0.0253 + 0.0825 + 0.0065, time: 6.422215]
2023-05-23 19:33:35.275: epoch 134:	0.02711750  	0.20006318  	0.10958210  
2023-05-23 19:33:41.750: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.473264]
2023-05-23 19:33:41.903: epoch 135:	0.02707516  	0.19982758  	0.10942691  
2023-05-23 19:33:48.326: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.422258]
2023-05-23 19:33:48.466: epoch 136:	0.02701872  	0.19983028  	0.10929129  
2023-05-23 19:33:54.915: [iter 137 : loss : 0.1132 = 0.0243 + 0.0824 + 0.0066, time: 6.445120]
2023-05-23 19:33:55.068: epoch 137:	0.02708927  	0.19985127  	0.10939059  
2023-05-23 19:34:01.517: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.448541]
2023-05-23 19:34:01.676: epoch 138:	0.02701166  	0.19937064  	0.10920369  
2023-05-23 19:34:08.107: [iter 139 : loss : 0.1126 = 0.0237 + 0.0823 + 0.0066, time: 6.430493]
2023-05-23 19:34:08.260: epoch 139:	0.02703283  	0.19949026  	0.10928718  
2023-05-23 19:34:14.706: [iter 140 : loss : 0.1121 = 0.0232 + 0.0822 + 0.0067, time: 6.444572]
2023-05-23 19:34:14.859: epoch 140:	0.02703283  	0.19942643  	0.10925040  
2023-05-23 19:34:21.156: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.295204]
2023-05-23 19:34:21.308: epoch 141:	0.02704694  	0.19932535  	0.10946346  
2023-05-23 19:34:27.709: [iter 142 : loss : 0.1118 = 0.0229 + 0.0822 + 0.0067, time: 6.400097]
2023-05-23 19:34:27.861: epoch 142:	0.02707517  	0.19970559  	0.10959908  
2023-05-23 19:34:34.311: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.449511]
2023-05-23 19:34:34.464: epoch 143:	0.02708928  	0.19976741  	0.10972610  
2023-05-23 19:34:40.909: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.442220]
2023-05-23 19:34:41.051: epoch 144:	0.02705400  	0.19976166  	0.10965661  
2023-05-23 19:34:47.509: [iter 145 : loss : 0.1114 = 0.0225 + 0.0821 + 0.0068, time: 6.457270]
2023-05-23 19:34:47.665: epoch 145:	0.02711045  	0.19991350  	0.10974696  
2023-05-23 19:34:54.099: [iter 146 : loss : 0.1115 = 0.0226 + 0.0820 + 0.0068, time: 6.432197]
2023-05-23 19:34:54.253: epoch 146:	0.02702578  	0.19924080  	0.10942609  
2023-05-23 19:35:00.726: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.471304]
2023-05-23 19:35:00.879: epoch 147:	0.02710340  	0.19995272  	0.10978813  
2023-05-23 19:35:07.317: [iter 148 : loss : 0.1102 = 0.0213 + 0.0820 + 0.0069, time: 6.436096]
2023-05-23 19:35:07.474: epoch 148:	0.02710340  	0.19966340  	0.10970699  
2023-05-23 19:35:13.912: [iter 149 : loss : 0.1106 = 0.0217 + 0.0819 + 0.0069, time: 6.437353]
2023-05-23 19:35:14.066: epoch 149:	0.02715985  	0.20004411  	0.10979738  
2023-05-23 19:35:20.489: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.422441]
2023-05-23 19:35:20.631: epoch 150:	0.02718807  	0.20013879  	0.11013640  
2023-05-23 19:35:26.906: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.274106]
2023-05-23 19:35:27.059: epoch 151:	0.02718808  	0.19999963  	0.11009878  
2023-05-23 19:35:33.491: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.429931]
2023-05-23 19:35:33.634: epoch 152:	0.02711045  	0.19934964  	0.11003497  
2023-05-23 19:35:39.911: [iter 153 : loss : 0.1086 = 0.0198 + 0.0818 + 0.0070, time: 6.276098]
2023-05-23 19:35:40.064: epoch 153:	0.02710339  	0.19926266  	0.10981814  
2023-05-23 19:35:46.492: [iter 154 : loss : 0.1092 = 0.0204 + 0.0818 + 0.0070, time: 6.425811]
2023-05-23 19:35:46.645: epoch 154:	0.02723041  	0.20032369  	0.11022569  
2023-05-23 19:35:52.906: [iter 155 : loss : 0.1098 = 0.0210 + 0.0818 + 0.0071, time: 6.260096]
2023-05-23 19:35:53.057: epoch 155:	0.02713868  	0.19980915  	0.11001094  
2023-05-23 19:35:59.482: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.423795]
2023-05-23 19:35:59.633: epoch 156:	0.02714574  	0.19987027  	0.10984176  
2023-05-23 19:36:06.061: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.426711]
2023-05-23 19:36:06.201: epoch 157:	0.02711751  	0.19966646  	0.10975536  
2023-05-23 19:36:06.201: Early stopping is trigger at epoch: 157
2023-05-23 19:36:06.201: best_result@epoch 132:

2023-05-23 19:36:06.201: 		0.0272      	0.2007      	0.1096      
2023-05-23 19:49:10.411: my pid: 14124
2023-05-23 19:49:10.411: model: model.general_recommender.SGL
2023-05-23 19:49:10.411: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 19:49:10.411: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 19:49:14.036: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 19:49:21.453: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.415523]
2023-05-23 19:49:21.596: epoch 1:	0.00216625  	0.01497536  	0.00764244  
2023-05-23 19:49:21.597: Find a better model.
2023-05-23 19:49:29.046: [iter 2 : loss : 0.7706 = 0.6929 + 0.0777 + 0.0000, time: 7.446970]
2023-05-23 19:49:29.245: epoch 2:	0.00394438  	0.02714157  	0.01355890  
2023-05-23 19:49:29.245: Find a better model.
2023-05-23 19:49:36.660: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.413729]
2023-05-23 19:49:36.821: epoch 3:	0.00671742  	0.04654722  	0.02366749  
2023-05-23 19:49:36.822: Find a better model.
2023-05-23 19:49:44.066: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.243539]
2023-05-23 19:49:44.221: epoch 4:	0.00967396  	0.06787906  	0.03394979  
2023-05-23 19:49:44.221: Find a better model.
2023-05-23 19:49:51.264: [iter 5 : loss : 0.7685 = 0.6906 + 0.0778 + 0.0000, time: 7.040772]
2023-05-23 19:49:51.418: epoch 5:	0.01265885  	0.08938721  	0.04379842  
2023-05-23 19:49:51.418: Find a better model.
2023-05-23 19:49:58.406: [iter 6 : loss : 0.7655 = 0.6874 + 0.0781 + 0.0000, time: 6.986573]
2023-05-23 19:49:58.559: epoch 6:	0.01543907  	0.11075804  	0.05446367  
2023-05-23 19:49:58.559: Find a better model.
2023-05-23 19:50:05.413: [iter 7 : loss : 0.7576 = 0.6787 + 0.0789 + 0.0000, time: 6.853014]
2023-05-23 19:50:05.555: epoch 7:	0.01788764  	0.12975959  	0.06405847  
2023-05-23 19:50:05.555: Find a better model.
2023-05-23 19:50:12.408: [iter 8 : loss : 0.7388 = 0.6578 + 0.0809 + 0.0001, time: 6.851299]
2023-05-23 19:50:12.561: epoch 8:	0.01873441  	0.13699752  	0.06902540  
2023-05-23 19:50:12.561: Find a better model.
2023-05-23 19:50:19.421: [iter 9 : loss : 0.6989 = 0.6139 + 0.0848 + 0.0002, time: 6.859017]
2023-05-23 19:50:19.576: epoch 9:	0.01879792  	0.13885236  	0.06976726  
2023-05-23 19:50:19.576: Find a better model.
2023-05-23 19:50:26.229: [iter 10 : loss : 0.6345 = 0.5442 + 0.0900 + 0.0003, time: 6.651241]
2023-05-23 19:50:26.383: epoch 10:	0.01888260  	0.13985242  	0.06963884  
2023-05-23 19:50:26.383: Find a better model.
2023-05-23 19:50:33.032: [iter 11 : loss : 0.5590 = 0.4638 + 0.0948 + 0.0004, time: 6.648448]
2023-05-23 19:50:33.188: epoch 11:	0.01871325  	0.13860905  	0.06942577  
2023-05-23 19:50:39.799: [iter 12 : loss : 0.4925 = 0.3940 + 0.0979 + 0.0006, time: 6.610657]
2023-05-23 19:50:39.940: epoch 12:	0.01852272  	0.13726650  	0.06928337  
2023-05-23 19:50:46.600: [iter 13 : loss : 0.4439 = 0.3436 + 0.0996 + 0.0007, time: 6.658387]
2023-05-23 19:50:46.754: epoch 13:	0.01857212  	0.13756423  	0.06985772  
2023-05-23 19:50:53.408: [iter 14 : loss : 0.4072 = 0.3058 + 0.1005 + 0.0009, time: 6.650495]
2023-05-23 19:50:53.560: epoch 14:	0.01878382  	0.13956578  	0.07076950  
2023-05-23 19:51:00.199: [iter 15 : loss : 0.3812 = 0.2795 + 0.1008 + 0.0010, time: 6.637850]
2023-05-23 19:51:00.342: epoch 15:	0.01891789  	0.14010404  	0.07146242  
2023-05-23 19:51:00.342: Find a better model.
2023-05-23 19:51:06.991: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 6.647878]
2023-05-23 19:51:07.143: epoch 16:	0.01919310  	0.14209834  	0.07224111  
2023-05-23 19:51:07.143: Find a better model.
2023-05-23 19:51:13.635: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 6.490829]
2023-05-23 19:51:13.792: epoch 17:	0.01939774  	0.14316788  	0.07318529  
2023-05-23 19:51:13.792: Find a better model.
2023-05-23 19:51:20.380: [iter 18 : loss : 0.3286 = 0.2268 + 0.1004 + 0.0013, time: 6.585961]
2023-05-23 19:51:20.532: epoch 18:	0.01965882  	0.14523189  	0.07400754  
2023-05-23 19:51:20.532: Find a better model.
2023-05-23 19:51:27.172: [iter 19 : loss : 0.3146 = 0.2131 + 0.1000 + 0.0014, time: 6.637149]
2023-05-23 19:51:27.323: epoch 19:	0.01989875  	0.14659438  	0.07485601  
2023-05-23 19:51:27.324: Find a better model.
2023-05-23 19:51:33.786: [iter 20 : loss : 0.3051 = 0.2039 + 0.0996 + 0.0015, time: 6.461673]
2023-05-23 19:51:33.930: epoch 20:	0.02015279  	0.14849868  	0.07577936  
2023-05-23 19:51:33.930: Find a better model.
2023-05-23 19:51:40.585: [iter 21 : loss : 0.2954 = 0.1946 + 0.0993 + 0.0016, time: 6.653117]
2023-05-23 19:51:40.740: epoch 21:	0.02032920  	0.14976291  	0.07656690  
2023-05-23 19:51:40.740: Find a better model.
2023-05-23 19:51:47.383: [iter 22 : loss : 0.2873 = 0.1868 + 0.0989 + 0.0017, time: 6.641785]
2023-05-23 19:51:47.535: epoch 22:	0.02051266  	0.15155566  	0.07746946  
2023-05-23 19:51:47.535: Find a better model.
2023-05-23 19:51:54.016: [iter 23 : loss : 0.2793 = 0.1790 + 0.0985 + 0.0018, time: 6.480819]
2023-05-23 19:51:54.169: epoch 23:	0.02067497  	0.15280922  	0.07839331  
2023-05-23 19:51:54.169: Find a better model.
2023-05-23 19:52:00.776: [iter 24 : loss : 0.2728 = 0.1729 + 0.0980 + 0.0018, time: 6.605596]
2023-05-23 19:52:00.923: epoch 24:	0.02087960  	0.15387651  	0.07897241  
2023-05-23 19:52:00.923: Find a better model.
2023-05-23 19:52:07.573: [iter 25 : loss : 0.2661 = 0.1665 + 0.0976 + 0.0019, time: 6.648052]
2023-05-23 19:52:07.724: epoch 25:	0.02102073  	0.15470774  	0.07946541  
2023-05-23 19:52:07.724: Find a better model.
2023-05-23 19:52:14.365: [iter 26 : loss : 0.2624 = 0.1633 + 0.0972 + 0.0020, time: 6.633639]
2023-05-23 19:52:14.519: epoch 26:	0.02112659  	0.15535788  	0.07995071  
2023-05-23 19:52:14.520: Find a better model.
2023-05-23 19:52:21.162: [iter 27 : loss : 0.2548 = 0.1559 + 0.0968 + 0.0021, time: 6.640783]
2023-05-23 19:52:21.305: epoch 27:	0.02129594  	0.15674502  	0.08069664  
2023-05-23 19:52:21.305: Find a better model.
2023-05-23 19:52:27.770: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 6.463481]
2023-05-23 19:52:27.927: epoch 28:	0.02143002  	0.15756500  	0.08144733  
2023-05-23 19:52:27.927: Find a better model.
2023-05-23 19:52:34.394: [iter 29 : loss : 0.2456 = 0.1474 + 0.0960 + 0.0022, time: 6.464955]
2023-05-23 19:52:34.547: epoch 29:	0.02162054  	0.15895677  	0.08225098  
2023-05-23 19:52:34.547: Find a better model.
2023-05-23 19:52:41.165: [iter 30 : loss : 0.2390 = 0.1411 + 0.0956 + 0.0022, time: 6.615417]
2023-05-23 19:52:41.317: epoch 30:	0.02184634  	0.16083184  	0.08313150  
2023-05-23 19:52:41.318: Find a better model.
2023-05-23 19:52:47.992: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 6.672248]
2023-05-23 19:52:48.139: epoch 31:	0.02198747  	0.16185437  	0.08384563  
2023-05-23 19:52:48.139: Find a better model.
2023-05-23 19:52:54.752: [iter 32 : loss : 0.2300 = 0.1327 + 0.0949 + 0.0024, time: 6.611593]
2023-05-23 19:52:54.899: epoch 32:	0.02214271  	0.16267397  	0.08440990  
2023-05-23 19:52:54.900: Find a better model.
2023-05-23 19:53:01.552: [iter 33 : loss : 0.2272 = 0.1302 + 0.0945 + 0.0024, time: 6.651200]
2023-05-23 19:53:01.704: epoch 33:	0.02221327  	0.16328903  	0.08470640  
2023-05-23 19:53:01.704: Find a better model.
2023-05-23 19:53:08.331: [iter 34 : loss : 0.2234 = 0.1268 + 0.0942 + 0.0025, time: 6.625315]
2023-05-23 19:53:08.485: epoch 34:	0.02237557  	0.16443875  	0.08538613  
2023-05-23 19:53:08.485: Find a better model.
2023-05-23 19:53:15.176: [iter 35 : loss : 0.2200 = 0.1236 + 0.0939 + 0.0025, time: 6.689617]
2023-05-23 19:53:15.327: epoch 35:	0.02248847  	0.16539912  	0.08601477  
2023-05-23 19:53:15.328: Find a better model.
2023-05-23 19:53:21.960: [iter 36 : loss : 0.2166 = 0.1204 + 0.0936 + 0.0026, time: 6.630678]
2023-05-23 19:53:22.111: epoch 36:	0.02270723  	0.16716278  	0.08693756  
2023-05-23 19:53:22.111: Find a better model.
2023-05-23 19:53:28.745: [iter 37 : loss : 0.2126 = 0.1167 + 0.0932 + 0.0027, time: 6.631993]
2023-05-23 19:53:28.895: epoch 37:	0.02288364  	0.16815960  	0.08760352  
2023-05-23 19:53:28.895: Find a better model.
2023-05-23 19:53:35.539: [iter 38 : loss : 0.2111 = 0.1154 + 0.0930 + 0.0027, time: 6.642889]
2023-05-23 19:53:35.693: epoch 38:	0.02296126  	0.16911186  	0.08815136  
2023-05-23 19:53:35.693: Find a better model.
2023-05-23 19:53:42.338: [iter 39 : loss : 0.2067 = 0.1112 + 0.0927 + 0.0028, time: 6.644159]
2023-05-23 19:53:42.481: epoch 39:	0.02294715  	0.16911449  	0.08876958  
2023-05-23 19:53:42.481: Find a better model.
2023-05-23 19:53:49.145: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 6.663648]
2023-05-23 19:53:49.300: epoch 40:	0.02297538  	0.16947632  	0.08907121  
2023-05-23 19:53:49.300: Find a better model.
2023-05-23 19:53:55.943: [iter 41 : loss : 0.2019 = 0.1070 + 0.0921 + 0.0029, time: 6.642744]
2023-05-23 19:53:56.095: epoch 41:	0.02314474  	0.17047954  	0.08967278  
2023-05-23 19:53:56.095: Find a better model.
2023-05-23 19:54:02.749: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.653152]
2023-05-23 19:54:02.902: epoch 42:	0.02327175  	0.17125009  	0.09019362  
2023-05-23 19:54:02.903: Find a better model.
2023-05-23 19:54:09.547: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 6.643585]
2023-05-23 19:54:09.698: epoch 43:	0.02338466  	0.17248400  	0.09090815  
2023-05-23 19:54:09.698: Find a better model.
2023-05-23 19:54:16.335: [iter 44 : loss : 0.1924 = 0.0981 + 0.0912 + 0.0030, time: 6.635052]
2023-05-23 19:54:16.488: epoch 44:	0.02351873  	0.17322424  	0.09142201  
2023-05-23 19:54:16.488: Find a better model.
2023-05-23 19:54:23.144: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.653638]
2023-05-23 19:54:23.295: epoch 45:	0.02365986  	0.17424634  	0.09224367  
2023-05-23 19:54:23.295: Find a better model.
2023-05-23 19:54:29.930: [iter 46 : loss : 0.1880 = 0.0941 + 0.0908 + 0.0031, time: 6.633817]
2023-05-23 19:54:30.087: epoch 46:	0.02369515  	0.17449503  	0.09244721  
2023-05-23 19:54:30.087: Find a better model.
2023-05-23 19:54:36.563: [iter 47 : loss : 0.1871 = 0.0933 + 0.0905 + 0.0032, time: 6.474000]
2023-05-23 19:54:36.716: epoch 47:	0.02386451  	0.17573193  	0.09284776  
2023-05-23 19:54:36.716: Find a better model.
2023-05-23 19:54:43.302: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.585788]
2023-05-23 19:54:43.445: epoch 48:	0.02392095  	0.17622703  	0.09325764  
2023-05-23 19:54:43.445: Find a better model.
2023-05-23 19:54:50.114: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 6.667134]
2023-05-23 19:54:50.268: epoch 49:	0.02406914  	0.17730820  	0.09392841  
2023-05-23 19:54:50.268: Find a better model.
2023-05-23 19:54:56.913: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 6.642842]
2023-05-23 19:54:57.071: epoch 50:	0.02406208  	0.17759329  	0.09424033  
2023-05-23 19:54:57.071: Find a better model.
2023-05-23 19:55:03.695: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 6.622862]
2023-05-23 19:55:03.847: epoch 51:	0.02416793  	0.17844321  	0.09467940  
2023-05-23 19:55:03.847: Find a better model.
2023-05-23 19:55:10.497: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 6.648856]
2023-05-23 19:55:10.652: epoch 52:	0.02422437  	0.17842750  	0.09497578  
2023-05-23 19:55:17.139: [iter 53 : loss : 0.1742 = 0.0815 + 0.0893 + 0.0035, time: 6.485319]
2023-05-23 19:55:17.293: epoch 53:	0.02433728  	0.17941333  	0.09565471  
2023-05-23 19:55:17.293: Find a better model.
2023-05-23 19:55:23.897: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 6.602202]
2023-05-23 19:55:24.051: epoch 54:	0.02434433  	0.17965502  	0.09601045  
2023-05-23 19:55:24.051: Find a better model.
2023-05-23 19:55:30.694: [iter 55 : loss : 0.1703 = 0.0779 + 0.0889 + 0.0036, time: 6.639163]
2023-05-23 19:55:30.848: epoch 55:	0.02432316  	0.17928515  	0.09599151  
2023-05-23 19:55:37.483: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.633544]
2023-05-23 19:55:37.635: epoch 56:	0.02438667  	0.17958453  	0.09643993  
2023-05-23 19:55:44.295: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 6.656856]
2023-05-23 19:55:44.447: epoch 57:	0.02448546  	0.18022777  	0.09681772  
2023-05-23 19:55:44.447: Find a better model.
2023-05-23 19:55:51.079: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 6.629385]
2023-05-23 19:55:51.230: epoch 58:	0.02447134  	0.17994051  	0.09698641  
2023-05-23 19:55:57.894: [iter 59 : loss : 0.1640 = 0.0721 + 0.0882 + 0.0038, time: 6.661736]
2023-05-23 19:55:58.035: epoch 59:	0.02459130  	0.18102334  	0.09751311  
2023-05-23 19:55:58.035: Find a better model.
2023-05-23 19:56:04.507: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 6.471591]
2023-05-23 19:56:04.664: epoch 60:	0.02473243  	0.18233371  	0.09813038  
2023-05-23 19:56:04.664: Find a better model.
2023-05-23 19:56:11.296: [iter 61 : loss : 0.1612 = 0.0694 + 0.0879 + 0.0038, time: 6.631093]
2023-05-23 19:56:11.449: epoch 61:	0.02476772  	0.18282568  	0.09840386  
2023-05-23 19:56:11.449: Find a better model.
2023-05-23 19:56:18.103: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 6.651962]
2023-05-23 19:56:18.256: epoch 62:	0.02479594  	0.18302089  	0.09864884  
2023-05-23 19:56:18.256: Find a better model.
2023-05-23 19:56:24.880: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 6.621617]
2023-05-23 19:56:25.032: epoch 63:	0.02488062  	0.18378438  	0.09916424  
2023-05-23 19:56:25.032: Find a better model.
2023-05-23 19:56:31.686: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 6.652821]
2023-05-23 19:56:31.839: epoch 64:	0.02494413  	0.18437508  	0.09951241  
2023-05-23 19:56:31.839: Find a better model.
2023-05-23 19:56:38.477: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 6.636714]
2023-05-23 19:56:38.618: epoch 65:	0.02497941  	0.18466699  	0.09980574  
2023-05-23 19:56:38.619: Find a better model.
2023-05-23 19:56:45.268: [iter 66 : loss : 0.1546 = 0.0634 + 0.0871 + 0.0041, time: 6.648245]
2023-05-23 19:56:45.421: epoch 66:	0.02506409  	0.18534249  	0.10031982  
2023-05-23 19:56:45.421: Find a better model.
2023-05-23 19:56:52.087: [iter 67 : loss : 0.1530 = 0.0620 + 0.0869 + 0.0041, time: 6.665111]
2023-05-23 19:56:52.241: epoch 67:	0.02502175  	0.18512684  	0.10033373  
2023-05-23 19:56:58.880: [iter 68 : loss : 0.1528 = 0.0618 + 0.0868 + 0.0042, time: 6.636713]
2023-05-23 19:56:59.034: epoch 68:	0.02517699  	0.18632852  	0.10074176  
2023-05-23 19:56:59.034: Find a better model.
2023-05-23 19:57:05.677: [iter 69 : loss : 0.1509 = 0.0601 + 0.0867 + 0.0042, time: 6.641873]
2023-05-23 19:57:05.820: epoch 69:	0.02514876  	0.18617438  	0.10094364  
2023-05-23 19:57:12.463: [iter 70 : loss : 0.1495 = 0.0587 + 0.0866 + 0.0042, time: 6.641830]
2023-05-23 19:57:12.615: epoch 70:	0.02522638  	0.18657640  	0.10142211  
2023-05-23 19:57:12.615: Find a better model.
2023-05-23 19:57:19.291: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.673622]
2023-05-23 19:57:19.446: epoch 71:	0.02530401  	0.18723078  	0.10194766  
2023-05-23 19:57:19.446: Find a better model.
2023-05-23 19:57:26.054: [iter 72 : loss : 0.1477 = 0.0571 + 0.0863 + 0.0043, time: 6.607171]
2023-05-23 19:57:26.198: epoch 72:	0.02538163  	0.18807197  	0.10218677  
2023-05-23 19:57:26.198: Find a better model.
2023-05-23 19:57:32.863: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 6.663774]
2023-05-23 19:57:33.016: epoch 73:	0.02545925  	0.18872808  	0.10249167  
2023-05-23 19:57:33.016: Find a better model.
2023-05-23 19:57:39.664: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.646585]
2023-05-23 19:57:39.806: epoch 74:	0.02547336  	0.18867107  	0.10270183  
2023-05-23 19:57:46.458: [iter 75 : loss : 0.1444 = 0.0540 + 0.0860 + 0.0044, time: 6.651649]
2023-05-23 19:57:46.612: epoch 75:	0.02556510  	0.18946289  	0.10315620  
2023-05-23 19:57:46.613: Find a better model.
2023-05-23 19:57:53.274: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 6.658516]
2023-05-23 19:57:53.426: epoch 76:	0.02557921  	0.18948366  	0.10323747  
2023-05-23 19:57:53.426: Find a better model.
2023-05-23 19:58:00.081: [iter 77 : loss : 0.1426 = 0.0523 + 0.0857 + 0.0045, time: 6.654615]
2023-05-23 19:58:00.235: epoch 77:	0.02567094  	0.19007935  	0.10351834  
2023-05-23 19:58:00.235: Find a better model.
2023-05-23 19:58:07.030: [iter 78 : loss : 0.1416 = 0.0515 + 0.0856 + 0.0046, time: 6.793425]
2023-05-23 19:58:07.186: epoch 78:	0.02574150  	0.19066168  	0.10372009  
2023-05-23 19:58:07.186: Find a better model.
2023-05-23 19:58:13.852: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 6.665427]
2023-05-23 19:58:14.008: epoch 79:	0.02572739  	0.19031818  	0.10357767  
2023-05-23 19:58:20.653: [iter 80 : loss : 0.1398 = 0.0498 + 0.0854 + 0.0047, time: 6.643595]
2023-05-23 19:58:20.808: epoch 80:	0.02576267  	0.19068532  	0.10380763  
2023-05-23 19:58:20.808: Find a better model.
2023-05-23 19:58:27.445: [iter 81 : loss : 0.1394 = 0.0494 + 0.0853 + 0.0047, time: 6.636721]
2023-05-23 19:58:27.590: epoch 81:	0.02581912  	0.19134311  	0.10397296  
2023-05-23 19:58:27.590: Find a better model.
2023-05-23 19:58:34.258: [iter 82 : loss : 0.1381 = 0.0482 + 0.0852 + 0.0047, time: 6.666880]
2023-05-23 19:58:34.411: epoch 82:	0.02590380  	0.19196683  	0.10444871  
2023-05-23 19:58:34.411: Find a better model.
2023-05-23 19:58:41.066: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 6.653833]
2023-05-23 19:58:41.224: epoch 83:	0.02589674  	0.19199549  	0.10462420  
2023-05-23 19:58:41.224: Find a better model.
2023-05-23 19:58:47.839: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 6.613493]
2023-05-23 19:58:47.993: epoch 84:	0.02598847  	0.19262144  	0.10496923  
2023-05-23 19:58:47.994: Find a better model.
2023-05-23 19:58:54.633: [iter 85 : loss : 0.1363 = 0.0465 + 0.0849 + 0.0048, time: 6.638642]
2023-05-23 19:58:54.788: epoch 85:	0.02589674  	0.19191842  	0.10492845  
2023-05-23 19:59:01.449: [iter 86 : loss : 0.1359 = 0.0463 + 0.0848 + 0.0049, time: 6.660410]
2023-05-23 19:59:01.601: epoch 86:	0.02596731  	0.19267619  	0.10519524  
2023-05-23 19:59:01.601: Find a better model.
2023-05-23 19:59:08.237: [iter 87 : loss : 0.1334 = 0.0437 + 0.0847 + 0.0049, time: 6.634729]
2023-05-23 19:59:08.395: epoch 87:	0.02600259  	0.19296810  	0.10554296  
2023-05-23 19:59:08.395: Find a better model.
2023-05-23 19:59:15.204: [iter 88 : loss : 0.1327 = 0.0431 + 0.0846 + 0.0050, time: 6.807978]
2023-05-23 19:59:15.359: epoch 88:	0.02606610  	0.19332168  	0.10571963  
2023-05-23 19:59:15.359: Find a better model.
2023-05-23 19:59:22.045: [iter 89 : loss : 0.1325 = 0.0430 + 0.0845 + 0.0050, time: 6.685197]
2023-05-23 19:59:22.199: epoch 89:	0.02603082  	0.19324417  	0.10568256  
2023-05-23 19:59:28.806: [iter 90 : loss : 0.1330 = 0.0435 + 0.0844 + 0.0050, time: 6.604677]
2023-05-23 19:59:28.959: epoch 90:	0.02607316  	0.19354725  	0.10576592  
2023-05-23 19:59:28.959: Find a better model.
2023-05-23 19:59:35.602: [iter 91 : loss : 0.1317 = 0.0422 + 0.0843 + 0.0051, time: 6.641517]
2023-05-23 19:59:35.757: epoch 91:	0.02612960  	0.19385689  	0.10596313  
2023-05-23 19:59:35.757: Find a better model.
2023-05-23 19:59:42.409: [iter 92 : loss : 0.1306 = 0.0413 + 0.0843 + 0.0051, time: 6.651395]
2023-05-23 19:59:42.563: epoch 92:	0.02617195  	0.19424167  	0.10611590  
2023-05-23 19:59:42.563: Find a better model.
2023-05-23 19:59:49.235: [iter 93 : loss : 0.1313 = 0.0420 + 0.0842 + 0.0052, time: 6.671009]
2023-05-23 19:59:49.388: epoch 93:	0.02623546  	0.19499393  	0.10628727  
2023-05-23 19:59:49.388: Find a better model.
2023-05-23 19:59:56.024: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 6.633251]
2023-05-23 19:59:56.179: epoch 94:	0.02618607  	0.19498123  	0.10625774  
2023-05-23 20:00:02.839: [iter 95 : loss : 0.1284 = 0.0391 + 0.0841 + 0.0052, time: 6.659135]
2023-05-23 20:00:02.993: epoch 95:	0.02616489  	0.19487981  	0.10619650  
2023-05-23 20:00:09.608: [iter 96 : loss : 0.1285 = 0.0393 + 0.0840 + 0.0053, time: 6.612534]
2023-05-23 20:00:09.761: epoch 96:	0.02619311  	0.19471452  	0.10647081  
2023-05-23 20:00:16.418: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 6.654828]
2023-05-23 20:00:16.573: epoch 97:	0.02620723  	0.19499263  	0.10654882  
2023-05-23 20:00:23.220: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 6.646017]
2023-05-23 20:00:23.379: epoch 98:	0.02632719  	0.19583116  	0.10707002  
2023-05-23 20:00:23.379: Find a better model.
2023-05-23 20:00:30.006: [iter 99 : loss : 0.1266 = 0.0374 + 0.0838 + 0.0054, time: 6.624170]
2023-05-23 20:00:30.159: epoch 99:	0.02634130  	0.19620173  	0.10694032  
2023-05-23 20:00:30.159: Find a better model.
2023-05-23 20:00:36.806: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 6.645140]
2023-05-23 20:00:36.956: epoch 100:	0.02635542  	0.19621514  	0.10690347  
2023-05-23 20:00:36.956: Find a better model.
2023-05-23 20:00:43.620: [iter 101 : loss : 0.1256 = 0.0365 + 0.0836 + 0.0054, time: 6.661354]
2023-05-23 20:00:43.772: epoch 101:	0.02632013  	0.19547941  	0.10677489  
2023-05-23 20:00:50.381: [iter 102 : loss : 0.1247 = 0.0356 + 0.0836 + 0.0055, time: 6.608062]
2023-05-23 20:00:50.532: epoch 102:	0.02644715  	0.19631743  	0.10713492  
2023-05-23 20:00:50.532: Find a better model.
2023-05-23 20:00:57.189: [iter 103 : loss : 0.1244 = 0.0354 + 0.0835 + 0.0055, time: 6.655887]
2023-05-23 20:00:57.343: epoch 103:	0.02649655  	0.19629750  	0.10718405  
2023-05-23 20:01:03.982: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 6.638000]
2023-05-23 20:01:04.126: epoch 104:	0.02639070  	0.19517985  	0.10690341  
2023-05-23 20:01:10.783: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.654613]
2023-05-23 20:01:10.935: epoch 105:	0.02644009  	0.19569534  	0.10721971  
2023-05-23 20:01:17.592: [iter 106 : loss : 0.1236 = 0.0347 + 0.0833 + 0.0056, time: 6.654797]
2023-05-23 20:01:17.744: epoch 106:	0.02655300  	0.19644500  	0.10756146  
2023-05-23 20:01:17.744: Find a better model.
2023-05-23 20:01:24.396: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0057, time: 6.651014]
2023-05-23 20:01:24.549: epoch 107:	0.02658828  	0.19660066  	0.10754263  
2023-05-23 20:01:24.549: Find a better model.
2023-05-23 20:01:30.993: [iter 108 : loss : 0.1225 = 0.0336 + 0.0832 + 0.0057, time: 6.442464]
2023-05-23 20:01:31.148: epoch 108:	0.02657416  	0.19656892  	0.10760897  
2023-05-23 20:01:37.776: [iter 109 : loss : 0.1213 = 0.0324 + 0.0831 + 0.0057, time: 6.626704]
2023-05-23 20:01:37.928: epoch 109:	0.02655300  	0.19610904  	0.10753655  
2023-05-23 20:01:44.568: [iter 110 : loss : 0.1206 = 0.0318 + 0.0831 + 0.0058, time: 6.639717]
2023-05-23 20:01:44.721: epoch 110:	0.02649654  	0.19590265  	0.10753446  
2023-05-23 20:01:51.363: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 6.639869]
2023-05-23 20:01:51.505: epoch 111:	0.02652477  	0.19638896  	0.10765999  
2023-05-23 20:01:58.170: [iter 112 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0058, time: 6.662447]
2023-05-23 20:01:58.325: epoch 112:	0.02660944  	0.19709578  	0.10788505  
2023-05-23 20:01:58.326: Find a better model.
2023-05-23 20:02:04.990: [iter 113 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0059, time: 6.663274]
2023-05-23 20:02:05.143: epoch 113:	0.02663062  	0.19723035  	0.10813689  
2023-05-23 20:02:05.143: Find a better model.
2023-05-23 20:02:11.754: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 6.609691]
2023-05-23 20:02:11.907: epoch 114:	0.02658122  	0.19682686  	0.10804591  
2023-05-23 20:02:18.554: [iter 115 : loss : 0.1191 = 0.0305 + 0.0827 + 0.0059, time: 6.646238]
2023-05-23 20:02:18.707: epoch 115:	0.02656006  	0.19668262  	0.10788937  
2023-05-23 20:02:25.350: [iter 116 : loss : 0.1183 = 0.0296 + 0.0827 + 0.0060, time: 6.640191]
2023-05-23 20:02:25.501: epoch 116:	0.02658123  	0.19686478  	0.10793549  
2023-05-23 20:02:32.177: [iter 117 : loss : 0.1184 = 0.0298 + 0.0827 + 0.0060, time: 6.673222]
2023-05-23 20:02:32.334: epoch 117:	0.02668002  	0.19766250  	0.10817615  
2023-05-23 20:02:32.334: Find a better model.
2023-05-23 20:02:38.946: [iter 118 : loss : 0.1183 = 0.0297 + 0.0826 + 0.0060, time: 6.610848]
2023-05-23 20:02:39.098: epoch 118:	0.02665884  	0.19731481  	0.10806911  
2023-05-23 20:02:45.759: [iter 119 : loss : 0.1174 = 0.0288 + 0.0825 + 0.0061, time: 6.659203]
2023-05-23 20:02:45.912: epoch 119:	0.02668707  	0.19727953  	0.10817645  
2023-05-23 20:02:52.533: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 6.618664]
2023-05-23 20:02:52.685: epoch 120:	0.02670824  	0.19743823  	0.10833859  
2023-05-23 20:02:59.343: [iter 121 : loss : 0.1175 = 0.0289 + 0.0824 + 0.0061, time: 6.657088]
2023-05-23 20:02:59.497: epoch 121:	0.02665884  	0.19708557  	0.10821532  
2023-05-23 20:03:06.135: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.635461]
2023-05-23 20:03:06.281: epoch 122:	0.02668707  	0.19697042  	0.10830878  
2023-05-23 20:03:12.919: [iter 123 : loss : 0.1165 = 0.0279 + 0.0823 + 0.0062, time: 6.635916]
2023-05-23 20:03:13.071: epoch 123:	0.02668002  	0.19692968  	0.10842764  
2023-05-23 20:03:19.554: [iter 124 : loss : 0.1157 = 0.0272 + 0.0823 + 0.0062, time: 6.482564]
2023-05-23 20:03:19.697: epoch 124:	0.02671530  	0.19694725  	0.10860755  
2023-05-23 20:03:26.174: [iter 125 : loss : 0.1149 = 0.0264 + 0.0823 + 0.0062, time: 6.474990]
2023-05-23 20:03:26.329: epoch 125:	0.02674352  	0.19724028  	0.10870171  
2023-05-23 20:03:32.945: [iter 126 : loss : 0.1153 = 0.0269 + 0.0822 + 0.0063, time: 6.614487]
2023-05-23 20:03:33.088: epoch 126:	0.02675059  	0.19766319  	0.10891895  
2023-05-23 20:03:33.089: Find a better model.
2023-05-23 20:03:39.737: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.647085]
2023-05-23 20:03:39.893: epoch 127:	0.02674353  	0.19739142  	0.10889015  
2023-05-23 20:03:46.520: [iter 128 : loss : 0.1155 = 0.0270 + 0.0821 + 0.0063, time: 6.626343]
2023-05-23 20:03:46.673: epoch 128:	0.02673647  	0.19733141  	0.10891551  
2023-05-23 20:03:53.335: [iter 129 : loss : 0.1144 = 0.0260 + 0.0821 + 0.0064, time: 6.660766]
2023-05-23 20:03:53.489: epoch 129:	0.02672941  	0.19743913  	0.10895985  
2023-05-23 20:04:00.123: [iter 130 : loss : 0.1146 = 0.0262 + 0.0820 + 0.0064, time: 6.633149]
2023-05-23 20:04:00.268: epoch 130:	0.02682114  	0.19819628  	0.10914594  
2023-05-23 20:04:00.268: Find a better model.
2023-05-23 20:04:06.954: [iter 131 : loss : 0.1137 = 0.0252 + 0.0820 + 0.0064, time: 6.684721]
2023-05-23 20:04:07.108: epoch 131:	0.02684231  	0.19796750  	0.10912370  
2023-05-23 20:04:13.533: [iter 132 : loss : 0.1139 = 0.0255 + 0.0819 + 0.0065, time: 6.424321]
2023-05-23 20:04:13.686: epoch 132:	0.02688465  	0.19827610  	0.10925872  
2023-05-23 20:04:13.686: Find a better model.
2023-05-23 20:04:20.319: [iter 133 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0065, time: 6.632128]
2023-05-23 20:04:20.470: epoch 133:	0.02689170  	0.19830032  	0.10926478  
2023-05-23 20:04:20.471: Find a better model.
2023-05-23 20:04:27.102: [iter 134 : loss : 0.1134 = 0.0250 + 0.0819 + 0.0065, time: 6.628308]
2023-05-23 20:04:27.260: epoch 134:	0.02680702  	0.19761473  	0.10913905  
2023-05-23 20:04:33.904: [iter 135 : loss : 0.1132 = 0.0248 + 0.0818 + 0.0065, time: 6.642681]
2023-05-23 20:04:34.058: epoch 135:	0.02681408  	0.19745371  	0.10916027  
2023-05-23 20:04:40.526: [iter 136 : loss : 0.1127 = 0.0243 + 0.0818 + 0.0066, time: 6.466600]
2023-05-23 20:04:40.678: epoch 136:	0.02681408  	0.19742630  	0.10903557  
2023-05-23 20:04:47.318: [iter 137 : loss : 0.1124 = 0.0241 + 0.0818 + 0.0066, time: 6.638565]
2023-05-23 20:04:47.471: epoch 137:	0.02684231  	0.19761193  	0.10906953  
2023-05-23 20:04:54.109: [iter 138 : loss : 0.1122 = 0.0238 + 0.0817 + 0.0066, time: 6.637308]
2023-05-23 20:04:54.267: epoch 138:	0.02687759  	0.19765916  	0.10920744  
2023-05-23 20:05:00.721: [iter 139 : loss : 0.1119 = 0.0236 + 0.0817 + 0.0067, time: 6.452384]
2023-05-23 20:05:00.863: epoch 139:	0.02687053  	0.19785458  	0.10917115  
2023-05-23 20:05:07.490: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.625074]
2023-05-23 20:05:07.644: epoch 140:	0.02686348  	0.19800864  	0.10932780  
2023-05-23 20:05:14.281: [iter 141 : loss : 0.1119 = 0.0235 + 0.0816 + 0.0067, time: 6.636450]
2023-05-23 20:05:14.435: epoch 141:	0.02693404  	0.19855353  	0.10956673  
2023-05-23 20:05:14.435: Find a better model.
2023-05-23 20:05:21.097: [iter 142 : loss : 0.1109 = 0.0226 + 0.0816 + 0.0067, time: 6.660068]
2023-05-23 20:05:21.251: epoch 142:	0.02684937  	0.19841415  	0.10969059  
2023-05-23 20:05:27.924: [iter 143 : loss : 0.1110 = 0.0227 + 0.0815 + 0.0068, time: 6.671088]
2023-05-23 20:05:28.076: epoch 143:	0.02690581  	0.19863001  	0.10972361  
2023-05-23 20:05:28.076: Find a better model.
2023-05-23 20:05:34.677: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.599541]
2023-05-23 20:05:34.820: epoch 144:	0.02690581  	0.19870186  	0.10966837  
2023-05-23 20:05:34.820: Find a better model.
2023-05-23 20:05:41.493: [iter 145 : loss : 0.1103 = 0.0221 + 0.0815 + 0.0068, time: 6.672895]
2023-05-23 20:05:41.648: epoch 145:	0.02685641  	0.19821979  	0.10944925  
2023-05-23 20:05:48.292: [iter 146 : loss : 0.1108 = 0.0225 + 0.0814 + 0.0068, time: 6.642182]
2023-05-23 20:05:48.445: epoch 146:	0.02692698  	0.19875494  	0.10966538  
2023-05-23 20:05:48.445: Find a better model.
2023-05-23 20:05:54.891: [iter 147 : loss : 0.1106 = 0.0223 + 0.0814 + 0.0069, time: 6.444762]
2023-05-23 20:05:55.045: epoch 147:	0.02694814  	0.19895861  	0.10966863  
2023-05-23 20:05:55.045: Find a better model.
2023-05-23 20:06:01.498: [iter 148 : loss : 0.1094 = 0.0211 + 0.0814 + 0.0069, time: 6.452726]
2023-05-23 20:06:01.652: epoch 148:	0.02691287  	0.19872272  	0.10961576  
2023-05-23 20:06:08.302: [iter 149 : loss : 0.1098 = 0.0215 + 0.0813 + 0.0069, time: 6.648827]
2023-05-23 20:06:08.453: epoch 149:	0.02691286  	0.19870187  	0.10954656  
2023-05-23 20:06:15.064: [iter 150 : loss : 0.1090 = 0.0207 + 0.0813 + 0.0070, time: 6.609442]
2023-05-23 20:06:15.208: epoch 150:	0.02694815  	0.19876078  	0.10966653  
2023-05-23 20:06:21.884: [iter 151 : loss : 0.1092 = 0.0210 + 0.0813 + 0.0070, time: 6.675322]
2023-05-23 20:06:22.036: epoch 151:	0.02689170  	0.19818804  	0.10969822  
2023-05-23 20:06:28.672: [iter 152 : loss : 0.1086 = 0.0203 + 0.0812 + 0.0070, time: 6.634998]
2023-05-23 20:06:28.815: epoch 152:	0.02687053  	0.19813918  	0.10960150  
2023-05-23 20:06:35.292: [iter 153 : loss : 0.1078 = 0.0196 + 0.0812 + 0.0070, time: 6.474592]
2023-05-23 20:06:35.447: epoch 153:	0.02687759  	0.19838913  	0.10953961  
2023-05-23 20:06:41.895: [iter 154 : loss : 0.1083 = 0.0200 + 0.0812 + 0.0071, time: 6.447315]
2023-05-23 20:06:42.038: epoch 154:	0.02689876  	0.19847068  	0.10971138  
2023-05-23 20:06:48.506: [iter 155 : loss : 0.1091 = 0.0209 + 0.0812 + 0.0071, time: 6.464932]
2023-05-23 20:06:48.660: epoch 155:	0.02689876  	0.19860487  	0.10961466  
2023-05-23 20:06:55.243: [iter 156 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.581578]
2023-05-23 20:06:55.389: epoch 156:	0.02685642  	0.19805728  	0.10945553  
2023-05-23 20:07:01.871: [iter 157 : loss : 0.1080 = 0.0198 + 0.0811 + 0.0071, time: 6.480525]
2023-05-23 20:07:02.015: epoch 157:	0.02686348  	0.19790718  	0.10944707  
2023-05-23 20:07:08.475: [iter 158 : loss : 0.1074 = 0.0192 + 0.0811 + 0.0072, time: 6.457728]
2023-05-23 20:07:08.632: epoch 158:	0.02689876  	0.19813226  	0.10944280  
2023-05-23 20:07:15.267: [iter 159 : loss : 0.1078 = 0.0196 + 0.0810 + 0.0072, time: 6.634429]
2023-05-23 20:07:15.429: epoch 159:	0.02685642  	0.19783713  	0.10933661  
2023-05-23 20:07:21.869: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.438859]
2023-05-23 20:07:22.024: epoch 160:	0.02683525  	0.19733575  	0.10930043  
2023-05-23 20:07:28.701: [iter 161 : loss : 0.1070 = 0.0187 + 0.0810 + 0.0072, time: 6.674112]
2023-05-23 20:07:28.854: epoch 161:	0.02676468  	0.19708057  	0.10913695  
2023-05-23 20:07:35.467: [iter 162 : loss : 0.1063 = 0.0181 + 0.0809 + 0.0073, time: 6.612229]
2023-05-23 20:07:35.622: epoch 162:	0.02678585  	0.19708905  	0.10927796  
2023-05-23 20:07:42.077: [iter 163 : loss : 0.1067 = 0.0185 + 0.0809 + 0.0073, time: 6.453790]
2023-05-23 20:07:42.219: epoch 163:	0.02672941  	0.19658612  	0.10897678  
2023-05-23 20:07:48.677: [iter 164 : loss : 0.1068 = 0.0185 + 0.0809 + 0.0073, time: 6.456410]
2023-05-23 20:07:48.831: epoch 164:	0.02678585  	0.19686300  	0.10910100  
2023-05-23 20:07:55.461: [iter 165 : loss : 0.1063 = 0.0181 + 0.0809 + 0.0073, time: 6.628301]
2023-05-23 20:07:55.616: epoch 165:	0.02673645  	0.19675004  	0.10908605  
2023-05-23 20:08:02.246: [iter 166 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 6.627983]
2023-05-23 20:08:02.399: epoch 166:	0.02675057  	0.19690099  	0.10904147  
2023-05-23 20:08:08.857: [iter 167 : loss : 0.1065 = 0.0183 + 0.0808 + 0.0074, time: 6.455698]
2023-05-23 20:08:09.000: epoch 167:	0.02670823  	0.19620065  	0.10915717  
2023-05-23 20:08:15.447: [iter 168 : loss : 0.1060 = 0.0178 + 0.0808 + 0.0074, time: 6.446696]
2023-05-23 20:08:15.603: epoch 168:	0.02678585  	0.19688244  	0.10901172  
2023-05-23 20:08:22.063: [iter 169 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 6.457408]
2023-05-23 20:08:22.215: epoch 169:	0.02677174  	0.19665568  	0.10898970  
2023-05-23 20:08:28.817: [iter 170 : loss : 0.1058 = 0.0176 + 0.0807 + 0.0075, time: 6.599492]
2023-05-23 20:08:28.958: epoch 170:	0.02669412  	0.19606255  	0.10877904  
2023-05-23 20:08:35.440: [iter 171 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0075, time: 6.479919]
2023-05-23 20:08:35.595: epoch 171:	0.02671529  	0.19594882  	0.10887702  
2023-05-23 20:08:42.041: [iter 172 : loss : 0.1051 = 0.0169 + 0.0807 + 0.0075, time: 6.445650]
2023-05-23 20:08:42.200: epoch 172:	0.02668706  	0.19586635  	0.10889713  
2023-05-23 20:08:42.201: Early stopping is trigger at epoch: 172
2023-05-23 20:08:42.201: best_result@epoch 147:

2023-05-23 20:08:42.201: 		0.0269      	0.1990      	0.1097      
2023-05-23 20:13:10.370: my pid: 3900
2023-05-23 20:13:10.370: model: model.general_recommender.SGL
2023-05-23 20:13:10.370: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-23 20:13:10.371: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 20:13:14.266: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 20:13:22.021: [iter 1 : loss : 0.7706 = 0.6930 + 0.0776 + 0.0000, time: 7.754973]
2023-05-23 20:13:22.174: epoch 1:	0.00183461  	0.01236751  	0.00641957  
2023-05-23 20:13:22.174: Find a better model.
2023-05-23 20:13:29.801: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.625330]
2023-05-23 20:13:29.976: epoch 2:	0.00339401  	0.02335494  	0.01195696  
2023-05-23 20:13:29.976: Find a better model.
2023-05-23 20:13:37.549: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.572041]
2023-05-23 20:13:37.724: epoch 3:	0.00569429  	0.03921259  	0.01960516  
2023-05-23 20:13:37.724: Find a better model.
2023-05-23 20:13:45.155: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.429946]
2023-05-23 20:13:45.310: epoch 4:	0.00808630  	0.05648810  	0.02844983  
2023-05-23 20:13:45.310: Find a better model.
2023-05-23 20:13:52.584: [iter 5 : loss : 0.7685 = 0.6912 + 0.0773 + 0.0000, time: 7.272779]
2023-05-23 20:13:52.726: epoch 5:	0.01091589  	0.07726161  	0.03741086  
2023-05-23 20:13:52.727: Find a better model.
2023-05-23 20:13:59.948: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.220254]
2023-05-23 20:14:00.105: epoch 6:	0.01384432  	0.09877191  	0.04794341  
2023-05-23 20:14:00.105: Find a better model.
2023-05-23 20:14:07.153: [iter 7 : loss : 0.7604 = 0.6822 + 0.0781 + 0.0000, time: 7.046449]
2023-05-23 20:14:07.310: epoch 7:	0.01661748  	0.12048244  	0.05941228  
2023-05-23 20:14:07.310: Find a better model.
2023-05-23 20:14:14.331: [iter 8 : loss : 0.7460 = 0.6664 + 0.0795 + 0.0001, time: 7.019920]
2023-05-23 20:14:14.475: epoch 8:	0.01818401  	0.13326196  	0.06658761  
2023-05-23 20:14:14.475: Find a better model.
2023-05-23 20:14:21.543: [iter 9 : loss : 0.7139 = 0.6311 + 0.0827 + 0.0001, time: 7.066270]
2023-05-23 20:14:21.700: epoch 9:	0.01888966  	0.13894115  	0.06959072  
2023-05-23 20:14:21.700: Find a better model.
2023-05-23 20:14:28.721: [iter 10 : loss : 0.6577 = 0.5699 + 0.0876 + 0.0002, time: 7.020696]
2023-05-23 20:14:28.878: epoch 10:	0.01872735  	0.13819201  	0.06943880  
2023-05-23 20:14:35.739: [iter 11 : loss : 0.5837 = 0.4907 + 0.0926 + 0.0004, time: 6.858319]
2023-05-23 20:14:35.897: epoch 11:	0.01871325  	0.13850106  	0.06945288  
2023-05-23 20:14:42.737: [iter 12 : loss : 0.5123 = 0.4155 + 0.0963 + 0.0005, time: 6.837971]
2023-05-23 20:14:42.880: epoch 12:	0.01860740  	0.13764323  	0.06942309  
2023-05-23 20:14:49.755: [iter 13 : loss : 0.4582 = 0.3590 + 0.0985 + 0.0007, time: 6.870974]
2023-05-23 20:14:49.904: epoch 13:	0.01866386  	0.13818514  	0.06990115  
2023-05-23 20:14:56.739: [iter 14 : loss : 0.4170 = 0.3166 + 0.0996 + 0.0008, time: 6.833393]
2023-05-23 20:14:56.894: epoch 14:	0.01881204  	0.13954856  	0.07087963  
2023-05-23 20:14:56.894: Find a better model.
2023-05-23 20:15:03.746: [iter 15 : loss : 0.3882 = 0.2872 + 0.1001 + 0.0010, time: 6.848688]
2023-05-23 20:15:03.903: epoch 15:	0.01905196  	0.14149752  	0.07188386  
2023-05-23 20:15:03.903: Find a better model.
2023-05-23 20:15:10.543: [iter 16 : loss : 0.3646 = 0.2633 + 0.1002 + 0.0011, time: 6.638116]
2023-05-23 20:15:10.698: epoch 16:	0.01926366  	0.14257549  	0.07258890  
2023-05-23 20:15:10.699: Find a better model.
2023-05-23 20:15:17.493: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 6.792697]
2023-05-23 20:15:17.647: epoch 17:	0.01952475  	0.14435115  	0.07346696  
2023-05-23 20:15:17.647: Find a better model.
2023-05-23 20:15:24.332: [iter 18 : loss : 0.3315 = 0.2302 + 0.1000 + 0.0013, time: 6.683390]
2023-05-23 20:15:24.475: epoch 18:	0.01970823  	0.14547800  	0.07412752  
2023-05-23 20:15:24.475: Find a better model.
2023-05-23 20:15:31.111: [iter 19 : loss : 0.3169 = 0.2158 + 0.0997 + 0.0014, time: 6.634691]
2023-05-23 20:15:31.252: epoch 19:	0.01989876  	0.14681418  	0.07483394  
2023-05-23 20:15:31.252: Find a better model.
2023-05-23 20:15:38.087: [iter 20 : loss : 0.3069 = 0.2061 + 0.0993 + 0.0015, time: 6.831979]
2023-05-23 20:15:38.243: epoch 20:	0.01996226  	0.14709879  	0.07529653  
2023-05-23 20:15:38.243: Find a better model.
2023-05-23 20:15:45.093: [iter 21 : loss : 0.2969 = 0.1964 + 0.0989 + 0.0016, time: 6.849040]
2023-05-23 20:15:45.234: epoch 21:	0.02027981  	0.14938436  	0.07626184  
2023-05-23 20:15:45.234: Find a better model.
2023-05-23 20:15:51.930: [iter 22 : loss : 0.2886 = 0.1884 + 0.0985 + 0.0017, time: 6.695231]
2023-05-23 20:15:52.085: epoch 22:	0.02041388  	0.15025993  	0.07680344  
2023-05-23 20:15:52.085: Find a better model.
2023-05-23 20:15:58.899: [iter 23 : loss : 0.2802 = 0.1803 + 0.0981 + 0.0018, time: 6.812182]
2023-05-23 20:15:59.053: epoch 23:	0.02053383  	0.15106921  	0.07751744  
2023-05-23 20:15:59.053: Find a better model.
2023-05-23 20:16:05.882: [iter 24 : loss : 0.2736 = 0.1740 + 0.0977 + 0.0018, time: 6.827903]
2023-05-23 20:16:06.038: epoch 24:	0.02078787  	0.15308173  	0.07848143  
2023-05-23 20:16:06.039: Find a better model.
2023-05-23 20:16:12.700: [iter 25 : loss : 0.2667 = 0.1675 + 0.0973 + 0.0019, time: 6.659629]
2023-05-23 20:16:12.841: epoch 25:	0.02087961  	0.15337154  	0.07890216  
2023-05-23 20:16:12.841: Find a better model.
2023-05-23 20:16:19.537: [iter 26 : loss : 0.2630 = 0.1641 + 0.0969 + 0.0020, time: 6.693778]
2023-05-23 20:16:19.690: epoch 26:	0.02112659  	0.15508309  	0.07974935  
2023-05-23 20:16:19.690: Find a better model.
2023-05-23 20:16:26.340: [iter 27 : loss : 0.2551 = 0.1566 + 0.0965 + 0.0020, time: 6.647190]
2023-05-23 20:16:26.480: epoch 27:	0.02133829  	0.15645410  	0.08044992  
2023-05-23 20:16:26.480: Find a better model.
2023-05-23 20:16:33.111: [iter 28 : loss : 0.2503 = 0.1521 + 0.0961 + 0.0021, time: 6.627896]
2023-05-23 20:16:33.253: epoch 28:	0.02147236  	0.15735768  	0.08131745  
2023-05-23 20:16:33.253: Find a better model.
2023-05-23 20:16:39.880: [iter 29 : loss : 0.2458 = 0.1480 + 0.0956 + 0.0022, time: 6.625871]
2023-05-23 20:16:40.023: epoch 29:	0.02167699  	0.15908341  	0.08226252  
2023-05-23 20:16:40.023: Find a better model.
2023-05-23 20:16:46.691: [iter 30 : loss : 0.2392 = 0.1417 + 0.0953 + 0.0022, time: 6.665928]
2023-05-23 20:16:46.832: epoch 30:	0.02178284  	0.16044876  	0.08293393  
2023-05-23 20:16:46.834: Find a better model.
2023-05-23 20:16:53.501: [iter 31 : loss : 0.2356 = 0.1384 + 0.0949 + 0.0023, time: 6.666148]
2023-05-23 20:16:53.653: epoch 31:	0.02186751  	0.16057427  	0.08329571  
2023-05-23 20:16:53.653: Find a better model.
2023-05-23 20:17:00.298: [iter 32 : loss : 0.2300 = 0.1331 + 0.0946 + 0.0024, time: 6.642401]
2023-05-23 20:17:00.440: epoch 32:	0.02212860  	0.16257350  	0.08435014  
2023-05-23 20:17:00.440: Find a better model.
2023-05-23 20:17:07.090: [iter 33 : loss : 0.2273 = 0.1307 + 0.0942 + 0.0024, time: 6.647386]
2023-05-23 20:17:07.244: epoch 33:	0.02219917  	0.16291153  	0.08473682  
2023-05-23 20:17:07.245: Find a better model.
2023-05-23 20:17:13.880: [iter 34 : loss : 0.2234 = 0.1270 + 0.0938 + 0.0025, time: 6.634024]
2023-05-23 20:17:14.035: epoch 34:	0.02229089  	0.16361551  	0.08533307  
2023-05-23 20:17:14.036: Find a better model.
2023-05-23 20:17:20.849: [iter 35 : loss : 0.2200 = 0.1239 + 0.0936 + 0.0025, time: 6.811636]
2023-05-23 20:17:21.007: epoch 35:	0.02251670  	0.16539687  	0.08611237  
2023-05-23 20:17:21.007: Find a better model.
2023-05-23 20:17:27.682: [iter 36 : loss : 0.2165 = 0.1206 + 0.0932 + 0.0026, time: 6.673649]
2023-05-23 20:17:27.837: epoch 36:	0.02262255  	0.16630647  	0.08676223  
2023-05-23 20:17:27.837: Find a better model.
2023-05-23 20:17:34.479: [iter 37 : loss : 0.2125 = 0.1170 + 0.0929 + 0.0027, time: 6.641842]
2023-05-23 20:17:34.633: epoch 37:	0.02282014  	0.16797574  	0.08749385  
2023-05-23 20:17:34.633: Find a better model.
2023-05-23 20:17:41.462: [iter 38 : loss : 0.2110 = 0.1157 + 0.0926 + 0.0027, time: 6.827024]
2023-05-23 20:17:41.604: epoch 38:	0.02292599  	0.16889168  	0.08832098  
2023-05-23 20:17:41.604: Find a better model.
2023-05-23 20:17:48.297: [iter 39 : loss : 0.2066 = 0.1115 + 0.0923 + 0.0028, time: 6.691457]
2023-05-23 20:17:48.450: epoch 39:	0.02314474  	0.17035054  	0.08942634  
2023-05-23 20:17:48.450: Find a better model.
2023-05-23 20:17:55.302: [iter 40 : loss : 0.2034 = 0.1085 + 0.0920 + 0.0028, time: 6.851210]
2023-05-23 20:17:55.453: epoch 40:	0.02321531  	0.17081171  	0.08966282  
2023-05-23 20:17:55.453: Find a better model.
2023-05-23 20:18:02.297: [iter 41 : loss : 0.2017 = 0.1071 + 0.0917 + 0.0029, time: 6.842591]
2023-05-23 20:18:02.449: epoch 41:	0.02325059  	0.17118654  	0.09005117  
2023-05-23 20:18:02.449: Find a better model.
2023-05-23 20:18:09.259: [iter 42 : loss : 0.1995 = 0.1051 + 0.0915 + 0.0029, time: 6.808216]
2023-05-23 20:18:09.413: epoch 42:	0.02330704  	0.17206314  	0.09066550  
2023-05-23 20:18:09.413: Find a better model.
2023-05-23 20:18:16.248: [iter 43 : loss : 0.1955 = 0.1014 + 0.0912 + 0.0030, time: 6.833457]
2023-05-23 20:18:16.391: epoch 43:	0.02342700  	0.17316291  	0.09097954  
2023-05-23 20:18:16.391: Find a better model.
2023-05-23 20:18:23.086: [iter 44 : loss : 0.1921 = 0.0982 + 0.0909 + 0.0030, time: 6.694162]
2023-05-23 20:18:23.226: epoch 44:	0.02349051  	0.17356110  	0.09148567  
2023-05-23 20:18:23.226: Find a better model.
2023-05-23 20:18:30.041: [iter 45 : loss : 0.1900 = 0.0962 + 0.0907 + 0.0031, time: 6.813948]
2023-05-23 20:18:30.181: epoch 45:	0.02365281  	0.17470303  	0.09201422  
2023-05-23 20:18:30.181: Find a better model.
2023-05-23 20:18:36.857: [iter 46 : loss : 0.1876 = 0.0941 + 0.0904 + 0.0031, time: 6.673916]
2023-05-23 20:18:37.012: epoch 46:	0.02369515  	0.17490071  	0.09253069  
2023-05-23 20:18:37.012: Find a better model.
2023-05-23 20:18:43.825: [iter 47 : loss : 0.1868 = 0.0934 + 0.0902 + 0.0032, time: 6.812105]
2023-05-23 20:18:43.978: epoch 47:	0.02372337  	0.17514330  	0.09286022  
2023-05-23 20:18:43.978: Find a better model.
2023-05-23 20:18:50.653: [iter 48 : loss : 0.1830 = 0.0898 + 0.0899 + 0.0032, time: 6.674379]
2023-05-23 20:18:50.807: epoch 48:	0.02377982  	0.17574771  	0.09340488  
2023-05-23 20:18:50.808: Find a better model.
2023-05-23 20:18:57.456: [iter 49 : loss : 0.1799 = 0.0868 + 0.0898 + 0.0033, time: 6.646372]
2023-05-23 20:18:57.608: epoch 49:	0.02387861  	0.17628348  	0.09388212  
2023-05-23 20:18:57.608: Find a better model.
2023-05-23 20:19:04.252: [iter 50 : loss : 0.1791 = 0.0862 + 0.0895 + 0.0033, time: 6.642859]
2023-05-23 20:19:04.405: epoch 50:	0.02397034  	0.17681864  	0.09435506  
2023-05-23 20:19:04.405: Find a better model.
2023-05-23 20:19:11.204: [iter 51 : loss : 0.1761 = 0.0833 + 0.0893 + 0.0034, time: 6.798157]
2023-05-23 20:19:11.346: epoch 51:	0.02406913  	0.17761993  	0.09447741  
2023-05-23 20:19:11.346: Find a better model.
2023-05-23 20:19:18.072: [iter 52 : loss : 0.1760 = 0.0835 + 0.0891 + 0.0034, time: 6.724663]
2023-05-23 20:19:18.225: epoch 52:	0.02414674  	0.17800161  	0.09501617  
2023-05-23 20:19:18.225: Find a better model.
2023-05-23 20:19:25.046: [iter 53 : loss : 0.1739 = 0.0816 + 0.0889 + 0.0035, time: 6.819322]
2023-05-23 20:19:25.202: epoch 53:	0.02422437  	0.17870639  	0.09540950  
2023-05-23 20:19:25.202: Find a better model.
2023-05-23 20:19:32.057: [iter 54 : loss : 0.1719 = 0.0797 + 0.0887 + 0.0035, time: 6.853790]
2023-05-23 20:19:32.214: epoch 54:	0.02433727  	0.17925531  	0.09584527  
2023-05-23 20:19:32.214: Find a better model.
2023-05-23 20:19:39.028: [iter 55 : loss : 0.1700 = 0.0779 + 0.0885 + 0.0036, time: 6.813304]
2023-05-23 20:19:39.185: epoch 55:	0.02438666  	0.17950936  	0.09599542  
2023-05-23 20:19:39.185: Find a better model.
2023-05-23 20:19:46.036: [iter 56 : loss : 0.1684 = 0.0765 + 0.0883 + 0.0036, time: 6.850140]
2023-05-23 20:19:46.192: epoch 56:	0.02445018  	0.18027648  	0.09656397  
2023-05-23 20:19:46.192: Find a better model.
2023-05-23 20:19:53.048: [iter 57 : loss : 0.1666 = 0.0747 + 0.0882 + 0.0037, time: 6.855102]
2023-05-23 20:19:53.203: epoch 57:	0.02452074  	0.18120766  	0.09705110  
2023-05-23 20:19:53.203: Find a better model.
2023-05-23 20:20:00.014: [iter 58 : loss : 0.1646 = 0.0729 + 0.0880 + 0.0037, time: 6.810059]
2023-05-23 20:20:00.160: epoch 58:	0.02460541  	0.18177348  	0.09749097  
2023-05-23 20:20:00.160: Find a better model.
2023-05-23 20:20:06.984: [iter 59 : loss : 0.1636 = 0.0720 + 0.0878 + 0.0038, time: 6.823339]
2023-05-23 20:20:07.127: epoch 59:	0.02471832  	0.18256748  	0.09778157  
2023-05-23 20:20:07.127: Find a better model.
2023-05-23 20:20:13.815: [iter 60 : loss : 0.1621 = 0.0706 + 0.0877 + 0.0038, time: 6.685196]
2023-05-23 20:20:13.968: epoch 60:	0.02480299  	0.18318272  	0.09820500  
2023-05-23 20:20:13.968: Find a better model.
2023-05-23 20:20:20.805: [iter 61 : loss : 0.1608 = 0.0695 + 0.0875 + 0.0039, time: 6.834931]
2023-05-23 20:20:20.960: epoch 61:	0.02488767  	0.18389155  	0.09867558  
2023-05-23 20:20:20.960: Find a better model.
2023-05-23 20:20:27.793: [iter 62 : loss : 0.1591 = 0.0679 + 0.0873 + 0.0039, time: 6.831436]
2023-05-23 20:20:27.947: epoch 62:	0.02486650  	0.18365544  	0.09873232  
2023-05-23 20:20:34.806: [iter 63 : loss : 0.1580 = 0.0668 + 0.0872 + 0.0039, time: 6.857848]
2023-05-23 20:20:34.959: epoch 63:	0.02503585  	0.18452638  	0.09914229  
2023-05-23 20:20:34.960: Find a better model.
2023-05-23 20:20:41.820: [iter 64 : loss : 0.1569 = 0.0659 + 0.0870 + 0.0040, time: 6.859548]
2023-05-23 20:20:41.976: epoch 64:	0.02508524  	0.18505508  	0.09964429  
2023-05-23 20:20:41.976: Find a better model.
2023-05-23 20:20:48.635: [iter 65 : loss : 0.1559 = 0.0650 + 0.0868 + 0.0040, time: 6.657522]
2023-05-23 20:20:48.791: epoch 65:	0.02519815  	0.18587269  	0.10004805  
2023-05-23 20:20:48.792: Find a better model.
2023-05-23 20:20:55.604: [iter 66 : loss : 0.1542 = 0.0634 + 0.0867 + 0.0041, time: 6.811249]
2023-05-23 20:20:55.756: epoch 66:	0.02514876  	0.18601719  	0.10022576  
2023-05-23 20:20:55.756: Find a better model.
2023-05-23 20:21:02.622: [iter 67 : loss : 0.1526 = 0.0619 + 0.0866 + 0.0041, time: 6.865387]
2023-05-23 20:21:02.775: epoch 67:	0.02529695  	0.18734446  	0.10088319  
2023-05-23 20:21:02.775: Find a better model.
2023-05-23 20:21:09.590: [iter 68 : loss : 0.1524 = 0.0618 + 0.0864 + 0.0042, time: 6.813192]
2023-05-23 20:21:09.745: epoch 68:	0.02535340  	0.18750137  	0.10108730  
2023-05-23 20:21:09.745: Find a better model.
2023-05-23 20:21:16.597: [iter 69 : loss : 0.1504 = 0.0599 + 0.0863 + 0.0042, time: 6.850664]
2023-05-23 20:21:16.739: epoch 69:	0.02541691  	0.18815079  	0.10144237  
2023-05-23 20:21:16.739: Find a better model.
2023-05-23 20:21:23.608: [iter 70 : loss : 0.1489 = 0.0585 + 0.0862 + 0.0042, time: 6.865687]
2023-05-23 20:21:23.748: epoch 70:	0.02545924  	0.18849093  	0.10177673  
2023-05-23 20:21:23.748: Find a better model.
2023-05-23 20:21:30.585: [iter 71 : loss : 0.1474 = 0.0570 + 0.0861 + 0.0043, time: 6.835542]
2023-05-23 20:21:30.738: epoch 71:	0.02548041  	0.18853112  	0.10191826  
2023-05-23 20:21:30.738: Find a better model.
2023-05-23 20:21:37.587: [iter 72 : loss : 0.1474 = 0.0572 + 0.0859 + 0.0043, time: 6.847931]
2023-05-23 20:21:37.739: epoch 72:	0.02555098  	0.18891686  	0.10209201  
2023-05-23 20:21:37.740: Find a better model.
2023-05-23 20:21:44.601: [iter 73 : loss : 0.1460 = 0.0558 + 0.0858 + 0.0044, time: 6.860070]
2023-05-23 20:21:44.754: epoch 73:	0.02556509  	0.18922070  	0.10221530  
2023-05-23 20:21:44.754: Find a better model.
2023-05-23 20:21:51.583: [iter 74 : loss : 0.1444 = 0.0543 + 0.0857 + 0.0044, time: 6.828141]
2023-05-23 20:21:51.735: epoch 74:	0.02559332  	0.18956019  	0.10267995  
2023-05-23 20:21:51.735: Find a better model.
2023-05-23 20:21:58.566: [iter 75 : loss : 0.1440 = 0.0540 + 0.0856 + 0.0045, time: 6.829221]
2023-05-23 20:21:58.708: epoch 75:	0.02566388  	0.18962374  	0.10293914  
2023-05-23 20:21:58.708: Find a better model.
2023-05-23 20:22:05.581: [iter 76 : loss : 0.1431 = 0.0531 + 0.0854 + 0.0045, time: 6.871244]
2023-05-23 20:22:05.735: epoch 76:	0.02572034  	0.18996643  	0.10322244  
2023-05-23 20:22:05.735: Find a better model.
2023-05-23 20:22:12.575: [iter 77 : loss : 0.1421 = 0.0522 + 0.0853 + 0.0045, time: 6.838870]
2023-05-23 20:22:12.717: epoch 77:	0.02573445  	0.19027075  	0.10355686  
2023-05-23 20:22:12.717: Find a better model.
2023-05-23 20:22:19.406: [iter 78 : loss : 0.1412 = 0.0514 + 0.0852 + 0.0046, time: 6.687317]
2023-05-23 20:22:19.558: epoch 78:	0.02579090  	0.19069675  	0.10374455  
2023-05-23 20:22:19.558: Find a better model.
2023-05-23 20:22:26.385: [iter 79 : loss : 0.1401 = 0.0503 + 0.0851 + 0.0046, time: 6.825826]
2023-05-23 20:22:26.538: epoch 79:	0.02581913  	0.19073546  	0.10401697  
2023-05-23 20:22:26.538: Find a better model.
2023-05-23 20:22:33.202: [iter 80 : loss : 0.1393 = 0.0496 + 0.0850 + 0.0047, time: 6.661533]
2023-05-23 20:22:33.359: epoch 80:	0.02587558  	0.19123527  	0.10416666  
2023-05-23 20:22:33.359: Find a better model.
2023-05-23 20:22:39.981: [iter 81 : loss : 0.1390 = 0.0494 + 0.0849 + 0.0047, time: 6.620045]
2023-05-23 20:22:40.134: epoch 81:	0.02589675  	0.19136623  	0.10422117  
2023-05-23 20:22:40.135: Find a better model.
2023-05-23 20:22:46.761: [iter 82 : loss : 0.1378 = 0.0482 + 0.0848 + 0.0047, time: 6.625087]
2023-05-23 20:22:46.915: epoch 82:	0.02593203  	0.19155334  	0.10431480  
2023-05-23 20:22:46.916: Find a better model.
2023-05-23 20:22:53.589: [iter 83 : loss : 0.1368 = 0.0473 + 0.0847 + 0.0048, time: 6.672872]
2023-05-23 20:22:53.731: epoch 83:	0.02596731  	0.19199136  	0.10464371  
2023-05-23 20:22:53.731: Find a better model.
2023-05-23 20:23:00.365: [iter 84 : loss : 0.1367 = 0.0473 + 0.0846 + 0.0048, time: 6.631865]
2023-05-23 20:23:00.506: epoch 84:	0.02599554  	0.19242968  	0.10474219  
2023-05-23 20:23:00.507: Find a better model.
2023-05-23 20:23:07.332: [iter 85 : loss : 0.1358 = 0.0464 + 0.0845 + 0.0049, time: 6.824091]
2023-05-23 20:23:07.485: epoch 85:	0.02601671  	0.19256759  	0.10505594  
2023-05-23 20:23:07.485: Find a better model.
2023-05-23 20:23:14.151: [iter 86 : loss : 0.1356 = 0.0463 + 0.0844 + 0.0049, time: 6.664916]
2023-05-23 20:23:14.292: epoch 86:	0.02607316  	0.19276667  	0.10533709  
2023-05-23 20:23:14.293: Find a better model.
2023-05-23 20:23:21.139: [iter 87 : loss : 0.1329 = 0.0436 + 0.0843 + 0.0049, time: 6.845026]
2023-05-23 20:23:21.294: epoch 87:	0.02611550  	0.19322906  	0.10558621  
2023-05-23 20:23:21.294: Find a better model.
2023-05-23 20:23:28.118: [iter 88 : loss : 0.1323 = 0.0431 + 0.0842 + 0.0050, time: 6.822696]
2023-05-23 20:23:28.259: epoch 88:	0.02612256  	0.19319054  	0.10564854  
2023-05-23 20:23:34.951: [iter 89 : loss : 0.1320 = 0.0429 + 0.0841 + 0.0050, time: 6.690199]
2023-05-23 20:23:35.104: epoch 89:	0.02611550  	0.19314213  	0.10580886  
2023-05-23 20:23:41.922: [iter 90 : loss : 0.1326 = 0.0435 + 0.0841 + 0.0051, time: 6.816832]
2023-05-23 20:23:42.077: epoch 90:	0.02617195  	0.19325066  	0.10591676  
2023-05-23 20:23:42.077: Find a better model.
2023-05-23 20:23:48.770: [iter 91 : loss : 0.1314 = 0.0423 + 0.0840 + 0.0051, time: 6.690851]
2023-05-23 20:23:48.923: epoch 91:	0.02614372  	0.19319981  	0.10589855  
2023-05-23 20:23:55.762: [iter 92 : loss : 0.1304 = 0.0414 + 0.0839 + 0.0051, time: 6.837739]
2023-05-23 20:23:55.902: epoch 92:	0.02618607  	0.19330914  	0.10590240  
2023-05-23 20:23:55.902: Find a better model.
2023-05-23 20:24:02.579: [iter 93 : loss : 0.1310 = 0.0420 + 0.0838 + 0.0052, time: 6.675170]
2023-05-23 20:24:02.734: epoch 93:	0.02618607  	0.19313544  	0.10606378  
2023-05-23 20:24:09.523: [iter 94 : loss : 0.1287 = 0.0397 + 0.0837 + 0.0052, time: 6.788462]
2023-05-23 20:24:09.677: epoch 94:	0.02629897  	0.19428515  	0.10654860  
2023-05-23 20:24:09.677: Find a better model.
2023-05-23 20:24:16.500: [iter 95 : loss : 0.1280 = 0.0391 + 0.0837 + 0.0052, time: 6.822133]
2023-05-23 20:24:16.656: epoch 95:	0.02635543  	0.19455573  	0.10666927  
2023-05-23 20:24:16.656: Find a better model.
2023-05-23 20:24:23.354: [iter 96 : loss : 0.1281 = 0.0392 + 0.0836 + 0.0053, time: 6.696314]
2023-05-23 20:24:23.513: epoch 96:	0.02639071  	0.19521853  	0.10681961  
2023-05-23 20:24:23.513: Find a better model.
2023-05-23 20:24:30.328: [iter 97 : loss : 0.1264 = 0.0376 + 0.0835 + 0.0053, time: 6.814348]
2023-05-23 20:24:30.486: epoch 97:	0.02642599  	0.19522639  	0.10699895  
2023-05-23 20:24:30.486: Find a better model.
2023-05-23 20:24:37.312: [iter 98 : loss : 0.1272 = 0.0384 + 0.0834 + 0.0053, time: 6.825183]
2023-05-23 20:24:37.470: epoch 98:	0.02645421  	0.19541481  	0.10714524  
2023-05-23 20:24:37.470: Find a better model.
2023-05-23 20:24:44.131: [iter 99 : loss : 0.1262 = 0.0374 + 0.0834 + 0.0054, time: 6.658741]
2023-05-23 20:24:44.273: epoch 99:	0.02641188  	0.19525418  	0.10717371  
2023-05-23 20:24:51.099: [iter 100 : loss : 0.1257 = 0.0370 + 0.0833 + 0.0054, time: 6.825340]
2023-05-23 20:24:51.242: epoch 100:	0.02648244  	0.19553041  	0.10718539  
2023-05-23 20:24:51.242: Find a better model.
2023-05-23 20:24:57.928: [iter 101 : loss : 0.1252 = 0.0365 + 0.0832 + 0.0055, time: 6.683974]
2023-05-23 20:24:58.071: epoch 101:	0.02651772  	0.19570085  	0.10728646  
2023-05-23 20:24:58.071: Find a better model.
2023-05-23 20:25:04.915: [iter 102 : loss : 0.1243 = 0.0357 + 0.0832 + 0.0055, time: 6.842923]
2023-05-23 20:25:05.067: epoch 102:	0.02651772  	0.19596979  	0.10733478  
2023-05-23 20:25:05.067: Find a better model.
2023-05-23 20:25:11.910: [iter 103 : loss : 0.1240 = 0.0354 + 0.0831 + 0.0055, time: 6.842657]
2023-05-23 20:25:12.061: epoch 103:	0.02656006  	0.19647545  	0.10759817  
2023-05-23 20:25:12.062: Find a better model.
2023-05-23 20:25:18.913: [iter 104 : loss : 0.1244 = 0.0358 + 0.0830 + 0.0056, time: 6.849995]
2023-05-23 20:25:19.069: epoch 104:	0.02664473  	0.19676012  	0.10769300  
2023-05-23 20:25:19.069: Find a better model.
2023-05-23 20:25:25.733: [iter 105 : loss : 0.1236 = 0.0351 + 0.0829 + 0.0056, time: 6.663225]
2023-05-23 20:25:25.887: epoch 105:	0.02653183  	0.19594124  	0.10771105  
2023-05-23 20:25:32.710: [iter 106 : loss : 0.1232 = 0.0347 + 0.0829 + 0.0056, time: 6.822057]
2023-05-23 20:25:32.863: epoch 106:	0.02657416  	0.19614139  	0.10781108  
2023-05-23 20:25:39.683: [iter 107 : loss : 0.1224 = 0.0339 + 0.0828 + 0.0057, time: 6.818010]
2023-05-23 20:25:39.836: epoch 107:	0.02658828  	0.19620708  	0.10779146  
2023-05-23 20:25:46.491: [iter 108 : loss : 0.1221 = 0.0336 + 0.0828 + 0.0057, time: 6.654686]
2023-05-23 20:25:46.648: epoch 108:	0.02653183  	0.19614425  	0.10784166  
2023-05-23 20:25:53.332: [iter 109 : loss : 0.1209 = 0.0324 + 0.0827 + 0.0057, time: 6.680685]
2023-05-23 20:25:53.484: epoch 109:	0.02653183  	0.19609949  	0.10789390  
2023-05-23 20:26:00.103: [iter 110 : loss : 0.1202 = 0.0318 + 0.0827 + 0.0058, time: 6.618281]
2023-05-23 20:26:00.260: epoch 110:	0.02658123  	0.19632484  	0.10794420  
2023-05-23 20:26:07.095: [iter 111 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 6.834100]
2023-05-23 20:26:07.251: epoch 111:	0.02651066  	0.19593634  	0.10801624  
2023-05-23 20:26:13.896: [iter 112 : loss : 0.1201 = 0.0318 + 0.0825 + 0.0058, time: 6.644484]
2023-05-23 20:26:14.052: epoch 112:	0.02654594  	0.19586037  	0.10802300  
2023-05-23 20:26:20.883: [iter 113 : loss : 0.1200 = 0.0317 + 0.0825 + 0.0059, time: 6.829907]
2023-05-23 20:26:21.038: epoch 113:	0.02658829  	0.19631526  	0.10819907  
2023-05-23 20:26:27.885: [iter 114 : loss : 0.1192 = 0.0309 + 0.0824 + 0.0059, time: 6.844401]
2023-05-23 20:26:28.040: epoch 114:	0.02661651  	0.19680947  	0.10817680  
2023-05-23 20:26:28.041: Find a better model.
2023-05-23 20:26:34.881: [iter 115 : loss : 0.1187 = 0.0304 + 0.0824 + 0.0059, time: 6.839032]
2023-05-23 20:26:35.036: epoch 115:	0.02665178  	0.19661292  	0.10820226  
2023-05-23 20:26:41.885: [iter 116 : loss : 0.1179 = 0.0296 + 0.0823 + 0.0060, time: 6.847770]
2023-05-23 20:26:42.042: epoch 116:	0.02666590  	0.19690497  	0.10834768  
2023-05-23 20:26:42.042: Find a better model.
2023-05-23 20:26:48.897: [iter 117 : loss : 0.1179 = 0.0296 + 0.0823 + 0.0060, time: 6.853673]
2023-05-23 20:26:49.050: epoch 117:	0.02666590  	0.19653687  	0.10831585  
2023-05-23 20:26:55.891: [iter 118 : loss : 0.1179 = 0.0296 + 0.0822 + 0.0060, time: 6.839558]
2023-05-23 20:26:56.045: epoch 118:	0.02665178  	0.19628444  	0.10820936  
2023-05-23 20:27:02.886: [iter 119 : loss : 0.1170 = 0.0288 + 0.0821 + 0.0061, time: 6.839816]
2023-05-23 20:27:03.041: epoch 119:	0.02663767  	0.19630784  	0.10827519  
2023-05-23 20:27:09.866: [iter 120 : loss : 0.1172 = 0.0290 + 0.0821 + 0.0061, time: 6.824247]
2023-05-23 20:27:10.021: epoch 120:	0.02654594  	0.19574594  	0.10810343  
2023-05-23 20:27:16.859: [iter 121 : loss : 0.1170 = 0.0288 + 0.0820 + 0.0061, time: 6.836237]
2023-05-23 20:27:17.013: epoch 121:	0.02653889  	0.19567746  	0.10808822  
2023-05-23 20:27:23.697: [iter 122 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 6.682241]
2023-05-23 20:27:23.854: epoch 122:	0.02652477  	0.19546537  	0.10817829  
2023-05-23 20:27:30.669: [iter 123 : loss : 0.1161 = 0.0280 + 0.0820 + 0.0062, time: 6.813758]
2023-05-23 20:27:30.826: epoch 123:	0.02651772  	0.19546977  	0.10818406  
2023-05-23 20:27:37.655: [iter 124 : loss : 0.1152 = 0.0271 + 0.0819 + 0.0062, time: 6.827155]
2023-05-23 20:27:37.811: epoch 124:	0.02649655  	0.19525202  	0.10829458  
2023-05-23 20:27:44.651: [iter 125 : loss : 0.1145 = 0.0264 + 0.0819 + 0.0063, time: 6.837445]
2023-05-23 20:27:44.805: epoch 125:	0.02656712  	0.19566239  	0.10857996  
2023-05-23 20:27:51.654: [iter 126 : loss : 0.1150 = 0.0268 + 0.0818 + 0.0063, time: 6.847918]
2023-05-23 20:27:51.811: epoch 126:	0.02655301  	0.19537948  	0.10852358  
2023-05-23 20:27:58.641: [iter 127 : loss : 0.1139 = 0.0258 + 0.0818 + 0.0063, time: 6.827515]
2023-05-23 20:27:58.797: epoch 127:	0.02651067  	0.19516858  	0.10851824  
2023-05-23 20:28:05.639: [iter 128 : loss : 0.1150 = 0.0269 + 0.0817 + 0.0064, time: 6.839197]
2023-05-23 20:28:05.786: epoch 128:	0.02652478  	0.19521660  	0.10855851  
2023-05-23 20:28:12.617: [iter 129 : loss : 0.1141 = 0.0261 + 0.0817 + 0.0064, time: 6.829664]
2023-05-23 20:28:12.764: epoch 129:	0.02656712  	0.19598484  	0.10881732  
2023-05-23 20:28:19.460: [iter 130 : loss : 0.1142 = 0.0261 + 0.0816 + 0.0064, time: 6.694861]
2023-05-23 20:28:19.602: epoch 130:	0.02658124  	0.19625978  	0.10903976  
2023-05-23 20:28:26.271: [iter 131 : loss : 0.1132 = 0.0252 + 0.0816 + 0.0064, time: 6.667928]
2023-05-23 20:28:26.424: epoch 131:	0.02660241  	0.19634405  	0.10898194  
2023-05-23 20:28:33.084: [iter 132 : loss : 0.1135 = 0.0255 + 0.0815 + 0.0065, time: 6.658571]
2023-05-23 20:28:33.239: epoch 132:	0.02657418  	0.19579524  	0.10892423  
2023-05-23 20:28:40.031: [iter 133 : loss : 0.1124 = 0.0243 + 0.0815 + 0.0065, time: 6.791318]
2023-05-23 20:28:40.185: epoch 133:	0.02658829  	0.19594781  	0.10893065  
2023-05-23 20:28:46.857: [iter 134 : loss : 0.1130 = 0.0250 + 0.0815 + 0.0065, time: 6.671293]
2023-05-23 20:28:47.015: epoch 134:	0.02663063  	0.19626926  	0.10907491  
2023-05-23 20:28:53.830: [iter 135 : loss : 0.1127 = 0.0247 + 0.0814 + 0.0066, time: 6.813707]
2023-05-23 20:28:53.983: epoch 135:	0.02660240  	0.19593233  	0.10902938  
2023-05-23 20:29:00.630: [iter 136 : loss : 0.1124 = 0.0244 + 0.0814 + 0.0066, time: 6.644656]
2023-05-23 20:29:00.772: epoch 136:	0.02661651  	0.19614594  	0.10904912  
2023-05-23 20:29:07.423: [iter 137 : loss : 0.1120 = 0.0240 + 0.0814 + 0.0066, time: 6.649189]
2023-05-23 20:29:07.578: epoch 137:	0.02668002  	0.19659379  	0.10918131  
2023-05-23 20:29:14.223: [iter 138 : loss : 0.1117 = 0.0237 + 0.0813 + 0.0066, time: 6.642505]
2023-05-23 20:29:14.377: epoch 138:	0.02670825  	0.19687140  	0.10941659  
2023-05-23 20:29:21.022: [iter 139 : loss : 0.1114 = 0.0235 + 0.0813 + 0.0067, time: 6.644100]
2023-05-23 20:29:21.177: epoch 139:	0.02663768  	0.19616213  	0.10925389  
2023-05-23 20:29:28.003: [iter 140 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0067, time: 6.824296]
2023-05-23 20:29:28.160: epoch 140:	0.02671530  	0.19674809  	0.10953756  
2023-05-23 20:29:34.827: [iter 141 : loss : 0.1115 = 0.0236 + 0.0812 + 0.0067, time: 6.666668]
2023-05-23 20:29:34.982: epoch 141:	0.02668002  	0.19616468  	0.10929364  
2023-05-23 20:29:34.983: Early stopping is trigger at epoch: 141
2023-05-23 20:29:34.983: best_result@epoch 116:

2023-05-23 20:29:34.983: 		0.0267      	0.1969      	0.1083      
2023-05-25 18:07:25.915: my pid: 13288
2023-05-25 18:07:25.915: model: model.general_recommender.SGL
2023-05-25 18:07:25.915: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 18:07:25.915: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 18:07:29.685: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 18:07:37.513: [iter 1 : loss : 0.7706 = 0.6930 + 0.0776 + 0.0000, time: 7.828240]
2023-05-25 18:07:37.666: epoch 1:	0.00183461  	0.01236751  	0.00641957  
2023-05-25 18:07:37.666: Find a better model.
2023-05-25 18:07:45.550: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.883172]
2023-05-25 18:07:45.748: epoch 2:	0.00339401  	0.02335494  	0.01195696  
2023-05-25 18:07:45.748: Find a better model.
2023-05-25 18:07:53.445: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.695485]
2023-05-25 18:07:53.623: epoch 3:	0.00569429  	0.03921259  	0.01960516  
2023-05-25 18:07:53.623: Find a better model.
2023-05-25 18:08:01.048: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.423020]
2023-05-25 18:08:01.203: epoch 4:	0.00808630  	0.05648810  	0.02844983  
2023-05-25 18:08:01.203: Find a better model.
2023-05-25 18:08:08.466: [iter 5 : loss : 0.7685 = 0.6912 + 0.0773 + 0.0000, time: 7.260015]
2023-05-25 18:08:08.621: epoch 5:	0.01091589  	0.07726161  	0.03741086  
2023-05-25 18:08:08.621: Find a better model.
2023-05-25 18:08:15.600: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 6.978481]
2023-05-25 18:08:15.751: epoch 6:	0.01384432  	0.09877191  	0.04794341  
2023-05-25 18:08:15.751: Find a better model.
2023-05-25 18:08:22.841: [iter 7 : loss : 0.7604 = 0.6822 + 0.0781 + 0.0000, time: 7.088951]
2023-05-25 18:08:23.005: epoch 7:	0.01661748  	0.12048244  	0.05941228  
2023-05-25 18:08:23.005: Find a better model.
2023-05-25 18:08:30.029: [iter 8 : loss : 0.7460 = 0.6664 + 0.0795 + 0.0001, time: 7.022611]
2023-05-25 18:08:30.179: epoch 8:	0.01818401  	0.13326196  	0.06658761  
2023-05-25 18:08:30.179: Find a better model.
2023-05-25 18:08:37.228: [iter 9 : loss : 0.7139 = 0.6311 + 0.0827 + 0.0001, time: 7.047997]
2023-05-25 18:08:37.379: epoch 9:	0.01888966  	0.13894115  	0.06959072  
2023-05-25 18:08:37.379: Find a better model.
2023-05-25 18:08:44.231: [iter 10 : loss : 0.6577 = 0.5699 + 0.0876 + 0.0002, time: 6.849993]
2023-05-25 18:08:44.383: epoch 10:	0.01872735  	0.13819201  	0.06943880  
2023-05-25 18:08:51.222: [iter 11 : loss : 0.5837 = 0.4907 + 0.0926 + 0.0004, time: 6.838037]
2023-05-25 18:08:51.390: epoch 11:	0.01871325  	0.13850106  	0.06945288  
2023-05-25 18:08:58.412: [iter 12 : loss : 0.5123 = 0.4155 + 0.0963 + 0.0005, time: 7.021431]
2023-05-25 18:08:58.577: epoch 12:	0.01860740  	0.13764323  	0.06942309  
2023-05-25 18:09:05.448: [iter 13 : loss : 0.4582 = 0.3590 + 0.0985 + 0.0007, time: 6.869026]
2023-05-25 18:09:05.604: epoch 13:	0.01866386  	0.13818514  	0.06990115  
2023-05-25 18:09:12.439: [iter 14 : loss : 0.4170 = 0.3166 + 0.0996 + 0.0008, time: 6.834013]
2023-05-25 18:09:12.594: epoch 14:	0.01881204  	0.13954856  	0.07087963  
2023-05-25 18:09:12.594: Find a better model.
2023-05-25 18:09:19.439: [iter 15 : loss : 0.3882 = 0.2872 + 0.1001 + 0.0010, time: 6.843465]
2023-05-25 18:09:19.599: epoch 15:	0.01905196  	0.14149752  	0.07188386  
2023-05-25 18:09:19.599: Find a better model.
2023-05-25 18:09:26.401: [iter 16 : loss : 0.3646 = 0.2633 + 0.1002 + 0.0011, time: 6.800020]
2023-05-25 18:09:26.557: epoch 16:	0.01926366  	0.14257549  	0.07258890  
2023-05-25 18:09:26.557: Find a better model.
2023-05-25 18:09:33.415: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 6.857095]
2023-05-25 18:09:33.569: epoch 17:	0.01952475  	0.14435115  	0.07346696  
2023-05-25 18:09:33.569: Find a better model.
2023-05-25 18:09:40.426: [iter 18 : loss : 0.3315 = 0.2302 + 0.1000 + 0.0013, time: 6.854994]
2023-05-25 18:09:40.580: epoch 18:	0.01970823  	0.14547800  	0.07412752  
2023-05-25 18:09:40.580: Find a better model.
2023-05-25 18:09:47.405: [iter 19 : loss : 0.3169 = 0.2158 + 0.0997 + 0.0014, time: 6.823005]
2023-05-25 18:09:47.561: epoch 19:	0.01989876  	0.14681418  	0.07483394  
2023-05-25 18:09:47.561: Find a better model.
2023-05-25 18:09:54.403: [iter 20 : loss : 0.3069 = 0.2061 + 0.0993 + 0.0015, time: 6.841233]
2023-05-25 18:09:54.558: epoch 20:	0.01996226  	0.14709879  	0.07529653  
2023-05-25 18:09:54.558: Find a better model.
2023-05-25 18:10:01.396: [iter 21 : loss : 0.2969 = 0.1964 + 0.0989 + 0.0016, time: 6.835070]
2023-05-25 18:10:01.551: epoch 21:	0.02027981  	0.14938436  	0.07626184  
2023-05-25 18:10:01.551: Find a better model.
2023-05-25 18:10:08.402: [iter 22 : loss : 0.2886 = 0.1884 + 0.0985 + 0.0017, time: 6.850065]
2023-05-25 18:10:08.555: epoch 22:	0.02041388  	0.15025993  	0.07680344  
2023-05-25 18:10:08.555: Find a better model.
2023-05-25 18:10:15.390: [iter 23 : loss : 0.2802 = 0.1803 + 0.0981 + 0.0018, time: 6.834054]
2023-05-25 18:10:15.546: epoch 23:	0.02053383  	0.15106921  	0.07751744  
2023-05-25 18:10:15.546: Find a better model.
2023-05-25 18:10:22.389: [iter 24 : loss : 0.2736 = 0.1740 + 0.0977 + 0.0018, time: 6.840008]
2023-05-25 18:10:22.542: epoch 24:	0.02078787  	0.15308173  	0.07848143  
2023-05-25 18:10:22.542: Find a better model.
2023-05-25 18:10:29.583: [iter 25 : loss : 0.2667 = 0.1675 + 0.0973 + 0.0019, time: 7.039023]
2023-05-25 18:10:29.734: epoch 25:	0.02087961  	0.15337154  	0.07890216  
2023-05-25 18:10:29.734: Find a better model.
2023-05-25 18:10:36.604: [iter 26 : loss : 0.2630 = 0.1641 + 0.0969 + 0.0020, time: 6.868090]
2023-05-25 18:10:36.767: epoch 26:	0.02112659  	0.15508309  	0.07974935  
2023-05-25 18:10:36.767: Find a better model.
2023-05-25 18:10:43.604: [iter 27 : loss : 0.2551 = 0.1566 + 0.0965 + 0.0020, time: 6.836020]
2023-05-25 18:10:43.770: epoch 27:	0.02133829  	0.15645410  	0.08044992  
2023-05-25 18:10:43.770: Find a better model.
2023-05-25 18:10:50.612: [iter 28 : loss : 0.2503 = 0.1521 + 0.0961 + 0.0021, time: 6.840956]
2023-05-25 18:10:50.761: epoch 28:	0.02147236  	0.15735768  	0.08131745  
2023-05-25 18:10:50.761: Find a better model.
2023-05-25 18:10:57.572: [iter 29 : loss : 0.2458 = 0.1480 + 0.0956 + 0.0022, time: 6.810004]
2023-05-25 18:10:57.720: epoch 29:	0.02167699  	0.15908341  	0.08226252  
2023-05-25 18:10:57.720: Find a better model.
2023-05-25 18:11:04.564: [iter 30 : loss : 0.2392 = 0.1417 + 0.0953 + 0.0022, time: 6.843057]
2023-05-25 18:11:04.728: epoch 30:	0.02178284  	0.16044876  	0.08293393  
2023-05-25 18:11:04.728: Find a better model.
2023-05-25 18:11:11.589: [iter 31 : loss : 0.2356 = 0.1384 + 0.0949 + 0.0023, time: 6.860003]
2023-05-25 18:11:11.753: epoch 31:	0.02186751  	0.16057427  	0.08329571  
2023-05-25 18:11:11.753: Find a better model.
2023-05-25 18:11:18.573: [iter 32 : loss : 0.2300 = 0.1331 + 0.0946 + 0.0024, time: 6.818986]
2023-05-25 18:11:18.723: epoch 32:	0.02212860  	0.16257350  	0.08435014  
2023-05-25 18:11:18.723: Find a better model.
2023-05-25 18:11:25.561: [iter 33 : loss : 0.2273 = 0.1307 + 0.0942 + 0.0024, time: 6.837027]
2023-05-25 18:11:25.723: epoch 33:	0.02219917  	0.16291153  	0.08473682  
2023-05-25 18:11:25.723: Find a better model.
2023-05-25 18:11:32.576: [iter 34 : loss : 0.2234 = 0.1270 + 0.0938 + 0.0025, time: 6.852015]
2023-05-25 18:11:32.740: epoch 34:	0.02229089  	0.16361551  	0.08533307  
2023-05-25 18:11:32.740: Find a better model.
2023-05-25 18:11:39.573: [iter 35 : loss : 0.2200 = 0.1239 + 0.0936 + 0.0025, time: 6.832023]
2023-05-25 18:11:39.722: epoch 35:	0.02251670  	0.16539687  	0.08611237  
2023-05-25 18:11:39.722: Find a better model.
2023-05-25 18:11:46.559: [iter 36 : loss : 0.2165 = 0.1206 + 0.0932 + 0.0026, time: 6.836004]
2023-05-25 18:11:46.722: epoch 36:	0.02262255  	0.16630647  	0.08676223  
2023-05-25 18:11:46.722: Find a better model.
2023-05-25 18:11:53.561: [iter 37 : loss : 0.2125 = 0.1170 + 0.0929 + 0.0027, time: 6.838142]
2023-05-25 18:11:53.709: epoch 37:	0.02282014  	0.16797574  	0.08749385  
2023-05-25 18:11:53.709: Find a better model.
2023-05-25 18:12:00.554: [iter 38 : loss : 0.2110 = 0.1157 + 0.0926 + 0.0027, time: 6.844062]
2023-05-25 18:12:00.704: epoch 38:	0.02292599  	0.16889168  	0.08832098  
2023-05-25 18:12:00.704: Find a better model.
2023-05-25 18:12:07.568: [iter 39 : loss : 0.2066 = 0.1115 + 0.0923 + 0.0028, time: 6.863003]
2023-05-25 18:12:07.721: epoch 39:	0.02314474  	0.17035054  	0.08942634  
2023-05-25 18:12:07.721: Find a better model.
2023-05-25 18:12:14.582: [iter 40 : loss : 0.2034 = 0.1085 + 0.0920 + 0.0028, time: 6.860018]
2023-05-25 18:12:14.732: epoch 40:	0.02321531  	0.17081171  	0.08966282  
2023-05-25 18:12:14.732: Find a better model.
2023-05-25 18:12:21.749: [iter 41 : loss : 0.2017 = 0.1071 + 0.0917 + 0.0029, time: 7.015005]
2023-05-25 18:12:21.898: epoch 41:	0.02325059  	0.17118654  	0.09005117  
2023-05-25 18:12:21.898: Find a better model.
2023-05-25 18:12:28.757: [iter 42 : loss : 0.1995 = 0.1051 + 0.0915 + 0.0029, time: 6.858018]
2023-05-25 18:12:28.904: epoch 42:	0.02330704  	0.17206314  	0.09066550  
2023-05-25 18:12:28.904: Find a better model.
2023-05-25 18:12:35.781: [iter 43 : loss : 0.1955 = 0.1014 + 0.0912 + 0.0030, time: 6.875020]
2023-05-25 18:12:35.930: epoch 43:	0.02342700  	0.17316291  	0.09097954  
2023-05-25 18:12:35.930: Find a better model.
2023-05-25 18:12:42.811: [iter 44 : loss : 0.1921 = 0.0982 + 0.0909 + 0.0030, time: 6.879138]
2023-05-25 18:12:42.980: epoch 44:	0.02349051  	0.17356110  	0.09148567  
2023-05-25 18:12:42.980: Find a better model.
2023-05-25 18:12:49.956: [iter 45 : loss : 0.1900 = 0.0962 + 0.0907 + 0.0031, time: 6.974497]
2023-05-25 18:12:50.105: epoch 45:	0.02365281  	0.17470303  	0.09201422  
2023-05-25 18:12:50.105: Find a better model.
2023-05-25 18:12:56.948: [iter 46 : loss : 0.1876 = 0.0941 + 0.0904 + 0.0031, time: 6.841012]
2023-05-25 18:12:57.095: epoch 46:	0.02369515  	0.17490071  	0.09253069  
2023-05-25 18:12:57.095: Find a better model.
2023-05-25 18:13:03.940: [iter 47 : loss : 0.1868 = 0.0934 + 0.0902 + 0.0032, time: 6.842015]
2023-05-25 18:13:04.091: epoch 47:	0.02372337  	0.17514330  	0.09286022  
2023-05-25 18:13:04.091: Find a better model.
2023-05-25 18:13:10.951: [iter 48 : loss : 0.1830 = 0.0898 + 0.0899 + 0.0032, time: 6.859004]
2023-05-25 18:13:11.100: epoch 48:	0.02377982  	0.17574771  	0.09340488  
2023-05-25 18:13:11.100: Find a better model.
2023-05-25 18:13:17.927: [iter 49 : loss : 0.1799 = 0.0868 + 0.0898 + 0.0033, time: 6.826020]
2023-05-25 18:13:18.091: epoch 49:	0.02387861  	0.17628348  	0.09388212  
2023-05-25 18:13:18.091: Find a better model.
2023-05-25 18:13:24.936: [iter 50 : loss : 0.1791 = 0.0862 + 0.0895 + 0.0033, time: 6.844013]
2023-05-25 18:13:25.087: epoch 50:	0.02397034  	0.17681864  	0.09435506  
2023-05-25 18:13:25.088: Find a better model.
2023-05-25 18:13:32.122: [iter 51 : loss : 0.1761 = 0.0833 + 0.0893 + 0.0034, time: 7.033172]
2023-05-25 18:13:32.272: epoch 51:	0.02406913  	0.17761993  	0.09447869  
2023-05-25 18:13:32.273: Find a better model.
2023-05-25 18:13:39.330: [iter 52 : loss : 0.1760 = 0.0835 + 0.0891 + 0.0034, time: 7.055009]
2023-05-25 18:13:39.481: epoch 52:	0.02414674  	0.17800161  	0.09501639  
2023-05-25 18:13:39.482: Find a better model.
2023-05-25 18:13:46.552: [iter 53 : loss : 0.1740 = 0.0816 + 0.0889 + 0.0035, time: 7.068888]
2023-05-25 18:13:46.701: epoch 53:	0.02421731  	0.17865935  	0.09539431  
2023-05-25 18:13:46.702: Find a better model.
2023-05-25 18:13:53.751: [iter 54 : loss : 0.1719 = 0.0797 + 0.0887 + 0.0035, time: 7.048078]
2023-05-25 18:13:53.920: epoch 54:	0.02434432  	0.17926471  	0.09585232  
2023-05-25 18:13:53.920: Find a better model.
2023-05-25 18:14:00.920: [iter 55 : loss : 0.1700 = 0.0779 + 0.0885 + 0.0036, time: 6.998014]
2023-05-25 18:14:01.087: epoch 55:	0.02437961  	0.17936824  	0.09596348  
2023-05-25 18:14:01.087: Find a better model.
2023-05-25 18:14:08.120: [iter 56 : loss : 0.1684 = 0.0765 + 0.0883 + 0.0036, time: 7.030993]
2023-05-25 18:14:08.270: epoch 56:	0.02444312  	0.18025886  	0.09658890  
2023-05-25 18:14:08.270: Find a better model.
2023-05-25 18:14:15.312: [iter 57 : loss : 0.1666 = 0.0747 + 0.0882 + 0.0037, time: 7.040071]
2023-05-25 18:14:15.459: epoch 57:	0.02451368  	0.18116063  	0.09703913  
2023-05-25 18:14:15.460: Find a better model.
2023-05-25 18:14:22.499: [iter 58 : loss : 0.1646 = 0.0729 + 0.0880 + 0.0037, time: 7.038003]
2023-05-25 18:14:22.647: epoch 58:	0.02460541  	0.18177348  	0.09747923  
2023-05-25 18:14:22.647: Find a better model.
2023-05-25 18:14:29.695: [iter 59 : loss : 0.1636 = 0.0720 + 0.0878 + 0.0038, time: 7.047016]
2023-05-25 18:14:29.846: epoch 59:	0.02471832  	0.18261452  	0.09779141  
2023-05-25 18:14:29.846: Find a better model.
2023-05-25 18:14:36.903: [iter 60 : loss : 0.1621 = 0.0706 + 0.0876 + 0.0038, time: 7.055024]
2023-05-25 18:14:37.053: epoch 60:	0.02481005  	0.18321800  	0.09822003  
2023-05-25 18:14:37.053: Find a better model.
2023-05-25 18:14:44.095: [iter 61 : loss : 0.1608 = 0.0695 + 0.0875 + 0.0039, time: 7.041219]
2023-05-25 18:14:44.244: epoch 61:	0.02488767  	0.18389155  	0.09867841  
2023-05-25 18:14:44.244: Find a better model.
2023-05-25 18:14:51.300: [iter 62 : loss : 0.1591 = 0.0679 + 0.0873 + 0.0039, time: 7.054256]
2023-05-25 18:14:51.469: epoch 62:	0.02486650  	0.18365544  	0.09873114  
2023-05-25 18:14:58.510: [iter 63 : loss : 0.1579 = 0.0668 + 0.0872 + 0.0039, time: 7.039993]
2023-05-25 18:14:58.661: epoch 63:	0.02503585  	0.18452638  	0.09915788  
2023-05-25 18:14:58.661: Find a better model.
2023-05-25 18:15:05.684: [iter 64 : loss : 0.1569 = 0.0659 + 0.0870 + 0.0040, time: 7.022110]
2023-05-25 18:15:05.836: epoch 64:	0.02508524  	0.18505508  	0.09964011  
2023-05-25 18:15:05.836: Find a better model.
2023-05-25 18:15:12.739: [iter 65 : loss : 0.1558 = 0.0650 + 0.0868 + 0.0040, time: 6.901999]
2023-05-25 18:15:12.892: epoch 65:	0.02521226  	0.18601382  	0.10007998  
2023-05-25 18:15:12.892: Find a better model.
2023-05-25 18:15:19.919: [iter 66 : loss : 0.1542 = 0.0634 + 0.0867 + 0.0041, time: 7.025051]
2023-05-25 18:15:20.087: epoch 66:	0.02516287  	0.18607706  	0.10025271  
2023-05-25 18:15:20.087: Find a better model.
2023-05-25 18:15:27.102: [iter 67 : loss : 0.1526 = 0.0619 + 0.0866 + 0.0041, time: 7.014182]
2023-05-25 18:15:27.252: epoch 67:	0.02529695  	0.18731506  	0.10088006  
2023-05-25 18:15:27.252: Find a better model.
2023-05-25 18:15:34.272: [iter 68 : loss : 0.1524 = 0.0618 + 0.0864 + 0.0042, time: 7.018993]
2023-05-25 18:15:34.423: epoch 68:	0.02534634  	0.18747786  	0.10107961  
2023-05-25 18:15:34.423: Find a better model.
2023-05-25 18:15:41.480: [iter 69 : loss : 0.1504 = 0.0599 + 0.0863 + 0.0042, time: 7.054587]
2023-05-25 18:15:41.635: epoch 69:	0.02541691  	0.18815079  	0.10141803  
2023-05-25 18:15:41.635: Find a better model.
2023-05-25 18:15:48.700: [iter 70 : loss : 0.1489 = 0.0585 + 0.0862 + 0.0042, time: 7.064183]
2023-05-25 18:15:48.849: epoch 70:	0.02544513  	0.18846743  	0.10177006  
2023-05-25 18:15:48.849: Find a better model.
2023-05-25 18:15:55.880: [iter 71 : loss : 0.1474 = 0.0571 + 0.0860 + 0.0043, time: 7.028253]
2023-05-25 18:15:56.029: epoch 71:	0.02548041  	0.18853112  	0.10192010  
2023-05-25 18:15:56.029: Find a better model.
2023-05-25 18:16:03.072: [iter 72 : loss : 0.1474 = 0.0572 + 0.0859 + 0.0043, time: 7.042003]
2023-05-25 18:16:03.237: epoch 72:	0.02555803  	0.18894441  	0.10213837  
2023-05-25 18:16:03.237: Find a better model.
2023-05-25 18:16:10.280: [iter 73 : loss : 0.1459 = 0.0558 + 0.0858 + 0.0044, time: 7.040543]
2023-05-25 18:16:10.447: epoch 73:	0.02554392  	0.18904428  	0.10216590  
2023-05-25 18:16:10.447: Find a better model.
2023-05-25 18:16:17.657: [iter 74 : loss : 0.1444 = 0.0543 + 0.0857 + 0.0044, time: 7.208020]
2023-05-25 18:16:17.806: epoch 74:	0.02560038  	0.18955368  	0.10270458  
2023-05-25 18:16:17.806: Find a better model.
2023-05-25 18:16:24.869: [iter 75 : loss : 0.1440 = 0.0540 + 0.0855 + 0.0045, time: 7.061049]
2023-05-25 18:16:25.021: epoch 75:	0.02567094  	0.18969430  	0.10295459  
2023-05-25 18:16:25.021: Find a better model.
2023-05-25 18:16:32.083: [iter 76 : loss : 0.1431 = 0.0531 + 0.0854 + 0.0045, time: 7.059031]
2023-05-25 18:16:32.249: epoch 76:	0.02570623  	0.18998143  	0.10320710  
2023-05-25 18:16:32.249: Find a better model.
2023-05-25 18:16:39.462: [iter 77 : loss : 0.1421 = 0.0522 + 0.0853 + 0.0045, time: 7.211000]
2023-05-25 18:16:39.624: epoch 77:	0.02572739  	0.19022372  	0.10353088  
2023-05-25 18:16:39.624: Find a better model.
2023-05-25 18:16:46.704: [iter 78 : loss : 0.1412 = 0.0514 + 0.0852 + 0.0046, time: 7.077016]
2023-05-25 18:16:46.868: epoch 78:	0.02577679  	0.19057913  	0.10369058  
2023-05-25 18:16:46.868: Find a better model.
2023-05-25 18:16:54.081: [iter 79 : loss : 0.1400 = 0.0503 + 0.0851 + 0.0046, time: 7.211021]
2023-05-25 18:16:54.233: epoch 79:	0.02582619  	0.19081782  	0.10399541  
2023-05-25 18:16:54.233: Find a better model.
2023-05-25 18:17:01.274: [iter 80 : loss : 0.1392 = 0.0496 + 0.0850 + 0.0047, time: 7.040091]
2023-05-25 18:17:01.423: epoch 80:	0.02586853  	0.19128165  	0.10416587  
2023-05-25 18:17:01.423: Find a better model.
2023-05-25 18:17:08.460: [iter 81 : loss : 0.1390 = 0.0494 + 0.0849 + 0.0047, time: 7.035013]
2023-05-25 18:17:08.622: epoch 81:	0.02588969  	0.19129567  	0.10420147  
2023-05-25 18:17:08.623: Find a better model.
2023-05-25 18:17:15.665: [iter 82 : loss : 0.1378 = 0.0483 + 0.0848 + 0.0047, time: 7.041052]
2023-05-25 18:17:15.830: epoch 82:	0.02591792  	0.19143572  	0.10428526  
2023-05-25 18:17:15.831: Find a better model.
2023-05-25 18:17:22.874: [iter 83 : loss : 0.1368 = 0.0473 + 0.0847 + 0.0048, time: 7.041754]
2023-05-25 18:17:23.023: epoch 83:	0.02596731  	0.19199136  	0.10465901  
2023-05-25 18:17:23.024: Find a better model.
2023-05-25 18:17:30.033: [iter 84 : loss : 0.1367 = 0.0473 + 0.0846 + 0.0048, time: 7.007993]
2023-05-25 18:17:30.182: epoch 84:	0.02598848  	0.19229326  	0.10473472  
2023-05-25 18:17:30.182: Find a better model.
2023-05-25 18:17:37.252: [iter 85 : loss : 0.1357 = 0.0464 + 0.0845 + 0.0049, time: 7.069195]
2023-05-25 18:17:37.420: epoch 85:	0.02600965  	0.19242647  	0.10507125  
2023-05-25 18:17:37.420: Find a better model.
2023-05-25 18:17:44.624: [iter 86 : loss : 0.1356 = 0.0463 + 0.0844 + 0.0049, time: 7.202006]
2023-05-25 18:17:44.791: epoch 86:	0.02607316  	0.19279018  	0.10534012  
2023-05-25 18:17:44.792: Find a better model.
2023-05-25 18:17:51.841: [iter 87 : loss : 0.1329 = 0.0436 + 0.0843 + 0.0049, time: 7.047997]
2023-05-25 18:17:51.992: epoch 87:	0.02611550  	0.19311146  	0.10556564  
2023-05-25 18:17:51.992: Find a better model.
2023-05-25 18:17:59.040: [iter 88 : loss : 0.1323 = 0.0431 + 0.0842 + 0.0050, time: 7.046993]
2023-05-25 18:17:59.191: epoch 88:	0.02613667  	0.19327286  	0.10567599  
2023-05-25 18:17:59.191: Find a better model.
2023-05-25 18:18:06.237: [iter 89 : loss : 0.1320 = 0.0429 + 0.0841 + 0.0050, time: 7.045003]
2023-05-25 18:18:06.402: epoch 89:	0.02614373  	0.19340086  	0.10586503  
2023-05-25 18:18:06.402: Find a better model.
2023-05-25 18:18:13.603: [iter 90 : loss : 0.1326 = 0.0435 + 0.0840 + 0.0051, time: 7.199012]
2023-05-25 18:18:13.752: epoch 90:	0.02617901  	0.19325493  	0.10594596  
2023-05-25 18:18:20.844: [iter 91 : loss : 0.1313 = 0.0423 + 0.0839 + 0.0051, time: 7.089660]
2023-05-25 18:18:20.995: epoch 91:	0.02614372  	0.19319981  	0.10588811  
2023-05-25 18:18:28.059: [iter 92 : loss : 0.1304 = 0.0414 + 0.0839 + 0.0051, time: 7.062994]
2023-05-25 18:18:28.208: epoch 92:	0.02617196  	0.19330041  	0.10589728  
2023-05-25 18:18:35.421: [iter 93 : loss : 0.1310 = 0.0420 + 0.0838 + 0.0052, time: 7.211993]
2023-05-25 18:18:35.575: epoch 93:	0.02620018  	0.19321060  	0.10608124  
2023-05-25 18:18:42.624: [iter 94 : loss : 0.1287 = 0.0398 + 0.0837 + 0.0052, time: 7.047978]
2023-05-25 18:18:42.771: epoch 94:	0.02629897  	0.19440274  	0.10656825  
2023-05-25 18:18:42.772: Find a better model.
2023-05-25 18:18:49.821: [iter 95 : loss : 0.1280 = 0.0391 + 0.0836 + 0.0052, time: 7.048007]
2023-05-25 18:18:49.969: epoch 95:	0.02634837  	0.19448517  	0.10665527  
2023-05-25 18:18:49.969: Find a better model.
2023-05-25 18:18:57.047: [iter 96 : loss : 0.1281 = 0.0392 + 0.0836 + 0.0053, time: 7.075005]
2023-05-25 18:18:57.199: epoch 96:	0.02639071  	0.19521853  	0.10682653  
2023-05-25 18:18:57.199: Find a better model.
2023-05-25 18:19:04.224: [iter 97 : loss : 0.1264 = 0.0376 + 0.0835 + 0.0053, time: 7.023004]
2023-05-25 18:19:04.373: epoch 97:	0.02642599  	0.19520286  	0.10698997  
2023-05-25 18:19:11.585: [iter 98 : loss : 0.1272 = 0.0384 + 0.0834 + 0.0053, time: 7.210994]
2023-05-25 18:19:11.752: epoch 98:	0.02645421  	0.19540304  	0.10715363  
2023-05-25 18:19:11.752: Find a better model.
2023-05-25 18:19:18.796: [iter 99 : loss : 0.1261 = 0.0374 + 0.0833 + 0.0054, time: 7.043281]
2023-05-25 18:19:18.948: epoch 99:	0.02641188  	0.19525418  	0.10716520  
2023-05-25 18:19:26.011: [iter 100 : loss : 0.1257 = 0.0370 + 0.0833 + 0.0054, time: 7.062025]
2023-05-25 18:19:26.163: epoch 100:	0.02646833  	0.19538930  	0.10712774  
2023-05-25 18:19:33.194: [iter 101 : loss : 0.1252 = 0.0365 + 0.0832 + 0.0055, time: 7.029103]
2023-05-25 18:19:33.345: epoch 101:	0.02650361  	0.19555973  	0.10724990  
2023-05-25 18:19:33.345: Find a better model.
2023-05-25 18:19:40.394: [iter 102 : loss : 0.1243 = 0.0357 + 0.0831 + 0.0055, time: 7.047963]
2023-05-25 18:19:40.546: epoch 102:	0.02651066  	0.19597448  	0.10732735  
2023-05-25 18:19:40.546: Find a better model.
2023-05-25 18:19:47.604: [iter 103 : loss : 0.1240 = 0.0354 + 0.0831 + 0.0055, time: 7.056993]
2023-05-25 18:19:47.774: epoch 103:	0.02655300  	0.19643177  	0.10753255  
2023-05-25 18:19:47.774: Find a better model.
2023-05-25 18:19:54.818: [iter 104 : loss : 0.1244 = 0.0358 + 0.0830 + 0.0056, time: 7.042757]
2023-05-25 18:19:54.967: epoch 104:	0.02664473  	0.19676012  	0.10770696  
2023-05-25 18:19:54.967: Find a better model.
2023-05-25 18:20:02.014: [iter 105 : loss : 0.1236 = 0.0351 + 0.0829 + 0.0056, time: 7.045007]
2023-05-25 18:20:02.164: epoch 105:	0.02653888  	0.19594124  	0.10771486  
2023-05-25 18:20:09.221: [iter 106 : loss : 0.1232 = 0.0347 + 0.0829 + 0.0056, time: 7.055307]
2023-05-25 18:20:09.370: epoch 106:	0.02656005  	0.19605319  	0.10775003  
2023-05-25 18:20:16.565: [iter 107 : loss : 0.1224 = 0.0339 + 0.0828 + 0.0057, time: 7.192111]
2023-05-25 18:20:16.729: epoch 107:	0.02659534  	0.19626823  	0.10781346  
2023-05-25 18:20:23.976: [iter 108 : loss : 0.1220 = 0.0336 + 0.0828 + 0.0057, time: 7.246261]
2023-05-25 18:20:24.129: epoch 108:	0.02652477  	0.19610791  	0.10782728  
2023-05-25 18:20:31.189: [iter 109 : loss : 0.1209 = 0.0324 + 0.0827 + 0.0057, time: 7.059085]
2023-05-25 18:20:31.340: epoch 109:	0.02653183  	0.19609949  	0.10791298  
2023-05-25 18:20:38.563: [iter 110 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 7.219993]
2023-05-25 18:20:38.711: epoch 110:	0.02656711  	0.19626841  	0.10792717  
2023-05-25 18:20:45.774: [iter 111 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 7.061012]
2023-05-25 18:20:45.924: epoch 111:	0.02653183  	0.19602166  	0.10803550  
2023-05-25 18:20:52.971: [iter 112 : loss : 0.1201 = 0.0318 + 0.0825 + 0.0058, time: 7.046364]
2023-05-25 18:20:53.121: epoch 112:	0.02653183  	0.19577806  	0.10801121  
2023-05-25 18:21:00.160: [iter 113 : loss : 0.1200 = 0.0317 + 0.0825 + 0.0059, time: 7.037002]
2023-05-25 18:21:00.312: epoch 113:	0.02658123  	0.19623686  	0.10819159  
2023-05-25 18:21:07.345: [iter 114 : loss : 0.1192 = 0.0309 + 0.0824 + 0.0059, time: 7.031462]
2023-05-25 18:21:07.496: epoch 114:	0.02660240  	0.19656248  	0.10812242  
2023-05-25 18:21:14.576: [iter 115 : loss : 0.1187 = 0.0304 + 0.0823 + 0.0059, time: 7.078999]
2023-05-25 18:21:14.726: epoch 115:	0.02666590  	0.19675405  	0.10823486  
2023-05-25 18:21:21.768: [iter 116 : loss : 0.1179 = 0.0296 + 0.0823 + 0.0060, time: 7.039993]
2023-05-25 18:21:21.936: epoch 116:	0.02665179  	0.19682030  	0.10830899  
2023-05-25 18:21:21.936: Find a better model.
2023-05-25 18:21:28.987: [iter 117 : loss : 0.1179 = 0.0297 + 0.0822 + 0.0060, time: 7.048995]
2023-05-25 18:21:29.136: epoch 117:	0.02666590  	0.19652513  	0.10827845  
2023-05-25 18:21:36.177: [iter 118 : loss : 0.1178 = 0.0296 + 0.0822 + 0.0060, time: 7.038999]
2023-05-25 18:21:36.329: epoch 118:	0.02666590  	0.19639029  	0.10822640  
2023-05-25 18:21:43.375: [iter 119 : loss : 0.1170 = 0.0288 + 0.0821 + 0.0061, time: 7.044509]
2023-05-25 18:21:43.529: epoch 119:	0.02664473  	0.19643718  	0.10831276  
2023-05-25 18:21:50.557: [iter 120 : loss : 0.1172 = 0.0290 + 0.0821 + 0.0061, time: 7.025995]
2023-05-25 18:21:50.709: epoch 120:	0.02654594  	0.19572243  	0.10810462  
2023-05-25 18:21:57.748: [iter 121 : loss : 0.1170 = 0.0288 + 0.0820 + 0.0061, time: 7.035294]
2023-05-25 18:21:57.897: epoch 121:	0.02654594  	0.19569188  	0.10810082  
2023-05-25 18:22:04.971: [iter 122 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 7.072015]
2023-05-25 18:22:05.140: epoch 122:	0.02651772  	0.19546536  	0.10818428  
2023-05-25 18:22:12.146: [iter 123 : loss : 0.1161 = 0.0280 + 0.0819 + 0.0062, time: 7.005022]
2023-05-25 18:22:12.295: epoch 123:	0.02651066  	0.19539921  	0.10815108  
2023-05-25 18:22:19.332: [iter 124 : loss : 0.1152 = 0.0271 + 0.0819 + 0.0062, time: 7.034238]
2023-05-25 18:22:19.481: epoch 124:	0.02649656  	0.19529434  	0.10830414  
2023-05-25 18:22:26.525: [iter 125 : loss : 0.1145 = 0.0264 + 0.0818 + 0.0063, time: 7.042027]
2023-05-25 18:22:26.677: epoch 125:	0.02655301  	0.19555186  	0.10852303  
2023-05-25 18:22:33.733: [iter 126 : loss : 0.1149 = 0.0269 + 0.0818 + 0.0063, time: 7.054241]
2023-05-25 18:22:33.884: epoch 126:	0.02656007  	0.19547357  	0.10857677  
2023-05-25 18:22:40.931: [iter 127 : loss : 0.1139 = 0.0258 + 0.0818 + 0.0063, time: 7.044002]
2023-05-25 18:22:41.081: epoch 127:	0.02651773  	0.19523914  	0.10856479  
2023-05-25 18:22:48.116: [iter 128 : loss : 0.1150 = 0.0269 + 0.0817 + 0.0064, time: 7.033934]
2023-05-25 18:22:48.267: epoch 128:	0.02653184  	0.19526362  	0.10857139  
2023-05-25 18:22:55.316: [iter 129 : loss : 0.1141 = 0.0261 + 0.0817 + 0.0064, time: 7.047370]
2023-05-25 18:22:55.467: epoch 129:	0.02658829  	0.19617298  	0.10886722  
2023-05-25 18:23:02.538: [iter 130 : loss : 0.1142 = 0.0262 + 0.0816 + 0.0064, time: 7.067194]
2023-05-25 18:23:02.688: epoch 130:	0.02659535  	0.19636896  	0.10906675  
2023-05-25 18:23:09.750: [iter 131 : loss : 0.1132 = 0.0252 + 0.0816 + 0.0064, time: 7.060995]
2023-05-25 18:23:09.915: epoch 131:	0.02658124  	0.19627517  	0.10897803  
2023-05-25 18:23:16.935: [iter 132 : loss : 0.1135 = 0.0255 + 0.0815 + 0.0065, time: 7.017019]
2023-05-25 18:23:17.084: epoch 132:	0.02655301  	0.19571626  	0.10891122  
2023-05-25 18:23:24.117: [iter 133 : loss : 0.1123 = 0.0244 + 0.0815 + 0.0065, time: 7.031288]
2023-05-25 18:23:24.280: epoch 133:	0.02658123  	0.19591422  	0.10892907  
2023-05-25 18:23:31.315: [iter 134 : loss : 0.1130 = 0.0250 + 0.0814 + 0.0065, time: 7.033244]
2023-05-25 18:23:31.467: epoch 134:	0.02663768  	0.19633982  	0.10908300  
2023-05-25 18:23:38.536: [iter 135 : loss : 0.1127 = 0.0247 + 0.0814 + 0.0066, time: 7.067074]
2023-05-25 18:23:38.685: epoch 135:	0.02660945  	0.19602990  	0.10907241  
2023-05-25 18:23:45.702: [iter 136 : loss : 0.1124 = 0.0244 + 0.0814 + 0.0066, time: 7.016107]
2023-05-25 18:23:45.853: epoch 136:	0.02662357  	0.19617271  	0.10903518  
2023-05-25 18:23:52.896: [iter 137 : loss : 0.1120 = 0.0241 + 0.0813 + 0.0066, time: 7.041010]
2023-05-25 18:23:53.048: epoch 137:	0.02668002  	0.19666435  	0.10922439  
2023-05-25 18:24:00.113: [iter 138 : loss : 0.1116 = 0.0237 + 0.0813 + 0.0066, time: 7.063063]
2023-05-25 18:24:00.267: epoch 138:	0.02670825  	0.19688787  	0.10946044  
2023-05-25 18:24:00.267: Find a better model.
2023-05-25 18:24:07.289: [iter 139 : loss : 0.1114 = 0.0235 + 0.0812 + 0.0067, time: 7.019024]
2023-05-25 18:24:07.440: epoch 139:	0.02661652  	0.19604452  	0.10926850  
2023-05-25 18:24:14.491: [iter 140 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0067, time: 7.050038]
2023-05-25 18:24:14.641: epoch 140:	0.02675764  	0.19719499  	0.10966732  
2023-05-25 18:24:14.641: Find a better model.
2023-05-25 18:24:21.690: [iter 141 : loss : 0.1115 = 0.0236 + 0.0812 + 0.0067, time: 7.047282]
2023-05-25 18:24:21.840: epoch 141:	0.02668707  	0.19628230  	0.10931800  
2023-05-25 18:24:28.886: [iter 142 : loss : 0.1106 = 0.0227 + 0.0811 + 0.0068, time: 7.044013]
2023-05-25 18:24:29.053: epoch 142:	0.02660946  	0.19581333  	0.10916381  
2023-05-25 18:24:36.119: [iter 143 : loss : 0.1106 = 0.0228 + 0.0811 + 0.0068, time: 7.065473]
2023-05-25 18:24:36.283: epoch 143:	0.02670825  	0.19672152  	0.10959210  
2023-05-25 18:24:43.329: [iter 144 : loss : 0.1100 = 0.0221 + 0.0811 + 0.0068, time: 7.045046]
2023-05-25 18:24:43.482: epoch 144:	0.02670825  	0.19677654  	0.10941208  
2023-05-25 18:24:50.538: [iter 145 : loss : 0.1098 = 0.0220 + 0.0810 + 0.0068, time: 7.055009]
2023-05-25 18:24:50.717: epoch 145:	0.02669413  	0.19646761  	0.10948996  
2023-05-25 18:24:57.901: [iter 146 : loss : 0.1103 = 0.0224 + 0.0810 + 0.0069, time: 7.182501]
2023-05-25 18:24:58.054: epoch 146:	0.02661651  	0.19614151  	0.10935292  
2023-05-25 18:25:05.110: [iter 147 : loss : 0.1101 = 0.0223 + 0.0810 + 0.0069, time: 7.054271]
2023-05-25 18:25:05.261: epoch 147:	0.02660240  	0.19597685  	0.10925205  
2023-05-25 18:25:12.296: [iter 148 : loss : 0.1089 = 0.0210 + 0.0809 + 0.0069, time: 7.033000]
2023-05-25 18:25:12.448: epoch 148:	0.02665179  	0.19634344  	0.10944857  
2023-05-25 18:25:19.490: [iter 149 : loss : 0.1093 = 0.0215 + 0.0809 + 0.0069, time: 7.040411]
2023-05-25 18:25:19.640: epoch 149:	0.02665179  	0.19598961  	0.10942703  
2023-05-25 18:25:26.678: [iter 150 : loss : 0.1087 = 0.0209 + 0.0809 + 0.0070, time: 7.035007]
2023-05-25 18:25:26.846: epoch 150:	0.02663062  	0.19599342  	0.10951611  
2023-05-25 18:25:33.869: [iter 151 : loss : 0.1089 = 0.0211 + 0.0808 + 0.0070, time: 7.021070]
2023-05-25 18:25:34.037: epoch 151:	0.02661650  	0.19579555  	0.10949899  
2023-05-25 18:25:41.065: [iter 152 : loss : 0.1082 = 0.0204 + 0.0808 + 0.0070, time: 7.026042]
2023-05-25 18:25:41.214: epoch 152:	0.02658827  	0.19564082  	0.10959592  
2023-05-25 18:25:48.069: [iter 153 : loss : 0.1074 = 0.0196 + 0.0808 + 0.0070, time: 6.853020]
2023-05-25 18:25:48.220: epoch 153:	0.02654594  	0.19524562  	0.10939363  
2023-05-25 18:25:55.088: [iter 154 : loss : 0.1077 = 0.0199 + 0.0808 + 0.0071, time: 6.867002]
2023-05-25 18:25:55.238: epoch 154:	0.02657417  	0.19544671  	0.10937213  
2023-05-25 18:26:02.269: [iter 155 : loss : 0.1086 = 0.0208 + 0.0807 + 0.0071, time: 7.029087]
2023-05-25 18:26:02.418: epoch 155:	0.02651771  	0.19528393  	0.10937887  
2023-05-25 18:26:09.479: [iter 156 : loss : 0.1078 = 0.0200 + 0.0807 + 0.0071, time: 7.060007]
2023-05-25 18:26:09.632: epoch 156:	0.02646126  	0.19467387  	0.10916097  
2023-05-25 18:26:16.675: [iter 157 : loss : 0.1077 = 0.0198 + 0.0807 + 0.0072, time: 7.041003]
2023-05-25 18:26:16.827: epoch 157:	0.02648948  	0.19495113  	0.10919838  
2023-05-25 18:26:23.679: [iter 158 : loss : 0.1070 = 0.0192 + 0.0806 + 0.0072, time: 6.849997]
2023-05-25 18:26:23.828: epoch 158:	0.02651066  	0.19509876  	0.10911755  
2023-05-25 18:26:30.854: [iter 159 : loss : 0.1073 = 0.0195 + 0.0806 + 0.0072, time: 7.024000]
2023-05-25 18:26:31.007: epoch 159:	0.02653888  	0.19528100  	0.10933505  
2023-05-25 18:26:38.041: [iter 160 : loss : 0.1069 = 0.0191 + 0.0806 + 0.0072, time: 7.032993]
2023-05-25 18:26:38.205: epoch 160:	0.02655300  	0.19528913  	0.10944472  
2023-05-25 18:26:45.080: [iter 161 : loss : 0.1065 = 0.0187 + 0.0805 + 0.0073, time: 6.873027]
2023-05-25 18:26:45.230: epoch 161:	0.02656005  	0.19537659  	0.10931046  
2023-05-25 18:26:52.240: [iter 162 : loss : 0.1058 = 0.0180 + 0.0805 + 0.0073, time: 7.008510]
2023-05-25 18:26:52.390: epoch 162:	0.02659533  	0.19546986  	0.10932148  
2023-05-25 18:26:59.445: [iter 163 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 7.053993]
2023-05-25 18:26:59.602: epoch 163:	0.02654594  	0.19534360  	0.10927954  
2023-05-25 18:27:06.639: [iter 164 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 7.036121]
2023-05-25 18:27:06.790: epoch 164:	0.02651066  	0.19500767  	0.10925679  
2023-05-25 18:27:13.832: [iter 165 : loss : 0.1060 = 0.0182 + 0.0804 + 0.0074, time: 7.041066]
2023-05-25 18:27:13.980: epoch 165:	0.02660239  	0.19551156  	0.10934222  
2023-05-25 18:27:13.980: Early stopping is trigger at epoch: 165
2023-05-25 18:27:13.980: best_result@epoch 140:

2023-05-25 18:27:13.980: 		0.0268      	0.1972      	0.1097      
2023-05-25 19:46:06.188: my pid: 12128
2023-05-25 19:46:06.188: model: model.general_recommender.SGL
2023-05-25 19:46:06.188: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 19:46:06.188: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 19:46:09.949: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 19:46:17.626: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.677032]
2023-05-25 19:46:17.779: epoch 1:	0.00216625  	0.01497536  	0.00764244  
2023-05-25 19:46:17.780: Find a better model.
2023-05-25 19:46:25.412: [iter 2 : loss : 0.7706 = 0.6929 + 0.0777 + 0.0000, time: 7.631037]
2023-05-25 19:46:25.610: epoch 2:	0.00394438  	0.02714157  	0.01355890  
2023-05-25 19:46:25.610: Find a better model.
2023-05-25 19:46:33.219: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.608052]
2023-05-25 19:46:33.396: epoch 3:	0.00671742  	0.04654722  	0.02366749  
2023-05-25 19:46:33.396: Find a better model.
2023-05-25 19:46:40.823: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.426015]
2023-05-25 19:46:40.978: epoch 4:	0.00967396  	0.06787906  	0.03394979  
2023-05-25 19:46:40.978: Find a better model.
2023-05-25 19:46:48.433: [iter 5 : loss : 0.7685 = 0.6906 + 0.0778 + 0.0000, time: 7.454371]
2023-05-25 19:46:48.609: epoch 5:	0.01265885  	0.08938721  	0.04379842  
2023-05-25 19:46:48.609: Find a better model.
2023-05-25 19:46:55.809: [iter 6 : loss : 0.7655 = 0.6874 + 0.0781 + 0.0000, time: 7.197448]
2023-05-25 19:46:55.965: epoch 6:	0.01543907  	0.11075804  	0.05446367  
2023-05-25 19:46:55.965: Find a better model.
2023-05-25 19:47:03.004: [iter 7 : loss : 0.7576 = 0.6787 + 0.0789 + 0.0000, time: 7.038101]
2023-05-25 19:47:03.170: epoch 7:	0.01788764  	0.12975959  	0.06405847  
2023-05-25 19:47:03.171: Find a better model.
2023-05-25 19:47:09.989: [iter 8 : loss : 0.7388 = 0.6578 + 0.0809 + 0.0001, time: 6.816003]
2023-05-25 19:47:10.137: epoch 8:	0.01873441  	0.13699752  	0.06902540  
2023-05-25 19:47:10.138: Find a better model.
2023-05-25 19:47:17.005: [iter 9 : loss : 0.6989 = 0.6139 + 0.0848 + 0.0002, time: 6.865999]
2023-05-25 19:47:17.155: epoch 9:	0.01879792  	0.13885236  	0.06976726  
2023-05-25 19:47:17.155: Find a better model.
2023-05-25 19:47:23.992: [iter 10 : loss : 0.6345 = 0.5442 + 0.0900 + 0.0003, time: 6.835004]
2023-05-25 19:47:24.144: epoch 10:	0.01888260  	0.13985242  	0.06963884  
2023-05-25 19:47:24.144: Find a better model.
2023-05-25 19:47:30.998: [iter 11 : loss : 0.5590 = 0.4638 + 0.0948 + 0.0004, time: 6.853024]
2023-05-25 19:47:31.151: epoch 11:	0.01871325  	0.13860905  	0.06942577  
2023-05-25 19:47:37.976: [iter 12 : loss : 0.4925 = 0.3940 + 0.0979 + 0.0006, time: 6.824017]
2023-05-25 19:47:38.144: epoch 12:	0.01852272  	0.13726650  	0.06928337  
2023-05-25 19:47:45.005: [iter 13 : loss : 0.4439 = 0.3436 + 0.0996 + 0.0007, time: 6.860006]
2023-05-25 19:47:45.169: epoch 13:	0.01857212  	0.13756423  	0.06985772  
2023-05-25 19:47:52.172: [iter 14 : loss : 0.4072 = 0.3058 + 0.1005 + 0.0009, time: 7.002092]
2023-05-25 19:47:52.340: epoch 14:	0.01878382  	0.13956578  	0.07076950  
2023-05-25 19:47:59.180: [iter 15 : loss : 0.3812 = 0.2795 + 0.1008 + 0.0010, time: 6.839015]
2023-05-25 19:47:59.329: epoch 15:	0.01891789  	0.14010404  	0.07146242  
2023-05-25 19:47:59.329: Find a better model.
2023-05-25 19:48:06.158: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 6.827016]
2023-05-25 19:48:06.308: epoch 16:	0.01919310  	0.14209834  	0.07224111  
2023-05-25 19:48:06.308: Find a better model.
2023-05-25 19:48:13.193: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 6.884025]
2023-05-25 19:48:13.346: epoch 17:	0.01939774  	0.14316788  	0.07318529  
2023-05-25 19:48:13.346: Find a better model.
2023-05-25 19:48:20.171: [iter 18 : loss : 0.3286 = 0.2268 + 0.1004 + 0.0013, time: 6.823234]
2023-05-25 19:48:20.340: epoch 18:	0.01965882  	0.14523189  	0.07400754  
2023-05-25 19:48:20.340: Find a better model.
2023-05-25 19:48:27.184: [iter 19 : loss : 0.3146 = 0.2131 + 0.1000 + 0.0014, time: 6.843514]
2023-05-25 19:48:27.337: epoch 19:	0.01989875  	0.14659438  	0.07485601  
2023-05-25 19:48:27.337: Find a better model.
2023-05-25 19:48:34.159: [iter 20 : loss : 0.3051 = 0.2039 + 0.0996 + 0.0015, time: 6.820107]
2023-05-25 19:48:34.312: epoch 20:	0.02015279  	0.14849868  	0.07577936  
2023-05-25 19:48:34.312: Find a better model.
2023-05-25 19:48:41.148: [iter 21 : loss : 0.2954 = 0.1946 + 0.0993 + 0.0016, time: 6.835013]
2023-05-25 19:48:41.299: epoch 21:	0.02032920  	0.14976291  	0.07656690  
2023-05-25 19:48:41.299: Find a better model.
2023-05-25 19:48:48.160: [iter 22 : loss : 0.2873 = 0.1868 + 0.0989 + 0.0017, time: 6.859116]
2023-05-25 19:48:48.314: epoch 22:	0.02051266  	0.15155566  	0.07746946  
2023-05-25 19:48:48.314: Find a better model.
2023-05-25 19:48:55.188: [iter 23 : loss : 0.2793 = 0.1790 + 0.0985 + 0.0018, time: 6.872028]
2023-05-25 19:48:55.337: epoch 23:	0.02067497  	0.15280922  	0.07839331  
2023-05-25 19:48:55.337: Find a better model.
2023-05-25 19:49:02.174: [iter 24 : loss : 0.2728 = 0.1729 + 0.0980 + 0.0018, time: 6.833934]
2023-05-25 19:49:02.342: epoch 24:	0.02087960  	0.15387651  	0.07897241  
2023-05-25 19:49:02.342: Find a better model.
2023-05-25 19:49:09.149: [iter 25 : loss : 0.2661 = 0.1665 + 0.0976 + 0.0019, time: 6.804442]
2023-05-25 19:49:09.299: epoch 25:	0.02102073  	0.15470774  	0.07946541  
2023-05-25 19:49:09.300: Find a better model.
2023-05-25 19:49:16.152: [iter 26 : loss : 0.2624 = 0.1633 + 0.0972 + 0.0020, time: 6.851016]
2023-05-25 19:49:16.302: epoch 26:	0.02112659  	0.15535788  	0.07995071  
2023-05-25 19:49:16.302: Find a better model.
2023-05-25 19:49:23.157: [iter 27 : loss : 0.2548 = 0.1559 + 0.0968 + 0.0021, time: 6.853006]
2023-05-25 19:49:23.305: epoch 27:	0.02129594  	0.15674502  	0.08069664  
2023-05-25 19:49:23.305: Find a better model.
2023-05-25 19:49:30.140: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 6.834186]
2023-05-25 19:49:30.293: epoch 28:	0.02143002  	0.15756500  	0.08144733  
2023-05-25 19:49:30.293: Find a better model.
2023-05-25 19:49:37.158: [iter 29 : loss : 0.2456 = 0.1474 + 0.0960 + 0.0022, time: 6.863024]
2023-05-25 19:49:37.324: epoch 29:	0.02162054  	0.15895677  	0.08225098  
2023-05-25 19:49:37.325: Find a better model.
2023-05-25 19:49:44.148: [iter 30 : loss : 0.2390 = 0.1411 + 0.0956 + 0.0022, time: 6.821774]
2023-05-25 19:49:44.315: epoch 30:	0.02184634  	0.16083184  	0.08313150  
2023-05-25 19:49:44.315: Find a better model.
2023-05-25 19:49:51.121: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 6.805415]
2023-05-25 19:49:51.274: epoch 31:	0.02198747  	0.16185437  	0.08384563  
2023-05-25 19:49:51.274: Find a better model.
2023-05-25 19:49:58.123: [iter 32 : loss : 0.2300 = 0.1327 + 0.0949 + 0.0024, time: 6.848012]
2023-05-25 19:49:58.291: epoch 32:	0.02214271  	0.16267397  	0.08440990  
2023-05-25 19:49:58.291: Find a better model.
2023-05-25 19:50:05.117: [iter 33 : loss : 0.2272 = 0.1302 + 0.0945 + 0.0024, time: 6.825014]
2023-05-25 19:50:05.269: epoch 33:	0.02221327  	0.16328903  	0.08470640  
2023-05-25 19:50:05.269: Find a better model.
2023-05-25 19:50:11.926: [iter 34 : loss : 0.2234 = 0.1268 + 0.0942 + 0.0025, time: 6.655405]
2023-05-25 19:50:12.075: epoch 34:	0.02237557  	0.16443875  	0.08538613  
2023-05-25 19:50:12.076: Find a better model.
2023-05-25 19:50:18.755: [iter 35 : loss : 0.2200 = 0.1236 + 0.0939 + 0.0025, time: 6.678006]
2023-05-25 19:50:18.905: epoch 35:	0.02248847  	0.16539912  	0.08601477  
2023-05-25 19:50:18.905: Find a better model.
2023-05-25 19:50:25.709: [iter 36 : loss : 0.2166 = 0.1204 + 0.0936 + 0.0026, time: 6.803020]
2023-05-25 19:50:25.861: epoch 36:	0.02270723  	0.16716278  	0.08693756  
2023-05-25 19:50:25.861: Find a better model.
2023-05-25 19:50:32.515: [iter 37 : loss : 0.2126 = 0.1167 + 0.0932 + 0.0027, time: 6.653021]
2023-05-25 19:50:32.665: epoch 37:	0.02288364  	0.16815960  	0.08760352  
2023-05-25 19:50:32.665: Find a better model.
2023-05-25 19:50:39.321: [iter 38 : loss : 0.2111 = 0.1154 + 0.0930 + 0.0027, time: 6.654003]
2023-05-25 19:50:39.473: epoch 38:	0.02296126  	0.16911186  	0.08815136  
2023-05-25 19:50:39.473: Find a better model.
2023-05-25 19:50:46.134: [iter 39 : loss : 0.2067 = 0.1112 + 0.0927 + 0.0028, time: 6.657413]
2023-05-25 19:50:46.303: epoch 39:	0.02294715  	0.16911449  	0.08876958  
2023-05-25 19:50:46.303: Find a better model.
2023-05-25 19:50:53.106: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 6.802117]
2023-05-25 19:50:53.257: epoch 40:	0.02297538  	0.16947632  	0.08907121  
2023-05-25 19:50:53.257: Find a better model.
2023-05-25 19:51:00.136: [iter 41 : loss : 0.2019 = 0.1070 + 0.0921 + 0.0029, time: 6.878003]
2023-05-25 19:51:00.289: epoch 41:	0.02314474  	0.17047954  	0.08967278  
2023-05-25 19:51:00.289: Find a better model.
2023-05-25 19:51:07.092: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.801015]
2023-05-25 19:51:07.241: epoch 42:	0.02327175  	0.17125009  	0.09019362  
2023-05-25 19:51:07.242: Find a better model.
2023-05-25 19:51:14.098: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 6.854006]
2023-05-25 19:51:14.248: epoch 43:	0.02338466  	0.17248400  	0.09090815  
2023-05-25 19:51:14.249: Find a better model.
2023-05-25 19:51:21.090: [iter 44 : loss : 0.1924 = 0.0981 + 0.0912 + 0.0030, time: 6.839056]
2023-05-25 19:51:21.240: epoch 44:	0.02351873  	0.17322424  	0.09142201  
2023-05-25 19:51:21.240: Find a better model.
2023-05-25 19:51:28.108: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.862001]
2023-05-25 19:51:28.261: epoch 45:	0.02365986  	0.17424634  	0.09224367  
2023-05-25 19:51:28.261: Find a better model.
2023-05-25 19:51:35.098: [iter 46 : loss : 0.1880 = 0.0941 + 0.0908 + 0.0031, time: 6.836357]
2023-05-25 19:51:35.248: epoch 46:	0.02369515  	0.17449503  	0.09244721  
2023-05-25 19:51:35.248: Find a better model.
2023-05-25 19:51:42.119: [iter 47 : loss : 0.1871 = 0.0933 + 0.0905 + 0.0032, time: 6.870055]
2023-05-25 19:51:42.270: epoch 47:	0.02386451  	0.17573193  	0.09284776  
2023-05-25 19:51:42.270: Find a better model.
2023-05-25 19:51:49.081: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.809017]
2023-05-25 19:51:49.235: epoch 48:	0.02392095  	0.17622703  	0.09325764  
2023-05-25 19:51:49.236: Find a better model.
2023-05-25 19:51:56.091: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 6.854012]
2023-05-25 19:51:56.242: epoch 49:	0.02406914  	0.17730820  	0.09392841  
2023-05-25 19:51:56.242: Find a better model.
2023-05-25 19:52:03.115: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 6.872103]
2023-05-25 19:52:03.265: epoch 50:	0.02406208  	0.17759329  	0.09424033  
2023-05-25 19:52:03.265: Find a better model.
2023-05-25 19:52:10.086: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 6.820016]
2023-05-25 19:52:10.238: epoch 51:	0.02416793  	0.17844321  	0.09468060  
2023-05-25 19:52:10.238: Find a better model.
2023-05-25 19:52:17.102: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 6.863016]
2023-05-25 19:52:17.254: epoch 52:	0.02423849  	0.17860389  	0.09501697  
2023-05-25 19:52:17.254: Find a better model.
2023-05-25 19:52:24.105: [iter 53 : loss : 0.1743 = 0.0815 + 0.0893 + 0.0035, time: 6.850007]
2023-05-25 19:52:24.255: epoch 53:	0.02433728  	0.17941333  	0.09565419  
2023-05-25 19:52:24.255: Find a better model.
2023-05-25 19:52:31.084: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 6.827289]
2023-05-25 19:52:31.234: epoch 54:	0.02434434  	0.17962208  	0.09600072  
2023-05-25 19:52:31.234: Find a better model.
2023-05-25 19:52:38.261: [iter 55 : loss : 0.1703 = 0.0779 + 0.0889 + 0.0036, time: 7.025999]
2023-05-25 19:52:38.429: epoch 55:	0.02432316  	0.17928515  	0.09600009  
2023-05-25 19:52:45.287: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.856275]
2023-05-25 19:52:45.439: epoch 56:	0.02440078  	0.17974919  	0.09648073  
2023-05-25 19:52:45.439: Find a better model.
2023-05-25 19:52:52.274: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 6.833149]
2023-05-25 19:52:52.422: epoch 57:	0.02448546  	0.18022776  	0.09681066  
2023-05-25 19:52:52.422: Find a better model.
2023-05-25 19:52:59.261: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 6.838048]
2023-05-25 19:52:59.409: epoch 58:	0.02445723  	0.17982291  	0.09695093  
2023-05-25 19:53:06.295: [iter 59 : loss : 0.1640 = 0.0721 + 0.0882 + 0.0038, time: 6.885131]
2023-05-25 19:53:06.446: epoch 59:	0.02458424  	0.18097632  	0.09751640  
2023-05-25 19:53:06.446: Find a better model.
2023-05-25 19:53:13.270: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 6.822994]
2023-05-25 19:53:13.426: epoch 60:	0.02472538  	0.18231960  	0.09811839  
2023-05-25 19:53:13.426: Find a better model.
2023-05-25 19:53:20.268: [iter 61 : loss : 0.1611 = 0.0694 + 0.0878 + 0.0038, time: 6.841051]
2023-05-25 19:53:20.417: epoch 61:	0.02476066  	0.18281001  	0.09839344  
2023-05-25 19:53:20.417: Find a better model.
2023-05-25 19:53:27.431: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 7.013037]
2023-05-25 19:53:27.580: epoch 62:	0.02481006  	0.18312673  	0.09868816  
2023-05-25 19:53:27.580: Find a better model.
2023-05-25 19:53:34.461: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 6.879004]
2023-05-25 19:53:34.628: epoch 63:	0.02488768  	0.18381262  	0.09919062  
2023-05-25 19:53:34.628: Find a better model.
2023-05-25 19:53:41.633: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 7.003993]
2023-05-25 19:53:41.784: epoch 64:	0.02495824  	0.18446131  	0.09954022  
2023-05-25 19:53:41.784: Find a better model.
2023-05-25 19:53:48.683: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 6.896993]
2023-05-25 19:53:48.851: epoch 65:	0.02497941  	0.18466701  	0.09981101  
2023-05-25 19:53:48.851: Find a better model.
2023-05-25 19:53:55.654: [iter 66 : loss : 0.1546 = 0.0634 + 0.0871 + 0.0041, time: 6.800530]
2023-05-25 19:53:55.808: epoch 66:	0.02507115  	0.18548362  	0.10038882  
2023-05-25 19:53:55.808: Find a better model.
2023-05-25 19:54:02.646: [iter 67 : loss : 0.1530 = 0.0620 + 0.0869 + 0.0041, time: 6.836080]
2023-05-25 19:54:02.797: epoch 67:	0.02502881  	0.18526797  	0.10035633  
2023-05-25 19:54:09.649: [iter 68 : loss : 0.1528 = 0.0619 + 0.0868 + 0.0042, time: 6.850993]
2023-05-25 19:54:09.798: epoch 68:	0.02519111  	0.18643436  	0.10077632  
2023-05-25 19:54:09.798: Find a better model.
2023-05-25 19:54:16.836: [iter 69 : loss : 0.1509 = 0.0601 + 0.0866 + 0.0042, time: 7.034993]
2023-05-25 19:54:16.989: epoch 69:	0.02516288  	0.18631551  	0.10098260  
2023-05-25 19:54:23.855: [iter 70 : loss : 0.1495 = 0.0587 + 0.0865 + 0.0042, time: 6.865380]
2023-05-25 19:54:24.005: epoch 70:	0.02523344  	0.18660460  	0.10145098  
2023-05-25 19:54:24.005: Find a better model.
2023-05-25 19:54:30.877: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.870007]
2023-05-25 19:54:31.026: epoch 71:	0.02531812  	0.18727782  	0.10195889  
2023-05-25 19:54:31.026: Find a better model.
2023-05-25 19:54:37.833: [iter 72 : loss : 0.1477 = 0.0571 + 0.0863 + 0.0043, time: 6.805437]
2023-05-25 19:54:37.983: epoch 72:	0.02538869  	0.18807590  	0.10220618  
2023-05-25 19:54:37.984: Find a better model.
2023-05-25 19:54:44.859: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 6.873066]
2023-05-25 19:54:45.021: epoch 73:	0.02545925  	0.18872808  	0.10251085  
2023-05-25 19:54:45.021: Find a better model.
2023-05-25 19:54:51.835: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.813024]
2023-05-25 19:54:51.983: epoch 74:	0.02548042  	0.18868677  	0.10271636  
2023-05-25 19:54:58.842: [iter 75 : loss : 0.1444 = 0.0540 + 0.0859 + 0.0044, time: 6.858232]
2023-05-25 19:54:58.992: epoch 75:	0.02556510  	0.18946289  	0.10317285  
2023-05-25 19:54:58.992: Find a better model.
2023-05-25 19:55:05.846: [iter 76 : loss : 0.1433 = 0.0531 + 0.0858 + 0.0045, time: 6.853000]
2023-05-25 19:55:06.011: epoch 76:	0.02560038  	0.18970564  	0.10328311  
2023-05-25 19:55:06.011: Find a better model.
2023-05-25 19:55:12.863: [iter 77 : loss : 0.1425 = 0.0523 + 0.0857 + 0.0045, time: 6.851023]
2023-05-25 19:55:13.013: epoch 77:	0.02567094  	0.19011462  	0.10350730  
2023-05-25 19:55:13.013: Find a better model.
2023-05-25 19:55:19.850: [iter 78 : loss : 0.1416 = 0.0515 + 0.0856 + 0.0046, time: 6.834001]
2023-05-25 19:55:19.998: epoch 78:	0.02574150  	0.19066168  	0.10367940  
2023-05-25 19:55:19.998: Find a better model.
2023-05-25 19:55:27.003: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 7.003048]
2023-05-25 19:55:27.171: epoch 79:	0.02573445  	0.19034639  	0.10359398  
2023-05-25 19:55:34.031: [iter 80 : loss : 0.1398 = 0.0498 + 0.0854 + 0.0047, time: 6.859019]
2023-05-25 19:55:34.187: epoch 80:	0.02576267  	0.19061306  	0.10380425  
2023-05-25 19:55:41.038: [iter 81 : loss : 0.1394 = 0.0494 + 0.0853 + 0.0047, time: 6.849993]
2023-05-25 19:55:41.190: epoch 81:	0.02581206  	0.19129217  	0.10394937  
2023-05-25 19:55:41.191: Find a better model.
2023-05-25 19:55:48.010: [iter 82 : loss : 0.1381 = 0.0482 + 0.0852 + 0.0047, time: 6.818009]
2023-05-25 19:55:48.160: epoch 82:	0.02588968  	0.19186099  	0.10441563  
2023-05-25 19:55:48.160: Find a better model.
2023-05-25 19:55:55.037: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 6.875993]
2023-05-25 19:55:55.185: epoch 83:	0.02589674  	0.19197303  	0.10463911  
2023-05-25 19:55:55.185: Find a better model.
2023-05-25 19:56:02.001: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 6.815000]
2023-05-25 19:56:02.152: epoch 84:	0.02598847  	0.19260970  	0.10494372  
2023-05-25 19:56:02.152: Find a better model.
2023-05-25 19:56:09.006: [iter 85 : loss : 0.1363 = 0.0465 + 0.0849 + 0.0048, time: 6.853009]
2023-05-25 19:56:09.156: epoch 85:	0.02592497  	0.19215833  	0.10494842  
2023-05-25 19:56:16.008: [iter 86 : loss : 0.1359 = 0.0463 + 0.0847 + 0.0049, time: 6.851001]
2023-05-25 19:56:16.160: epoch 86:	0.02598143  	0.19277029  	0.10522211  
2023-05-25 19:56:16.161: Find a better model.
2023-05-25 19:56:23.017: [iter 87 : loss : 0.1333 = 0.0437 + 0.0847 + 0.0049, time: 6.855335]
2023-05-25 19:56:23.185: epoch 87:	0.02600259  	0.19281523  	0.10557290  
2023-05-25 19:56:23.185: Find a better model.
2023-05-25 19:56:30.006: [iter 88 : loss : 0.1327 = 0.0431 + 0.0846 + 0.0050, time: 6.820000]
2023-05-25 19:56:30.156: epoch 88:	0.02608021  	0.19335964  	0.10570078  
2023-05-25 19:56:30.156: Find a better model.
2023-05-25 19:56:37.011: [iter 89 : loss : 0.1325 = 0.0430 + 0.0845 + 0.0050, time: 6.852103]
2023-05-25 19:56:37.161: epoch 89:	0.02601670  	0.19314606  	0.10563821  
2023-05-25 19:56:43.997: [iter 90 : loss : 0.1330 = 0.0436 + 0.0844 + 0.0050, time: 6.833257]
2023-05-25 19:56:44.146: epoch 90:	0.02608021  	0.19369593  	0.10580257  
2023-05-25 19:56:44.146: Find a better model.
2023-05-25 19:56:51.001: [iter 91 : loss : 0.1316 = 0.0422 + 0.0843 + 0.0051, time: 6.854033]
2023-05-25 19:56:51.160: epoch 91:	0.02613666  	0.19393452  	0.10598397  
2023-05-25 19:56:51.161: Find a better model.
2023-05-25 19:56:57.968: [iter 92 : loss : 0.1306 = 0.0413 + 0.0842 + 0.0051, time: 6.805038]
2023-05-25 19:56:58.115: epoch 92:	0.02618606  	0.19441809  	0.10616513  
2023-05-25 19:56:58.116: Find a better model.
2023-05-25 19:57:04.981: [iter 93 : loss : 0.1313 = 0.0420 + 0.0842 + 0.0052, time: 6.863046]
2023-05-25 19:57:05.133: epoch 93:	0.02623546  	0.19497511  	0.10626277  
2023-05-25 19:57:05.133: Find a better model.
2023-05-25 19:57:11.968: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 6.834342]
2023-05-25 19:57:12.121: epoch 94:	0.02620018  	0.19489855  	0.10620005  
2023-05-25 19:57:19.001: [iter 95 : loss : 0.1284 = 0.0391 + 0.0840 + 0.0052, time: 6.879172]
2023-05-25 19:57:19.164: epoch 95:	0.02617195  	0.19487198  	0.10620668  
2023-05-25 19:57:25.973: [iter 96 : loss : 0.1285 = 0.0393 + 0.0839 + 0.0053, time: 6.806244]
2023-05-25 19:57:26.139: epoch 96:	0.02619311  	0.19467755  	0.10644942  
2023-05-25 19:57:32.990: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 6.849029]
2023-05-25 19:57:33.143: epoch 97:	0.02622840  	0.19518079  	0.10660832  
2023-05-25 19:57:33.143: Find a better model.
2023-05-25 19:57:39.965: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 6.821013]
2023-05-25 19:57:40.115: epoch 98:	0.02632013  	0.19588290  	0.10704506  
2023-05-25 19:57:40.115: Find a better model.
2023-05-25 19:57:46.962: [iter 99 : loss : 0.1265 = 0.0374 + 0.0837 + 0.0054, time: 6.846015]
2023-05-25 19:57:47.113: epoch 99:	0.02635542  	0.19627656  	0.10693970  
2023-05-25 19:57:47.113: Find a better model.
2023-05-25 19:57:53.975: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 6.861003]
2023-05-25 19:57:54.125: epoch 100:	0.02636247  	0.19631392  	0.10691092  
2023-05-25 19:57:54.125: Find a better model.
2023-05-25 19:58:00.972: [iter 101 : loss : 0.1256 = 0.0366 + 0.0836 + 0.0054, time: 6.846330]
2023-05-25 19:58:01.120: epoch 101:	0.02632719  	0.19566759  	0.10681876  
2023-05-25 19:58:07.955: [iter 102 : loss : 0.1246 = 0.0356 + 0.0835 + 0.0055, time: 6.833010]
2023-05-25 19:58:08.105: epoch 102:	0.02642598  	0.19613756  	0.10707492  
2023-05-25 19:58:14.949: [iter 103 : loss : 0.1244 = 0.0355 + 0.0834 + 0.0055, time: 6.842003]
2023-05-25 19:58:15.098: epoch 103:	0.02648949  	0.19622694  	0.10714813  
2023-05-25 19:58:21.944: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 6.845014]
2023-05-25 19:58:22.093: epoch 104:	0.02640481  	0.19519849  	0.10692021  
2023-05-25 19:58:28.949: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.855047]
2023-05-25 19:58:29.099: epoch 105:	0.02641892  	0.19555114  	0.10713213  
2023-05-25 19:58:35.938: [iter 106 : loss : 0.1236 = 0.0347 + 0.0833 + 0.0056, time: 6.838063]
2023-05-25 19:58:36.104: epoch 106:	0.02656005  	0.19645508  	0.10757197  
2023-05-25 19:58:36.104: Find a better model.
2023-05-25 19:58:42.967: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0056, time: 6.862014]
2023-05-25 19:58:43.116: epoch 107:	0.02656005  	0.19635367  	0.10745913  
2023-05-25 19:58:49.942: [iter 108 : loss : 0.1224 = 0.0336 + 0.0832 + 0.0057, time: 6.825003]
2023-05-25 19:58:50.095: epoch 108:	0.02657416  	0.19652186  	0.10756820  
2023-05-25 19:58:50.095: Find a better model.
2023-05-25 19:58:56.954: [iter 109 : loss : 0.1213 = 0.0325 + 0.0831 + 0.0057, time: 6.858025]
2023-05-25 19:58:57.104: epoch 109:	0.02656711  	0.19617960  	0.10755830  
2023-05-25 19:59:03.938: [iter 110 : loss : 0.1206 = 0.0318 + 0.0830 + 0.0058, time: 6.831991]
2023-05-25 19:59:04.088: epoch 110:	0.02651065  	0.19612138  	0.10760006  
2023-05-25 19:59:10.944: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 6.852134]
2023-05-25 19:59:11.107: epoch 111:	0.02654594  	0.19647519  	0.10772496  
2023-05-25 19:59:17.930: [iter 112 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0058, time: 6.822005]
2023-05-25 19:59:18.079: epoch 112:	0.02660239  	0.19702522  	0.10785513  
2023-05-25 19:59:18.079: Find a better model.
2023-05-25 19:59:24.963: [iter 113 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0059, time: 6.883003]
2023-05-25 19:59:25.112: epoch 113:	0.02663767  	0.19727741  	0.10817398  
2023-05-25 19:59:25.112: Find a better model.
2023-05-25 19:59:31.936: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 6.822192]
2023-05-25 19:59:32.088: epoch 114:	0.02661651  	0.19705419  	0.10808742  
2023-05-25 19:59:38.925: [iter 115 : loss : 0.1191 = 0.0305 + 0.0827 + 0.0059, time: 6.836004]
2023-05-25 19:59:39.092: epoch 115:	0.02657417  	0.19674611  	0.10792990  
2023-05-25 19:59:45.926: [iter 116 : loss : 0.1183 = 0.0296 + 0.0827 + 0.0060, time: 6.832034]
2023-05-25 19:59:46.078: epoch 116:	0.02660945  	0.19707255  	0.10800567  
2023-05-25 19:59:52.914: [iter 117 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 6.834005]
2023-05-25 19:59:53.066: epoch 117:	0.02668002  	0.19762407  	0.10819799  
2023-05-25 19:59:53.066: Find a better model.
2023-05-25 19:59:59.914: [iter 118 : loss : 0.1183 = 0.0297 + 0.0826 + 0.0060, time: 6.846004]
2023-05-25 20:00:00.067: epoch 118:	0.02669413  	0.19754297  	0.10818888  
2023-05-25 20:00:06.948: [iter 119 : loss : 0.1173 = 0.0288 + 0.0825 + 0.0061, time: 6.879057]
2023-05-25 20:00:07.114: epoch 119:	0.02668707  	0.19738537  	0.10818056  
2023-05-25 20:00:13.928: [iter 120 : loss : 0.1176 = 0.0291 + 0.0825 + 0.0061, time: 6.813005]
2023-05-25 20:00:14.082: epoch 120:	0.02672235  	0.19749366  	0.10839781  
2023-05-25 20:00:20.921: [iter 121 : loss : 0.1174 = 0.0289 + 0.0824 + 0.0061, time: 6.838066]
2023-05-25 20:00:21.072: epoch 121:	0.02668707  	0.19726904  	0.10826670  
2023-05-25 20:00:27.917: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.843024]
2023-05-25 20:00:28.068: epoch 122:	0.02670825  	0.19734034  	0.10841158  
2023-05-25 20:00:34.893: [iter 123 : loss : 0.1165 = 0.0280 + 0.0823 + 0.0062, time: 6.823056]
2023-05-25 20:00:35.042: epoch 123:	0.02670119  	0.19713353  	0.10848255  
2023-05-25 20:00:41.907: [iter 124 : loss : 0.1157 = 0.0272 + 0.0823 + 0.0062, time: 6.864015]
2023-05-25 20:00:42.074: epoch 124:	0.02673646  	0.19710015  	0.10868273  
2023-05-25 20:00:48.924: [iter 125 : loss : 0.1149 = 0.0264 + 0.0822 + 0.0062, time: 6.848003]
2023-05-25 20:00:49.073: epoch 125:	0.02675058  	0.19731531  	0.10872910  
2023-05-25 20:00:55.917: [iter 126 : loss : 0.1153 = 0.0269 + 0.0822 + 0.0063, time: 6.841769]
2023-05-25 20:00:56.082: epoch 126:	0.02676470  	0.19782312  	0.10896057  
2023-05-25 20:00:56.083: Find a better model.
2023-05-25 20:01:02.918: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.833900]
2023-05-25 20:01:03.078: epoch 127:	0.02675058  	0.19742669  	0.10889345  
2023-05-25 20:01:09.914: [iter 128 : loss : 0.1155 = 0.0270 + 0.0821 + 0.0063, time: 6.834055]
2023-05-25 20:01:10.065: epoch 128:	0.02675058  	0.19743726  	0.10896354  
2023-05-25 20:01:16.907: [iter 129 : loss : 0.1144 = 0.0260 + 0.0821 + 0.0064, time: 6.840994]
2023-05-25 20:01:17.074: epoch 129:	0.02671530  	0.19726166  	0.10889328  
2023-05-25 20:01:23.917: [iter 130 : loss : 0.1146 = 0.0262 + 0.0820 + 0.0064, time: 6.841041]
2023-05-25 20:01:24.082: epoch 130:	0.02682114  	0.19811395  	0.10917456  
2023-05-25 20:01:24.082: Find a better model.
2023-05-25 20:01:30.907: [iter 131 : loss : 0.1136 = 0.0253 + 0.0820 + 0.0064, time: 6.823017]
2023-05-25 20:01:31.056: epoch 131:	0.02683525  	0.19802721  	0.10918777  
2023-05-25 20:01:37.887: [iter 132 : loss : 0.1139 = 0.0255 + 0.0819 + 0.0065, time: 6.828988]
2023-05-25 20:01:38.054: epoch 132:	0.02687054  	0.19835101  	0.10923808  
2023-05-25 20:01:38.054: Find a better model.
2023-05-25 20:01:44.890: [iter 133 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0065, time: 6.835016]
2023-05-25 20:01:45.059: epoch 133:	0.02689876  	0.19843820  	0.10928484  
2023-05-25 20:01:45.059: Find a better model.
2023-05-25 20:01:51.891: [iter 134 : loss : 0.1134 = 0.0250 + 0.0818 + 0.0065, time: 6.831004]
2023-05-25 20:01:52.045: epoch 134:	0.02682113  	0.19781464  	0.10920998  
2023-05-25 20:01:58.876: [iter 135 : loss : 0.1132 = 0.0248 + 0.0818 + 0.0065, time: 6.830016]
2023-05-25 20:01:59.027: epoch 135:	0.02679996  	0.19743317  	0.10915659  
2023-05-25 20:02:05.879: [iter 136 : loss : 0.1127 = 0.0244 + 0.0818 + 0.0066, time: 6.850061]
2023-05-25 20:02:06.046: epoch 136:	0.02680702  	0.19741346  	0.10907158  
2023-05-25 20:02:12.880: [iter 137 : loss : 0.1124 = 0.0241 + 0.0817 + 0.0066, time: 6.832009]
2023-05-25 20:02:13.028: epoch 137:	0.02684231  	0.19755076  	0.10909368  
2023-05-25 20:02:19.860: [iter 138 : loss : 0.1122 = 0.0238 + 0.0817 + 0.0066, time: 6.830004]
2023-05-25 20:02:20.013: epoch 138:	0.02684937  	0.19747581  	0.10916671  
2023-05-25 20:02:26.875: [iter 139 : loss : 0.1119 = 0.0236 + 0.0816 + 0.0067, time: 6.861003]
2023-05-25 20:02:27.028: epoch 139:	0.02688465  	0.19799574  	0.10925320  
2023-05-25 20:02:33.871: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.842035]
2023-05-25 20:02:34.022: epoch 140:	0.02684936  	0.19788514  	0.10930970  
2023-05-25 20:02:40.878: [iter 141 : loss : 0.1118 = 0.0236 + 0.0816 + 0.0067, time: 6.854035]
2023-05-25 20:02:41.045: epoch 141:	0.02695521  	0.19868292  	0.10959685  
2023-05-25 20:02:41.045: Find a better model.
2023-05-25 20:02:47.858: [iter 142 : loss : 0.1109 = 0.0227 + 0.0815 + 0.0067, time: 6.811006]
2023-05-25 20:02:48.007: epoch 142:	0.02687054  	0.19848707  	0.10969986  
2023-05-25 20:02:54.699: [iter 143 : loss : 0.1110 = 0.0228 + 0.0815 + 0.0068, time: 6.691013]
2023-05-25 20:02:54.856: epoch 143:	0.02689876  	0.19861355  	0.10971859  
2023-05-25 20:03:01.647: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.789024]
2023-05-25 20:03:01.796: epoch 144:	0.02690581  	0.19868302  	0.10971556  
2023-05-25 20:03:01.796: Find a better model.
2023-05-25 20:03:08.659: [iter 145 : loss : 0.1103 = 0.0221 + 0.0814 + 0.0068, time: 6.862149]
2023-05-25 20:03:08.833: epoch 145:	0.02685641  	0.19818451  	0.10944551  
2023-05-25 20:03:15.649: [iter 146 : loss : 0.1108 = 0.0225 + 0.0814 + 0.0068, time: 6.813999]
2023-05-25 20:03:15.820: epoch 146:	0.02691992  	0.19859028  	0.10962114  
2023-05-25 20:03:22.666: [iter 147 : loss : 0.1105 = 0.0223 + 0.0814 + 0.0069, time: 6.843017]
2023-05-25 20:03:22.821: epoch 147:	0.02696226  	0.19909973  	0.10974038  
2023-05-25 20:03:22.821: Find a better model.
2023-05-25 20:03:29.626: [iter 148 : loss : 0.1094 = 0.0211 + 0.0813 + 0.0069, time: 6.804024]
2023-05-25 20:03:29.776: epoch 148:	0.02691992  	0.19868979  	0.10961661  
2023-05-25 20:03:36.663: [iter 149 : loss : 0.1098 = 0.0215 + 0.0813 + 0.0069, time: 6.884023]
2023-05-25 20:03:36.818: epoch 149:	0.02693404  	0.19895120  	0.10959475  
2023-05-25 20:03:43.643: [iter 150 : loss : 0.1090 = 0.0207 + 0.0813 + 0.0070, time: 6.824002]
2023-05-25 20:03:43.793: epoch 150:	0.02695521  	0.19879605  	0.10966691  
2023-05-25 20:03:50.622: [iter 151 : loss : 0.1092 = 0.0210 + 0.0812 + 0.0070, time: 6.828014]
2023-05-25 20:03:50.771: epoch 151:	0.02691287  	0.19839804  	0.10970254  
2023-05-25 20:03:57.636: [iter 152 : loss : 0.1086 = 0.0203 + 0.0812 + 0.0070, time: 6.864025]
2023-05-25 20:03:57.786: epoch 152:	0.02687759  	0.19815499  	0.10961009  
2023-05-25 20:04:04.638: [iter 153 : loss : 0.1078 = 0.0196 + 0.0812 + 0.0070, time: 6.851016]
2023-05-25 20:04:04.812: epoch 153:	0.02688464  	0.19818686  	0.10952248  
2023-05-25 20:04:11.656: [iter 154 : loss : 0.1083 = 0.0200 + 0.0811 + 0.0071, time: 6.842004]
2023-05-25 20:04:11.829: epoch 154:	0.02689171  	0.19832957  	0.10966832  
2023-05-25 20:04:18.653: [iter 155 : loss : 0.1091 = 0.0209 + 0.0811 + 0.0071, time: 6.822018]
2023-05-25 20:04:18.807: epoch 155:	0.02689171  	0.19864722  	0.10963609  
2023-05-25 20:04:25.618: [iter 156 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.809004]
2023-05-25 20:04:25.768: epoch 156:	0.02686348  	0.19809021  	0.10944910  
2023-05-25 20:04:32.620: [iter 157 : loss : 0.1080 = 0.0198 + 0.0811 + 0.0071, time: 6.850019]
2023-05-25 20:04:32.774: epoch 157:	0.02688465  	0.19807652  	0.10951892  
2023-05-25 20:04:39.431: [iter 158 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.654510]
2023-05-25 20:04:39.580: epoch 158:	0.02689170  	0.19803925  	0.10939914  
2023-05-25 20:04:46.249: [iter 159 : loss : 0.1077 = 0.0196 + 0.0810 + 0.0072, time: 6.667041]
2023-05-25 20:04:46.418: epoch 159:	0.02685642  	0.19782066  	0.10931858  
2023-05-25 20:04:53.199: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.780017]
2023-05-25 20:04:53.351: epoch 160:	0.02686347  	0.19767210  	0.10939603  
2023-05-25 20:05:00.058: [iter 161 : loss : 0.1069 = 0.0188 + 0.0809 + 0.0072, time: 6.703032]
2023-05-25 20:05:00.209: epoch 161:	0.02673646  	0.19691475  	0.10913499  
2023-05-25 20:05:07.018: [iter 162 : loss : 0.1063 = 0.0181 + 0.0809 + 0.0073, time: 6.808094]
2023-05-25 20:05:07.188: epoch 162:	0.02677880  	0.19704200  	0.10927297  
2023-05-25 20:05:14.017: [iter 163 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 6.827985]
2023-05-25 20:05:14.185: epoch 163:	0.02674352  	0.19672020  	0.10902116  
2023-05-25 20:05:21.035: [iter 164 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 6.848006]
2023-05-25 20:05:21.206: epoch 164:	0.02678585  	0.19696063  	0.10910699  
2023-05-25 20:05:28.034: [iter 165 : loss : 0.1063 = 0.0181 + 0.0808 + 0.0073, time: 6.826039]
2023-05-25 20:05:28.203: epoch 165:	0.02673645  	0.19672650  	0.10907187  
2023-05-25 20:05:35.004: [iter 166 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 6.800005]
2023-05-25 20:05:35.156: epoch 166:	0.02676468  	0.19703035  	0.10903782  
2023-05-25 20:05:41.860: [iter 167 : loss : 0.1065 = 0.0183 + 0.0808 + 0.0074, time: 6.703464]
2023-05-25 20:05:42.026: epoch 167:	0.02668000  	0.19600895  	0.10905457  
2023-05-25 20:05:48.813: [iter 168 : loss : 0.1060 = 0.0178 + 0.0808 + 0.0074, time: 6.785015]
2023-05-25 20:05:48.971: epoch 168:	0.02678585  	0.19689998  	0.10899168  
2023-05-25 20:05:55.793: [iter 169 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0074, time: 6.820005]
2023-05-25 20:05:55.947: epoch 169:	0.02677879  	0.19672625  	0.10901497  
2023-05-25 20:06:02.814: [iter 170 : loss : 0.1058 = 0.0176 + 0.0807 + 0.0075, time: 6.866019]
2023-05-25 20:06:02.964: epoch 170:	0.02671529  	0.19623190  	0.10879979  
2023-05-25 20:06:09.801: [iter 171 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0075, time: 6.835006]
2023-05-25 20:06:09.954: epoch 171:	0.02675057  	0.19638146  	0.10898226  
2023-05-25 20:06:16.793: [iter 172 : loss : 0.1051 = 0.0169 + 0.0807 + 0.0075, time: 6.838004]
2023-05-25 20:06:16.945: epoch 172:	0.02668000  	0.19594163  	0.10885426  
2023-05-25 20:06:16.945: Early stopping is trigger at epoch: 172
2023-05-25 20:06:16.945: best_result@epoch 147:

2023-05-25 20:06:16.946: 		0.0270      	0.1991      	0.1097      
2023-05-25 20:14:04.306: my pid: 8568
2023-05-25 20:14:04.306: model: model.general_recommender.SGL
2023-05-25 20:14:04.306: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 20:14:04.306: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 20:14:08.024: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 20:14:15.469: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.445030]
2023-05-25 20:14:15.618: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-25 20:14:15.618: Find a better model.
2023-05-25 20:14:23.058: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.437971]
2023-05-25 20:14:23.274: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-25 20:14:23.274: Find a better model.
2023-05-25 20:14:30.663: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.387968]
2023-05-25 20:14:30.829: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-25 20:14:30.829: Find a better model.
2023-05-25 20:14:38.032: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.199016]
2023-05-25 20:14:38.184: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-25 20:14:38.184: Find a better model.
2023-05-25 20:14:45.234: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.048011]
2023-05-25 20:14:45.380: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-25 20:14:45.380: Find a better model.
2023-05-25 20:14:52.203: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.822004]
2023-05-25 20:14:52.352: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-25 20:14:52.352: Find a better model.
2023-05-25 20:14:59.185: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.831013]
2023-05-25 20:14:59.347: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-25 20:14:59.347: Find a better model.
2023-05-25 20:15:06.019: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.669021]
2023-05-25 20:15:06.173: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-25 20:15:06.173: Find a better model.
2023-05-25 20:15:12.824: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.650529]
2023-05-25 20:15:12.974: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-25 20:15:19.604: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.629088]
2023-05-25 20:15:19.751: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-25 20:15:26.400: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.647101]
2023-05-25 20:15:26.548: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-25 20:15:33.177: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.628322]
2023-05-25 20:15:33.327: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-25 20:15:39.993: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.664014]
2023-05-25 20:15:40.143: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-25 20:15:46.799: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.654994]
2023-05-25 20:15:46.950: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-25 20:15:53.597: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.644455]
2023-05-25 20:15:53.745: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-25 20:15:53.745: Find a better model.
2023-05-25 20:16:00.383: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.636006]
2023-05-25 20:16:00.529: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-25 20:16:00.529: Find a better model.
2023-05-25 20:16:07.185: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.655022]
2023-05-25 20:16:07.334: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-25 20:16:07.334: Find a better model.
2023-05-25 20:16:13.986: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.649417]
2023-05-25 20:16:14.133: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-25 20:16:14.134: Find a better model.
2023-05-25 20:16:20.777: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.641024]
2023-05-25 20:16:20.927: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-25 20:16:20.927: Find a better model.
2023-05-25 20:16:27.380: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.451046]
2023-05-25 20:16:27.529: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-25 20:16:27.530: Find a better model.
2023-05-25 20:16:34.155: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.624012]
2023-05-25 20:16:34.304: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-25 20:16:34.304: Find a better model.
2023-05-25 20:16:40.981: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.676029]
2023-05-25 20:16:41.131: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-25 20:16:41.131: Find a better model.
2023-05-25 20:16:47.772: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.639014]
2023-05-25 20:16:47.931: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-25 20:16:47.931: Find a better model.
2023-05-25 20:16:54.591: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.658017]
2023-05-25 20:16:54.740: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-25 20:16:54.740: Find a better model.
2023-05-25 20:17:01.355: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.614247]
2023-05-25 20:17:01.505: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-25 20:17:01.505: Find a better model.
2023-05-25 20:17:08.176: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.669012]
2023-05-25 20:17:08.342: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-25 20:17:08.342: Find a better model.
2023-05-25 20:17:14.970: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.627020]
2023-05-25 20:17:15.118: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-25 20:17:15.118: Find a better model.
2023-05-25 20:17:21.934: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.813999]
2023-05-25 20:17:22.086: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-25 20:17:22.086: Find a better model.
2023-05-25 20:17:28.756: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.669048]
2023-05-25 20:17:28.906: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-25 20:17:28.906: Find a better model.
2023-05-25 20:17:35.543: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.634994]
2023-05-25 20:17:35.691: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-25 20:17:35.691: Find a better model.
2023-05-25 20:17:42.369: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.675379]
2023-05-25 20:17:42.518: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-25 20:17:42.518: Find a better model.
2023-05-25 20:17:49.159: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.639001]
2023-05-25 20:17:49.307: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-25 20:17:49.307: Find a better model.
2023-05-25 20:17:55.953: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.643994]
2023-05-25 20:17:56.104: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-25 20:17:56.104: Find a better model.
2023-05-25 20:18:02.923: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.818001]
2023-05-25 20:18:03.071: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-25 20:18:03.071: Find a better model.
2023-05-25 20:18:09.752: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.680014]
2023-05-25 20:18:09.912: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-25 20:18:09.912: Find a better model.
2023-05-25 20:18:16.544: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.631007]
2023-05-25 20:18:16.692: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-25 20:18:16.692: Find a better model.
2023-05-25 20:18:23.337: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.643110]
2023-05-25 20:18:23.489: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-25 20:18:23.489: Find a better model.
2023-05-25 20:18:30.137: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.646994]
2023-05-25 20:18:30.289: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-25 20:18:30.289: Find a better model.
2023-05-25 20:18:37.121: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.831042]
2023-05-25 20:18:37.271: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-25 20:18:37.271: Find a better model.
2023-05-25 20:18:44.108: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.836460]
2023-05-25 20:18:44.274: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-25 20:18:50.940: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.664998]
2023-05-25 20:18:51.088: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-25 20:18:51.088: Find a better model.
2023-05-25 20:18:57.730: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.641078]
2023-05-25 20:18:57.885: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-25 20:18:57.885: Find a better model.
2023-05-25 20:19:04.696: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.809993]
2023-05-25 20:19:04.852: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-25 20:19:04.853: Find a better model.
2023-05-25 20:19:11.535: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.680920]
2023-05-25 20:19:11.683: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-25 20:19:11.683: Find a better model.
2023-05-25 20:19:18.324: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.640259]
2023-05-25 20:19:18.475: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-25 20:19:18.475: Find a better model.
2023-05-25 20:19:25.118: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.640336]
2023-05-25 20:19:25.280: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-25 20:19:25.280: Find a better model.
2023-05-25 20:19:31.911: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.629997]
2023-05-25 20:19:32.060: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-25 20:19:32.061: Find a better model.
2023-05-25 20:19:38.703: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.641012]
2023-05-25 20:19:38.858: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-25 20:19:38.858: Find a better model.
2023-05-25 20:19:45.488: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.629007]
2023-05-25 20:19:45.639: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-25 20:19:45.639: Find a better model.
2023-05-25 20:19:52.309: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.668882]
2023-05-25 20:19:52.456: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-25 20:19:52.456: Find a better model.
2023-05-25 20:19:59.113: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.655266]
2023-05-25 20:19:59.263: epoch 51:	0.02399858  	0.17744949  	0.09439241  
2023-05-25 20:20:06.090: [iter 52 : loss : 0.1776 = 0.0841 + 0.0901 + 0.0034, time: 6.824754]
2023-05-25 20:20:06.237: epoch 52:	0.02410442  	0.17821886  	0.09495795  
2023-05-25 20:20:06.237: Find a better model.
2023-05-25 20:20:13.074: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.833999]
2023-05-25 20:20:13.238: epoch 53:	0.02419615  	0.17914237  	0.09549850  
2023-05-25 20:20:13.238: Find a better model.
2023-05-25 20:20:20.088: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.848173]
2023-05-25 20:20:20.256: epoch 54:	0.02428788  	0.18013717  	0.09606101  
2023-05-25 20:20:20.256: Find a better model.
2023-05-25 20:20:27.081: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.824457]
2023-05-25 20:20:27.232: epoch 55:	0.02432316  	0.18041351  	0.09617996  
2023-05-25 20:20:27.232: Find a better model.
2023-05-25 20:20:34.099: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.865941]
2023-05-25 20:20:34.265: epoch 56:	0.02442195  	0.18121195  	0.09663617  
2023-05-25 20:20:34.265: Find a better model.
2023-05-25 20:20:41.122: [iter 57 : loss : 0.1679 = 0.0751 + 0.0891 + 0.0036, time: 6.854351]
2023-05-25 20:20:41.270: epoch 57:	0.02448546  	0.18160756  	0.09683716  
2023-05-25 20:20:41.270: Find a better model.
2023-05-25 20:20:48.087: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.813994]
2023-05-25 20:20:48.237: epoch 58:	0.02457719  	0.18282667  	0.09742414  
2023-05-25 20:20:48.237: Find a better model.
2023-05-25 20:20:55.078: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.839999]
2023-05-25 20:20:55.226: epoch 59:	0.02462659  	0.18288851  	0.09757956  
2023-05-25 20:20:55.226: Find a better model.
2023-05-25 20:21:02.075: [iter 60 : loss : 0.1636 = 0.0712 + 0.0886 + 0.0038, time: 6.848080]
2023-05-25 20:21:02.241: epoch 60:	0.02465482  	0.18319421  	0.09799483  
2023-05-25 20:21:02.241: Find a better model.
2023-05-25 20:21:09.073: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.830063]
2023-05-25 20:21:09.220: epoch 61:	0.02471127  	0.18349673  	0.09829111  
2023-05-25 20:21:09.220: Find a better model.
2023-05-25 20:21:16.052: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.831036]
2023-05-25 20:21:16.199: epoch 62:	0.02479595  	0.18397142  	0.09872374  
2023-05-25 20:21:16.199: Find a better model.
2023-05-25 20:21:23.065: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.864006]
2023-05-25 20:21:23.213: epoch 63:	0.02482417  	0.18390447  	0.09891205  
2023-05-25 20:21:30.050: [iter 64 : loss : 0.1583 = 0.0664 + 0.0879 + 0.0040, time: 6.834012]
2023-05-25 20:21:30.197: epoch 64:	0.02492296  	0.18457001  	0.09919607  
2023-05-25 20:21:30.198: Find a better model.
2023-05-25 20:21:36.889: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.690003]
2023-05-25 20:21:37.050: epoch 65:	0.02497236  	0.18481568  	0.09988973  
2023-05-25 20:21:37.050: Find a better model.
2023-05-25 20:21:43.845: [iter 66 : loss : 0.1555 = 0.0638 + 0.0876 + 0.0040, time: 6.794016]
2023-05-25 20:21:43.994: epoch 66:	0.02510643  	0.18578339  	0.10042768  
2023-05-25 20:21:43.994: Find a better model.
2023-05-25 20:21:50.842: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.846006]
2023-05-25 20:21:50.988: epoch 67:	0.02514171  	0.18596944  	0.10078032  
2023-05-25 20:21:50.988: Find a better model.
2023-05-25 20:21:57.862: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.873018]
2023-05-25 20:21:58.027: epoch 68:	0.02526873  	0.18671282  	0.10106254  
2023-05-25 20:21:58.027: Find a better model.
2023-05-25 20:22:04.852: [iter 69 : loss : 0.1519 = 0.0604 + 0.0872 + 0.0042, time: 6.824033]
2023-05-25 20:22:05.001: epoch 69:	0.02526167  	0.18681890  	0.10116343  
2023-05-25 20:22:05.002: Find a better model.
2023-05-25 20:22:11.862: [iter 70 : loss : 0.1502 = 0.0589 + 0.0871 + 0.0042, time: 6.858993]
2023-05-25 20:22:12.028: epoch 70:	0.02542397  	0.18775471  	0.10162742  
2023-05-25 20:22:12.028: Find a better model.
2023-05-25 20:22:18.844: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.814019]
2023-05-25 20:22:19.009: epoch 71:	0.02545219  	0.18776338  	0.10187343  
2023-05-25 20:22:19.009: Find a better model.
2023-05-25 20:22:25.823: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.812016]
2023-05-25 20:22:25.973: epoch 72:	0.02542397  	0.18779665  	0.10200806  
2023-05-25 20:22:25.973: Find a better model.
2023-05-25 20:22:32.825: [iter 73 : loss : 0.1473 = 0.0562 + 0.0867 + 0.0043, time: 6.850003]
2023-05-25 20:22:32.980: epoch 73:	0.02548748  	0.18822598  	0.10244584  
2023-05-25 20:22:32.980: Find a better model.
2023-05-25 20:22:39.826: [iter 74 : loss : 0.1459 = 0.0549 + 0.0867 + 0.0044, time: 6.845379]
2023-05-25 20:22:39.994: epoch 74:	0.02550864  	0.18809420  	0.10254635  
2023-05-25 20:22:46.817: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.821003]
2023-05-25 20:22:46.965: epoch 75:	0.02547336  	0.18788670  	0.10256235  
2023-05-25 20:22:53.836: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.870046]
2023-05-25 20:22:53.987: epoch 76:	0.02557215  	0.18857168  	0.10300840  
2023-05-25 20:22:53.987: Find a better model.
2023-05-25 20:23:00.646: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.657982]
2023-05-25 20:23:00.795: epoch 77:	0.02564272  	0.18906085  	0.10317964  
2023-05-25 20:23:00.795: Find a better model.
2023-05-25 20:23:07.619: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.823073]
2023-05-25 20:23:07.768: epoch 78:	0.02568506  	0.18941851  	0.10334965  
2023-05-25 20:23:07.768: Find a better model.
2023-05-25 20:23:14.630: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.861197]
2023-05-25 20:23:14.778: epoch 79:	0.02567094  	0.18933600  	0.10335872  
2023-05-25 20:23:21.438: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.658971]
2023-05-25 20:23:21.590: epoch 80:	0.02574856  	0.18999065  	0.10368081  
2023-05-25 20:23:21.590: Find a better model.
2023-05-25 20:23:28.422: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.829994]
2023-05-25 20:23:28.584: epoch 81:	0.02576268  	0.19007890  	0.10377019  
2023-05-25 20:23:28.584: Find a better model.
2023-05-25 20:23:35.237: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.650993]
2023-05-25 20:23:35.385: epoch 82:	0.02593909  	0.19141515  	0.10441577  
2023-05-25 20:23:35.385: Find a better model.
2023-05-25 20:23:42.222: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.835994]
2023-05-25 20:23:42.369: epoch 83:	0.02591087  	0.19119224  	0.10436522  
2023-05-25 20:23:49.022: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.650876]
2023-05-25 20:23:49.169: epoch 84:	0.02591087  	0.19124350  	0.10439318  
2023-05-25 20:23:55.819: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.648292]
2023-05-25 20:23:55.968: epoch 85:	0.02592499  	0.19143361  	0.10479315  
2023-05-25 20:23:55.968: Find a better model.
2023-05-25 20:24:02.800: [iter 86 : loss : 0.1368 = 0.0466 + 0.0853 + 0.0049, time: 6.829209]
2023-05-25 20:24:02.950: epoch 86:	0.02599555  	0.19190833  	0.10493799  
2023-05-25 20:24:02.950: Find a better model.
2023-05-25 20:24:09.624: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.672029]
2023-05-25 20:24:09.786: epoch 87:	0.02606612  	0.19223826  	0.10507970  
2023-05-25 20:24:09.786: Find a better model.
2023-05-25 20:24:16.423: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.634998]
2023-05-25 20:24:16.586: epoch 88:	0.02611551  	0.19253215  	0.10516543  
2023-05-25 20:24:16.587: Find a better model.
2023-05-25 20:24:23.208: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.619891]
2023-05-25 20:24:23.356: epoch 89:	0.02606612  	0.19203798  	0.10502657  
2023-05-25 20:24:30.002: [iter 90 : loss : 0.1341 = 0.0440 + 0.0850 + 0.0050, time: 6.645001]
2023-05-25 20:24:30.152: epoch 90:	0.02620018  	0.19275653  	0.10539840  
2023-05-25 20:24:30.152: Find a better model.
2023-05-25 20:24:36.813: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.660260]
2023-05-25 20:24:36.962: epoch 91:	0.02622841  	0.19318554  	0.10559827  
2023-05-25 20:24:36.962: Find a better model.
2023-05-25 20:24:43.608: [iter 92 : loss : 0.1314 = 0.0415 + 0.0848 + 0.0051, time: 6.644994]
2023-05-25 20:24:43.758: epoch 92:	0.02627075  	0.19325422  	0.10572527  
2023-05-25 20:24:43.758: Find a better model.
2023-05-25 20:24:50.415: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.655093]
2023-05-25 20:24:50.580: epoch 93:	0.02629192  	0.19370896  	0.10595030  
2023-05-25 20:24:50.581: Find a better model.
2023-05-25 20:24:57.374: [iter 94 : loss : 0.1300 = 0.0402 + 0.0847 + 0.0052, time: 6.791996]
2023-05-25 20:24:57.525: epoch 94:	0.02638366  	0.19442128  	0.10628322  
2023-05-25 20:24:57.525: Find a better model.
2023-05-25 20:25:04.201: [iter 95 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.674993]
2023-05-25 20:25:04.367: epoch 95:	0.02633426  	0.19389038  	0.10621881  
2023-05-25 20:25:11.199: [iter 96 : loss : 0.1293 = 0.0395 + 0.0845 + 0.0052, time: 6.829000]
2023-05-25 20:25:11.363: epoch 96:	0.02633426  	0.19402470  	0.10638132  
2023-05-25 20:25:18.001: [iter 97 : loss : 0.1278 = 0.0381 + 0.0845 + 0.0053, time: 6.635885]
2023-05-25 20:25:18.164: epoch 97:	0.02639777  	0.19449547  	0.10645210  
2023-05-25 20:25:18.164: Find a better model.
2023-05-25 20:25:24.797: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.631004]
2023-05-25 20:25:24.952: epoch 98:	0.02648950  	0.19531241  	0.10683785  
2023-05-25 20:25:24.952: Find a better model.
2023-05-25 20:25:31.774: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 6.820993]
2023-05-25 20:25:31.926: epoch 99:	0.02655301  	0.19582823  	0.10704585  
2023-05-25 20:25:31.926: Find a better model.
2023-05-25 20:25:38.591: [iter 100 : loss : 0.1269 = 0.0373 + 0.0842 + 0.0054, time: 6.663013]
2023-05-25 20:25:38.743: epoch 100:	0.02659534  	0.19628014  	0.10699420  
2023-05-25 20:25:38.743: Find a better model.
2023-05-25 20:25:45.387: [iter 101 : loss : 0.1265 = 0.0369 + 0.0842 + 0.0054, time: 6.643014]
2023-05-25 20:25:45.535: epoch 101:	0.02661651  	0.19654712  	0.10716521  
2023-05-25 20:25:45.535: Find a better model.
2023-05-25 20:25:52.374: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0054, time: 6.837019]
2023-05-25 20:25:52.540: epoch 102:	0.02668002  	0.19673117  	0.10737451  
2023-05-25 20:25:52.540: Find a better model.
2023-05-25 20:25:59.186: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.643395]
2023-05-25 20:25:59.336: epoch 103:	0.02673648  	0.19722913  	0.10752133  
2023-05-25 20:25:59.336: Find a better model.
2023-05-25 20:26:06.159: [iter 104 : loss : 0.1257 = 0.0362 + 0.0840 + 0.0055, time: 6.822176]
2023-05-25 20:26:06.309: epoch 104:	0.02677882  	0.19766803  	0.10786368  
2023-05-25 20:26:06.309: Find a better model.
2023-05-25 20:26:13.146: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 6.836153]
2023-05-25 20:26:13.297: epoch 105:	0.02671530  	0.19733053  	0.10781404  
2023-05-25 20:26:20.152: [iter 106 : loss : 0.1245 = 0.0351 + 0.0839 + 0.0056, time: 6.853993]
2023-05-25 20:26:20.319: epoch 106:	0.02670825  	0.19687521  	0.10760348  
2023-05-25 20:26:27.160: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.839993]
2023-05-25 20:26:27.307: epoch 107:	0.02672941  	0.19690803  	0.10760050  
2023-05-25 20:26:34.137: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0056, time: 6.829054]
2023-05-25 20:26:34.285: epoch 108:	0.02675764  	0.19743097  	0.10780030  
2023-05-25 20:26:40.996: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.710256]
2023-05-25 20:26:41.164: epoch 109:	0.02679292  	0.19754675  	0.10779482  
2023-05-25 20:26:47.756: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.591005]
2023-05-25 20:26:47.910: epoch 110:	0.02684232  	0.19785625  	0.10786530  
2023-05-25 20:26:47.910: Find a better model.
2023-05-25 20:26:54.572: [iter 111 : loss : 0.1215 = 0.0322 + 0.0836 + 0.0058, time: 6.660012]
2023-05-25 20:26:54.735: epoch 111:	0.02684937  	0.19811195  	0.10795763  
2023-05-25 20:26:54.736: Find a better model.
2023-05-25 20:27:01.533: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.795300]
2023-05-25 20:27:01.682: epoch 112:	0.02690582  	0.19852194  	0.10813838  
2023-05-25 20:27:01.682: Find a better model.
2023-05-25 20:27:08.348: [iter 113 : loss : 0.1212 = 0.0319 + 0.0835 + 0.0058, time: 6.665024]
2023-05-25 20:27:08.497: epoch 113:	0.02694110  	0.19904543  	0.10828774  
2023-05-25 20:27:08.497: Find a better model.
2023-05-25 20:27:15.158: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.660671]
2023-05-25 20:27:15.323: epoch 114:	0.02699050  	0.19934446  	0.10847918  
2023-05-25 20:27:15.323: Find a better model.
2023-05-25 20:27:22.157: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.832003]
2023-05-25 20:27:22.321: epoch 115:	0.02698343  	0.19882178  	0.10852438  
2023-05-25 20:27:28.968: [iter 116 : loss : 0.1193 = 0.0300 + 0.0833 + 0.0059, time: 6.645003]
2023-05-25 20:27:29.130: epoch 116:	0.02692698  	0.19835888  	0.10836104  
2023-05-25 20:27:35.941: [iter 117 : loss : 0.1193 = 0.0301 + 0.0832 + 0.0060, time: 6.806993]
2023-05-25 20:27:36.089: epoch 117:	0.02691287  	0.19816273  	0.10819234  
2023-05-25 20:27:42.742: [iter 118 : loss : 0.1191 = 0.0299 + 0.0832 + 0.0060, time: 6.652013]
2023-05-25 20:27:42.893: epoch 118:	0.02698344  	0.19865434  	0.10842561  
2023-05-25 20:27:49.734: [iter 119 : loss : 0.1181 = 0.0289 + 0.0831 + 0.0060, time: 6.840014]
2023-05-25 20:27:49.885: epoch 119:	0.02692698  	0.19825359  	0.10852231  
2023-05-25 20:27:56.549: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0060, time: 6.663024]
2023-05-25 20:27:56.713: epoch 120:	0.02699049  	0.19855525  	0.10865512  
2023-05-25 20:28:03.507: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.792012]
2023-05-25 20:28:03.657: epoch 121:	0.02696932  	0.19834879  	0.10876279  
2023-05-25 20:28:10.339: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.681011]
2023-05-25 20:28:10.487: epoch 122:	0.02701166  	0.19873798  	0.10885013  
2023-05-25 20:28:17.144: [iter 123 : loss : 0.1175 = 0.0285 + 0.0829 + 0.0061, time: 6.656016]
2023-05-25 20:28:17.294: epoch 123:	0.02697637  	0.19851381  	0.10859610  
2023-05-25 20:28:23.931: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.636004]
2023-05-25 20:28:24.098: epoch 124:	0.02701166  	0.19873896  	0.10857188  
2023-05-25 20:28:30.726: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.627140]
2023-05-25 20:28:30.878: epoch 125:	0.02708222  	0.19945388  	0.10878672  
2023-05-25 20:28:30.879: Find a better model.
2023-05-25 20:28:37.528: [iter 126 : loss : 0.1161 = 0.0271 + 0.0828 + 0.0062, time: 6.647468]
2023-05-25 20:28:37.676: epoch 126:	0.02704694  	0.19923322  	0.10876847  
2023-05-25 20:28:44.330: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.652005]
2023-05-25 20:28:44.479: epoch 127:	0.02701166  	0.19934471  	0.10895356  
2023-05-25 20:28:51.120: [iter 128 : loss : 0.1163 = 0.0273 + 0.0827 + 0.0063, time: 6.640012]
2023-05-25 20:28:51.271: epoch 128:	0.02708222  	0.19983803  	0.10907459  
2023-05-25 20:28:51.271: Find a better model.
2023-05-25 20:28:57.927: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.655022]
2023-05-25 20:28:58.076: epoch 129:	0.02712456  	0.19999887  	0.10922003  
2023-05-25 20:28:58.077: Find a better model.
2023-05-25 20:29:04.889: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.810399]
2023-05-25 20:29:05.039: epoch 130:	0.02712456  	0.20027731  	0.10938381  
2023-05-25 20:29:05.039: Find a better model.
2023-05-25 20:29:11.715: [iter 131 : loss : 0.1144 = 0.0255 + 0.0826 + 0.0064, time: 6.675014]
2023-05-25 20:29:11.882: epoch 131:	0.02710340  	0.19991049  	0.10947413  
2023-05-25 20:29:18.511: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.626994]
2023-05-25 20:29:18.660: epoch 132:	0.02715279  	0.20060162  	0.10953381  
2023-05-25 20:29:18.660: Find a better model.
2023-05-25 20:29:25.310: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.648424]
2023-05-25 20:29:25.458: epoch 133:	0.02711044  	0.20037563  	0.10964371  
2023-05-25 20:29:32.112: [iter 134 : loss : 0.1143 = 0.0253 + 0.0824 + 0.0065, time: 6.653525]
2023-05-25 20:29:32.274: epoch 134:	0.02712456  	0.20007493  	0.10960964  
2023-05-25 20:29:38.936: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.660153]
2023-05-25 20:29:39.084: epoch 135:	0.02710339  	0.20001183  	0.10952632  
2023-05-25 20:29:45.870: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.785022]
2023-05-25 20:29:46.017: epoch 136:	0.02703989  	0.19990754  	0.10925525  
2023-05-25 20:29:52.685: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.667015]
2023-05-25 20:29:52.838: epoch 137:	0.02710338  	0.20008647  	0.10947565  
2023-05-25 20:29:59.665: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.825002]
2023-05-25 20:29:59.813: epoch 138:	0.02702578  	0.19958900  	0.10926393  
2023-05-25 20:30:06.498: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.682024]
2023-05-25 20:30:06.646: epoch 139:	0.02704694  	0.19962433  	0.10930187  
2023-05-25 20:30:13.316: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.667340]
2023-05-25 20:30:13.474: epoch 140:	0.02703988  	0.19928262  	0.10924840  
2023-05-25 20:30:20.110: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.633003]
2023-05-25 20:30:20.259: epoch 141:	0.02706811  	0.19949001  	0.10953185  
2023-05-25 20:30:26.897: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.636007]
2023-05-25 20:30:27.046: epoch 142:	0.02708222  	0.19971006  	0.10960425  
2023-05-25 20:30:33.682: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.633006]
2023-05-25 20:30:33.836: epoch 143:	0.02708928  	0.19980270  	0.10972548  
2023-05-25 20:30:40.484: [iter 144 : loss : 0.1113 = 0.0225 + 0.0821 + 0.0068, time: 6.644001]
2023-05-25 20:30:40.632: epoch 144:	0.02706106  	0.19966052  	0.10969147  
2023-05-25 20:30:47.279: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.644994]
2023-05-25 20:30:47.443: epoch 145:	0.02712457  	0.20014285  	0.10978524  
2023-05-25 20:30:54.087: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.643009]
2023-05-25 20:30:54.238: epoch 146:	0.02703284  	0.19932783  	0.10943812  
2023-05-25 20:31:00.875: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.635993]
2023-05-25 20:31:01.022: epoch 147:	0.02706812  	0.19969204  	0.10974921  
2023-05-25 20:31:07.695: [iter 148 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 6.671018]
2023-05-25 20:31:07.852: epoch 148:	0.02712457  	0.19985332  	0.10973133  
2023-05-25 20:31:14.467: [iter 149 : loss : 0.1105 = 0.0218 + 0.0819 + 0.0069, time: 6.614377]
2023-05-25 20:31:14.633: epoch 149:	0.02715985  	0.20001867  	0.10980643  
2023-05-25 20:31:21.253: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.617993]
2023-05-25 20:31:21.400: epoch 150:	0.02715985  	0.19995062  	0.11012015  
2023-05-25 20:31:28.071: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.669238]
2023-05-25 20:31:28.220: epoch 151:	0.02716691  	0.19972973  	0.11003188  
2023-05-25 20:31:35.057: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.836004]
2023-05-25 20:31:35.220: epoch 152:	0.02710340  	0.19948761  	0.11001437  
2023-05-25 20:31:41.872: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.649036]
2023-05-25 20:31:42.020: epoch 153:	0.02711045  	0.19936849  	0.10988425  
2023-05-25 20:31:48.689: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.668004]
2023-05-25 20:31:48.855: epoch 154:	0.02720218  	0.20023789  	0.11016576  
2023-05-25 20:31:55.461: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.604047]
2023-05-25 20:31:55.609: epoch 155:	0.02712457  	0.19966097  	0.10994089  
2023-05-25 20:32:02.256: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.645086]
2023-05-25 20:32:02.405: epoch 156:	0.02711751  	0.19966093  	0.10977328  
2023-05-25 20:32:09.055: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.649004]
2023-05-25 20:32:09.203: epoch 157:	0.02711751  	0.19964765  	0.10977482  
2023-05-25 20:32:09.203: Early stopping is trigger at epoch: 157
2023-05-25 20:32:09.203: best_result@epoch 132:

2023-05-25 20:32:09.203: 		0.0272      	0.2006      	0.1095      
2023-05-25 20:39:02.330: my pid: 8060
2023-05-25 20:39:02.330: model: model.general_recommender.SGL
2023-05-25 20:39:02.330: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 20:39:02.330: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 20:39:06.055: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 20:39:13.490: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.434753]
2023-05-25 20:39:13.658: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-25 20:39:13.659: Find a better model.
2023-05-25 20:39:21.133: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.472025]
2023-05-25 20:39:21.315: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-25 20:39:21.315: Find a better model.
2023-05-25 20:39:28.703: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.386109]
2023-05-25 20:39:28.862: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-25 20:39:28.862: Find a better model.
2023-05-25 20:39:36.089: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.225009]
2023-05-25 20:39:36.239: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-25 20:39:36.240: Find a better model.
2023-05-25 20:39:43.293: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 7.052016]
2023-05-25 20:39:43.440: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-25 20:39:43.440: Find a better model.
2023-05-25 20:39:50.288: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.846993]
2023-05-25 20:39:50.437: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-25 20:39:50.437: Find a better model.
2023-05-25 20:39:57.274: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.836001]
2023-05-25 20:39:57.425: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-25 20:39:57.425: Find a better model.
2023-05-25 20:40:04.254: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.827994]
2023-05-25 20:40:04.403: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-25 20:40:04.403: Find a better model.
2023-05-25 20:40:11.270: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.866088]
2023-05-25 20:40:11.418: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-25 20:40:18.239: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.820034]
2023-05-25 20:40:18.389: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-25 20:40:25.080: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.690010]
2023-05-25 20:40:25.232: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-25 20:40:32.065: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.832015]
2023-05-25 20:40:32.230: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-25 20:40:39.032: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.801016]
2023-05-25 20:40:39.179: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-25 20:40:39.179: Find a better model.
2023-05-25 20:40:45.892: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.711352]
2023-05-25 20:40:46.042: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-25 20:40:46.042: Find a better model.
2023-05-25 20:40:52.664: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.621011]
2023-05-25 20:40:52.813: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-25 20:40:52.813: Find a better model.
2023-05-25 20:40:59.254: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.440064]
2023-05-25 20:40:59.404: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-25 20:40:59.404: Find a better model.
2023-05-25 20:41:06.036: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.630019]
2023-05-25 20:41:06.188: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-25 20:41:06.188: Find a better model.
2023-05-25 20:41:12.815: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.625022]
2023-05-25 20:41:12.965: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-25 20:41:12.965: Find a better model.
2023-05-25 20:41:19.443: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.475999]
2023-05-25 20:41:19.594: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-25 20:41:19.595: Find a better model.
2023-05-25 20:41:26.221: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.624485]
2023-05-25 20:41:26.387: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-25 20:41:26.387: Find a better model.
2023-05-25 20:41:33.027: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.638458]
2023-05-25 20:41:33.174: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-25 20:41:33.175: Find a better model.
2023-05-25 20:41:39.647: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.470994]
2023-05-25 20:41:39.796: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-25 20:41:39.796: Find a better model.
2023-05-25 20:41:46.222: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.424821]
2023-05-25 20:41:46.373: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-25 20:41:46.373: Find a better model.
2023-05-25 20:41:52.830: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.455994]
2023-05-25 20:41:52.978: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-25 20:41:52.978: Find a better model.
2023-05-25 20:41:59.427: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.447994]
2023-05-25 20:41:59.575: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-25 20:41:59.575: Find a better model.
2023-05-25 20:42:06.017: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.440035]
2023-05-25 20:42:06.168: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-25 20:42:06.168: Find a better model.
2023-05-25 20:42:12.614: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.444994]
2023-05-25 20:42:12.766: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-25 20:42:12.766: Find a better model.
2023-05-25 20:42:19.027: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.260057]
2023-05-25 20:42:19.175: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-25 20:42:19.175: Find a better model.
2023-05-25 20:42:25.608: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.431003]
2023-05-25 20:42:25.755: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-25 20:42:25.755: Find a better model.
2023-05-25 20:42:32.188: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.431367]
2023-05-25 20:42:32.339: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-25 20:42:32.339: Find a better model.
2023-05-25 20:42:38.808: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.466004]
2023-05-25 20:42:38.961: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-25 20:42:38.961: Find a better model.
2023-05-25 20:42:45.402: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.439994]
2023-05-25 20:42:45.552: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-25 20:42:45.552: Find a better model.
2023-05-25 20:42:52.015: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.461013]
2023-05-25 20:42:52.164: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-25 20:42:52.164: Find a better model.
2023-05-25 20:42:58.614: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.447966]
2023-05-25 20:42:58.762: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-25 20:42:58.763: Find a better model.
2023-05-25 20:43:05.217: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.452016]
2023-05-25 20:43:05.366: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-25 20:43:05.366: Find a better model.
2023-05-25 20:43:11.823: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.453428]
2023-05-25 20:43:11.979: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-25 20:43:11.980: Find a better model.
2023-05-25 20:43:18.420: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.439016]
2023-05-25 20:43:18.568: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-25 20:43:18.568: Find a better model.
2023-05-25 20:43:25.185: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.616127]
2023-05-25 20:43:25.335: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-25 20:43:25.335: Find a better model.
2023-05-25 20:43:31.802: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.465003]
2023-05-25 20:43:31.956: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-25 20:43:31.956: Find a better model.
2023-05-25 20:43:38.402: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.445002]
2023-05-25 20:43:38.550: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-25 20:43:38.550: Find a better model.
2023-05-25 20:43:44.999: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.447016]
2023-05-25 20:43:45.150: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-25 20:43:45.150: Find a better model.
2023-05-25 20:43:51.798: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.647035]
2023-05-25 20:43:51.949: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-25 20:43:51.949: Find a better model.
2023-05-25 20:43:58.390: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.440025]
2023-05-25 20:43:58.539: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-25 20:44:04.989: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.449004]
2023-05-25 20:44:05.140: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-25 20:44:05.140: Find a better model.
2023-05-25 20:44:11.793: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.650660]
2023-05-25 20:44:11.953: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-25 20:44:11.953: Find a better model.
2023-05-25 20:44:18.612: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.656766]
2023-05-25 20:44:18.773: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-25 20:44:18.773: Find a better model.
2023-05-25 20:44:25.374: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.599044]
2023-05-25 20:44:25.522: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-25 20:44:25.522: Find a better model.
2023-05-25 20:44:31.992: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.469343]
2023-05-25 20:44:32.140: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-25 20:44:32.140: Find a better model.
2023-05-25 20:44:38.766: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.623000]
2023-05-25 20:44:38.919: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-25 20:44:38.919: Find a better model.
2023-05-25 20:44:45.383: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.461661]
2023-05-25 20:44:45.534: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-25 20:44:52.178: [iter 51 : loss : 0.1789 = 0.0845 + 0.0911 + 0.0034, time: 6.643037]
2023-05-25 20:44:52.325: epoch 51:	0.02385745  	0.17556633  	0.09347536  
2023-05-25 20:44:52.325: Find a better model.
2023-05-25 20:44:58.973: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.647431]
2023-05-25 20:44:59.122: epoch 52:	0.02395623  	0.17601489  	0.09390710  
2023-05-25 20:44:59.123: Find a better model.
2023-05-25 20:45:05.783: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.659059]
2023-05-25 20:45:05.938: epoch 53:	0.02406208  	0.17695470  	0.09432394  
2023-05-25 20:45:05.938: Find a better model.
2023-05-25 20:45:12.585: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.645237]
2023-05-25 20:45:12.753: epoch 54:	0.02420321  	0.17795064  	0.09494643  
2023-05-25 20:45:12.753: Find a better model.
2023-05-25 20:45:19.362: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.606994]
2023-05-25 20:45:19.510: epoch 55:	0.02423144  	0.17833951  	0.09528571  
2023-05-25 20:45:19.510: Find a better model.
2023-05-25 20:45:26.165: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.653988]
2023-05-25 20:45:26.317: epoch 56:	0.02433022  	0.17895587  	0.09569942  
2023-05-25 20:45:26.317: Find a better model.
2023-05-25 20:45:32.989: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.671174]
2023-05-25 20:45:33.152: epoch 57:	0.02445724  	0.18021582  	0.09626380  
2023-05-25 20:45:33.152: Find a better model.
2023-05-25 20:45:39.765: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.610993]
2023-05-25 20:45:39.919: epoch 58:	0.02451369  	0.18070015  	0.09666315  
2023-05-25 20:45:39.919: Find a better model.
2023-05-25 20:45:46.559: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.639036]
2023-05-25 20:45:46.710: epoch 59:	0.02457014  	0.18136871  	0.09688648  
2023-05-25 20:45:46.710: Find a better model.
2023-05-25 20:45:53.353: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.641005]
2023-05-25 20:45:53.504: epoch 60:	0.02457720  	0.18123862  	0.09709927  
2023-05-25 20:46:00.138: [iter 61 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 6.633004]
2023-05-25 20:46:00.286: epoch 61:	0.02473950  	0.18246689  	0.09783471  
2023-05-25 20:46:00.287: Find a better model.
2023-05-25 20:46:06.970: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.681190]
2023-05-25 20:46:07.120: epoch 62:	0.02473950  	0.18253952  	0.09800158  
2023-05-25 20:46:07.120: Find a better model.
2023-05-25 20:46:13.763: [iter 63 : loss : 0.1607 = 0.0680 + 0.0889 + 0.0039, time: 6.641165]
2023-05-25 20:46:13.929: epoch 63:	0.02485945  	0.18358658  	0.09858698  
2023-05-25 20:46:13.929: Find a better model.
2023-05-25 20:46:20.542: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.611994]
2023-05-25 20:46:20.691: epoch 64:	0.02491591  	0.18385525  	0.09907693  
2023-05-25 20:46:20.691: Find a better model.
2023-05-25 20:46:27.333: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.641178]
2023-05-25 20:46:27.483: epoch 65:	0.02485240  	0.18346439  	0.09909746  
2023-05-25 20:46:34.131: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.646016]
2023-05-25 20:46:34.281: epoch 66:	0.02494413  	0.18398443  	0.09929436  
2023-05-25 20:46:34.281: Find a better model.
2023-05-25 20:46:40.938: [iter 67 : loss : 0.1555 = 0.0632 + 0.0883 + 0.0041, time: 6.655094]
2023-05-25 20:46:41.086: epoch 67:	0.02506409  	0.18478742  	0.09981620  
2023-05-25 20:46:41.086: Find a better model.
2023-05-25 20:46:47.742: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.654040]
2023-05-25 20:46:47.896: epoch 68:	0.02512054  	0.18514730  	0.10016883  
2023-05-25 20:46:47.897: Find a better model.
2023-05-25 20:46:54.703: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.804993]
2023-05-25 20:46:54.853: epoch 69:	0.02512054  	0.18500322  	0.10034642  
2023-05-25 20:47:01.695: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.840012]
2023-05-25 20:47:01.846: epoch 70:	0.02522638  	0.18607423  	0.10065963  
2023-05-25 20:47:01.846: Find a better model.
2023-05-25 20:47:08.717: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.870014]
2023-05-25 20:47:08.865: epoch 71:	0.02527578  	0.18630695  	0.10095549  
2023-05-25 20:47:08.865: Find a better model.
2023-05-25 20:47:15.716: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.849000]
2023-05-25 20:47:15.884: epoch 72:	0.02531812  	0.18684871  	0.10120672  
2023-05-25 20:47:15.884: Find a better model.
2023-05-25 20:47:22.695: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.809015]
2023-05-25 20:47:22.844: epoch 73:	0.02534635  	0.18715927  	0.10135323  
2023-05-25 20:47:22.844: Find a better model.
2023-05-25 20:47:29.527: [iter 74 : loss : 0.1470 = 0.0553 + 0.0874 + 0.0044, time: 6.681951]
2023-05-25 20:47:29.677: epoch 74:	0.02545925  	0.18799150  	0.10185751  
2023-05-25 20:47:29.677: Find a better model.
2023-05-25 20:47:36.326: [iter 75 : loss : 0.1468 = 0.0551 + 0.0873 + 0.0044, time: 6.648274]
2023-05-25 20:47:36.477: epoch 75:	0.02547337  	0.18818423  	0.10195465  
2023-05-25 20:47:36.477: Find a better model.
2023-05-25 20:47:43.119: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.641003]
2023-05-25 20:47:43.270: epoch 76:	0.02556510  	0.18908282  	0.10232373  
2023-05-25 20:47:43.270: Find a better model.
2023-05-25 20:47:50.095: [iter 77 : loss : 0.1449 = 0.0533 + 0.0870 + 0.0045, time: 6.822056]
2023-05-25 20:47:50.247: epoch 77:	0.02552982  	0.18871117  	0.10226977  
2023-05-25 20:47:56.915: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.666001]
2023-05-25 20:47:57.064: epoch 78:	0.02557215  	0.18913417  	0.10251340  
2023-05-25 20:47:57.064: Find a better model.
2023-05-25 20:48:03.899: [iter 79 : loss : 0.1425 = 0.0511 + 0.0868 + 0.0046, time: 6.832029]
2023-05-25 20:48:04.047: epoch 79:	0.02566389  	0.18979087  	0.10278916  
2023-05-25 20:48:04.047: Find a better model.
2023-05-25 20:48:10.872: [iter 80 : loss : 0.1418 = 0.0504 + 0.0867 + 0.0046, time: 6.822994]
2023-05-25 20:48:11.026: epoch 80:	0.02570623  	0.19020224  	0.10312619  
2023-05-25 20:48:11.026: Find a better model.
2023-05-25 20:48:17.711: [iter 81 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 6.684518]
2023-05-25 20:48:17.860: epoch 81:	0.02570623  	0.19019452  	0.10334124  
2023-05-25 20:48:24.670: [iter 82 : loss : 0.1402 = 0.0490 + 0.0865 + 0.0047, time: 6.807474]
2023-05-25 20:48:24.817: epoch 82:	0.02567800  	0.18980905  	0.10336329  
2023-05-25 20:48:31.487: [iter 83 : loss : 0.1395 = 0.0484 + 0.0865 + 0.0047, time: 6.668993]
2023-05-25 20:48:31.638: epoch 83:	0.02574857  	0.19047789  	0.10360593  
2023-05-25 20:48:31.638: Find a better model.
2023-05-25 20:48:38.305: [iter 84 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 6.665994]
2023-05-25 20:48:38.455: epoch 84:	0.02565683  	0.18967713  	0.10357493  
2023-05-25 20:48:45.094: [iter 85 : loss : 0.1384 = 0.0474 + 0.0862 + 0.0048, time: 6.637909]
2023-05-25 20:48:45.245: epoch 85:	0.02574151  	0.19035104  	0.10384895  
2023-05-25 20:48:52.084: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.837047]
2023-05-25 20:48:52.232: epoch 86:	0.02583325  	0.19104545  	0.10410501  
2023-05-25 20:48:52.232: Find a better model.
2023-05-25 20:48:58.889: [iter 87 : loss : 0.1355 = 0.0446 + 0.0861 + 0.0049, time: 6.656046]
2023-05-25 20:48:59.040: epoch 87:	0.02592498  	0.19175190  	0.10439243  
2023-05-25 20:48:59.041: Find a better model.
2023-05-25 20:49:05.884: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.841003]
2023-05-25 20:49:06.052: epoch 88:	0.02598143  	0.19215560  	0.10469357  
2023-05-25 20:49:06.052: Find a better model.
2023-05-25 20:49:12.864: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.811006]
2023-05-25 20:49:13.017: epoch 89:	0.02593909  	0.19166388  	0.10472674  
2023-05-25 20:49:19.676: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.657996]
2023-05-25 20:49:19.826: epoch 90:	0.02601671  	0.19235268  	0.10506452  
2023-05-25 20:49:19.826: Find a better model.
2023-05-25 20:49:26.667: [iter 91 : loss : 0.1337 = 0.0430 + 0.0857 + 0.0050, time: 6.838016]
2023-05-25 20:49:26.817: epoch 91:	0.02607316  	0.19304304  	0.10520826  
2023-05-25 20:49:26.818: Find a better model.
2023-05-25 20:49:33.659: [iter 92 : loss : 0.1328 = 0.0422 + 0.0856 + 0.0051, time: 6.840961]
2023-05-25 20:49:33.807: epoch 92:	0.02606611  	0.19325309  	0.10530273  
2023-05-25 20:49:33.807: Find a better model.
2023-05-25 20:49:40.681: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.871209]
2023-05-25 20:49:40.831: epoch 93:	0.02606611  	0.19362028  	0.10544434  
2023-05-25 20:49:40.831: Find a better model.
2023-05-25 20:49:47.680: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.848000]
2023-05-25 20:49:47.827: epoch 94:	0.02603788  	0.19327219  	0.10544233  
2023-05-25 20:49:54.672: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.844014]
2023-05-25 20:49:54.821: epoch 95:	0.02603788  	0.19309556  	0.10551426  
2023-05-25 20:50:01.669: [iter 96 : loss : 0.1305 = 0.0400 + 0.0853 + 0.0052, time: 6.847113]
2023-05-25 20:50:01.817: epoch 96:	0.02608022  	0.19372027  	0.10579384  
2023-05-25 20:50:01.817: Find a better model.
2023-05-25 20:50:08.849: [iter 97 : loss : 0.1289 = 0.0385 + 0.0852 + 0.0052, time: 7.030126]
2023-05-25 20:50:09.002: epoch 97:	0.02608021  	0.19341087  	0.10577220  
2023-05-25 20:50:15.881: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.877401]
2023-05-25 20:50:16.031: epoch 98:	0.02606610  	0.19342220  	0.10578956  
2023-05-25 20:50:22.855: [iter 99 : loss : 0.1285 = 0.0380 + 0.0851 + 0.0053, time: 6.821010]
2023-05-25 20:50:23.005: epoch 99:	0.02610138  	0.19383501  	0.10600889  
2023-05-25 20:50:23.005: Find a better model.
2023-05-25 20:50:29.847: [iter 100 : loss : 0.1280 = 0.0377 + 0.0850 + 0.0053, time: 6.840449]
2023-05-25 20:50:30.002: epoch 100:	0.02617195  	0.19436575  	0.10618011  
2023-05-25 20:50:30.002: Find a better model.
2023-05-25 20:50:36.656: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.652003]
2023-05-25 20:50:36.804: epoch 101:	0.02621429  	0.19452716  	0.10632234  
2023-05-25 20:50:36.804: Find a better model.
2023-05-25 20:50:43.459: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.654001]
2023-05-25 20:50:43.622: epoch 102:	0.02621429  	0.19448298  	0.10639211  
2023-05-25 20:50:50.255: [iter 103 : loss : 0.1264 = 0.0361 + 0.0848 + 0.0055, time: 6.630043]
2023-05-25 20:50:50.406: epoch 103:	0.02621429  	0.19467154  	0.10655469  
2023-05-25 20:50:50.406: Find a better model.
2023-05-25 20:50:57.061: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.653030]
2023-05-25 20:50:57.212: epoch 104:	0.02622840  	0.19481848  	0.10671044  
2023-05-25 20:50:57.212: Find a better model.
2023-05-25 20:51:03.859: [iter 105 : loss : 0.1262 = 0.0359 + 0.0847 + 0.0055, time: 6.645100]
2023-05-25 20:51:04.014: epoch 105:	0.02620018  	0.19457205  	0.10680111  
2023-05-25 20:51:10.649: [iter 106 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 6.632014]
2023-05-25 20:51:10.815: epoch 106:	0.02617196  	0.19430926  	0.10658271  
2023-05-25 20:51:17.438: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.621001]
2023-05-25 20:51:17.588: epoch 107:	0.02622841  	0.19484513  	0.10674941  
2023-05-25 20:51:17.588: Find a better model.
2023-05-25 20:51:24.246: [iter 108 : loss : 0.1245 = 0.0343 + 0.0846 + 0.0056, time: 6.657049]
2023-05-25 20:51:24.395: epoch 108:	0.02621430  	0.19489457  	0.10675219  
2023-05-25 20:51:24.395: Find a better model.
2023-05-25 20:51:31.221: [iter 109 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 6.824140]
2023-05-25 20:51:31.372: epoch 109:	0.02628486  	0.19560690  	0.10698405  
2023-05-25 20:51:31.372: Find a better model.
2023-05-25 20:51:38.212: [iter 110 : loss : 0.1225 = 0.0324 + 0.0844 + 0.0057, time: 6.838032]
2023-05-25 20:51:38.360: epoch 110:	0.02631308  	0.19570130  	0.10696437  
2023-05-25 20:51:38.360: Find a better model.
2023-05-25 20:51:45.039: [iter 111 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0057, time: 6.678012]
2023-05-25 20:51:45.190: epoch 111:	0.02635542  	0.19601567  	0.10723492  
2023-05-25 20:51:45.191: Find a better model.
2023-05-25 20:51:52.028: [iter 112 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.835069]
2023-05-25 20:51:52.177: epoch 112:	0.02635542  	0.19575356  	0.10719679  
2023-05-25 20:51:58.993: [iter 113 : loss : 0.1223 = 0.0322 + 0.0842 + 0.0058, time: 6.805302]
2023-05-25 20:51:59.143: epoch 113:	0.02630603  	0.19547369  	0.10709397  
2023-05-25 20:52:06.007: [iter 114 : loss : 0.1215 = 0.0315 + 0.0842 + 0.0058, time: 6.863030]
2023-05-25 20:52:06.156: epoch 114:	0.02637659  	0.19573277  	0.10724302  
2023-05-25 20:52:13.015: [iter 115 : loss : 0.1210 = 0.0311 + 0.0841 + 0.0059, time: 6.858013]
2023-05-25 20:52:13.164: epoch 115:	0.02635542  	0.19588290  	0.10713280  
2023-05-25 20:52:20.011: [iter 116 : loss : 0.1204 = 0.0304 + 0.0841 + 0.0059, time: 6.846039]
2023-05-25 20:52:20.179: epoch 116:	0.02637659  	0.19606535  	0.10718149  
2023-05-25 20:52:20.179: Find a better model.
2023-05-25 20:52:27.010: [iter 117 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0059, time: 6.829993]
2023-05-25 20:52:27.159: epoch 117:	0.02647539  	0.19672194  	0.10737840  
2023-05-25 20:52:27.160: Find a better model.
2023-05-25 20:52:34.003: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.842058]
2023-05-25 20:52:34.153: epoch 118:	0.02655300  	0.19719434  	0.10763924  
2023-05-25 20:52:34.153: Find a better model.
2023-05-25 20:52:40.810: [iter 119 : loss : 0.1192 = 0.0293 + 0.0839 + 0.0060, time: 6.655012]
2023-05-25 20:52:40.959: epoch 119:	0.02657417  	0.19701733  	0.10766494  
2023-05-25 20:52:47.806: [iter 120 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 6.845548]
2023-05-25 20:52:47.958: epoch 120:	0.02646127  	0.19594470  	0.10739335  
2023-05-25 20:52:54.808: [iter 121 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0061, time: 6.847994]
2023-05-25 20:52:54.969: epoch 121:	0.02646833  	0.19605201  	0.10753069  
2023-05-25 20:53:01.817: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.847000]
2023-05-25 20:53:01.977: epoch 122:	0.02646127  	0.19622391  	0.10764185  
2023-05-25 20:53:08.798: [iter 123 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 6.819548]
2023-05-25 20:53:08.951: epoch 123:	0.02642599  	0.19593590  	0.10750403  
2023-05-25 20:53:15.609: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.657060]
2023-05-25 20:53:15.761: epoch 124:	0.02646833  	0.19610898  	0.10755581  
2023-05-25 20:53:22.400: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.637968]
2023-05-25 20:53:22.552: epoch 125:	0.02649656  	0.19672477  	0.10766514  
2023-05-25 20:53:29.197: [iter 126 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 6.644003]
2023-05-25 20:53:29.347: epoch 126:	0.02650362  	0.19647475  	0.10774744  
2023-05-25 20:53:36.197: [iter 127 : loss : 0.1162 = 0.0264 + 0.0835 + 0.0062, time: 6.849015]
2023-05-25 20:53:36.364: epoch 127:	0.02644716  	0.19609503  	0.10768312  
2023-05-25 20:53:43.174: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.809013]
2023-05-25 20:53:43.341: epoch 128:	0.02651067  	0.19585666  	0.10758903  
2023-05-25 20:53:50.187: [iter 129 : loss : 0.1164 = 0.0266 + 0.0835 + 0.0063, time: 6.844046]
2023-05-25 20:53:50.336: epoch 129:	0.02651067  	0.19621202  	0.10772727  
2023-05-25 20:53:57.171: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.833007]
2023-05-25 20:53:57.337: epoch 130:	0.02645421  	0.19562824  	0.10761155  
2023-05-25 20:54:03.989: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 6.650011]
2023-05-25 20:54:04.155: epoch 131:	0.02646833  	0.19594850  	0.10767387  
2023-05-25 20:54:10.794: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.638003]
2023-05-25 20:54:10.956: epoch 132:	0.02643304  	0.19577932  	0.10771248  
2023-05-25 20:54:17.754: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.796247]
2023-05-25 20:54:17.906: epoch 133:	0.02636953  	0.19518094  	0.10768214  
2023-05-25 20:54:24.756: [iter 134 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 6.848031]
2023-05-25 20:54:24.916: epoch 134:	0.02638365  	0.19510621  	0.10769399  
2023-05-25 20:54:31.577: [iter 135 : loss : 0.1150 = 0.0253 + 0.0832 + 0.0065, time: 6.660029]
2023-05-25 20:54:31.729: epoch 135:	0.02643304  	0.19570200  	0.10780668  
2023-05-25 20:54:38.387: [iter 136 : loss : 0.1146 = 0.0249 + 0.0832 + 0.0065, time: 6.657010]
2023-05-25 20:54:38.537: epoch 136:	0.02642599  	0.19565850  	0.10779212  
2023-05-25 20:54:45.179: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.640023]
2023-05-25 20:54:45.331: epoch 137:	0.02644010  	0.19593474  	0.10784190  
2023-05-25 20:54:51.958: [iter 138 : loss : 0.1139 = 0.0243 + 0.0831 + 0.0066, time: 6.626020]
2023-05-25 20:54:52.107: epoch 138:	0.02645421  	0.19599007  	0.10798435  
2023-05-25 20:54:58.760: [iter 139 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 6.652004]
2023-05-25 20:54:58.914: epoch 139:	0.02646126  	0.19586013  	0.10793521  
2023-05-25 20:55:05.565: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.650022]
2023-05-25 20:55:05.717: epoch 140:	0.02644715  	0.19571728  	0.10787428  
2023-05-25 20:55:12.536: [iter 141 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 6.818004]
2023-05-25 20:55:12.705: epoch 141:	0.02644010  	0.19574803  	0.10787975  
2023-05-25 20:55:19.341: [iter 142 : loss : 0.1126 = 0.0231 + 0.0829 + 0.0067, time: 6.635134]
2023-05-25 20:55:19.494: epoch 142:	0.02639071  	0.19581506  	0.10799351  
2023-05-25 20:55:26.155: [iter 143 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 6.659003]
2023-05-25 20:55:26.306: epoch 143:	0.02639775  	0.19585544  	0.10816894  
2023-05-25 20:55:26.306: Early stopping is trigger at epoch: 143
2023-05-25 20:55:26.306: best_result@epoch 118:

2023-05-25 20:55:26.306: 		0.0266      	0.1972      	0.1076      
2023-05-25 21:22:00.567: my pid: 10112
2023-05-25 21:22:00.567: model: model.general_recommender.SGL
2023-05-25 21:22:00.567: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 21:22:00.567: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 21:22:04.276: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 21:22:11.447: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.170999]
2023-05-25 21:22:11.597: epoch 1:	0.00203924  	0.01432136  	0.00729454  
2023-05-25 21:22:11.597: Find a better model.
2023-05-25 21:22:19.019: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.420213]
2023-05-25 21:22:19.213: epoch 2:	0.00478406  	0.03443001  	0.01690566  
2023-05-25 21:22:19.213: Find a better model.
2023-05-25 21:22:26.598: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.382481]
2023-05-25 21:22:26.780: epoch 3:	0.00788873  	0.05646078  	0.02796516  
2023-05-25 21:22:26.780: Find a better model.
2023-05-25 21:22:33.993: [iter 4 : loss : 0.7713 = 0.6914 + 0.0800 + 0.0000, time: 7.211437]
2023-05-25 21:22:34.156: epoch 4:	0.01172033  	0.08282045  	0.03980501  
2023-05-25 21:22:34.156: Find a better model.
2023-05-25 21:22:41.230: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 7.073291]
2023-05-25 21:22:41.405: epoch 5:	0.01521326  	0.10884760  	0.05229084  
2023-05-25 21:22:41.406: Find a better model.
2023-05-25 21:22:48.220: [iter 6 : loss : 0.7660 = 0.6850 + 0.0809 + 0.0000, time: 6.812450]
2023-05-25 21:22:48.379: epoch 6:	0.01762655  	0.12596598  	0.06164180  
2023-05-25 21:22:48.379: Find a better model.
2023-05-25 21:22:55.187: [iter 7 : loss : 0.7561 = 0.6739 + 0.0822 + 0.0000, time: 6.807203]
2023-05-25 21:22:55.357: epoch 7:	0.01864268  	0.13527347  	0.06688826  
2023-05-25 21:22:55.357: Find a better model.
2023-05-25 21:23:01.987: [iter 8 : loss : 0.7333 = 0.6483 + 0.0849 + 0.0001, time: 6.626994]
2023-05-25 21:23:02.135: epoch 8:	0.01890378  	0.13831645  	0.06872977  
2023-05-25 21:23:02.135: Find a better model.
2023-05-25 21:23:08.792: [iter 9 : loss : 0.6876 = 0.5979 + 0.0895 + 0.0002, time: 6.656059]
2023-05-25 21:23:08.941: epoch 9:	0.01873442  	0.13818790  	0.06860495  
2023-05-25 21:23:15.575: [iter 10 : loss : 0.6197 = 0.5246 + 0.0948 + 0.0003, time: 6.633003]
2023-05-25 21:23:15.742: epoch 10:	0.01829691  	0.13509032  	0.06706029  
2023-05-25 21:23:22.194: [iter 11 : loss : 0.5468 = 0.4473 + 0.0990 + 0.0005, time: 6.451004]
2023-05-25 21:23:22.344: epoch 11:	0.01835337  	0.13575500  	0.06715121  
2023-05-25 21:23:28.786: [iter 12 : loss : 0.4859 = 0.3837 + 0.1016 + 0.0006, time: 6.439018]
2023-05-25 21:23:28.934: epoch 12:	0.01828986  	0.13479917  	0.06730105  
2023-05-25 21:23:35.357: [iter 13 : loss : 0.4417 = 0.3380 + 0.1029 + 0.0008, time: 6.421930]
2023-05-25 21:23:35.508: epoch 13:	0.01848745  	0.13685237  	0.06832035  
2023-05-25 21:23:41.996: [iter 14 : loss : 0.4077 = 0.3034 + 0.1034 + 0.0009, time: 6.486994]
2023-05-25 21:23:42.144: epoch 14:	0.01874854  	0.13879488  	0.06923629  
2023-05-25 21:23:42.144: Find a better model.
2023-05-25 21:23:48.569: [iter 15 : loss : 0.3837 = 0.2792 + 0.1035 + 0.0010, time: 6.424026]
2023-05-25 21:23:48.717: epoch 15:	0.01882615  	0.13954487  	0.06991188  
2023-05-25 21:23:48.717: Find a better model.
2023-05-25 21:23:55.354: [iter 16 : loss : 0.3631 = 0.2585 + 0.1035 + 0.0011, time: 6.636005]
2023-05-25 21:23:55.504: epoch 16:	0.01905196  	0.14125791  	0.07095956  
2023-05-25 21:23:55.504: Find a better model.
2023-05-25 21:24:02.136: [iter 17 : loss : 0.3477 = 0.2434 + 0.1032 + 0.0012, time: 6.631154]
2023-05-25 21:24:02.286: epoch 17:	0.01922837  	0.14225909  	0.07166037  
2023-05-25 21:24:02.286: Find a better model.
2023-05-25 21:24:08.769: [iter 18 : loss : 0.3331 = 0.2289 + 0.1029 + 0.0013, time: 6.480980]
2023-05-25 21:24:08.933: epoch 18:	0.01936245  	0.14336030  	0.07235111  
2023-05-25 21:24:08.934: Find a better model.
2023-05-25 21:24:15.384: [iter 19 : loss : 0.3195 = 0.2156 + 0.1025 + 0.0014, time: 6.448994]
2023-05-25 21:24:15.532: epoch 19:	0.01962354  	0.14525086  	0.07337818  
2023-05-25 21:24:15.532: Find a better model.
2023-05-25 21:24:21.972: [iter 20 : loss : 0.3101 = 0.2065 + 0.1021 + 0.0015, time: 6.438005]
2023-05-25 21:24:22.120: epoch 20:	0.01988464  	0.14728081  	0.07441803  
2023-05-25 21:24:22.121: Find a better model.
2023-05-25 21:24:28.554: [iter 21 : loss : 0.3008 = 0.1975 + 0.1017 + 0.0016, time: 6.432005]
2023-05-25 21:24:28.702: epoch 21:	0.02006811  	0.14867450  	0.07526683  
2023-05-25 21:24:28.702: Find a better model.
2023-05-25 21:24:35.173: [iter 22 : loss : 0.2926 = 0.1897 + 0.1012 + 0.0017, time: 6.470015]
2023-05-25 21:24:35.339: epoch 22:	0.02030803  	0.15070923  	0.07621783  
2023-05-25 21:24:35.339: Find a better model.
2023-05-25 21:24:41.740: [iter 23 : loss : 0.2845 = 0.1819 + 0.1008 + 0.0017, time: 6.399057]
2023-05-25 21:24:41.889: epoch 23:	0.02044915  	0.15141676  	0.07680257  
2023-05-25 21:24:41.889: Find a better model.
2023-05-25 21:24:48.368: [iter 24 : loss : 0.2781 = 0.1759 + 0.1004 + 0.0018, time: 6.478003]
2023-05-25 21:24:48.518: epoch 24:	0.02060440  	0.15200818  	0.07732188  
2023-05-25 21:24:48.518: Find a better model.
2023-05-25 21:24:55.116: [iter 25 : loss : 0.2715 = 0.1696 + 0.1000 + 0.0019, time: 6.596099]
2023-05-25 21:24:55.264: epoch 25:	0.02083021  	0.15347055  	0.07818237  
2023-05-25 21:24:55.264: Find a better model.
2023-05-25 21:25:01.743: [iter 26 : loss : 0.2678 = 0.1663 + 0.0995 + 0.0020, time: 6.478021]
2023-05-25 21:25:01.911: epoch 26:	0.02100662  	0.15437225  	0.07877313  
2023-05-25 21:25:01.912: Find a better model.
2023-05-25 21:25:08.527: [iter 27 : loss : 0.2602 = 0.1590 + 0.0991 + 0.0020, time: 6.614127]
2023-05-25 21:25:08.678: epoch 27:	0.02123243  	0.15572694  	0.07970133  
2023-05-25 21:25:08.678: Find a better model.
2023-05-25 21:25:15.335: [iter 28 : loss : 0.2553 = 0.1546 + 0.0987 + 0.0021, time: 6.655131]
2023-05-25 21:25:15.490: epoch 28:	0.02148647  	0.15756127  	0.08083389  
2023-05-25 21:25:15.490: Find a better model.
2023-05-25 21:25:22.125: [iter 29 : loss : 0.2510 = 0.1506 + 0.0983 + 0.0021, time: 6.633067]
2023-05-25 21:25:22.273: epoch 29:	0.02165583  	0.15919425  	0.08170892  
2023-05-25 21:25:22.273: Find a better model.
2023-05-25 21:25:28.757: [iter 30 : loss : 0.2442 = 0.1441 + 0.0979 + 0.0022, time: 6.482004]
2023-05-25 21:25:28.907: epoch 30:	0.02184635  	0.16071603  	0.08260520  
2023-05-25 21:25:28.907: Find a better model.
2023-05-25 21:25:35.523: [iter 31 : loss : 0.2410 = 0.1412 + 0.0975 + 0.0023, time: 6.614363]
2023-05-25 21:25:35.671: epoch 31:	0.02209333  	0.16248375  	0.08326704  
2023-05-25 21:25:35.671: Find a better model.
2023-05-25 21:25:42.144: [iter 32 : loss : 0.2353 = 0.1358 + 0.0972 + 0.0023, time: 6.472015]
2023-05-25 21:25:42.292: epoch 32:	0.02215683  	0.16332962  	0.08395989  
2023-05-25 21:25:42.292: Find a better model.
2023-05-25 21:25:48.739: [iter 33 : loss : 0.2328 = 0.1336 + 0.0968 + 0.0024, time: 6.445225]
2023-05-25 21:25:48.886: epoch 33:	0.02236852  	0.16472344  	0.08467601  
2023-05-25 21:25:48.886: Find a better model.
2023-05-25 21:25:55.528: [iter 34 : loss : 0.2284 = 0.1295 + 0.0965 + 0.0024, time: 6.640069]
2023-05-25 21:25:55.695: epoch 34:	0.02248142  	0.16563728  	0.08530647  
2023-05-25 21:25:55.695: Find a better model.
2023-05-25 21:26:02.330: [iter 35 : loss : 0.2251 = 0.1265 + 0.0962 + 0.0025, time: 6.634026]
2023-05-25 21:26:02.485: epoch 35:	0.02263667  	0.16659069  	0.08599351  
2023-05-25 21:26:02.485: Find a better model.
2023-05-25 21:26:08.941: [iter 36 : loss : 0.2217 = 0.1233 + 0.0959 + 0.0026, time: 6.454750]
2023-05-25 21:26:09.092: epoch 36:	0.02267901  	0.16679229  	0.08641277  
2023-05-25 21:26:09.092: Find a better model.
2023-05-25 21:26:15.547: [iter 37 : loss : 0.2178 = 0.1197 + 0.0955 + 0.0026, time: 6.453204]
2023-05-25 21:26:15.694: epoch 37:	0.02274957  	0.16762532  	0.08684597  
2023-05-25 21:26:15.694: Find a better model.
2023-05-25 21:26:22.140: [iter 38 : loss : 0.2165 = 0.1185 + 0.0953 + 0.0027, time: 6.443994]
2023-05-25 21:26:22.306: epoch 38:	0.02300361  	0.16974261  	0.08761356  
2023-05-25 21:26:22.306: Find a better model.
2023-05-25 21:26:28.711: [iter 39 : loss : 0.2119 = 0.1142 + 0.0949 + 0.0027, time: 6.402940]
2023-05-25 21:26:28.874: epoch 39:	0.02306712  	0.17032199  	0.08814044  
2023-05-25 21:26:28.874: Find a better model.
2023-05-25 21:26:35.493: [iter 40 : loss : 0.2085 = 0.1111 + 0.0946 + 0.0028, time: 6.617017]
2023-05-25 21:26:35.642: epoch 40:	0.02316591  	0.17131597  	0.08862084  
2023-05-25 21:26:35.642: Find a better model.
2023-05-25 21:26:42.128: [iter 41 : loss : 0.2070 = 0.1098 + 0.0944 + 0.0028, time: 6.484994]
2023-05-25 21:26:42.277: epoch 41:	0.02318708  	0.17120029  	0.08892763  
2023-05-25 21:26:48.729: [iter 42 : loss : 0.2047 = 0.1078 + 0.0941 + 0.0029, time: 6.451303]
2023-05-25 21:26:48.878: epoch 42:	0.02320119  	0.17143442  	0.08931787  
2023-05-25 21:26:48.878: Find a better model.
2023-05-25 21:26:55.321: [iter 43 : loss : 0.2010 = 0.1042 + 0.0938 + 0.0029, time: 6.442007]
2023-05-25 21:26:55.471: epoch 43:	0.02328587  	0.17195295  	0.08973392  
2023-05-25 21:26:55.471: Find a better model.
2023-05-25 21:27:01.903: [iter 44 : loss : 0.1973 = 0.1008 + 0.0936 + 0.0030, time: 6.429999]
2023-05-25 21:27:02.067: epoch 44:	0.02339171  	0.17289244  	0.09023273  
2023-05-25 21:27:02.067: Find a better model.
2023-05-25 21:27:08.530: [iter 45 : loss : 0.1952 = 0.0988 + 0.0933 + 0.0030, time: 6.460027]
2023-05-25 21:27:08.692: epoch 45:	0.02352579  	0.17378782  	0.09092207  
2023-05-25 21:27:08.692: Find a better model.
2023-05-25 21:27:15.114: [iter 46 : loss : 0.1928 = 0.0967 + 0.0930 + 0.0031, time: 6.421021]
2023-05-25 21:27:15.263: epoch 46:	0.02358930  	0.17413798  	0.09128740  
2023-05-25 21:27:15.264: Find a better model.
2023-05-25 21:27:21.675: [iter 47 : loss : 0.1922 = 0.0963 + 0.0928 + 0.0031, time: 6.409994]
2023-05-25 21:27:21.824: epoch 47:	0.02367398  	0.17438143  	0.09157982  
2023-05-25 21:27:21.824: Find a better model.
2023-05-25 21:27:28.306: [iter 48 : loss : 0.1883 = 0.0925 + 0.0926 + 0.0032, time: 6.481032]
2023-05-25 21:27:28.465: epoch 48:	0.02374454  	0.17486846  	0.09202965  
2023-05-25 21:27:28.465: Find a better model.
2023-05-25 21:27:34.916: [iter 49 : loss : 0.1852 = 0.0896 + 0.0924 + 0.0032, time: 6.449004]
2023-05-25 21:27:35.080: epoch 49:	0.02388567  	0.17609003  	0.09272396  
2023-05-25 21:27:35.080: Find a better model.
2023-05-25 21:27:41.497: [iter 50 : loss : 0.1846 = 0.0891 + 0.0922 + 0.0033, time: 6.416026]
2023-05-25 21:27:41.644: epoch 50:	0.02396329  	0.17698787  	0.09332760  
2023-05-25 21:27:41.644: Find a better model.
2023-05-25 21:27:48.109: [iter 51 : loss : 0.1813 = 0.0859 + 0.0921 + 0.0033, time: 6.463052]
2023-05-25 21:27:48.256: epoch 51:	0.02408325  	0.17744924  	0.09369165  
2023-05-25 21:27:48.256: Find a better model.
2023-05-25 21:27:54.887: [iter 52 : loss : 0.1811 = 0.0859 + 0.0918 + 0.0034, time: 6.630004]
2023-05-25 21:27:55.035: epoch 52:	0.02416792  	0.17778826  	0.09419630  
2023-05-25 21:27:55.035: Find a better model.
2023-05-25 21:28:01.664: [iter 53 : loss : 0.1793 = 0.0843 + 0.0916 + 0.0034, time: 6.628004]
2023-05-25 21:28:01.814: epoch 53:	0.02434433  	0.17893963  	0.09492746  
2023-05-25 21:28:01.814: Find a better model.
2023-05-25 21:28:08.486: [iter 54 : loss : 0.1771 = 0.0823 + 0.0914 + 0.0035, time: 6.670081]
2023-05-25 21:28:08.634: epoch 54:	0.02441490  	0.17947637  	0.09532586  
2023-05-25 21:28:08.635: Find a better model.
2023-05-25 21:28:15.262: [iter 55 : loss : 0.1753 = 0.0806 + 0.0912 + 0.0035, time: 6.625484]
2023-05-25 21:28:15.418: epoch 55:	0.02452074  	0.18015356  	0.09563243  
2023-05-25 21:28:15.419: Find a better model.
2023-05-25 21:28:22.107: [iter 56 : loss : 0.1734 = 0.0788 + 0.0910 + 0.0035, time: 6.686371]
2023-05-25 21:28:22.254: epoch 56:	0.02461954  	0.18091413  	0.09611047  
2023-05-25 21:28:22.254: Find a better model.
2023-05-25 21:28:28.884: [iter 57 : loss : 0.1717 = 0.0772 + 0.0909 + 0.0036, time: 6.628035]
2023-05-25 21:28:29.034: epoch 57:	0.02480300  	0.18243252  	0.09676906  
2023-05-25 21:28:29.034: Find a better model.
2023-05-25 21:28:35.695: [iter 58 : loss : 0.1697 = 0.0754 + 0.0907 + 0.0036, time: 6.659040]
2023-05-25 21:28:35.843: epoch 58:	0.02480300  	0.18228316  	0.09691634  
2023-05-25 21:28:42.474: [iter 59 : loss : 0.1685 = 0.0744 + 0.0905 + 0.0037, time: 6.629994]
2023-05-25 21:28:42.625: epoch 59:	0.02490178  	0.18303388  	0.09756291  
2023-05-25 21:28:42.625: Find a better model.
2023-05-25 21:28:49.284: [iter 60 : loss : 0.1670 = 0.0729 + 0.0904 + 0.0037, time: 6.657416]
2023-05-25 21:28:49.436: epoch 60:	0.02495824  	0.18370463  	0.09796915  
2023-05-25 21:28:49.436: Find a better model.
2023-05-25 21:28:56.089: [iter 61 : loss : 0.1659 = 0.0719 + 0.0902 + 0.0038, time: 6.651993]
2023-05-25 21:28:56.237: epoch 61:	0.02500763  	0.18398963  	0.09829815  
2023-05-25 21:28:56.238: Find a better model.
2023-05-25 21:29:02.882: [iter 62 : loss : 0.1643 = 0.0704 + 0.0900 + 0.0038, time: 6.642994]
2023-05-25 21:29:03.031: epoch 62:	0.02504997  	0.18447447  	0.09860431  
2023-05-25 21:29:03.031: Find a better model.
2023-05-25 21:29:09.653: [iter 63 : loss : 0.1628 = 0.0691 + 0.0898 + 0.0039, time: 6.620938]
2023-05-25 21:29:09.802: epoch 63:	0.02512759  	0.18484949  	0.09886358  
2023-05-25 21:29:09.802: Find a better model.
2023-05-25 21:29:16.470: [iter 64 : loss : 0.1618 = 0.0682 + 0.0897 + 0.0039, time: 6.666275]
2023-05-25 21:29:16.619: epoch 64:	0.02516993  	0.18523824  	0.09907286  
2023-05-25 21:29:16.619: Find a better model.
2023-05-25 21:29:23.268: [iter 65 : loss : 0.1604 = 0.0670 + 0.0895 + 0.0039, time: 6.648336]
2023-05-25 21:29:23.418: epoch 65:	0.02529695  	0.18589616  	0.09951977  
2023-05-25 21:29:23.418: Find a better model.
2023-05-25 21:29:30.077: [iter 66 : loss : 0.1590 = 0.0657 + 0.0894 + 0.0040, time: 6.657002]
2023-05-25 21:29:30.225: epoch 66:	0.02526166  	0.18593603  	0.09979579  
2023-05-25 21:29:30.225: Find a better model.
2023-05-25 21:29:36.877: [iter 67 : loss : 0.1575 = 0.0642 + 0.0893 + 0.0040, time: 6.650162]
2023-05-25 21:29:37.027: epoch 67:	0.02534634  	0.18650654  	0.10018709  
2023-05-25 21:29:37.027: Find a better model.
2023-05-25 21:29:43.679: [iter 68 : loss : 0.1573 = 0.0641 + 0.0891 + 0.0041, time: 6.650004]
2023-05-25 21:29:43.841: epoch 68:	0.02533223  	0.18650003  	0.10021531  
2023-05-25 21:29:50.461: [iter 69 : loss : 0.1553 = 0.0622 + 0.0890 + 0.0041, time: 6.618996]
2023-05-25 21:29:50.609: epoch 69:	0.02527577  	0.18603688  	0.10033759  
2023-05-25 21:29:57.277: [iter 70 : loss : 0.1535 = 0.0605 + 0.0889 + 0.0042, time: 6.666994]
2023-05-25 21:29:57.430: epoch 70:	0.02536046  	0.18671128  	0.10065188  
2023-05-25 21:29:57.430: Find a better model.
2023-05-25 21:30:04.215: [iter 71 : loss : 0.1523 = 0.0593 + 0.0887 + 0.0042, time: 6.782897]
2023-05-25 21:30:04.372: epoch 71:	0.02541691  	0.18717805  	0.10084246  
2023-05-25 21:30:04.372: Find a better model.
2023-05-25 21:30:11.056: [iter 72 : loss : 0.1519 = 0.0590 + 0.0886 + 0.0042, time: 6.682381]
2023-05-25 21:30:11.205: epoch 72:	0.02547336  	0.18784954  	0.10122311  
2023-05-25 21:30:11.205: Find a better model.
2023-05-25 21:30:17.852: [iter 73 : loss : 0.1505 = 0.0578 + 0.0885 + 0.0043, time: 6.646195]
2023-05-25 21:30:18.000: epoch 73:	0.02559332  	0.18817979  	0.10155302  
2023-05-25 21:30:18.000: Find a better model.
2023-05-25 21:30:24.655: [iter 74 : loss : 0.1491 = 0.0564 + 0.0884 + 0.0043, time: 6.652592]
2023-05-25 21:30:24.803: epoch 74:	0.02569211  	0.18894839  	0.10191187  
2023-05-25 21:30:24.803: Find a better model.
2023-05-25 21:30:31.446: [iter 75 : loss : 0.1486 = 0.0560 + 0.0883 + 0.0044, time: 6.642159]
2023-05-25 21:30:31.607: epoch 75:	0.02563565  	0.18832238  	0.10182218  
2023-05-25 21:30:38.245: [iter 76 : loss : 0.1476 = 0.0550 + 0.0881 + 0.0044, time: 6.636463]
2023-05-25 21:30:38.410: epoch 76:	0.02566388  	0.18863107  	0.10215775  
2023-05-25 21:30:45.047: [iter 77 : loss : 0.1465 = 0.0541 + 0.0880 + 0.0044, time: 6.635000]
2023-05-25 21:30:45.211: epoch 77:	0.02575562  	0.18938510  	0.10250708  
2023-05-25 21:30:45.211: Find a better model.
2023-05-25 21:30:51.813: [iter 78 : loss : 0.1460 = 0.0536 + 0.0880 + 0.0045, time: 6.600994]
2023-05-25 21:30:51.961: epoch 78:	0.02583324  	0.19001158  	0.10291748  
2023-05-25 21:30:51.961: Find a better model.
2023-05-25 21:30:58.617: [iter 79 : loss : 0.1443 = 0.0520 + 0.0878 + 0.0045, time: 6.655493]
2023-05-25 21:30:58.766: epoch 79:	0.02584029  	0.18992704  	0.10318016  
2023-05-25 21:31:05.426: [iter 80 : loss : 0.1435 = 0.0512 + 0.0878 + 0.0046, time: 6.657642]
2023-05-25 21:31:05.574: epoch 80:	0.02590380  	0.19066747  	0.10343491  
2023-05-25 21:31:05.574: Find a better model.
2023-05-25 21:31:12.217: [iter 81 : loss : 0.1438 = 0.0515 + 0.0876 + 0.0046, time: 6.641994]
2023-05-25 21:31:12.384: epoch 81:	0.02585441  	0.19060220  	0.10363664  
2023-05-25 21:31:19.023: [iter 82 : loss : 0.1421 = 0.0499 + 0.0875 + 0.0046, time: 6.636861]
2023-05-25 21:31:19.174: epoch 82:	0.02591791  	0.19121872  	0.10385925  
2023-05-25 21:31:19.174: Find a better model.
2023-05-25 21:31:25.632: [iter 83 : loss : 0.1413 = 0.0492 + 0.0875 + 0.0047, time: 6.456994]
2023-05-25 21:31:25.780: epoch 83:	0.02590380  	0.19112846  	0.10397351  
2023-05-25 21:31:32.415: [iter 84 : loss : 0.1413 = 0.0492 + 0.0873 + 0.0047, time: 6.633001]
2023-05-25 21:31:32.564: epoch 84:	0.02599554  	0.19171609  	0.10426582  
2023-05-25 21:31:32.564: Find a better model.
2023-05-25 21:31:39.218: [iter 85 : loss : 0.1402 = 0.0482 + 0.0872 + 0.0047, time: 6.653033]
2023-05-25 21:31:39.382: epoch 85:	0.02610844  	0.19241816  	0.10460685  
2023-05-25 21:31:39.383: Find a better model.
2023-05-25 21:31:45.831: [iter 86 : loss : 0.1398 = 0.0478 + 0.0871 + 0.0048, time: 6.447042]
2023-05-25 21:31:45.979: epoch 86:	0.02607315  	0.19222982  	0.10462012  
2023-05-25 21:31:52.596: [iter 87 : loss : 0.1372 = 0.0454 + 0.0871 + 0.0048, time: 6.615192]
2023-05-25 21:31:52.745: epoch 87:	0.02609432  	0.19271186  	0.10486133  
2023-05-25 21:31:52.745: Find a better model.
2023-05-25 21:31:59.413: [iter 88 : loss : 0.1365 = 0.0446 + 0.0870 + 0.0049, time: 6.666011]
2023-05-25 21:31:59.575: epoch 88:	0.02609432  	0.19276297  	0.10505664  
2023-05-25 21:31:59.575: Find a better model.
2023-05-25 21:32:06.209: [iter 89 : loss : 0.1362 = 0.0444 + 0.0869 + 0.0049, time: 6.632795]
2023-05-25 21:32:06.363: epoch 89:	0.02620722  	0.19368610  	0.10522961  
2023-05-25 21:32:06.363: Find a better model.
2023-05-25 21:32:12.967: [iter 90 : loss : 0.1368 = 0.0451 + 0.0868 + 0.0049, time: 6.602468]
2023-05-25 21:32:13.119: epoch 90:	0.02626367  	0.19409740  	0.10559210  
2023-05-25 21:32:13.119: Find a better model.
2023-05-25 21:32:19.620: [iter 91 : loss : 0.1357 = 0.0441 + 0.0867 + 0.0050, time: 6.500041]
2023-05-25 21:32:19.769: epoch 91:	0.02630601  	0.19422784  	0.10570654  
2023-05-25 21:32:19.769: Find a better model.
2023-05-25 21:32:26.214: [iter 92 : loss : 0.1347 = 0.0431 + 0.0866 + 0.0050, time: 6.442994]
2023-05-25 21:32:26.370: epoch 92:	0.02641186  	0.19513136  	0.10601354  
2023-05-25 21:32:26.370: Find a better model.
2023-05-25 21:32:32.816: [iter 93 : loss : 0.1348 = 0.0432 + 0.0866 + 0.0050, time: 6.443990]
2023-05-25 21:32:32.965: epoch 93:	0.02636952  	0.19474998  	0.10596376  
2023-05-25 21:32:39.417: [iter 94 : loss : 0.1329 = 0.0414 + 0.0865 + 0.0051, time: 6.449359]
2023-05-25 21:32:39.567: epoch 94:	0.02631306  	0.19412877  	0.10602254  
2023-05-25 21:32:46.186: [iter 95 : loss : 0.1322 = 0.0407 + 0.0864 + 0.0051, time: 6.617002]
2023-05-25 21:32:46.332: epoch 95:	0.02637657  	0.19458751  	0.10637774  
2023-05-25 21:32:52.797: [iter 96 : loss : 0.1323 = 0.0408 + 0.0863 + 0.0052, time: 6.464416]
2023-05-25 21:32:52.947: epoch 96:	0.02640480  	0.19487002  	0.10671901  
2023-05-25 21:32:59.398: [iter 97 : loss : 0.1306 = 0.0391 + 0.0862 + 0.0052, time: 6.449398]
2023-05-25 21:32:59.545: epoch 97:	0.02643303  	0.19519971  	0.10659885  
2023-05-25 21:32:59.545: Find a better model.
2023-05-25 21:33:06.180: [iter 98 : loss : 0.1314 = 0.0400 + 0.0862 + 0.0052, time: 6.633995]
2023-05-25 21:33:06.344: epoch 98:	0.02640480  	0.19496755  	0.10676862  
2023-05-25 21:33:12.797: [iter 99 : loss : 0.1302 = 0.0388 + 0.0861 + 0.0053, time: 6.452664]
2023-05-25 21:33:12.944: epoch 99:	0.02640480  	0.19483033  	0.10676960  
2023-05-25 21:33:19.389: [iter 100 : loss : 0.1298 = 0.0385 + 0.0860 + 0.0053, time: 6.444061]
2023-05-25 21:33:19.537: epoch 100:	0.02638363  	0.19471948  	0.10674780  
2023-05-25 21:33:25.989: [iter 101 : loss : 0.1294 = 0.0381 + 0.0859 + 0.0053, time: 6.450016]
2023-05-25 21:33:26.141: epoch 101:	0.02645420  	0.19506650  	0.10695957  
2023-05-25 21:33:32.588: [iter 102 : loss : 0.1283 = 0.0370 + 0.0859 + 0.0054, time: 6.445063]
2023-05-25 21:33:32.740: epoch 102:	0.02642597  	0.19473566  	0.10688907  
2023-05-25 21:33:39.158: [iter 103 : loss : 0.1279 = 0.0367 + 0.0858 + 0.0054, time: 6.417004]
2023-05-25 21:33:39.305: epoch 103:	0.02641891  	0.19500078  	0.10695617  
2023-05-25 21:33:45.768: [iter 104 : loss : 0.1284 = 0.0372 + 0.0858 + 0.0054, time: 6.460996]
2023-05-25 21:33:45.916: epoch 104:	0.02651770  	0.19581851  	0.10721080  
2023-05-25 21:33:45.916: Find a better model.
2023-05-25 21:33:52.387: [iter 105 : loss : 0.1278 = 0.0367 + 0.0857 + 0.0055, time: 6.470014]
2023-05-25 21:33:52.538: epoch 105:	0.02650359  	0.19562982  	0.10703617  
2023-05-25 21:33:58.983: [iter 106 : loss : 0.1272 = 0.0361 + 0.0856 + 0.0055, time: 6.444005]
2023-05-25 21:33:59.132: epoch 106:	0.02653887  	0.19592021  	0.10721768  
2023-05-25 21:33:59.133: Find a better model.
2023-05-25 21:34:05.558: [iter 107 : loss : 0.1264 = 0.0353 + 0.0856 + 0.0055, time: 6.424006]
2023-05-25 21:34:05.707: epoch 107:	0.02653182  	0.19584338  	0.10732523  
2023-05-25 21:34:12.157: [iter 108 : loss : 0.1261 = 0.0350 + 0.0856 + 0.0056, time: 6.447994]
2023-05-25 21:34:12.305: epoch 108:	0.02659533  	0.19636711  	0.10745034  
2023-05-25 21:34:12.305: Find a better model.
2023-05-25 21:34:18.746: [iter 109 : loss : 0.1248 = 0.0337 + 0.0855 + 0.0056, time: 6.438656]
2023-05-25 21:34:18.893: epoch 109:	0.02659532  	0.19640994  	0.10755213  
2023-05-25 21:34:18.893: Find a better model.
2023-05-25 21:34:25.369: [iter 110 : loss : 0.1242 = 0.0331 + 0.0854 + 0.0056, time: 6.475004]
2023-05-25 21:34:25.532: epoch 110:	0.02664472  	0.19654718  	0.10759567  
2023-05-25 21:34:25.532: Find a better model.
2023-05-25 21:34:31.946: [iter 111 : loss : 0.1243 = 0.0332 + 0.0854 + 0.0057, time: 6.412004]
2023-05-25 21:34:32.094: epoch 111:	0.02654594  	0.19575892  	0.10746305  
2023-05-25 21:34:38.523: [iter 112 : loss : 0.1240 = 0.0330 + 0.0853 + 0.0057, time: 6.427035]
2023-05-25 21:34:38.674: epoch 112:	0.02660944  	0.19617836  	0.10758223  
2023-05-25 21:34:45.160: [iter 113 : loss : 0.1237 = 0.0327 + 0.0853 + 0.0057, time: 6.485053]
2023-05-25 21:34:45.308: epoch 113:	0.02669412  	0.19683874  	0.10782328  
2023-05-25 21:34:45.308: Find a better model.
2023-05-25 21:34:51.713: [iter 114 : loss : 0.1230 = 0.0320 + 0.0852 + 0.0058, time: 6.404011]
2023-05-25 21:34:51.863: epoch 114:	0.02664472  	0.19648358  	0.10774848  
2023-05-25 21:34:58.156: [iter 115 : loss : 0.1226 = 0.0317 + 0.0851 + 0.0058, time: 6.291196]
2023-05-25 21:34:58.303: epoch 115:	0.02660944  	0.19636601  	0.10775533  
2023-05-25 21:35:04.721: [iter 116 : loss : 0.1217 = 0.0308 + 0.0851 + 0.0058, time: 6.417028]
2023-05-25 21:35:04.868: epoch 116:	0.02664473  	0.19652103  	0.10781332  
2023-05-25 21:35:11.330: [iter 117 : loss : 0.1217 = 0.0308 + 0.0850 + 0.0059, time: 6.461017]
2023-05-25 21:35:11.478: epoch 117:	0.02661650  	0.19645917  	0.10777276  
2023-05-25 21:35:17.945: [iter 118 : loss : 0.1215 = 0.0306 + 0.0849 + 0.0059, time: 6.465994]
2023-05-25 21:35:18.093: epoch 118:	0.02668001  	0.19689675  	0.10802325  
2023-05-25 21:35:18.093: Find a better model.
2023-05-25 21:35:24.510: [iter 119 : loss : 0.1205 = 0.0297 + 0.0849 + 0.0059, time: 6.415004]
2023-05-25 21:35:24.660: epoch 119:	0.02668707  	0.19683078  	0.10814954  
2023-05-25 21:35:31.135: [iter 120 : loss : 0.1209 = 0.0301 + 0.0849 + 0.0060, time: 6.471085]
2023-05-25 21:35:31.285: epoch 120:	0.02666590  	0.19672154  	0.10815501  
2023-05-25 21:35:37.726: [iter 121 : loss : 0.1208 = 0.0300 + 0.0848 + 0.0060, time: 6.440084]
2023-05-25 21:35:37.874: epoch 121:	0.02670118  	0.19701467  	0.10831106  
2023-05-25 21:35:37.874: Find a better model.
2023-05-25 21:35:44.338: [iter 122 : loss : 0.1199 = 0.0290 + 0.0848 + 0.0060, time: 6.462013]
2023-05-25 21:35:44.491: epoch 122:	0.02666590  	0.19673283  	0.10822979  
2023-05-25 21:35:50.745: [iter 123 : loss : 0.1199 = 0.0291 + 0.0847 + 0.0061, time: 6.252007]
2023-05-25 21:35:50.895: epoch 123:	0.02672941  	0.19710702  	0.10833328  
2023-05-25 21:35:50.895: Find a better model.
2023-05-25 21:35:57.334: [iter 124 : loss : 0.1191 = 0.0283 + 0.0847 + 0.0061, time: 6.437994]
2023-05-25 21:35:57.487: epoch 124:	0.02670824  	0.19680148  	0.10833839  
2023-05-25 21:36:03.927: [iter 125 : loss : 0.1184 = 0.0277 + 0.0846 + 0.0061, time: 6.439003]
2023-05-25 21:36:04.076: epoch 125:	0.02668707  	0.19640632  	0.10830620  
2023-05-25 21:36:10.512: [iter 126 : loss : 0.1187 = 0.0280 + 0.0846 + 0.0061, time: 6.435004]
2023-05-25 21:36:10.665: epoch 126:	0.02665179  	0.19602761  	0.10800290  
2023-05-25 21:36:17.093: [iter 127 : loss : 0.1178 = 0.0271 + 0.0846 + 0.0062, time: 6.426003]
2023-05-25 21:36:17.244: epoch 127:	0.02670118  	0.19669558  	0.10812467  
2023-05-25 21:36:23.685: [iter 128 : loss : 0.1186 = 0.0278 + 0.0845 + 0.0062, time: 6.440006]
2023-05-25 21:36:23.834: epoch 128:	0.02665884  	0.19628403  	0.10806566  
2023-05-25 21:36:30.289: [iter 129 : loss : 0.1179 = 0.0272 + 0.0845 + 0.0062, time: 6.453004]
2023-05-25 21:36:30.446: epoch 129:	0.02667296  	0.19618478  	0.10815445  
2023-05-25 21:36:36.897: [iter 130 : loss : 0.1179 = 0.0272 + 0.0844 + 0.0063, time: 6.450015]
2023-05-25 21:36:37.049: epoch 130:	0.02676470  	0.19696441  	0.10844191  
2023-05-25 21:36:43.499: [iter 131 : loss : 0.1170 = 0.0263 + 0.0844 + 0.0063, time: 6.449007]
2023-05-25 21:36:43.648: epoch 131:	0.02669412  	0.19638664  	0.10835613  
2023-05-25 21:36:50.099: [iter 132 : loss : 0.1173 = 0.0267 + 0.0843 + 0.0063, time: 6.449011]
2023-05-25 21:36:50.247: epoch 132:	0.02663768  	0.19567734  	0.10824626  
2023-05-25 21:36:56.516: [iter 133 : loss : 0.1159 = 0.0253 + 0.0843 + 0.0064, time: 6.266556]
2023-05-25 21:36:56.665: epoch 133:	0.02663062  	0.19571146  	0.10850903  
2023-05-25 21:37:02.913: [iter 134 : loss : 0.1168 = 0.0261 + 0.0843 + 0.0064, time: 6.246014]
2023-05-25 21:37:03.065: epoch 134:	0.02668707  	0.19620794  	0.10852741  
2023-05-25 21:37:09.478: [iter 135 : loss : 0.1164 = 0.0258 + 0.0842 + 0.0064, time: 6.412195]
2023-05-25 21:37:09.632: epoch 135:	0.02670118  	0.19586323  	0.10854066  
2023-05-25 21:37:16.100: [iter 136 : loss : 0.1160 = 0.0253 + 0.0842 + 0.0064, time: 6.465997]
2023-05-25 21:37:16.252: epoch 136:	0.02669412  	0.19589272  	0.10852626  
2023-05-25 21:37:22.699: [iter 137 : loss : 0.1155 = 0.0249 + 0.0841 + 0.0065, time: 6.444241]
2023-05-25 21:37:22.866: epoch 137:	0.02665884  	0.19585262  	0.10855351  
2023-05-25 21:37:29.295: [iter 138 : loss : 0.1154 = 0.0248 + 0.0841 + 0.0065, time: 6.427994]
2023-05-25 21:37:29.447: epoch 138:	0.02673646  	0.19623947  	0.10880633  
2023-05-25 21:37:35.891: [iter 139 : loss : 0.1153 = 0.0247 + 0.0841 + 0.0065, time: 6.443316]
2023-05-25 21:37:36.041: epoch 139:	0.02666590  	0.19579993  	0.10862917  
2023-05-25 21:37:42.476: [iter 140 : loss : 0.1145 = 0.0239 + 0.0840 + 0.0066, time: 6.432994]
2023-05-25 21:37:42.628: epoch 140:	0.02670117  	0.19607300  	0.10875324  
2023-05-25 21:37:49.089: [iter 141 : loss : 0.1151 = 0.0245 + 0.0840 + 0.0066, time: 6.459000]
2023-05-25 21:37:49.238: epoch 141:	0.02667295  	0.19592576  	0.10874301  
2023-05-25 21:37:55.503: [iter 142 : loss : 0.1141 = 0.0236 + 0.0839 + 0.0066, time: 6.264028]
2023-05-25 21:37:55.653: epoch 142:	0.02666589  	0.19561318  	0.10866290  
2023-05-25 21:38:02.058: [iter 143 : loss : 0.1142 = 0.0237 + 0.0839 + 0.0066, time: 6.404015]
2023-05-25 21:38:02.208: epoch 143:	0.02665178  	0.19542851  	0.10871881  
2023-05-25 21:38:08.680: [iter 144 : loss : 0.1135 = 0.0230 + 0.0839 + 0.0067, time: 6.470046]
2023-05-25 21:38:08.832: epoch 144:	0.02665178  	0.19516414  	0.10864709  
2023-05-25 21:38:15.289: [iter 145 : loss : 0.1134 = 0.0228 + 0.0838 + 0.0067, time: 6.456022]
2023-05-25 21:38:15.450: epoch 145:	0.02660238  	0.19507141  	0.10862613  
2023-05-25 21:38:21.877: [iter 146 : loss : 0.1140 = 0.0234 + 0.0838 + 0.0067, time: 6.425004]
2023-05-25 21:38:22.025: epoch 146:	0.02663061  	0.19528235  	0.10869601  
2023-05-25 21:38:28.477: [iter 147 : loss : 0.1136 = 0.0231 + 0.0838 + 0.0067, time: 6.450004]
2023-05-25 21:38:28.646: epoch 147:	0.02668000  	0.19568628  	0.10897502  
2023-05-25 21:38:35.074: [iter 148 : loss : 0.1124 = 0.0219 + 0.0837 + 0.0068, time: 6.427014]
2023-05-25 21:38:35.224: epoch 148:	0.02665178  	0.19540267  	0.10892893  
2023-05-25 21:38:35.224: Early stopping is trigger at epoch: 148
2023-05-25 21:38:35.224: best_result@epoch 123:

2023-05-25 21:38:35.224: 		0.0267      	0.1971      	0.1083      
2023-05-25 21:55:18.783: my pid: 3748
2023-05-25 21:55:18.783: model: model.general_recommender.SGL
2023-05-25 21:55:18.783: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-25 21:55:18.783: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 21:55:22.527: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 21:55:30.224: [iter 1 : loss : 0.7706 = 0.6930 + 0.0776 + 0.0000, time: 7.696588]
2023-05-25 21:55:30.376: epoch 1:	0.00183461  	0.01236751  	0.00641957  
2023-05-25 21:55:30.376: Find a better model.
2023-05-25 21:55:38.225: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.848294]
2023-05-25 21:55:38.424: epoch 2:	0.00339401  	0.02335494  	0.01195696  
2023-05-25 21:55:38.424: Find a better model.
2023-05-25 21:55:46.199: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.774039]
2023-05-25 21:55:46.375: epoch 3:	0.00569429  	0.03921259  	0.01960516  
2023-05-25 21:55:46.375: Find a better model.
2023-05-25 21:55:53.973: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.595993]
2023-05-25 21:55:54.140: epoch 4:	0.00808630  	0.05648810  	0.02844983  
2023-05-25 21:55:54.140: Find a better model.
2023-05-25 21:56:01.572: [iter 5 : loss : 0.7685 = 0.6912 + 0.0773 + 0.0000, time: 7.431145]
2023-05-25 21:56:01.728: epoch 5:	0.01091589  	0.07726161  	0.03741086  
2023-05-25 21:56:01.728: Find a better model.
2023-05-25 21:56:08.966: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.237014]
2023-05-25 21:56:09.137: epoch 6:	0.01384432  	0.09877191  	0.04794341  
2023-05-25 21:56:09.137: Find a better model.
2023-05-25 21:56:16.363: [iter 7 : loss : 0.7604 = 0.6822 + 0.0781 + 0.0000, time: 7.224018]
2023-05-25 21:56:16.518: epoch 7:	0.01661748  	0.12048244  	0.05941228  
2023-05-25 21:56:16.518: Find a better model.
2023-05-25 21:56:23.552: [iter 8 : loss : 0.7460 = 0.6664 + 0.0795 + 0.0001, time: 7.032006]
2023-05-25 21:56:23.703: epoch 8:	0.01818401  	0.13326196  	0.06658761  
2023-05-25 21:56:23.703: Find a better model.
2023-05-25 21:56:30.737: [iter 9 : loss : 0.7139 = 0.6311 + 0.0827 + 0.0001, time: 7.032937]
2023-05-25 21:56:30.891: epoch 9:	0.01888966  	0.13894115  	0.06959072  
2023-05-25 21:56:30.891: Find a better model.
2023-05-25 21:56:37.740: [iter 10 : loss : 0.6577 = 0.5699 + 0.0876 + 0.0002, time: 6.848013]
2023-05-25 21:56:37.890: epoch 10:	0.01872735  	0.13819201  	0.06943880  
2023-05-25 21:56:44.758: [iter 11 : loss : 0.5837 = 0.4907 + 0.0926 + 0.0004, time: 6.867003]
2023-05-25 21:56:44.911: epoch 11:	0.01871325  	0.13850106  	0.06945288  
2023-05-25 21:56:51.930: [iter 12 : loss : 0.5123 = 0.4155 + 0.0963 + 0.0005, time: 7.016960]
2023-05-25 21:56:52.086: epoch 12:	0.01860740  	0.13764323  	0.06942309  
2023-05-25 21:56:58.976: [iter 13 : loss : 0.4582 = 0.3590 + 0.0985 + 0.0007, time: 6.887004]
2023-05-25 21:56:59.129: epoch 13:	0.01866386  	0.13818514  	0.06990115  
2023-05-25 21:57:05.970: [iter 14 : loss : 0.4170 = 0.3166 + 0.0996 + 0.0008, time: 6.838004]
2023-05-25 21:57:06.138: epoch 14:	0.01881204  	0.13954856  	0.07087963  
2023-05-25 21:57:06.138: Find a better model.
2023-05-25 21:57:12.968: [iter 15 : loss : 0.3882 = 0.2872 + 0.1001 + 0.0010, time: 6.829026]
2023-05-25 21:57:13.124: epoch 15:	0.01905196  	0.14149752  	0.07188386  
2023-05-25 21:57:13.124: Find a better model.
2023-05-25 21:57:20.118: [iter 16 : loss : 0.3646 = 0.2633 + 0.1002 + 0.0011, time: 6.993039]
2023-05-25 21:57:20.271: epoch 16:	0.01926366  	0.14257549  	0.07258890  
2023-05-25 21:57:20.271: Find a better model.
2023-05-25 21:57:27.318: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 7.046010]
2023-05-25 21:57:27.470: epoch 17:	0.01952475  	0.14435115  	0.07346696  
2023-05-25 21:57:27.470: Find a better model.
2023-05-25 21:57:34.366: [iter 18 : loss : 0.3315 = 0.2302 + 0.1000 + 0.0013, time: 6.892643]
2023-05-25 21:57:34.515: epoch 18:	0.01970823  	0.14547800  	0.07412752  
2023-05-25 21:57:34.515: Find a better model.
2023-05-25 21:57:41.533: [iter 19 : loss : 0.3169 = 0.2158 + 0.0997 + 0.0014, time: 7.016001]
2023-05-25 21:57:41.697: epoch 19:	0.01989876  	0.14681418  	0.07483394  
2023-05-25 21:57:41.697: Find a better model.
2023-05-25 21:57:48.724: [iter 20 : loss : 0.3069 = 0.2061 + 0.0993 + 0.0015, time: 7.025008]
2023-05-25 21:57:48.883: epoch 20:	0.01996226  	0.14709879  	0.07529653  
2023-05-25 21:57:48.883: Find a better model.
2023-05-25 21:57:55.719: [iter 21 : loss : 0.2969 = 0.1964 + 0.0989 + 0.0016, time: 6.835117]
2023-05-25 21:57:55.868: epoch 21:	0.02027981  	0.14938436  	0.07626184  
2023-05-25 21:57:55.868: Find a better model.
2023-05-25 21:58:02.907: [iter 22 : loss : 0.2886 = 0.1884 + 0.0985 + 0.0017, time: 7.038019]
2023-05-25 21:58:03.056: epoch 22:	0.02041388  	0.15025993  	0.07680344  
2023-05-25 21:58:03.056: Find a better model.
2023-05-25 21:58:10.112: [iter 23 : loss : 0.2802 = 0.1803 + 0.0981 + 0.0018, time: 7.055000]
2023-05-25 21:58:10.264: epoch 23:	0.02053383  	0.15106921  	0.07751744  
2023-05-25 21:58:10.264: Find a better model.
2023-05-25 21:58:17.303: [iter 24 : loss : 0.2736 = 0.1740 + 0.0977 + 0.0018, time: 7.037392]
2023-05-25 21:58:17.457: epoch 24:	0.02078787  	0.15308173  	0.07848143  
2023-05-25 21:58:17.457: Find a better model.
2023-05-25 21:58:24.493: [iter 25 : loss : 0.2667 = 0.1675 + 0.0973 + 0.0019, time: 7.033006]
2023-05-25 21:58:24.642: epoch 25:	0.02087961  	0.15337154  	0.07890216  
2023-05-25 21:58:24.643: Find a better model.
2023-05-25 21:58:31.542: [iter 26 : loss : 0.2630 = 0.1641 + 0.0969 + 0.0020, time: 6.898049]
2023-05-25 21:58:31.706: epoch 26:	0.02112659  	0.15508309  	0.07974935  
2023-05-25 21:58:31.706: Find a better model.
2023-05-25 21:58:38.542: [iter 27 : loss : 0.2551 = 0.1566 + 0.0965 + 0.0020, time: 6.834024]
2023-05-25 21:58:38.704: epoch 27:	0.02133829  	0.15645410  	0.08044992  
2023-05-25 21:58:38.705: Find a better model.
2023-05-25 21:58:45.695: [iter 28 : loss : 0.2503 = 0.1521 + 0.0961 + 0.0021, time: 6.989014]
2023-05-25 21:58:45.845: epoch 28:	0.02147236  	0.15735768  	0.08131745  
2023-05-25 21:58:45.845: Find a better model.
2023-05-25 21:58:52.894: [iter 29 : loss : 0.2458 = 0.1480 + 0.0956 + 0.0022, time: 7.047016]
2023-05-25 21:58:53.043: epoch 29:	0.02167699  	0.15908341  	0.08226252  
2023-05-25 21:58:53.043: Find a better model.
2023-05-25 21:59:00.067: [iter 30 : loss : 0.2392 = 0.1417 + 0.0953 + 0.0022, time: 7.023000]
2023-05-25 21:59:00.218: epoch 30:	0.02178284  	0.16044876  	0.08293393  
2023-05-25 21:59:00.218: Find a better model.
2023-05-25 21:59:07.125: [iter 31 : loss : 0.2356 = 0.1384 + 0.0949 + 0.0023, time: 6.904464]
2023-05-25 21:59:07.276: epoch 31:	0.02186751  	0.16057427  	0.08329571  
2023-05-25 21:59:07.276: Find a better model.
2023-05-25 21:59:14.279: [iter 32 : loss : 0.2300 = 0.1331 + 0.0946 + 0.0024, time: 7.002241]
2023-05-25 21:59:14.427: epoch 32:	0.02212860  	0.16257350  	0.08435014  
2023-05-25 21:59:14.427: Find a better model.
2023-05-25 21:59:21.477: [iter 33 : loss : 0.2273 = 0.1307 + 0.0942 + 0.0024, time: 7.048020]
2023-05-25 21:59:21.642: epoch 33:	0.02219917  	0.16291153  	0.08473682  
2023-05-25 21:59:21.642: Find a better model.
2023-05-25 21:59:28.502: [iter 34 : loss : 0.2234 = 0.1270 + 0.0938 + 0.0025, time: 6.859025]
2023-05-25 21:59:28.650: epoch 34:	0.02229089  	0.16361551  	0.08533307  
2023-05-25 21:59:28.650: Find a better model.
2023-05-25 21:59:35.661: [iter 35 : loss : 0.2200 = 0.1239 + 0.0936 + 0.0025, time: 7.009154]
2023-05-25 21:59:35.811: epoch 35:	0.02251670  	0.16539687  	0.08611237  
2023-05-25 21:59:35.812: Find a better model.
2023-05-25 21:59:42.872: [iter 36 : loss : 0.2165 = 0.1206 + 0.0932 + 0.0026, time: 7.058993]
2023-05-25 21:59:43.041: epoch 36:	0.02262255  	0.16630647  	0.08676223  
2023-05-25 21:59:43.042: Find a better model.
2023-05-25 21:59:50.072: [iter 37 : loss : 0.2125 = 0.1170 + 0.0929 + 0.0027, time: 7.028000]
2023-05-25 21:59:50.223: epoch 37:	0.02282014  	0.16797574  	0.08749385  
2023-05-25 21:59:50.223: Find a better model.
2023-05-25 21:59:57.273: [iter 38 : loss : 0.2110 = 0.1157 + 0.0926 + 0.0027, time: 7.048011]
2023-05-25 21:59:57.426: epoch 38:	0.02292599  	0.16889168  	0.08832098  
2023-05-25 21:59:57.426: Find a better model.
2023-05-25 22:00:04.313: [iter 39 : loss : 0.2066 = 0.1115 + 0.0923 + 0.0028, time: 6.885504]
2023-05-25 22:00:04.481: epoch 39:	0.02314474  	0.17035054  	0.08942634  
2023-05-25 22:00:04.481: Find a better model.
2023-05-25 22:00:11.311: [iter 40 : loss : 0.2034 = 0.1085 + 0.0920 + 0.0028, time: 6.827011]
2023-05-25 22:00:11.461: epoch 40:	0.02321531  	0.17081171  	0.08966282  
2023-05-25 22:00:11.461: Find a better model.
2023-05-25 22:00:18.314: [iter 41 : loss : 0.2017 = 0.1071 + 0.0917 + 0.0029, time: 6.852016]
2023-05-25 22:00:18.477: epoch 41:	0.02325059  	0.17118654  	0.09005117  
2023-05-25 22:00:18.477: Find a better model.
2023-05-25 22:00:25.446: [iter 42 : loss : 0.1995 = 0.1051 + 0.0915 + 0.0029, time: 6.967010]
2023-05-25 22:00:25.597: epoch 42:	0.02330704  	0.17206314  	0.09066550  
2023-05-25 22:00:25.597: Find a better model.
2023-05-25 22:00:32.473: [iter 43 : loss : 0.1955 = 0.1014 + 0.0912 + 0.0030, time: 6.874029]
2023-05-25 22:00:32.626: epoch 43:	0.02342700  	0.17316291  	0.09097954  
2023-05-25 22:00:32.626: Find a better model.
2023-05-25 22:00:39.511: [iter 44 : loss : 0.1921 = 0.0982 + 0.0909 + 0.0030, time: 6.881957]
2023-05-25 22:00:39.675: epoch 44:	0.02349051  	0.17356110  	0.09148567  
2023-05-25 22:00:39.675: Find a better model.
2023-05-25 22:00:46.651: [iter 45 : loss : 0.1900 = 0.0962 + 0.0907 + 0.0031, time: 6.974242]
2023-05-25 22:00:46.799: epoch 45:	0.02365281  	0.17470303  	0.09201422  
2023-05-25 22:00:46.799: Find a better model.
2023-05-25 22:00:53.667: [iter 46 : loss : 0.1876 = 0.0941 + 0.0904 + 0.0031, time: 6.866006]
2023-05-25 22:00:53.820: epoch 46:	0.02369515  	0.17490071  	0.09253069  
2023-05-25 22:00:53.820: Find a better model.
2023-05-25 22:01:00.666: [iter 47 : loss : 0.1868 = 0.0934 + 0.0902 + 0.0032, time: 6.844009]
2023-05-25 22:01:00.818: epoch 47:	0.02372337  	0.17514330  	0.09286022  
2023-05-25 22:01:00.818: Find a better model.
2023-05-25 22:01:07.848: [iter 48 : loss : 0.1830 = 0.0898 + 0.0899 + 0.0032, time: 7.028970]
2023-05-25 22:01:08.015: epoch 48:	0.02377982  	0.17574771  	0.09340488  
2023-05-25 22:01:08.015: Find a better model.
2023-05-25 22:01:14.860: [iter 49 : loss : 0.1799 = 0.0868 + 0.0898 + 0.0033, time: 6.844006]
2023-05-25 22:01:15.015: epoch 49:	0.02387861  	0.17628348  	0.09388212  
2023-05-25 22:01:15.015: Find a better model.
2023-05-25 22:01:21.855: [iter 50 : loss : 0.1791 = 0.0862 + 0.0895 + 0.0033, time: 6.839212]
2023-05-25 22:01:22.005: epoch 50:	0.02397034  	0.17681864  	0.09435506  
2023-05-25 22:01:22.005: Find a better model.
2023-05-25 22:01:29.031: [iter 51 : loss : 0.1761 = 0.0833 + 0.0893 + 0.0034, time: 7.025023]
2023-05-25 22:01:29.183: epoch 51:	0.02406913  	0.17761993  	0.09447741  
2023-05-25 22:01:29.183: Find a better model.
2023-05-25 22:01:36.083: [iter 52 : loss : 0.1760 = 0.0835 + 0.0891 + 0.0034, time: 6.898063]
2023-05-25 22:01:36.249: epoch 52:	0.02414674  	0.17800161  	0.09501617  
2023-05-25 22:01:36.250: Find a better model.
2023-05-25 22:01:43.269: [iter 53 : loss : 0.1739 = 0.0816 + 0.0889 + 0.0035, time: 7.018004]
2023-05-25 22:01:43.432: epoch 53:	0.02422437  	0.17870639  	0.09540950  
2023-05-25 22:01:43.432: Find a better model.
2023-05-25 22:01:50.471: [iter 54 : loss : 0.1719 = 0.0797 + 0.0887 + 0.0035, time: 7.037005]
2023-05-25 22:01:50.637: epoch 54:	0.02433727  	0.17925531  	0.09584527  
2023-05-25 22:01:50.638: Find a better model.
2023-05-25 22:01:57.646: [iter 55 : loss : 0.1700 = 0.0779 + 0.0885 + 0.0036, time: 7.006178]
2023-05-25 22:01:57.809: epoch 55:	0.02438666  	0.17950936  	0.09599542  
2023-05-25 22:01:57.810: Find a better model.
2023-05-25 22:02:04.651: [iter 56 : loss : 0.1684 = 0.0765 + 0.0883 + 0.0036, time: 6.840160]
2023-05-25 22:02:04.812: epoch 56:	0.02445018  	0.18027648  	0.09656397  
2023-05-25 22:02:04.812: Find a better model.
2023-05-25 22:02:11.671: [iter 57 : loss : 0.1666 = 0.0747 + 0.0882 + 0.0037, time: 6.858006]
2023-05-25 22:02:11.822: epoch 57:	0.02452074  	0.18120766  	0.09705110  
2023-05-25 22:02:11.822: Find a better model.
2023-05-25 22:02:18.654: [iter 58 : loss : 0.1646 = 0.0729 + 0.0880 + 0.0037, time: 6.829015]
2023-05-25 22:02:18.816: epoch 58:	0.02460541  	0.18177348  	0.09749097  
2023-05-25 22:02:18.816: Find a better model.
2023-05-25 22:02:25.642: [iter 59 : loss : 0.1636 = 0.0720 + 0.0878 + 0.0038, time: 6.824032]
2023-05-25 22:02:25.807: epoch 59:	0.02471832  	0.18256748  	0.09778157  
2023-05-25 22:02:25.807: Find a better model.
2023-05-25 22:02:32.636: [iter 60 : loss : 0.1621 = 0.0706 + 0.0877 + 0.0038, time: 6.828023]
2023-05-25 22:02:32.789: epoch 60:	0.02480299  	0.18318272  	0.09820500  
2023-05-25 22:02:32.790: Find a better model.
2023-05-25 22:02:39.624: [iter 61 : loss : 0.1608 = 0.0695 + 0.0875 + 0.0039, time: 6.833185]
2023-05-25 22:02:39.778: epoch 61:	0.02488767  	0.18389155  	0.09867558  
2023-05-25 22:02:39.779: Find a better model.
2023-05-25 22:02:46.641: [iter 62 : loss : 0.1591 = 0.0679 + 0.0873 + 0.0039, time: 6.861447]
2023-05-25 22:02:46.798: epoch 62:	0.02486650  	0.18365544  	0.09873232  
2023-05-25 22:02:53.617: [iter 63 : loss : 0.1580 = 0.0668 + 0.0872 + 0.0039, time: 6.816126]
2023-05-25 22:02:53.769: epoch 63:	0.02503585  	0.18452638  	0.09914229  
2023-05-25 22:02:53.769: Find a better model.
2023-05-25 22:03:00.623: [iter 64 : loss : 0.1569 = 0.0659 + 0.0870 + 0.0040, time: 6.852438]
2023-05-25 22:03:00.778: epoch 64:	0.02508524  	0.18505508  	0.09964429  
2023-05-25 22:03:00.778: Find a better model.
2023-05-25 22:03:07.625: [iter 65 : loss : 0.1559 = 0.0650 + 0.0868 + 0.0040, time: 6.846024]
2023-05-25 22:03:07.774: epoch 65:	0.02519815  	0.18587269  	0.10004805  
2023-05-25 22:03:07.774: Find a better model.
2023-05-25 22:03:14.622: [iter 66 : loss : 0.1542 = 0.0634 + 0.0867 + 0.0041, time: 6.845985]
2023-05-25 22:03:14.772: epoch 66:	0.02514876  	0.18601719  	0.10022576  
2023-05-25 22:03:14.772: Find a better model.
2023-05-25 22:03:21.649: [iter 67 : loss : 0.1526 = 0.0619 + 0.0866 + 0.0041, time: 6.876001]
2023-05-25 22:03:21.799: epoch 67:	0.02529695  	0.18734446  	0.10088319  
2023-05-25 22:03:21.799: Find a better model.
2023-05-25 22:03:28.616: [iter 68 : loss : 0.1524 = 0.0618 + 0.0864 + 0.0042, time: 6.816016]
2023-05-25 22:03:28.780: epoch 68:	0.02535340  	0.18750137  	0.10108730  
2023-05-25 22:03:28.780: Find a better model.
2023-05-25 22:03:35.605: [iter 69 : loss : 0.1504 = 0.0599 + 0.0863 + 0.0042, time: 6.822993]
2023-05-25 22:03:35.760: epoch 69:	0.02541691  	0.18815079  	0.10144237  
2023-05-25 22:03:35.760: Find a better model.
2023-05-25 22:03:42.615: [iter 70 : loss : 0.1489 = 0.0585 + 0.0862 + 0.0042, time: 6.853028]
2023-05-25 22:03:42.768: epoch 70:	0.02545924  	0.18849093  	0.10177673  
2023-05-25 22:03:42.768: Find a better model.
2023-05-25 22:03:49.604: [iter 71 : loss : 0.1474 = 0.0570 + 0.0861 + 0.0043, time: 6.834021]
2023-05-25 22:03:49.762: epoch 71:	0.02548041  	0.18853112  	0.10191826  
2023-05-25 22:03:49.762: Find a better model.
2023-05-25 22:03:56.603: [iter 72 : loss : 0.1474 = 0.0572 + 0.0859 + 0.0043, time: 6.838994]
2023-05-25 22:03:56.753: epoch 72:	0.02555098  	0.18891686  	0.10209201  
2023-05-25 22:03:56.753: Find a better model.
2023-05-25 22:04:03.610: [iter 73 : loss : 0.1460 = 0.0558 + 0.0858 + 0.0044, time: 6.855112]
2023-05-25 22:04:03.778: epoch 73:	0.02556509  	0.18922070  	0.10221530  
2023-05-25 22:04:03.778: Find a better model.
2023-05-25 22:04:10.800: [iter 74 : loss : 0.1444 = 0.0543 + 0.0857 + 0.0044, time: 7.020994]
2023-05-25 22:04:10.966: epoch 74:	0.02559332  	0.18956019  	0.10267995  
2023-05-25 22:04:10.966: Find a better model.
2023-05-25 22:04:17.783: [iter 75 : loss : 0.1440 = 0.0540 + 0.0856 + 0.0045, time: 6.814208]
2023-05-25 22:04:17.936: epoch 75:	0.02566388  	0.18962374  	0.10293914  
2023-05-25 22:04:17.936: Find a better model.
2023-05-25 22:04:24.790: [iter 76 : loss : 0.1431 = 0.0531 + 0.0854 + 0.0045, time: 6.853267]
2023-05-25 22:04:24.954: epoch 76:	0.02572034  	0.18996643  	0.10322244  
2023-05-25 22:04:24.954: Find a better model.
2023-05-25 22:04:31.775: [iter 77 : loss : 0.1421 = 0.0522 + 0.0853 + 0.0045, time: 6.819053]
2023-05-25 22:04:31.928: epoch 77:	0.02573445  	0.19027075  	0.10355686  
2023-05-25 22:04:31.928: Find a better model.
2023-05-25 22:04:38.787: [iter 78 : loss : 0.1412 = 0.0514 + 0.0852 + 0.0046, time: 6.857526]
2023-05-25 22:04:38.938: epoch 78:	0.02579090  	0.19069675  	0.10374455  
2023-05-25 22:04:38.938: Find a better model.
2023-05-25 22:04:45.803: [iter 79 : loss : 0.1401 = 0.0503 + 0.0851 + 0.0046, time: 6.862015]
2023-05-25 22:04:45.953: epoch 79:	0.02581913  	0.19073546  	0.10401697  
2023-05-25 22:04:45.953: Find a better model.
2023-05-25 22:04:52.798: [iter 80 : loss : 0.1393 = 0.0496 + 0.0850 + 0.0047, time: 6.844023]
2023-05-25 22:04:52.947: epoch 80:	0.02587558  	0.19123527  	0.10416666  
2023-05-25 22:04:52.947: Find a better model.
2023-05-25 22:04:59.970: [iter 81 : loss : 0.1390 = 0.0494 + 0.0849 + 0.0047, time: 7.021085]
2023-05-25 22:05:00.128: epoch 81:	0.02589675  	0.19136623  	0.10421991  
2023-05-25 22:05:00.128: Find a better model.
2023-05-25 22:05:07.169: [iter 82 : loss : 0.1378 = 0.0482 + 0.0848 + 0.0047, time: 7.040107]
2023-05-25 22:05:07.334: epoch 82:	0.02593909  	0.19162390  	0.10433961  
2023-05-25 22:05:07.334: Find a better model.
2023-05-25 22:05:14.394: [iter 83 : loss : 0.1368 = 0.0473 + 0.0847 + 0.0048, time: 7.059268]
2023-05-25 22:05:14.545: epoch 83:	0.02596731  	0.19199136  	0.10464545  
2023-05-25 22:05:14.546: Find a better model.
2023-05-25 22:05:21.561: [iter 84 : loss : 0.1367 = 0.0473 + 0.0846 + 0.0048, time: 7.013001]
2023-05-25 22:05:21.713: epoch 84:	0.02600260  	0.19245790  	0.10475000  
2023-05-25 22:05:21.713: Find a better model.
2023-05-25 22:05:28.744: [iter 85 : loss : 0.1357 = 0.0464 + 0.0845 + 0.0049, time: 7.029603]
2023-05-25 22:05:28.893: epoch 85:	0.02601671  	0.19256759  	0.10506047  
2023-05-25 22:05:28.893: Find a better model.
2023-05-25 22:05:35.961: [iter 86 : loss : 0.1356 = 0.0463 + 0.0844 + 0.0049, time: 7.067256]
2023-05-25 22:05:36.119: epoch 86:	0.02608022  	0.19283722  	0.10536218  
2023-05-25 22:05:36.119: Find a better model.
2023-05-25 22:05:43.157: [iter 87 : loss : 0.1329 = 0.0436 + 0.0843 + 0.0049, time: 7.037029]
2023-05-25 22:05:43.307: epoch 87:	0.02610845  	0.19304091  	0.10554018  
2023-05-25 22:05:43.307: Find a better model.
2023-05-25 22:05:50.380: [iter 88 : loss : 0.1323 = 0.0431 + 0.0842 + 0.0050, time: 7.070961]
2023-05-25 22:05:50.535: epoch 88:	0.02612961  	0.19326112  	0.10567118  
2023-05-25 22:05:50.535: Find a better model.
2023-05-25 22:05:57.579: [iter 89 : loss : 0.1320 = 0.0429 + 0.0841 + 0.0050, time: 7.041993]
2023-05-25 22:05:57.746: epoch 89:	0.02611550  	0.19314213  	0.10579273  
2023-05-25 22:06:04.932: [iter 90 : loss : 0.1326 = 0.0435 + 0.0840 + 0.0051, time: 7.185135]
2023-05-25 22:06:05.089: epoch 90:	0.02617195  	0.19325066  	0.10591801  
2023-05-25 22:06:12.156: [iter 91 : loss : 0.1313 = 0.0423 + 0.0839 + 0.0051, time: 7.065997]
2023-05-25 22:06:12.304: epoch 91:	0.02613667  	0.19315277  	0.10587490  
2023-05-25 22:06:19.378: [iter 92 : loss : 0.1304 = 0.0414 + 0.0839 + 0.0051, time: 7.071929]
2023-05-25 22:06:19.529: epoch 92:	0.02617901  	0.19334745  	0.10591150  
2023-05-25 22:06:19.529: Find a better model.
2023-05-25 22:06:26.568: [iter 93 : loss : 0.1309 = 0.0420 + 0.0838 + 0.0052, time: 7.038004]
2023-05-25 22:06:26.734: epoch 93:	0.02617901  	0.19310787  	0.10606785  
2023-05-25 22:06:33.758: [iter 94 : loss : 0.1287 = 0.0397 + 0.0837 + 0.0052, time: 7.022636]
2023-05-25 22:06:33.922: epoch 94:	0.02630603  	0.19442627  	0.10657728  
2023-05-25 22:06:33.922: Find a better model.
2023-05-25 22:06:40.955: [iter 95 : loss : 0.1280 = 0.0391 + 0.0836 + 0.0052, time: 7.031280]
2023-05-25 22:06:41.111: epoch 95:	0.02635543  	0.19455573  	0.10667443  
2023-05-25 22:06:41.111: Find a better model.
2023-05-25 22:06:48.185: [iter 96 : loss : 0.1281 = 0.0392 + 0.0836 + 0.0053, time: 7.072999]
2023-05-25 22:06:48.339: epoch 96:	0.02639071  	0.19521853  	0.10682219  
2023-05-25 22:06:48.339: Find a better model.
2023-05-25 22:06:55.337: [iter 97 : loss : 0.1264 = 0.0376 + 0.0835 + 0.0053, time: 6.996993]
2023-05-25 22:06:55.488: epoch 97:	0.02643304  	0.19522049  	0.10699588  
2023-05-25 22:06:55.488: Find a better model.
2023-05-25 22:07:02.532: [iter 98 : loss : 0.1272 = 0.0384 + 0.0834 + 0.0053, time: 7.043101]
2023-05-25 22:07:02.685: epoch 98:	0.02645421  	0.19541481  	0.10715137  
2023-05-25 22:07:02.685: Find a better model.
2023-05-25 22:07:09.736: [iter 99 : loss : 0.1261 = 0.0374 + 0.0833 + 0.0054, time: 7.049421]
2023-05-25 22:07:09.887: epoch 99:	0.02641188  	0.19525418  	0.10716271  
2023-05-25 22:07:17.113: [iter 100 : loss : 0.1257 = 0.0370 + 0.0833 + 0.0054, time: 7.224993]
2023-05-25 22:07:17.266: epoch 100:	0.02646833  	0.19538930  	0.10713739  
2023-05-25 22:07:24.338: [iter 101 : loss : 0.1252 = 0.0365 + 0.0832 + 0.0055, time: 7.071049]
2023-05-25 22:07:24.507: epoch 101:	0.02650361  	0.19555973  	0.10724526  
2023-05-25 22:07:24.507: Find a better model.
2023-05-25 22:07:31.528: [iter 102 : loss : 0.1243 = 0.0357 + 0.0831 + 0.0055, time: 7.019019]
2023-05-25 22:07:31.678: epoch 102:	0.02651066  	0.19597448  	0.10732597  
2023-05-25 22:07:31.678: Find a better model.
2023-05-25 22:07:38.711: [iter 103 : loss : 0.1240 = 0.0354 + 0.0831 + 0.0055, time: 7.031993]
2023-05-25 22:07:38.861: epoch 103:	0.02655300  	0.19642000  	0.10758585  
2023-05-25 22:07:38.861: Find a better model.
2023-05-25 22:07:45.931: [iter 104 : loss : 0.1243 = 0.0358 + 0.0830 + 0.0056, time: 7.069044]
2023-05-25 22:07:46.082: epoch 104:	0.02664473  	0.19676012  	0.10770824  
2023-05-25 22:07:46.082: Find a better model.
2023-05-25 22:07:53.132: [iter 105 : loss : 0.1236 = 0.0351 + 0.0829 + 0.0056, time: 7.048187]
2023-05-25 22:07:53.290: epoch 105:	0.02654594  	0.19608235  	0.10774774  
2023-05-25 22:08:00.334: [iter 106 : loss : 0.1232 = 0.0347 + 0.0829 + 0.0056, time: 7.041532]
2023-05-25 22:08:00.483: epoch 106:	0.02656005  	0.19604731  	0.10778759  
2023-05-25 22:08:07.508: [iter 107 : loss : 0.1223 = 0.0339 + 0.0828 + 0.0057, time: 7.023015]
2023-05-25 22:08:07.658: epoch 107:	0.02658122  	0.19616239  	0.10780796  
2023-05-25 22:08:14.709: [iter 108 : loss : 0.1220 = 0.0336 + 0.0828 + 0.0057, time: 7.049012]
2023-05-25 22:08:14.860: epoch 108:	0.02653183  	0.19612074  	0.10783588  
2023-05-25 22:08:21.913: [iter 109 : loss : 0.1209 = 0.0324 + 0.0827 + 0.0057, time: 7.051008]
2023-05-25 22:08:22.063: epoch 109:	0.02653183  	0.19609949  	0.10791396  
2023-05-25 22:08:29.119: [iter 110 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 7.053997]
2023-05-25 22:08:29.287: epoch 110:	0.02657417  	0.19627781  	0.10792731  
2023-05-25 22:08:36.308: [iter 111 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 7.019317]
2023-05-25 22:08:36.478: epoch 111:	0.02653889  	0.19604637  	0.10804310  
2023-05-25 22:08:43.506: [iter 112 : loss : 0.1201 = 0.0318 + 0.0825 + 0.0058, time: 7.027009]
2023-05-25 22:08:43.656: epoch 112:	0.02653889  	0.19581334  	0.10802368  
2023-05-25 22:08:50.697: [iter 113 : loss : 0.1200 = 0.0317 + 0.0825 + 0.0059, time: 7.039014]
2023-05-25 22:08:50.848: epoch 113:	0.02658123  	0.19629174  	0.10820109  
2023-05-25 22:08:57.898: [iter 114 : loss : 0.1192 = 0.0309 + 0.0824 + 0.0059, time: 7.048994]
2023-05-25 22:08:58.067: epoch 114:	0.02660240  	0.19656248  	0.10811436  
2023-05-25 22:09:05.086: [iter 115 : loss : 0.1187 = 0.0304 + 0.0823 + 0.0059, time: 7.018170]
2023-05-25 22:09:05.239: epoch 115:	0.02666590  	0.19675405  	0.10823935  
2023-05-25 22:09:12.290: [iter 116 : loss : 0.1179 = 0.0296 + 0.0823 + 0.0060, time: 7.050051]
2023-05-25 22:09:12.443: epoch 116:	0.02665885  	0.19689088  	0.10832449  
2023-05-25 22:09:12.444: Find a better model.
2023-05-25 22:09:19.494: [iter 117 : loss : 0.1179 = 0.0297 + 0.0822 + 0.0060, time: 7.049003]
2023-05-25 22:09:19.646: epoch 117:	0.02667295  	0.19658393  	0.10830198  
2023-05-25 22:09:26.713: [iter 118 : loss : 0.1178 = 0.0296 + 0.0822 + 0.0060, time: 7.066025]
2023-05-25 22:09:26.862: epoch 118:	0.02666590  	0.19639029  	0.10823362  
2023-05-25 22:09:34.096: [iter 119 : loss : 0.1170 = 0.0288 + 0.0821 + 0.0061, time: 7.232993]
2023-05-25 22:09:34.248: epoch 119:	0.02663767  	0.19634312  	0.10828543  
2023-05-25 22:09:41.279: [iter 120 : loss : 0.1172 = 0.0290 + 0.0821 + 0.0061, time: 7.028012]
2023-05-25 22:09:41.430: epoch 120:	0.02655300  	0.19579299  	0.10811248  
2023-05-25 22:09:48.481: [iter 121 : loss : 0.1170 = 0.0288 + 0.0820 + 0.0061, time: 7.050161]
2023-05-25 22:09:48.634: epoch 121:	0.02653183  	0.19565395  	0.10808379  
2023-05-25 22:09:55.689: [iter 122 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 7.052986]
2023-05-25 22:09:55.838: epoch 122:	0.02651772  	0.19546536  	0.10818695  
2023-05-25 22:10:02.882: [iter 123 : loss : 0.1161 = 0.0280 + 0.0819 + 0.0062, time: 7.041420]
2023-05-25 22:10:03.049: epoch 123:	0.02651066  	0.19539921  	0.10815607  
2023-05-25 22:10:10.079: [iter 124 : loss : 0.1152 = 0.0271 + 0.0819 + 0.0062, time: 7.027192]
2023-05-25 22:10:10.231: epoch 124:	0.02649656  	0.19529434  	0.10830216  
2023-05-25 22:10:17.262: [iter 125 : loss : 0.1145 = 0.0264 + 0.0818 + 0.0063, time: 7.029363]
2023-05-25 22:10:17.412: epoch 125:	0.02655301  	0.19555186  	0.10852493  
2023-05-25 22:10:24.460: [iter 126 : loss : 0.1149 = 0.0269 + 0.0818 + 0.0063, time: 7.047051]
2023-05-25 22:10:24.613: epoch 126:	0.02656007  	0.19547357  	0.10856497  
2023-05-25 22:10:31.659: [iter 127 : loss : 0.1139 = 0.0258 + 0.0818 + 0.0063, time: 7.043317]
2023-05-25 22:10:31.809: epoch 127:	0.02651067  	0.19516858  	0.10852338  
2023-05-25 22:10:38.870: [iter 128 : loss : 0.1150 = 0.0269 + 0.0817 + 0.0064, time: 7.059165]
2023-05-25 22:10:39.036: epoch 128:	0.02653184  	0.19526362  	0.10857508  
2023-05-25 22:10:46.065: [iter 129 : loss : 0.1141 = 0.0261 + 0.0817 + 0.0064, time: 7.028315]
2023-05-25 22:10:46.223: epoch 129:	0.02658124  	0.19612594  	0.10884143  
2023-05-25 22:10:53.270: [iter 130 : loss : 0.1142 = 0.0261 + 0.0816 + 0.0064, time: 7.046013]
2023-05-25 22:10:53.423: epoch 130:	0.02658124  	0.19625136  	0.10898914  
2023-05-25 22:11:00.475: [iter 131 : loss : 0.1132 = 0.0252 + 0.0816 + 0.0064, time: 7.049284]
2023-05-25 22:11:00.625: epoch 131:	0.02658829  	0.19629867  	0.10899267  
2023-05-25 22:11:07.656: [iter 132 : loss : 0.1135 = 0.0255 + 0.0815 + 0.0065, time: 7.028025]
2023-05-25 22:11:07.805: epoch 132:	0.02654595  	0.19566922  	0.10889426  
2023-05-25 22:11:14.831: [iter 133 : loss : 0.1123 = 0.0244 + 0.0815 + 0.0065, time: 7.024065]
2023-05-25 22:11:14.980: epoch 133:	0.02658123  	0.19591422  	0.10892233  
2023-05-25 22:11:22.041: [iter 134 : loss : 0.1129 = 0.0250 + 0.0814 + 0.0065, time: 7.060007]
2023-05-25 22:11:22.199: epoch 134:	0.02663768  	0.19633982  	0.10910899  
2023-05-25 22:11:29.252: [iter 135 : loss : 0.1127 = 0.0247 + 0.0814 + 0.0066, time: 7.050041]
2023-05-25 22:11:29.402: epoch 135:	0.02660945  	0.19602990  	0.10906693  
2023-05-25 22:11:36.443: [iter 136 : loss : 0.1124 = 0.0244 + 0.0814 + 0.0066, time: 7.039262]
2023-05-25 22:11:36.613: epoch 136:	0.02661651  	0.19618213  	0.10903253  
2023-05-25 22:11:43.632: [iter 137 : loss : 0.1120 = 0.0240 + 0.0813 + 0.0066, time: 7.017013]
2023-05-25 22:11:43.799: epoch 137:	0.02667297  	0.19661731  	0.10919772  
2023-05-25 22:11:50.813: [iter 138 : loss : 0.1116 = 0.0237 + 0.0813 + 0.0066, time: 7.013009]
2023-05-25 22:11:50.965: epoch 138:	0.02671531  	0.19691138  	0.10944375  
2023-05-25 22:11:50.966: Find a better model.
2023-05-25 22:11:58.042: [iter 139 : loss : 0.1114 = 0.0235 + 0.0812 + 0.0067, time: 7.074018]
2023-05-25 22:11:58.202: epoch 139:	0.02661652  	0.19604452  	0.10926432  
2023-05-25 22:12:05.211: [iter 140 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0067, time: 7.008035]
2023-05-25 22:12:05.362: epoch 140:	0.02675059  	0.19712444  	0.10964565  
2023-05-25 22:12:05.362: Find a better model.
2023-05-25 22:12:12.244: [iter 141 : loss : 0.1115 = 0.0236 + 0.0812 + 0.0067, time: 6.879580]
2023-05-25 22:12:12.402: epoch 141:	0.02668002  	0.19621173  	0.10930231  
2023-05-25 22:12:19.425: [iter 142 : loss : 0.1106 = 0.0227 + 0.0811 + 0.0068, time: 7.022017]
2023-05-25 22:12:19.576: epoch 142:	0.02660946  	0.19580154  	0.10918300  
2023-05-25 22:12:26.447: [iter 143 : loss : 0.1106 = 0.0228 + 0.0811 + 0.0068, time: 6.869005]
2023-05-25 22:12:26.597: epoch 143:	0.02671530  	0.19678034  	0.10960750  
2023-05-25 22:12:33.467: [iter 144 : loss : 0.1100 = 0.0221 + 0.0811 + 0.0068, time: 6.868399]
2023-05-25 22:12:33.620: epoch 144:	0.02671530  	0.19684710  	0.10944261  
2023-05-25 22:12:40.648: [iter 145 : loss : 0.1098 = 0.0220 + 0.0810 + 0.0068, time: 7.026023]
2023-05-25 22:12:40.799: epoch 145:	0.02669413  	0.19646761  	0.10948565  
2023-05-25 22:12:47.624: [iter 146 : loss : 0.1103 = 0.0224 + 0.0810 + 0.0069, time: 6.823025]
2023-05-25 22:12:47.776: epoch 146:	0.02663063  	0.19623560  	0.10938036  
2023-05-25 22:12:54.623: [iter 147 : loss : 0.1101 = 0.0223 + 0.0810 + 0.0069, time: 6.845029]
2023-05-25 22:12:54.772: epoch 147:	0.02661651  	0.19609448  	0.10931027  
2023-05-25 22:13:01.654: [iter 148 : loss : 0.1089 = 0.0210 + 0.0809 + 0.0069, time: 6.880004]
2023-05-25 22:13:01.804: epoch 148:	0.02665179  	0.19634344  	0.10944731  
2023-05-25 22:13:08.614: [iter 149 : loss : 0.1093 = 0.0215 + 0.0809 + 0.0069, time: 6.807993]
2023-05-25 22:13:08.765: epoch 149:	0.02666590  	0.19607584  	0.10946212  
2023-05-25 22:13:15.623: [iter 150 : loss : 0.1087 = 0.0209 + 0.0809 + 0.0070, time: 6.857011]
2023-05-25 22:13:15.777: epoch 150:	0.02663768  	0.19604048  	0.10953185  
2023-05-25 22:13:22.615: [iter 151 : loss : 0.1089 = 0.0211 + 0.0808 + 0.0070, time: 6.836034]
2023-05-25 22:13:22.765: epoch 151:	0.02661650  	0.19577673  	0.10950321  
2023-05-25 22:13:29.795: [iter 152 : loss : 0.1082 = 0.0204 + 0.0808 + 0.0070, time: 7.029003]
2023-05-25 22:13:29.947: epoch 152:	0.02658827  	0.19564082  	0.10960270  
2023-05-25 22:13:36.973: [iter 153 : loss : 0.1074 = 0.0196 + 0.0808 + 0.0071, time: 7.024043]
2023-05-25 22:13:37.129: epoch 153:	0.02656711  	0.19543380  	0.10944983  
2023-05-25 22:13:44.015: [iter 154 : loss : 0.1077 = 0.0199 + 0.0807 + 0.0071, time: 6.885114]
2023-05-25 22:13:44.174: epoch 154:	0.02657417  	0.19541143  	0.10936848  
2023-05-25 22:13:51.194: [iter 155 : loss : 0.1086 = 0.0208 + 0.0807 + 0.0071, time: 7.018051]
2023-05-25 22:13:51.345: epoch 155:	0.02651065  	0.19524866  	0.10936096  
2023-05-25 22:13:58.216: [iter 156 : loss : 0.1078 = 0.0200 + 0.0807 + 0.0071, time: 6.870119]
2023-05-25 22:13:58.366: epoch 156:	0.02646831  	0.19474444  	0.10918250  
2023-05-25 22:14:05.402: [iter 157 : loss : 0.1077 = 0.0198 + 0.0807 + 0.0072, time: 7.035029]
2023-05-25 22:14:05.554: epoch 157:	0.02651065  	0.19513930  	0.10925920  
2023-05-25 22:14:12.605: [iter 158 : loss : 0.1070 = 0.0192 + 0.0806 + 0.0072, time: 7.049258]
2023-05-25 22:14:12.775: epoch 158:	0.02651771  	0.19516933  	0.10913115  
2023-05-25 22:14:19.789: [iter 159 : loss : 0.1073 = 0.0195 + 0.0806 + 0.0072, time: 7.011125]
2023-05-25 22:14:19.946: epoch 159:	0.02653182  	0.19526815  	0.10932573  
2023-05-25 22:14:26.984: [iter 160 : loss : 0.1069 = 0.0191 + 0.0806 + 0.0072, time: 7.036003]
2023-05-25 22:14:27.138: epoch 160:	0.02656005  	0.19543026  	0.10947976  
2023-05-25 22:14:34.004: [iter 161 : loss : 0.1065 = 0.0187 + 0.0805 + 0.0073, time: 6.865015]
2023-05-25 22:14:34.154: epoch 161:	0.02656005  	0.19537659  	0.10928217  
2023-05-25 22:14:41.149: [iter 162 : loss : 0.1058 = 0.0180 + 0.0805 + 0.0073, time: 6.993413]
2023-05-25 22:14:41.302: epoch 162:	0.02657416  	0.19532873  	0.10928676  
2023-05-25 22:14:48.200: [iter 163 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 6.896347]
2023-05-25 22:14:48.352: epoch 163:	0.02654594  	0.19534360  	0.10928567  
2023-05-25 22:14:55.369: [iter 164 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 7.016013]
2023-05-25 22:14:55.522: epoch 164:	0.02651066  	0.19498415  	0.10924836  
2023-05-25 22:15:02.372: [iter 165 : loss : 0.1060 = 0.0182 + 0.0804 + 0.0074, time: 6.849006]
2023-05-25 22:15:02.524: epoch 165:	0.02660239  	0.19551156  	0.10934774  
2023-05-25 22:15:02.524: Early stopping is trigger at epoch: 165
2023-05-25 22:15:02.524: best_result@epoch 140:

2023-05-25 22:15:02.524: 		0.0268      	0.1971      	0.1096      
2023-05-26 09:14:59.390: my pid: 7796
2023-05-26 09:14:59.390: model: model.general_recommender.SGL
2023-05-26 09:14:59.390: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 09:14:59.390: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 09:15:03.114: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 09:15:11.012: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.897092]
2023-05-26 09:15:11.165: epoch 1:	0.00216625  	0.01497536  	0.00764244  
2023-05-26 09:15:11.165: Find a better model.
2023-05-26 09:15:19.045: [iter 2 : loss : 0.7706 = 0.6929 + 0.0777 + 0.0000, time: 7.879048]
2023-05-26 09:15:19.254: epoch 2:	0.00394438  	0.02714157  	0.01355890  
2023-05-26 09:15:19.254: Find a better model.
2023-05-26 09:15:26.805: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.548086]
2023-05-26 09:15:26.983: epoch 3:	0.00671742  	0.04654722  	0.02366749  
2023-05-26 09:15:26.983: Find a better model.
2023-05-26 09:15:34.623: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.639074]
2023-05-26 09:15:34.785: epoch 4:	0.00967396  	0.06787906  	0.03394979  
2023-05-26 09:15:34.785: Find a better model.
2023-05-26 09:15:42.214: [iter 5 : loss : 0.7685 = 0.6906 + 0.0778 + 0.0000, time: 7.428059]
2023-05-26 09:15:42.368: epoch 5:	0.01265885  	0.08938721  	0.04379842  
2023-05-26 09:15:42.368: Find a better model.
2023-05-26 09:15:49.771: [iter 6 : loss : 0.7655 = 0.6874 + 0.0781 + 0.0000, time: 7.401027]
2023-05-26 09:15:49.928: epoch 6:	0.01543907  	0.11075804  	0.05446367  
2023-05-26 09:15:49.928: Find a better model.
2023-05-26 09:15:57.190: [iter 7 : loss : 0.7576 = 0.6787 + 0.0789 + 0.0000, time: 7.261007]
2023-05-26 09:15:57.346: epoch 7:	0.01788764  	0.12975959  	0.06405847  
2023-05-26 09:15:57.347: Find a better model.
2023-05-26 09:16:04.564: [iter 8 : loss : 0.7388 = 0.6578 + 0.0809 + 0.0001, time: 7.215002]
2023-05-26 09:16:04.714: epoch 8:	0.01873441  	0.13699752  	0.06902540  
2023-05-26 09:16:04.714: Find a better model.
2023-05-26 09:16:11.784: [iter 9 : loss : 0.6989 = 0.6139 + 0.0848 + 0.0002, time: 7.069019]
2023-05-26 09:16:11.934: epoch 9:	0.01879792  	0.13885236  	0.06976726  
2023-05-26 09:16:11.934: Find a better model.
2023-05-26 09:16:18.965: [iter 10 : loss : 0.6345 = 0.5442 + 0.0900 + 0.0003, time: 7.028993]
2023-05-26 09:16:19.116: epoch 10:	0.01888260  	0.13985242  	0.06963884  
2023-05-26 09:16:19.116: Find a better model.
2023-05-26 09:16:26.001: [iter 11 : loss : 0.5590 = 0.4638 + 0.0948 + 0.0004, time: 6.883126]
2023-05-26 09:16:26.150: epoch 11:	0.01871325  	0.13860905  	0.06942577  
2023-05-26 09:16:32.968: [iter 12 : loss : 0.4925 = 0.3940 + 0.0979 + 0.0006, time: 6.817435]
2023-05-26 09:16:33.131: epoch 12:	0.01852272  	0.13726650  	0.06928337  
2023-05-26 09:16:39.973: [iter 13 : loss : 0.4439 = 0.3436 + 0.0996 + 0.0007, time: 6.839997]
2023-05-26 09:16:40.125: epoch 13:	0.01857212  	0.13756423  	0.06985772  
2023-05-26 09:16:46.969: [iter 14 : loss : 0.4072 = 0.3058 + 0.1005 + 0.0009, time: 6.842401]
2023-05-26 09:16:47.121: epoch 14:	0.01878382  	0.13956578  	0.07076950  
2023-05-26 09:16:53.971: [iter 15 : loss : 0.3812 = 0.2795 + 0.1008 + 0.0010, time: 6.848994]
2023-05-26 09:16:54.124: epoch 15:	0.01891789  	0.14010404  	0.07146242  
2023-05-26 09:16:54.124: Find a better model.
2023-05-26 09:17:00.971: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 6.846132]
2023-05-26 09:17:01.122: epoch 16:	0.01919310  	0.14209834  	0.07224111  
2023-05-26 09:17:01.123: Find a better model.
2023-05-26 09:17:07.992: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 6.867289]
2023-05-26 09:17:08.147: epoch 17:	0.01939774  	0.14316788  	0.07318529  
2023-05-26 09:17:08.147: Find a better model.
2023-05-26 09:17:14.954: [iter 18 : loss : 0.3286 = 0.2268 + 0.1004 + 0.0013, time: 6.805038]
2023-05-26 09:17:15.105: epoch 18:	0.01965882  	0.14523189  	0.07400754  
2023-05-26 09:17:15.105: Find a better model.
2023-05-26 09:17:21.950: [iter 19 : loss : 0.3146 = 0.2131 + 0.1000 + 0.0014, time: 6.844013]
2023-05-26 09:17:22.104: epoch 19:	0.01989875  	0.14659438  	0.07485601  
2023-05-26 09:17:22.104: Find a better model.
2023-05-26 09:17:28.947: [iter 20 : loss : 0.3051 = 0.2039 + 0.0996 + 0.0015, time: 6.842044]
2023-05-26 09:17:29.098: epoch 20:	0.02015279  	0.14849868  	0.07577936  
2023-05-26 09:17:29.098: Find a better model.
2023-05-26 09:17:35.944: [iter 21 : loss : 0.2954 = 0.1946 + 0.0993 + 0.0016, time: 6.845027]
2023-05-26 09:17:36.096: epoch 21:	0.02032920  	0.14976291  	0.07656690  
2023-05-26 09:17:36.097: Find a better model.
2023-05-26 09:17:42.948: [iter 22 : loss : 0.2873 = 0.1868 + 0.0989 + 0.0017, time: 6.850013]
2023-05-26 09:17:43.102: epoch 22:	0.02051266  	0.15155566  	0.07746946  
2023-05-26 09:17:43.102: Find a better model.
2023-05-26 09:17:49.983: [iter 23 : loss : 0.2793 = 0.1790 + 0.0985 + 0.0018, time: 6.879462]
2023-05-26 09:17:50.154: epoch 23:	0.02067497  	0.15280922  	0.07839331  
2023-05-26 09:17:50.154: Find a better model.
2023-05-26 09:17:56.954: [iter 24 : loss : 0.2728 = 0.1729 + 0.0980 + 0.0018, time: 6.799025]
2023-05-26 09:17:57.113: epoch 24:	0.02087960  	0.15387651  	0.07897241  
2023-05-26 09:17:57.113: Find a better model.
2023-05-26 09:18:03.939: [iter 25 : loss : 0.2661 = 0.1665 + 0.0976 + 0.0019, time: 6.825004]
2023-05-26 09:18:04.089: epoch 25:	0.02102073  	0.15470774  	0.07946541  
2023-05-26 09:18:04.089: Find a better model.
2023-05-26 09:18:11.123: [iter 26 : loss : 0.2624 = 0.1633 + 0.0972 + 0.0020, time: 7.032421]
2023-05-26 09:18:11.272: epoch 26:	0.02112659  	0.15535788  	0.07995071  
2023-05-26 09:18:11.273: Find a better model.
2023-05-26 09:18:18.344: [iter 27 : loss : 0.2548 = 0.1559 + 0.0968 + 0.0021, time: 7.070041]
2023-05-26 09:18:18.502: epoch 27:	0.02129594  	0.15674502  	0.08069664  
2023-05-26 09:18:18.502: Find a better model.
2023-05-26 09:18:25.531: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 7.028010]
2023-05-26 09:18:25.683: epoch 28:	0.02143002  	0.15756500  	0.08144733  
2023-05-26 09:18:25.683: Find a better model.
2023-05-26 09:18:32.751: [iter 29 : loss : 0.2456 = 0.1474 + 0.0960 + 0.0022, time: 7.066004]
2023-05-26 09:18:32.904: epoch 29:	0.02162054  	0.15895677  	0.08225098  
2023-05-26 09:18:32.904: Find a better model.
2023-05-26 09:18:39.918: [iter 30 : loss : 0.2390 = 0.1411 + 0.0956 + 0.0022, time: 7.013015]
2023-05-26 09:18:40.070: epoch 30:	0.02184634  	0.16083184  	0.08313150  
2023-05-26 09:18:40.070: Find a better model.
2023-05-26 09:18:47.128: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 7.057025]
2023-05-26 09:18:47.280: epoch 31:	0.02198747  	0.16185437  	0.08384563  
2023-05-26 09:18:47.280: Find a better model.
2023-05-26 09:18:54.306: [iter 32 : loss : 0.2300 = 0.1327 + 0.0949 + 0.0024, time: 7.024007]
2023-05-26 09:18:54.459: epoch 32:	0.02214271  	0.16267397  	0.08440990  
2023-05-26 09:18:54.460: Find a better model.
2023-05-26 09:19:01.539: [iter 33 : loss : 0.2272 = 0.1302 + 0.0945 + 0.0024, time: 7.076411]
2023-05-26 09:19:01.699: epoch 33:	0.02221327  	0.16328903  	0.08470640  
2023-05-26 09:19:01.699: Find a better model.
2023-05-26 09:19:08.717: [iter 34 : loss : 0.2234 = 0.1268 + 0.0942 + 0.0025, time: 7.015994]
2023-05-26 09:19:08.887: epoch 34:	0.02237557  	0.16443875  	0.08538613  
2023-05-26 09:19:08.887: Find a better model.
2023-05-26 09:19:15.926: [iter 35 : loss : 0.2200 = 0.1236 + 0.0939 + 0.0025, time: 7.038249]
2023-05-26 09:19:16.079: epoch 35:	0.02248847  	0.16539912  	0.08601477  
2023-05-26 09:19:16.079: Find a better model.
2023-05-26 09:19:23.092: [iter 36 : loss : 0.2166 = 0.1204 + 0.0936 + 0.0026, time: 7.011222]
2023-05-26 09:19:23.243: epoch 36:	0.02270723  	0.16716278  	0.08693756  
2023-05-26 09:19:23.243: Find a better model.
2023-05-26 09:19:30.122: [iter 37 : loss : 0.2126 = 0.1167 + 0.0932 + 0.0027, time: 6.878026]
2023-05-26 09:19:30.281: epoch 37:	0.02288364  	0.16815960  	0.08760352  
2023-05-26 09:19:30.281: Find a better model.
2023-05-26 09:19:37.312: [iter 38 : loss : 0.2111 = 0.1154 + 0.0930 + 0.0027, time: 7.030030]
2023-05-26 09:19:37.466: epoch 38:	0.02296126  	0.16911186  	0.08815136  
2023-05-26 09:19:37.466: Find a better model.
2023-05-26 09:19:44.503: [iter 39 : loss : 0.2067 = 0.1112 + 0.0927 + 0.0028, time: 7.036426]
2023-05-26 09:19:44.655: epoch 39:	0.02294715  	0.16911449  	0.08876958  
2023-05-26 09:19:44.655: Find a better model.
2023-05-26 09:19:51.693: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 7.036481]
2023-05-26 09:19:51.842: epoch 40:	0.02297538  	0.16947632  	0.08907121  
2023-05-26 09:19:51.842: Find a better model.
2023-05-26 09:19:58.736: [iter 41 : loss : 0.2019 = 0.1070 + 0.0921 + 0.0029, time: 6.891994]
2023-05-26 09:19:58.902: epoch 41:	0.02314474  	0.17047954  	0.08967278  
2023-05-26 09:19:58.903: Find a better model.
2023-05-26 09:20:05.875: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.971308]
2023-05-26 09:20:06.025: epoch 42:	0.02327175  	0.17125009  	0.09019362  
2023-05-26 09:20:06.026: Find a better model.
2023-05-26 09:20:13.064: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 7.036993]
2023-05-26 09:20:13.216: epoch 43:	0.02338466  	0.17248400  	0.09090815  
2023-05-26 09:20:13.216: Find a better model.
2023-05-26 09:20:20.089: [iter 44 : loss : 0.1924 = 0.0981 + 0.0912 + 0.0030, time: 6.871007]
2023-05-26 09:20:20.238: epoch 44:	0.02351873  	0.17322424  	0.09142201  
2023-05-26 09:20:20.238: Find a better model.
2023-05-26 09:20:27.094: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.855020]
2023-05-26 09:20:27.243: epoch 45:	0.02365986  	0.17424634  	0.09224367  
2023-05-26 09:20:27.243: Find a better model.
2023-05-26 09:20:34.273: [iter 46 : loss : 0.1880 = 0.0941 + 0.0908 + 0.0031, time: 7.028000]
2023-05-26 09:20:34.428: epoch 46:	0.02369515  	0.17449503  	0.09244721  
2023-05-26 09:20:34.428: Find a better model.
2023-05-26 09:20:41.324: [iter 47 : loss : 0.1871 = 0.0933 + 0.0905 + 0.0032, time: 6.895117]
2023-05-26 09:20:41.481: epoch 47:	0.02386451  	0.17573193  	0.09284776  
2023-05-26 09:20:41.481: Find a better model.
2023-05-26 09:20:48.299: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.816104]
2023-05-26 09:20:48.464: epoch 48:	0.02392095  	0.17622703  	0.09325764  
2023-05-26 09:20:48.464: Find a better model.
2023-05-26 09:20:55.466: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 7.000007]
2023-05-26 09:20:55.618: epoch 49:	0.02406914  	0.17730820  	0.09392841  
2023-05-26 09:20:55.618: Find a better model.
2023-05-26 09:21:02.658: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 7.038001]
2023-05-26 09:21:02.812: epoch 50:	0.02406208  	0.17759329  	0.09424033  
2023-05-26 09:21:02.812: Find a better model.
2023-05-26 09:21:09.873: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 7.060044]
2023-05-26 09:21:10.026: epoch 51:	0.02416793  	0.17844321  	0.09467940  
2023-05-26 09:21:10.026: Find a better model.
2023-05-26 09:21:16.874: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 6.846274]
2023-05-26 09:21:17.022: epoch 52:	0.02422437  	0.17842750  	0.09497578  
2023-05-26 09:21:23.896: [iter 53 : loss : 0.1742 = 0.0815 + 0.0893 + 0.0035, time: 6.871003]
2023-05-26 09:21:24.061: epoch 53:	0.02433728  	0.17941333  	0.09565471  
2023-05-26 09:21:24.062: Find a better model.
2023-05-26 09:21:31.047: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 6.984079]
2023-05-26 09:21:31.198: epoch 54:	0.02434433  	0.17965502  	0.09601045  
2023-05-26 09:21:31.198: Find a better model.
2023-05-26 09:21:38.064: [iter 55 : loss : 0.1703 = 0.0779 + 0.0889 + 0.0036, time: 6.864176]
2023-05-26 09:21:38.217: epoch 55:	0.02432316  	0.17928515  	0.09599151  
2023-05-26 09:21:45.068: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.850081]
2023-05-26 09:21:45.219: epoch 56:	0.02438667  	0.17958453  	0.09643993  
2023-05-26 09:21:52.286: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 7.065127]
2023-05-26 09:21:52.454: epoch 57:	0.02448546  	0.18022777  	0.09681772  
2023-05-26 09:21:52.454: Find a better model.
2023-05-26 09:21:59.484: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 7.028032]
2023-05-26 09:21:59.652: epoch 58:	0.02447134  	0.17994051  	0.09698641  
2023-05-26 09:22:06.677: [iter 59 : loss : 0.1640 = 0.0721 + 0.0882 + 0.0038, time: 7.023031]
2023-05-26 09:22:06.825: epoch 59:	0.02459130  	0.18102334  	0.09751311  
2023-05-26 09:22:06.825: Find a better model.
2023-05-26 09:22:13.876: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 7.050089]
2023-05-26 09:22:14.044: epoch 60:	0.02473243  	0.18233371  	0.09813038  
2023-05-26 09:22:14.044: Find a better model.
2023-05-26 09:22:21.064: [iter 61 : loss : 0.1612 = 0.0694 + 0.0879 + 0.0038, time: 7.019400]
2023-05-26 09:22:21.222: epoch 61:	0.02476772  	0.18282568  	0.09840386  
2023-05-26 09:22:21.222: Find a better model.
2023-05-26 09:22:28.227: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 7.003057]
2023-05-26 09:22:28.377: epoch 62:	0.02479594  	0.18302089  	0.09864884  
2023-05-26 09:22:28.378: Find a better model.
2023-05-26 09:22:35.433: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 7.051000]
2023-05-26 09:22:35.584: epoch 63:	0.02488062  	0.18378438  	0.09916424  
2023-05-26 09:22:35.584: Find a better model.
2023-05-26 09:22:42.446: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 6.861038]
2023-05-26 09:22:42.597: epoch 64:	0.02494413  	0.18437508  	0.09951241  
2023-05-26 09:22:42.597: Find a better model.
2023-05-26 09:22:49.657: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 7.059006]
2023-05-26 09:22:49.826: epoch 65:	0.02497941  	0.18466699  	0.09980574  
2023-05-26 09:22:49.827: Find a better model.
2023-05-26 09:22:56.827: [iter 66 : loss : 0.1546 = 0.0634 + 0.0871 + 0.0041, time: 6.998010]
2023-05-26 09:22:56.979: epoch 66:	0.02506409  	0.18534249  	0.10031982  
2023-05-26 09:22:56.980: Find a better model.
2023-05-26 09:23:04.035: [iter 67 : loss : 0.1530 = 0.0620 + 0.0869 + 0.0041, time: 7.054061]
2023-05-26 09:23:04.185: epoch 67:	0.02502175  	0.18512684  	0.10033373  
2023-05-26 09:23:11.220: [iter 68 : loss : 0.1528 = 0.0618 + 0.0868 + 0.0042, time: 7.034003]
2023-05-26 09:23:11.370: epoch 68:	0.02517699  	0.18632852  	0.10074176  
2023-05-26 09:23:11.370: Find a better model.
2023-05-26 09:23:18.230: [iter 69 : loss : 0.1509 = 0.0601 + 0.0867 + 0.0042, time: 6.859003]
2023-05-26 09:23:18.383: epoch 69:	0.02514876  	0.18617438  	0.10094364  
2023-05-26 09:23:25.409: [iter 70 : loss : 0.1495 = 0.0587 + 0.0866 + 0.0042, time: 7.023029]
2023-05-26 09:23:25.561: epoch 70:	0.02522638  	0.18657640  	0.10142211  
2023-05-26 09:23:25.561: Find a better model.
2023-05-26 09:23:32.458: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.896055]
2023-05-26 09:23:32.608: epoch 71:	0.02530401  	0.18723078  	0.10194766  
2023-05-26 09:23:32.608: Find a better model.
2023-05-26 09:23:39.632: [iter 72 : loss : 0.1477 = 0.0571 + 0.0863 + 0.0043, time: 7.022993]
2023-05-26 09:23:39.783: epoch 72:	0.02538163  	0.18807197  	0.10218677  
2023-05-26 09:23:39.783: Find a better model.
2023-05-26 09:23:46.813: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 7.028003]
2023-05-26 09:23:46.966: epoch 73:	0.02545925  	0.18872808  	0.10249167  
2023-05-26 09:23:46.966: Find a better model.
2023-05-26 09:23:54.013: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 7.045007]
2023-05-26 09:23:54.164: epoch 74:	0.02547336  	0.18867107  	0.10270183  
2023-05-26 09:24:01.206: [iter 75 : loss : 0.1444 = 0.0540 + 0.0860 + 0.0044, time: 7.041047]
2023-05-26 09:24:01.356: epoch 75:	0.02556510  	0.18946289  	0.10315620  
2023-05-26 09:24:01.356: Find a better model.
2023-05-26 09:24:08.409: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 7.052041]
2023-05-26 09:24:08.573: epoch 76:	0.02557921  	0.18948366  	0.10323747  
2023-05-26 09:24:08.574: Find a better model.
2023-05-26 09:24:15.640: [iter 77 : loss : 0.1426 = 0.0523 + 0.0857 + 0.0045, time: 7.064013]
2023-05-26 09:24:15.790: epoch 77:	0.02567094  	0.19007935  	0.10351834  
2023-05-26 09:24:15.790: Find a better model.
2023-05-26 09:24:22.790: [iter 78 : loss : 0.1416 = 0.0515 + 0.0856 + 0.0046, time: 6.999008]
2023-05-26 09:24:22.942: epoch 78:	0.02574150  	0.19066168  	0.10372009  
2023-05-26 09:24:22.942: Find a better model.
2023-05-26 09:24:29.992: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 7.049007]
2023-05-26 09:24:30.143: epoch 79:	0.02572739  	0.19031818  	0.10357767  
2023-05-26 09:24:37.185: [iter 80 : loss : 0.1398 = 0.0498 + 0.0854 + 0.0047, time: 7.040062]
2023-05-26 09:24:37.353: epoch 80:	0.02576267  	0.19068532  	0.10380763  
2023-05-26 09:24:37.353: Find a better model.
2023-05-26 09:24:44.421: [iter 81 : loss : 0.1393 = 0.0494 + 0.0853 + 0.0047, time: 7.067034]
2023-05-26 09:24:44.591: epoch 81:	0.02582618  	0.19137841  	0.10398567  
2023-05-26 09:24:44.591: Find a better model.
2023-05-26 09:24:51.793: [iter 82 : loss : 0.1381 = 0.0482 + 0.0852 + 0.0047, time: 7.201044]
2023-05-26 09:24:51.945: epoch 82:	0.02591085  	0.19203739  	0.10445392  
2023-05-26 09:24:51.945: Find a better model.
2023-05-26 09:24:59.203: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 7.256188]
2023-05-26 09:24:59.354: epoch 83:	0.02590379  	0.19201303  	0.10463109  
2023-05-26 09:25:06.621: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 7.265396]
2023-05-26 09:25:06.774: epoch 84:	0.02598847  	0.19262144  	0.10496287  
2023-05-26 09:25:06.774: Find a better model.
2023-05-26 09:25:13.978: [iter 85 : loss : 0.1362 = 0.0465 + 0.0849 + 0.0048, time: 7.202207]
2023-05-26 09:25:14.130: epoch 85:	0.02589674  	0.19191842  	0.10492502  
2023-05-26 09:25:21.363: [iter 86 : loss : 0.1359 = 0.0463 + 0.0847 + 0.0049, time: 7.232136]
2023-05-26 09:25:21.517: epoch 86:	0.02598142  	0.19279382  	0.10523263  
2023-05-26 09:25:21.517: Find a better model.
2023-05-26 09:25:28.586: [iter 87 : loss : 0.1333 = 0.0437 + 0.0847 + 0.0049, time: 7.067036]
2023-05-26 09:25:28.735: epoch 87:	0.02600259  	0.19286226  	0.10554045  
2023-05-26 09:25:28.735: Find a better model.
2023-05-26 09:25:35.789: [iter 88 : loss : 0.1326 = 0.0431 + 0.0846 + 0.0050, time: 7.053031]
2023-05-26 09:25:35.940: epoch 88:	0.02608021  	0.19334084  	0.10573853  
2023-05-26 09:25:35.941: Find a better model.
2023-05-26 09:25:43.000: [iter 89 : loss : 0.1325 = 0.0430 + 0.0845 + 0.0050, time: 7.058022]
2023-05-26 09:25:43.152: epoch 89:	0.02603787  	0.19325595  	0.10566834  
2023-05-26 09:25:50.189: [iter 90 : loss : 0.1330 = 0.0435 + 0.0844 + 0.0050, time: 7.035195]
2023-05-26 09:25:50.355: epoch 90:	0.02607316  	0.19354725  	0.10574456  
2023-05-26 09:25:50.355: Find a better model.
2023-05-26 09:25:57.394: [iter 91 : loss : 0.1316 = 0.0422 + 0.0843 + 0.0051, time: 7.038034]
2023-05-26 09:25:57.562: epoch 91:	0.02612960  	0.19385689  	0.10596286  
2023-05-26 09:25:57.562: Find a better model.
2023-05-26 09:26:04.763: [iter 92 : loss : 0.1306 = 0.0413 + 0.0842 + 0.0051, time: 7.200158]
2023-05-26 09:26:04.931: epoch 92:	0.02617195  	0.19427696  	0.10613449  
2023-05-26 09:26:04.932: Find a better model.
2023-05-26 09:26:11.982: [iter 93 : loss : 0.1313 = 0.0420 + 0.0842 + 0.0052, time: 7.048977]
2023-05-26 09:26:12.132: epoch 93:	0.02623546  	0.19497511  	0.10627158  
2023-05-26 09:26:12.132: Find a better model.
2023-05-26 09:26:19.149: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 7.016038]
2023-05-26 09:26:19.301: epoch 94:	0.02619312  	0.19497247  	0.10626858  
2023-05-26 09:26:26.399: [iter 95 : loss : 0.1284 = 0.0391 + 0.0840 + 0.0052, time: 7.095553]
2023-05-26 09:26:26.568: epoch 95:	0.02616489  	0.19485630  	0.10618858  
2023-05-26 09:26:33.553: [iter 96 : loss : 0.1285 = 0.0393 + 0.0839 + 0.0053, time: 6.984006]
2023-05-26 09:26:33.703: epoch 96:	0.02620017  	0.19472459  	0.10646574  
2023-05-26 09:26:40.744: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 7.040025]
2023-05-26 09:26:40.896: epoch 97:	0.02622134  	0.19511022  	0.10657919  
2023-05-26 09:26:40.896: Find a better model.
2023-05-26 09:26:47.965: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 7.068034]
2023-05-26 09:26:48.116: epoch 98:	0.02633425  	0.19596523  	0.10705563  
2023-05-26 09:26:48.116: Find a better model.
2023-05-26 09:26:55.161: [iter 99 : loss : 0.1265 = 0.0374 + 0.0837 + 0.0054, time: 7.044031]
2023-05-26 09:26:55.314: epoch 99:	0.02634836  	0.19627228  	0.10693242  
2023-05-26 09:26:55.314: Find a better model.
2023-05-26 09:27:02.530: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 7.214197]
2023-05-26 09:27:02.680: epoch 100:	0.02636247  	0.19631392  	0.10692953  
2023-05-26 09:27:02.680: Find a better model.
2023-05-26 09:27:09.756: [iter 101 : loss : 0.1255 = 0.0365 + 0.0836 + 0.0054, time: 7.073996]
2023-05-26 09:27:09.911: epoch 101:	0.02632719  	0.19566759  	0.10681476  
2023-05-26 09:27:16.939: [iter 102 : loss : 0.1246 = 0.0356 + 0.0835 + 0.0055, time: 7.027063]
2023-05-26 09:27:17.092: epoch 102:	0.02643304  	0.19618462  	0.10712220  
2023-05-26 09:27:24.122: [iter 103 : loss : 0.1244 = 0.0355 + 0.0834 + 0.0055, time: 7.028016]
2023-05-26 09:27:24.274: epoch 103:	0.02648949  	0.19622694  	0.10718184  
2023-05-26 09:27:31.333: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 7.057000]
2023-05-26 09:27:31.486: epoch 104:	0.02639070  	0.19518626  	0.10691708  
2023-05-26 09:27:38.544: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 7.056017]
2023-05-26 09:27:38.711: epoch 105:	0.02643304  	0.19567963  	0.10718454  
2023-05-26 09:27:45.724: [iter 106 : loss : 0.1236 = 0.0347 + 0.0832 + 0.0056, time: 7.012003]
2023-05-26 09:27:45.878: epoch 106:	0.02656711  	0.19647859  	0.10757437  
2023-05-26 09:27:45.878: Find a better model.
2023-05-26 09:27:52.782: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0057, time: 6.903004]
2023-05-26 09:27:52.950: epoch 107:	0.02657416  	0.19644777  	0.10748140  
2023-05-26 09:27:59.945: [iter 108 : loss : 0.1224 = 0.0336 + 0.0832 + 0.0057, time: 6.993957]
2023-05-26 09:28:00.101: epoch 108:	0.02657416  	0.19652188  	0.10757142  
2023-05-26 09:28:00.101: Find a better model.
2023-05-26 09:28:07.139: [iter 109 : loss : 0.1212 = 0.0325 + 0.0831 + 0.0057, time: 7.036882]
2023-05-26 09:28:07.292: epoch 109:	0.02656005  	0.19613257  	0.10754200  
2023-05-26 09:28:14.517: [iter 110 : loss : 0.1206 = 0.0318 + 0.0830 + 0.0058, time: 7.224008]
2023-05-26 09:28:14.669: epoch 110:	0.02651771  	0.19610256  	0.10759687  
2023-05-26 09:28:21.738: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 7.066244]
2023-05-26 09:28:21.890: epoch 111:	0.02653182  	0.19632624  	0.10767207  
2023-05-26 09:28:28.939: [iter 112 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0058, time: 7.047397]
2023-05-26 09:28:29.106: epoch 112:	0.02659533  	0.19688410  	0.10784857  
2023-05-26 09:28:29.106: Find a better model.
2023-05-26 09:28:36.151: [iter 113 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0059, time: 7.044428]
2023-05-26 09:28:36.302: epoch 113:	0.02664473  	0.19730093  	0.10815167  
2023-05-26 09:28:36.302: Find a better model.
2023-05-26 09:28:43.327: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 7.022571]
2023-05-26 09:28:43.482: epoch 114:	0.02661650  	0.19707774  	0.10812361  
2023-05-26 09:28:50.525: [iter 115 : loss : 0.1191 = 0.0305 + 0.0827 + 0.0059, time: 7.041698]
2023-05-26 09:28:50.694: epoch 115:	0.02658123  	0.19683549  	0.10794176  
2023-05-26 09:28:57.698: [iter 116 : loss : 0.1183 = 0.0296 + 0.0827 + 0.0060, time: 7.003003]
2023-05-26 09:28:57.851: epoch 116:	0.02660240  	0.19700196  	0.10798942  
2023-05-26 09:29:04.909: [iter 117 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 7.056014]
2023-05-26 09:29:05.060: epoch 117:	0.02667296  	0.19760135  	0.10817439  
2023-05-26 09:29:05.060: Find a better model.
2023-05-26 09:29:11.913: [iter 118 : loss : 0.1183 = 0.0297 + 0.0826 + 0.0060, time: 6.852004]
2023-05-26 09:29:12.066: epoch 118:	0.02667296  	0.19743241  	0.10815363  
2023-05-26 09:29:19.113: [iter 119 : loss : 0.1173 = 0.0288 + 0.0825 + 0.0061, time: 7.045031]
2023-05-26 09:29:19.267: epoch 119:	0.02668707  	0.19738537  	0.10817889  
2023-05-26 09:29:26.311: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 7.043023]
2023-05-26 09:29:26.477: epoch 120:	0.02672235  	0.19749366  	0.10839914  
2023-05-26 09:29:33.496: [iter 121 : loss : 0.1174 = 0.0289 + 0.0824 + 0.0061, time: 7.018050]
2023-05-26 09:29:33.666: epoch 121:	0.02667296  	0.19716318  	0.10823841  
2023-05-26 09:29:40.501: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.833971]
2023-05-26 09:29:40.654: epoch 122:	0.02671530  	0.19739914  	0.10842416  
2023-05-26 09:29:47.487: [iter 123 : loss : 0.1164 = 0.0280 + 0.0823 + 0.0062, time: 6.830994]
2023-05-26 09:29:47.637: epoch 123:	0.02671530  	0.19725896  	0.10851417  
2023-05-26 09:29:54.691: [iter 124 : loss : 0.1157 = 0.0272 + 0.0823 + 0.0062, time: 7.052030]
2023-05-26 09:29:54.859: epoch 124:	0.02672235  	0.19701780  	0.10864180  
2023-05-26 09:30:01.729: [iter 125 : loss : 0.1149 = 0.0264 + 0.0822 + 0.0062, time: 6.867003]
2023-05-26 09:30:01.897: epoch 125:	0.02675058  	0.19731531  	0.10876710  
2023-05-26 09:30:08.693: [iter 126 : loss : 0.1153 = 0.0269 + 0.0822 + 0.0063, time: 6.794028]
2023-05-26 09:30:08.843: epoch 126:	0.02677175  	0.19789368  	0.10897581  
2023-05-26 09:30:08.843: Find a better model.
2023-05-26 09:30:15.709: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.865006]
2023-05-26 09:30:15.879: epoch 127:	0.02674352  	0.19739142  	0.10887627  
2023-05-26 09:30:22.871: [iter 128 : loss : 0.1154 = 0.0270 + 0.0821 + 0.0063, time: 6.990013]
2023-05-26 09:30:23.023: epoch 128:	0.02675058  	0.19747254  	0.10895581  
2023-05-26 09:30:30.072: [iter 129 : loss : 0.1144 = 0.0260 + 0.0821 + 0.0064, time: 7.047924]
2023-05-26 09:30:30.240: epoch 129:	0.02670825  	0.19718041  	0.10886372  
2023-05-26 09:30:37.264: [iter 130 : loss : 0.1146 = 0.0262 + 0.0820 + 0.0064, time: 7.022104]
2023-05-26 09:30:37.421: epoch 130:	0.02682114  	0.19809043  	0.10913019  
2023-05-26 09:30:37.421: Find a better model.
2023-05-26 09:30:44.487: [iter 131 : loss : 0.1136 = 0.0253 + 0.0820 + 0.0064, time: 7.065005]
2023-05-26 09:30:44.655: epoch 131:	0.02684936  	0.19806901  	0.10919322  
2023-05-26 09:30:51.666: [iter 132 : loss : 0.1139 = 0.0255 + 0.0819 + 0.0065, time: 7.009010]
2023-05-26 09:30:51.817: epoch 132:	0.02686348  	0.19830397  	0.10923047  
2023-05-26 09:30:51.817: Find a better model.
2023-05-26 09:30:58.858: [iter 133 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0065, time: 7.037080]
2023-05-26 09:30:59.007: epoch 133:	0.02691287  	0.19846995  	0.10927822  
2023-05-26 09:30:59.008: Find a better model.
2023-05-26 09:31:05.871: [iter 134 : loss : 0.1133 = 0.0250 + 0.0818 + 0.0065, time: 6.862006]
2023-05-26 09:31:06.039: epoch 134:	0.02682113  	0.19781464  	0.10920904  
2023-05-26 09:31:13.058: [iter 135 : loss : 0.1132 = 0.0248 + 0.0818 + 0.0065, time: 7.018013]
2023-05-26 09:31:13.211: epoch 135:	0.02679291  	0.19739789  	0.10913677  
2023-05-26 09:31:20.277: [iter 136 : loss : 0.1127 = 0.0244 + 0.0818 + 0.0066, time: 7.065058]
2023-05-26 09:31:20.444: epoch 136:	0.02680702  	0.19741346  	0.10906369  
2023-05-26 09:31:27.477: [iter 137 : loss : 0.1124 = 0.0241 + 0.0817 + 0.0066, time: 7.031175]
2023-05-26 09:31:27.643: epoch 137:	0.02685642  	0.19768718  	0.10912795  
2023-05-26 09:31:34.664: [iter 138 : loss : 0.1122 = 0.0238 + 0.0817 + 0.0066, time: 7.019986]
2023-05-26 09:31:34.832: epoch 138:	0.02685642  	0.19749345  	0.10917272  
2023-05-26 09:31:41.847: [iter 139 : loss : 0.1119 = 0.0236 + 0.0816 + 0.0067, time: 7.014004]
2023-05-26 09:31:42.011: epoch 139:	0.02687759  	0.19792518  	0.10919942  
2023-05-26 09:31:48.865: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.852013]
2023-05-26 09:31:49.017: epoch 140:	0.02686348  	0.19797336  	0.10934309  
2023-05-26 09:31:56.034: [iter 141 : loss : 0.1118 = 0.0236 + 0.0816 + 0.0067, time: 7.015067]
2023-05-26 09:31:56.184: epoch 141:	0.02694815  	0.19861002  	0.10960418  
2023-05-26 09:31:56.184: Find a better model.
2023-05-26 09:32:03.244: [iter 142 : loss : 0.1109 = 0.0227 + 0.0815 + 0.0067, time: 7.059003]
2023-05-26 09:32:03.417: epoch 142:	0.02687054  	0.19848707  	0.10970152  
2023-05-26 09:32:10.459: [iter 143 : loss : 0.1110 = 0.0227 + 0.0815 + 0.0068, time: 7.041031]
2023-05-26 09:32:10.609: epoch 143:	0.02689170  	0.19856650  	0.10967665  
2023-05-26 09:32:17.464: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.854027]
2023-05-26 09:32:17.629: epoch 144:	0.02689875  	0.19865480  	0.10973512  
2023-05-26 09:32:17.629: Find a better model.
2023-05-26 09:32:24.636: [iter 145 : loss : 0.1103 = 0.0221 + 0.0814 + 0.0068, time: 7.006016]
2023-05-26 09:32:24.786: epoch 145:	0.02685641  	0.19818451  	0.10944367  
2023-05-26 09:32:31.818: [iter 146 : loss : 0.1108 = 0.0225 + 0.0814 + 0.0068, time: 7.030003]
2023-05-26 09:32:31.984: epoch 146:	0.02690581  	0.19853148  	0.10962118  
2023-05-26 09:32:39.020: [iter 147 : loss : 0.1105 = 0.0223 + 0.0814 + 0.0069, time: 7.035132]
2023-05-26 09:32:39.174: epoch 147:	0.02696226  	0.19909973  	0.10972913  
2023-05-26 09:32:39.174: Find a better model.
2023-05-26 09:32:46.219: [iter 148 : loss : 0.1094 = 0.0211 + 0.0813 + 0.0069, time: 7.044056]
2023-05-26 09:32:46.372: epoch 148:	0.02691287  	0.19869921  	0.10961562  
2023-05-26 09:32:53.454: [iter 149 : loss : 0.1098 = 0.0215 + 0.0813 + 0.0069, time: 7.080000]
2023-05-26 09:32:53.607: epoch 149:	0.02693404  	0.19897473  	0.10961001  
2023-05-26 09:33:00.652: [iter 150 : loss : 0.1089 = 0.0207 + 0.0813 + 0.0070, time: 7.042022]
2023-05-26 09:33:00.800: epoch 150:	0.02694109  	0.19869021  	0.10962934  
2023-05-26 09:33:07.840: [iter 151 : loss : 0.1092 = 0.0210 + 0.0812 + 0.0070, time: 7.038004]
2023-05-26 09:33:07.991: epoch 151:	0.02691287  	0.19832748  	0.10971968  
2023-05-26 09:33:15.012: [iter 152 : loss : 0.1085 = 0.0203 + 0.0812 + 0.0070, time: 7.020043]
2023-05-26 09:33:15.167: epoch 152:	0.02688465  	0.19825678  	0.10964087  
2023-05-26 09:33:22.232: [iter 153 : loss : 0.1078 = 0.0196 + 0.0812 + 0.0070, time: 7.062996]
2023-05-26 09:33:22.406: epoch 153:	0.02688464  	0.19829977  	0.10955414  
2023-05-26 09:33:29.422: [iter 154 : loss : 0.1082 = 0.0200 + 0.0811 + 0.0071, time: 7.015016]
2023-05-26 09:33:29.591: epoch 154:	0.02689170  	0.19837467  	0.10965764  
2023-05-26 09:33:36.659: [iter 155 : loss : 0.1091 = 0.0209 + 0.0811 + 0.0071, time: 7.067010]
2023-05-26 09:33:36.825: epoch 155:	0.02687054  	0.19848257  	0.10960022  
2023-05-26 09:33:43.824: [iter 156 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.997003]
2023-05-26 09:33:43.974: epoch 156:	0.02687759  	0.19817254  	0.10950074  
2023-05-26 09:33:51.014: [iter 157 : loss : 0.1080 = 0.0198 + 0.0811 + 0.0071, time: 7.037009]
2023-05-26 09:33:51.165: epoch 157:	0.02688465  	0.19807652  	0.10952023  
2023-05-26 09:33:58.200: [iter 158 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 7.034000]
2023-05-26 09:33:58.369: epoch 158:	0.02689876  	0.19814856  	0.10945178  
2023-05-26 09:34:05.421: [iter 159 : loss : 0.1077 = 0.0196 + 0.0810 + 0.0072, time: 7.051014]
2023-05-26 09:34:05.587: epoch 159:	0.02686348  	0.19792651  	0.10935209  
2023-05-26 09:34:12.596: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 7.007050]
2023-05-26 09:34:12.750: epoch 160:	0.02686347  	0.19763681  	0.10938754  
2023-05-26 09:34:19.645: [iter 161 : loss : 0.1069 = 0.0188 + 0.0809 + 0.0072, time: 6.894004]
2023-05-26 09:34:19.796: epoch 161:	0.02674351  	0.19697826  	0.10916586  
2023-05-26 09:34:26.804: [iter 162 : loss : 0.1063 = 0.0181 + 0.0809 + 0.0073, time: 7.006042]
2023-05-26 09:34:26.957: epoch 162:	0.02677174  	0.19694793  	0.10927787  
2023-05-26 09:34:33.985: [iter 163 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 7.026001]
2023-05-26 09:34:34.135: epoch 163:	0.02675763  	0.19681428  	0.10902502  
2023-05-26 09:34:41.171: [iter 164 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 7.034050]
2023-05-26 09:34:41.323: epoch 164:	0.02678585  	0.19696063  	0.10911652  
2023-05-26 09:34:48.390: [iter 165 : loss : 0.1063 = 0.0181 + 0.0808 + 0.0073, time: 7.065001]
2023-05-26 09:34:48.540: epoch 165:	0.02672940  	0.19667947  	0.10902674  
2023-05-26 09:34:55.582: [iter 166 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 7.040454]
2023-05-26 09:34:55.733: epoch 166:	0.02677174  	0.19706564  	0.10904150  
2023-05-26 09:35:02.643: [iter 167 : loss : 0.1065 = 0.0183 + 0.0808 + 0.0074, time: 6.909065]
2023-05-26 09:35:02.797: epoch 167:	0.02668706  	0.19613440  	0.10908443  
2023-05-26 09:35:09.785: [iter 168 : loss : 0.1059 = 0.0178 + 0.0808 + 0.0074, time: 6.985004]
2023-05-26 09:35:09.953: epoch 168:	0.02677174  	0.19680120  	0.10896485  
2023-05-26 09:35:16.995: [iter 169 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0074, time: 7.040002]
2023-05-26 09:35:17.161: epoch 169:	0.02677174  	0.19665568  	0.10901324  
2023-05-26 09:35:24.170: [iter 170 : loss : 0.1058 = 0.0176 + 0.0807 + 0.0075, time: 7.008039]
2023-05-26 09:35:24.323: epoch 170:	0.02670823  	0.19616134  	0.10878197  
2023-05-26 09:35:31.386: [iter 171 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0075, time: 7.060057]
2023-05-26 09:35:31.552: epoch 171:	0.02674351  	0.19633444  	0.10896747  
2023-05-26 09:35:38.582: [iter 172 : loss : 0.1051 = 0.0169 + 0.0807 + 0.0075, time: 7.027993]
2023-05-26 09:35:38.748: epoch 172:	0.02668706  	0.19595338  	0.10885762  
2023-05-26 09:35:38.749: Early stopping is trigger at epoch: 172
2023-05-26 09:35:38.749: best_result@epoch 147:

2023-05-26 09:35:38.749: 		0.0270      	0.1991      	0.1097      
2023-05-26 09:36:08.940: my pid: 11288
2023-05-26 09:36:08.940: model: model.general_recommender.SGL
2023-05-26 09:36:08.940: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 09:36:08.940: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 09:36:12.796: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 09:36:20.392: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.596100]
2023-05-26 09:36:20.547: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-26 09:36:20.547: Find a better model.
2023-05-26 09:36:28.161: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.611910]
2023-05-26 09:36:28.331: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-26 09:36:28.332: Find a better model.
2023-05-26 09:36:35.748: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.414172]
2023-05-26 09:36:35.921: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-26 09:36:35.921: Find a better model.
2023-05-26 09:36:43.121: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.198446]
2023-05-26 09:36:43.274: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-26 09:36:43.274: Find a better model.
2023-05-26 09:36:50.381: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.106027]
2023-05-26 09:36:50.554: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-26 09:36:50.554: Find a better model.
2023-05-26 09:36:57.542: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.987014]
2023-05-26 09:36:57.692: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-26 09:36:57.692: Find a better model.
2023-05-26 09:37:04.540: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.847472]
2023-05-26 09:37:04.689: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-26 09:37:04.690: Find a better model.
2023-05-26 09:37:11.526: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.834521]
2023-05-26 09:37:11.678: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-26 09:37:11.678: Find a better model.
2023-05-26 09:37:18.515: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.836003]
2023-05-26 09:37:18.680: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-26 09:37:25.512: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.829054]
2023-05-26 09:37:25.659: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-26 09:37:32.355: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.694443]
2023-05-26 09:37:32.503: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-26 09:37:39.302: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.797597]
2023-05-26 09:37:39.453: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-26 09:37:46.100: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.646249]
2023-05-26 09:37:46.250: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-26 09:37:52.933: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.682026]
2023-05-26 09:37:53.098: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-26 09:37:59.711: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.612305]
2023-05-26 09:37:59.860: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-26 09:37:59.860: Find a better model.
2023-05-26 09:38:06.521: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.659041]
2023-05-26 09:38:06.684: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-26 09:38:06.684: Find a better model.
2023-05-26 09:38:13.493: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.808068]
2023-05-26 09:38:13.655: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-26 09:38:13.655: Find a better model.
2023-05-26 09:38:20.325: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.668006]
2023-05-26 09:38:20.486: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-26 09:38:20.486: Find a better model.
2023-05-26 09:38:27.084: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.596001]
2023-05-26 09:38:27.234: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-26 09:38:27.234: Find a better model.
2023-05-26 09:38:33.865: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.630005]
2023-05-26 09:38:34.012: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-26 09:38:34.012: Find a better model.
2023-05-26 09:38:40.683: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.669484]
2023-05-26 09:38:40.831: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-26 09:38:40.831: Find a better model.
2023-05-26 09:38:47.483: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.650448]
2023-05-26 09:38:47.632: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-26 09:38:47.632: Find a better model.
2023-05-26 09:38:54.293: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.659014]
2023-05-26 09:38:54.447: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-26 09:38:54.447: Find a better model.
2023-05-26 09:39:01.277: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.829008]
2023-05-26 09:39:01.433: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-26 09:39:01.433: Find a better model.
2023-05-26 09:39:08.065: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.631058]
2023-05-26 09:39:08.229: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-26 09:39:08.229: Find a better model.
2023-05-26 09:39:14.878: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.648002]
2023-05-26 09:39:15.030: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-26 09:39:15.030: Find a better model.
2023-05-26 09:39:21.689: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.657012]
2023-05-26 09:39:21.837: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-26 09:39:21.837: Find a better model.
2023-05-26 09:39:28.491: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.652042]
2023-05-26 09:39:28.641: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-26 09:39:28.641: Find a better model.
2023-05-26 09:39:35.464: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.820993]
2023-05-26 09:39:35.625: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-26 09:39:35.626: Find a better model.
2023-05-26 09:39:42.284: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.657010]
2023-05-26 09:39:42.436: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-26 09:39:42.436: Find a better model.
2023-05-26 09:39:49.078: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.640013]
2023-05-26 09:39:49.225: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-26 09:39:49.225: Find a better model.
2023-05-26 09:39:55.860: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.633014]
2023-05-26 09:39:56.008: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-26 09:39:56.008: Find a better model.
2023-05-26 09:40:02.656: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.646005]
2023-05-26 09:40:02.808: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-26 09:40:02.808: Find a better model.
2023-05-26 09:40:09.465: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.656015]
2023-05-26 09:40:09.616: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-26 09:40:09.617: Find a better model.
2023-05-26 09:40:16.268: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.649994]
2023-05-26 09:40:16.421: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-26 09:40:16.422: Find a better model.
2023-05-26 09:40:23.060: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.636013]
2023-05-26 09:40:23.208: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-26 09:40:23.208: Find a better model.
2023-05-26 09:40:29.845: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.635171]
2023-05-26 09:40:29.992: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-26 09:40:29.992: Find a better model.
2023-05-26 09:40:36.656: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.663210]
2023-05-26 09:40:36.805: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-26 09:40:36.805: Find a better model.
2023-05-26 09:40:43.459: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.653426]
2023-05-26 09:40:43.629: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-26 09:40:43.629: Find a better model.
2023-05-26 09:40:50.257: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.625266]
2023-05-26 09:40:50.425: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-26 09:40:57.041: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.613743]
2023-05-26 09:40:57.187: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-26 09:40:57.187: Find a better model.
2023-05-26 09:41:03.836: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.647004]
2023-05-26 09:41:03.983: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-26 09:41:03.984: Find a better model.
2023-05-26 09:41:10.656: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.671020]
2023-05-26 09:41:10.807: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-26 09:41:10.807: Find a better model.
2023-05-26 09:41:17.462: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.653994]
2023-05-26 09:41:17.609: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-26 09:41:17.609: Find a better model.
2023-05-26 09:41:24.231: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.621004]
2023-05-26 09:41:24.379: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-26 09:41:24.379: Find a better model.
2023-05-26 09:41:30.840: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.459575]
2023-05-26 09:41:30.990: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-26 09:41:30.990: Find a better model.
2023-05-26 09:41:37.627: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.636022]
2023-05-26 09:41:37.773: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-26 09:41:37.773: Find a better model.
2023-05-26 09:41:44.419: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.645022]
2023-05-26 09:41:44.567: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-26 09:41:44.567: Find a better model.
2023-05-26 09:41:51.218: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.649003]
2023-05-26 09:41:51.365: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-26 09:41:51.365: Find a better model.
2023-05-26 09:41:58.014: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.648005]
2023-05-26 09:41:58.164: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-26 09:41:58.164: Find a better model.
2023-05-26 09:42:04.651: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.485851]
2023-05-26 09:42:04.799: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-26 09:42:11.401: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.601038]
2023-05-26 09:42:11.550: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-26 09:42:11.550: Find a better model.
2023-05-26 09:42:18.026: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.475013]
2023-05-26 09:42:18.178: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-26 09:42:18.178: Find a better model.
2023-05-26 09:42:24.609: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.429004]
2023-05-26 09:42:24.760: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-26 09:42:24.760: Find a better model.
2023-05-26 09:42:31.422: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.661196]
2023-05-26 09:42:31.575: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-26 09:42:31.575: Find a better model.
2023-05-26 09:42:38.201: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.625030]
2023-05-26 09:42:38.349: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-26 09:42:38.349: Find a better model.
2023-05-26 09:42:44.833: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.483050]
2023-05-26 09:42:44.979: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-26 09:42:44.980: Find a better model.
2023-05-26 09:42:51.582: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.601096]
2023-05-26 09:42:51.730: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-26 09:42:51.730: Find a better model.
2023-05-26 09:42:58.207: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.475053]
2023-05-26 09:42:58.355: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-26 09:42:58.355: Find a better model.
2023-05-26 09:43:04.813: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.457051]
2023-05-26 09:43:04.963: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-26 09:43:04.963: Find a better model.
2023-05-26 09:43:11.593: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.628027]
2023-05-26 09:43:11.740: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-26 09:43:11.740: Find a better model.
2023-05-26 09:43:18.399: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.657007]
2023-05-26 09:43:18.565: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-26 09:43:18.565: Find a better model.
2023-05-26 09:43:25.195: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.629031]
2023-05-26 09:43:25.344: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-26 09:43:31.800: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.454010]
2023-05-26 09:43:31.950: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-26 09:43:31.950: Find a better model.
2023-05-26 09:43:38.572: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.619019]
2023-05-26 09:43:38.718: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-26 09:43:38.719: Find a better model.
2023-05-26 09:43:45.388: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.668012]
2023-05-26 09:43:45.552: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-26 09:43:45.552: Find a better model.
2023-05-26 09:43:52.189: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.635021]
2023-05-26 09:43:52.337: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-26 09:43:52.337: Find a better model.
2023-05-26 09:43:58.800: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.462366]
2023-05-26 09:43:58.968: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-26 09:43:58.968: Find a better model.
2023-05-26 09:44:05.576: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.605999]
2023-05-26 09:44:05.726: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-26 09:44:05.726: Find a better model.
2023-05-26 09:44:12.400: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.673014]
2023-05-26 09:44:12.553: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-26 09:44:12.553: Find a better model.
2023-05-26 09:44:18.990: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.436016]
2023-05-26 09:44:19.138: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-26 09:44:25.743: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.603004]
2023-05-26 09:44:25.890: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-26 09:44:25.890: Find a better model.
2023-05-26 09:44:32.376: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.483994]
2023-05-26 09:44:32.523: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-26 09:44:32.523: Find a better model.
2023-05-26 09:44:38.981: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.455994]
2023-05-26 09:44:39.133: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-26 09:44:45.571: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.435571]
2023-05-26 09:44:45.720: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-26 09:44:52.355: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.634161]
2023-05-26 09:44:52.505: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-26 09:44:52.505: Find a better model.
2023-05-26 09:44:58.964: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.458136]
2023-05-26 09:44:59.113: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-26 09:44:59.113: Find a better model.
2023-05-26 09:45:05.746: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.632030]
2023-05-26 09:45:05.894: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-26 09:45:05.894: Find a better model.
2023-05-26 09:45:12.550: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.654065]
2023-05-26 09:45:12.716: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-26 09:45:19.326: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.608026]
2023-05-26 09:45:19.478: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-26 09:45:19.479: Find a better model.
2023-05-26 09:45:26.147: [iter 81 : loss : 0.1404 = 0.0499 + 0.0858 + 0.0047, time: 6.667039]
2023-05-26 09:45:26.300: epoch 81:	0.02574856  	0.18996128  	0.10372350  
2023-05-26 09:45:26.301: Find a better model.
2023-05-26 09:45:32.964: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.661087]
2023-05-26 09:45:33.111: epoch 82:	0.02593203  	0.19120815  	0.10441370  
2023-05-26 09:45:33.111: Find a better model.
2023-05-26 09:45:39.770: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.658004]
2023-05-26 09:45:39.919: epoch 83:	0.02591087  	0.19119930  	0.10433015  
2023-05-26 09:45:46.555: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.633179]
2023-05-26 09:45:46.704: epoch 84:	0.02591792  	0.19129056  	0.10439532  
2023-05-26 09:45:46.704: Find a better model.
2023-05-26 09:45:53.353: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.648012]
2023-05-26 09:45:53.506: epoch 85:	0.02591793  	0.19138658  	0.10480066  
2023-05-26 09:45:53.506: Find a better model.
2023-05-26 09:46:00.322: [iter 86 : loss : 0.1368 = 0.0466 + 0.0853 + 0.0049, time: 6.815087]
2023-05-26 09:46:00.476: epoch 86:	0.02597438  	0.19170369  	0.10489958  
2023-05-26 09:46:00.476: Find a better model.
2023-05-26 09:46:07.137: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.660009]
2023-05-26 09:46:07.284: epoch 87:	0.02606611  	0.19219515  	0.10506900  
2023-05-26 09:46:07.284: Find a better model.
2023-05-26 09:46:13.936: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.650013]
2023-05-26 09:46:14.085: epoch 88:	0.02608729  	0.19233896  	0.10512576  
2023-05-26 09:46:14.085: Find a better model.
2023-05-26 09:46:20.743: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.655177]
2023-05-26 09:46:20.892: epoch 89:	0.02604495  	0.19179258  	0.10495026  
2023-05-26 09:46:27.544: [iter 90 : loss : 0.1340 = 0.0440 + 0.0850 + 0.0050, time: 6.650244]
2023-05-26 09:46:27.709: epoch 90:	0.02619313  	0.19268598  	0.10537103  
2023-05-26 09:46:27.709: Find a better model.
2023-05-26 09:46:34.353: [iter 91 : loss : 0.1326 = 0.0427 + 0.0849 + 0.0050, time: 6.642007]
2023-05-26 09:46:34.512: epoch 91:	0.02622841  	0.19316201  	0.10557381  
2023-05-26 09:46:34.512: Find a better model.
2023-05-26 09:46:41.130: [iter 92 : loss : 0.1314 = 0.0415 + 0.0848 + 0.0051, time: 6.617013]
2023-05-26 09:46:41.279: epoch 92:	0.02626370  	0.19322601  	0.10570642  
2023-05-26 09:46:41.279: Find a better model.
2023-05-26 09:46:47.929: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.648034]
2023-05-26 09:46:48.079: epoch 93:	0.02627781  	0.19349909  	0.10590052  
2023-05-26 09:46:48.079: Find a better model.
2023-05-26 09:46:54.727: [iter 94 : loss : 0.1300 = 0.0402 + 0.0847 + 0.0052, time: 6.647010]
2023-05-26 09:46:54.875: epoch 94:	0.02636249  	0.19411081  	0.10620536  
2023-05-26 09:46:54.875: Find a better model.
2023-05-26 09:47:01.550: [iter 95 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.672370]
2023-05-26 09:47:01.712: epoch 95:	0.02633426  	0.19392097  	0.10623044  
2023-05-26 09:47:08.360: [iter 96 : loss : 0.1293 = 0.0395 + 0.0845 + 0.0052, time: 6.647188]
2023-05-26 09:47:08.517: epoch 96:	0.02633426  	0.19394943  	0.10633997  
2023-05-26 09:47:15.304: [iter 97 : loss : 0.1278 = 0.0380 + 0.0844 + 0.0053, time: 6.784993]
2023-05-26 09:47:15.469: epoch 97:	0.02638366  	0.19442491  	0.10643354  
2023-05-26 09:47:15.469: Find a better model.
2023-05-26 09:47:22.303: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.832512]
2023-05-26 09:47:22.470: epoch 98:	0.02648950  	0.19530457  	0.10684288  
2023-05-26 09:47:22.470: Find a better model.
2023-05-26 09:47:29.114: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 6.643148]
2023-05-26 09:47:29.266: epoch 99:	0.02653890  	0.19577278  	0.10702658  
2023-05-26 09:47:29.266: Find a better model.
2023-05-26 09:47:35.922: [iter 100 : loss : 0.1269 = 0.0373 + 0.0842 + 0.0054, time: 6.654002]
2023-05-26 09:47:36.071: epoch 100:	0.02659534  	0.19630365  	0.10702746  
2023-05-26 09:47:36.071: Find a better model.
2023-05-26 09:47:42.702: [iter 101 : loss : 0.1264 = 0.0369 + 0.0842 + 0.0054, time: 6.629994]
2023-05-26 09:47:42.865: epoch 101:	0.02660240  	0.19649538  	0.10706690  
2023-05-26 09:47:42.865: Find a better model.
2023-05-26 09:47:49.531: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0055, time: 6.664520]
2023-05-26 09:47:49.683: epoch 102:	0.02668708  	0.19680172  	0.10738961  
2023-05-26 09:47:49.683: Find a better model.
2023-05-26 09:47:56.308: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.624137]
2023-05-26 09:47:56.470: epoch 103:	0.02675059  	0.19731146  	0.10752033  
2023-05-26 09:47:56.470: Find a better model.
2023-05-26 09:48:03.094: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.623080]
2023-05-26 09:48:03.242: epoch 104:	0.02677882  	0.19760688  	0.10784601  
2023-05-26 09:48:03.242: Find a better model.
2023-05-26 09:48:09.912: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.669024]
2023-05-26 09:48:10.074: epoch 105:	0.02671531  	0.19737288  	0.10783216  
2023-05-26 09:48:16.697: [iter 106 : loss : 0.1245 = 0.0351 + 0.0838 + 0.0056, time: 6.622007]
2023-05-26 09:48:16.846: epoch 106:	0.02669414  	0.19678113  	0.10754056  
2023-05-26 09:48:23.514: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.665999]
2023-05-26 09:48:23.664: epoch 107:	0.02673647  	0.19702093  	0.10766675  
2023-05-26 09:48:30.315: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 6.649066]
2023-05-26 09:48:30.475: epoch 108:	0.02673647  	0.19723104  	0.10774960  
2023-05-26 09:48:37.131: [iter 109 : loss : 0.1221 = 0.0328 + 0.0837 + 0.0057, time: 6.655046]
2023-05-26 09:48:37.296: epoch 109:	0.02680703  	0.19770670  	0.10784515  
2023-05-26 09:48:37.296: Find a better model.
2023-05-26 09:48:43.888: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.590070]
2023-05-26 09:48:44.037: epoch 110:	0.02686348  	0.19800378  	0.10788895  
2023-05-26 09:48:44.037: Find a better model.
2023-05-26 09:48:50.671: [iter 111 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0058, time: 6.632458]
2023-05-26 09:48:50.818: epoch 111:	0.02685643  	0.19818251  	0.10797095  
2023-05-26 09:48:50.818: Find a better model.
2023-05-26 09:48:57.477: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.657009]
2023-05-26 09:48:57.624: epoch 112:	0.02690582  	0.19846314  	0.10810366  
2023-05-26 09:48:57.624: Find a better model.
2023-05-26 09:49:04.286: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.660016]
2023-05-26 09:49:04.443: epoch 113:	0.02694816  	0.19907364  	0.10829639  
2023-05-26 09:49:04.443: Find a better model.
2023-05-26 09:49:11.077: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.632976]
2023-05-26 09:49:11.239: epoch 114:	0.02696933  	0.19924569  	0.10851342  
2023-05-26 09:49:11.239: Find a better model.
2023-05-26 09:49:17.878: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.638013]
2023-05-26 09:49:18.030: epoch 115:	0.02698344  	0.19887096  	0.10852957  
2023-05-26 09:49:24.649: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.618005]
2023-05-26 09:49:24.800: epoch 116:	0.02691287  	0.19817071  	0.10832782  
2023-05-26 09:49:31.474: [iter 117 : loss : 0.1193 = 0.0301 + 0.0832 + 0.0060, time: 6.672003]
2023-05-26 09:49:31.635: epoch 117:	0.02691287  	0.19809218  	0.10824026  
2023-05-26 09:49:38.266: [iter 118 : loss : 0.1191 = 0.0299 + 0.0832 + 0.0060, time: 6.628531]
2023-05-26 09:49:38.419: epoch 118:	0.02696932  	0.19853675  	0.10841770  
2023-05-26 09:49:45.045: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.624104]
2023-05-26 09:49:45.194: epoch 119:	0.02691992  	0.19814539  	0.10847185  
2023-05-26 09:49:51.865: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.670014]
2023-05-26 09:49:52.030: epoch 120:	0.02700461  	0.19877870  	0.10873345  
2023-05-26 09:49:58.656: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.624018]
2023-05-26 09:49:58.821: epoch 121:	0.02698343  	0.19852519  	0.10878448  
2023-05-26 09:50:05.483: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.661003]
2023-05-26 09:50:05.649: epoch 122:	0.02701166  	0.19874974  	0.10883870  
2023-05-26 09:50:12.255: [iter 123 : loss : 0.1175 = 0.0285 + 0.0829 + 0.0061, time: 6.605047]
2023-05-26 09:50:12.406: epoch 123:	0.02699048  	0.19863144  	0.10862576  
2023-05-26 09:50:19.052: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.644004]
2023-05-26 09:50:19.200: epoch 124:	0.02703988  	0.19904472  	0.10866051  
2023-05-26 09:50:25.841: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.639065]
2023-05-26 09:50:25.989: epoch 125:	0.02707516  	0.19940683  	0.10876899  
2023-05-26 09:50:25.989: Find a better model.
2023-05-26 09:50:32.657: [iter 126 : loss : 0.1161 = 0.0270 + 0.0828 + 0.0062, time: 6.666071]
2023-05-26 09:50:32.806: epoch 126:	0.02704694  	0.19924128  	0.10874914  
2023-05-26 09:50:39.429: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.621018]
2023-05-26 09:50:39.577: epoch 127:	0.02699755  	0.19923887  	0.10892854  
2023-05-26 09:50:46.235: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 6.657007]
2023-05-26 09:50:46.386: epoch 128:	0.02706811  	0.19969688  	0.10904835  
2023-05-26 09:50:46.386: Find a better model.
2023-05-26 09:50:53.017: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.629017]
2023-05-26 09:50:53.167: epoch 129:	0.02713162  	0.20003416  	0.10924208  
2023-05-26 09:50:53.167: Find a better model.
2023-05-26 09:50:59.824: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.655025]
2023-05-26 09:50:59.971: epoch 130:	0.02713868  	0.20039493  	0.10945855  
2023-05-26 09:50:59.971: Find a better model.
2023-05-26 09:51:06.648: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.676031]
2023-05-26 09:51:06.797: epoch 131:	0.02712457  	0.20007513  	0.10952345  
2023-05-26 09:51:13.417: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.618021]
2023-05-26 09:51:13.570: epoch 132:	0.02716690  	0.20064868  	0.10958902  
2023-05-26 09:51:13.570: Find a better model.
2023-05-26 09:51:20.245: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.674149]
2023-05-26 09:51:20.393: epoch 133:	0.02711750  	0.20036857  	0.10963763  
2023-05-26 09:51:27.036: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.641085]
2023-05-26 09:51:27.183: epoch 134:	0.02712456  	0.20007493  	0.10961650  
2023-05-26 09:51:33.836: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.650195]
2023-05-26 09:51:33.985: epoch 135:	0.02709633  	0.19988248  	0.10950078  
2023-05-26 09:51:40.640: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.652993]
2023-05-26 09:51:40.787: epoch 136:	0.02703283  	0.19989745  	0.10931328  
2023-05-26 09:51:47.424: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.635112]
2023-05-26 09:51:47.593: epoch 137:	0.02711044  	0.20013352  	0.10948252  
2023-05-26 09:51:54.223: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.628023]
2023-05-26 09:51:54.375: epoch 138:	0.02703989  	0.19969720  	0.10929241  
2023-05-26 09:52:01.015: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.638474]
2023-05-26 09:52:01.161: epoch 139:	0.02703283  	0.19941266  	0.10926148  
2023-05-26 09:52:07.804: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.641150]
2023-05-26 09:52:07.953: epoch 140:	0.02706811  	0.19964552  	0.10932919  
2023-05-26 09:52:14.630: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.676163]
2023-05-26 09:52:14.795: epoch 141:	0.02705400  	0.19939590  	0.10948652  
2023-05-26 09:52:21.417: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.619454]
2023-05-26 09:52:21.565: epoch 142:	0.02706811  	0.19961935  	0.10953622  
2023-05-26 09:52:28.203: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.637005]
2023-05-26 09:52:28.351: epoch 143:	0.02708222  	0.19972038  	0.10966109  
2023-05-26 09:52:35.009: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.656989]
2023-05-26 09:52:35.171: epoch 144:	0.02705400  	0.19964875  	0.10967912  
2023-05-26 09:52:41.799: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.626389]
2023-05-26 09:52:41.946: epoch 145:	0.02712457  	0.20010756  	0.10978077  
2023-05-26 09:52:48.629: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.681124]
2023-05-26 09:52:48.779: epoch 146:	0.02702578  	0.19929959  	0.10948531  
2023-05-26 09:52:55.401: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.621006]
2023-05-26 09:52:55.552: epoch 147:	0.02707518  	0.19976261  	0.10976949  
2023-05-26 09:53:02.235: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.680999]
2023-05-26 09:53:02.397: epoch 148:	0.02711046  	0.19977392  	0.10970208  
2023-05-26 09:53:09.017: [iter 149 : loss : 0.1105 = 0.0217 + 0.0819 + 0.0069, time: 6.619364]
2023-05-26 09:53:09.169: epoch 149:	0.02715279  	0.19992656  	0.10979668  
2023-05-26 09:53:15.799: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.629078]
2023-05-26 09:53:15.950: epoch 150:	0.02716691  	0.20002118  	0.11011802  
2023-05-26 09:53:22.589: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.637000]
2023-05-26 09:53:22.738: epoch 151:	0.02716691  	0.19984920  	0.11005633  
2023-05-26 09:53:29.398: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.658001]
2023-05-26 09:53:29.549: epoch 152:	0.02711751  	0.19955111  	0.11003111  
2023-05-26 09:53:36.198: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.647001]
2023-05-26 09:53:36.365: epoch 153:	0.02712457  	0.19950961  	0.10990880  
2023-05-26 09:53:43.007: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.641068]
2023-05-26 09:53:43.156: epoch 154:	0.02722335  	0.20031428  	0.11021017  
2023-05-26 09:53:49.964: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.805197]
2023-05-26 09:53:50.113: epoch 155:	0.02713868  	0.19976681  	0.10998125  
2023-05-26 09:53:56.793: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.678016]
2023-05-26 09:53:56.943: epoch 156:	0.02711751  	0.19968447  	0.10981885  
2023-05-26 09:54:03.578: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.634035]
2023-05-26 09:54:03.729: epoch 157:	0.02713163  	0.19979949  	0.10979492  
2023-05-26 09:54:03.729: Early stopping is trigger at epoch: 157
2023-05-26 09:54:03.729: best_result@epoch 132:

2023-05-26 09:54:03.729: 		0.0272      	0.2006      	0.1096      
2023-05-26 10:30:53.346: my pid: 11556
2023-05-26 10:30:53.346: model: model.general_recommender.SGL
2023-05-26 10:30:53.346: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 10:30:53.346: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 10:30:57.106: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 10:31:04.423: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.315291]
2023-05-26 10:31:04.577: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-26 10:31:04.577: Find a better model.
2023-05-26 10:31:12.034: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.455337]
2023-05-26 10:31:12.205: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-26 10:31:12.205: Find a better model.
2023-05-26 10:31:19.423: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.216073]
2023-05-26 10:31:19.602: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-26 10:31:19.602: Find a better model.
2023-05-26 10:31:26.799: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.196354]
2023-05-26 10:31:26.952: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-26 10:31:26.952: Find a better model.
2023-05-26 10:31:33.992: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 7.038774]
2023-05-26 10:31:34.142: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-26 10:31:34.142: Find a better model.
2023-05-26 10:31:40.997: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.854035]
2023-05-26 10:31:41.149: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-26 10:31:41.149: Find a better model.
2023-05-26 10:31:47.800: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.650227]
2023-05-26 10:31:47.948: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-26 10:31:47.948: Find a better model.
2023-05-26 10:31:54.573: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.622161]
2023-05-26 10:31:54.720: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-26 10:31:54.720: Find a better model.
2023-05-26 10:32:01.374: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.653090]
2023-05-26 10:32:01.528: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-26 10:32:08.166: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.636477]
2023-05-26 10:32:08.313: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-26 10:32:14.768: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.454911]
2023-05-26 10:32:14.921: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-26 10:32:21.388: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.465055]
2023-05-26 10:32:21.546: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-26 10:32:27.979: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.429089]
2023-05-26 10:32:28.125: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-26 10:32:28.125: Find a better model.
2023-05-26 10:32:34.578: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.451030]
2023-05-26 10:32:34.728: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-26 10:32:34.729: Find a better model.
2023-05-26 10:32:41.193: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.463075]
2023-05-26 10:32:41.343: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-26 10:32:41.343: Find a better model.
2023-05-26 10:32:47.753: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.409003]
2023-05-26 10:32:47.902: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-26 10:32:47.902: Find a better model.
2023-05-26 10:32:54.378: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.474030]
2023-05-26 10:32:54.538: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-26 10:32:54.538: Find a better model.
2023-05-26 10:33:00.967: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.428020]
2023-05-26 10:33:01.116: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-26 10:33:01.116: Find a better model.
2023-05-26 10:33:07.572: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.455016]
2023-05-26 10:33:07.722: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-26 10:33:07.722: Find a better model.
2023-05-26 10:33:14.324: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.601033]
2023-05-26 10:33:14.479: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-26 10:33:14.479: Find a better model.
2023-05-26 10:33:20.948: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.467943]
2023-05-26 10:33:21.100: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-26 10:33:21.100: Find a better model.
2023-05-26 10:33:27.549: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.448015]
2023-05-26 10:33:27.699: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-26 10:33:27.699: Find a better model.
2023-05-26 10:33:34.145: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.444005]
2023-05-26 10:33:34.297: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-26 10:33:34.297: Find a better model.
2023-05-26 10:33:40.726: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.428003]
2023-05-26 10:33:40.875: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-26 10:33:40.875: Find a better model.
2023-05-26 10:33:47.342: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.465049]
2023-05-26 10:33:47.506: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-26 10:33:47.507: Find a better model.
2023-05-26 10:33:53.941: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.432032]
2023-05-26 10:33:54.093: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-26 10:33:54.093: Find a better model.
2023-05-26 10:34:00.540: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.446173]
2023-05-26 10:34:00.692: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-26 10:34:00.692: Find a better model.
2023-05-26 10:34:07.145: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.452008]
2023-05-26 10:34:07.292: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-26 10:34:07.292: Find a better model.
2023-05-26 10:34:13.736: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.442994]
2023-05-26 10:34:13.901: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-26 10:34:13.901: Find a better model.
2023-05-26 10:34:20.329: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.427015]
2023-05-26 10:34:20.480: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-26 10:34:20.480: Find a better model.
2023-05-26 10:34:26.924: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.443013]
2023-05-26 10:34:27.074: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-26 10:34:27.074: Find a better model.
2023-05-26 10:34:33.533: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.457004]
2023-05-26 10:34:33.681: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-26 10:34:33.682: Find a better model.
2023-05-26 10:34:40.127: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.443994]
2023-05-26 10:34:40.276: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-26 10:34:40.276: Find a better model.
2023-05-26 10:34:46.707: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.429016]
2023-05-26 10:34:46.855: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-26 10:34:46.856: Find a better model.
2023-05-26 10:34:53.318: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.460025]
2023-05-26 10:34:53.481: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-26 10:34:53.481: Find a better model.
2023-05-26 10:34:59.930: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.447994]
2023-05-26 10:35:00.096: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-26 10:35:00.096: Find a better model.
2023-05-26 10:35:06.515: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.417034]
2023-05-26 10:35:06.661: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-26 10:35:06.662: Find a better model.
2023-05-26 10:35:13.113: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.449005]
2023-05-26 10:35:13.261: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-26 10:35:13.261: Find a better model.
2023-05-26 10:35:19.711: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.449175]
2023-05-26 10:35:19.860: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-26 10:35:19.860: Find a better model.
2023-05-26 10:35:26.494: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.632025]
2023-05-26 10:35:26.643: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-26 10:35:26.643: Find a better model.
2023-05-26 10:35:33.292: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.648023]
2023-05-26 10:35:33.460: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-26 10:35:33.460: Find a better model.
2023-05-26 10:35:39.901: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.440007]
2023-05-26 10:35:40.051: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-26 10:35:40.051: Find a better model.
2023-05-26 10:35:46.520: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.466012]
2023-05-26 10:35:46.671: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-26 10:35:53.301: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.628014]
2023-05-26 10:35:53.453: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-26 10:35:53.453: Find a better model.
2023-05-26 10:35:59.890: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.435003]
2023-05-26 10:36:00.042: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-26 10:36:00.042: Find a better model.
2023-05-26 10:36:06.502: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.459021]
2023-05-26 10:36:06.651: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-26 10:36:06.651: Find a better model.
2023-05-26 10:36:13.286: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.634014]
2023-05-26 10:36:13.432: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-26 10:36:13.433: Find a better model.
2023-05-26 10:36:19.901: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.465994]
2023-05-26 10:36:20.048: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-26 10:36:20.048: Find a better model.
2023-05-26 10:36:26.504: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.454240]
2023-05-26 10:36:26.653: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-26 10:36:26.653: Find a better model.
2023-05-26 10:36:33.280: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.626005]
2023-05-26 10:36:33.448: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-26 10:36:40.076: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0034, time: 6.627005]
2023-05-26 10:36:40.240: epoch 51:	0.02385745  	0.17556633  	0.09347075  
2023-05-26 10:36:40.241: Find a better model.
2023-05-26 10:36:46.685: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.443106]
2023-05-26 10:36:46.832: epoch 52:	0.02396329  	0.17615600  	0.09392820  
2023-05-26 10:36:46.832: Find a better model.
2023-05-26 10:36:53.274: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.440050]
2023-05-26 10:36:53.420: epoch 53:	0.02406913  	0.17702526  	0.09434863  
2023-05-26 10:36:53.420: Find a better model.
2023-05-26 10:36:59.866: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.444050]
2023-05-26 10:37:00.018: epoch 54:	0.02419615  	0.17792241  	0.09494144  
2023-05-26 10:37:00.018: Find a better model.
2023-05-26 10:37:06.479: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.460031]
2023-05-26 10:37:06.629: epoch 55:	0.02423849  	0.17839193  	0.09532860  
2023-05-26 10:37:06.629: Find a better model.
2023-05-26 10:37:13.254: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.623013]
2023-05-26 10:37:13.402: epoch 56:	0.02433728  	0.17909700  	0.09573369  
2023-05-26 10:37:13.402: Find a better model.
2023-05-26 10:37:19.868: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.464006]
2023-05-26 10:37:20.016: epoch 57:	0.02446430  	0.18026286  	0.09629583  
2023-05-26 10:37:20.016: Find a better model.
2023-05-26 10:37:26.643: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.625992]
2023-05-26 10:37:26.809: epoch 58:	0.02450663  	0.18062960  	0.09664251  
2023-05-26 10:37:26.809: Find a better model.
2023-05-26 10:37:33.476: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.665034]
2023-05-26 10:37:33.639: epoch 59:	0.02455603  	0.18130884  	0.09686511  
2023-05-26 10:37:33.639: Find a better model.
2023-05-26 10:37:40.270: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.630003]
2023-05-26 10:37:40.419: epoch 60:	0.02457720  	0.18123862  	0.09715549  
2023-05-26 10:37:47.045: [iter 61 : loss : 0.1636 = 0.0705 + 0.0892 + 0.0038, time: 6.625011]
2023-05-26 10:37:47.197: epoch 61:	0.02474656  	0.18253747  	0.09781680  
2023-05-26 10:37:47.198: Find a better model.
2023-05-26 10:37:53.856: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.655994]
2023-05-26 10:37:54.006: epoch 62:	0.02473244  	0.18249248  	0.09802019  
2023-05-26 10:38:00.662: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.654994]
2023-05-26 10:38:00.812: epoch 63:	0.02485240  	0.18354045  	0.09855148  
2023-05-26 10:38:00.812: Find a better model.
2023-05-26 10:38:07.452: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.639111]
2023-05-26 10:38:07.601: epoch 64:	0.02490885  	0.18378471  	0.09903330  
2023-05-26 10:38:07.601: Find a better model.
2023-05-26 10:38:14.261: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.658048]
2023-05-26 10:38:14.412: epoch 65:	0.02485945  	0.18354057  	0.09913395  
2023-05-26 10:38:21.018: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.604175]
2023-05-26 10:38:21.167: epoch 66:	0.02493708  	0.18397158  	0.09932361  
2023-05-26 10:38:21.167: Find a better model.
2023-05-26 10:38:27.661: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.493005]
2023-05-26 10:38:27.810: epoch 67:	0.02504998  	0.18468159  	0.09978308  
2023-05-26 10:38:27.810: Find a better model.
2023-05-26 10:38:34.438: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.627002]
2023-05-26 10:38:34.595: epoch 68:	0.02510642  	0.18502969  	0.10012835  
2023-05-26 10:38:34.595: Find a better model.
2023-05-26 10:38:41.241: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.643023]
2023-05-26 10:38:41.390: epoch 69:	0.02512054  	0.18508086  	0.10032206  
2023-05-26 10:38:41.391: Find a better model.
2023-05-26 10:38:47.844: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.452203]
2023-05-26 10:38:47.993: epoch 70:	0.02521933  	0.18603894  	0.10070904  
2023-05-26 10:38:47.993: Find a better model.
2023-05-26 10:38:54.450: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.454465]
2023-05-26 10:38:54.598: epoch 71:	0.02525461  	0.18614230  	0.10090048  
2023-05-26 10:38:54.605: Find a better model.
2023-05-26 10:39:01.231: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.625021]
2023-05-26 10:39:01.384: epoch 72:	0.02532518  	0.18680170  	0.10119528  
2023-05-26 10:39:01.384: Find a better model.
2023-05-26 10:39:07.831: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.444997]
2023-05-26 10:39:07.979: epoch 73:	0.02535341  	0.18726511  	0.10137676  
2023-05-26 10:39:07.979: Find a better model.
2023-05-26 10:39:14.637: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.656065]
2023-05-26 10:39:14.800: epoch 74:	0.02542397  	0.18757991  	0.10174557  
2023-05-26 10:39:14.800: Find a better model.
2023-05-26 10:39:21.437: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.636019]
2023-05-26 10:39:21.591: epoch 75:	0.02547337  	0.18816072  	0.10190730  
2023-05-26 10:39:21.591: Find a better model.
2023-05-26 10:39:28.233: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.640008]
2023-05-26 10:39:28.382: epoch 76:	0.02557922  	0.18915337  	0.10234687  
2023-05-26 10:39:28.383: Find a better model.
2023-05-26 10:39:34.828: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.444000]
2023-05-26 10:39:34.977: epoch 77:	0.02549453  	0.18842891  	0.10214259  
2023-05-26 10:39:41.619: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.641020]
2023-05-26 10:39:41.772: epoch 78:	0.02557921  	0.18915769  	0.10253035  
2023-05-26 10:39:41.772: Find a better model.
2023-05-26 10:39:48.421: [iter 79 : loss : 0.1425 = 0.0511 + 0.0869 + 0.0046, time: 6.648082]
2023-05-26 10:39:48.570: epoch 79:	0.02564978  	0.18960856  	0.10280474  
2023-05-26 10:39:48.571: Find a better model.
2023-05-26 10:39:55.220: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.648001]
2023-05-26 10:39:55.369: epoch 80:	0.02565683  	0.18977816  	0.10304097  
2023-05-26 10:39:55.369: Find a better model.
2023-05-26 10:40:02.202: [iter 81 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 6.832022]
2023-05-26 10:40:02.350: epoch 81:	0.02569917  	0.18998754  	0.10331520  
2023-05-26 10:40:02.350: Find a better model.
2023-05-26 10:40:09.025: [iter 82 : loss : 0.1402 = 0.0490 + 0.0865 + 0.0047, time: 6.674016]
2023-05-26 10:40:09.173: epoch 82:	0.02568506  	0.18981844  	0.10338026  
2023-05-26 10:40:15.814: [iter 83 : loss : 0.1395 = 0.0483 + 0.0864 + 0.0047, time: 6.640042]
2023-05-26 10:40:15.962: epoch 83:	0.02574857  	0.19043793  	0.10361800  
2023-05-26 10:40:15.962: Find a better model.
2023-05-26 10:40:22.809: [iter 84 : loss : 0.1393 = 0.0482 + 0.0863 + 0.0048, time: 6.845023]
2023-05-26 10:40:22.959: epoch 84:	0.02565684  	0.18962421  	0.10356726  
2023-05-26 10:40:29.787: [iter 85 : loss : 0.1384 = 0.0473 + 0.0862 + 0.0048, time: 6.827018]
2023-05-26 10:40:29.936: epoch 85:	0.02574856  	0.19042161  	0.10385852  
2023-05-26 10:40:36.631: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.693025]
2023-05-26 10:40:36.797: epoch 86:	0.02582619  	0.19117424  	0.10410466  
2023-05-26 10:40:36.797: Find a better model.
2023-05-26 10:40:43.584: [iter 87 : loss : 0.1355 = 0.0445 + 0.0860 + 0.0049, time: 6.784620]
2023-05-26 10:40:43.733: epoch 87:	0.02593204  	0.19179186  	0.10438767  
2023-05-26 10:40:43.733: Find a better model.
2023-05-26 10:40:50.402: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.667347]
2023-05-26 10:40:50.550: epoch 88:	0.02597437  	0.19213209  	0.10468812  
2023-05-26 10:40:50.550: Find a better model.
2023-05-26 10:40:57.217: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.666219]
2023-05-26 10:40:57.384: epoch 89:	0.02594615  	0.19176090  	0.10476073  
2023-05-26 10:41:03.996: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.611016]
2023-05-26 10:41:04.145: epoch 90:	0.02597437  	0.19207750  	0.10495221  
2023-05-26 10:41:10.818: [iter 91 : loss : 0.1336 = 0.0429 + 0.0857 + 0.0050, time: 6.671003]
2023-05-26 10:41:10.967: epoch 91:	0.02607316  	0.19290191  	0.10518404  
2023-05-26 10:41:10.968: Find a better model.
2023-05-26 10:41:17.772: [iter 92 : loss : 0.1328 = 0.0421 + 0.0856 + 0.0051, time: 6.802832]
2023-05-26 10:41:17.922: epoch 92:	0.02605905  	0.19315898  	0.10530039  
2023-05-26 10:41:17.922: Find a better model.
2023-05-26 10:41:24.772: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.848995]
2023-05-26 10:41:24.938: epoch 93:	0.02608022  	0.19367203  	0.10544178  
2023-05-26 10:41:24.938: Find a better model.
2023-05-26 10:41:31.779: [iter 94 : loss : 0.1311 = 0.0405 + 0.0855 + 0.0051, time: 6.838944]
2023-05-26 10:41:31.943: epoch 94:	0.02603082  	0.19325453  	0.10540769  
2023-05-26 10:41:38.604: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.658994]
2023-05-26 10:41:38.767: epoch 95:	0.02603082  	0.19302499  	0.10549602  
2023-05-26 10:41:45.400: [iter 96 : loss : 0.1305 = 0.0400 + 0.0853 + 0.0052, time: 6.631411]
2023-05-26 10:41:45.558: epoch 96:	0.02607316  	0.19356740  	0.10575093  
2023-05-26 10:41:52.177: [iter 97 : loss : 0.1289 = 0.0384 + 0.0852 + 0.0052, time: 6.617003]
2023-05-26 10:41:52.327: epoch 97:	0.02608021  	0.19341087  	0.10574394  
2023-05-26 10:41:58.986: [iter 98 : loss : 0.1296 = 0.0392 + 0.0852 + 0.0053, time: 6.658006]
2023-05-26 10:41:59.154: epoch 98:	0.02608021  	0.19353981  	0.10582867  
2023-05-26 10:42:05.773: [iter 99 : loss : 0.1284 = 0.0380 + 0.0851 + 0.0053, time: 6.617017]
2023-05-26 10:42:05.924: epoch 99:	0.02612255  	0.19398789  	0.10604382  
2023-05-26 10:42:05.925: Find a better model.
2023-05-26 10:42:12.571: [iter 100 : loss : 0.1280 = 0.0377 + 0.0850 + 0.0053, time: 6.645026]
2023-05-26 10:42:12.739: epoch 100:	0.02617195  	0.19447160  	0.10620478  
2023-05-26 10:42:12.739: Find a better model.
2023-05-26 10:42:19.364: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.624013]
2023-05-26 10:42:19.519: epoch 101:	0.02621429  	0.19450600  	0.10635199  
2023-05-26 10:42:19.519: Find a better model.
2023-05-26 10:42:25.981: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.461088]
2023-05-26 10:42:26.142: epoch 102:	0.02622135  	0.19457705  	0.10640652  
2023-05-26 10:42:26.143: Find a better model.
2023-05-26 10:42:32.745: [iter 103 : loss : 0.1264 = 0.0361 + 0.0848 + 0.0055, time: 6.600004]
2023-05-26 10:42:32.894: epoch 103:	0.02622135  	0.19471858  	0.10654877  
2023-05-26 10:42:32.894: Find a better model.
2023-05-26 10:42:39.565: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.670031]
2023-05-26 10:42:39.730: epoch 104:	0.02622135  	0.19477144  	0.10674329  
2023-05-26 10:42:39.731: Find a better model.
2023-05-26 10:42:46.370: [iter 105 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 6.637328]
2023-05-26 10:42:46.524: epoch 105:	0.02620018  	0.19459087  	0.10678753  
2023-05-26 10:42:52.957: [iter 106 : loss : 0.1255 = 0.0354 + 0.0846 + 0.0056, time: 6.432035]
2023-05-26 10:42:53.109: epoch 106:	0.02616490  	0.19430524  	0.10657448  
2023-05-26 10:42:59.748: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.637075]
2023-05-26 10:42:59.896: epoch 107:	0.02621429  	0.19475104  	0.10675983  
2023-05-26 10:43:06.368: [iter 108 : loss : 0.1244 = 0.0343 + 0.0846 + 0.0056, time: 6.470456]
2023-05-26 10:43:06.532: epoch 108:	0.02621429  	0.19474640  	0.10672462  
2023-05-26 10:43:13.144: [iter 109 : loss : 0.1230 = 0.0329 + 0.0844 + 0.0057, time: 6.611155]
2023-05-26 10:43:13.292: epoch 109:	0.02627075  	0.19539523  	0.10695287  
2023-05-26 10:43:13.292: Find a better model.
2023-05-26 10:43:19.936: [iter 110 : loss : 0.1225 = 0.0324 + 0.0844 + 0.0057, time: 6.642444]
2023-05-26 10:43:20.084: epoch 110:	0.02633425  	0.19582899  	0.10699755  
2023-05-26 10:43:20.084: Find a better model.
2023-05-26 10:43:26.719: [iter 111 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0057, time: 6.632001]
2023-05-26 10:43:26.871: epoch 111:	0.02634837  	0.19601567  	0.10726173  
2023-05-26 10:43:26.871: Find a better model.
2023-05-26 10:43:33.538: [iter 112 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0058, time: 6.665018]
2023-05-26 10:43:33.702: epoch 112:	0.02635542  	0.19579589  	0.10720215  
2023-05-26 10:43:40.336: [iter 113 : loss : 0.1223 = 0.0322 + 0.0842 + 0.0058, time: 6.631027]
2023-05-26 10:43:40.500: epoch 113:	0.02631308  	0.19550192  	0.10708181  
2023-05-26 10:43:47.115: [iter 114 : loss : 0.1215 = 0.0315 + 0.0842 + 0.0058, time: 6.613525]
2023-05-26 10:43:47.263: epoch 114:	0.02636954  	0.19559164  	0.10720489  
2023-05-26 10:43:53.743: [iter 115 : loss : 0.1210 = 0.0311 + 0.0841 + 0.0059, time: 6.478412]
2023-05-26 10:43:53.890: epoch 115:	0.02634131  	0.19575275  	0.10707185  
2023-05-26 10:44:00.525: [iter 116 : loss : 0.1204 = 0.0304 + 0.0841 + 0.0059, time: 6.633994]
2023-05-26 10:44:00.674: epoch 116:	0.02638365  	0.19609360  	0.10715836  
2023-05-26 10:44:00.674: Find a better model.
2023-05-26 10:44:07.331: [iter 117 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0059, time: 6.655994]
2023-05-26 10:44:07.485: epoch 117:	0.02646833  	0.19668666  	0.10738005  
2023-05-26 10:44:07.485: Find a better model.
2023-05-26 10:44:13.939: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.452004]
2023-05-26 10:44:14.087: epoch 118:	0.02656006  	0.19726489  	0.10766866  
2023-05-26 10:44:14.087: Find a better model.
2023-05-26 10:44:20.725: [iter 119 : loss : 0.1192 = 0.0292 + 0.0839 + 0.0060, time: 6.637029]
2023-05-26 10:44:20.877: epoch 119:	0.02657417  	0.19701733  	0.10766336  
2023-05-26 10:44:27.519: [iter 120 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 6.641035]
2023-05-26 10:44:27.668: epoch 120:	0.02647538  	0.19609758  	0.10741025  
2023-05-26 10:44:34.316: [iter 121 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 6.647027]
2023-05-26 10:44:34.470: epoch 121:	0.02644716  	0.19596864  	0.10743783  
2023-05-26 10:44:41.099: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.627546]
2023-05-26 10:44:41.250: epoch 122:	0.02646127  	0.19622391  	0.10763576  
2023-05-26 10:44:47.740: [iter 123 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 6.489003]
2023-05-26 10:44:47.891: epoch 123:	0.02644011  	0.19605352  	0.10750768  
2023-05-26 10:44:54.531: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.638012]
2023-05-26 10:44:54.678: epoch 124:	0.02647539  	0.19615602  	0.10750274  
2023-05-26 10:45:01.327: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.647068]
2023-05-26 10:45:01.491: epoch 125:	0.02651067  	0.19684237  	0.10769816  
2023-05-26 10:45:08.107: [iter 126 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 6.614999]
2023-05-26 10:45:08.270: epoch 126:	0.02650362  	0.19647475  	0.10775650  
2023-05-26 10:45:14.887: [iter 127 : loss : 0.1162 = 0.0264 + 0.0835 + 0.0062, time: 6.614227]
2023-05-26 10:45:15.038: epoch 127:	0.02644010  	0.19602448  	0.10766996  
2023-05-26 10:45:21.702: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.663005]
2023-05-26 10:45:21.850: epoch 128:	0.02651066  	0.19584490  	0.10756096  
2023-05-26 10:45:28.504: [iter 129 : loss : 0.1163 = 0.0266 + 0.0835 + 0.0063, time: 6.652015]
2023-05-26 10:45:28.653: epoch 129:	0.02651067  	0.19621202  	0.10771608  
2023-05-26 10:45:35.292: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.638017]
2023-05-26 10:45:35.443: epoch 130:	0.02646833  	0.19572231  	0.10769799  
2023-05-26 10:45:42.094: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 6.647004]
2023-05-26 10:45:42.241: epoch 131:	0.02646833  	0.19595322  	0.10769798  
2023-05-26 10:45:48.714: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.471291]
2023-05-26 10:45:48.882: epoch 132:	0.02643304  	0.19573697  	0.10771520  
2023-05-26 10:45:55.511: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.627102]
2023-05-26 10:45:55.681: epoch 133:	0.02636953  	0.19522797  	0.10769410  
2023-05-26 10:46:02.292: [iter 134 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 6.610029]
2023-05-26 10:46:02.446: epoch 134:	0.02636248  	0.19496039  	0.10765255  
2023-05-26 10:46:09.067: [iter 135 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0065, time: 6.618003]
2023-05-26 10:46:09.216: epoch 135:	0.02641893  	0.19543740  	0.10775886  
2023-05-26 10:46:15.681: [iter 136 : loss : 0.1145 = 0.0249 + 0.0832 + 0.0065, time: 6.464004]
2023-05-26 10:46:15.830: epoch 136:	0.02643304  	0.19570555  	0.10780551  
2023-05-26 10:46:22.465: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.633027]
2023-05-26 10:46:22.616: epoch 137:	0.02643304  	0.19582184  	0.10784832  
2023-05-26 10:46:29.308: [iter 138 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.691315]
2023-05-26 10:46:29.475: epoch 138:	0.02646126  	0.19600575  	0.10797906  
2023-05-26 10:46:36.072: [iter 139 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 6.596014]
2023-05-26 10:46:36.222: epoch 139:	0.02645421  	0.19580963  	0.10791041  
2023-05-26 10:46:42.855: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.631017]
2023-05-26 10:46:43.004: epoch 140:	0.02644010  	0.19568200  	0.10788058  
2023-05-26 10:46:49.646: [iter 141 : loss : 0.1136 = 0.0239 + 0.0830 + 0.0066, time: 6.639994]
2023-05-26 10:46:49.795: epoch 141:	0.02642599  	0.19568084  	0.10785300  
2023-05-26 10:46:56.464: [iter 142 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0067, time: 6.667049]
2023-05-26 10:46:56.616: epoch 142:	0.02639776  	0.19584329  	0.10799068  
2023-05-26 10:47:03.265: [iter 143 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 6.647014]
2023-05-26 10:47:03.415: epoch 143:	0.02640481  	0.19588366  	0.10820960  
2023-05-26 10:47:03.415: Early stopping is trigger at epoch: 143
2023-05-26 10:47:03.415: best_result@epoch 118:

2023-05-26 10:47:03.415: 		0.0266      	0.1973      	0.1077      
2023-05-26 10:59:08.931: my pid: 13780
2023-05-26 10:59:08.931: model: model.general_recommender.SGL
2023-05-26 10:59:08.931: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 10:59:08.931: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 10:59:12.681: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 10:59:19.858: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.177056]
2023-05-26 10:59:20.010: epoch 1:	0.00203924  	0.01432136  	0.00729454  
2023-05-26 10:59:20.010: Find a better model.
2023-05-26 10:59:27.410: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.398934]
2023-05-26 10:59:27.606: epoch 2:	0.00478406  	0.03443001  	0.01690566  
2023-05-26 10:59:27.607: Find a better model.
2023-05-26 10:59:34.834: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.225312]
2023-05-26 10:59:35.006: epoch 3:	0.00788873  	0.05646078  	0.02796516  
2023-05-26 10:59:35.006: Find a better model.
2023-05-26 10:59:42.029: [iter 4 : loss : 0.7713 = 0.6914 + 0.0800 + 0.0000, time: 7.021942]
2023-05-26 10:59:42.187: epoch 4:	0.01172033  	0.08282045  	0.03980501  
2023-05-26 10:59:42.187: Find a better model.
2023-05-26 10:59:49.213: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 7.023597]
2023-05-26 10:59:49.365: epoch 5:	0.01521326  	0.10884760  	0.05229084  
2023-05-26 10:59:49.365: Find a better model.
2023-05-26 10:59:56.230: [iter 6 : loss : 0.7660 = 0.6850 + 0.0809 + 0.0000, time: 6.864003]
2023-05-26 10:59:56.391: epoch 6:	0.01762655  	0.12596598  	0.06164180  
2023-05-26 10:59:56.391: Find a better model.
2023-05-26 11:00:03.173: [iter 7 : loss : 0.7561 = 0.6739 + 0.0822 + 0.0000, time: 6.781130]
2023-05-26 11:00:03.341: epoch 7:	0.01864268  	0.13527347  	0.06688826  
2023-05-26 11:00:03.341: Find a better model.
2023-05-26 11:00:09.992: [iter 8 : loss : 0.7333 = 0.6483 + 0.0849 + 0.0001, time: 6.650356]
2023-05-26 11:00:10.143: epoch 8:	0.01890378  	0.13831645  	0.06872977  
2023-05-26 11:00:10.143: Find a better model.
2023-05-26 11:00:16.601: [iter 9 : loss : 0.6876 = 0.5979 + 0.0895 + 0.0002, time: 6.457153]
2023-05-26 11:00:16.750: epoch 9:	0.01873442  	0.13818790  	0.06860495  
2023-05-26 11:00:23.197: [iter 10 : loss : 0.6197 = 0.5246 + 0.0948 + 0.0003, time: 6.444022]
2023-05-26 11:00:23.344: epoch 10:	0.01829691  	0.13509032  	0.06706029  
2023-05-26 11:00:29.815: [iter 11 : loss : 0.5468 = 0.4473 + 0.0990 + 0.0005, time: 6.470167]
2023-05-26 11:00:29.963: epoch 11:	0.01835337  	0.13575500  	0.06715121  
2023-05-26 11:00:36.394: [iter 12 : loss : 0.4859 = 0.3837 + 0.1016 + 0.0006, time: 6.428016]
2023-05-26 11:00:36.542: epoch 12:	0.01828986  	0.13479917  	0.06730105  
2023-05-26 11:00:43.008: [iter 13 : loss : 0.4417 = 0.3380 + 0.1029 + 0.0008, time: 6.463454]
2023-05-26 11:00:43.160: epoch 13:	0.01848745  	0.13685237  	0.06832035  
2023-05-26 11:00:49.580: [iter 14 : loss : 0.4077 = 0.3034 + 0.1034 + 0.0009, time: 6.418025]
2023-05-26 11:00:49.728: epoch 14:	0.01874854  	0.13879488  	0.06923629  
2023-05-26 11:00:49.728: Find a better model.
2023-05-26 11:00:56.167: [iter 15 : loss : 0.3837 = 0.2792 + 0.1035 + 0.0010, time: 6.438076]
2023-05-26 11:00:56.314: epoch 15:	0.01882615  	0.13954487  	0.06991188  
2023-05-26 11:00:56.314: Find a better model.
2023-05-26 11:01:02.602: [iter 16 : loss : 0.3631 = 0.2585 + 0.1035 + 0.0011, time: 6.286003]
2023-05-26 11:01:02.750: epoch 16:	0.01905196  	0.14125791  	0.07095956  
2023-05-26 11:01:02.750: Find a better model.
2023-05-26 11:01:09.193: [iter 17 : loss : 0.3477 = 0.2434 + 0.1032 + 0.0012, time: 6.442014]
2023-05-26 11:01:09.341: epoch 17:	0.01922837  	0.14225909  	0.07166037  
2023-05-26 11:01:09.341: Find a better model.
2023-05-26 11:01:15.606: [iter 18 : loss : 0.3331 = 0.2289 + 0.1029 + 0.0013, time: 6.263363]
2023-05-26 11:01:15.772: epoch 18:	0.01936245  	0.14336030  	0.07235111  
2023-05-26 11:01:15.772: Find a better model.
2023-05-26 11:01:22.167: [iter 19 : loss : 0.3195 = 0.2156 + 0.1025 + 0.0014, time: 6.393994]
2023-05-26 11:01:22.320: epoch 19:	0.01962354  	0.14525086  	0.07337818  
2023-05-26 11:01:22.320: Find a better model.
2023-05-26 11:01:28.589: [iter 20 : loss : 0.3101 = 0.2065 + 0.1021 + 0.0015, time: 6.268000]
2023-05-26 11:01:28.737: epoch 20:	0.01988464  	0.14728081  	0.07441803  
2023-05-26 11:01:28.738: Find a better model.
2023-05-26 11:01:34.999: [iter 21 : loss : 0.3008 = 0.1975 + 0.1017 + 0.0016, time: 6.260005]
2023-05-26 11:01:35.164: epoch 21:	0.02006811  	0.14867450  	0.07526683  
2023-05-26 11:01:35.164: Find a better model.
2023-05-26 11:01:41.403: [iter 22 : loss : 0.2926 = 0.1897 + 0.1012 + 0.0017, time: 6.238016]
2023-05-26 11:01:41.553: epoch 22:	0.02030803  	0.15070923  	0.07621783  
2023-05-26 11:01:41.553: Find a better model.
2023-05-26 11:01:47.969: [iter 23 : loss : 0.2845 = 0.1819 + 0.1008 + 0.0017, time: 6.413004]
2023-05-26 11:01:48.135: epoch 23:	0.02044915  	0.15141676  	0.07680257  
2023-05-26 11:01:48.135: Find a better model.
2023-05-26 11:01:54.559: [iter 24 : loss : 0.2781 = 0.1759 + 0.1004 + 0.0018, time: 6.423019]
2023-05-26 11:01:54.709: epoch 24:	0.02060440  	0.15200818  	0.07732188  
2023-05-26 11:01:54.710: Find a better model.
2023-05-26 11:02:01.152: [iter 25 : loss : 0.2715 = 0.1696 + 0.1000 + 0.0019, time: 6.441014]
2023-05-26 11:02:01.302: epoch 25:	0.02083021  	0.15347055  	0.07818237  
2023-05-26 11:02:01.302: Find a better model.
2023-05-26 11:02:07.785: [iter 26 : loss : 0.2678 = 0.1663 + 0.0995 + 0.0020, time: 6.480014]
2023-05-26 11:02:07.934: epoch 26:	0.02100662  	0.15437225  	0.07877313  
2023-05-26 11:02:07.934: Find a better model.
2023-05-26 11:02:14.365: [iter 27 : loss : 0.2602 = 0.1590 + 0.0991 + 0.0020, time: 6.430002]
2023-05-26 11:02:14.513: epoch 27:	0.02123243  	0.15572694  	0.07970133  
2023-05-26 11:02:14.513: Find a better model.
2023-05-26 11:02:20.988: [iter 28 : loss : 0.2553 = 0.1546 + 0.0987 + 0.0021, time: 6.473010]
2023-05-26 11:02:21.148: epoch 28:	0.02148647  	0.15756127  	0.08083389  
2023-05-26 11:02:21.148: Find a better model.
2023-05-26 11:02:27.564: [iter 29 : loss : 0.2510 = 0.1506 + 0.0983 + 0.0021, time: 6.412992]
2023-05-26 11:02:27.711: epoch 29:	0.02165583  	0.15919425  	0.08170892  
2023-05-26 11:02:27.711: Find a better model.
2023-05-26 11:02:34.163: [iter 30 : loss : 0.2442 = 0.1441 + 0.0979 + 0.0022, time: 6.450522]
2023-05-26 11:02:34.311: epoch 30:	0.02184635  	0.16071603  	0.08260520  
2023-05-26 11:02:34.311: Find a better model.
2023-05-26 11:02:40.738: [iter 31 : loss : 0.2410 = 0.1412 + 0.0975 + 0.0023, time: 6.425003]
2023-05-26 11:02:40.886: epoch 31:	0.02209333  	0.16248375  	0.08326704  
2023-05-26 11:02:40.886: Find a better model.
2023-05-26 11:02:47.353: [iter 32 : loss : 0.2353 = 0.1358 + 0.0972 + 0.0023, time: 6.466016]
2023-05-26 11:02:47.503: epoch 32:	0.02215683  	0.16332962  	0.08395989  
2023-05-26 11:02:47.503: Find a better model.
2023-05-26 11:02:53.963: [iter 33 : loss : 0.2328 = 0.1336 + 0.0968 + 0.0024, time: 6.459014]
2023-05-26 11:02:54.134: epoch 33:	0.02236852  	0.16472344  	0.08467601  
2023-05-26 11:02:54.134: Find a better model.
2023-05-26 11:03:00.563: [iter 34 : loss : 0.2284 = 0.1295 + 0.0965 + 0.0024, time: 6.427014]
2023-05-26 11:03:00.711: epoch 34:	0.02248142  	0.16563728  	0.08530647  
2023-05-26 11:03:00.712: Find a better model.
2023-05-26 11:03:07.163: [iter 35 : loss : 0.2251 = 0.1265 + 0.0962 + 0.0025, time: 6.450006]
2023-05-26 11:03:07.314: epoch 35:	0.02263667  	0.16659069  	0.08599351  
2023-05-26 11:03:07.314: Find a better model.
2023-05-26 11:03:13.750: [iter 36 : loss : 0.2217 = 0.1233 + 0.0959 + 0.0026, time: 6.434004]
2023-05-26 11:03:13.899: epoch 36:	0.02267901  	0.16679229  	0.08641277  
2023-05-26 11:03:13.899: Find a better model.
2023-05-26 11:03:20.361: [iter 37 : loss : 0.2178 = 0.1197 + 0.0955 + 0.0026, time: 6.460995]
2023-05-26 11:03:20.510: epoch 37:	0.02274957  	0.16762532  	0.08684597  
2023-05-26 11:03:20.511: Find a better model.
2023-05-26 11:03:27.140: [iter 38 : loss : 0.2165 = 0.1185 + 0.0953 + 0.0027, time: 6.628019]
2023-05-26 11:03:27.288: epoch 38:	0.02300361  	0.16974261  	0.08761356  
2023-05-26 11:03:27.289: Find a better model.
2023-05-26 11:03:33.894: [iter 39 : loss : 0.2119 = 0.1142 + 0.0949 + 0.0027, time: 6.603314]
2023-05-26 11:03:34.058: epoch 39:	0.02306712  	0.17032199  	0.08814044  
2023-05-26 11:03:34.059: Find a better model.
2023-05-26 11:03:40.547: [iter 40 : loss : 0.2085 = 0.1111 + 0.0946 + 0.0028, time: 6.486995]
2023-05-26 11:03:40.696: epoch 40:	0.02316591  	0.17131597  	0.08862084  
2023-05-26 11:03:40.696: Find a better model.
2023-05-26 11:03:47.334: [iter 41 : loss : 0.2070 = 0.1098 + 0.0944 + 0.0028, time: 6.636015]
2023-05-26 11:03:47.500: epoch 41:	0.02318708  	0.17120029  	0.08892763  
2023-05-26 11:03:54.128: [iter 42 : loss : 0.2047 = 0.1078 + 0.0941 + 0.0029, time: 6.627059]
2023-05-26 11:03:54.278: epoch 42:	0.02320119  	0.17143442  	0.08931787  
2023-05-26 11:03:54.278: Find a better model.
2023-05-26 11:04:00.921: [iter 43 : loss : 0.2010 = 0.1042 + 0.0938 + 0.0029, time: 6.642067]
2023-05-26 11:04:01.069: epoch 43:	0.02328587  	0.17195295  	0.08973392  
2023-05-26 11:04:01.069: Find a better model.
2023-05-26 11:04:07.525: [iter 44 : loss : 0.1973 = 0.1008 + 0.0936 + 0.0030, time: 6.454005]
2023-05-26 11:04:07.676: epoch 44:	0.02339171  	0.17289244  	0.09023273  
2023-05-26 11:04:07.676: Find a better model.
2023-05-26 11:04:14.141: [iter 45 : loss : 0.1952 = 0.0988 + 0.0933 + 0.0030, time: 6.463003]
2023-05-26 11:04:14.291: epoch 45:	0.02352579  	0.17378782  	0.09092207  
2023-05-26 11:04:14.291: Find a better model.
2023-05-26 11:04:20.923: [iter 46 : loss : 0.1928 = 0.0967 + 0.0930 + 0.0031, time: 6.631074]
2023-05-26 11:04:21.071: epoch 46:	0.02358930  	0.17413798  	0.09128740  
2023-05-26 11:04:21.071: Find a better model.
2023-05-26 11:04:27.498: [iter 47 : loss : 0.1922 = 0.0963 + 0.0928 + 0.0031, time: 6.425014]
2023-05-26 11:04:27.646: epoch 47:	0.02367398  	0.17438143  	0.09157982  
2023-05-26 11:04:27.647: Find a better model.
2023-05-26 11:04:34.123: [iter 48 : loss : 0.1883 = 0.0925 + 0.0926 + 0.0032, time: 6.475014]
2023-05-26 11:04:34.273: epoch 48:	0.02374454  	0.17486846  	0.09202965  
2023-05-26 11:04:34.274: Find a better model.
2023-05-26 11:04:40.891: [iter 49 : loss : 0.1852 = 0.0896 + 0.0924 + 0.0032, time: 6.616024]
2023-05-26 11:04:41.056: epoch 49:	0.02388567  	0.17609003  	0.09272396  
2023-05-26 11:04:41.057: Find a better model.
2023-05-26 11:04:47.540: [iter 50 : loss : 0.1846 = 0.0891 + 0.0922 + 0.0033, time: 6.482004]
2023-05-26 11:04:47.687: epoch 50:	0.02396329  	0.17698787  	0.09332760  
2023-05-26 11:04:47.687: Find a better model.
2023-05-26 11:04:54.130: [iter 51 : loss : 0.1813 = 0.0859 + 0.0920 + 0.0033, time: 6.441849]
2023-05-26 11:04:54.293: epoch 51:	0.02408325  	0.17744924  	0.09368711  
2023-05-26 11:04:54.293: Find a better model.
2023-05-26 11:05:00.913: [iter 52 : loss : 0.1811 = 0.0859 + 0.0918 + 0.0034, time: 6.618016]
2023-05-26 11:05:01.064: epoch 52:	0.02416086  	0.17771770  	0.09417638  
2023-05-26 11:05:01.064: Find a better model.
2023-05-26 11:05:07.510: [iter 53 : loss : 0.1793 = 0.0843 + 0.0916 + 0.0034, time: 6.444026]
2023-05-26 11:05:07.660: epoch 53:	0.02433022  	0.17879848  	0.09487104  
2023-05-26 11:05:07.660: Find a better model.
2023-05-26 11:05:14.111: [iter 54 : loss : 0.1771 = 0.0823 + 0.0914 + 0.0035, time: 6.450509]
2023-05-26 11:05:14.261: epoch 54:	0.02440079  	0.17928819  	0.09526451  
2023-05-26 11:05:14.261: Find a better model.
2023-05-26 11:05:20.690: [iter 55 : loss : 0.1753 = 0.0806 + 0.0912 + 0.0035, time: 6.427012]
2023-05-26 11:05:20.836: epoch 55:	0.02453486  	0.18025234  	0.09566356  
2023-05-26 11:05:20.836: Find a better model.
2023-05-26 11:05:27.299: [iter 56 : loss : 0.1734 = 0.0788 + 0.0910 + 0.0035, time: 6.461036]
2023-05-26 11:05:27.452: epoch 56:	0.02460542  	0.18085532  	0.09608176  
2023-05-26 11:05:27.452: Find a better model.
2023-05-26 11:05:34.109: [iter 57 : loss : 0.1717 = 0.0772 + 0.0909 + 0.0036, time: 6.656034]
2023-05-26 11:05:34.264: epoch 57:	0.02480300  	0.18248290  	0.09678154  
2023-05-26 11:05:34.264: Find a better model.
2023-05-26 11:05:40.721: [iter 58 : loss : 0.1697 = 0.0754 + 0.0907 + 0.0036, time: 6.456004]
2023-05-26 11:05:40.887: epoch 58:	0.02481006  	0.18246661  	0.09700285  
2023-05-26 11:05:47.488: [iter 59 : loss : 0.1685 = 0.0744 + 0.0905 + 0.0037, time: 6.600018]
2023-05-26 11:05:47.639: epoch 59:	0.02490884  	0.18311858  	0.09757935  
2023-05-26 11:05:47.639: Find a better model.
2023-05-26 11:05:54.291: [iter 60 : loss : 0.1670 = 0.0729 + 0.0904 + 0.0037, time: 6.651005]
2023-05-26 11:05:54.441: epoch 60:	0.02495824  	0.18366934  	0.09796051  
2023-05-26 11:05:54.441: Find a better model.
2023-05-26 11:06:00.895: [iter 61 : loss : 0.1658 = 0.0719 + 0.0902 + 0.0038, time: 6.453515]
2023-05-26 11:06:01.045: epoch 61:	0.02502174  	0.18423937  	0.09836213  
2023-05-26 11:06:01.045: Find a better model.
2023-05-26 11:06:07.485: [iter 62 : loss : 0.1642 = 0.0704 + 0.0900 + 0.0038, time: 6.439003]
2023-05-26 11:06:07.633: epoch 62:	0.02505702  	0.18448728  	0.09861389  
2023-05-26 11:06:07.633: Find a better model.
2023-05-26 11:06:14.263: [iter 63 : loss : 0.1628 = 0.0691 + 0.0899 + 0.0039, time: 6.628994]
2023-05-26 11:06:14.426: epoch 63:	0.02512053  	0.18477893  	0.09885200  
2023-05-26 11:06:14.426: Find a better model.
2023-05-26 11:06:21.079: [iter 64 : loss : 0.1618 = 0.0682 + 0.0897 + 0.0039, time: 6.650035]
2023-05-26 11:06:21.230: epoch 64:	0.02519110  	0.18531586  	0.09913474  
2023-05-26 11:06:21.230: Find a better model.
2023-05-26 11:06:27.869: [iter 65 : loss : 0.1604 = 0.0670 + 0.0895 + 0.0039, time: 6.637994]
2023-05-26 11:06:28.018: epoch 65:	0.02528989  	0.18582559  	0.09949189  
2023-05-26 11:06:28.018: Find a better model.
2023-05-26 11:06:34.484: [iter 66 : loss : 0.1590 = 0.0656 + 0.0894 + 0.0040, time: 6.465006]
2023-05-26 11:06:34.636: epoch 66:	0.02527577  	0.18600659  	0.09982549  
2023-05-26 11:06:34.636: Find a better model.
2023-05-26 11:06:41.253: [iter 67 : loss : 0.1575 = 0.0642 + 0.0893 + 0.0040, time: 6.616000]
2023-05-26 11:06:41.404: epoch 67:	0.02534634  	0.18650654  	0.10019246  
2023-05-26 11:06:41.404: Find a better model.
2023-05-26 11:06:48.058: [iter 68 : loss : 0.1573 = 0.0641 + 0.0891 + 0.0041, time: 6.651928]
2023-05-26 11:06:48.229: epoch 68:	0.02532517  	0.18634009  	0.10026655  
2023-05-26 11:06:54.680: [iter 69 : loss : 0.1553 = 0.0622 + 0.0890 + 0.0041, time: 6.450001]
2023-05-26 11:06:54.829: epoch 69:	0.02528283  	0.18604864  	0.10030070  
2023-05-26 11:07:01.275: [iter 70 : loss : 0.1535 = 0.0605 + 0.0889 + 0.0042, time: 6.445043]
2023-05-26 11:07:01.442: epoch 70:	0.02533929  	0.18661562  	0.10063095  
2023-05-26 11:07:01.442: Find a better model.
2023-05-26 11:07:08.037: [iter 71 : loss : 0.1523 = 0.0593 + 0.0887 + 0.0042, time: 6.594033]
2023-05-26 11:07:08.187: epoch 71:	0.02540985  	0.18716040  	0.10084125  
2023-05-26 11:07:08.187: Find a better model.
2023-05-26 11:07:14.669: [iter 72 : loss : 0.1519 = 0.0590 + 0.0887 + 0.0042, time: 6.481169]
2023-05-26 11:07:14.818: epoch 72:	0.02548041  	0.18792009  	0.10125958  
2023-05-26 11:07:14.818: Find a better model.
2023-05-26 11:07:21.270: [iter 73 : loss : 0.1506 = 0.0578 + 0.0885 + 0.0043, time: 6.451017]
2023-05-26 11:07:21.438: epoch 73:	0.02556509  	0.18796811  	0.10149755  
2023-05-26 11:07:21.438: Find a better model.
2023-05-26 11:07:27.867: [iter 74 : loss : 0.1491 = 0.0563 + 0.0884 + 0.0043, time: 6.428004]
2023-05-26 11:07:28.018: epoch 74:	0.02565683  	0.18864259  	0.10181564  
2023-05-26 11:07:28.018: Find a better model.
2023-05-26 11:07:34.436: [iter 75 : loss : 0.1486 = 0.0560 + 0.0883 + 0.0044, time: 6.416063]
2023-05-26 11:07:34.586: epoch 75:	0.02564271  	0.18824854  	0.10185554  
2023-05-26 11:07:41.063: [iter 76 : loss : 0.1476 = 0.0550 + 0.0882 + 0.0044, time: 6.475036]
2023-05-26 11:07:41.215: epoch 76:	0.02565683  	0.18863107  	0.10216448  
2023-05-26 11:07:47.646: [iter 77 : loss : 0.1466 = 0.0541 + 0.0880 + 0.0044, time: 6.430032]
2023-05-26 11:07:47.796: epoch 77:	0.02574856  	0.18938510  	0.10247061  
2023-05-26 11:07:47.796: Find a better model.
2023-05-26 11:07:54.251: [iter 78 : loss : 0.1460 = 0.0536 + 0.0880 + 0.0045, time: 6.453994]
2023-05-26 11:07:54.400: epoch 78:	0.02579090  	0.18967761  	0.10286859  
2023-05-26 11:07:54.400: Find a better model.
2023-05-26 11:08:00.837: [iter 79 : loss : 0.1443 = 0.0520 + 0.0878 + 0.0045, time: 6.435422]
2023-05-26 11:08:00.987: epoch 79:	0.02584029  	0.18997407  	0.10317799  
2023-05-26 11:08:00.987: Find a better model.
2023-05-26 11:08:07.448: [iter 80 : loss : 0.1435 = 0.0512 + 0.0878 + 0.0046, time: 6.460051]
2023-05-26 11:08:07.610: epoch 80:	0.02591086  	0.19076154  	0.10348532  
2023-05-26 11:08:07.611: Find a better model.
2023-05-26 11:08:14.243: [iter 81 : loss : 0.1437 = 0.0515 + 0.0876 + 0.0046, time: 6.630019]
2023-05-26 11:08:14.393: epoch 81:	0.02585441  	0.19062573  	0.10365047  
2023-05-26 11:08:21.035: [iter 82 : loss : 0.1421 = 0.0499 + 0.0875 + 0.0046, time: 6.640181]
2023-05-26 11:08:21.186: epoch 82:	0.02591086  	0.19114816  	0.10384017  
2023-05-26 11:08:21.186: Find a better model.
2023-05-26 11:08:27.836: [iter 83 : loss : 0.1413 = 0.0492 + 0.0874 + 0.0047, time: 6.647994]
2023-05-26 11:08:27.984: epoch 83:	0.02589674  	0.19103372  	0.10391201  
2023-05-26 11:08:34.637: [iter 84 : loss : 0.1413 = 0.0492 + 0.0873 + 0.0047, time: 6.652018]
2023-05-26 11:08:34.785: epoch 84:	0.02598848  	0.19169256  	0.10423878  
2023-05-26 11:08:34.785: Find a better model.
2023-05-26 11:08:41.255: [iter 85 : loss : 0.1402 = 0.0482 + 0.0872 + 0.0047, time: 6.467052]
2023-05-26 11:08:41.406: epoch 85:	0.02609432  	0.19225350  	0.10456846  
2023-05-26 11:08:41.406: Find a better model.
2023-05-26 11:08:48.049: [iter 86 : loss : 0.1397 = 0.0478 + 0.0871 + 0.0048, time: 6.641108]
2023-05-26 11:08:48.210: epoch 86:	0.02607315  	0.19227386  	0.10462286  
2023-05-26 11:08:48.210: Find a better model.
2023-05-26 11:08:54.820: [iter 87 : loss : 0.1372 = 0.0453 + 0.0870 + 0.0048, time: 6.606507]
2023-05-26 11:08:54.968: epoch 87:	0.02611549  	0.19292353  	0.10489331  
2023-05-26 11:08:54.968: Find a better model.
2023-05-26 11:09:01.439: [iter 88 : loss : 0.1365 = 0.0446 + 0.0870 + 0.0049, time: 6.468994]
2023-05-26 11:09:01.587: epoch 88:	0.02612961  	0.19312756  	0.10516146  
2023-05-26 11:09:01.587: Find a better model.
2023-05-26 11:09:08.234: [iter 89 : loss : 0.1361 = 0.0444 + 0.0869 + 0.0049, time: 6.645993]
2023-05-26 11:09:08.401: epoch 89:	0.02619311  	0.19353628  	0.10521550  
2023-05-26 11:09:08.401: Find a better model.
2023-05-26 11:09:15.020: [iter 90 : loss : 0.1368 = 0.0451 + 0.0868 + 0.0049, time: 6.617160]
2023-05-26 11:09:15.184: epoch 90:	0.02625662  	0.19402686  	0.10561228  
2023-05-26 11:09:15.184: Find a better model.
2023-05-26 11:09:21.635: [iter 91 : loss : 0.1357 = 0.0440 + 0.0867 + 0.0050, time: 6.448551]
2023-05-26 11:09:21.783: epoch 91:	0.02632013  	0.19428900  	0.10573297  
2023-05-26 11:09:21.783: Find a better model.
2023-05-26 11:09:28.223: [iter 92 : loss : 0.1347 = 0.0431 + 0.0866 + 0.0050, time: 6.438025]
2023-05-26 11:09:28.372: epoch 92:	0.02641892  	0.19520584  	0.10606359  
2023-05-26 11:09:28.372: Find a better model.
2023-05-26 11:09:34.824: [iter 93 : loss : 0.1347 = 0.0431 + 0.0865 + 0.0051, time: 6.451005]
2023-05-26 11:09:34.976: epoch 93:	0.02639069  	0.19492640  	0.10602504  
2023-05-26 11:09:41.420: [iter 94 : loss : 0.1329 = 0.0413 + 0.0865 + 0.0051, time: 6.442040]
2023-05-26 11:09:41.567: epoch 94:	0.02630601  	0.19410132  	0.10605615  
2023-05-26 11:09:48.191: [iter 95 : loss : 0.1322 = 0.0407 + 0.0864 + 0.0051, time: 6.623322]
2023-05-26 11:09:48.338: epoch 95:	0.02636246  	0.19446993  	0.10635142  
2023-05-26 11:09:54.981: [iter 96 : loss : 0.1322 = 0.0408 + 0.0863 + 0.0052, time: 6.641014]
2023-05-26 11:09:55.151: epoch 96:	0.02639069  	0.19485590  	0.10668398  
2023-05-26 11:10:01.612: [iter 97 : loss : 0.1305 = 0.0391 + 0.0862 + 0.0052, time: 6.459011]
2023-05-26 11:10:01.764: epoch 97:	0.02641186  	0.19507034  	0.10657661  
2023-05-26 11:10:08.390: [iter 98 : loss : 0.1313 = 0.0400 + 0.0861 + 0.0052, time: 6.625004]
2023-05-26 11:10:08.558: epoch 98:	0.02640480  	0.19497930  	0.10674630  
2023-05-26 11:10:15.021: [iter 99 : loss : 0.1302 = 0.0388 + 0.0861 + 0.0053, time: 6.462054]
2023-05-26 11:10:15.185: epoch 99:	0.02638363  	0.19467746  	0.10670303  
2023-05-26 11:10:21.809: [iter 100 : loss : 0.1298 = 0.0384 + 0.0860 + 0.0053, time: 6.622265]
2023-05-26 11:10:21.957: epoch 100:	0.02639068  	0.19473122  	0.10676985  
2023-05-26 11:10:28.411: [iter 101 : loss : 0.1294 = 0.0381 + 0.0859 + 0.0053, time: 6.451495]
2023-05-26 11:10:28.560: epoch 101:	0.02644714  	0.19504298  	0.10696062  
2023-05-26 11:10:35.200: [iter 102 : loss : 0.1282 = 0.0370 + 0.0859 + 0.0054, time: 6.637092]
2023-05-26 11:10:35.363: epoch 102:	0.02643303  	0.19487679  	0.10693812  
2023-05-26 11:10:41.962: [iter 103 : loss : 0.1279 = 0.0367 + 0.0858 + 0.0054, time: 6.596994]
2023-05-26 11:10:42.130: epoch 103:	0.02643303  	0.19503136  	0.10694531  
2023-05-26 11:10:48.807: [iter 104 : loss : 0.1284 = 0.0372 + 0.0858 + 0.0054, time: 6.675019]
2023-05-26 11:10:48.959: epoch 104:	0.02647536  	0.19531514  	0.10705702  
2023-05-26 11:10:48.959: Find a better model.
2023-05-26 11:10:55.578: [iter 105 : loss : 0.1278 = 0.0366 + 0.0857 + 0.0055, time: 6.618516]
2023-05-26 11:10:55.728: epoch 105:	0.02649653  	0.19568156  	0.10706681  
2023-05-26 11:10:55.728: Find a better model.
2023-05-26 11:11:02.198: [iter 106 : loss : 0.1272 = 0.0361 + 0.0856 + 0.0055, time: 6.469007]
2023-05-26 11:11:02.363: epoch 106:	0.02653887  	0.19579087  	0.10722095  
2023-05-26 11:11:02.363: Find a better model.
2023-05-26 11:11:08.981: [iter 107 : loss : 0.1264 = 0.0353 + 0.0856 + 0.0055, time: 6.617027]
2023-05-26 11:11:09.134: epoch 107:	0.02653888  	0.19589041  	0.10733683  
2023-05-26 11:11:09.134: Find a better model.
2023-05-26 11:11:15.589: [iter 108 : loss : 0.1261 = 0.0350 + 0.0855 + 0.0056, time: 6.454005]
2023-05-26 11:11:15.738: epoch 108:	0.02658827  	0.19633184  	0.10745029  
2023-05-26 11:11:15.738: Find a better model.
2023-05-26 11:11:22.188: [iter 109 : loss : 0.1248 = 0.0337 + 0.0855 + 0.0056, time: 6.449015]
2023-05-26 11:11:22.339: epoch 109:	0.02659532  	0.19640994  	0.10751204  
2023-05-26 11:11:22.339: Find a better model.
2023-05-26 11:11:28.966: [iter 110 : loss : 0.1242 = 0.0331 + 0.0854 + 0.0056, time: 6.625994]
2023-05-26 11:11:29.120: epoch 110:	0.02663767  	0.19647661  	0.10758826  
2023-05-26 11:11:29.120: Find a better model.
2023-05-26 11:11:35.743: [iter 111 : loss : 0.1243 = 0.0332 + 0.0854 + 0.0057, time: 6.621013]
2023-05-26 11:11:35.894: epoch 111:	0.02654593  	0.19582948  	0.10747534  
2023-05-26 11:11:42.375: [iter 112 : loss : 0.1240 = 0.0329 + 0.0853 + 0.0057, time: 6.479994]
2023-05-26 11:11:42.527: epoch 112:	0.02660944  	0.19617836  	0.10760885  
2023-05-26 11:11:48.972: [iter 113 : loss : 0.1237 = 0.0327 + 0.0853 + 0.0057, time: 6.444003]
2023-05-26 11:11:49.124: epoch 113:	0.02666589  	0.19658001  	0.10774224  
2023-05-26 11:11:49.125: Find a better model.
2023-05-26 11:11:55.573: [iter 114 : loss : 0.1229 = 0.0320 + 0.0852 + 0.0058, time: 6.447022]
2023-05-26 11:11:55.723: epoch 114:	0.02663061  	0.19631895  	0.10770645  
2023-05-26 11:12:02.169: [iter 115 : loss : 0.1226 = 0.0316 + 0.0851 + 0.0058, time: 6.444004]
2023-05-26 11:12:02.319: epoch 115:	0.02656710  	0.19607265  	0.10768110  
2023-05-26 11:12:08.939: [iter 116 : loss : 0.1217 = 0.0308 + 0.0851 + 0.0058, time: 6.617002]
2023-05-26 11:12:09.089: epoch 116:	0.02664473  	0.19656283  	0.10783117  
2023-05-26 11:12:15.548: [iter 117 : loss : 0.1216 = 0.0308 + 0.0850 + 0.0059, time: 6.457246]
2023-05-26 11:12:15.697: epoch 117:	0.02660239  	0.19631806  	0.10774370  
2023-05-26 11:12:22.186: [iter 118 : loss : 0.1214 = 0.0306 + 0.0849 + 0.0059, time: 6.487004]
2023-05-26 11:12:22.335: epoch 118:	0.02668707  	0.19686253  	0.10804898  
2023-05-26 11:12:22.335: Find a better model.
2023-05-26 11:12:28.919: [iter 119 : loss : 0.1205 = 0.0297 + 0.0849 + 0.0059, time: 6.582055]
2023-05-26 11:12:29.066: epoch 119:	0.02666589  	0.19665438  	0.10810548  
2023-05-26 11:12:35.552: [iter 120 : loss : 0.1209 = 0.0301 + 0.0849 + 0.0060, time: 6.483994]
2023-05-26 11:12:35.699: epoch 120:	0.02666590  	0.19661677  	0.10813715  
2023-05-26 11:12:42.153: [iter 121 : loss : 0.1208 = 0.0300 + 0.0848 + 0.0060, time: 6.450994]
2023-05-26 11:12:42.302: epoch 121:	0.02665885  	0.19665954  	0.10821266  
2023-05-26 11:12:48.759: [iter 122 : loss : 0.1198 = 0.0290 + 0.0848 + 0.0060, time: 6.455999]
2023-05-26 11:12:48.909: epoch 122:	0.02663768  	0.19640355  	0.10810829  
2023-05-26 11:12:55.353: [iter 123 : loss : 0.1199 = 0.0291 + 0.0847 + 0.0061, time: 6.442994]
2023-05-26 11:12:55.505: epoch 123:	0.02675058  	0.19724031  	0.10834578  
2023-05-26 11:12:55.505: Find a better model.
2023-05-26 11:13:01.942: [iter 124 : loss : 0.1190 = 0.0283 + 0.0847 + 0.0061, time: 6.436442]
2023-05-26 11:13:02.091: epoch 124:	0.02669413  	0.19669563  	0.10834598  
2023-05-26 11:13:08.360: [iter 125 : loss : 0.1184 = 0.0277 + 0.0846 + 0.0061, time: 6.268053]
2023-05-26 11:13:08.516: epoch 125:	0.02668707  	0.19640635  	0.10830749  
2023-05-26 11:13:14.952: [iter 126 : loss : 0.1186 = 0.0279 + 0.0846 + 0.0061, time: 6.434994]
2023-05-26 11:13:15.101: epoch 126:	0.02665179  	0.19610521  	0.10805789  
2023-05-26 11:13:21.514: [iter 127 : loss : 0.1178 = 0.0271 + 0.0846 + 0.0062, time: 6.409993]
2023-05-26 11:13:21.667: epoch 127:	0.02668707  	0.19657798  	0.10809062  
2023-05-26 11:13:28.154: [iter 128 : loss : 0.1185 = 0.0278 + 0.0845 + 0.0062, time: 6.485994]
2023-05-26 11:13:28.303: epoch 128:	0.02665884  	0.19621740  	0.10809784  
2023-05-26 11:13:34.746: [iter 129 : loss : 0.1179 = 0.0272 + 0.0845 + 0.0062, time: 6.441994]
2023-05-26 11:13:34.895: epoch 129:	0.02669413  	0.19632778  	0.10822456  
2023-05-26 11:13:41.325: [iter 130 : loss : 0.1178 = 0.0272 + 0.0844 + 0.0063, time: 6.428994]
2023-05-26 11:13:41.476: epoch 130:	0.02676470  	0.19695881  	0.10845163  
2023-05-26 11:13:47.920: [iter 131 : loss : 0.1170 = 0.0263 + 0.0844 + 0.0063, time: 6.442374]
2023-05-26 11:13:48.073: epoch 131:	0.02669412  	0.19638665  	0.10840152  
2023-05-26 11:13:54.506: [iter 132 : loss : 0.1173 = 0.0266 + 0.0843 + 0.0063, time: 6.430994]
2023-05-26 11:13:54.654: epoch 132:	0.02664473  	0.19572911  	0.10831394  
2023-05-26 11:14:01.128: [iter 133 : loss : 0.1159 = 0.0252 + 0.0843 + 0.0064, time: 6.472994]
2023-05-26 11:14:01.296: epoch 133:	0.02664473  	0.19588786  	0.10858998  
2023-05-26 11:14:07.706: [iter 134 : loss : 0.1167 = 0.0261 + 0.0842 + 0.0064, time: 6.408804]
2023-05-26 11:14:07.853: epoch 134:	0.02667296  	0.19611387  	0.10852922  
2023-05-26 11:14:14.304: [iter 135 : loss : 0.1164 = 0.0258 + 0.0842 + 0.0064, time: 6.448994]
2023-05-26 11:14:14.454: epoch 135:	0.02669412  	0.19588286  	0.10855149  
2023-05-26 11:14:20.926: [iter 136 : loss : 0.1159 = 0.0253 + 0.0842 + 0.0064, time: 6.469994]
2023-05-26 11:14:21.092: epoch 136:	0.02668707  	0.19581039  	0.10852810  
2023-05-26 11:14:27.511: [iter 137 : loss : 0.1155 = 0.0249 + 0.0841 + 0.0065, time: 6.417994]
2023-05-26 11:14:27.663: epoch 137:	0.02668707  	0.19602469  	0.10858094  
2023-05-26 11:14:34.138: [iter 138 : loss : 0.1154 = 0.0248 + 0.0841 + 0.0065, time: 6.473994]
2023-05-26 11:14:34.290: epoch 138:	0.02671530  	0.19613256  	0.10878285  
2023-05-26 11:14:40.736: [iter 139 : loss : 0.1153 = 0.0247 + 0.0841 + 0.0065, time: 6.444423]
2023-05-26 11:14:40.885: epoch 139:	0.02665884  	0.19570893  	0.10860979  
2023-05-26 11:14:47.327: [iter 140 : loss : 0.1145 = 0.0239 + 0.0840 + 0.0066, time: 6.439994]
2023-05-26 11:14:47.477: epoch 140:	0.02670823  	0.19608867  	0.10875889  
2023-05-26 11:14:53.902: [iter 141 : loss : 0.1151 = 0.0245 + 0.0840 + 0.0066, time: 6.423994]
2023-05-26 11:14:54.052: epoch 141:	0.02665883  	0.19578464  	0.10870947  
2023-05-26 11:15:00.495: [iter 142 : loss : 0.1141 = 0.0236 + 0.0839 + 0.0066, time: 6.442001]
2023-05-26 11:15:00.647: epoch 142:	0.02665883  	0.19551910  	0.10863922  
2023-05-26 11:15:07.091: [iter 143 : loss : 0.1142 = 0.0236 + 0.0839 + 0.0066, time: 6.443068]
2023-05-26 11:15:07.247: epoch 143:	0.02664472  	0.19538148  	0.10869134  
2023-05-26 11:15:13.718: [iter 144 : loss : 0.1135 = 0.0230 + 0.0839 + 0.0067, time: 6.470014]
2023-05-26 11:15:13.867: epoch 144:	0.02663766  	0.19516060  	0.10864778  
2023-05-26 11:15:20.296: [iter 145 : loss : 0.1134 = 0.0228 + 0.0838 + 0.0067, time: 6.427994]
2023-05-26 11:15:20.445: epoch 145:	0.02661649  	0.19516549  	0.10863887  
2023-05-26 11:15:26.914: [iter 146 : loss : 0.1139 = 0.0234 + 0.0838 + 0.0067, time: 6.466994]
2023-05-26 11:15:27.064: epoch 146:	0.02661650  	0.19524707  	0.10868637  
2023-05-26 11:15:33.493: [iter 147 : loss : 0.1136 = 0.0231 + 0.0838 + 0.0067, time: 6.428021]
2023-05-26 11:15:33.643: epoch 147:	0.02666589  	0.19549812  	0.10890321  
2023-05-26 11:15:40.088: [iter 148 : loss : 0.1124 = 0.0219 + 0.0837 + 0.0068, time: 6.444158]
2023-05-26 11:15:40.235: epoch 148:	0.02665883  	0.19550851  	0.10900407  
2023-05-26 11:15:40.235: Early stopping is trigger at epoch: 148
2023-05-26 11:15:40.235: best_result@epoch 123:

2023-05-26 11:15:40.235: 		0.0268      	0.1972      	0.1083      
2023-05-26 14:35:47.413: my pid: 15484
2023-05-26 14:35:47.413: model: model.general_recommender.SGL
2023-05-26 14:35:47.413: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 14:35:47.413: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 14:35:51.056: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 14:35:58.837: [iter 1 : loss : 0.7706 = 0.6930 + 0.0776 + 0.0000, time: 7.781070]
2023-05-26 14:35:58.994: epoch 1:	0.00183461  	0.01236751  	0.00641957  
2023-05-26 14:35:58.994: Find a better model.
2023-05-26 14:36:06.851: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 7.856078]
2023-05-26 14:36:07.055: epoch 2:	0.00339401  	0.02335494  	0.01195696  
2023-05-26 14:36:07.055: Find a better model.
2023-05-26 14:36:14.812: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.755285]
2023-05-26 14:36:14.987: epoch 3:	0.00569429  	0.03921259  	0.01960516  
2023-05-26 14:36:14.987: Find a better model.
2023-05-26 14:36:22.584: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.596064]
2023-05-26 14:36:22.751: epoch 4:	0.00808630  	0.05648810  	0.02844983  
2023-05-26 14:36:22.752: Find a better model.
2023-05-26 14:36:30.232: [iter 5 : loss : 0.7685 = 0.6912 + 0.0773 + 0.0000, time: 7.478993]
2023-05-26 14:36:30.389: epoch 5:	0.01091589  	0.07726161  	0.03741086  
2023-05-26 14:36:30.390: Find a better model.
2023-05-26 14:36:37.597: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.205372]
2023-05-26 14:36:37.760: epoch 6:	0.01384432  	0.09877191  	0.04794341  
2023-05-26 14:36:37.760: Find a better model.
2023-05-26 14:36:44.975: [iter 7 : loss : 0.7604 = 0.6822 + 0.0781 + 0.0000, time: 7.214011]
2023-05-26 14:36:45.132: epoch 7:	0.01661748  	0.12048244  	0.05941228  
2023-05-26 14:36:45.132: Find a better model.
2023-05-26 14:36:52.178: [iter 8 : loss : 0.7460 = 0.6664 + 0.0795 + 0.0001, time: 7.044520]
2023-05-26 14:36:52.335: epoch 8:	0.01818401  	0.13326196  	0.06658761  
2023-05-26 14:36:52.335: Find a better model.
2023-05-26 14:36:59.365: [iter 9 : loss : 0.7139 = 0.6311 + 0.0827 + 0.0001, time: 7.029125]
2023-05-26 14:36:59.522: epoch 9:	0.01888966  	0.13894115  	0.06959072  
2023-05-26 14:36:59.522: Find a better model.
2023-05-26 14:37:06.561: [iter 10 : loss : 0.6577 = 0.5699 + 0.0876 + 0.0002, time: 7.038036]
2023-05-26 14:37:06.704: epoch 10:	0.01872735  	0.13819201  	0.06943880  
2023-05-26 14:37:13.574: [iter 11 : loss : 0.5837 = 0.4907 + 0.0926 + 0.0004, time: 6.867218]
2023-05-26 14:37:13.729: epoch 11:	0.01871325  	0.13850106  	0.06945288  
2023-05-26 14:37:20.735: [iter 12 : loss : 0.5123 = 0.4155 + 0.0963 + 0.0005, time: 7.005037]
2023-05-26 14:37:20.891: epoch 12:	0.01860740  	0.13764323  	0.06942309  
2023-05-26 14:37:27.797: [iter 13 : loss : 0.4582 = 0.3590 + 0.0985 + 0.0007, time: 6.903029]
2023-05-26 14:37:27.953: epoch 13:	0.01866386  	0.13818514  	0.06990115  
2023-05-26 14:37:34.962: [iter 14 : loss : 0.4170 = 0.3166 + 0.0996 + 0.0008, time: 7.007056]
2023-05-26 14:37:35.120: epoch 14:	0.01881204  	0.13954856  	0.07087963  
2023-05-26 14:37:35.121: Find a better model.
2023-05-26 14:37:41.994: [iter 15 : loss : 0.3882 = 0.2872 + 0.1001 + 0.0010, time: 6.871037]
2023-05-26 14:37:42.148: epoch 15:	0.01905196  	0.14149752  	0.07188386  
2023-05-26 14:37:42.148: Find a better model.
2023-05-26 14:37:48.945: [iter 16 : loss : 0.3646 = 0.2633 + 0.1002 + 0.0011, time: 6.796099]
2023-05-26 14:37:49.100: epoch 16:	0.01926366  	0.14257549  	0.07258890  
2023-05-26 14:37:49.100: Find a better model.
2023-05-26 14:37:55.939: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 6.837994]
2023-05-26 14:37:56.097: epoch 17:	0.01952475  	0.14435115  	0.07346696  
2023-05-26 14:37:56.097: Find a better model.
2023-05-26 14:38:02.952: [iter 18 : loss : 0.3315 = 0.2302 + 0.1000 + 0.0013, time: 6.853860]
2023-05-26 14:38:03.107: epoch 18:	0.01970823  	0.14547800  	0.07412752  
2023-05-26 14:38:03.107: Find a better model.
2023-05-26 14:38:09.947: [iter 19 : loss : 0.3169 = 0.2158 + 0.0997 + 0.0014, time: 6.838206]
2023-05-26 14:38:10.103: epoch 19:	0.01989876  	0.14681418  	0.07483394  
2023-05-26 14:38:10.104: Find a better model.
2023-05-26 14:38:16.953: [iter 20 : loss : 0.3069 = 0.2061 + 0.0993 + 0.0015, time: 6.848007]
2023-05-26 14:38:17.110: epoch 20:	0.01996226  	0.14709879  	0.07529653  
2023-05-26 14:38:17.110: Find a better model.
2023-05-26 14:38:23.949: [iter 21 : loss : 0.2969 = 0.1964 + 0.0989 + 0.0016, time: 6.838046]
2023-05-26 14:38:24.105: epoch 21:	0.02027981  	0.14938436  	0.07626184  
2023-05-26 14:38:24.105: Find a better model.
2023-05-26 14:38:30.937: [iter 22 : loss : 0.2886 = 0.1884 + 0.0985 + 0.0017, time: 6.831004]
2023-05-26 14:38:31.093: epoch 22:	0.02041388  	0.15025993  	0.07680344  
2023-05-26 14:38:31.094: Find a better model.
2023-05-26 14:38:37.939: [iter 23 : loss : 0.2802 = 0.1803 + 0.0981 + 0.0018, time: 6.844046]
2023-05-26 14:38:38.097: epoch 23:	0.02053383  	0.15106921  	0.07751744  
2023-05-26 14:38:38.097: Find a better model.
2023-05-26 14:38:45.123: [iter 24 : loss : 0.2736 = 0.1740 + 0.0977 + 0.0018, time: 7.025035]
2023-05-26 14:38:45.278: epoch 24:	0.02078787  	0.15308173  	0.07848143  
2023-05-26 14:38:45.278: Find a better model.
2023-05-26 14:38:52.122: [iter 25 : loss : 0.2667 = 0.1675 + 0.0973 + 0.0019, time: 6.842018]
2023-05-26 14:38:52.279: epoch 25:	0.02087961  	0.15337154  	0.07890216  
2023-05-26 14:38:52.279: Find a better model.
2023-05-26 14:38:59.150: [iter 26 : loss : 0.2630 = 0.1641 + 0.0969 + 0.0020, time: 6.870021]
2023-05-26 14:38:59.307: epoch 26:	0.02112659  	0.15508309  	0.07974935  
2023-05-26 14:38:59.307: Find a better model.
2023-05-26 14:39:06.153: [iter 27 : loss : 0.2551 = 0.1566 + 0.0965 + 0.0020, time: 6.845068]
2023-05-26 14:39:06.307: epoch 27:	0.02133829  	0.15645410  	0.08044992  
2023-05-26 14:39:06.307: Find a better model.
2023-05-26 14:39:13.138: [iter 28 : loss : 0.2503 = 0.1521 + 0.0961 + 0.0021, time: 6.830007]
2023-05-26 14:39:13.292: epoch 28:	0.02147236  	0.15735768  	0.08131745  
2023-05-26 14:39:13.292: Find a better model.
2023-05-26 14:39:20.121: [iter 29 : loss : 0.2458 = 0.1480 + 0.0956 + 0.0022, time: 6.828027]
2023-05-26 14:39:20.277: epoch 29:	0.02167699  	0.15908341  	0.08226252  
2023-05-26 14:39:20.277: Find a better model.
2023-05-26 14:39:27.105: [iter 30 : loss : 0.2392 = 0.1417 + 0.0953 + 0.0022, time: 6.827036]
2023-05-26 14:39:27.263: epoch 30:	0.02178284  	0.16044876  	0.08293393  
2023-05-26 14:39:27.264: Find a better model.
2023-05-26 14:39:34.110: [iter 31 : loss : 0.2356 = 0.1384 + 0.0949 + 0.0023, time: 6.845014]
2023-05-26 14:39:34.267: epoch 31:	0.02186751  	0.16057427  	0.08329571  
2023-05-26 14:39:34.267: Find a better model.
2023-05-26 14:39:41.108: [iter 32 : loss : 0.2300 = 0.1331 + 0.0946 + 0.0024, time: 6.840016]
2023-05-26 14:39:41.265: epoch 32:	0.02212860  	0.16257350  	0.08435014  
2023-05-26 14:39:41.265: Find a better model.
2023-05-26 14:39:48.119: [iter 33 : loss : 0.2273 = 0.1307 + 0.0942 + 0.0024, time: 6.853025]
2023-05-26 14:39:48.272: epoch 33:	0.02219917  	0.16291153  	0.08473682  
2023-05-26 14:39:48.272: Find a better model.
2023-05-26 14:39:55.104: [iter 34 : loss : 0.2234 = 0.1270 + 0.0938 + 0.0025, time: 6.830579]
2023-05-26 14:39:55.247: epoch 34:	0.02229089  	0.16361551  	0.08533307  
2023-05-26 14:39:55.247: Find a better model.
2023-05-26 14:40:02.114: [iter 35 : loss : 0.2200 = 0.1239 + 0.0936 + 0.0025, time: 6.865247]
2023-05-26 14:40:02.271: epoch 35:	0.02251670  	0.16539687  	0.08611237  
2023-05-26 14:40:02.271: Find a better model.
2023-05-26 14:40:09.095: [iter 36 : loss : 0.2165 = 0.1206 + 0.0932 + 0.0026, time: 6.822994]
2023-05-26 14:40:09.237: epoch 36:	0.02262255  	0.16630647  	0.08676223  
2023-05-26 14:40:09.238: Find a better model.
2023-05-26 14:40:16.096: [iter 37 : loss : 0.2125 = 0.1170 + 0.0929 + 0.0027, time: 6.856985]
2023-05-26 14:40:16.239: epoch 37:	0.02282014  	0.16797574  	0.08749385  
2023-05-26 14:40:16.239: Find a better model.
2023-05-26 14:40:23.113: [iter 38 : loss : 0.2110 = 0.1157 + 0.0926 + 0.0027, time: 6.871994]
2023-05-26 14:40:23.267: epoch 38:	0.02292599  	0.16889168  	0.08832098  
2023-05-26 14:40:23.267: Find a better model.
2023-05-26 14:40:30.298: [iter 39 : loss : 0.2066 = 0.1115 + 0.0923 + 0.0028, time: 7.029030]
2023-05-26 14:40:30.454: epoch 39:	0.02314474  	0.17035054  	0.08942634  
2023-05-26 14:40:30.454: Find a better model.
2023-05-26 14:40:37.314: [iter 40 : loss : 0.2034 = 0.1085 + 0.0920 + 0.0028, time: 6.857464]
2023-05-26 14:40:37.457: epoch 40:	0.02321531  	0.17081171  	0.08966282  
2023-05-26 14:40:37.458: Find a better model.
2023-05-26 14:40:44.321: [iter 41 : loss : 0.2017 = 0.1071 + 0.0917 + 0.0029, time: 6.862051]
2023-05-26 14:40:44.467: epoch 41:	0.02325059  	0.17118654  	0.09005117  
2023-05-26 14:40:44.467: Find a better model.
2023-05-26 14:40:51.292: [iter 42 : loss : 0.1995 = 0.1051 + 0.0915 + 0.0029, time: 6.824024]
2023-05-26 14:40:51.449: epoch 42:	0.02330704  	0.17206314  	0.09066550  
2023-05-26 14:40:51.449: Find a better model.
2023-05-26 14:40:58.494: [iter 43 : loss : 0.1955 = 0.1014 + 0.0912 + 0.0030, time: 7.044011]
2023-05-26 14:40:58.653: epoch 43:	0.02342700  	0.17316291  	0.09097954  
2023-05-26 14:40:58.654: Find a better model.
2023-05-26 14:41:05.697: [iter 44 : loss : 0.1921 = 0.0982 + 0.0909 + 0.0030, time: 7.041993]
2023-05-26 14:41:05.853: epoch 44:	0.02349051  	0.17356110  	0.09148567  
2023-05-26 14:41:05.853: Find a better model.
2023-05-26 14:41:12.875: [iter 45 : loss : 0.1900 = 0.0962 + 0.0907 + 0.0031, time: 7.021023]
2023-05-26 14:41:13.019: epoch 45:	0.02365281  	0.17470303  	0.09201422  
2023-05-26 14:41:13.019: Find a better model.
2023-05-26 14:41:20.043: [iter 46 : loss : 0.1876 = 0.0941 + 0.0904 + 0.0031, time: 7.022993]
2023-05-26 14:41:20.185: epoch 46:	0.02369515  	0.17490071  	0.09253069  
2023-05-26 14:41:20.185: Find a better model.
2023-05-26 14:41:27.069: [iter 47 : loss : 0.1868 = 0.0934 + 0.0902 + 0.0032, time: 6.882017]
2023-05-26 14:41:27.224: epoch 47:	0.02372337  	0.17514330  	0.09286022  
2023-05-26 14:41:27.225: Find a better model.
2023-05-26 14:41:34.073: [iter 48 : loss : 0.1830 = 0.0898 + 0.0899 + 0.0032, time: 6.846297]
2023-05-26 14:41:34.228: epoch 48:	0.02377982  	0.17574771  	0.09340488  
2023-05-26 14:41:34.228: Find a better model.
2023-05-26 14:41:41.070: [iter 49 : loss : 0.1799 = 0.0868 + 0.0898 + 0.0033, time: 6.839900]
2023-05-26 14:41:41.223: epoch 49:	0.02387861  	0.17628348  	0.09388212  
2023-05-26 14:41:41.223: Find a better model.
2023-05-26 14:41:48.050: [iter 50 : loss : 0.1791 = 0.0862 + 0.0895 + 0.0033, time: 6.826034]
2023-05-26 14:41:48.193: epoch 50:	0.02397034  	0.17681864  	0.09435506  
2023-05-26 14:41:48.194: Find a better model.
2023-05-26 14:41:55.072: [iter 51 : loss : 0.1761 = 0.0833 + 0.0893 + 0.0034, time: 6.877195]
2023-05-26 14:41:55.228: epoch 51:	0.02406913  	0.17761993  	0.09447741  
2023-05-26 14:41:55.228: Find a better model.
2023-05-26 14:42:02.083: [iter 52 : loss : 0.1760 = 0.0835 + 0.0891 + 0.0034, time: 6.854033]
2023-05-26 14:42:02.243: epoch 52:	0.02414674  	0.17800161  	0.09501617  
2023-05-26 14:42:02.243: Find a better model.
2023-05-26 14:42:09.090: [iter 53 : loss : 0.1739 = 0.0816 + 0.0889 + 0.0035, time: 6.846030]
2023-05-26 14:42:09.246: epoch 53:	0.02422437  	0.17870639  	0.09540950  
2023-05-26 14:42:09.246: Find a better model.
2023-05-26 14:42:16.090: [iter 54 : loss : 0.1719 = 0.0797 + 0.0887 + 0.0035, time: 6.842592]
2023-05-26 14:42:16.244: epoch 54:	0.02433727  	0.17925531  	0.09584527  
2023-05-26 14:42:16.244: Find a better model.
2023-05-26 14:42:23.046: [iter 55 : loss : 0.1700 = 0.0779 + 0.0885 + 0.0036, time: 6.800312]
2023-05-26 14:42:23.188: epoch 55:	0.02438666  	0.17950936  	0.09599542  
2023-05-26 14:42:23.188: Find a better model.
2023-05-26 14:42:30.045: [iter 56 : loss : 0.1684 = 0.0765 + 0.0883 + 0.0036, time: 6.856002]
2023-05-26 14:42:30.199: epoch 56:	0.02445018  	0.18027648  	0.09656397  
2023-05-26 14:42:30.199: Find a better model.
2023-05-26 14:42:37.082: [iter 57 : loss : 0.1666 = 0.0747 + 0.0882 + 0.0037, time: 6.882027]
2023-05-26 14:42:37.236: epoch 57:	0.02452074  	0.18120766  	0.09705110  
2023-05-26 14:42:37.237: Find a better model.
2023-05-26 14:42:44.062: [iter 58 : loss : 0.1646 = 0.0729 + 0.0880 + 0.0037, time: 6.824010]
2023-05-26 14:42:44.218: epoch 58:	0.02460541  	0.18177348  	0.09749097  
2023-05-26 14:42:44.218: Find a better model.
2023-05-26 14:42:51.069: [iter 59 : loss : 0.1636 = 0.0720 + 0.0878 + 0.0038, time: 6.850028]
2023-05-26 14:42:51.227: epoch 59:	0.02471832  	0.18256748  	0.09778157  
2023-05-26 14:42:51.227: Find a better model.
2023-05-26 14:42:58.049: [iter 60 : loss : 0.1621 = 0.0706 + 0.0877 + 0.0038, time: 6.821003]
2023-05-26 14:42:58.205: epoch 60:	0.02480299  	0.18318272  	0.09820500  
2023-05-26 14:42:58.205: Find a better model.
2023-05-26 14:43:05.041: [iter 61 : loss : 0.1608 = 0.0695 + 0.0875 + 0.0039, time: 6.835008]
2023-05-26 14:43:05.197: epoch 61:	0.02488767  	0.18389155  	0.09867558  
2023-05-26 14:43:05.197: Find a better model.
2023-05-26 14:43:12.030: [iter 62 : loss : 0.1591 = 0.0679 + 0.0873 + 0.0039, time: 6.832671]
2023-05-26 14:43:12.188: epoch 62:	0.02486650  	0.18365544  	0.09873232  
2023-05-26 14:43:19.034: [iter 63 : loss : 0.1580 = 0.0668 + 0.0872 + 0.0039, time: 6.845003]
2023-05-26 14:43:19.189: epoch 63:	0.02503585  	0.18452638  	0.09914229  
2023-05-26 14:43:19.189: Find a better model.
2023-05-26 14:43:26.040: [iter 64 : loss : 0.1569 = 0.0659 + 0.0870 + 0.0040, time: 6.849044]
2023-05-26 14:43:26.181: epoch 64:	0.02508524  	0.18505508  	0.09964429  
2023-05-26 14:43:26.181: Find a better model.
2023-05-26 14:43:33.062: [iter 65 : loss : 0.1559 = 0.0650 + 0.0868 + 0.0040, time: 6.880036]
2023-05-26 14:43:33.221: epoch 65:	0.02519815  	0.18587269  	0.10004805  
2023-05-26 14:43:33.221: Find a better model.
2023-05-26 14:43:40.039: [iter 66 : loss : 0.1542 = 0.0634 + 0.0867 + 0.0041, time: 6.817061]
2023-05-26 14:43:40.194: epoch 66:	0.02514876  	0.18601719  	0.10022576  
2023-05-26 14:43:40.194: Find a better model.
2023-05-26 14:43:47.072: [iter 67 : loss : 0.1526 = 0.0619 + 0.0866 + 0.0041, time: 6.877010]
2023-05-26 14:43:47.229: epoch 67:	0.02529695  	0.18734446  	0.10088319  
2023-05-26 14:43:47.229: Find a better model.
2023-05-26 14:43:54.033: [iter 68 : loss : 0.1524 = 0.0618 + 0.0864 + 0.0042, time: 6.800098]
2023-05-26 14:43:54.190: epoch 68:	0.02535340  	0.18750137  	0.10108730  
2023-05-26 14:43:54.190: Find a better model.
2023-05-26 14:44:01.222: [iter 69 : loss : 0.1504 = 0.0599 + 0.0863 + 0.0042, time: 7.031539]
2023-05-26 14:44:01.379: epoch 69:	0.02541691  	0.18815079  	0.10144237  
2023-05-26 14:44:01.379: Find a better model.
2023-05-26 14:44:08.250: [iter 70 : loss : 0.1489 = 0.0585 + 0.0862 + 0.0042, time: 6.870107]
2023-05-26 14:44:08.407: epoch 70:	0.02545924  	0.18849093  	0.10177673  
2023-05-26 14:44:08.407: Find a better model.
2023-05-26 14:44:15.214: [iter 71 : loss : 0.1474 = 0.0570 + 0.0861 + 0.0043, time: 6.805546]
2023-05-26 14:44:15.358: epoch 71:	0.02548041  	0.18853112  	0.10191826  
2023-05-26 14:44:15.358: Find a better model.
2023-05-26 14:44:22.219: [iter 72 : loss : 0.1474 = 0.0572 + 0.0859 + 0.0043, time: 6.859091]
2023-05-26 14:44:22.376: epoch 72:	0.02555098  	0.18891686  	0.10209201  
2023-05-26 14:44:22.376: Find a better model.
2023-05-26 14:44:29.235: [iter 73 : loss : 0.1460 = 0.0558 + 0.0858 + 0.0044, time: 6.857993]
2023-05-26 14:44:29.391: epoch 73:	0.02556509  	0.18922070  	0.10221530  
2023-05-26 14:44:29.391: Find a better model.
2023-05-26 14:44:36.221: [iter 74 : loss : 0.1444 = 0.0543 + 0.0857 + 0.0044, time: 6.829026]
2023-05-26 14:44:36.376: epoch 74:	0.02559332  	0.18956019  	0.10267995  
2023-05-26 14:44:36.376: Find a better model.
2023-05-26 14:44:43.201: [iter 75 : loss : 0.1440 = 0.0540 + 0.0856 + 0.0045, time: 6.824002]
2023-05-26 14:44:43.361: epoch 75:	0.02566388  	0.18962374  	0.10293914  
2023-05-26 14:44:43.361: Find a better model.
2023-05-26 14:44:50.206: [iter 76 : loss : 0.1431 = 0.0531 + 0.0854 + 0.0045, time: 6.843096]
2023-05-26 14:44:50.366: epoch 76:	0.02572034  	0.18996643  	0.10322244  
2023-05-26 14:44:50.366: Find a better model.
2023-05-26 14:44:57.221: [iter 77 : loss : 0.1421 = 0.0522 + 0.0853 + 0.0045, time: 6.854003]
2023-05-26 14:44:57.377: epoch 77:	0.02573445  	0.19027075  	0.10355686  
2023-05-26 14:44:57.377: Find a better model.
2023-05-26 14:45:04.226: [iter 78 : loss : 0.1412 = 0.0514 + 0.0852 + 0.0046, time: 6.848043]
2023-05-26 14:45:04.382: epoch 78:	0.02579090  	0.19069675  	0.10374455  
2023-05-26 14:45:04.382: Find a better model.
2023-05-26 14:45:11.253: [iter 79 : loss : 0.1401 = 0.0503 + 0.0851 + 0.0046, time: 6.869002]
2023-05-26 14:45:11.408: epoch 79:	0.02581913  	0.19073546  	0.10401697  
2023-05-26 14:45:11.408: Find a better model.
2023-05-26 14:45:18.225: [iter 80 : loss : 0.1393 = 0.0496 + 0.0850 + 0.0047, time: 6.816038]
2023-05-26 14:45:18.382: epoch 80:	0.02587558  	0.19123527  	0.10416666  
2023-05-26 14:45:18.383: Find a better model.
2023-05-26 14:45:25.205: [iter 81 : loss : 0.1390 = 0.0494 + 0.0849 + 0.0047, time: 6.820387]
2023-05-26 14:45:25.361: epoch 81:	0.02589675  	0.19136623  	0.10422117  
2023-05-26 14:45:25.361: Find a better model.
2023-05-26 14:45:32.184: [iter 82 : loss : 0.1378 = 0.0482 + 0.0848 + 0.0047, time: 6.822031]
2023-05-26 14:45:32.342: epoch 82:	0.02593203  	0.19155334  	0.10431480  
2023-05-26 14:45:32.342: Find a better model.
2023-05-26 14:45:39.027: [iter 83 : loss : 0.1368 = 0.0473 + 0.0847 + 0.0048, time: 6.683078]
2023-05-26 14:45:39.184: epoch 83:	0.02596731  	0.19199136  	0.10464371  
2023-05-26 14:45:39.184: Find a better model.
2023-05-26 14:45:45.989: [iter 84 : loss : 0.1367 = 0.0473 + 0.0846 + 0.0048, time: 6.804279]
2023-05-26 14:45:46.146: epoch 84:	0.02599554  	0.19242968  	0.10474219  
2023-05-26 14:45:46.146: Find a better model.
2023-05-26 14:45:52.994: [iter 85 : loss : 0.1358 = 0.0464 + 0.0845 + 0.0049, time: 6.847003]
2023-05-26 14:45:53.149: epoch 85:	0.02601671  	0.19256759  	0.10505594  
2023-05-26 14:45:53.149: Find a better model.
2023-05-26 14:45:59.979: [iter 86 : loss : 0.1356 = 0.0463 + 0.0844 + 0.0049, time: 6.828022]
2023-05-26 14:46:00.135: epoch 86:	0.02607316  	0.19276667  	0.10533709  
2023-05-26 14:46:00.135: Find a better model.
2023-05-26 14:46:06.955: [iter 87 : loss : 0.1329 = 0.0436 + 0.0843 + 0.0049, time: 6.818011]
2023-05-26 14:46:07.100: epoch 87:	0.02611550  	0.19322906  	0.10558621  
2023-05-26 14:46:07.100: Find a better model.
2023-05-26 14:46:13.969: [iter 88 : loss : 0.1323 = 0.0431 + 0.0842 + 0.0050, time: 6.868061]
2023-05-26 14:46:14.128: epoch 88:	0.02612256  	0.19319054  	0.10564854  
2023-05-26 14:46:20.976: [iter 89 : loss : 0.1320 = 0.0429 + 0.0841 + 0.0050, time: 6.845004]
2023-05-26 14:46:21.120: epoch 89:	0.02611550  	0.19314213  	0.10580886  
2023-05-26 14:46:27.995: [iter 90 : loss : 0.1326 = 0.0435 + 0.0841 + 0.0051, time: 6.873009]
2023-05-26 14:46:28.152: epoch 90:	0.02617195  	0.19325066  	0.10591676  
2023-05-26 14:46:28.152: Find a better model.
2023-05-26 14:46:35.017: [iter 91 : loss : 0.1314 = 0.0423 + 0.0840 + 0.0051, time: 6.864001]
2023-05-26 14:46:35.177: epoch 91:	0.02614372  	0.19319981  	0.10589855  
2023-05-26 14:46:41.991: [iter 92 : loss : 0.1304 = 0.0414 + 0.0839 + 0.0051, time: 6.813333]
2023-05-26 14:46:42.136: epoch 92:	0.02618607  	0.19330914  	0.10590240  
2023-05-26 14:46:42.136: Find a better model.
2023-05-26 14:46:49.008: [iter 93 : loss : 0.1310 = 0.0420 + 0.0838 + 0.0052, time: 6.870009]
2023-05-26 14:46:49.163: epoch 93:	0.02618607  	0.19313544  	0.10606378  
2023-05-26 14:46:55.958: [iter 94 : loss : 0.1287 = 0.0397 + 0.0837 + 0.0052, time: 6.793140]
2023-05-26 14:46:56.116: epoch 94:	0.02629897  	0.19428515  	0.10654860  
2023-05-26 14:46:56.116: Find a better model.
2023-05-26 14:47:02.963: [iter 95 : loss : 0.1280 = 0.0391 + 0.0837 + 0.0052, time: 6.846012]
2023-05-26 14:47:03.120: epoch 95:	0.02635543  	0.19455573  	0.10666927  
2023-05-26 14:47:03.120: Find a better model.
2023-05-26 14:47:09.964: [iter 96 : loss : 0.1281 = 0.0392 + 0.0836 + 0.0053, time: 6.843007]
2023-05-26 14:47:10.121: epoch 96:	0.02639071  	0.19521853  	0.10681961  
2023-05-26 14:47:10.122: Find a better model.
2023-05-26 14:47:16.952: [iter 97 : loss : 0.1264 = 0.0376 + 0.0835 + 0.0053, time: 6.829454]
2023-05-26 14:47:17.109: epoch 97:	0.02642599  	0.19522639  	0.10699895  
2023-05-26 14:47:17.109: Find a better model.
2023-05-26 14:47:23.959: [iter 98 : loss : 0.1272 = 0.0384 + 0.0834 + 0.0053, time: 6.849003]
2023-05-26 14:47:24.117: epoch 98:	0.02645421  	0.19541481  	0.10714524  
2023-05-26 14:47:24.118: Find a better model.
2023-05-26 14:47:30.960: [iter 99 : loss : 0.1262 = 0.0374 + 0.0834 + 0.0054, time: 6.840500]
2023-05-26 14:47:31.116: epoch 99:	0.02641188  	0.19525418  	0.10717371  
2023-05-26 14:47:38.142: [iter 100 : loss : 0.1257 = 0.0370 + 0.0833 + 0.0054, time: 7.025070]
2023-05-26 14:47:38.299: epoch 100:	0.02648244  	0.19553041  	0.10718539  
2023-05-26 14:47:38.299: Find a better model.
2023-05-26 14:47:45.152: [iter 101 : loss : 0.1252 = 0.0365 + 0.0832 + 0.0055, time: 6.852037]
2023-05-26 14:47:45.309: epoch 101:	0.02651772  	0.19570085  	0.10728646  
2023-05-26 14:47:45.310: Find a better model.
2023-05-26 14:47:52.151: [iter 102 : loss : 0.1243 = 0.0357 + 0.0831 + 0.0055, time: 6.840015]
2023-05-26 14:47:52.308: epoch 102:	0.02651772  	0.19596979  	0.10732546  
2023-05-26 14:47:52.309: Find a better model.
2023-05-26 14:47:59.147: [iter 103 : loss : 0.1240 = 0.0354 + 0.0831 + 0.0055, time: 6.836993]
2023-05-26 14:47:59.301: epoch 103:	0.02655300  	0.19642839  	0.10758237  
2023-05-26 14:47:59.301: Find a better model.
2023-05-26 14:48:06.168: [iter 104 : loss : 0.1243 = 0.0358 + 0.0830 + 0.0056, time: 6.866030]
2023-05-26 14:48:06.310: epoch 104:	0.02664473  	0.19676012  	0.10774575  
2023-05-26 14:48:06.310: Find a better model.
2023-05-26 14:48:13.345: [iter 105 : loss : 0.1236 = 0.0351 + 0.0829 + 0.0056, time: 7.034030]
2023-05-26 14:48:13.502: epoch 105:	0.02653183  	0.19594124  	0.10771834  
2023-05-26 14:48:20.372: [iter 106 : loss : 0.1232 = 0.0347 + 0.0829 + 0.0056, time: 6.869192]
2023-05-26 14:48:20.529: epoch 106:	0.02658122  	0.19621198  	0.10783951  
2023-05-26 14:48:27.499: [iter 107 : loss : 0.1223 = 0.0339 + 0.0828 + 0.0057, time: 6.968035]
2023-05-26 14:48:27.644: epoch 107:	0.02658828  	0.19620708  	0.10781402  
2023-05-26 14:48:34.544: [iter 108 : loss : 0.1220 = 0.0336 + 0.0828 + 0.0057, time: 6.898005]
2023-05-26 14:48:34.702: epoch 108:	0.02653183  	0.19612074  	0.10784153  
2023-05-26 14:48:41.547: [iter 109 : loss : 0.1209 = 0.0324 + 0.0827 + 0.0057, time: 6.844052]
2023-05-26 14:48:41.692: epoch 109:	0.02653183  	0.19609949  	0.10790573  
2023-05-26 14:48:48.690: [iter 110 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 6.997005]
2023-05-26 14:48:48.835: epoch 110:	0.02658828  	0.19639543  	0.10796814  
2023-05-26 14:48:55.736: [iter 111 : loss : 0.1202 = 0.0318 + 0.0826 + 0.0058, time: 6.900337]
2023-05-26 14:48:55.893: epoch 111:	0.02652477  	0.19601865  	0.10804333  
2023-05-26 14:49:02.914: [iter 112 : loss : 0.1201 = 0.0318 + 0.0825 + 0.0058, time: 7.020036]
2023-05-26 14:49:03.071: epoch 112:	0.02654594  	0.19586037  	0.10803900  
2023-05-26 14:49:09.925: [iter 113 : loss : 0.1200 = 0.0317 + 0.0825 + 0.0059, time: 6.851435]
2023-05-26 14:49:10.081: epoch 113:	0.02659534  	0.19638583  	0.10822762  
2023-05-26 14:49:17.108: [iter 114 : loss : 0.1192 = 0.0309 + 0.0824 + 0.0059, time: 7.026078]
2023-05-26 14:49:17.268: epoch 114:	0.02660240  	0.19657426  	0.10811460  
2023-05-26 14:49:24.295: [iter 115 : loss : 0.1187 = 0.0304 + 0.0823 + 0.0059, time: 7.026021]
2023-05-26 14:49:24.455: epoch 115:	0.02665178  	0.19665526  	0.10821168  
2023-05-26 14:49:31.511: [iter 116 : loss : 0.1178 = 0.0296 + 0.0823 + 0.0060, time: 7.055017]
2023-05-26 14:49:31.669: epoch 116:	0.02665885  	0.19689088  	0.10834187  
2023-05-26 14:49:31.670: Find a better model.
2023-05-26 14:49:38.711: [iter 117 : loss : 0.1179 = 0.0296 + 0.0822 + 0.0060, time: 7.040234]
2023-05-26 14:49:38.868: epoch 117:	0.02667295  	0.19660744  	0.10832653  
2023-05-26 14:49:45.748: [iter 118 : loss : 0.1178 = 0.0296 + 0.0822 + 0.0060, time: 6.879066]
2023-05-26 14:49:45.903: epoch 118:	0.02665884  	0.19631974  	0.10821676  
2023-05-26 14:49:52.998: [iter 119 : loss : 0.1170 = 0.0288 + 0.0821 + 0.0061, time: 7.093437]
2023-05-26 14:49:53.163: epoch 119:	0.02663767  	0.19634312  	0.10828815  
2023-05-26 14:50:00.113: [iter 120 : loss : 0.1172 = 0.0290 + 0.0821 + 0.0061, time: 6.949014]
2023-05-26 14:50:00.258: epoch 120:	0.02654594  	0.19574594  	0.10809996  
2023-05-26 14:50:07.266: [iter 121 : loss : 0.1170 = 0.0288 + 0.0820 + 0.0061, time: 7.007017]
2023-05-26 14:50:07.410: epoch 121:	0.02653183  	0.19565395  	0.10807998  
2023-05-26 14:50:14.301: [iter 122 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 6.888993]
2023-05-26 14:50:14.444: epoch 122:	0.02652477  	0.19548889  	0.10819281  
2023-05-26 14:50:21.297: [iter 123 : loss : 0.1161 = 0.0280 + 0.0819 + 0.0062, time: 6.851327]
2023-05-26 14:50:21.442: epoch 123:	0.02651066  	0.19539921  	0.10817691  
2023-05-26 14:50:28.480: [iter 124 : loss : 0.1152 = 0.0271 + 0.0819 + 0.0062, time: 7.036289]
2023-05-26 14:50:28.627: epoch 124:	0.02650361  	0.19532257  	0.10831185  
2023-05-26 14:50:35.487: [iter 125 : loss : 0.1145 = 0.0264 + 0.0818 + 0.0063, time: 6.859366]
2023-05-26 14:50:35.634: epoch 125:	0.02656712  	0.19566946  	0.10856041  
2023-05-26 14:50:42.680: [iter 126 : loss : 0.1149 = 0.0269 + 0.0818 + 0.0063, time: 7.045064]
2023-05-26 14:50:42.823: epoch 126:	0.02656712  	0.19552059  	0.10857014  
2023-05-26 14:50:49.687: [iter 127 : loss : 0.1139 = 0.0258 + 0.0818 + 0.0063, time: 6.861993]
2023-05-26 14:50:49.844: epoch 127:	0.02651067  	0.19516858  	0.10852119  
2023-05-26 14:50:56.876: [iter 128 : loss : 0.1150 = 0.0269 + 0.0817 + 0.0064, time: 7.031042]
2023-05-26 14:50:57.031: epoch 128:	0.02652478  	0.19521660  	0.10856277  
2023-05-26 14:51:03.885: [iter 129 : loss : 0.1141 = 0.0261 + 0.0817 + 0.0064, time: 6.852115]
2023-05-26 14:51:04.042: epoch 129:	0.02657418  	0.19605538  	0.10882579  
2023-05-26 14:51:11.087: [iter 130 : loss : 0.1141 = 0.0261 + 0.0816 + 0.0064, time: 7.044021]
2023-05-26 14:51:11.243: epoch 130:	0.02657418  	0.19621609  	0.10898083  
2023-05-26 14:51:18.114: [iter 131 : loss : 0.1132 = 0.0252 + 0.0816 + 0.0064, time: 6.869017]
2023-05-26 14:51:18.269: epoch 131:	0.02658829  	0.19629867  	0.10895988  
2023-05-26 14:51:25.299: [iter 132 : loss : 0.1134 = 0.0255 + 0.0815 + 0.0065, time: 7.029001]
2023-05-26 14:51:25.456: epoch 132:	0.02656006  	0.19576329  	0.10892604  
2023-05-26 14:51:32.447: [iter 133 : loss : 0.1123 = 0.0243 + 0.0815 + 0.0065, time: 6.989083]
2023-05-26 14:51:32.607: epoch 133:	0.02658123  	0.19591422  	0.10892953  
2023-05-26 14:51:39.641: [iter 134 : loss : 0.1129 = 0.0250 + 0.0814 + 0.0065, time: 7.032006]
2023-05-26 14:51:39.786: epoch 134:	0.02663768  	0.19633982  	0.10911319  
2023-05-26 14:51:46.672: [iter 135 : loss : 0.1127 = 0.0247 + 0.0814 + 0.0066, time: 6.883063]
2023-05-26 14:51:46.826: epoch 135:	0.02662357  	0.19610874  	0.10907801  
2023-05-26 14:51:53.669: [iter 136 : loss : 0.1123 = 0.0244 + 0.0814 + 0.0066, time: 6.840325]
2023-05-26 14:51:53.824: epoch 136:	0.02660946  	0.19613509  	0.10902009  
2023-05-26 14:52:00.661: [iter 137 : loss : 0.1120 = 0.0240 + 0.0813 + 0.0066, time: 6.836041]
2023-05-26 14:52:00.807: epoch 137:	0.02668708  	0.19673492  	0.10922982  
2023-05-26 14:52:07.668: [iter 138 : loss : 0.1116 = 0.0237 + 0.0813 + 0.0066, time: 6.860004]
2023-05-26 14:52:07.828: epoch 138:	0.02670825  	0.19684082  	0.10942172  
2023-05-26 14:52:14.663: [iter 139 : loss : 0.1114 = 0.0235 + 0.0812 + 0.0067, time: 6.834003]
2023-05-26 14:52:14.817: epoch 139:	0.02663063  	0.19609158  	0.10927761  
2023-05-26 14:52:21.657: [iter 140 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0067, time: 6.837017]
2023-05-26 14:52:21.812: epoch 140:	0.02675059  	0.19712444  	0.10964297  
2023-05-26 14:52:21.812: Find a better model.
2023-05-26 14:52:28.646: [iter 141 : loss : 0.1115 = 0.0236 + 0.0812 + 0.0067, time: 6.833029]
2023-05-26 14:52:28.803: epoch 141:	0.02668002  	0.19623522  	0.10930877  
2023-05-26 14:52:35.649: [iter 142 : loss : 0.1106 = 0.0227 + 0.0811 + 0.0068, time: 6.845403]
2023-05-26 14:52:35.806: epoch 142:	0.02660946  	0.19582506  	0.10918694  
2023-05-26 14:52:42.685: [iter 143 : loss : 0.1106 = 0.0227 + 0.0811 + 0.0068, time: 6.877058]
2023-05-26 14:52:42.841: epoch 143:	0.02670825  	0.19673330  	0.10957848  
2023-05-26 14:52:49.667: [iter 144 : loss : 0.1100 = 0.0221 + 0.0811 + 0.0068, time: 6.825019]
2023-05-26 14:52:49.819: epoch 144:	0.02672236  	0.19685794  	0.10944554  
2023-05-26 14:52:56.670: [iter 145 : loss : 0.1098 = 0.0220 + 0.0810 + 0.0068, time: 6.850006]
2023-05-26 14:52:56.830: epoch 145:	0.02669413  	0.19645417  	0.10948110  
2023-05-26 14:53:03.650: [iter 146 : loss : 0.1103 = 0.0224 + 0.0810 + 0.0069, time: 6.817203]
2023-05-26 14:53:03.804: epoch 146:	0.02663768  	0.19626382  	0.10939839  
2023-05-26 14:53:10.645: [iter 147 : loss : 0.1101 = 0.0223 + 0.0810 + 0.0069, time: 6.839019]
2023-05-26 14:53:10.803: epoch 147:	0.02660240  	0.19595335  	0.10925786  
2023-05-26 14:53:17.655: [iter 148 : loss : 0.1089 = 0.0210 + 0.0809 + 0.0069, time: 6.851028]
2023-05-26 14:53:17.798: epoch 148:	0.02665179  	0.19634344  	0.10944410  
2023-05-26 14:53:24.631: [iter 149 : loss : 0.1093 = 0.0215 + 0.0809 + 0.0069, time: 6.832345]
2023-05-26 14:53:24.788: epoch 149:	0.02665884  	0.19602881  	0.10942896  
2023-05-26 14:53:31.632: [iter 150 : loss : 0.1087 = 0.0209 + 0.0809 + 0.0070, time: 6.841013]
2023-05-26 14:53:31.775: epoch 150:	0.02662356  	0.19594169  	0.10950873  
2023-05-26 14:53:38.635: [iter 151 : loss : 0.1089 = 0.0211 + 0.0808 + 0.0070, time: 6.859006]
2023-05-26 14:53:38.792: epoch 151:	0.02662356  	0.19582376  	0.10950286  
2023-05-26 14:53:45.624: [iter 152 : loss : 0.1082 = 0.0204 + 0.0808 + 0.0070, time: 6.830018]
2023-05-26 14:53:45.781: epoch 152:	0.02658122  	0.19563298  	0.10960251  
2023-05-26 14:53:52.623: [iter 153 : loss : 0.1074 = 0.0196 + 0.0808 + 0.0071, time: 6.840131]
2023-05-26 14:53:52.778: epoch 153:	0.02656711  	0.19543380  	0.10945208  
2023-05-26 14:53:59.836: [iter 154 : loss : 0.1077 = 0.0199 + 0.0807 + 0.0071, time: 7.057085]
2023-05-26 14:53:59.992: epoch 154:	0.02656711  	0.19537616  	0.10935167  
2023-05-26 14:54:06.817: [iter 155 : loss : 0.1086 = 0.0208 + 0.0807 + 0.0071, time: 6.824041]
2023-05-26 14:54:06.972: epoch 155:	0.02651065  	0.19524866  	0.10935976  
2023-05-26 14:54:13.829: [iter 156 : loss : 0.1078 = 0.0200 + 0.0807 + 0.0071, time: 6.856023]
2023-05-26 14:54:13.987: epoch 156:	0.02646831  	0.19474444  	0.10918597  
2023-05-26 14:54:20.827: [iter 157 : loss : 0.1076 = 0.0198 + 0.0807 + 0.0072, time: 6.838510]
2023-05-26 14:54:20.984: epoch 157:	0.02650359  	0.19506873  	0.10923731  
2023-05-26 14:54:27.838: [iter 158 : loss : 0.1070 = 0.0192 + 0.0806 + 0.0072, time: 6.853014]
2023-05-26 14:54:27.995: epoch 158:	0.02651771  	0.19516933  	0.10913770  
2023-05-26 14:54:34.823: [iter 159 : loss : 0.1073 = 0.0195 + 0.0806 + 0.0072, time: 6.827066]
2023-05-26 14:54:34.979: epoch 159:	0.02653182  	0.19526815  	0.10933650  
2023-05-26 14:54:41.813: [iter 160 : loss : 0.1069 = 0.0191 + 0.0806 + 0.0072, time: 6.832375]
2023-05-26 14:54:41.969: epoch 160:	0.02656005  	0.19535971  	0.10946666  
2023-05-26 14:54:48.822: [iter 161 : loss : 0.1065 = 0.0187 + 0.0805 + 0.0073, time: 6.851064]
2023-05-26 14:54:48.976: epoch 161:	0.02656005  	0.19537659  	0.10929277  
2023-05-26 14:54:55.823: [iter 162 : loss : 0.1058 = 0.0180 + 0.0805 + 0.0073, time: 6.845066]
2023-05-26 14:54:55.972: epoch 162:	0.02657416  	0.19532873  	0.10928503  
2023-05-26 14:55:02.807: [iter 163 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 6.834012]
2023-05-26 14:55:02.965: epoch 163:	0.02655300  	0.19541416  	0.10930247  
2023-05-26 14:55:09.783: [iter 164 : loss : 0.1063 = 0.0185 + 0.0805 + 0.0073, time: 6.816338]
2023-05-26 14:55:09.929: epoch 164:	0.02651772  	0.19501944  	0.10925280  
2023-05-26 14:55:16.783: [iter 165 : loss : 0.1060 = 0.0182 + 0.0804 + 0.0074, time: 6.851431]
2023-05-26 14:55:16.926: epoch 165:	0.02660945  	0.19555859  	0.10937901  
2023-05-26 14:55:16.927: Early stopping is trigger at epoch: 165
2023-05-26 14:55:16.927: best_result@epoch 140:

2023-05-26 14:55:16.927: 		0.0268      	0.1971      	0.1096      
2023-05-26 15:54:54.430: my pid: 15068
2023-05-26 15:54:54.430: model: model.general_recommender.SGL
2023-05-26 15:54:54.430: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 15:54:54.430: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 15:54:58.104: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 15:55:05.588: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.483110]
2023-05-26 15:55:05.733: epoch 1:	0.00216625  	0.01497536  	0.00764244  
2023-05-26 15:55:05.734: Find a better model.
2023-05-26 15:55:13.351: [iter 2 : loss : 0.7706 = 0.6929 + 0.0777 + 0.0000, time: 7.616174]
2023-05-26 15:55:13.553: epoch 2:	0.00394438  	0.02714157  	0.01355890  
2023-05-26 15:55:13.553: Find a better model.
2023-05-26 15:55:20.961: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.407082]
2023-05-26 15:55:21.118: epoch 3:	0.00671742  	0.04654722  	0.02366749  
2023-05-26 15:55:21.118: Find a better model.
2023-05-26 15:55:28.397: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.276993]
2023-05-26 15:55:28.553: epoch 4:	0.00967396  	0.06787906  	0.03394979  
2023-05-26 15:55:28.553: Find a better model.
2023-05-26 15:55:35.755: [iter 5 : loss : 0.7685 = 0.6906 + 0.0778 + 0.0000, time: 7.201452]
2023-05-26 15:55:35.913: epoch 5:	0.01265885  	0.08938721  	0.04379842  
2023-05-26 15:55:35.913: Find a better model.
2023-05-26 15:55:42.744: [iter 6 : loss : 0.7655 = 0.6874 + 0.0781 + 0.0000, time: 6.830003]
2023-05-26 15:55:42.901: epoch 6:	0.01543907  	0.11075804  	0.05446367  
2023-05-26 15:55:42.901: Find a better model.
2023-05-26 15:55:49.932: [iter 7 : loss : 0.7576 = 0.6787 + 0.0789 + 0.0000, time: 7.030002]
2023-05-26 15:55:50.085: epoch 7:	0.01788764  	0.12975959  	0.06405847  
2023-05-26 15:55:50.086: Find a better model.
2023-05-26 15:55:56.927: [iter 8 : loss : 0.7388 = 0.6578 + 0.0809 + 0.0001, time: 6.840048]
2023-05-26 15:55:57.078: epoch 8:	0.01873441  	0.13699752  	0.06902540  
2023-05-26 15:55:57.078: Find a better model.
2023-05-26 15:56:03.728: [iter 9 : loss : 0.6989 = 0.6139 + 0.0848 + 0.0002, time: 6.649011]
2023-05-26 15:56:03.885: epoch 9:	0.01879792  	0.13885236  	0.06976726  
2023-05-26 15:56:03.885: Find a better model.
2023-05-26 15:56:10.516: [iter 10 : loss : 0.6345 = 0.5442 + 0.0900 + 0.0003, time: 6.629366]
2023-05-26 15:56:10.658: epoch 10:	0.01888260  	0.13985242  	0.06963884  
2023-05-26 15:56:10.659: Find a better model.
2023-05-26 15:56:17.354: [iter 11 : loss : 0.5590 = 0.4638 + 0.0948 + 0.0004, time: 6.694473]
2023-05-26 15:56:17.508: epoch 11:	0.01871325  	0.13860905  	0.06942577  
2023-05-26 15:56:24.287: [iter 12 : loss : 0.4925 = 0.3940 + 0.0979 + 0.0006, time: 6.778037]
2023-05-26 15:56:24.431: epoch 12:	0.01852272  	0.13726650  	0.06928337  
2023-05-26 15:56:31.120: [iter 13 : loss : 0.4439 = 0.3436 + 0.0996 + 0.0007, time: 6.687239]
2023-05-26 15:56:31.274: epoch 13:	0.01857212  	0.13756423  	0.06985772  
2023-05-26 15:56:37.901: [iter 14 : loss : 0.4072 = 0.3058 + 0.1005 + 0.0009, time: 6.626332]
2023-05-26 15:56:38.043: epoch 14:	0.01878382  	0.13956578  	0.07076950  
2023-05-26 15:56:44.731: [iter 15 : loss : 0.3812 = 0.2795 + 0.1008 + 0.0010, time: 6.687071]
2023-05-26 15:56:44.888: epoch 15:	0.01891789  	0.14010404  	0.07146242  
2023-05-26 15:56:44.889: Find a better model.
2023-05-26 15:56:51.519: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 6.629022]
2023-05-26 15:56:51.678: epoch 16:	0.01919310  	0.14209834  	0.07224111  
2023-05-26 15:56:51.678: Find a better model.
2023-05-26 15:56:58.346: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 6.666950]
2023-05-26 15:56:58.500: epoch 17:	0.01939774  	0.14316788  	0.07318529  
2023-05-26 15:56:58.500: Find a better model.
2023-05-26 15:57:05.102: [iter 18 : loss : 0.3286 = 0.2268 + 0.1004 + 0.0013, time: 6.600049]
2023-05-26 15:57:05.246: epoch 18:	0.01965882  	0.14523189  	0.07400754  
2023-05-26 15:57:05.247: Find a better model.
2023-05-26 15:57:12.096: [iter 19 : loss : 0.3146 = 0.2131 + 0.1000 + 0.0014, time: 6.848017]
2023-05-26 15:57:12.254: epoch 19:	0.01989875  	0.14659438  	0.07485601  
2023-05-26 15:57:12.254: Find a better model.
2023-05-26 15:57:19.088: [iter 20 : loss : 0.3051 = 0.2039 + 0.0996 + 0.0015, time: 6.832488]
2023-05-26 15:57:19.243: epoch 20:	0.02015279  	0.14849868  	0.07577936  
2023-05-26 15:57:19.243: Find a better model.
2023-05-26 15:57:26.086: [iter 21 : loss : 0.2954 = 0.1946 + 0.0993 + 0.0016, time: 6.841116]
2023-05-26 15:57:26.241: epoch 21:	0.02032920  	0.14976291  	0.07656690  
2023-05-26 15:57:26.242: Find a better model.
2023-05-26 15:57:33.090: [iter 22 : loss : 0.2873 = 0.1868 + 0.0989 + 0.0017, time: 6.847010]
2023-05-26 15:57:33.245: epoch 22:	0.02051266  	0.15155566  	0.07746946  
2023-05-26 15:57:33.245: Find a better model.
2023-05-26 15:57:40.102: [iter 23 : loss : 0.2793 = 0.1790 + 0.0985 + 0.0018, time: 6.855722]
2023-05-26 15:57:40.256: epoch 23:	0.02067497  	0.15280922  	0.07839331  
2023-05-26 15:57:40.256: Find a better model.
2023-05-26 15:57:47.092: [iter 24 : loss : 0.2728 = 0.1729 + 0.0980 + 0.0018, time: 6.835011]
2023-05-26 15:57:47.246: epoch 24:	0.02087960  	0.15387651  	0.07897241  
2023-05-26 15:57:47.246: Find a better model.
2023-05-26 15:57:53.899: [iter 25 : loss : 0.2661 = 0.1665 + 0.0976 + 0.0019, time: 6.651635]
2023-05-26 15:57:54.056: epoch 25:	0.02102073  	0.15470774  	0.07946541  
2023-05-26 15:57:54.056: Find a better model.
2023-05-26 15:58:00.682: [iter 26 : loss : 0.2624 = 0.1633 + 0.0972 + 0.0020, time: 6.624006]
2023-05-26 15:58:00.828: epoch 26:	0.02112659  	0.15535788  	0.07995071  
2023-05-26 15:58:00.828: Find a better model.
2023-05-26 15:58:07.495: [iter 27 : loss : 0.2548 = 0.1559 + 0.0968 + 0.0021, time: 6.665009]
2023-05-26 15:58:07.648: epoch 27:	0.02129594  	0.15674502  	0.08069664  
2023-05-26 15:58:07.649: Find a better model.
2023-05-26 15:58:14.301: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 6.651041]
2023-05-26 15:58:14.456: epoch 28:	0.02143002  	0.15756500  	0.08144733  
2023-05-26 15:58:14.457: Find a better model.
2023-05-26 15:58:21.114: [iter 29 : loss : 0.2456 = 0.1474 + 0.0960 + 0.0022, time: 6.656033]
2023-05-26 15:58:21.268: epoch 29:	0.02162054  	0.15895677  	0.08225098  
2023-05-26 15:58:21.269: Find a better model.
2023-05-26 15:58:28.044: [iter 30 : loss : 0.2390 = 0.1411 + 0.0956 + 0.0022, time: 6.773703]
2023-05-26 15:58:28.186: epoch 30:	0.02184634  	0.16083184  	0.08313150  
2023-05-26 15:58:28.186: Find a better model.
2023-05-26 15:58:34.897: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 6.710042]
2023-05-26 15:58:35.053: epoch 31:	0.02198747  	0.16185437  	0.08384563  
2023-05-26 15:58:35.053: Find a better model.
2023-05-26 15:58:41.860: [iter 32 : loss : 0.2300 = 0.1327 + 0.0949 + 0.0024, time: 6.806058]
2023-05-26 15:58:42.002: epoch 32:	0.02214271  	0.16267397  	0.08440990  
2023-05-26 15:58:42.002: Find a better model.
2023-05-26 15:58:48.686: [iter 33 : loss : 0.2272 = 0.1302 + 0.0945 + 0.0024, time: 6.681086]
2023-05-26 15:58:48.843: epoch 33:	0.02221327  	0.16328903  	0.08470640  
2023-05-26 15:58:48.844: Find a better model.
2023-05-26 15:58:55.652: [iter 34 : loss : 0.2234 = 0.1268 + 0.0942 + 0.0025, time: 6.806998]
2023-05-26 15:58:55.806: epoch 34:	0.02237557  	0.16443875  	0.08538613  
2023-05-26 15:58:55.806: Find a better model.
2023-05-26 15:59:02.493: [iter 35 : loss : 0.2200 = 0.1236 + 0.0939 + 0.0025, time: 6.685019]
2023-05-26 15:59:02.650: epoch 35:	0.02248847  	0.16539912  	0.08601477  
2023-05-26 15:59:02.650: Find a better model.
2023-05-26 15:59:09.439: [iter 36 : loss : 0.2166 = 0.1204 + 0.0936 + 0.0026, time: 6.787615]
2023-05-26 15:59:09.591: epoch 36:	0.02270723  	0.16716278  	0.08693756  
2023-05-26 15:59:09.592: Find a better model.
2023-05-26 15:59:16.250: [iter 37 : loss : 0.2126 = 0.1167 + 0.0932 + 0.0027, time: 6.657008]
2023-05-26 15:59:16.392: epoch 37:	0.02288364  	0.16815960  	0.08760352  
2023-05-26 15:59:16.392: Find a better model.
2023-05-26 15:59:23.078: [iter 38 : loss : 0.2111 = 0.1154 + 0.0930 + 0.0027, time: 6.685165]
2023-05-26 15:59:23.230: epoch 38:	0.02296126  	0.16911186  	0.08815136  
2023-05-26 15:59:23.230: Find a better model.
2023-05-26 15:59:29.860: [iter 39 : loss : 0.2067 = 0.1112 + 0.0927 + 0.0028, time: 6.629004]
2023-05-26 15:59:30.013: epoch 39:	0.02294715  	0.16911449  	0.08876958  
2023-05-26 15:59:30.013: Find a better model.
2023-05-26 15:59:36.670: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 6.656033]
2023-05-26 15:59:36.824: epoch 40:	0.02297538  	0.16947632  	0.08907121  
2023-05-26 15:59:36.825: Find a better model.
2023-05-26 15:59:43.473: [iter 41 : loss : 0.2019 = 0.1070 + 0.0921 + 0.0029, time: 6.647028]
2023-05-26 15:59:43.626: epoch 41:	0.02314474  	0.17047954  	0.08967278  
2023-05-26 15:59:43.626: Find a better model.
2023-05-26 15:59:50.228: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.600031]
2023-05-26 15:59:50.372: epoch 42:	0.02327175  	0.17125009  	0.09019362  
2023-05-26 15:59:50.372: Find a better model.
2023-05-26 15:59:57.030: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 6.655926]
2023-05-26 15:59:57.171: epoch 43:	0.02338466  	0.17248400  	0.09090815  
2023-05-26 15:59:57.171: Find a better model.
2023-05-26 16:00:03.863: [iter 44 : loss : 0.1924 = 0.0981 + 0.0912 + 0.0030, time: 6.690048]
2023-05-26 16:00:04.018: epoch 44:	0.02351873  	0.17322424  	0.09142201  
2023-05-26 16:00:04.018: Find a better model.
2023-05-26 16:00:10.647: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.628271]
2023-05-26 16:00:10.803: epoch 45:	0.02365986  	0.17424634  	0.09224367  
2023-05-26 16:00:10.803: Find a better model.
2023-05-26 16:00:17.429: [iter 46 : loss : 0.1880 = 0.0941 + 0.0908 + 0.0031, time: 6.622058]
2023-05-26 16:00:17.583: epoch 46:	0.02369515  	0.17449503  	0.09244721  
2023-05-26 16:00:17.583: Find a better model.
2023-05-26 16:00:24.258: [iter 47 : loss : 0.1871 = 0.0933 + 0.0905 + 0.0032, time: 6.673070]
2023-05-26 16:00:24.417: epoch 47:	0.02386451  	0.17573193  	0.09284776  
2023-05-26 16:00:24.418: Find a better model.
2023-05-26 16:00:31.030: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.611010]
2023-05-26 16:00:31.173: epoch 48:	0.02392095  	0.17622703  	0.09325764  
2023-05-26 16:00:31.173: Find a better model.
2023-05-26 16:00:37.833: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 6.659021]
2023-05-26 16:00:37.985: epoch 49:	0.02406914  	0.17730820  	0.09392841  
2023-05-26 16:00:37.985: Find a better model.
2023-05-26 16:00:44.625: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 6.639019]
2023-05-26 16:00:44.778: epoch 50:	0.02406208  	0.17759329  	0.09424033  
2023-05-26 16:00:44.778: Find a better model.
2023-05-26 16:00:51.418: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 6.638402]
2023-05-26 16:00:51.571: epoch 51:	0.02416793  	0.17844321  	0.09467940  
2023-05-26 16:00:51.571: Find a better model.
2023-05-26 16:00:58.241: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 6.668405]
2023-05-26 16:00:58.397: epoch 52:	0.02422437  	0.17842750  	0.09497578  
2023-05-26 16:01:05.035: [iter 53 : loss : 0.1742 = 0.0815 + 0.0893 + 0.0035, time: 6.637061]
2023-05-26 16:01:05.175: epoch 53:	0.02433728  	0.17941333  	0.09565471  
2023-05-26 16:01:05.176: Find a better model.
2023-05-26 16:01:11.795: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 6.618042]
2023-05-26 16:01:11.939: epoch 54:	0.02434433  	0.17965502  	0.09601045  
2023-05-26 16:01:11.939: Find a better model.
2023-05-26 16:01:18.604: [iter 55 : loss : 0.1703 = 0.0779 + 0.0889 + 0.0036, time: 6.663979]
2023-05-26 16:01:18.746: epoch 55:	0.02432316  	0.17928515  	0.09599151  
2023-05-26 16:01:25.405: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.657053]
2023-05-26 16:01:25.559: epoch 56:	0.02438667  	0.17958453  	0.09643993  
2023-05-26 16:01:32.214: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 6.654019]
2023-05-26 16:01:32.370: epoch 57:	0.02448546  	0.18022777  	0.09681772  
2023-05-26 16:01:32.370: Find a better model.
2023-05-26 16:01:39.023: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 6.652003]
2023-05-26 16:01:39.177: epoch 58:	0.02447134  	0.17994051  	0.09698641  
2023-05-26 16:01:45.846: [iter 59 : loss : 0.1640 = 0.0721 + 0.0882 + 0.0038, time: 6.668164]
2023-05-26 16:01:46.001: epoch 59:	0.02459130  	0.18102334  	0.09751311  
2023-05-26 16:01:46.001: Find a better model.
2023-05-26 16:01:52.614: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 6.612238]
2023-05-26 16:01:52.767: epoch 60:	0.02473243  	0.18233371  	0.09813038  
2023-05-26 16:01:52.767: Find a better model.
2023-05-26 16:01:59.414: [iter 61 : loss : 0.1612 = 0.0694 + 0.0879 + 0.0038, time: 6.645004]
2023-05-26 16:01:59.567: epoch 61:	0.02476772  	0.18282568  	0.09840386  
2023-05-26 16:01:59.568: Find a better model.
2023-05-26 16:02:06.220: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 6.651088]
2023-05-26 16:02:06.374: epoch 62:	0.02479594  	0.18302089  	0.09864884  
2023-05-26 16:02:06.374: Find a better model.
2023-05-26 16:02:13.008: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 6.632004]
2023-05-26 16:02:13.162: epoch 63:	0.02488062  	0.18378438  	0.09916424  
2023-05-26 16:02:13.162: Find a better model.
2023-05-26 16:02:19.820: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 6.657003]
2023-05-26 16:02:19.975: epoch 64:	0.02494413  	0.18437508  	0.09951241  
2023-05-26 16:02:19.975: Find a better model.
2023-05-26 16:02:26.606: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 6.629013]
2023-05-26 16:02:26.747: epoch 65:	0.02497941  	0.18466699  	0.09980574  
2023-05-26 16:02:26.747: Find a better model.
2023-05-26 16:02:33.202: [iter 66 : loss : 0.1546 = 0.0634 + 0.0871 + 0.0041, time: 6.454014]
2023-05-26 16:02:33.357: epoch 66:	0.02506409  	0.18534249  	0.10031982  
2023-05-26 16:02:33.357: Find a better model.
2023-05-26 16:02:39.981: [iter 67 : loss : 0.1530 = 0.0620 + 0.0869 + 0.0041, time: 6.623004]
2023-05-26 16:02:40.124: epoch 67:	0.02502175  	0.18512684  	0.10033373  
2023-05-26 16:02:46.787: [iter 68 : loss : 0.1528 = 0.0618 + 0.0868 + 0.0042, time: 6.659297]
2023-05-26 16:02:46.930: epoch 68:	0.02517699  	0.18632852  	0.10074176  
2023-05-26 16:02:46.930: Find a better model.
2023-05-26 16:02:53.586: [iter 69 : loss : 0.1509 = 0.0601 + 0.0867 + 0.0042, time: 6.654208]
2023-05-26 16:02:53.729: epoch 69:	0.02514876  	0.18617438  	0.10094364  
2023-05-26 16:03:00.380: [iter 70 : loss : 0.1495 = 0.0587 + 0.0866 + 0.0042, time: 6.650138]
2023-05-26 16:03:00.524: epoch 70:	0.02522638  	0.18657640  	0.10142211  
2023-05-26 16:03:00.524: Find a better model.
2023-05-26 16:03:07.186: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.660999]
2023-05-26 16:03:07.329: epoch 71:	0.02530401  	0.18723078  	0.10194766  
2023-05-26 16:03:07.329: Find a better model.
2023-05-26 16:03:13.983: [iter 72 : loss : 0.1477 = 0.0571 + 0.0863 + 0.0043, time: 6.653135]
2023-05-26 16:03:14.136: epoch 72:	0.02538163  	0.18807197  	0.10218677  
2023-05-26 16:03:14.137: Find a better model.
2023-05-26 16:03:20.983: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 6.845008]
2023-05-26 16:03:21.136: epoch 73:	0.02545925  	0.18872808  	0.10249167  
2023-05-26 16:03:21.136: Find a better model.
2023-05-26 16:03:27.962: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.825008]
2023-05-26 16:03:28.117: epoch 74:	0.02547336  	0.18867107  	0.10270183  
2023-05-26 16:03:34.772: [iter 75 : loss : 0.1444 = 0.0540 + 0.0860 + 0.0044, time: 6.654055]
2023-05-26 16:03:34.917: epoch 75:	0.02556510  	0.18946289  	0.10315620  
2023-05-26 16:03:34.917: Find a better model.
2023-05-26 16:03:41.746: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 6.827995]
2023-05-26 16:03:41.904: epoch 76:	0.02557921  	0.18948366  	0.10323747  
2023-05-26 16:03:41.904: Find a better model.
2023-05-26 16:03:48.611: [iter 77 : loss : 0.1426 = 0.0523 + 0.0857 + 0.0045, time: 6.706012]
2023-05-26 16:03:48.766: epoch 77:	0.02567094  	0.19007935  	0.10351834  
2023-05-26 16:03:48.766: Find a better model.
2023-05-26 16:03:55.551: [iter 78 : loss : 0.1416 = 0.0515 + 0.0856 + 0.0046, time: 6.782967]
2023-05-26 16:03:55.706: epoch 78:	0.02574150  	0.19066168  	0.10372009  
2023-05-26 16:03:55.706: Find a better model.
2023-05-26 16:04:02.373: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 6.666070]
2023-05-26 16:04:02.526: epoch 79:	0.02572739  	0.19031818  	0.10357767  
2023-05-26 16:04:09.163: [iter 80 : loss : 0.1398 = 0.0498 + 0.0854 + 0.0047, time: 6.636055]
2023-05-26 16:04:09.318: epoch 80:	0.02576267  	0.19068532  	0.10380763  
2023-05-26 16:04:09.318: Find a better model.
2023-05-26 16:04:16.132: [iter 81 : loss : 0.1394 = 0.0494 + 0.0853 + 0.0047, time: 6.813015]
2023-05-26 16:04:16.285: epoch 81:	0.02581912  	0.19134311  	0.10397296  
2023-05-26 16:04:16.285: Find a better model.
2023-05-26 16:04:22.972: [iter 82 : loss : 0.1381 = 0.0482 + 0.0852 + 0.0047, time: 6.686005]
2023-05-26 16:04:23.127: epoch 82:	0.02590380  	0.19196683  	0.10444871  
2023-05-26 16:04:23.127: Find a better model.
2023-05-26 16:04:29.783: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 6.654030]
2023-05-26 16:04:29.939: epoch 83:	0.02589674  	0.19199549  	0.10462420  
2023-05-26 16:04:29.939: Find a better model.
2023-05-26 16:04:36.548: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 6.608010]
2023-05-26 16:04:36.691: epoch 84:	0.02598847  	0.19262144  	0.10496923  
2023-05-26 16:04:36.691: Find a better model.
2023-05-26 16:04:43.343: [iter 85 : loss : 0.1363 = 0.0465 + 0.0849 + 0.0048, time: 6.651011]
2023-05-26 16:04:43.498: epoch 85:	0.02589674  	0.19191842  	0.10492845  
2023-05-26 16:04:50.145: [iter 86 : loss : 0.1359 = 0.0463 + 0.0848 + 0.0049, time: 6.646007]
2023-05-26 16:04:50.288: epoch 86:	0.02596731  	0.19267619  	0.10519524  
2023-05-26 16:04:50.288: Find a better model.
2023-05-26 16:04:56.943: [iter 87 : loss : 0.1334 = 0.0437 + 0.0847 + 0.0049, time: 6.654040]
2023-05-26 16:04:57.096: epoch 87:	0.02600259  	0.19296810  	0.10554296  
2023-05-26 16:04:57.096: Find a better model.
2023-05-26 16:05:03.925: [iter 88 : loss : 0.1327 = 0.0431 + 0.0846 + 0.0050, time: 6.828015]
2023-05-26 16:05:04.079: epoch 88:	0.02606610  	0.19332168  	0.10571963  
2023-05-26 16:05:04.079: Find a better model.
2023-05-26 16:05:10.777: [iter 89 : loss : 0.1325 = 0.0430 + 0.0845 + 0.0050, time: 6.697050]
2023-05-26 16:05:10.933: epoch 89:	0.02603082  	0.19324417  	0.10568256  
2023-05-26 16:05:17.736: [iter 90 : loss : 0.1330 = 0.0435 + 0.0844 + 0.0050, time: 6.802191]
2023-05-26 16:05:17.893: epoch 90:	0.02607316  	0.19354725  	0.10576592  
2023-05-26 16:05:17.893: Find a better model.
2023-05-26 16:05:24.529: [iter 91 : loss : 0.1317 = 0.0422 + 0.0843 + 0.0051, time: 6.634032]
2023-05-26 16:05:24.684: epoch 91:	0.02612960  	0.19385689  	0.10596313  
2023-05-26 16:05:24.684: Find a better model.
2023-05-26 16:05:31.313: [iter 92 : loss : 0.1306 = 0.0413 + 0.0843 + 0.0051, time: 6.627152]
2023-05-26 16:05:31.466: epoch 92:	0.02617195  	0.19424167  	0.10611590  
2023-05-26 16:05:31.466: Find a better model.
2023-05-26 16:05:38.122: [iter 93 : loss : 0.1313 = 0.0420 + 0.0842 + 0.0052, time: 6.655097]
2023-05-26 16:05:38.276: epoch 93:	0.02623546  	0.19499393  	0.10628727  
2023-05-26 16:05:38.276: Find a better model.
2023-05-26 16:05:44.939: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 6.662007]
2023-05-26 16:05:45.093: epoch 94:	0.02618607  	0.19498123  	0.10625774  
2023-05-26 16:05:51.955: [iter 95 : loss : 0.1284 = 0.0391 + 0.0841 + 0.0052, time: 6.861018]
2023-05-26 16:05:52.107: epoch 95:	0.02616489  	0.19487981  	0.10619650  
2023-05-26 16:05:58.918: [iter 96 : loss : 0.1285 = 0.0393 + 0.0840 + 0.0053, time: 6.809101]
2023-05-26 16:05:59.074: epoch 96:	0.02619311  	0.19471452  	0.10647081  
2023-05-26 16:06:05.893: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 6.817033]
2023-05-26 16:06:06.051: epoch 97:	0.02620723  	0.19499263  	0.10654882  
2023-05-26 16:06:12.721: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 6.668160]
2023-05-26 16:06:12.877: epoch 98:	0.02632719  	0.19583116  	0.10707002  
2023-05-26 16:06:12.877: Find a better model.
2023-05-26 16:06:19.523: [iter 99 : loss : 0.1266 = 0.0374 + 0.0838 + 0.0054, time: 6.644068]
2023-05-26 16:06:19.677: epoch 99:	0.02634130  	0.19620173  	0.10694032  
2023-05-26 16:06:19.677: Find a better model.
2023-05-26 16:06:26.320: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 6.642086]
2023-05-26 16:06:26.472: epoch 100:	0.02635542  	0.19621514  	0.10690347  
2023-05-26 16:06:26.473: Find a better model.
2023-05-26 16:06:33.306: [iter 101 : loss : 0.1255 = 0.0365 + 0.0836 + 0.0054, time: 6.831005]
2023-05-26 16:06:33.458: epoch 101:	0.02632013  	0.19547941  	0.10677466  
2023-05-26 16:06:40.301: [iter 102 : loss : 0.1246 = 0.0356 + 0.0835 + 0.0055, time: 6.841576]
2023-05-26 16:06:40.457: epoch 102:	0.02644009  	0.19624688  	0.10713372  
2023-05-26 16:06:40.457: Find a better model.
2023-05-26 16:06:47.294: [iter 103 : loss : 0.1244 = 0.0354 + 0.0834 + 0.0055, time: 6.836265]
2023-05-26 16:06:47.450: epoch 103:	0.02649655  	0.19629750  	0.10719112  
2023-05-26 16:06:47.450: Find a better model.
2023-05-26 16:06:54.277: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 6.825538]
2023-05-26 16:06:54.431: epoch 104:	0.02638364  	0.19510929  	0.10688413  
2023-05-26 16:07:01.290: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.856036]
2023-05-26 16:07:01.432: epoch 105:	0.02644715  	0.19569924  	0.10723691  
2023-05-26 16:07:08.285: [iter 106 : loss : 0.1236 = 0.0347 + 0.0832 + 0.0056, time: 6.851544]
2023-05-26 16:07:08.437: epoch 106:	0.02655300  	0.19644500  	0.10756232  
2023-05-26 16:07:08.438: Find a better model.
2023-05-26 16:07:15.321: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0057, time: 6.882008]
2023-05-26 16:07:15.473: epoch 107:	0.02658122  	0.19653009  	0.10752318  
2023-05-26 16:07:15.474: Find a better model.
2023-05-26 16:07:22.295: [iter 108 : loss : 0.1224 = 0.0336 + 0.0831 + 0.0057, time: 6.820003]
2023-05-26 16:07:22.448: epoch 108:	0.02658122  	0.19663948  	0.10760888  
2023-05-26 16:07:22.448: Find a better model.
2023-05-26 16:07:29.273: [iter 109 : loss : 0.1212 = 0.0324 + 0.0831 + 0.0057, time: 6.824047]
2023-05-26 16:07:29.416: epoch 109:	0.02656005  	0.19613257  	0.10754209  
2023-05-26 16:07:36.271: [iter 110 : loss : 0.1206 = 0.0318 + 0.0830 + 0.0058, time: 6.853574]
2023-05-26 16:07:36.415: epoch 110:	0.02649654  	0.19594967  	0.10754173  
2023-05-26 16:07:43.276: [iter 111 : loss : 0.1206 = 0.0319 + 0.0830 + 0.0058, time: 6.859319]
2023-05-26 16:07:43.432: epoch 111:	0.02651771  	0.19629489  	0.10767335  
2023-05-26 16:07:50.299: [iter 112 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0058, time: 6.865089]
2023-05-26 16:07:50.453: epoch 112:	0.02660944  	0.19709578  	0.10786820  
2023-05-26 16:07:50.453: Find a better model.
2023-05-26 16:07:57.322: [iter 113 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0059, time: 6.867460]
2023-05-26 16:07:57.477: epoch 113:	0.02663767  	0.19727741  	0.10813812  
2023-05-26 16:07:57.477: Find a better model.
2023-05-26 16:08:04.289: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 6.811000]
2023-05-26 16:08:04.444: epoch 114:	0.02659534  	0.19692484  	0.10808059  
2023-05-26 16:08:11.278: [iter 115 : loss : 0.1191 = 0.0305 + 0.0827 + 0.0059, time: 6.833036]
2023-05-26 16:08:11.430: epoch 115:	0.02656712  	0.19675317  	0.10791782  
2023-05-26 16:08:18.258: [iter 116 : loss : 0.1183 = 0.0296 + 0.0827 + 0.0060, time: 6.826492]
2023-05-26 16:08:18.413: epoch 116:	0.02659534  	0.19696671  	0.10797234  
2023-05-26 16:08:25.263: [iter 117 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 6.849016]
2023-05-26 16:08:25.418: epoch 117:	0.02667296  	0.19760135  	0.10814789  
2023-05-26 16:08:25.418: Find a better model.
2023-05-26 16:08:32.260: [iter 118 : loss : 0.1182 = 0.0297 + 0.0826 + 0.0060, time: 6.841001]
2023-05-26 16:08:32.413: epoch 118:	0.02666590  	0.19736184  	0.10813465  
2023-05-26 16:08:39.276: [iter 119 : loss : 0.1173 = 0.0288 + 0.0825 + 0.0061, time: 6.861506]
2023-05-26 16:08:39.430: epoch 119:	0.02669412  	0.19735008  	0.10818756  
2023-05-26 16:08:46.081: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 6.649997]
2023-05-26 16:08:46.236: epoch 120:	0.02671530  	0.19747348  	0.10836747  
2023-05-26 16:08:53.056: [iter 121 : loss : 0.1174 = 0.0289 + 0.0824 + 0.0061, time: 6.819037]
2023-05-26 16:08:53.212: epoch 121:	0.02667296  	0.19716318  	0.10823629  
2023-05-26 16:08:59.865: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.651028]
2023-05-26 16:09:00.028: epoch 122:	0.02669413  	0.19708802  	0.10834233  
2023-05-26 16:09:06.844: [iter 123 : loss : 0.1164 = 0.0279 + 0.0823 + 0.0062, time: 6.814082]
2023-05-26 16:09:06.997: epoch 123:	0.02670824  	0.19721192  	0.10850468  
2023-05-26 16:09:13.849: [iter 124 : loss : 0.1157 = 0.0272 + 0.0823 + 0.0062, time: 6.850207]
2023-05-26 16:09:13.990: epoch 124:	0.02671530  	0.19692373  	0.10860506  
2023-05-26 16:09:20.661: [iter 125 : loss : 0.1149 = 0.0264 + 0.0822 + 0.0062, time: 6.670014]
2023-05-26 16:09:20.804: epoch 125:	0.02675058  	0.19731531  	0.10873982  
2023-05-26 16:09:27.457: [iter 126 : loss : 0.1153 = 0.0269 + 0.0822 + 0.0063, time: 6.652016]
2023-05-26 16:09:27.611: epoch 126:	0.02676470  	0.19781137  	0.10894614  
2023-05-26 16:09:27.611: Find a better model.
2023-05-26 16:09:34.241: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.628447]
2023-05-26 16:09:34.396: epoch 127:	0.02672941  	0.19725029  	0.10884640  
2023-05-26 16:09:41.045: [iter 128 : loss : 0.1154 = 0.0270 + 0.0821 + 0.0063, time: 6.647024]
2023-05-26 16:09:41.200: epoch 128:	0.02675058  	0.19747254  	0.10895059  
2023-05-26 16:09:47.848: [iter 129 : loss : 0.1144 = 0.0260 + 0.0821 + 0.0064, time: 6.647064]
2023-05-26 16:09:48.005: epoch 129:	0.02671530  	0.19722745  	0.10888635  
2023-05-26 16:09:54.821: [iter 130 : loss : 0.1146 = 0.0262 + 0.0820 + 0.0064, time: 6.815068]
2023-05-26 16:09:54.975: epoch 130:	0.02683526  	0.19830213  	0.10917120  
2023-05-26 16:09:54.975: Find a better model.
2023-05-26 16:10:01.666: [iter 131 : loss : 0.1136 = 0.0252 + 0.0820 + 0.0064, time: 6.689015]
2023-05-26 16:10:01.810: epoch 131:	0.02685642  	0.19813956  	0.10917182  
2023-05-26 16:10:08.443: [iter 132 : loss : 0.1139 = 0.0255 + 0.0819 + 0.0065, time: 6.631019]
2023-05-26 16:10:08.598: epoch 132:	0.02686348  	0.19819106  	0.10921270  
2023-05-26 16:10:15.233: [iter 133 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0065, time: 6.633570]
2023-05-26 16:10:15.389: epoch 133:	0.02689170  	0.19830032  	0.10924599  
2023-05-26 16:10:22.041: [iter 134 : loss : 0.1133 = 0.0250 + 0.0818 + 0.0065, time: 6.651049]
2023-05-26 16:10:22.196: epoch 134:	0.02682113  	0.19781464  	0.10921898  
2023-05-26 16:10:28.834: [iter 135 : loss : 0.1132 = 0.0248 + 0.0818 + 0.0065, time: 6.637013]
2023-05-26 16:10:28.993: epoch 135:	0.02679291  	0.19739789  	0.10912424  
2023-05-26 16:10:35.619: [iter 136 : loss : 0.1127 = 0.0244 + 0.0818 + 0.0066, time: 6.624994]
2023-05-26 16:10:35.763: epoch 136:	0.02679996  	0.19734290  	0.10904685  
2023-05-26 16:10:42.632: [iter 137 : loss : 0.1124 = 0.0241 + 0.0817 + 0.0066, time: 6.867568]
2023-05-26 16:10:42.787: epoch 137:	0.02686347  	0.19773424  	0.10913648  
2023-05-26 16:10:49.440: [iter 138 : loss : 0.1121 = 0.0238 + 0.0817 + 0.0066, time: 6.652020]
2023-05-26 16:10:49.595: epoch 138:	0.02685642  	0.19749345  	0.10917252  
2023-05-26 16:10:56.229: [iter 139 : loss : 0.1118 = 0.0236 + 0.0816 + 0.0067, time: 6.633294]
2023-05-26 16:10:56.382: epoch 139:	0.02687759  	0.19792518  	0.10923240  
2023-05-26 16:11:03.020: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.634959]
2023-05-26 16:11:03.174: epoch 140:	0.02685642  	0.19793808  	0.10933251  
2023-05-26 16:11:09.819: [iter 141 : loss : 0.1118 = 0.0235 + 0.0816 + 0.0067, time: 6.644009]
2023-05-26 16:11:09.977: epoch 141:	0.02694815  	0.19863354  	0.10960301  
2023-05-26 16:11:09.977: Find a better model.
2023-05-26 16:11:16.627: [iter 142 : loss : 0.1109 = 0.0226 + 0.0815 + 0.0067, time: 6.648004]
2023-05-26 16:11:16.781: epoch 142:	0.02687054  	0.19848707  	0.10970949  
2023-05-26 16:11:23.616: [iter 143 : loss : 0.1110 = 0.0227 + 0.0815 + 0.0068, time: 6.833628]
2023-05-26 16:11:23.771: epoch 143:	0.02689876  	0.19863707  	0.10969745  
2023-05-26 16:11:23.771: Find a better model.
2023-05-26 16:11:30.401: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.629010]
2023-05-26 16:11:30.556: epoch 144:	0.02689875  	0.19867362  	0.10966948  
2023-05-26 16:11:30.556: Find a better model.
2023-05-26 16:11:37.369: [iter 145 : loss : 0.1103 = 0.0221 + 0.0814 + 0.0068, time: 6.811018]
2023-05-26 16:11:37.524: epoch 145:	0.02686347  	0.19823156  	0.10945716  
2023-05-26 16:11:44.216: [iter 146 : loss : 0.1108 = 0.0225 + 0.0814 + 0.0068, time: 6.689640]
2023-05-26 16:11:44.370: epoch 146:	0.02691286  	0.19855499  	0.10962229  
2023-05-26 16:11:51.004: [iter 147 : loss : 0.1105 = 0.0223 + 0.0814 + 0.0069, time: 6.633320]
2023-05-26 16:11:51.158: epoch 147:	0.02696226  	0.19909973  	0.10971665  
2023-05-26 16:11:51.158: Find a better model.
2023-05-26 16:11:57.803: [iter 148 : loss : 0.1093 = 0.0211 + 0.0813 + 0.0069, time: 6.644016]
2023-05-26 16:11:57.960: epoch 148:	0.02689875  	0.19858159  	0.10958281  
2023-05-26 16:12:04.617: [iter 149 : loss : 0.1097 = 0.0215 + 0.0813 + 0.0069, time: 6.656331]
2023-05-26 16:12:04.771: epoch 149:	0.02694815  	0.19909233  	0.10964464  
2023-05-26 16:12:11.566: [iter 150 : loss : 0.1089 = 0.0207 + 0.0813 + 0.0070, time: 6.793344]
2023-05-26 16:12:11.722: epoch 150:	0.02694109  	0.19869021  	0.10964469  
2023-05-26 16:12:18.381: [iter 151 : loss : 0.1092 = 0.0210 + 0.0812 + 0.0070, time: 6.656889]
2023-05-26 16:12:18.524: epoch 151:	0.02689170  	0.19823508  	0.10966709  
2023-05-26 16:12:25.188: [iter 152 : loss : 0.1085 = 0.0203 + 0.0812 + 0.0070, time: 6.663466]
2023-05-26 16:12:25.344: epoch 152:	0.02687759  	0.19820973  	0.10961987  
2023-05-26 16:12:31.986: [iter 153 : loss : 0.1078 = 0.0196 + 0.0812 + 0.0070, time: 6.639692]
2023-05-26 16:12:32.143: epoch 153:	0.02688464  	0.19832328  	0.10956130  
2023-05-26 16:12:38.791: [iter 154 : loss : 0.1082 = 0.0200 + 0.0811 + 0.0071, time: 6.647009]
2023-05-26 16:12:38.947: epoch 154:	0.02689876  	0.19846874  	0.10970165  
2023-05-26 16:12:45.608: [iter 155 : loss : 0.1091 = 0.0209 + 0.0811 + 0.0071, time: 6.657987]
2023-05-26 16:12:45.752: epoch 155:	0.02687759  	0.19852962  	0.10961963  
2023-05-26 16:12:52.376: [iter 156 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.622012]
2023-05-26 16:12:52.529: epoch 156:	0.02687759  	0.19817254  	0.10946877  
2023-05-26 16:12:59.175: [iter 157 : loss : 0.1080 = 0.0198 + 0.0811 + 0.0071, time: 6.645003]
2023-05-26 16:12:59.331: epoch 157:	0.02688465  	0.19811887  	0.10952891  
2023-05-26 16:13:05.975: [iter 158 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.643013]
2023-05-26 16:13:06.128: epoch 158:	0.02690581  	0.19819561  	0.10946434  
2023-05-26 16:13:12.768: [iter 159 : loss : 0.1077 = 0.0196 + 0.0810 + 0.0072, time: 6.639003]
2023-05-26 16:13:12.928: epoch 159:	0.02686348  	0.19792651  	0.10935353  
2023-05-26 16:13:19.569: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.639994]
2023-05-26 16:13:19.724: epoch 160:	0.02685642  	0.19756626  	0.10935589  
2023-05-26 16:13:26.394: [iter 161 : loss : 0.1069 = 0.0188 + 0.0809 + 0.0072, time: 6.669017]
2023-05-26 16:13:26.549: epoch 161:	0.02673646  	0.19690768  	0.10914412  
2023-05-26 16:13:33.162: [iter 162 : loss : 0.1062 = 0.0181 + 0.0809 + 0.0073, time: 6.612021]
2023-05-26 16:13:33.316: epoch 162:	0.02677880  	0.19701849  	0.10928760  
2023-05-26 16:13:39.964: [iter 163 : loss : 0.1067 = 0.0185 + 0.0809 + 0.0073, time: 6.645306]
2023-05-26 16:13:40.119: epoch 163:	0.02675058  	0.19678606  	0.10902820  
2023-05-26 16:13:46.949: [iter 164 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 6.828978]
2023-05-26 16:13:47.093: epoch 164:	0.02678585  	0.19693945  	0.10911848  
2023-05-26 16:13:53.746: [iter 165 : loss : 0.1063 = 0.0181 + 0.0808 + 0.0073, time: 6.652395]
2023-05-26 16:13:53.893: epoch 165:	0.02674351  	0.19676179  	0.10907329  
2023-05-26 16:14:00.555: [iter 166 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 6.659013]
2023-05-26 16:14:00.698: epoch 166:	0.02677174  	0.19706564  	0.10907066  
2023-05-26 16:14:07.351: [iter 167 : loss : 0.1065 = 0.0183 + 0.0808 + 0.0074, time: 6.650662]
2023-05-26 16:14:07.496: epoch 167:	0.02669412  	0.19614853  	0.10909779  
2023-05-26 16:14:14.142: [iter 168 : loss : 0.1059 = 0.0178 + 0.0808 + 0.0074, time: 6.645005]
2023-05-26 16:14:14.285: epoch 168:	0.02677174  	0.19678238  	0.10897257  
2023-05-26 16:14:20.941: [iter 169 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0074, time: 6.653994]
2023-05-26 16:14:21.098: epoch 169:	0.02676468  	0.19658510  	0.10899232  
2023-05-26 16:14:27.732: [iter 170 : loss : 0.1058 = 0.0176 + 0.0807 + 0.0075, time: 6.633003]
2023-05-26 16:14:27.878: epoch 170:	0.02671529  	0.19620839  	0.10878133  
2023-05-26 16:14:34.538: [iter 171 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0075, time: 6.659003]
2023-05-26 16:14:34.681: epoch 171:	0.02675763  	0.19640163  	0.10898765  
2023-05-26 16:14:41.354: [iter 172 : loss : 0.1051 = 0.0169 + 0.0807 + 0.0075, time: 6.672048]
2023-05-26 16:14:41.507: epoch 172:	0.02668706  	0.19589694  	0.10884470  
2023-05-26 16:14:41.507: Early stopping is trigger at epoch: 172
2023-05-26 16:14:41.507: best_result@epoch 147:

2023-05-26 16:14:41.507: 		0.0270      	0.1991      	0.1097      
2023-05-26 16:24:52.136: my pid: 3516
2023-05-26 16:24:52.136: model: model.general_recommender.SGL
2023-05-26 16:24:52.136: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 16:24:52.136: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 16:24:55.904: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 16:25:03.401: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.497023]
2023-05-26 16:25:03.582: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-26 16:25:03.582: Find a better model.
2023-05-26 16:25:11.180: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.597283]
2023-05-26 16:25:11.391: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-26 16:25:11.391: Find a better model.
2023-05-26 16:25:18.739: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.346527]
2023-05-26 16:25:18.909: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-26 16:25:18.909: Find a better model.
2023-05-26 16:25:25.916: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.005309]
2023-05-26 16:25:26.086: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-26 16:25:26.086: Find a better model.
2023-05-26 16:25:33.125: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.037072]
2023-05-26 16:25:33.273: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-26 16:25:33.273: Find a better model.
2023-05-26 16:25:40.105: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.830222]
2023-05-26 16:25:40.262: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-26 16:25:40.262: Find a better model.
2023-05-26 16:25:46.894: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.631007]
2023-05-26 16:25:47.046: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-26 16:25:47.047: Find a better model.
2023-05-26 16:25:53.695: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.647026]
2023-05-26 16:25:53.851: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-26 16:25:53.851: Find a better model.
2023-05-26 16:26:00.498: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.646027]
2023-05-26 16:26:00.643: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-26 16:26:07.291: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.646014]
2023-05-26 16:26:07.446: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-26 16:26:14.098: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.651506]
2023-05-26 16:26:14.258: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-26 16:26:20.871: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.611034]
2023-05-26 16:26:21.019: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-26 16:26:27.674: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.653472]
2023-05-26 16:26:27.831: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-26 16:26:34.483: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.650316]
2023-05-26 16:26:34.640: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-26 16:26:41.267: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.626013]
2023-05-26 16:26:41.422: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-26 16:26:41.422: Find a better model.
2023-05-26 16:26:48.085: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.662038]
2023-05-26 16:26:48.244: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-26 16:26:48.244: Find a better model.
2023-05-26 16:26:54.887: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.641007]
2023-05-26 16:26:55.050: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-26 16:26:55.050: Find a better model.
2023-05-26 16:27:01.679: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.627006]
2023-05-26 16:27:01.825: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-26 16:27:01.825: Find a better model.
2023-05-26 16:27:08.460: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.634022]
2023-05-26 16:27:08.616: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-26 16:27:08.617: Find a better model.
2023-05-26 16:27:15.270: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.652006]
2023-05-26 16:27:15.428: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-26 16:27:15.428: Find a better model.
2023-05-26 16:27:22.075: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.645968]
2023-05-26 16:27:22.234: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-26 16:27:22.234: Find a better model.
2023-05-26 16:27:29.042: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.806093]
2023-05-26 16:27:29.198: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-26 16:27:29.198: Find a better model.
2023-05-26 16:27:35.880: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.680536]
2023-05-26 16:27:36.040: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-26 16:27:36.040: Find a better model.
2023-05-26 16:27:42.684: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.642036]
2023-05-26 16:27:42.837: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-26 16:27:42.837: Find a better model.
2023-05-26 16:27:49.425: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.587189]
2023-05-26 16:27:49.581: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-26 16:27:49.581: Find a better model.
2023-05-26 16:27:56.239: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.657442]
2023-05-26 16:27:56.395: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-26 16:27:56.395: Find a better model.
2023-05-26 16:28:03.032: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.636061]
2023-05-26 16:28:03.177: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-26 16:28:03.177: Find a better model.
2023-05-26 16:28:09.659: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.481064]
2023-05-26 16:28:09.806: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-26 16:28:09.806: Find a better model.
2023-05-26 16:28:16.420: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.611008]
2023-05-26 16:28:16.562: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-26 16:28:16.562: Find a better model.
2023-05-26 16:28:23.048: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.483013]
2023-05-26 16:28:23.203: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-26 16:28:23.203: Find a better model.
2023-05-26 16:28:29.835: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.631001]
2023-05-26 16:28:29.991: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-26 16:28:29.992: Find a better model.
2023-05-26 16:28:36.618: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.625005]
2023-05-26 16:28:36.773: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-26 16:28:36.773: Find a better model.
2023-05-26 16:28:43.247: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.472010]
2023-05-26 16:28:43.403: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-26 16:28:43.403: Find a better model.
2023-05-26 16:28:50.030: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.626003]
2023-05-26 16:28:50.174: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-26 16:28:50.174: Find a better model.
2023-05-26 16:28:56.819: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.644029]
2023-05-26 16:28:56.974: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-26 16:28:56.974: Find a better model.
2023-05-26 16:29:03.601: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.626288]
2023-05-26 16:29:03.757: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-26 16:29:03.757: Find a better model.
2023-05-26 16:29:10.427: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.668042]
2023-05-26 16:29:10.581: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-26 16:29:10.581: Find a better model.
2023-05-26 16:29:17.214: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.631252]
2023-05-26 16:29:17.369: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-26 16:29:17.370: Find a better model.
2023-05-26 16:29:24.010: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.639029]
2023-05-26 16:29:24.167: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-26 16:29:24.168: Find a better model.
2023-05-26 16:29:30.809: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.640023]
2023-05-26 16:29:30.954: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-26 16:29:37.609: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.654239]
2023-05-26 16:29:37.765: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-26 16:29:37.765: Find a better model.
2023-05-26 16:29:44.400: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.633029]
2023-05-26 16:29:44.544: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-26 16:29:44.544: Find a better model.
2023-05-26 16:29:51.207: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.661044]
2023-05-26 16:29:51.350: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-26 16:29:51.350: Find a better model.
2023-05-26 16:29:58.038: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.687301]
2023-05-26 16:29:58.192: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-26 16:29:58.193: Find a better model.
2023-05-26 16:30:04.811: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.617306]
2023-05-26 16:30:04.955: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-26 16:30:04.955: Find a better model.
2023-05-26 16:30:11.421: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.464998]
2023-05-26 16:30:11.577: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-26 16:30:11.577: Find a better model.
2023-05-26 16:30:18.202: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.624017]
2023-05-26 16:30:18.357: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-26 16:30:18.357: Find a better model.
2023-05-26 16:30:25.012: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.653159]
2023-05-26 16:30:25.169: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-26 16:30:25.169: Find a better model.
2023-05-26 16:30:31.804: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.633583]
2023-05-26 16:30:31.947: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-26 16:30:31.947: Find a better model.
2023-05-26 16:30:38.431: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.483014]
2023-05-26 16:30:38.586: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-26 16:30:38.587: Find a better model.
2023-05-26 16:30:45.185: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.597017]
2023-05-26 16:30:45.327: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-26 16:30:52.003: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.674049]
2023-05-26 16:30:52.159: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-26 16:30:52.159: Find a better model.
2023-05-26 16:30:58.803: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.643013]
2023-05-26 16:30:58.959: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-26 16:30:58.959: Find a better model.
2023-05-26 16:31:05.560: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.600129]
2023-05-26 16:31:05.714: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-26 16:31:05.714: Find a better model.
2023-05-26 16:31:12.373: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.658200]
2023-05-26 16:31:12.516: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-26 16:31:12.516: Find a better model.
2023-05-26 16:31:18.978: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.460079]
2023-05-26 16:31:19.123: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-26 16:31:19.123: Find a better model.
2023-05-26 16:31:25.620: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.495997]
2023-05-26 16:31:25.774: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-26 16:31:25.775: Find a better model.
2023-05-26 16:31:32.376: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.598408]
2023-05-26 16:31:32.531: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-26 16:31:32.531: Find a better model.
2023-05-26 16:31:39.144: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.611008]
2023-05-26 16:31:39.288: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-26 16:31:39.288: Find a better model.
2023-05-26 16:31:45.974: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.684266]
2023-05-26 16:31:46.130: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-26 16:31:46.130: Find a better model.
2023-05-26 16:31:52.779: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.648038]
2023-05-26 16:31:52.938: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-26 16:31:52.938: Find a better model.
2023-05-26 16:31:59.565: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.626005]
2023-05-26 16:31:59.719: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-26 16:31:59.720: Find a better model.
2023-05-26 16:32:06.368: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.647037]
2023-05-26 16:32:06.521: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-26 16:32:13.186: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.662010]
2023-05-26 16:32:13.339: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-26 16:32:13.339: Find a better model.
2023-05-26 16:32:19.973: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.631994]
2023-05-26 16:32:20.128: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-26 16:32:20.128: Find a better model.
2023-05-26 16:32:26.776: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.646024]
2023-05-26 16:32:26.931: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-26 16:32:26.931: Find a better model.
2023-05-26 16:32:33.572: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.640019]
2023-05-26 16:32:33.716: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-26 16:32:33.716: Find a better model.
2023-05-26 16:32:40.362: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.644017]
2023-05-26 16:32:40.518: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-26 16:32:40.518: Find a better model.
2023-05-26 16:32:47.162: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.643030]
2023-05-26 16:32:47.320: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-26 16:32:47.320: Find a better model.
2023-05-26 16:32:53.987: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.666024]
2023-05-26 16:32:54.144: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-26 16:32:54.144: Find a better model.
2023-05-26 16:33:00.945: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.798524]
2023-05-26 16:33:01.102: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-26 16:33:07.751: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.648209]
2023-05-26 16:33:07.905: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-26 16:33:07.905: Find a better model.
2023-05-26 16:33:14.546: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.640014]
2023-05-26 16:33:14.705: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-26 16:33:14.705: Find a better model.
2023-05-26 16:33:21.352: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.646016]
2023-05-26 16:33:21.506: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-26 16:33:28.326: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.818077]
2023-05-26 16:33:28.479: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-26 16:33:35.141: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.661024]
2023-05-26 16:33:35.296: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-26 16:33:35.296: Find a better model.
2023-05-26 16:33:41.942: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.645015]
2023-05-26 16:33:42.103: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-26 16:33:42.103: Find a better model.
2023-05-26 16:33:48.913: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.808061]
2023-05-26 16:33:49.073: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-26 16:33:49.074: Find a better model.
2023-05-26 16:33:55.921: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.845993]
2023-05-26 16:33:56.082: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-26 16:34:02.719: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.634030]
2023-05-26 16:34:02.860: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-26 16:34:02.861: Find a better model.
2023-05-26 16:34:09.544: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.682632]
2023-05-26 16:34:09.702: epoch 81:	0.02575562  	0.19010241  	0.10375397  
2023-05-26 16:34:09.702: Find a better model.
2023-05-26 16:34:16.334: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.631055]
2023-05-26 16:34:16.475: epoch 82:	0.02593909  	0.19127873  	0.10442533  
2023-05-26 16:34:16.475: Find a better model.
2023-05-26 16:34:23.142: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.663994]
2023-05-26 16:34:23.299: epoch 83:	0.02591792  	0.19122753  	0.10434162  
2023-05-26 16:34:29.922: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.621433]
2023-05-26 16:34:30.077: epoch 84:	0.02591792  	0.19129056  	0.10438651  
2023-05-26 16:34:30.077: Find a better model.
2023-05-26 16:34:36.709: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.631350]
2023-05-26 16:34:36.863: epoch 85:	0.02591087  	0.19136642  	0.10479141  
2023-05-26 16:34:36.863: Find a better model.
2023-05-26 16:34:43.507: [iter 86 : loss : 0.1368 = 0.0466 + 0.0854 + 0.0049, time: 6.643023]
2023-05-26 16:34:43.661: epoch 86:	0.02597438  	0.19166841  	0.10489704  
2023-05-26 16:34:43.661: Find a better model.
2023-05-26 16:34:50.317: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.654037]
2023-05-26 16:34:50.471: epoch 87:	0.02607317  	0.19224219  	0.10512664  
2023-05-26 16:34:50.471: Find a better model.
2023-05-26 16:34:57.114: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.642198]
2023-05-26 16:34:57.275: epoch 88:	0.02608023  	0.19226837  	0.10511711  
2023-05-26 16:34:57.275: Find a better model.
2023-05-26 16:35:03.906: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.629014]
2023-05-26 16:35:04.064: epoch 89:	0.02603083  	0.19170186  	0.10493099  
2023-05-26 16:35:10.682: [iter 90 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 6.617003]
2023-05-26 16:35:10.840: epoch 90:	0.02620724  	0.19286238  	0.10541573  
2023-05-26 16:35:10.841: Find a better model.
2023-05-26 16:35:17.485: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.643007]
2023-05-26 16:35:17.628: epoch 91:	0.02622136  	0.19309144  	0.10551340  
2023-05-26 16:35:17.628: Find a better model.
2023-05-26 16:35:24.302: [iter 92 : loss : 0.1315 = 0.0415 + 0.0849 + 0.0051, time: 6.673044]
2023-05-26 16:35:24.446: epoch 92:	0.02627075  	0.19332008  	0.10576107  
2023-05-26 16:35:24.446: Find a better model.
2023-05-26 16:35:31.306: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.857294]
2023-05-26 16:35:31.462: epoch 93:	0.02626370  	0.19348286  	0.10588794  
2023-05-26 16:35:31.463: Find a better model.
2023-05-26 16:35:38.111: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.647032]
2023-05-26 16:35:38.264: epoch 94:	0.02635543  	0.19406378  	0.10619074  
2023-05-26 16:35:38.264: Find a better model.
2023-05-26 16:35:44.908: [iter 95 : loss : 0.1292 = 0.0394 + 0.0847 + 0.0052, time: 6.643001]
2023-05-26 16:35:45.067: epoch 95:	0.02632015  	0.19381511  	0.10616567  
2023-05-26 16:35:51.714: [iter 96 : loss : 0.1293 = 0.0395 + 0.0846 + 0.0052, time: 6.645021]
2023-05-26 16:35:51.868: epoch 96:	0.02631309  	0.19380218  	0.10632121  
2023-05-26 16:35:58.486: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 6.617163]
2023-05-26 16:35:58.642: epoch 97:	0.02635543  	0.19422498  	0.10641174  
2023-05-26 16:35:58.642: Find a better model.
2023-05-26 16:36:05.290: [iter 98 : loss : 0.1284 = 0.0386 + 0.0844 + 0.0053, time: 6.646016]
2023-05-26 16:36:05.444: epoch 98:	0.02649656  	0.19535162  	0.10685667  
2023-05-26 16:36:05.445: Find a better model.
2023-05-26 16:36:12.106: [iter 99 : loss : 0.1274 = 0.0377 + 0.0844 + 0.0053, time: 6.659075]
2023-05-26 16:36:12.260: epoch 99:	0.02656006  	0.19601974  	0.10707307  
2023-05-26 16:36:12.261: Find a better model.
2023-05-26 16:36:18.894: [iter 100 : loss : 0.1269 = 0.0373 + 0.0843 + 0.0054, time: 6.631007]
2023-05-26 16:36:19.050: epoch 100:	0.02658829  	0.19632106  	0.10702197  
2023-05-26 16:36:19.051: Find a better model.
2023-05-26 16:36:25.690: [iter 101 : loss : 0.1264 = 0.0369 + 0.0842 + 0.0054, time: 6.638336]
2023-05-26 16:36:25.846: epoch 101:	0.02660946  	0.19651890  	0.10707853  
2023-05-26 16:36:25.847: Find a better model.
2023-05-26 16:36:32.477: [iter 102 : loss : 0.1254 = 0.0359 + 0.0841 + 0.0055, time: 6.629005]
2023-05-26 16:36:32.620: epoch 102:	0.02668708  	0.19693109  	0.10740847  
2023-05-26 16:36:32.620: Find a better model.
2023-05-26 16:36:39.290: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.667437]
2023-05-26 16:36:39.434: epoch 103:	0.02673648  	0.19711666  	0.10746574  
2023-05-26 16:36:39.434: Find a better model.
2023-05-26 16:36:46.075: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.639540]
2023-05-26 16:36:46.231: epoch 104:	0.02677176  	0.19759600  	0.10782146  
2023-05-26 16:36:46.232: Find a better model.
2023-05-26 16:36:52.865: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.631527]
2023-05-26 16:36:53.009: epoch 105:	0.02671531  	0.19737288  	0.10782990  
2023-05-26 16:36:59.664: [iter 106 : loss : 0.1245 = 0.0351 + 0.0838 + 0.0056, time: 6.654024]
2023-05-26 16:36:59.821: epoch 106:	0.02669414  	0.19675760  	0.10753261  
2023-05-26 16:37:06.467: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.645025]
2023-05-26 16:37:06.623: epoch 107:	0.02675059  	0.19707580  	0.10767967  
2023-05-26 16:37:13.254: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 6.629997]
2023-05-26 16:37:13.399: epoch 108:	0.02674353  	0.19727808  	0.10775982  
2023-05-26 16:37:20.084: [iter 109 : loss : 0.1221 = 0.0328 + 0.0836 + 0.0057, time: 6.682952]
2023-05-26 16:37:20.239: epoch 109:	0.02679998  	0.19769494  	0.10781121  
2023-05-26 16:37:20.239: Find a better model.
2023-05-26 16:37:26.877: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.636226]
2023-05-26 16:37:27.035: epoch 110:	0.02684232  	0.19785798  	0.10784786  
2023-05-26 16:37:27.036: Find a better model.
2023-05-26 16:37:33.650: [iter 111 : loss : 0.1214 = 0.0321 + 0.0835 + 0.0058, time: 6.612114]
2023-05-26 16:37:33.793: epoch 111:	0.02683526  	0.19808450  	0.10796522  
2023-05-26 16:37:33.793: Find a better model.
2023-05-26 16:37:40.455: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.661020]
2023-05-26 16:37:40.610: epoch 112:	0.02691993  	0.19867483  	0.10817447  
2023-05-26 16:37:40.611: Find a better model.
2023-05-26 16:37:47.265: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.653010]
2023-05-26 16:37:47.419: epoch 113:	0.02695522  	0.19914421  	0.10828193  
2023-05-26 16:37:47.420: Find a better model.
2023-05-26 16:37:54.235: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.814026]
2023-05-26 16:37:54.393: epoch 114:	0.02696933  	0.19924569  	0.10849025  
2023-05-26 16:37:54.393: Find a better model.
2023-05-26 16:38:01.079: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.685004]
2023-05-26 16:38:01.233: epoch 115:	0.02695521  	0.19859578  	0.10845681  
2023-05-26 16:38:07.859: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.624069]
2023-05-26 16:38:08.017: epoch 116:	0.02690581  	0.19806486  	0.10830446  
2023-05-26 16:38:14.821: [iter 117 : loss : 0.1192 = 0.0301 + 0.0832 + 0.0060, time: 6.803006]
2023-05-26 16:38:14.977: epoch 117:	0.02690581  	0.19802162  	0.10818756  
2023-05-26 16:38:21.624: [iter 118 : loss : 0.1190 = 0.0299 + 0.0832 + 0.0060, time: 6.646008]
2023-05-26 16:38:21.767: epoch 118:	0.02696932  	0.19853675  	0.10840670  
2023-05-26 16:38:28.450: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.682041]
2023-05-26 16:38:28.609: epoch 119:	0.02693404  	0.19828652  	0.10854238  
2023-05-26 16:38:35.249: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.639007]
2023-05-26 16:38:35.404: epoch 120:	0.02699755  	0.19873168  	0.10873766  
2023-05-26 16:38:42.038: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.632013]
2023-05-26 16:38:42.193: epoch 121:	0.02697637  	0.19845463  	0.10879749  
2023-05-26 16:38:48.869: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.674126]
2023-05-26 16:38:49.024: epoch 122:	0.02702577  	0.19889085  	0.10889582  
2023-05-26 16:38:55.615: [iter 123 : loss : 0.1175 = 0.0284 + 0.0829 + 0.0061, time: 6.589059]
2023-05-26 16:38:55.761: epoch 123:	0.02698343  	0.19858441  	0.10859056  
2023-05-26 16:39:02.430: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.667439]
2023-05-26 16:39:02.585: epoch 124:	0.02703282  	0.19897889  	0.10867114  
2023-05-26 16:39:09.225: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.638922]
2023-05-26 16:39:09.378: epoch 125:	0.02706811  	0.19938666  	0.10877192  
2023-05-26 16:39:09.378: Find a better model.
2023-05-26 16:39:16.018: [iter 126 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 6.639193]
2023-05-26 16:39:16.173: epoch 126:	0.02701166  	0.19890256  	0.10865973  
2023-05-26 16:39:22.812: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.636087]
2023-05-26 16:39:22.955: epoch 127:	0.02699754  	0.19921534  	0.10892340  
2023-05-26 16:39:29.607: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 6.650052]
2023-05-26 16:39:29.753: epoch 128:	0.02706811  	0.19974394  	0.10905816  
2023-05-26 16:39:29.753: Find a better model.
2023-05-26 16:39:36.413: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.659003]
2023-05-26 16:39:36.568: epoch 129:	0.02712456  	0.19999887  	0.10922831  
2023-05-26 16:39:36.568: Find a better model.
2023-05-26 16:39:43.420: [iter 130 : loss : 0.1153 = 0.0264 + 0.0826 + 0.0064, time: 6.850415]
2023-05-26 16:39:43.577: epoch 130:	0.02713868  	0.20039493  	0.10947259  
2023-05-26 16:39:43.577: Find a better model.
2023-05-26 16:39:50.409: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.831466]
2023-05-26 16:39:50.566: epoch 131:	0.02713163  	0.20014569  	0.10956270  
2023-05-26 16:39:57.389: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.822072]
2023-05-26 16:39:57.546: epoch 132:	0.02715279  	0.20053107  	0.10953291  
2023-05-26 16:39:57.546: Find a better model.
2023-05-26 16:40:04.386: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.838992]
2023-05-26 16:40:04.543: epoch 133:	0.02712456  	0.20042375  	0.10964710  
2023-05-26 16:40:11.195: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.651018]
2023-05-26 16:40:11.337: epoch 134:	0.02712456  	0.20007493  	0.10961022  
2023-05-26 16:40:18.005: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.665978]
2023-05-26 16:40:18.149: epoch 135:	0.02708928  	0.19983542  	0.10947565  
2023-05-26 16:40:24.787: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.637008]
2023-05-26 16:40:24.929: epoch 136:	0.02701166  	0.19975971  	0.10928407  
2023-05-26 16:40:31.613: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.683029]
2023-05-26 16:40:31.768: epoch 137:	0.02710338  	0.20006296  	0.10944772  
2023-05-26 16:40:38.403: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.634222]
2023-05-26 16:40:38.559: epoch 138:	0.02703284  	0.19962664  	0.10925742  
2023-05-26 16:40:45.372: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.811061]
2023-05-26 16:40:45.530: epoch 139:	0.02703988  	0.19944791  	0.10927588  
2023-05-26 16:40:52.372: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.841051]
2023-05-26 16:40:52.529: epoch 140:	0.02705400  	0.19950998  	0.10928700  
2023-05-26 16:40:59.175: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.645273]
2023-05-26 16:40:59.317: epoch 141:	0.02705400  	0.19939590  	0.10950647  
2023-05-26 16:41:05.986: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.667545]
2023-05-26 16:41:06.145: epoch 142:	0.02706811  	0.19956894  	0.10957257  
2023-05-26 16:41:12.796: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.647167]
2023-05-26 16:41:12.951: epoch 143:	0.02708928  	0.19979094  	0.10967638  
2023-05-26 16:41:19.603: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.650994]
2023-05-26 16:41:19.761: epoch 144:	0.02704694  	0.19960172  	0.10965959  
2023-05-26 16:41:26.565: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.801995]
2023-05-26 16:41:26.722: epoch 145:	0.02712457  	0.20008992  	0.10977585  
2023-05-26 16:41:33.378: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.653998]
2023-05-26 16:41:33.523: epoch 146:	0.02703284  	0.19933487  	0.10950205  
2023-05-26 16:41:40.191: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.667433]
2023-05-26 16:41:40.349: epoch 147:	0.02708223  	0.19976455  	0.10977522  
2023-05-26 16:41:46.990: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.638994]
2023-05-26 16:41:47.136: epoch 148:	0.02712457  	0.19982803  	0.10969271  
2023-05-26 16:41:53.759: [iter 149 : loss : 0.1105 = 0.0217 + 0.0819 + 0.0069, time: 6.620994]
2023-05-26 16:41:53.901: epoch 149:	0.02714574  	0.19987169  	0.10978123  
2023-05-26 16:42:00.545: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.643130]
2023-05-26 16:42:00.690: epoch 150:	0.02717396  	0.20009175  	0.11015426  
2023-05-26 16:42:07.376: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.683994]
2023-05-26 16:42:07.531: epoch 151:	0.02715985  	0.19977865  	0.11002725  
2023-05-26 16:42:14.364: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.831042]
2023-05-26 16:42:14.522: epoch 152:	0.02711751  	0.19952758  	0.11003788  
2023-05-26 16:42:21.164: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.640994]
2023-05-26 16:42:21.320: epoch 153:	0.02709634  	0.19928616  	0.10985070  
2023-05-26 16:42:27.986: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.664037]
2023-05-26 16:42:28.145: epoch 154:	0.02721630  	0.20027706  	0.11020282  
2023-05-26 16:42:34.748: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.602002]
2023-05-26 16:42:34.891: epoch 155:	0.02714574  	0.19984443  	0.11000567  
2023-05-26 16:42:41.549: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.655514]
2023-05-26 16:42:41.706: epoch 156:	0.02713163  	0.19980206  	0.10985455  
2023-05-26 16:42:48.349: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.642011]
2023-05-26 16:42:48.505: epoch 157:	0.02713163  	0.19979949  	0.10979664  
2023-05-26 16:42:48.505: Early stopping is trigger at epoch: 157
2023-05-26 16:42:48.505: best_result@epoch 132:

2023-05-26 16:42:48.505: 		0.0272      	0.2005      	0.1095      
2023-05-26 16:50:36.226: my pid: 7420
2023-05-26 16:50:36.226: model: model.general_recommender.SGL
2023-05-26 16:50:36.226: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 16:50:36.226: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 16:50:39.859: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 16:50:47.173: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.314036]
2023-05-26 16:50:47.321: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-26 16:50:47.321: Find a better model.
2023-05-26 16:50:54.766: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.443037]
2023-05-26 16:50:54.981: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-26 16:50:54.981: Find a better model.
2023-05-26 16:51:02.357: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.373517]
2023-05-26 16:51:02.556: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-26 16:51:02.557: Find a better model.
2023-05-26 16:51:09.737: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.178044]
2023-05-26 16:51:09.896: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-26 16:51:09.896: Find a better model.
2023-05-26 16:51:16.952: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 7.054922]
2023-05-26 16:51:17.106: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-26 16:51:17.106: Find a better model.
2023-05-26 16:51:23.950: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.843056]
2023-05-26 16:51:24.110: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-26 16:51:24.110: Find a better model.
2023-05-26 16:51:30.949: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.836386]
2023-05-26 16:51:31.106: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-26 16:51:31.106: Find a better model.
2023-05-26 16:51:37.929: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.821403]
2023-05-26 16:51:38.086: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-26 16:51:38.086: Find a better model.
2023-05-26 16:51:44.736: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.649027]
2023-05-26 16:51:44.896: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-26 16:51:51.518: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.620004]
2023-05-26 16:51:51.674: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-26 16:51:58.326: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.650024]
2023-05-26 16:51:58.483: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-26 16:52:04.925: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.441616]
2023-05-26 16:52:05.071: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-26 16:52:11.544: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.471101]
2023-05-26 16:52:11.691: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-26 16:52:11.691: Find a better model.
2023-05-26 16:52:18.322: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.630025]
2023-05-26 16:52:18.480: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-26 16:52:18.480: Find a better model.
2023-05-26 16:52:24.922: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.440004]
2023-05-26 16:52:25.079: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-26 16:52:25.079: Find a better model.
2023-05-26 16:52:31.514: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.434023]
2023-05-26 16:52:31.672: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-26 16:52:31.672: Find a better model.
2023-05-26 16:52:38.319: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.645997]
2023-05-26 16:52:38.477: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-26 16:52:38.477: Find a better model.
2023-05-26 16:52:44.924: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.445016]
2023-05-26 16:52:45.072: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-26 16:52:45.072: Find a better model.
2023-05-26 16:52:51.514: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.441021]
2023-05-26 16:52:51.661: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-26 16:52:51.662: Find a better model.
2023-05-26 16:52:58.105: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.442014]
2023-05-26 16:52:58.260: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-26 16:52:58.260: Find a better model.
2023-05-26 16:53:04.723: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.461448]
2023-05-26 16:53:04.879: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-26 16:53:04.879: Find a better model.
2023-05-26 16:53:11.497: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.617004]
2023-05-26 16:53:11.656: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-26 16:53:11.656: Find a better model.
2023-05-26 16:53:18.290: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.632997]
2023-05-26 16:53:18.444: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-26 16:53:18.444: Find a better model.
2023-05-26 16:53:24.919: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.474211]
2023-05-26 16:53:25.073: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-26 16:53:25.073: Find a better model.
2023-05-26 16:53:31.687: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.613014]
2023-05-26 16:53:31.845: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-26 16:53:31.845: Find a better model.
2023-05-26 16:53:38.487: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.641003]
2023-05-26 16:53:38.645: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-26 16:53:38.646: Find a better model.
2023-05-26 16:53:45.098: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.450419]
2023-05-26 16:53:45.253: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-26 16:53:45.253: Find a better model.
2023-05-26 16:53:51.706: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.451006]
2023-05-26 16:53:51.861: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-26 16:53:51.861: Find a better model.
2023-05-26 16:53:58.291: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.429004]
2023-05-26 16:53:58.433: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-26 16:53:58.433: Find a better model.
2023-05-26 16:54:04.889: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.455012]
2023-05-26 16:54:05.033: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-26 16:54:05.033: Find a better model.
2023-05-26 16:54:11.501: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.467052]
2023-05-26 16:54:11.659: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-26 16:54:11.659: Find a better model.
2023-05-26 16:54:18.288: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.627039]
2023-05-26 16:54:18.444: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-26 16:54:18.445: Find a better model.
2023-05-26 16:54:24.897: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.451014]
2023-05-26 16:54:25.053: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-26 16:54:25.053: Find a better model.
2023-05-26 16:54:31.496: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.442170]
2023-05-26 16:54:31.641: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-26 16:54:31.641: Find a better model.
2023-05-26 16:54:38.089: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.447014]
2023-05-26 16:54:38.243: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-26 16:54:38.243: Find a better model.
2023-05-26 16:54:44.877: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.633017]
2023-05-26 16:54:45.022: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-26 16:54:45.022: Find a better model.
2023-05-26 16:54:51.659: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.636054]
2023-05-26 16:54:51.803: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-26 16:54:51.803: Find a better model.
2023-05-26 16:54:58.273: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.468022]
2023-05-26 16:54:58.417: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-26 16:54:58.417: Find a better model.
2023-05-26 16:55:04.893: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.474997]
2023-05-26 16:55:05.048: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-26 16:55:05.048: Find a better model.
2023-05-26 16:55:11.658: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.607518]
2023-05-26 16:55:11.814: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-26 16:55:11.814: Find a better model.
2023-05-26 16:55:18.264: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.449481]
2023-05-26 16:55:18.408: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-26 16:55:18.408: Find a better model.
2023-05-26 16:55:24.869: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.460079]
2023-05-26 16:55:25.014: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-26 16:55:25.014: Find a better model.
2023-05-26 16:55:31.460: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.445015]
2023-05-26 16:55:31.609: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-26 16:55:38.051: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.440455]
2023-05-26 16:55:38.210: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-26 16:55:38.211: Find a better model.
2023-05-26 16:55:44.661: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.449010]
2023-05-26 16:55:44.803: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-26 16:55:44.803: Find a better model.
2023-05-26 16:55:51.251: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.446994]
2023-05-26 16:55:51.393: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-26 16:55:51.393: Find a better model.
2023-05-26 16:55:57.849: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.454010]
2023-05-26 16:55:58.007: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-26 16:55:58.007: Find a better model.
2023-05-26 16:56:04.462: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.454238]
2023-05-26 16:56:04.620: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-26 16:56:04.620: Find a better model.
2023-05-26 16:56:11.060: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.439187]
2023-05-26 16:56:11.216: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-26 16:56:11.216: Find a better model.
2023-05-26 16:56:17.673: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.455110]
2023-05-26 16:56:17.830: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-26 16:56:24.432: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0034, time: 6.601007]
2023-05-26 16:56:24.591: epoch 51:	0.02385745  	0.17556633  	0.09347075  
2023-05-26 16:56:24.592: Find a better model.
2023-05-26 16:56:31.065: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.470057]
2023-05-26 16:56:31.220: epoch 52:	0.02396329  	0.17615600  	0.09392820  
2023-05-26 16:56:31.221: Find a better model.
2023-05-26 16:56:37.819: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.597021]
2023-05-26 16:56:37.962: epoch 53:	0.02406913  	0.17702526  	0.09434863  
2023-05-26 16:56:37.962: Find a better model.
2023-05-26 16:56:44.434: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.469018]
2023-05-26 16:56:44.582: epoch 54:	0.02419615  	0.17792241  	0.09494144  
2023-05-26 16:56:44.582: Find a better model.
2023-05-26 16:56:51.048: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.464090]
2023-05-26 16:56:51.205: epoch 55:	0.02423849  	0.17839193  	0.09532860  
2023-05-26 16:56:51.205: Find a better model.
2023-05-26 16:56:57.645: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.437994]
2023-05-26 16:56:57.800: epoch 56:	0.02433728  	0.17909700  	0.09573369  
2023-05-26 16:56:57.800: Find a better model.
2023-05-26 16:57:04.414: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.613462]
2023-05-26 16:57:04.572: epoch 57:	0.02446430  	0.18026286  	0.09629583  
2023-05-26 16:57:04.572: Find a better model.
2023-05-26 16:57:11.047: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.473026]
2023-05-26 16:57:11.192: epoch 58:	0.02450663  	0.18062960  	0.09664251  
2023-05-26 16:57:11.192: Find a better model.
2023-05-26 16:57:17.808: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.615007]
2023-05-26 16:57:17.964: epoch 59:	0.02455603  	0.18130884  	0.09686511  
2023-05-26 16:57:17.964: Find a better model.
2023-05-26 16:57:24.447: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.482043]
2023-05-26 16:57:24.608: epoch 60:	0.02457720  	0.18123862  	0.09715549  
2023-05-26 16:57:31.028: [iter 61 : loss : 0.1636 = 0.0705 + 0.0892 + 0.0038, time: 6.419035]
2023-05-26 16:57:31.186: epoch 61:	0.02474656  	0.18253747  	0.09781680  
2023-05-26 16:57:31.187: Find a better model.
2023-05-26 16:57:37.820: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.631003]
2023-05-26 16:57:37.973: epoch 62:	0.02473244  	0.18249248  	0.09802019  
2023-05-26 16:57:44.602: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.628076]
2023-05-26 16:57:44.757: epoch 63:	0.02485240  	0.18354045  	0.09855148  
2023-05-26 16:57:44.757: Find a better model.
2023-05-26 16:57:51.414: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.655007]
2023-05-26 16:57:51.572: epoch 64:	0.02490885  	0.18378471  	0.09903330  
2023-05-26 16:57:51.572: Find a better model.
2023-05-26 16:57:58.015: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.442170]
2023-05-26 16:57:58.172: epoch 65:	0.02485945  	0.18354057  	0.09913395  
2023-05-26 16:58:04.800: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.627004]
2023-05-26 16:58:04.956: epoch 66:	0.02493708  	0.18397158  	0.09932361  
2023-05-26 16:58:04.956: Find a better model.
2023-05-26 16:58:11.415: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.458013]
2023-05-26 16:58:11.577: epoch 67:	0.02504998  	0.18468159  	0.09978308  
2023-05-26 16:58:11.578: Find a better model.
2023-05-26 16:58:18.188: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.609015]
2023-05-26 16:58:18.343: epoch 68:	0.02510642  	0.18502969  	0.10012835  
2023-05-26 16:58:18.343: Find a better model.
2023-05-26 16:58:24.814: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.469045]
2023-05-26 16:58:24.968: epoch 69:	0.02512054  	0.18508086  	0.10032206  
2023-05-26 16:58:24.968: Find a better model.
2023-05-26 16:58:31.404: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.434512]
2023-05-26 16:58:31.567: epoch 70:	0.02521933  	0.18603894  	0.10070904  
2023-05-26 16:58:31.567: Find a better model.
2023-05-26 16:58:38.007: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.438030]
2023-05-26 16:58:38.164: epoch 71:	0.02525461  	0.18614230  	0.10090048  
2023-05-26 16:58:38.164: Find a better model.
2023-05-26 16:58:44.793: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.628075]
2023-05-26 16:58:44.949: epoch 72:	0.02532518  	0.18680170  	0.10119528  
2023-05-26 16:58:44.949: Find a better model.
2023-05-26 16:58:51.588: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.637065]
2023-05-26 16:58:51.742: epoch 73:	0.02535341  	0.18726511  	0.10137676  
2023-05-26 16:58:51.742: Find a better model.
2023-05-26 16:58:58.394: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.651005]
2023-05-26 16:58:58.555: epoch 74:	0.02542397  	0.18757991  	0.10174557  
2023-05-26 16:58:58.555: Find a better model.
2023-05-26 16:59:04.994: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.437026]
2023-05-26 16:59:05.139: epoch 75:	0.02547337  	0.18816072  	0.10190730  
2023-05-26 16:59:05.139: Find a better model.
2023-05-26 16:59:11.786: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.646038]
2023-05-26 16:59:11.928: epoch 76:	0.02557922  	0.18915337  	0.10234687  
2023-05-26 16:59:11.928: Find a better model.
2023-05-26 16:59:18.385: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.455004]
2023-05-26 16:59:18.541: epoch 77:	0.02549453  	0.18842891  	0.10214259  
2023-05-26 16:59:24.985: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.442026]
2023-05-26 16:59:25.143: epoch 78:	0.02557921  	0.18915769  	0.10253035  
2023-05-26 16:59:25.143: Find a better model.
2023-05-26 16:59:31.580: [iter 79 : loss : 0.1425 = 0.0511 + 0.0869 + 0.0046, time: 6.436016]
2023-05-26 16:59:31.735: epoch 79:	0.02564978  	0.18960856  	0.10280474  
2023-05-26 16:59:31.735: Find a better model.
2023-05-26 16:59:38.376: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.639131]
2023-05-26 16:59:38.531: epoch 80:	0.02565683  	0.18977816  	0.10304097  
2023-05-26 16:59:38.531: Find a better model.
2023-05-26 16:59:44.986: [iter 81 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0046, time: 6.454131]
2023-05-26 16:59:45.141: epoch 81:	0.02568506  	0.18989682  	0.10328542  
2023-05-26 16:59:45.141: Find a better model.
2023-05-26 16:59:51.575: [iter 82 : loss : 0.1402 = 0.0490 + 0.0866 + 0.0047, time: 6.431996]
2023-05-26 16:59:51.716: epoch 82:	0.02567800  	0.18979020  	0.10337701  
2023-05-26 16:59:58.175: [iter 83 : loss : 0.1395 = 0.0483 + 0.0865 + 0.0047, time: 6.458327]
2023-05-26 16:59:58.317: epoch 83:	0.02574857  	0.19041438  	0.10361630  
2023-05-26 16:59:58.317: Find a better model.
2023-05-26 17:00:04.794: [iter 84 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 6.475944]
2023-05-26 17:00:04.937: epoch 84:	0.02564272  	0.18948308  	0.10349984  
2023-05-26 17:00:11.374: [iter 85 : loss : 0.1384 = 0.0473 + 0.0863 + 0.0048, time: 6.435960]
2023-05-26 17:00:11.517: epoch 85:	0.02574151  	0.19035104  	0.10382067  
2023-05-26 17:00:17.961: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.442395]
2023-05-26 17:00:18.120: epoch 86:	0.02583325  	0.19120090  	0.10410055  
2023-05-26 17:00:18.120: Find a better model.
2023-05-26 17:00:24.584: [iter 87 : loss : 0.1355 = 0.0445 + 0.0861 + 0.0049, time: 6.462011]
2023-05-26 17:00:24.738: epoch 87:	0.02592498  	0.19165075  	0.10435608  
2023-05-26 17:00:24.739: Find a better model.
2023-05-26 17:00:31.343: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.603101]
2023-05-26 17:00:31.487: epoch 88:	0.02598143  	0.19216737  	0.10469663  
2023-05-26 17:00:31.487: Find a better model.
2023-05-26 17:00:37.952: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.463160]
2023-05-26 17:00:38.112: epoch 89:	0.02593909  	0.19168027  	0.10474261  
2023-05-26 17:00:44.560: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.447009]
2023-05-26 17:00:44.703: epoch 90:	0.02598143  	0.19210102  	0.10495852  
2023-05-26 17:00:51.152: [iter 91 : loss : 0.1337 = 0.0429 + 0.0857 + 0.0050, time: 6.447255]
2023-05-26 17:00:51.306: epoch 91:	0.02607316  	0.19301951  	0.10521194  
2023-05-26 17:00:51.306: Find a better model.
2023-05-26 17:00:57.763: [iter 92 : loss : 0.1328 = 0.0421 + 0.0857 + 0.0051, time: 6.455994]
2023-05-26 17:00:57.917: epoch 92:	0.02606611  	0.19320604  	0.10531200  
2023-05-26 17:00:57.917: Find a better model.
2023-05-26 17:01:04.370: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.452000]
2023-05-26 17:01:04.528: epoch 93:	0.02607316  	0.19364491  	0.10542238  
2023-05-26 17:01:04.528: Find a better model.
2023-05-26 17:01:10.945: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.416029]
2023-05-26 17:01:11.091: epoch 94:	0.02604493  	0.19334863  	0.10543600  
2023-05-26 17:01:17.571: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.477989]
2023-05-26 17:01:17.727: epoch 95:	0.02602377  	0.19293091  	0.10547489  
2023-05-26 17:01:24.140: [iter 96 : loss : 0.1305 = 0.0400 + 0.0854 + 0.0052, time: 6.412142]
2023-05-26 17:01:24.295: epoch 96:	0.02607316  	0.19358504  	0.10575362  
2023-05-26 17:01:30.751: [iter 97 : loss : 0.1289 = 0.0384 + 0.0853 + 0.0052, time: 6.454071]
2023-05-26 17:01:30.906: epoch 97:	0.02608727  	0.19345793  	0.10576922  
2023-05-26 17:01:37.339: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.431069]
2023-05-26 17:01:37.482: epoch 98:	0.02606610  	0.19350217  	0.10580727  
2023-05-26 17:01:43.926: [iter 99 : loss : 0.1285 = 0.0380 + 0.0851 + 0.0053, time: 6.443009]
2023-05-26 17:01:44.084: epoch 99:	0.02612255  	0.19398789  	0.10604306  
2023-05-26 17:01:44.084: Find a better model.
2023-05-26 17:01:50.549: [iter 100 : loss : 0.1280 = 0.0376 + 0.0851 + 0.0053, time: 6.463040]
2023-05-26 17:01:50.706: epoch 100:	0.02615078  	0.19422464  	0.10611188  
2023-05-26 17:01:50.706: Find a better model.
2023-05-26 17:01:57.341: [iter 101 : loss : 0.1275 = 0.0372 + 0.0849 + 0.0054, time: 6.634030]
2023-05-26 17:01:57.496: epoch 101:	0.02621429  	0.19451775  	0.10633907  
2023-05-26 17:01:57.497: Find a better model.
2023-05-26 17:02:04.133: [iter 102 : loss : 0.1267 = 0.0365 + 0.0849 + 0.0054, time: 6.635017]
2023-05-26 17:02:04.279: epoch 102:	0.02622135  	0.19455352  	0.10641422  
2023-05-26 17:02:04.279: Find a better model.
2023-05-26 17:02:10.910: [iter 103 : loss : 0.1264 = 0.0361 + 0.0848 + 0.0055, time: 6.629015]
2023-05-26 17:02:11.054: epoch 103:	0.02622840  	0.19481267  	0.10661077  
2023-05-26 17:02:11.054: Find a better model.
2023-05-26 17:02:17.738: [iter 104 : loss : 0.1268 = 0.0366 + 0.0847 + 0.0055, time: 6.682485]
2023-05-26 17:02:17.896: epoch 104:	0.02623546  	0.19487023  	0.10677145  
2023-05-26 17:02:17.896: Find a better model.
2023-05-26 17:02:24.530: [iter 105 : loss : 0.1261 = 0.0359 + 0.0847 + 0.0055, time: 6.632998]
2023-05-26 17:02:24.689: epoch 105:	0.02620018  	0.19461438  	0.10678995  
2023-05-26 17:02:31.310: [iter 106 : loss : 0.1255 = 0.0354 + 0.0846 + 0.0056, time: 6.620059]
2023-05-26 17:02:31.453: epoch 106:	0.02617196  	0.19437581  	0.10659170  
2023-05-26 17:02:38.108: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.653004]
2023-05-26 17:02:38.264: epoch 107:	0.02621429  	0.19463815  	0.10670415  
2023-05-26 17:02:44.906: [iter 108 : loss : 0.1244 = 0.0343 + 0.0845 + 0.0056, time: 6.640135]
2023-05-26 17:02:45.062: epoch 108:	0.02623546  	0.19497925  	0.10678419  
2023-05-26 17:02:45.062: Find a better model.
2023-05-26 17:02:51.701: [iter 109 : loss : 0.1230 = 0.0329 + 0.0844 + 0.0057, time: 6.638482]
2023-05-26 17:02:51.845: epoch 109:	0.02627075  	0.19532466  	0.10691450  
2023-05-26 17:02:51.845: Find a better model.
2023-05-26 17:02:58.497: [iter 110 : loss : 0.1225 = 0.0324 + 0.0844 + 0.0057, time: 6.649999]
2023-05-26 17:02:58.654: epoch 110:	0.02632014  	0.19573490  	0.10699286  
2023-05-26 17:02:58.654: Find a better model.
2023-05-26 17:03:05.303: [iter 111 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0057, time: 6.646985]
2023-05-26 17:03:05.461: epoch 111:	0.02634837  	0.19601567  	0.10725428  
2023-05-26 17:03:05.461: Find a better model.
2023-05-26 17:03:12.097: [iter 112 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0058, time: 6.634997]
2023-05-26 17:03:12.252: epoch 112:	0.02635542  	0.19584881  	0.10719389  
2023-05-26 17:03:18.912: [iter 113 : loss : 0.1223 = 0.0322 + 0.0842 + 0.0058, time: 6.659031]
2023-05-26 17:03:19.069: epoch 113:	0.02632720  	0.19564304  	0.10711826  
2023-05-26 17:03:25.726: [iter 114 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0058, time: 6.655994]
2023-05-26 17:03:25.881: epoch 114:	0.02636248  	0.19562456  	0.10719673  
2023-05-26 17:03:32.507: [iter 115 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 6.624965]
2023-05-26 17:03:32.665: epoch 115:	0.02636248  	0.19590564  	0.10712224  
2023-05-26 17:03:39.300: [iter 116 : loss : 0.1204 = 0.0304 + 0.0841 + 0.0059, time: 6.633003]
2023-05-26 17:03:39.454: epoch 116:	0.02639071  	0.19610101  	0.10714111  
2023-05-26 17:03:39.454: Find a better model.
2023-05-26 17:03:45.915: [iter 117 : loss : 0.1202 = 0.0302 + 0.0840 + 0.0059, time: 6.460039]
2023-05-26 17:03:46.069: epoch 117:	0.02647539  	0.19672194  	0.10740019  
2023-05-26 17:03:46.070: Find a better model.
2023-05-26 17:03:52.698: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.627015]
2023-05-26 17:03:52.857: epoch 118:	0.02654595  	0.19720964  	0.10758431  
2023-05-26 17:03:52.857: Find a better model.
2023-05-26 17:03:59.491: [iter 119 : loss : 0.1191 = 0.0292 + 0.0839 + 0.0060, time: 6.633044]
2023-05-26 17:03:59.647: epoch 119:	0.02657417  	0.19701733  	0.10769693  
2023-05-26 17:04:06.288: [iter 120 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0060, time: 6.638020]
2023-05-26 17:04:06.443: epoch 120:	0.02647538  	0.19600351  	0.10740139  
2023-05-26 17:04:13.090: [iter 121 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 6.646025]
2023-05-26 17:04:13.244: epoch 121:	0.02646127  	0.19610976  	0.10752419  
2023-05-26 17:04:19.868: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.623031]
2023-05-26 17:04:20.024: epoch 122:	0.02644010  	0.19603574  	0.10758741  
2023-05-26 17:04:26.492: [iter 123 : loss : 0.1184 = 0.0285 + 0.0837 + 0.0061, time: 6.467068]
2023-05-26 17:04:26.653: epoch 123:	0.02642599  	0.19587712  	0.10749868  
2023-05-26 17:04:33.282: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.627994]
2023-05-26 17:04:33.438: epoch 124:	0.02647539  	0.19613720  	0.10752356  
2023-05-26 17:04:40.044: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.605392]
2023-05-26 17:04:40.188: epoch 125:	0.02650362  	0.19681413  	0.10771277  
2023-05-26 17:04:46.860: [iter 126 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0062, time: 6.669512]
2023-05-26 17:04:47.017: epoch 126:	0.02650362  	0.19643947  	0.10773034  
2023-05-26 17:04:53.667: [iter 127 : loss : 0.1162 = 0.0264 + 0.0835 + 0.0062, time: 6.648994]
2023-05-26 17:04:53.810: epoch 127:	0.02643305  	0.19600880  	0.10764985  
2023-05-26 17:05:00.483: [iter 128 : loss : 0.1171 = 0.0274 + 0.0835 + 0.0063, time: 6.671001]
2023-05-26 17:05:00.629: epoch 128:	0.02651066  	0.19584490  	0.10755798  
2023-05-26 17:05:07.254: [iter 129 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 6.624006]
2023-05-26 17:05:07.397: epoch 129:	0.02651067  	0.19621202  	0.10771299  
2023-05-26 17:05:13.889: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.489004]
2023-05-26 17:05:14.045: epoch 130:	0.02646127  	0.19575760  	0.10770663  
2023-05-26 17:05:20.646: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 6.600007]
2023-05-26 17:05:20.790: epoch 131:	0.02648244  	0.19605905  	0.10775223  
2023-05-26 17:05:27.442: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.649079]
2023-05-26 17:05:27.605: epoch 132:	0.02643304  	0.19579579  	0.10774627  
2023-05-26 17:05:34.070: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.464005]
2023-05-26 17:05:34.228: epoch 133:	0.02636953  	0.19522797  	0.10768935  
2023-05-26 17:05:40.846: [iter 134 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 6.617013]
2023-05-26 17:05:41.000: epoch 134:	0.02636248  	0.19496040  	0.10765595  
2023-05-26 17:05:47.648: [iter 135 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0065, time: 6.647006]
2023-05-26 17:05:47.804: epoch 135:	0.02640481  	0.19539623  	0.10775267  
2023-05-26 17:05:54.263: [iter 136 : loss : 0.1145 = 0.0249 + 0.0832 + 0.0065, time: 6.457009]
2023-05-26 17:05:54.418: epoch 136:	0.02641893  	0.19558795  	0.10777292  
2023-05-26 17:06:00.852: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.432979]
2023-05-26 17:06:00.994: epoch 137:	0.02644715  	0.19588301  	0.10784824  
2023-05-26 17:06:07.633: [iter 138 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.637465]
2023-05-26 17:06:07.776: epoch 138:	0.02646126  	0.19612333  	0.10798246  
2023-05-26 17:06:14.265: [iter 139 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 6.488242]
2023-05-26 17:06:14.422: epoch 139:	0.02644715  	0.19580023  	0.10788836  
2023-05-26 17:06:20.854: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.430994]
2023-05-26 17:06:21.011: epoch 140:	0.02644010  	0.19568200  	0.10788347  
2023-05-26 17:06:27.462: [iter 141 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 6.448048]
2023-05-26 17:06:27.621: epoch 141:	0.02642599  	0.19571260  	0.10787903  
2023-05-26 17:06:34.240: [iter 142 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0067, time: 6.618014]
2023-05-26 17:06:34.398: epoch 142:	0.02640481  	0.19589205  	0.10802663  
2023-05-26 17:06:40.852: [iter 143 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 6.453596]
2023-05-26 17:06:41.007: epoch 143:	0.02638364  	0.19573078  	0.10818961  
2023-05-26 17:06:41.007: Early stopping is trigger at epoch: 143
2023-05-26 17:06:41.007: best_result@epoch 118:

2023-05-26 17:06:41.007: 		0.0265      	0.1972      	0.1076      
2023-05-26 17:12:05.797: my pid: 14632
2023-05-26 17:12:05.798: model: model.general_recommender.SGL
2023-05-26 17:12:05.798: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 17:12:05.798: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 17:12:09.451: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 17:12:16.565: [iter 1 : loss : 0.7726 = 0.6930 + 0.0796 + 0.0000, time: 7.113092]
2023-05-26 17:12:16.723: epoch 1:	0.00203924  	0.01432136  	0.00729454  
2023-05-26 17:12:16.723: Find a better model.
2023-05-26 17:12:24.093: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.368321]
2023-05-26 17:12:24.298: epoch 2:	0.00478406  	0.03443001  	0.01690566  
2023-05-26 17:12:24.298: Find a better model.
2023-05-26 17:12:31.355: [iter 3 : loss : 0.7720 = 0.6923 + 0.0797 + 0.0000, time: 7.056329]
2023-05-26 17:12:31.542: epoch 3:	0.00788873  	0.05646078  	0.02796516  
2023-05-26 17:12:31.542: Find a better model.
2023-05-26 17:12:38.533: [iter 4 : loss : 0.7713 = 0.6914 + 0.0800 + 0.0000, time: 6.990120]
2023-05-26 17:12:38.691: epoch 4:	0.01172033  	0.08282045  	0.03980501  
2023-05-26 17:12:38.691: Find a better model.
2023-05-26 17:12:45.546: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 6.853292]
2023-05-26 17:12:45.705: epoch 5:	0.01521326  	0.10884760  	0.05229084  
2023-05-26 17:12:45.705: Find a better model.
2023-05-26 17:12:52.533: [iter 6 : loss : 0.7660 = 0.6850 + 0.0809 + 0.0000, time: 6.827065]
2023-05-26 17:12:52.692: epoch 6:	0.01762655  	0.12596598  	0.06164180  
2023-05-26 17:12:52.692: Find a better model.
2023-05-26 17:12:59.481: [iter 7 : loss : 0.7561 = 0.6739 + 0.0822 + 0.0000, time: 6.787040]
2023-05-26 17:12:59.640: epoch 7:	0.01864268  	0.13527347  	0.06688826  
2023-05-26 17:12:59.640: Find a better model.
2023-05-26 17:13:06.320: [iter 8 : loss : 0.7333 = 0.6483 + 0.0849 + 0.0001, time: 6.679076]
2023-05-26 17:13:06.478: epoch 8:	0.01890378  	0.13831645  	0.06872977  
2023-05-26 17:13:06.478: Find a better model.
2023-05-26 17:13:13.076: [iter 9 : loss : 0.6876 = 0.5979 + 0.0895 + 0.0002, time: 6.596012]
2023-05-26 17:13:13.228: epoch 9:	0.01873442  	0.13818790  	0.06860495  
2023-05-26 17:13:19.713: [iter 10 : loss : 0.6197 = 0.5246 + 0.0948 + 0.0003, time: 6.483004]
2023-05-26 17:13:19.866: epoch 10:	0.01829691  	0.13509032  	0.06706029  
2023-05-26 17:13:26.313: [iter 11 : loss : 0.5468 = 0.4473 + 0.0990 + 0.0005, time: 6.445004]
2023-05-26 17:13:26.467: epoch 11:	0.01835337  	0.13575500  	0.06715121  
2023-05-26 17:13:32.921: [iter 12 : loss : 0.4859 = 0.3837 + 0.1016 + 0.0006, time: 6.452174]
2023-05-26 17:13:33.078: epoch 12:	0.01828986  	0.13479917  	0.06730105  
2023-05-26 17:13:39.529: [iter 13 : loss : 0.4417 = 0.3380 + 0.1029 + 0.0008, time: 6.448992]
2023-05-26 17:13:39.691: epoch 13:	0.01848745  	0.13685237  	0.06832035  
2023-05-26 17:13:46.309: [iter 14 : loss : 0.4077 = 0.3034 + 0.1034 + 0.0009, time: 6.617018]
2023-05-26 17:13:46.464: epoch 14:	0.01874854  	0.13879488  	0.06923629  
2023-05-26 17:13:46.464: Find a better model.
2023-05-26 17:13:52.866: [iter 15 : loss : 0.3837 = 0.2792 + 0.1035 + 0.0010, time: 6.401185]
2023-05-26 17:13:53.010: epoch 15:	0.01882615  	0.13954487  	0.06991188  
2023-05-26 17:13:53.010: Find a better model.
2023-05-26 17:13:59.310: [iter 16 : loss : 0.3631 = 0.2585 + 0.1035 + 0.0011, time: 6.298088]
2023-05-26 17:13:59.467: epoch 16:	0.01905196  	0.14125791  	0.07095956  
2023-05-26 17:13:59.467: Find a better model.
2023-05-26 17:14:05.886: [iter 17 : loss : 0.3477 = 0.2434 + 0.1032 + 0.0012, time: 6.418065]
2023-05-26 17:14:06.043: epoch 17:	0.01922837  	0.14225909  	0.07166037  
2023-05-26 17:14:06.043: Find a better model.
2023-05-26 17:14:12.493: [iter 18 : loss : 0.3331 = 0.2289 + 0.1029 + 0.0013, time: 6.449008]
2023-05-26 17:14:12.653: epoch 18:	0.01936245  	0.14336030  	0.07235111  
2023-05-26 17:14:12.653: Find a better model.
2023-05-26 17:14:19.092: [iter 19 : loss : 0.3195 = 0.2156 + 0.1025 + 0.0014, time: 6.438100]
2023-05-26 17:14:19.250: epoch 19:	0.01962354  	0.14525086  	0.07337818  
2023-05-26 17:14:19.251: Find a better model.
2023-05-26 17:14:25.681: [iter 20 : loss : 0.3101 = 0.2065 + 0.1021 + 0.0015, time: 6.428267]
2023-05-26 17:14:25.836: epoch 20:	0.01988464  	0.14728081  	0.07441803  
2023-05-26 17:14:25.836: Find a better model.
2023-05-26 17:14:32.272: [iter 21 : loss : 0.3008 = 0.1975 + 0.1017 + 0.0016, time: 6.435019]
2023-05-26 17:14:32.429: epoch 21:	0.02006811  	0.14867450  	0.07526683  
2023-05-26 17:14:32.429: Find a better model.
2023-05-26 17:14:38.888: [iter 22 : loss : 0.2926 = 0.1897 + 0.1012 + 0.0017, time: 6.457423]
2023-05-26 17:14:39.044: epoch 22:	0.02030803  	0.15070923  	0.07621783  
2023-05-26 17:14:39.044: Find a better model.
2023-05-26 17:14:45.452: [iter 23 : loss : 0.2845 = 0.1819 + 0.1008 + 0.0017, time: 6.406590]
2023-05-26 17:14:45.600: epoch 23:	0.02044915  	0.15141676  	0.07680257  
2023-05-26 17:14:45.600: Find a better model.
2023-05-26 17:14:52.087: [iter 24 : loss : 0.2781 = 0.1759 + 0.1004 + 0.0018, time: 6.486101]
2023-05-26 17:14:52.245: epoch 24:	0.02060440  	0.15200818  	0.07732188  
2023-05-26 17:14:52.245: Find a better model.
2023-05-26 17:14:58.678: [iter 25 : loss : 0.2715 = 0.1696 + 0.1000 + 0.0019, time: 6.432174]
2023-05-26 17:14:58.823: epoch 25:	0.02083021  	0.15347055  	0.07818237  
2023-05-26 17:14:58.823: Find a better model.
2023-05-26 17:15:05.451: [iter 26 : loss : 0.2678 = 0.1663 + 0.0995 + 0.0020, time: 6.626774]
2023-05-26 17:15:05.610: epoch 26:	0.02100662  	0.15437225  	0.07877313  
2023-05-26 17:15:05.610: Find a better model.
2023-05-26 17:15:12.281: [iter 27 : loss : 0.2602 = 0.1590 + 0.0991 + 0.0020, time: 6.670115]
2023-05-26 17:15:12.435: epoch 27:	0.02123243  	0.15572694  	0.07970133  
2023-05-26 17:15:12.435: Find a better model.
2023-05-26 17:15:18.890: [iter 28 : loss : 0.2553 = 0.1546 + 0.0987 + 0.0021, time: 6.453493]
2023-05-26 17:15:19.045: epoch 28:	0.02148647  	0.15756127  	0.08083389  
2023-05-26 17:15:19.045: Find a better model.
2023-05-26 17:15:25.491: [iter 29 : loss : 0.2510 = 0.1506 + 0.0983 + 0.0021, time: 6.445014]
2023-05-26 17:15:25.648: epoch 29:	0.02165583  	0.15919425  	0.08170892  
2023-05-26 17:15:25.648: Find a better model.
2023-05-26 17:15:32.247: [iter 30 : loss : 0.2442 = 0.1441 + 0.0979 + 0.0022, time: 6.598086]
2023-05-26 17:15:32.390: epoch 30:	0.02184635  	0.16071603  	0.08260520  
2023-05-26 17:15:32.390: Find a better model.
2023-05-26 17:15:38.843: [iter 31 : loss : 0.2410 = 0.1412 + 0.0975 + 0.0023, time: 6.450015]
2023-05-26 17:15:38.999: epoch 31:	0.02209333  	0.16248375  	0.08326704  
2023-05-26 17:15:38.999: Find a better model.
2023-05-26 17:15:45.654: [iter 32 : loss : 0.2353 = 0.1358 + 0.0972 + 0.0023, time: 6.654030]
2023-05-26 17:15:45.814: epoch 32:	0.02215683  	0.16332962  	0.08395989  
2023-05-26 17:15:45.814: Find a better model.
2023-05-26 17:15:52.487: [iter 33 : loss : 0.2328 = 0.1336 + 0.0968 + 0.0024, time: 6.671086]
2023-05-26 17:15:52.634: epoch 33:	0.02236852  	0.16472344  	0.08467601  
2023-05-26 17:15:52.634: Find a better model.
2023-05-26 17:15:59.237: [iter 34 : loss : 0.2284 = 0.1295 + 0.0965 + 0.0024, time: 6.601006]
2023-05-26 17:15:59.380: epoch 34:	0.02248142  	0.16563728  	0.08530647  
2023-05-26 17:15:59.380: Find a better model.
2023-05-26 17:16:05.849: [iter 35 : loss : 0.2251 = 0.1265 + 0.0962 + 0.0025, time: 6.467543]
2023-05-26 17:16:05.991: epoch 35:	0.02263667  	0.16659069  	0.08599351  
2023-05-26 17:16:05.991: Find a better model.
2023-05-26 17:16:12.467: [iter 36 : loss : 0.2217 = 0.1233 + 0.0959 + 0.0026, time: 6.475394]
2023-05-26 17:16:12.624: epoch 36:	0.02267901  	0.16679229  	0.08641277  
2023-05-26 17:16:12.625: Find a better model.
2023-05-26 17:16:19.047: [iter 37 : loss : 0.2178 = 0.1197 + 0.0955 + 0.0026, time: 6.421436]
2023-05-26 17:16:19.204: epoch 37:	0.02274957  	0.16762532  	0.08684597  
2023-05-26 17:16:19.204: Find a better model.
2023-05-26 17:16:25.664: [iter 38 : loss : 0.2165 = 0.1185 + 0.0953 + 0.0027, time: 6.459006]
2023-05-26 17:16:25.824: epoch 38:	0.02300361  	0.16974261  	0.08761356  
2023-05-26 17:16:25.824: Find a better model.
2023-05-26 17:16:32.398: [iter 39 : loss : 0.2119 = 0.1142 + 0.0949 + 0.0027, time: 6.573004]
2023-05-26 17:16:32.557: epoch 39:	0.02306712  	0.17032199  	0.08814044  
2023-05-26 17:16:32.557: Find a better model.
2023-05-26 17:16:38.842: [iter 40 : loss : 0.2085 = 0.1111 + 0.0946 + 0.0028, time: 6.283035]
2023-05-26 17:16:38.987: epoch 40:	0.02316591  	0.17131597  	0.08862084  
2023-05-26 17:16:38.987: Find a better model.
2023-05-26 17:16:45.411: [iter 41 : loss : 0.2070 = 0.1098 + 0.0944 + 0.0028, time: 6.423004]
2023-05-26 17:16:45.571: epoch 41:	0.02318708  	0.17120029  	0.08892763  
2023-05-26 17:16:51.847: [iter 42 : loss : 0.2047 = 0.1078 + 0.0941 + 0.0029, time: 6.275022]
2023-05-26 17:16:52.002: epoch 42:	0.02320119  	0.17143442  	0.08931787  
2023-05-26 17:16:52.002: Find a better model.
2023-05-26 17:16:58.422: [iter 43 : loss : 0.2010 = 0.1042 + 0.0938 + 0.0029, time: 6.419080]
2023-05-26 17:16:58.583: epoch 43:	0.02328587  	0.17195295  	0.08973392  
2023-05-26 17:16:58.583: Find a better model.
2023-05-26 17:17:04.830: [iter 44 : loss : 0.1973 = 0.1008 + 0.0936 + 0.0030, time: 6.245013]
2023-05-26 17:17:04.973: epoch 44:	0.02339171  	0.17289244  	0.09023273  
2023-05-26 17:17:04.973: Find a better model.
2023-05-26 17:17:11.434: [iter 45 : loss : 0.1952 = 0.0988 + 0.0933 + 0.0030, time: 6.460026]
2023-05-26 17:17:11.583: epoch 45:	0.02352579  	0.17378782  	0.09092207  
2023-05-26 17:17:11.583: Find a better model.
2023-05-26 17:17:17.839: [iter 46 : loss : 0.1928 = 0.0967 + 0.0930 + 0.0031, time: 6.254002]
2023-05-26 17:17:17.995: epoch 46:	0.02358930  	0.17413798  	0.09128740  
2023-05-26 17:17:17.995: Find a better model.
2023-05-26 17:17:24.402: [iter 47 : loss : 0.1922 = 0.0963 + 0.0928 + 0.0031, time: 6.405152]
2023-05-26 17:17:24.563: epoch 47:	0.02367398  	0.17438143  	0.09157982  
2023-05-26 17:17:24.564: Find a better model.
2023-05-26 17:17:31.005: [iter 48 : loss : 0.1883 = 0.0925 + 0.0926 + 0.0032, time: 6.439816]
2023-05-26 17:17:31.160: epoch 48:	0.02374454  	0.17486846  	0.09202965  
2023-05-26 17:17:31.160: Find a better model.
2023-05-26 17:17:37.604: [iter 49 : loss : 0.1852 = 0.0896 + 0.0924 + 0.0032, time: 6.443007]
2023-05-26 17:17:37.747: epoch 49:	0.02388567  	0.17609003  	0.09272396  
2023-05-26 17:17:37.747: Find a better model.
2023-05-26 17:17:44.217: [iter 50 : loss : 0.1846 = 0.0891 + 0.0922 + 0.0033, time: 6.469119]
2023-05-26 17:17:44.373: epoch 50:	0.02396329  	0.17698787  	0.09332760  
2023-05-26 17:17:44.373: Find a better model.
2023-05-26 17:17:50.819: [iter 51 : loss : 0.1813 = 0.0859 + 0.0920 + 0.0033, time: 6.445318]
2023-05-26 17:17:50.975: epoch 51:	0.02408325  	0.17744924  	0.09368711  
2023-05-26 17:17:50.975: Find a better model.
2023-05-26 17:17:57.405: [iter 52 : loss : 0.1811 = 0.0859 + 0.0918 + 0.0034, time: 6.428996]
2023-05-26 17:17:57.564: epoch 52:	0.02416086  	0.17771770  	0.09417638  
2023-05-26 17:17:57.564: Find a better model.
2023-05-26 17:18:03.990: [iter 53 : loss : 0.1793 = 0.0843 + 0.0916 + 0.0034, time: 6.424227]
2023-05-26 17:18:04.134: epoch 53:	0.02433022  	0.17879848  	0.09487104  
2023-05-26 17:18:04.134: Find a better model.
2023-05-26 17:18:10.603: [iter 54 : loss : 0.1771 = 0.0823 + 0.0914 + 0.0035, time: 6.467415]
2023-05-26 17:18:10.757: epoch 54:	0.02440079  	0.17928819  	0.09526451  
2023-05-26 17:18:10.757: Find a better model.
2023-05-26 17:18:17.163: [iter 55 : loss : 0.1753 = 0.0806 + 0.0912 + 0.0035, time: 6.404014]
2023-05-26 17:18:17.316: epoch 55:	0.02453486  	0.18025234  	0.09566356  
2023-05-26 17:18:17.316: Find a better model.
2023-05-26 17:18:23.611: [iter 56 : loss : 0.1734 = 0.0788 + 0.0910 + 0.0035, time: 6.293014]
2023-05-26 17:18:23.764: epoch 56:	0.02460542  	0.18085532  	0.09608176  
2023-05-26 17:18:23.764: Find a better model.
2023-05-26 17:18:30.214: [iter 57 : loss : 0.1717 = 0.0772 + 0.0909 + 0.0036, time: 6.449098]
2023-05-26 17:18:30.357: epoch 57:	0.02480300  	0.18248290  	0.09678154  
2023-05-26 17:18:30.357: Find a better model.
2023-05-26 17:18:36.780: [iter 58 : loss : 0.1697 = 0.0754 + 0.0907 + 0.0036, time: 6.421019]
2023-05-26 17:18:36.938: epoch 58:	0.02481006  	0.18246661  	0.09700285  
2023-05-26 17:18:43.399: [iter 59 : loss : 0.1685 = 0.0744 + 0.0905 + 0.0037, time: 6.460016]
2023-05-26 17:18:43.558: epoch 59:	0.02490884  	0.18311858  	0.09757935  
2023-05-26 17:18:43.558: Find a better model.
2023-05-26 17:18:49.815: [iter 60 : loss : 0.1670 = 0.0729 + 0.0904 + 0.0037, time: 6.256017]
2023-05-26 17:18:49.970: epoch 60:	0.02495824  	0.18366934  	0.09796051  
2023-05-26 17:18:49.970: Find a better model.
2023-05-26 17:18:56.589: [iter 61 : loss : 0.1658 = 0.0719 + 0.0902 + 0.0038, time: 6.616994]
2023-05-26 17:18:56.742: epoch 61:	0.02502174  	0.18423937  	0.09836213  
2023-05-26 17:18:56.742: Find a better model.
2023-05-26 17:19:03.192: [iter 62 : loss : 0.1642 = 0.0704 + 0.0900 + 0.0038, time: 6.449032]
2023-05-26 17:19:03.346: epoch 62:	0.02505702  	0.18448728  	0.09861389  
2023-05-26 17:19:03.346: Find a better model.
2023-05-26 17:19:09.765: [iter 63 : loss : 0.1628 = 0.0691 + 0.0899 + 0.0039, time: 6.416991]
2023-05-26 17:19:09.924: epoch 63:	0.02512053  	0.18477893  	0.09885200  
2023-05-26 17:19:09.924: Find a better model.
2023-05-26 17:19:16.398: [iter 64 : loss : 0.1618 = 0.0682 + 0.0897 + 0.0039, time: 6.473054]
2023-05-26 17:19:16.552: epoch 64:	0.02519110  	0.18531586  	0.09913474  
2023-05-26 17:19:16.553: Find a better model.
2023-05-26 17:19:22.945: [iter 65 : loss : 0.1604 = 0.0670 + 0.0895 + 0.0039, time: 6.388993]
2023-05-26 17:19:23.088: epoch 65:	0.02528989  	0.18582559  	0.09949189  
2023-05-26 17:19:23.089: Find a better model.
2023-05-26 17:19:29.572: [iter 66 : loss : 0.1590 = 0.0656 + 0.0894 + 0.0040, time: 6.481999]
2023-05-26 17:19:29.730: epoch 66:	0.02527577  	0.18600659  	0.09982549  
2023-05-26 17:19:29.730: Find a better model.
2023-05-26 17:19:36.177: [iter 67 : loss : 0.1575 = 0.0642 + 0.0893 + 0.0040, time: 6.446239]
2023-05-26 17:19:36.332: epoch 67:	0.02534634  	0.18650654  	0.10019246  
2023-05-26 17:19:36.332: Find a better model.
2023-05-26 17:19:42.586: [iter 68 : loss : 0.1573 = 0.0641 + 0.0891 + 0.0041, time: 6.252023]
2023-05-26 17:19:42.739: epoch 68:	0.02532517  	0.18634009  	0.10026655  
2023-05-26 17:19:49.197: [iter 69 : loss : 0.1553 = 0.0622 + 0.0890 + 0.0041, time: 6.457010]
2023-05-26 17:19:49.349: epoch 69:	0.02528283  	0.18604864  	0.10030070  
2023-05-26 17:19:55.775: [iter 70 : loss : 0.1535 = 0.0605 + 0.0889 + 0.0042, time: 6.424422]
2023-05-26 17:19:55.932: epoch 70:	0.02533929  	0.18661562  	0.10063095  
2023-05-26 17:19:55.932: Find a better model.
2023-05-26 17:20:02.348: [iter 71 : loss : 0.1523 = 0.0593 + 0.0887 + 0.0042, time: 6.413447]
2023-05-26 17:20:02.507: epoch 71:	0.02540985  	0.18716040  	0.10084125  
2023-05-26 17:20:02.507: Find a better model.
2023-05-26 17:20:08.778: [iter 72 : loss : 0.1519 = 0.0590 + 0.0887 + 0.0042, time: 6.270297]
2023-05-26 17:20:08.932: epoch 72:	0.02548041  	0.18792009  	0.10125958  
2023-05-26 17:20:08.932: Find a better model.
2023-05-26 17:20:15.365: [iter 73 : loss : 0.1506 = 0.0578 + 0.0885 + 0.0043, time: 6.432014]
2023-05-26 17:20:15.519: epoch 73:	0.02556509  	0.18796811  	0.10149755  
2023-05-26 17:20:15.520: Find a better model.
2023-05-26 17:20:21.935: [iter 74 : loss : 0.1491 = 0.0563 + 0.0884 + 0.0043, time: 6.413994]
2023-05-26 17:20:22.078: epoch 74:	0.02565683  	0.18864259  	0.10181564  
2023-05-26 17:20:22.078: Find a better model.
2023-05-26 17:20:28.379: [iter 75 : loss : 0.1486 = 0.0560 + 0.0883 + 0.0044, time: 6.300030]
2023-05-26 17:20:28.523: epoch 75:	0.02564271  	0.18824854  	0.10185554  
2023-05-26 17:20:34.951: [iter 76 : loss : 0.1476 = 0.0550 + 0.0882 + 0.0044, time: 6.427025]
2023-05-26 17:20:35.106: epoch 76:	0.02565683  	0.18863107  	0.10216448  
2023-05-26 17:20:41.526: [iter 77 : loss : 0.1466 = 0.0541 + 0.0880 + 0.0044, time: 6.419274]
2023-05-26 17:20:41.670: epoch 77:	0.02574856  	0.18938510  	0.10247061  
2023-05-26 17:20:41.670: Find a better model.
2023-05-26 17:20:47.959: [iter 78 : loss : 0.1460 = 0.0536 + 0.0880 + 0.0045, time: 6.288023]
2023-05-26 17:20:48.103: epoch 78:	0.02579090  	0.18967761  	0.10286859  
2023-05-26 17:20:48.103: Find a better model.
2023-05-26 17:20:54.534: [iter 79 : loss : 0.1443 = 0.0520 + 0.0878 + 0.0045, time: 6.429004]
2023-05-26 17:20:54.692: epoch 79:	0.02584029  	0.18997407  	0.10317799  
2023-05-26 17:20:54.692: Find a better model.
2023-05-26 17:21:01.097: [iter 80 : loss : 0.1435 = 0.0512 + 0.0878 + 0.0046, time: 6.403004]
2023-05-26 17:21:01.242: epoch 80:	0.02591086  	0.19076154  	0.10348532  
2023-05-26 17:21:01.242: Find a better model.
2023-05-26 17:21:07.550: [iter 81 : loss : 0.1438 = 0.0515 + 0.0877 + 0.0046, time: 6.304076]
2023-05-26 17:21:07.692: epoch 81:	0.02585441  	0.19062573  	0.10364163  
2023-05-26 17:21:13.958: [iter 82 : loss : 0.1421 = 0.0499 + 0.0876 + 0.0046, time: 6.265052]
2023-05-26 17:21:14.114: epoch 82:	0.02591086  	0.19114816  	0.10383965  
2023-05-26 17:21:14.114: Find a better model.
2023-05-26 17:21:20.554: [iter 83 : loss : 0.1413 = 0.0492 + 0.0875 + 0.0047, time: 6.438389]
2023-05-26 17:21:20.698: epoch 83:	0.02589674  	0.19103372  	0.10390976  
2023-05-26 17:21:26.956: [iter 84 : loss : 0.1413 = 0.0492 + 0.0874 + 0.0047, time: 6.256010]
2023-05-26 17:21:27.112: epoch 84:	0.02598848  	0.19168083  	0.10421749  
2023-05-26 17:21:27.112: Find a better model.
2023-05-26 17:21:33.543: [iter 85 : loss : 0.1402 = 0.0482 + 0.0873 + 0.0048, time: 6.430005]
2023-05-26 17:21:33.699: epoch 85:	0.02610138  	0.19230056  	0.10459109  
2023-05-26 17:21:33.699: Find a better model.
2023-05-26 17:21:40.123: [iter 86 : loss : 0.1398 = 0.0478 + 0.0872 + 0.0048, time: 6.423012]
2023-05-26 17:21:40.277: epoch 86:	0.02608021  	0.19241497  	0.10466553  
2023-05-26 17:21:40.277: Find a better model.
2023-05-26 17:21:46.699: [iter 87 : loss : 0.1373 = 0.0453 + 0.0871 + 0.0048, time: 6.421031]
2023-05-26 17:21:46.855: epoch 87:	0.02612255  	0.19297056  	0.10494141  
2023-05-26 17:21:46.855: Find a better model.
2023-05-26 17:21:53.319: [iter 88 : loss : 0.1365 = 0.0446 + 0.0870 + 0.0049, time: 6.462362]
2023-05-26 17:21:53.476: epoch 88:	0.02612961  	0.19322871  	0.10516411  
2023-05-26 17:21:53.477: Find a better model.
2023-05-26 17:21:59.741: [iter 89 : loss : 0.1362 = 0.0444 + 0.0869 + 0.0049, time: 6.263020]
2023-05-26 17:21:59.896: epoch 89:	0.02620017  	0.19358332  	0.10523101  
2023-05-26 17:21:59.896: Find a better model.
2023-05-26 17:22:06.328: [iter 90 : loss : 0.1369 = 0.0451 + 0.0868 + 0.0049, time: 6.431012]
2023-05-26 17:22:06.482: epoch 90:	0.02625662  	0.19409741  	0.10566785  
2023-05-26 17:22:06.482: Find a better model.
2023-05-26 17:22:12.732: [iter 91 : loss : 0.1357 = 0.0440 + 0.0867 + 0.0050, time: 6.248517]
2023-05-26 17:22:12.877: epoch 91:	0.02630601  	0.19423726  	0.10568868  
2023-05-26 17:22:12.877: Find a better model.
2023-05-26 17:22:19.330: [iter 92 : loss : 0.1347 = 0.0431 + 0.0866 + 0.0050, time: 6.451017]
2023-05-26 17:22:19.484: epoch 92:	0.02641186  	0.19518231  	0.10610586  
2023-05-26 17:22:19.484: Find a better model.
2023-05-26 17:22:25.725: [iter 93 : loss : 0.1348 = 0.0431 + 0.0866 + 0.0051, time: 6.239997]
2023-05-26 17:22:25.879: epoch 93:	0.02637657  	0.19489065  	0.10600370  
2023-05-26 17:22:32.326: [iter 94 : loss : 0.1329 = 0.0413 + 0.0865 + 0.0051, time: 6.445019]
2023-05-26 17:22:32.482: epoch 94:	0.02631306  	0.19407007  	0.10604251  
2023-05-26 17:22:38.873: [iter 95 : loss : 0.1323 = 0.0407 + 0.0864 + 0.0051, time: 6.390004]
2023-05-26 17:22:39.028: epoch 95:	0.02639069  	0.19467376  	0.10639199  
2023-05-26 17:22:45.468: [iter 96 : loss : 0.1323 = 0.0407 + 0.0864 + 0.0052, time: 6.439004]
2023-05-26 17:22:45.626: epoch 96:	0.02636952  	0.19462070  	0.10660001  
2023-05-26 17:22:52.080: [iter 97 : loss : 0.1306 = 0.0391 + 0.0863 + 0.0052, time: 6.453156]
2023-05-26 17:22:52.238: epoch 97:	0.02641186  	0.19509977  	0.10657820  
2023-05-26 17:22:58.691: [iter 98 : loss : 0.1314 = 0.0399 + 0.0862 + 0.0052, time: 6.452004]
2023-05-26 17:22:58.845: epoch 98:	0.02642597  	0.19502743  	0.10679405  
2023-05-26 17:23:05.316: [iter 99 : loss : 0.1303 = 0.0388 + 0.0862 + 0.0053, time: 6.470013]
2023-05-26 17:23:05.458: epoch 99:	0.02639068  	0.19468530  	0.10672148  
2023-05-26 17:23:11.720: [iter 100 : loss : 0.1298 = 0.0384 + 0.0861 + 0.0053, time: 6.261040]
2023-05-26 17:23:11.861: epoch 100:	0.02638363  	0.19468419  	0.10680231  
2023-05-26 17:23:18.316: [iter 101 : loss : 0.1293 = 0.0381 + 0.0859 + 0.0053, time: 6.453994]
2023-05-26 17:23:18.459: epoch 101:	0.02641891  	0.19487555  	0.10691471  
2023-05-26 17:23:24.912: [iter 102 : loss : 0.1282 = 0.0370 + 0.0859 + 0.0054, time: 6.451994]
2023-05-26 17:23:25.056: epoch 102:	0.02644009  	0.19494736  	0.10692620  
2023-05-26 17:23:31.482: [iter 103 : loss : 0.1279 = 0.0367 + 0.0858 + 0.0054, time: 6.425256]
2023-05-26 17:23:31.639: epoch 103:	0.02642597  	0.19509485  	0.10695770  
2023-05-26 17:23:38.105: [iter 104 : loss : 0.1284 = 0.0372 + 0.0858 + 0.0054, time: 6.465005]
2023-05-26 17:23:38.260: epoch 104:	0.02649654  	0.19559740  	0.10708794  
2023-05-26 17:23:38.260: Find a better model.
2023-05-26 17:23:44.698: [iter 105 : loss : 0.1278 = 0.0366 + 0.0857 + 0.0055, time: 6.436499]
2023-05-26 17:23:44.840: epoch 105:	0.02651065  	0.19567844  	0.10708613  
2023-05-26 17:23:44.840: Find a better model.
2023-05-26 17:23:51.298: [iter 106 : loss : 0.1272 = 0.0361 + 0.0856 + 0.0055, time: 6.457054]
2023-05-26 17:23:51.453: epoch 106:	0.02653887  	0.19580263  	0.10722138  
2023-05-26 17:23:51.453: Find a better model.
2023-05-26 17:23:57.900: [iter 107 : loss : 0.1264 = 0.0353 + 0.0856 + 0.0055, time: 6.446019]
2023-05-26 17:23:58.054: epoch 107:	0.02653182  	0.19582377  	0.10730898  
2023-05-26 17:23:58.054: Find a better model.
2023-05-26 17:24:04.485: [iter 108 : loss : 0.1261 = 0.0350 + 0.0855 + 0.0056, time: 6.430007]
2023-05-26 17:24:04.642: epoch 108:	0.02658121  	0.19629656  	0.10746341  
2023-05-26 17:24:04.642: Find a better model.
2023-05-26 17:24:11.266: [iter 109 : loss : 0.1247 = 0.0337 + 0.0855 + 0.0056, time: 6.621944]
2023-05-26 17:24:11.421: epoch 109:	0.02658827  	0.19633938  	0.10750378  
2023-05-26 17:24:11.421: Find a better model.
2023-05-26 17:24:17.897: [iter 110 : loss : 0.1242 = 0.0331 + 0.0854 + 0.0056, time: 6.475050]
2023-05-26 17:24:18.055: epoch 110:	0.02661650  	0.19632374  	0.10750835  
2023-05-26 17:24:24.463: [iter 111 : loss : 0.1242 = 0.0332 + 0.0853 + 0.0057, time: 6.406999]
2023-05-26 17:24:24.620: epoch 111:	0.02653888  	0.19569229  	0.10745042  
2023-05-26 17:24:31.091: [iter 112 : loss : 0.1239 = 0.0329 + 0.0853 + 0.0057, time: 6.470025]
2023-05-26 17:24:31.246: epoch 112:	0.02662355  	0.19624893  	0.10764587  
2023-05-26 17:24:37.681: [iter 113 : loss : 0.1237 = 0.0327 + 0.0853 + 0.0057, time: 6.433561]
2023-05-26 17:24:37.837: epoch 113:	0.02668001  	0.19666705  	0.10779707  
2023-05-26 17:24:37.837: Find a better model.
2023-05-26 17:24:44.280: [iter 114 : loss : 0.1229 = 0.0320 + 0.0852 + 0.0058, time: 6.440994]
2023-05-26 17:24:44.423: epoch 114:	0.02662355  	0.19630484  	0.10773810  
2023-05-26 17:24:50.867: [iter 115 : loss : 0.1226 = 0.0316 + 0.0851 + 0.0058, time: 6.441997]
2023-05-26 17:24:51.020: epoch 115:	0.02659533  	0.19634902  	0.10775828  
2023-05-26 17:24:57.485: [iter 116 : loss : 0.1217 = 0.0308 + 0.0851 + 0.0058, time: 6.463004]
2023-05-26 17:24:57.642: epoch 116:	0.02663767  	0.19654520  	0.10780865  
2023-05-26 17:25:04.062: [iter 117 : loss : 0.1216 = 0.0307 + 0.0850 + 0.0059, time: 6.419003]
2023-05-26 17:25:04.217: epoch 117:	0.02661650  	0.19641215  	0.10779928  
2023-05-26 17:25:10.665: [iter 118 : loss : 0.1214 = 0.0306 + 0.0849 + 0.0059, time: 6.446020]
2023-05-26 17:25:10.822: epoch 118:	0.02669412  	0.19693309  	0.10806561  
2023-05-26 17:25:10.823: Find a better model.
2023-05-26 17:25:17.257: [iter 119 : loss : 0.1205 = 0.0296 + 0.0849 + 0.0059, time: 6.432324]
2023-05-26 17:25:17.415: epoch 119:	0.02666589  	0.19661909  	0.10809894  
2023-05-26 17:25:23.851: [iter 120 : loss : 0.1209 = 0.0301 + 0.0849 + 0.0060, time: 6.434013]
2023-05-26 17:25:24.006: epoch 120:	0.02666590  	0.19661677  	0.10817327  
2023-05-26 17:25:30.452: [iter 121 : loss : 0.1208 = 0.0300 + 0.0848 + 0.0060, time: 6.445020]
2023-05-26 17:25:30.607: epoch 121:	0.02667296  	0.19680065  	0.10823669  
2023-05-26 17:25:37.037: [iter 122 : loss : 0.1198 = 0.0290 + 0.0848 + 0.0060, time: 6.428011]
2023-05-26 17:25:37.191: epoch 122:	0.02664473  	0.19647412  	0.10815858  
2023-05-26 17:25:43.638: [iter 123 : loss : 0.1199 = 0.0291 + 0.0847 + 0.0061, time: 6.445068]
2023-05-26 17:25:43.781: epoch 123:	0.02675763  	0.19731086  	0.10842107  
2023-05-26 17:25:43.782: Find a better model.
2023-05-26 17:25:50.259: [iter 124 : loss : 0.1190 = 0.0283 + 0.0847 + 0.0061, time: 6.476024]
2023-05-26 17:25:50.414: epoch 124:	0.02669413  	0.19664858  	0.10830648  
2023-05-26 17:25:56.838: [iter 125 : loss : 0.1184 = 0.0277 + 0.0846 + 0.0061, time: 6.422065]
2023-05-26 17:25:56.995: epoch 125:	0.02668001  	0.19625616  	0.10827687  
2023-05-26 17:26:03.451: [iter 126 : loss : 0.1186 = 0.0279 + 0.0846 + 0.0061, time: 6.455052]
2023-05-26 17:26:03.609: epoch 126:	0.02665884  	0.19617578  	0.10808047  
2023-05-26 17:26:10.040: [iter 127 : loss : 0.1178 = 0.0271 + 0.0846 + 0.0062, time: 6.430010]
2023-05-26 17:26:10.193: epoch 127:	0.02668001  	0.19658385  	0.10806581  
2023-05-26 17:26:16.658: [iter 128 : loss : 0.1185 = 0.0278 + 0.0845 + 0.0062, time: 6.463023]
2023-05-26 17:26:16.812: epoch 128:	0.02665884  	0.19621740  	0.10810555  
2023-05-26 17:26:23.254: [iter 129 : loss : 0.1179 = 0.0272 + 0.0845 + 0.0062, time: 6.439994]
2023-05-26 17:26:23.398: epoch 129:	0.02669413  	0.19635423  	0.10822184  
2023-05-26 17:26:29.832: [iter 130 : loss : 0.1178 = 0.0272 + 0.0844 + 0.0063, time: 6.432465]
2023-05-26 17:26:29.976: epoch 130:	0.02675058  	0.19690000  	0.10843254  
2023-05-26 17:26:36.412: [iter 131 : loss : 0.1170 = 0.0263 + 0.0844 + 0.0063, time: 6.434553]
2023-05-26 17:26:36.561: epoch 131:	0.02670824  	0.19650425  	0.10845979  
2023-05-26 17:26:42.837: [iter 132 : loss : 0.1173 = 0.0266 + 0.0843 + 0.0063, time: 6.275209]
2023-05-26 17:26:42.996: epoch 132:	0.02664473  	0.19564284  	0.10828152  
2023-05-26 17:26:49.433: [iter 133 : loss : 0.1159 = 0.0252 + 0.0843 + 0.0064, time: 6.434996]
2023-05-26 17:26:49.589: epoch 133:	0.02663062  	0.19578202  	0.10858161  
2023-05-26 17:26:56.026: [iter 134 : loss : 0.1167 = 0.0261 + 0.0842 + 0.0064, time: 6.433325]
2023-05-26 17:26:56.181: epoch 134:	0.02665884  	0.19597273  	0.10848545  
2023-05-26 17:27:02.604: [iter 135 : loss : 0.1164 = 0.0257 + 0.0842 + 0.0064, time: 6.421993]
2023-05-26 17:27:02.751: epoch 135:	0.02670823  	0.19600044  	0.10859819  
2023-05-26 17:27:09.211: [iter 136 : loss : 0.1159 = 0.0253 + 0.0842 + 0.0064, time: 6.459058]
2023-05-26 17:27:09.366: epoch 136:	0.02668001  	0.19578217  	0.10852530  
2023-05-26 17:27:15.802: [iter 137 : loss : 0.1155 = 0.0249 + 0.0841 + 0.0065, time: 6.434021]
2023-05-26 17:27:15.962: epoch 137:	0.02666589  	0.19579622  	0.10850549  
2023-05-26 17:27:22.420: [iter 138 : loss : 0.1154 = 0.0248 + 0.0841 + 0.0065, time: 6.455994]
2023-05-26 17:27:22.583: epoch 138:	0.02673646  	0.19628543  	0.10885467  
2023-05-26 17:27:29.004: [iter 139 : loss : 0.1153 = 0.0247 + 0.0840 + 0.0065, time: 6.420015]
2023-05-26 17:27:29.159: epoch 139:	0.02665884  	0.19566189  	0.10860722  
2023-05-26 17:27:35.609: [iter 140 : loss : 0.1145 = 0.0239 + 0.0840 + 0.0066, time: 6.449042]
2023-05-26 17:27:35.764: epoch 140:	0.02669412  	0.19592404  	0.10871992  
2023-05-26 17:27:42.203: [iter 141 : loss : 0.1151 = 0.0245 + 0.0840 + 0.0066, time: 6.438015]
2023-05-26 17:27:42.357: epoch 141:	0.02665178  	0.19573762  	0.10868403  
2023-05-26 17:27:48.802: [iter 142 : loss : 0.1141 = 0.0235 + 0.0839 + 0.0066, time: 6.442014]
2023-05-26 17:27:48.955: epoch 142:	0.02664472  	0.19544850  	0.10860745  
2023-05-26 17:27:55.375: [iter 143 : loss : 0.1142 = 0.0236 + 0.0839 + 0.0066, time: 6.418004]
2023-05-26 17:27:55.531: epoch 143:	0.02664472  	0.19548732  	0.10873081  
2023-05-26 17:28:01.980: [iter 144 : loss : 0.1135 = 0.0229 + 0.0839 + 0.0067, time: 6.446459]
2023-05-26 17:28:02.134: epoch 144:	0.02663766  	0.19518413  	0.10862974  
2023-05-26 17:28:08.567: [iter 145 : loss : 0.1134 = 0.0228 + 0.0838 + 0.0067, time: 6.432022]
2023-05-26 17:28:08.723: epoch 145:	0.02661649  	0.19516549  	0.10865180  
2023-05-26 17:28:15.021: [iter 146 : loss : 0.1139 = 0.0234 + 0.0838 + 0.0067, time: 6.297004]
2023-05-26 17:28:15.166: epoch 146:	0.02660944  	0.19517651  	0.10867299  
2023-05-26 17:28:21.412: [iter 147 : loss : 0.1136 = 0.0230 + 0.0838 + 0.0067, time: 6.244456]
2023-05-26 17:28:21.570: epoch 147:	0.02665883  	0.19545108  	0.10889763  
2023-05-26 17:28:27.800: [iter 148 : loss : 0.1124 = 0.0219 + 0.0837 + 0.0068, time: 6.229010]
2023-05-26 17:28:27.955: epoch 148:	0.02664473  	0.19543326  	0.10896697  
2023-05-26 17:28:27.955: Early stopping is trigger at epoch: 148
2023-05-26 17:28:27.955: best_result@epoch 123:

2023-05-26 17:28:27.955: 		0.0268      	0.1973      	0.1084      
2023-05-26 17:59:47.882: my pid: 14936
2023-05-26 17:59:47.882: model: model.general_recommender.SGL
2023-05-26 17:59:47.882: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 17:59:47.882: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 17:59:51.491: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 17:59:58.810: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.319047]
2023-05-26 17:59:58.955: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-26 17:59:58.955: Find a better model.
2023-05-26 18:00:06.378: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.422032]
2023-05-26 18:00:06.584: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-26 18:00:06.584: Find a better model.
2023-05-26 18:00:13.979: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.394035]
2023-05-26 18:00:14.142: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-26 18:00:14.143: Find a better model.
2023-05-26 18:00:21.374: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.229473]
2023-05-26 18:00:21.537: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-26 18:00:21.537: Find a better model.
2023-05-26 18:00:28.581: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.041013]
2023-05-26 18:00:28.727: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-26 18:00:28.727: Find a better model.
2023-05-26 18:00:35.566: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 6.838043]
2023-05-26 18:00:35.722: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-26 18:00:35.722: Find a better model.
2023-05-26 18:00:42.521: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.797009]
2023-05-26 18:00:42.673: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-26 18:00:42.673: Find a better model.
2023-05-26 18:00:49.354: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.679379]
2023-05-26 18:00:49.508: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-26 18:00:49.508: Find a better model.
2023-05-26 18:00:56.136: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.626006]
2023-05-26 18:00:56.287: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-26 18:00:56.287: Find a better model.
2023-05-26 18:01:02.957: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.668486]
2023-05-26 18:01:03.106: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-26 18:01:03.106: Find a better model.
2023-05-26 18:01:09.721: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.612145]
2023-05-26 18:01:09.877: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-26 18:01:09.877: Find a better model.
2023-05-26 18:01:16.332: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.453126]
2023-05-26 18:01:16.486: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-26 18:01:16.486: Find a better model.
2023-05-26 18:01:22.947: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.459996]
2023-05-26 18:01:23.101: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-26 18:01:23.101: Find a better model.
2023-05-26 18:01:29.550: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.447001]
2023-05-26 18:01:29.702: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-26 18:01:29.702: Find a better model.
2023-05-26 18:01:36.148: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.445007]
2023-05-26 18:01:36.302: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-26 18:01:42.735: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.431464]
2023-05-26 18:01:42.877: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-26 18:01:42.877: Find a better model.
2023-05-26 18:01:49.327: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.449086]
2023-05-26 18:01:49.480: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-26 18:01:49.480: Find a better model.
2023-05-26 18:01:55.928: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.446998]
2023-05-26 18:01:56.073: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-26 18:01:56.073: Find a better model.
2023-05-26 18:02:02.536: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.462028]
2023-05-26 18:02:02.690: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-26 18:02:02.690: Find a better model.
2023-05-26 18:02:09.133: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.442049]
2023-05-26 18:02:09.288: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-26 18:02:09.288: Find a better model.
2023-05-26 18:02:15.901: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.612003]
2023-05-26 18:02:16.047: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-26 18:02:16.047: Find a better model.
2023-05-26 18:02:22.492: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.444018]
2023-05-26 18:02:22.632: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-26 18:02:22.632: Find a better model.
2023-05-26 18:02:29.120: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.486005]
2023-05-26 18:02:29.263: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-26 18:02:29.263: Find a better model.
2023-05-26 18:02:35.909: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.644010]
2023-05-26 18:02:36.067: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-26 18:02:36.067: Find a better model.
2023-05-26 18:02:42.511: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.443227]
2023-05-26 18:02:42.654: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-26 18:02:42.654: Find a better model.
2023-05-26 18:02:49.305: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.650158]
2023-05-26 18:02:49.459: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-26 18:02:49.459: Find a better model.
2023-05-26 18:02:55.909: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.449013]
2023-05-26 18:02:56.067: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-26 18:02:56.067: Find a better model.
2023-05-26 18:03:02.699: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.630455]
2023-05-26 18:03:02.855: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-26 18:03:02.855: Find a better model.
2023-05-26 18:03:09.488: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.632032]
2023-05-26 18:03:09.641: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-26 18:03:09.641: Find a better model.
2023-05-26 18:03:16.096: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.454003]
2023-05-26 18:03:16.250: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-26 18:03:16.251: Find a better model.
2023-05-26 18:03:22.717: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.465018]
2023-05-26 18:03:22.860: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-26 18:03:22.860: Find a better model.
2023-05-26 18:03:29.293: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.432032]
2023-05-26 18:03:29.435: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-26 18:03:29.435: Find a better model.
2023-05-26 18:03:36.082: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.645491]
2023-05-26 18:03:36.237: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-26 18:03:36.237: Find a better model.
2023-05-26 18:03:42.865: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.627074]
2023-05-26 18:03:43.011: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-26 18:03:43.011: Find a better model.
2023-05-26 18:03:49.501: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.486994]
2023-05-26 18:03:49.657: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-26 18:03:49.657: Find a better model.
2023-05-26 18:03:56.264: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.605953]
2023-05-26 18:03:56.408: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-26 18:03:56.408: Find a better model.
2023-05-26 18:04:03.080: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.669286]
2023-05-26 18:04:03.233: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-26 18:04:03.233: Find a better model.
2023-05-26 18:04:09.843: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.609014]
2023-05-26 18:04:09.986: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-26 18:04:09.986: Find a better model.
2023-05-26 18:04:16.491: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.504024]
2023-05-26 18:04:16.645: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-26 18:04:16.645: Find a better model.
2023-05-26 18:04:23.274: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.628003]
2023-05-26 18:04:23.427: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-26 18:04:23.427: Find a better model.
2023-05-26 18:04:29.885: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.457471]
2023-05-26 18:04:30.043: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-26 18:04:30.043: Find a better model.
2023-05-26 18:04:36.486: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.441074]
2023-05-26 18:04:36.639: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-26 18:04:36.639: Find a better model.
2023-05-26 18:04:43.259: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.619120]
2023-05-26 18:04:43.414: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-26 18:04:43.414: Find a better model.
2023-05-26 18:04:50.068: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.653004]
2023-05-26 18:04:50.221: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-26 18:04:50.222: Find a better model.
2023-05-26 18:04:56.862: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.638519]
2023-05-26 18:04:57.020: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-26 18:04:57.020: Find a better model.
2023-05-26 18:05:03.465: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.444004]
2023-05-26 18:05:03.621: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-26 18:05:03.621: Find a better model.
2023-05-26 18:05:10.065: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.443015]
2023-05-26 18:05:10.219: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-26 18:05:10.219: Find a better model.
2023-05-26 18:05:16.836: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.614029]
2023-05-26 18:05:16.988: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-26 18:05:16.988: Find a better model.
2023-05-26 18:05:23.459: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.470005]
2023-05-26 18:05:23.612: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-26 18:05:30.247: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.633031]
2023-05-26 18:05:30.401: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-26 18:05:30.401: Find a better model.
2023-05-26 18:05:36.867: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.465025]
2023-05-26 18:05:37.027: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-26 18:05:37.027: Find a better model.
2023-05-26 18:05:43.637: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.608028]
2023-05-26 18:05:43.789: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-26 18:05:43.789: Find a better model.
2023-05-26 18:05:50.263: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.471026]
2023-05-26 18:05:50.415: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-26 18:05:50.415: Find a better model.
2023-05-26 18:05:57.030: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.614004]
2023-05-26 18:05:57.185: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-26 18:05:57.185: Find a better model.
2023-05-26 18:06:03.636: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.450016]
2023-05-26 18:06:03.778: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-26 18:06:10.240: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.461008]
2023-05-26 18:06:10.394: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-26 18:06:10.394: Find a better model.
2023-05-26 18:06:17.045: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.650017]
2023-05-26 18:06:17.186: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-26 18:06:17.186: Find a better model.
2023-05-26 18:06:23.645: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.457005]
2023-05-26 18:06:23.800: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-26 18:06:30.437: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.636553]
2023-05-26 18:06:30.593: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-26 18:06:30.593: Find a better model.
2023-05-26 18:06:37.234: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.639997]
2023-05-26 18:06:37.388: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-26 18:06:37.388: Find a better model.
2023-05-26 18:06:44.034: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.645018]
2023-05-26 18:06:44.190: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-26 18:06:44.190: Find a better model.
2023-05-26 18:06:50.843: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.651008]
2023-05-26 18:06:50.996: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-26 18:06:50.996: Find a better model.
2023-05-26 18:06:57.642: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.645006]
2023-05-26 18:06:57.799: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-26 18:06:57.799: Find a better model.
2023-05-26 18:07:04.419: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.619093]
2023-05-26 18:07:04.561: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-26 18:07:04.561: Find a better model.
2023-05-26 18:07:11.023: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.461500]
2023-05-26 18:07:11.178: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-26 18:07:11.178: Find a better model.
2023-05-26 18:07:17.789: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.609595]
2023-05-26 18:07:17.944: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-26 18:07:17.944: Find a better model.
2023-05-26 18:07:24.588: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.643016]
2023-05-26 18:07:24.740: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-26 18:07:31.234: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.492089]
2023-05-26 18:07:31.386: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-26 18:07:31.386: Find a better model.
2023-05-26 18:07:38.017: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.630017]
2023-05-26 18:07:38.172: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-26 18:07:38.172: Find a better model.
2023-05-26 18:07:44.813: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.640016]
2023-05-26 18:07:44.965: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-26 18:07:44.965: Find a better model.
2023-05-26 18:07:51.422: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.456039]
2023-05-26 18:07:51.575: epoch 71:	0.02632721  	0.19467905  	0.10684208  
2023-05-26 18:07:51.575: Find a better model.
2023-05-26 18:07:57.984: [iter 72 : loss : 0.2190 = 0.0478 + 0.1664 + 0.0048, time: 6.408006]
2023-05-26 18:07:58.127: epoch 72:	0.02639778  	0.19526137  	0.10706843  
2023-05-26 18:07:58.127: Find a better model.
2023-05-26 18:08:04.601: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.473042]
2023-05-26 18:08:04.743: epoch 73:	0.02641189  	0.19549032  	0.10711851  
2023-05-26 18:08:04.743: Find a better model.
2023-05-26 18:08:11.203: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.459021]
2023-05-26 18:08:11.357: epoch 74:	0.02646128  	0.19566278  	0.10750105  
2023-05-26 18:08:11.357: Find a better model.
2023-05-26 18:08:17.808: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.448020]
2023-05-26 18:08:17.962: epoch 75:	0.02654596  	0.19655427  	0.10756438  
2023-05-26 18:08:17.962: Find a better model.
2023-05-26 18:08:24.423: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.459994]
2023-05-26 18:08:24.566: epoch 76:	0.02658124  	0.19694291  	0.10773618  
2023-05-26 18:08:24.567: Find a better model.
2023-05-26 18:08:30.997: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.428520]
2023-05-26 18:08:31.139: epoch 77:	0.02659536  	0.19693758  	0.10767362  
2023-05-26 18:08:37.778: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.638422]
2023-05-26 18:08:37.919: epoch 78:	0.02667298  	0.19745006  	0.10793771  
2023-05-26 18:08:37.919: Find a better model.
2023-05-26 18:08:44.365: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.445378]
2023-05-26 18:08:44.507: epoch 79:	0.02668003  	0.19723570  	0.10796165  
2023-05-26 18:08:51.157: [iter 80 : loss : 0.2113 = 0.0410 + 0.1652 + 0.0051, time: 6.648918]
2023-05-26 18:08:51.310: epoch 80:	0.02660241  	0.19668077  	0.10794093  
2023-05-26 18:08:57.946: [iter 81 : loss : 0.2110 = 0.0408 + 0.1650 + 0.0052, time: 6.635004]
2023-05-26 18:08:58.089: epoch 81:	0.02660241  	0.19662951  	0.10788923  
2023-05-26 18:09:04.587: [iter 82 : loss : 0.2099 = 0.0398 + 0.1649 + 0.0052, time: 6.496009]
2023-05-26 18:09:04.739: epoch 82:	0.02649656  	0.19609496  	0.10785156  
2023-05-26 18:09:11.207: [iter 83 : loss : 0.2090 = 0.0390 + 0.1648 + 0.0053, time: 6.466014]
2023-05-26 18:09:11.359: epoch 83:	0.02653890  	0.19600566  	0.10790281  
2023-05-26 18:09:17.965: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.604096]
2023-05-26 18:09:18.118: epoch 84:	0.02667298  	0.19690226  	0.10819490  
2023-05-26 18:09:24.584: [iter 85 : loss : 0.2081 = 0.0382 + 0.1645 + 0.0053, time: 6.465053]
2023-05-26 18:09:24.738: epoch 85:	0.02675060  	0.19757095  	0.10846379  
2023-05-26 18:09:24.738: Find a better model.
2023-05-26 18:09:31.368: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.628320]
2023-05-26 18:09:31.521: epoch 86:	0.02669415  	0.19715470  	0.10848830  
2023-05-26 18:09:38.156: [iter 87 : loss : 0.2057 = 0.0359 + 0.1643 + 0.0054, time: 6.632981]
2023-05-26 18:09:38.309: epoch 87:	0.02686350  	0.19811502  	0.10885072  
2023-05-26 18:09:38.309: Find a better model.
2023-05-26 18:09:44.766: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.456299]
2023-05-26 18:09:44.907: epoch 88:	0.02678588  	0.19745855  	0.10858166  
2023-05-26 18:09:51.542: [iter 89 : loss : 0.2045 = 0.0349 + 0.1640 + 0.0055, time: 6.633003]
2023-05-26 18:09:51.694: epoch 89:	0.02673648  	0.19694941  	0.10849094  
2023-05-26 18:09:58.346: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.649505]
2023-05-26 18:09:58.500: epoch 90:	0.02682822  	0.19769356  	0.10869770  
2023-05-26 18:10:05.136: [iter 91 : loss : 0.2039 = 0.0346 + 0.1638 + 0.0056, time: 6.633994]
2023-05-26 18:10:05.290: epoch 91:	0.02691289  	0.19807483  	0.10884054  
2023-05-26 18:10:11.961: [iter 92 : loss : 0.2028 = 0.0334 + 0.1637 + 0.0056, time: 6.670569]
2023-05-26 18:10:12.117: epoch 92:	0.02691289  	0.19834703  	0.10895094  
2023-05-26 18:10:12.117: Find a better model.
2023-05-26 18:10:18.775: [iter 93 : loss : 0.2033 = 0.0340 + 0.1636 + 0.0057, time: 6.657110]
2023-05-26 18:10:18.931: epoch 93:	0.02688467  	0.19837846  	0.10883533  
2023-05-26 18:10:18.931: Find a better model.
2023-05-26 18:10:25.544: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.612004]
2023-05-26 18:10:25.699: epoch 94:	0.02689878  	0.19840631  	0.10900953  
2023-05-26 18:10:25.699: Find a better model.
2023-05-26 18:10:32.339: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.639611]
2023-05-26 18:10:32.494: epoch 95:	0.02692701  	0.19853988  	0.10915195  
2023-05-26 18:10:32.494: Find a better model.
2023-05-26 18:10:39.164: [iter 96 : loss : 0.2009 = 0.0318 + 0.1633 + 0.0058, time: 6.669195]
2023-05-26 18:10:39.317: epoch 96:	0.02686350  	0.19797775  	0.10893095  
2023-05-26 18:10:45.959: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.641044]
2023-05-26 18:10:46.115: epoch 97:	0.02694112  	0.19834363  	0.10928166  
2023-05-26 18:10:52.727: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.611041]
2023-05-26 18:10:52.879: epoch 98:	0.02694818  	0.19854747  	0.10942093  
2023-05-26 18:10:52.879: Find a better model.
2023-05-26 18:10:59.354: [iter 99 : loss : 0.1991 = 0.0301 + 0.1630 + 0.0059, time: 6.474012]
2023-05-26 18:10:59.506: epoch 99:	0.02703285  	0.19904999  	0.10957264  
2023-05-26 18:10:59.506: Find a better model.
2023-05-26 18:11:06.122: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.615025]
2023-05-26 18:11:06.277: epoch 100:	0.02705402  	0.19908023  	0.10961760  
2023-05-26 18:11:06.277: Find a better model.
2023-05-26 18:11:12.945: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.667043]
2023-05-26 18:11:13.100: epoch 101:	0.02705401  	0.19917580  	0.10956462  
2023-05-26 18:11:13.100: Find a better model.
2023-05-26 18:11:19.746: [iter 102 : loss : 0.1974 = 0.0287 + 0.1627 + 0.0061, time: 6.645009]
2023-05-26 18:11:19.889: epoch 102:	0.02708929  	0.19923764  	0.10959043  
2023-05-26 18:11:19.889: Find a better model.
2023-05-26 18:11:26.525: [iter 103 : loss : 0.1972 = 0.0285 + 0.1626 + 0.0061, time: 6.634357]
2023-05-26 18:11:26.677: epoch 103:	0.02707519  	0.19948873  	0.10976166  
2023-05-26 18:11:26.677: Find a better model.
2023-05-26 18:11:33.340: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.662017]
2023-05-26 18:11:33.495: epoch 104:	0.02704696  	0.19932652  	0.10971819  
2023-05-26 18:11:40.130: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.634355]
2023-05-26 18:11:40.282: epoch 105:	0.02699051  	0.19933046  	0.10973314  
2023-05-26 18:11:46.917: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.633022]
2023-05-26 18:11:47.062: epoch 106:	0.02701167  	0.19937827  	0.10981102  
2023-05-26 18:11:53.737: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.673514]
2023-05-26 18:11:53.892: epoch 107:	0.02706813  	0.19989811  	0.11013356  
2023-05-26 18:11:53.892: Find a better model.
2023-05-26 18:12:00.532: [iter 108 : loss : 0.1954 = 0.0268 + 0.1623 + 0.0063, time: 6.639315]
2023-05-26 18:12:00.674: epoch 108:	0.02700462  	0.19952522  	0.10990442  
2023-05-26 18:12:07.351: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.675007]
2023-05-26 18:12:07.504: epoch 109:	0.02704696  	0.20016053  	0.10989905  
2023-05-26 18:12:07.505: Find a better model.
2023-05-26 18:12:14.120: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.613220]
2023-05-26 18:12:14.272: epoch 110:	0.02701874  	0.20001934  	0.11001527  
2023-05-26 18:12:20.927: [iter 111 : loss : 0.1938 = 0.0254 + 0.1621 + 0.0064, time: 6.653009]
2023-05-26 18:12:21.084: epoch 111:	0.02700462  	0.19943477  	0.10989597  
2023-05-26 18:12:27.883: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.798117]
2023-05-26 18:12:28.040: epoch 112:	0.02703285  	0.19921325  	0.10984495  
2023-05-26 18:12:34.702: [iter 113 : loss : 0.1936 = 0.0252 + 0.1619 + 0.0065, time: 6.661144]
2023-05-26 18:12:34.842: epoch 113:	0.02703991  	0.19920979  	0.10981870  
2023-05-26 18:12:41.519: [iter 114 : loss : 0.1928 = 0.0245 + 0.1619 + 0.0065, time: 6.674006]
2023-05-26 18:12:41.674: epoch 114:	0.02713164  	0.19981673  	0.11002791  
2023-05-26 18:12:48.302: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.627167]
2023-05-26 18:12:48.454: epoch 115:	0.02708224  	0.19955315  	0.10994995  
2023-05-26 18:12:55.095: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.639006]
2023-05-26 18:12:55.248: epoch 116:	0.02704696  	0.19898276  	0.10995645  
2023-05-26 18:13:01.893: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.643145]
2023-05-26 18:13:02.049: epoch 117:	0.02699050  	0.19892606  	0.10984875  
2023-05-26 18:13:08.699: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.649038]
2023-05-26 18:13:08.852: epoch 118:	0.02698344  	0.19834651  	0.10981710  
2023-05-26 18:13:15.492: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.639004]
2023-05-26 18:13:15.644: epoch 119:	0.02701873  	0.19867659  	0.10980324  
2023-05-26 18:13:22.303: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.658145]
2023-05-26 18:13:22.457: epoch 120:	0.02701167  	0.19857386  	0.10987627  
2023-05-26 18:13:29.269: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.811021]
2023-05-26 18:13:29.423: epoch 121:	0.02700462  	0.19842827  	0.10991929  
2023-05-26 18:13:36.093: [iter 122 : loss : 0.1906 = 0.0224 + 0.1614 + 0.0068, time: 6.669011]
2023-05-26 18:13:36.237: epoch 122:	0.02694816  	0.19816545  	0.10981948  
2023-05-26 18:13:42.880: [iter 123 : loss : 0.1904 = 0.0223 + 0.1613 + 0.0068, time: 6.642009]
2023-05-26 18:13:43.037: epoch 123:	0.02695522  	0.19808462  	0.10980198  
2023-05-26 18:13:49.478: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.439014]
2023-05-26 18:13:49.620: epoch 124:	0.02696933  	0.19822593  	0.10990788  
2023-05-26 18:13:56.261: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.639023]
2023-05-26 18:13:56.416: epoch 125:	0.02702578  	0.19851798  	0.10997351  
2023-05-26 18:14:03.052: [iter 126 : loss : 0.1893 = 0.0213 + 0.1612 + 0.0069, time: 6.635013]
2023-05-26 18:14:03.194: epoch 126:	0.02692699  	0.19814073  	0.10991263  
2023-05-26 18:14:09.877: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.682074]
2023-05-26 18:14:10.036: epoch 127:	0.02687760  	0.19777001  	0.10988648  
2023-05-26 18:14:16.667: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.629440]
2023-05-26 18:14:16.809: epoch 128:	0.02695521  	0.19816811  	0.10989755  
2023-05-26 18:14:23.255: [iter 129 : loss : 0.1885 = 0.0205 + 0.1611 + 0.0070, time: 6.445994]
2023-05-26 18:14:23.396: epoch 129:	0.02695522  	0.19814949  	0.10989751  
2023-05-26 18:14:29.877: [iter 130 : loss : 0.1886 = 0.0206 + 0.1610 + 0.0070, time: 6.478503]
2023-05-26 18:14:30.035: epoch 130:	0.02688465  	0.19776551  	0.10980804  
2023-05-26 18:14:36.642: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.605949]
2023-05-26 18:14:36.797: epoch 131:	0.02694111  	0.19801711  	0.10991438  
2023-05-26 18:14:43.441: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.643046]
2023-05-26 18:14:43.596: epoch 132:	0.02689877  	0.19782066  	0.10988849  
2023-05-26 18:14:50.258: [iter 133 : loss : 0.1871 = 0.0191 + 0.1609 + 0.0071, time: 6.659003]
2023-05-26 18:14:50.411: epoch 133:	0.02697638  	0.19819023  	0.10998309  
2023-05-26 18:14:57.044: [iter 134 : loss : 0.1876 = 0.0197 + 0.1608 + 0.0071, time: 6.631986]
2023-05-26 18:14:57.197: epoch 134:	0.02691288  	0.19745693  	0.10976485  
2023-05-26 18:14:57.197: Early stopping is trigger at epoch: 134
2023-05-26 18:14:57.197: best_result@epoch 109:

2023-05-26 18:14:57.197: 		0.0270      	0.2002      	0.1099      
2023-05-26 18:45:11.507: my pid: 15944
2023-05-26 18:45:11.507: model: model.general_recommender.SGL
2023-05-26 18:45:11.507: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 18:45:11.507: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 18:45:15.188: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 18:45:22.481: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.292511]
2023-05-26 18:45:22.637: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-26 18:45:22.638: Find a better model.
2023-05-26 18:45:30.047: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.408441]
2023-05-26 18:45:30.251: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-26 18:45:30.251: Find a better model.
2023-05-26 18:45:37.713: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.460416]
2023-05-26 18:45:37.887: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-26 18:45:37.887: Find a better model.
2023-05-26 18:45:45.062: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.173211]
2023-05-26 18:45:45.225: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-26 18:45:45.225: Find a better model.
2023-05-26 18:45:52.252: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.025046]
2023-05-26 18:45:52.412: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-26 18:45:52.412: Find a better model.
2023-05-26 18:45:59.415: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 7.002034]
2023-05-26 18:45:59.571: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-26 18:45:59.571: Find a better model.
2023-05-26 18:46:06.412: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.840021]
2023-05-26 18:46:06.567: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-26 18:46:06.567: Find a better model.
2023-05-26 18:46:13.231: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.662008]
2023-05-26 18:46:13.382: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-26 18:46:13.382: Find a better model.
2023-05-26 18:46:20.017: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.634014]
2023-05-26 18:46:20.169: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-26 18:46:20.169: Find a better model.
2023-05-26 18:46:26.815: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.643566]
2023-05-26 18:46:26.967: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-26 18:46:26.967: Find a better model.
2023-05-26 18:46:33.586: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.618008]
2023-05-26 18:46:33.727: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-26 18:46:33.727: Find a better model.
2023-05-26 18:46:40.208: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.478443]
2023-05-26 18:46:40.360: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-26 18:46:40.360: Find a better model.
2023-05-26 18:46:46.986: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.625231]
2023-05-26 18:46:47.130: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-26 18:46:47.130: Find a better model.
2023-05-26 18:46:53.776: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.644354]
2023-05-26 18:46:53.931: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-26 18:46:53.931: Find a better model.
2023-05-26 18:47:00.404: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.472290]
2023-05-26 18:47:00.549: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-26 18:47:00.549: Find a better model.
2023-05-26 18:47:07.190: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.640164]
2023-05-26 18:47:07.346: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-26 18:47:07.346: Find a better model.
2023-05-26 18:47:13.803: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.456007]
2023-05-26 18:47:13.955: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-26 18:47:13.955: Find a better model.
2023-05-26 18:47:20.400: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.443115]
2023-05-26 18:47:20.543: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-26 18:47:20.543: Find a better model.
2023-05-26 18:47:27.010: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.465002]
2023-05-26 18:47:27.164: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-26 18:47:27.164: Find a better model.
2023-05-26 18:47:33.585: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.420102]
2023-05-26 18:47:33.738: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-26 18:47:33.738: Find a better model.
2023-05-26 18:47:40.186: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.447016]
2023-05-26 18:47:40.342: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-26 18:47:40.342: Find a better model.
2023-05-26 18:47:46.785: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.442021]
2023-05-26 18:47:46.941: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-26 18:47:46.941: Find a better model.
2023-05-26 18:47:53.366: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.423998]
2023-05-26 18:47:53.520: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-26 18:47:53.520: Find a better model.
2023-05-26 18:48:00.176: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.654020]
2023-05-26 18:48:00.318: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-26 18:48:00.318: Find a better model.
2023-05-26 18:48:06.764: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.445003]
2023-05-26 18:48:06.904: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-26 18:48:06.905: Find a better model.
2023-05-26 18:48:13.381: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.475042]
2023-05-26 18:48:13.535: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-26 18:48:13.535: Find a better model.
2023-05-26 18:48:19.979: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.443036]
2023-05-26 18:48:20.134: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-26 18:48:20.135: Find a better model.
2023-05-26 18:48:26.588: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.451314]
2023-05-26 18:48:26.743: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-26 18:48:26.743: Find a better model.
2023-05-26 18:48:33.174: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.430011]
2023-05-26 18:48:33.328: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-26 18:48:33.328: Find a better model.
2023-05-26 18:48:39.755: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.425080]
2023-05-26 18:48:39.899: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-26 18:48:39.899: Find a better model.
2023-05-26 18:48:46.383: [iter 31 : loss : 0.4376 = 0.1715 + 0.2641 + 0.0020, time: 6.482844]
2023-05-26 18:48:46.538: epoch 31:	0.02313064  	0.17113926  	0.08933837  
2023-05-26 18:48:46.538: Find a better model.
2023-05-26 18:48:52.954: [iter 32 : loss : 0.4271 = 0.1616 + 0.2634 + 0.0021, time: 6.415360]
2023-05-26 18:48:53.097: epoch 32:	0.02339173  	0.17321081  	0.09051806  
2023-05-26 18:48:53.098: Find a better model.
2023-05-26 18:48:59.580: [iter 33 : loss : 0.4190 = 0.1543 + 0.2625 + 0.0022, time: 6.480010]
2023-05-26 18:48:59.735: epoch 33:	0.02348345  	0.17394656  	0.09135464  
2023-05-26 18:48:59.736: Find a better model.
2023-05-26 18:49:06.342: [iter 34 : loss : 0.4108 = 0.1468 + 0.2617 + 0.0023, time: 6.605014]
2023-05-26 18:49:06.493: epoch 34:	0.02362458  	0.17503196  	0.09213932  
2023-05-26 18:49:06.493: Find a better model.
2023-05-26 18:49:13.158: [iter 35 : loss : 0.4034 = 0.1401 + 0.2609 + 0.0024, time: 6.664369]
2023-05-26 18:49:13.313: epoch 35:	0.02374454  	0.17582044  	0.09307712  
2023-05-26 18:49:13.313: Find a better model.
2023-05-26 18:49:19.953: [iter 36 : loss : 0.3969 = 0.1343 + 0.2602 + 0.0025, time: 6.638994]
2023-05-26 18:49:20.108: epoch 36:	0.02394918  	0.17751829  	0.09400745  
2023-05-26 18:49:20.108: Find a better model.
2023-05-26 18:49:26.579: [iter 37 : loss : 0.3898 = 0.1279 + 0.2594 + 0.0026, time: 6.469029]
2023-05-26 18:49:26.735: epoch 37:	0.02409736  	0.17887959  	0.09480833  
2023-05-26 18:49:26.735: Find a better model.
2023-05-26 18:49:33.342: [iter 38 : loss : 0.3854 = 0.1241 + 0.2587 + 0.0026, time: 6.606070]
2023-05-26 18:49:33.499: epoch 38:	0.02423850  	0.18015358  	0.09577529  
2023-05-26 18:49:33.499: Find a better model.
2023-05-26 18:49:40.155: [iter 39 : loss : 0.3787 = 0.1180 + 0.2580 + 0.0027, time: 6.655634]
2023-05-26 18:49:40.308: epoch 39:	0.02442196  	0.18145519  	0.09665413  
2023-05-26 18:49:40.308: Find a better model.
2023-05-26 18:49:46.942: [iter 40 : loss : 0.3734 = 0.1134 + 0.2572 + 0.0028, time: 6.632527]
2023-05-26 18:49:47.099: epoch 40:	0.02451370  	0.18158165  	0.09718434  
2023-05-26 18:49:47.099: Find a better model.
2023-05-26 18:49:53.737: [iter 41 : loss : 0.3697 = 0.1101 + 0.2567 + 0.0029, time: 6.636402]
2023-05-26 18:49:53.887: epoch 41:	0.02464778  	0.18233761  	0.09772446  
2023-05-26 18:49:53.888: Find a better model.
2023-05-26 18:50:00.510: [iter 42 : loss : 0.3651 = 0.1062 + 0.2560 + 0.0030, time: 6.621011]
2023-05-26 18:50:00.651: epoch 42:	0.02473952  	0.18298288  	0.09838484  
2023-05-26 18:50:00.651: Find a better model.
2023-05-26 18:50:07.334: [iter 43 : loss : 0.3601 = 0.1017 + 0.2554 + 0.0030, time: 6.680967]
2023-05-26 18:50:07.486: epoch 43:	0.02488770  	0.18432704  	0.09910157  
2023-05-26 18:50:07.486: Find a better model.
2023-05-26 18:50:13.959: [iter 44 : loss : 0.3556 = 0.0977 + 0.2547 + 0.0031, time: 6.471547]
2023-05-26 18:50:14.102: epoch 44:	0.02507822  	0.18588677  	0.09982639  
2023-05-26 18:50:14.102: Find a better model.
2023-05-26 18:50:20.553: [iter 45 : loss : 0.3515 = 0.0940 + 0.2543 + 0.0032, time: 6.449010]
2023-05-26 18:50:20.705: epoch 45:	0.02515584  	0.18642087  	0.10033828  
2023-05-26 18:50:20.705: Find a better model.
2023-05-26 18:50:27.132: [iter 46 : loss : 0.3483 = 0.0913 + 0.2537 + 0.0033, time: 6.426002]
2023-05-26 18:50:27.275: epoch 46:	0.02521935  	0.18701465  	0.10066313  
2023-05-26 18:50:27.275: Find a better model.
2023-05-26 18:50:33.733: [iter 47 : loss : 0.3462 = 0.0896 + 0.2532 + 0.0033, time: 6.457443]
2023-05-26 18:50:33.888: epoch 47:	0.02525463  	0.18704106  	0.10091247  
2023-05-26 18:50:33.889: Find a better model.
2023-05-26 18:50:40.321: [iter 48 : loss : 0.3417 = 0.0856 + 0.2528 + 0.0034, time: 6.431002]
2023-05-26 18:50:40.475: epoch 48:	0.02530403  	0.18767536  	0.10141196  
2023-05-26 18:50:40.475: Find a better model.
2023-05-26 18:50:46.912: [iter 49 : loss : 0.3380 = 0.0822 + 0.2523 + 0.0035, time: 6.436023]
2023-05-26 18:50:47.068: epoch 49:	0.02539576  	0.18800889  	0.10192321  
2023-05-26 18:50:47.068: Find a better model.
2023-05-26 18:50:53.507: [iter 50 : loss : 0.3358 = 0.0804 + 0.2519 + 0.0036, time: 6.438017]
2023-05-26 18:50:53.660: epoch 50:	0.02547338  	0.18860294  	0.10243494  
2023-05-26 18:50:53.660: Find a better model.
2023-05-26 18:51:00.127: [iter 51 : loss : 0.3325 = 0.0774 + 0.2515 + 0.0036, time: 6.465009]
2023-05-26 18:51:00.269: epoch 51:	0.02562157  	0.18948242  	0.10301709  
2023-05-26 18:51:00.269: Find a better model.
2023-05-26 18:51:06.709: [iter 52 : loss : 0.3312 = 0.0765 + 0.2510 + 0.0037, time: 6.439023]
2023-05-26 18:51:06.852: epoch 52:	0.02579092  	0.19067582  	0.10377309  
2023-05-26 18:51:06.852: Find a better model.
2023-05-26 18:51:13.311: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.458034]
2023-05-26 18:51:13.466: epoch 53:	0.02586148  	0.19149116  	0.10428696  
2023-05-26 18:51:13.466: Find a better model.
2023-05-26 18:51:19.912: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.444316]
2023-05-26 18:51:20.065: epoch 54:	0.02589676  	0.19195156  	0.10455631  
2023-05-26 18:51:20.065: Find a better model.
2023-05-26 18:51:26.499: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.432004]
2023-05-26 18:51:26.650: epoch 55:	0.02591793  	0.19219516  	0.10478327  
2023-05-26 18:51:26.650: Find a better model.
2023-05-26 18:51:33.121: [iter 56 : loss : 0.3210 = 0.0676 + 0.2494 + 0.0040, time: 6.470086]
2023-05-26 18:51:33.273: epoch 56:	0.02593205  	0.19196197  	0.10502896  
2023-05-26 18:51:39.913: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.638128]
2023-05-26 18:51:40.069: epoch 57:	0.02595321  	0.19218220  	0.10519829  
2023-05-26 18:51:46.515: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.445061]
2023-05-26 18:51:46.669: epoch 58:	0.02606612  	0.19308290  	0.10578318  
2023-05-26 18:51:46.669: Find a better model.
2023-05-26 18:51:53.114: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.444116]
2023-05-26 18:51:53.268: epoch 59:	0.02609434  	0.19337738  	0.10590531  
2023-05-26 18:51:53.269: Find a better model.
2023-05-26 18:51:59.870: [iter 60 : loss : 0.3135 = 0.0611 + 0.2482 + 0.0042, time: 6.600691]
2023-05-26 18:52:00.032: epoch 60:	0.02620725  	0.19395447  	0.10629762  
2023-05-26 18:52:00.033: Find a better model.
2023-05-26 18:52:06.489: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.453089]
2023-05-26 18:52:06.642: epoch 61:	0.02620725  	0.19454296  	0.10651705  
2023-05-26 18:52:06.642: Find a better model.
2023-05-26 18:52:13.091: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.448134]
2023-05-26 18:52:13.244: epoch 62:	0.02617196  	0.19414380  	0.10654917  
2023-05-26 18:52:19.720: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.475029]
2023-05-26 18:52:19.875: epoch 63:	0.02618607  	0.19401701  	0.10670833  
2023-05-26 18:52:26.297: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.421150]
2023-05-26 18:52:26.449: epoch 64:	0.02620725  	0.19436824  	0.10687846  
2023-05-26 18:52:32.879: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.426990]
2023-05-26 18:52:33.036: epoch 65:	0.02627075  	0.19462110  	0.10707077  
2023-05-26 18:52:33.036: Find a better model.
2023-05-26 18:52:39.482: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.445013]
2023-05-26 18:52:39.635: epoch 66:	0.02630604  	0.19498673  	0.10724138  
2023-05-26 18:52:39.635: Find a better model.
2023-05-26 18:52:46.092: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.456319]
2023-05-26 18:52:46.247: epoch 67:	0.02628487  	0.19462584  	0.10712864  
2023-05-26 18:52:52.871: [iter 68 : loss : 0.3017 = 0.0509 + 0.2460 + 0.0047, time: 6.621315]
2023-05-26 18:52:53.027: epoch 68:	0.02644717  	0.19577003  	0.10764769  
2023-05-26 18:52:53.027: Find a better model.
2023-05-26 18:52:59.667: [iter 69 : loss : 0.2999 = 0.0493 + 0.2459 + 0.0047, time: 6.639004]
2023-05-26 18:52:59.822: epoch 69:	0.02650362  	0.19595338  	0.10772637  
2023-05-26 18:52:59.822: Find a better model.
2023-05-26 18:53:06.319: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.495114]
2023-05-26 18:53:06.472: epoch 70:	0.02664475  	0.19702859  	0.10820810  
2023-05-26 18:53:06.472: Find a better model.
2023-05-26 18:53:13.068: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.593004]
2023-05-26 18:53:13.221: epoch 71:	0.02656713  	0.19665308  	0.10810143  
2023-05-26 18:53:19.854: [iter 72 : loss : 0.2963 = 0.0462 + 0.2452 + 0.0049, time: 6.631097]
2023-05-26 18:53:20.015: epoch 72:	0.02656007  	0.19652425  	0.10810161  
2023-05-26 18:53:26.851: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.834352]
2023-05-26 18:53:27.006: epoch 73:	0.02660241  	0.19657025  	0.10818605  
2023-05-26 18:53:33.463: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.454067]
2023-05-26 18:53:33.615: epoch 74:	0.02668002  	0.19708768  	0.10849189  
2023-05-26 18:53:33.615: Find a better model.
2023-05-26 18:53:40.260: [iter 75 : loss : 0.2931 = 0.0434 + 0.2446 + 0.0050, time: 6.644009]
2023-05-26 18:53:40.415: epoch 75:	0.02665886  	0.19705616  	0.10869642  
2023-05-26 18:53:47.040: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.624008]
2023-05-26 18:53:47.184: epoch 76:	0.02672237  	0.19759066  	0.10885058  
2023-05-26 18:53:47.184: Find a better model.
2023-05-26 18:53:53.634: [iter 77 : loss : 0.2910 = 0.0416 + 0.2442 + 0.0051, time: 6.448348]
2023-05-26 18:53:53.776: epoch 77:	0.02660241  	0.19694234  	0.10861786  
2023-05-26 18:54:00.262: [iter 78 : loss : 0.2905 = 0.0411 + 0.2442 + 0.0052, time: 6.485020]
2023-05-26 18:54:00.418: epoch 78:	0.02660946  	0.19709215  	0.10860539  
2023-05-26 18:54:06.856: [iter 79 : loss : 0.2889 = 0.0398 + 0.2439 + 0.0052, time: 6.437076]
2023-05-26 18:54:07.012: epoch 79:	0.02658829  	0.19694187  	0.10879070  
2023-05-26 18:54:13.454: [iter 80 : loss : 0.2882 = 0.0391 + 0.2438 + 0.0053, time: 6.440943]
2023-05-26 18:54:13.609: epoch 80:	0.02657419  	0.19640031  	0.10893568  
2023-05-26 18:54:20.045: [iter 81 : loss : 0.2877 = 0.0387 + 0.2436 + 0.0053, time: 6.435004]
2023-05-26 18:54:20.187: epoch 81:	0.02663063  	0.19645067  	0.10885140  
2023-05-26 18:54:26.642: [iter 82 : loss : 0.2866 = 0.0377 + 0.2435 + 0.0054, time: 6.453994]
2023-05-26 18:54:26.785: epoch 82:	0.02665180  	0.19645311  	0.10897100  
2023-05-26 18:54:33.261: [iter 83 : loss : 0.2856 = 0.0368 + 0.2434 + 0.0054, time: 6.475012]
2023-05-26 18:54:33.415: epoch 83:	0.02663768  	0.19620799  	0.10897882  
2023-05-26 18:54:39.860: [iter 84 : loss : 0.2855 = 0.0368 + 0.2432 + 0.0055, time: 6.444020]
2023-05-26 18:54:40.018: epoch 84:	0.02666592  	0.19664326  	0.10921748  
2023-05-26 18:54:46.457: [iter 85 : loss : 0.2847 = 0.0361 + 0.2431 + 0.0055, time: 6.437003]
2023-05-26 18:54:46.610: epoch 85:	0.02669414  	0.19661751  	0.10919429  
2023-05-26 18:54:53.048: [iter 86 : loss : 0.2839 = 0.0355 + 0.2429 + 0.0056, time: 6.437136]
2023-05-26 18:54:53.201: epoch 86:	0.02673648  	0.19685894  	0.10923503  
2023-05-26 18:54:59.634: [iter 87 : loss : 0.2824 = 0.0339 + 0.2428 + 0.0056, time: 6.431994]
2023-05-26 18:54:59.786: epoch 87:	0.02677176  	0.19690131  	0.10928166  
2023-05-26 18:55:06.237: [iter 88 : loss : 0.2817 = 0.0334 + 0.2426 + 0.0057, time: 6.450020]
2023-05-26 18:55:06.391: epoch 88:	0.02679293  	0.19745335  	0.10944445  
2023-05-26 18:55:12.846: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.452014]
2023-05-26 18:55:12.989: epoch 89:	0.02687055  	0.19797975  	0.10950413  
2023-05-26 18:55:12.989: Find a better model.
2023-05-26 18:55:19.434: [iter 90 : loss : 0.2813 = 0.0331 + 0.2424 + 0.0058, time: 6.444443]
2023-05-26 18:55:19.586: epoch 90:	0.02679293  	0.19731720  	0.10949855  
2023-05-26 18:55:26.025: [iter 91 : loss : 0.2805 = 0.0324 + 0.2422 + 0.0058, time: 6.437046]
2023-05-26 18:55:26.167: epoch 91:	0.02679999  	0.19708601  	0.10938798  
2023-05-26 18:55:32.633: [iter 92 : loss : 0.2794 = 0.0314 + 0.2422 + 0.0059, time: 6.463499]
2023-05-26 18:55:32.787: epoch 92:	0.02684233  	0.19765759  	0.10956241  
2023-05-26 18:55:39.228: [iter 93 : loss : 0.2797 = 0.0317 + 0.2421 + 0.0059, time: 6.439475]
2023-05-26 18:55:39.384: epoch 93:	0.02686350  	0.19753578  	0.10948608  
2023-05-26 18:55:46.002: [iter 94 : loss : 0.2782 = 0.0303 + 0.2420 + 0.0059, time: 6.616073]
2023-05-26 18:55:46.160: epoch 94:	0.02689878  	0.19771846  	0.10953841  
2023-05-26 18:55:52.803: [iter 95 : loss : 0.2774 = 0.0295 + 0.2419 + 0.0060, time: 6.641428]
2023-05-26 18:55:52.955: epoch 95:	0.02688466  	0.19732180  	0.10958642  
2023-05-26 18:55:59.430: [iter 96 : loss : 0.2774 = 0.0296 + 0.2417 + 0.0060, time: 6.474480]
2023-05-26 18:55:59.586: epoch 96:	0.02691289  	0.19755235  	0.10967118  
2023-05-26 18:56:05.999: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.410830]
2023-05-26 18:56:06.141: epoch 97:	0.02694111  	0.19779363  	0.10953162  
2023-05-26 18:56:12.611: [iter 98 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.469032]
2023-05-26 18:56:12.765: epoch 98:	0.02700462  	0.19833949  	0.10983928  
2023-05-26 18:56:12.765: Find a better model.
2023-05-26 18:56:19.209: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.443050]
2023-05-26 18:56:19.364: epoch 99:	0.02701168  	0.19829635  	0.10989334  
2023-05-26 18:56:25.821: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.456034]
2023-05-26 18:56:25.977: epoch 100:	0.02700462  	0.19829977  	0.10998259  
2023-05-26 18:56:32.590: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0063, time: 6.610409]
2023-05-26 18:56:32.742: epoch 101:	0.02691288  	0.19764145  	0.10986765  
2023-05-26 18:56:39.381: [iter 102 : loss : 0.2740 = 0.0266 + 0.2411 + 0.0063, time: 6.637012]
2023-05-26 18:56:39.533: epoch 102:	0.02694111  	0.19775045  	0.10992235  
2023-05-26 18:56:45.987: [iter 103 : loss : 0.2737 = 0.0264 + 0.2409 + 0.0063, time: 6.452019]
2023-05-26 18:56:46.129: epoch 103:	0.02688466  	0.19742535  	0.10998052  
2023-05-26 18:56:52.763: [iter 104 : loss : 0.2739 = 0.0265 + 0.2409 + 0.0064, time: 6.633077]
2023-05-26 18:56:52.905: epoch 104:	0.02696228  	0.19795127  	0.11005580  
2023-05-26 18:56:59.395: [iter 105 : loss : 0.2734 = 0.0261 + 0.2408 + 0.0064, time: 6.488005]
2023-05-26 18:56:59.550: epoch 105:	0.02689877  	0.19760482  	0.11000112  
2023-05-26 18:57:06.194: [iter 106 : loss : 0.2728 = 0.0256 + 0.2408 + 0.0065, time: 6.641481]
2023-05-26 18:57:06.336: epoch 106:	0.02693405  	0.19782355  	0.11000121  
2023-05-26 18:57:12.989: [iter 107 : loss : 0.2722 = 0.0250 + 0.2407 + 0.0065, time: 6.652083]
2023-05-26 18:57:13.144: epoch 107:	0.02696228  	0.19809414  	0.11020401  
2023-05-26 18:57:19.757: [iter 108 : loss : 0.2718 = 0.0246 + 0.2407 + 0.0065, time: 6.612015]
2023-05-26 18:57:19.899: epoch 108:	0.02696933  	0.19846529  	0.11027404  
2023-05-26 18:57:19.899: Find a better model.
2023-05-26 18:57:26.583: [iter 109 : loss : 0.2709 = 0.0239 + 0.2405 + 0.0066, time: 6.683021]
2023-05-26 18:57:26.735: epoch 109:	0.02699756  	0.19853191  	0.11028698  
2023-05-26 18:57:26.735: Find a better model.
2023-05-26 18:57:33.173: [iter 110 : loss : 0.2707 = 0.0236 + 0.2405 + 0.0066, time: 6.437015]
2023-05-26 18:57:33.316: epoch 110:	0.02693405  	0.19821087  	0.11020550  
2023-05-26 18:57:39.954: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.637009]
2023-05-26 18:57:40.110: epoch 111:	0.02694111  	0.19823436  	0.11023279  
2023-05-26 18:57:46.587: [iter 112 : loss : 0.2702 = 0.0231 + 0.2403 + 0.0067, time: 6.476031]
2023-05-26 18:57:46.742: epoch 112:	0.02689877  	0.19784415  	0.11015050  
2023-05-26 18:57:53.166: [iter 113 : loss : 0.2701 = 0.0232 + 0.2402 + 0.0067, time: 6.423006]
2023-05-26 18:57:53.322: epoch 113:	0.02687055  	0.19748604  	0.10997336  
2023-05-26 18:57:59.775: [iter 114 : loss : 0.2694 = 0.0225 + 0.2402 + 0.0068, time: 6.452023]
2023-05-26 18:57:59.930: epoch 114:	0.02690583  	0.19769663  	0.11005776  
2023-05-26 18:58:06.365: [iter 115 : loss : 0.2692 = 0.0223 + 0.2401 + 0.0068, time: 6.434024]
2023-05-26 18:58:06.519: epoch 115:	0.02694111  	0.19806287  	0.11013967  
2023-05-26 18:58:12.973: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.452019]
2023-05-26 18:58:13.127: epoch 116:	0.02686349  	0.19721574  	0.10989285  
2023-05-26 18:58:19.571: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.443026]
2023-05-26 18:58:19.725: epoch 117:	0.02679292  	0.19650227  	0.10972543  
2023-05-26 18:58:26.346: [iter 118 : loss : 0.2683 = 0.0214 + 0.2399 + 0.0069, time: 6.620040]
2023-05-26 18:58:26.501: epoch 118:	0.02674352  	0.19629291  	0.10975164  
2023-05-26 18:58:32.961: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.458188]
2023-05-26 18:58:33.104: epoch 119:	0.02680703  	0.19653887  	0.10983520  
2023-05-26 18:58:39.566: [iter 120 : loss : 0.2678 = 0.0211 + 0.2398 + 0.0070, time: 6.459908]
2023-05-26 18:58:39.721: epoch 120:	0.02679998  	0.19615597  	0.10970937  
2023-05-26 18:58:46.343: [iter 121 : loss : 0.2677 = 0.0209 + 0.2397 + 0.0070, time: 6.621005]
2023-05-26 18:58:46.496: epoch 121:	0.02679998  	0.19590542  	0.10961390  
2023-05-26 18:58:52.986: [iter 122 : loss : 0.2672 = 0.0205 + 0.2397 + 0.0070, time: 6.489182]
2023-05-26 18:58:53.140: epoch 122:	0.02677175  	0.19581203  	0.10967155  
2023-05-26 18:58:59.726: [iter 123 : loss : 0.2670 = 0.0203 + 0.2396 + 0.0071, time: 6.585003]
2023-05-26 18:58:59.880: epoch 123:	0.02676470  	0.19565992  	0.10964194  
2023-05-26 18:59:06.360: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.479026]
2023-05-26 18:59:06.513: epoch 124:	0.02674353  	0.19561106  	0.10969084  
2023-05-26 18:59:13.121: [iter 125 : loss : 0.2659 = 0.0193 + 0.2395 + 0.0072, time: 6.606016]
2023-05-26 18:59:13.273: epoch 125:	0.02677881  	0.19589010  	0.10977807  
2023-05-26 18:59:19.914: [iter 126 : loss : 0.2661 = 0.0195 + 0.2394 + 0.0072, time: 6.640004]
2023-05-26 18:59:20.077: epoch 126:	0.02675764  	0.19563553  	0.10969938  
2023-05-26 18:59:26.536: [iter 127 : loss : 0.2653 = 0.0186 + 0.2394 + 0.0072, time: 6.457101]
2023-05-26 18:59:26.692: epoch 127:	0.02678586  	0.19631541  	0.10981682  
2023-05-26 18:59:33.333: [iter 128 : loss : 0.2658 = 0.0192 + 0.2393 + 0.0073, time: 6.639481]
2023-05-26 18:59:33.486: epoch 128:	0.02681408  	0.19615000  	0.10968535  
2023-05-26 18:59:39.924: [iter 129 : loss : 0.2653 = 0.0186 + 0.2393 + 0.0073, time: 6.436097]
2023-05-26 18:59:40.081: epoch 129:	0.02678587  	0.19584170  	0.10947928  
2023-05-26 18:59:46.547: [iter 130 : loss : 0.2653 = 0.0188 + 0.2392 + 0.0073, time: 6.465419]
2023-05-26 18:59:46.702: epoch 130:	0.02675764  	0.19554435  	0.10937952  
2023-05-26 18:59:53.128: [iter 131 : loss : 0.2647 = 0.0181 + 0.2392 + 0.0073, time: 6.425010]
2023-05-26 18:59:53.273: epoch 131:	0.02668002  	0.19483392  	0.10943638  
2023-05-26 18:59:59.734: [iter 132 : loss : 0.2646 = 0.0181 + 0.2391 + 0.0074, time: 6.460027]
2023-05-26 18:59:59.887: epoch 132:	0.02660945  	0.19416001  	0.10918164  
2023-05-26 19:00:06.328: [iter 133 : loss : 0.2639 = 0.0174 + 0.2391 + 0.0074, time: 6.440030]
2023-05-26 19:00:06.471: epoch 133:	0.02663062  	0.19449998  	0.10924585  
2023-05-26 19:00:12.941: [iter 134 : loss : 0.2643 = 0.0178 + 0.2390 + 0.0074, time: 6.469025]
2023-05-26 19:00:13.098: epoch 134:	0.02660945  	0.19401975  	0.10916324  
2023-05-26 19:00:13.098: Early stopping is trigger at epoch: 134
2023-05-26 19:00:13.098: best_result@epoch 109:

2023-05-26 19:00:13.098: 		0.0270      	0.1985      	0.1103      
2023-05-26 19:08:06.096: my pid: 2648
2023-05-26 19:08:06.096: model: model.general_recommender.SGL
2023-05-26 19:08:06.096: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 19:08:06.096: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 19:08:09.719: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 19:08:17.006: [iter 1 : loss : 1.0070 = 0.6930 + 0.3140 + 0.0000, time: 7.287503]
2023-05-26 19:08:17.164: epoch 1:	0.00148180  	0.01007288  	0.00518638  
2023-05-26 19:08:17.164: Find a better model.
2023-05-26 19:08:24.578: [iter 2 : loss : 1.0056 = 0.6929 + 0.3127 + 0.0000, time: 7.413089]
2023-05-26 19:08:24.769: epoch 2:	0.00215214  	0.01506323  	0.00759623  
2023-05-26 19:08:24.769: Find a better model.
2023-05-26 19:08:32.172: [iter 3 : loss : 1.0053 = 0.6928 + 0.3125 + 0.0000, time: 7.402008]
2023-05-26 19:08:32.339: epoch 3:	0.00323877  	0.02255323  	0.01167415  
2023-05-26 19:08:32.339: Find a better model.
2023-05-26 19:08:39.542: [iter 4 : loss : 1.0051 = 0.6927 + 0.3124 + 0.0000, time: 7.202002]
2023-05-26 19:08:39.698: epoch 4:	0.00409961  	0.02849601  	0.01466823  
2023-05-26 19:08:39.698: Find a better model.
2023-05-26 19:08:46.786: [iter 5 : loss : 1.0049 = 0.6925 + 0.3124 + 0.0000, time: 7.087040]
2023-05-26 19:08:46.949: epoch 5:	0.00508747  	0.03545045  	0.01763683  
2023-05-26 19:08:46.949: Find a better model.
2023-05-26 19:08:53.917: [iter 6 : loss : 1.0049 = 0.6923 + 0.3125 + 0.0000, time: 6.967065]
2023-05-26 19:08:54.063: epoch 6:	0.00594831  	0.04169608  	0.02087439  
2023-05-26 19:08:54.064: Find a better model.
2023-05-26 19:09:00.926: [iter 7 : loss : 1.0045 = 0.6920 + 0.3124 + 0.0000, time: 6.861003]
2023-05-26 19:09:01.071: epoch 7:	0.00666097  	0.04731534  	0.02407812  
2023-05-26 19:09:01.071: Find a better model.
2023-05-26 19:09:07.932: [iter 8 : loss : 1.0043 = 0.6918 + 0.3126 + 0.0000, time: 6.860036]
2023-05-26 19:09:08.076: epoch 8:	0.00738069  	0.05191480  	0.02677541  
2023-05-26 19:09:08.076: Find a better model.
2023-05-26 19:09:14.902: [iter 9 : loss : 1.0040 = 0.6913 + 0.3127 + 0.0000, time: 6.825018]
2023-05-26 19:09:15.046: epoch 9:	0.00829798  	0.05921273  	0.03056381  
2023-05-26 19:09:15.046: Find a better model.
2023-05-26 19:09:21.716: [iter 10 : loss : 1.0036 = 0.6908 + 0.3128 + 0.0000, time: 6.668305]
2023-05-26 19:09:21.860: epoch 10:	0.00963162  	0.06750149  	0.03438413  
2023-05-26 19:09:21.860: Find a better model.
2023-05-26 19:09:28.557: [iter 11 : loss : 1.0030 = 0.6901 + 0.3129 + 0.0000, time: 6.695606]
2023-05-26 19:09:28.715: epoch 11:	0.01059835  	0.07446928  	0.03832243  
2023-05-26 19:09:28.715: Find a better model.
2023-05-26 19:09:35.321: [iter 12 : loss : 1.0022 = 0.6891 + 0.3130 + 0.0000, time: 6.605031]
2023-05-26 19:09:35.465: epoch 12:	0.01136046  	0.08116855  	0.04098159  
2023-05-26 19:09:35.465: Find a better model.
2023-05-26 19:09:42.129: [iter 13 : loss : 1.0010 = 0.6878 + 0.3132 + 0.0000, time: 6.663006]
2023-05-26 19:09:42.282: epoch 13:	0.01239775  	0.08946972  	0.04417939  
2023-05-26 19:09:42.283: Find a better model.
2023-05-26 19:09:48.926: [iter 14 : loss : 0.9993 = 0.6858 + 0.3134 + 0.0000, time: 6.642202]
2023-05-26 19:09:49.083: epoch 14:	0.01337860  	0.09696855  	0.04757192  
2023-05-26 19:09:49.083: Find a better model.
2023-05-26 19:09:55.706: [iter 15 : loss : 0.9967 = 0.6830 + 0.3137 + 0.0000, time: 6.621567]
2023-05-26 19:09:55.864: epoch 15:	0.01452174  	0.10474711  	0.05135924  
2023-05-26 19:09:55.864: Find a better model.
2023-05-26 19:10:02.323: [iter 16 : loss : 0.9927 = 0.6785 + 0.3141 + 0.0000, time: 6.456994]
2023-05-26 19:10:02.466: epoch 16:	0.01546730  	0.11179481  	0.05466865  
2023-05-26 19:10:02.466: Find a better model.
2023-05-26 19:10:09.112: [iter 17 : loss : 0.9865 = 0.6718 + 0.3147 + 0.0001, time: 6.644014]
2023-05-26 19:10:09.257: epoch 17:	0.01671629  	0.12208136  	0.05999736  
2023-05-26 19:10:09.257: Find a better model.
2023-05-26 19:10:15.929: [iter 18 : loss : 0.9772 = 0.6616 + 0.3155 + 0.0001, time: 6.670174]
2023-05-26 19:10:16.086: epoch 18:	0.01781003  	0.13029225  	0.06439240  
2023-05-26 19:10:16.086: Find a better model.
2023-05-26 19:10:22.704: [iter 19 : loss : 0.9631 = 0.6460 + 0.3169 + 0.0001, time: 6.616099]
2023-05-26 19:10:22.848: epoch 19:	0.01876969  	0.13692948  	0.06849489  
2023-05-26 19:10:22.848: Find a better model.
2023-05-26 19:10:29.519: [iter 20 : loss : 0.9430 = 0.6239 + 0.3190 + 0.0002, time: 6.669060]
2023-05-26 19:10:29.677: epoch 20:	0.01959530  	0.14298858  	0.07248525  
2023-05-26 19:10:29.677: Find a better model.
2023-05-26 19:10:36.328: [iter 21 : loss : 0.9149 = 0.5928 + 0.3219 + 0.0002, time: 6.650415]
2023-05-26 19:10:36.484: epoch 21:	0.02002576  	0.14709623  	0.07509179  
2023-05-26 19:10:36.484: Find a better model.
2023-05-26 19:10:43.095: [iter 22 : loss : 0.8791 = 0.5533 + 0.3255 + 0.0003, time: 6.610265]
2023-05-26 19:10:43.241: epoch 22:	0.02035036  	0.14914866  	0.07656167  
2023-05-26 19:10:43.241: Find a better model.
2023-05-26 19:10:49.875: [iter 23 : loss : 0.8370 = 0.5066 + 0.3299 + 0.0005, time: 6.633032]
2023-05-26 19:10:50.020: epoch 23:	0.02071024  	0.15207280  	0.07861388  
2023-05-26 19:10:50.020: Find a better model.
2023-05-26 19:10:56.689: [iter 24 : loss : 0.7915 = 0.4567 + 0.3343 + 0.0006, time: 6.667004]
2023-05-26 19:10:56.845: epoch 24:	0.02112658  	0.15577087  	0.08042523  
2023-05-26 19:10:56.845: Find a better model.
2023-05-26 19:11:03.298: [iter 25 : loss : 0.7469 = 0.4081 + 0.3381 + 0.0007, time: 6.452172]
2023-05-26 19:11:03.442: epoch 25:	0.02139472  	0.15815508  	0.08172884  
2023-05-26 19:11:03.442: Find a better model.
2023-05-26 19:11:09.919: [iter 26 : loss : 0.7068 = 0.3648 + 0.3411 + 0.0009, time: 6.475209]
2023-05-26 19:11:10.078: epoch 26:	0.02162759  	0.15912354  	0.08272821  
2023-05-26 19:11:10.079: Find a better model.
2023-05-26 19:11:16.688: [iter 27 : loss : 0.6704 = 0.3262 + 0.3432 + 0.0010, time: 6.608011]
2023-05-26 19:11:16.843: epoch 27:	0.02183224  	0.16129296  	0.08379698  
2023-05-26 19:11:16.843: Find a better model.
2023-05-26 19:11:23.308: [iter 28 : loss : 0.6398 = 0.2941 + 0.3445 + 0.0012, time: 6.464004]
2023-05-26 19:11:23.464: epoch 28:	0.02202982  	0.16227755  	0.08456451  
2023-05-26 19:11:23.464: Find a better model.
2023-05-26 19:11:30.077: [iter 29 : loss : 0.6146 = 0.2682 + 0.3451 + 0.0013, time: 6.612009]
2023-05-26 19:11:30.223: epoch 29:	0.02222740  	0.16435389  	0.08586542  
2023-05-26 19:11:30.223: Find a better model.
2023-05-26 19:11:36.691: [iter 30 : loss : 0.5914 = 0.2445 + 0.3454 + 0.0014, time: 6.467042]
2023-05-26 19:11:36.848: epoch 30:	0.02251671  	0.16634847  	0.08708978  
2023-05-26 19:11:36.849: Find a better model.
2023-05-26 19:11:43.314: [iter 31 : loss : 0.5726 = 0.2259 + 0.3451 + 0.0016, time: 6.464004]
2023-05-26 19:11:43.470: epoch 31:	0.02273547  	0.16816933  	0.08820927  
2023-05-26 19:11:43.470: Find a better model.
2023-05-26 19:11:50.071: [iter 32 : loss : 0.5557 = 0.2092 + 0.3448 + 0.0017, time: 6.599022]
2023-05-26 19:11:50.231: epoch 32:	0.02301773  	0.17058854  	0.08936694  
2023-05-26 19:11:50.231: Find a better model.
2023-05-26 19:11:56.876: [iter 33 : loss : 0.5418 = 0.1958 + 0.3441 + 0.0018, time: 6.644013]
2023-05-26 19:11:57.022: epoch 33:	0.02325766  	0.17228720  	0.09050984  
2023-05-26 19:11:57.023: Find a better model.
2023-05-26 19:12:03.492: [iter 34 : loss : 0.5289 = 0.1836 + 0.3434 + 0.0019, time: 6.468035]
2023-05-26 19:12:03.637: epoch 34:	0.02351168  	0.17402668  	0.09165509  
2023-05-26 19:12:03.637: Find a better model.
2023-05-26 19:12:10.279: [iter 35 : loss : 0.5173 = 0.1726 + 0.3426 + 0.0020, time: 6.641014]
2023-05-26 19:12:10.436: epoch 35:	0.02361048  	0.17472023  	0.09246583  
2023-05-26 19:12:10.436: Find a better model.
2023-05-26 19:12:17.063: [iter 36 : loss : 0.5073 = 0.1632 + 0.3419 + 0.0021, time: 6.625135]
2023-05-26 19:12:17.223: epoch 36:	0.02378688  	0.17620981  	0.09341335  
2023-05-26 19:12:17.223: Find a better model.
2023-05-26 19:12:23.700: [iter 37 : loss : 0.4971 = 0.1538 + 0.3410 + 0.0023, time: 6.475042]
2023-05-26 19:12:23.855: epoch 37:	0.02397740  	0.17784250  	0.09445093  
2023-05-26 19:12:23.855: Find a better model.
2023-05-26 19:12:30.289: [iter 38 : loss : 0.4900 = 0.1473 + 0.3402 + 0.0024, time: 6.433015]
2023-05-26 19:12:30.442: epoch 38:	0.02416087  	0.17913727  	0.09532082  
2023-05-26 19:12:30.443: Find a better model.
2023-05-26 19:12:37.060: [iter 39 : loss : 0.4809 = 0.1390 + 0.3394 + 0.0025, time: 6.616049]
2023-05-26 19:12:37.221: epoch 39:	0.02430200  	0.18023491  	0.09610991  
2023-05-26 19:12:37.221: Find a better model.
2023-05-26 19:12:43.678: [iter 40 : loss : 0.4736 = 0.1325 + 0.3385 + 0.0025, time: 6.456010]
2023-05-26 19:12:43.836: epoch 40:	0.02445725  	0.18119749  	0.09695539  
2023-05-26 19:12:43.836: Find a better model.
2023-05-26 19:12:50.477: [iter 41 : loss : 0.4680 = 0.1275 + 0.3379 + 0.0026, time: 6.639080]
2023-05-26 19:12:50.633: epoch 41:	0.02465483  	0.18251188  	0.09764455  
2023-05-26 19:12:50.633: Find a better model.
2023-05-26 19:12:57.261: [iter 42 : loss : 0.4616 = 0.1219 + 0.3370 + 0.0027, time: 6.626549]
2023-05-26 19:12:57.417: epoch 42:	0.02472540  	0.18241698  	0.09809777  
2023-05-26 19:13:04.035: [iter 43 : loss : 0.4552 = 0.1161 + 0.3363 + 0.0028, time: 6.617211]
2023-05-26 19:13:04.182: epoch 43:	0.02494415  	0.18405953  	0.09889601  
2023-05-26 19:13:04.182: Find a better model.
2023-05-26 19:13:10.690: [iter 44 : loss : 0.4494 = 0.1111 + 0.3355 + 0.0029, time: 6.505993]
2023-05-26 19:13:10.833: epoch 44:	0.02504999  	0.18522117  	0.09964625  
2023-05-26 19:13:10.833: Find a better model.
2023-05-26 19:13:17.462: [iter 45 : loss : 0.4442 = 0.1062 + 0.3350 + 0.0030, time: 6.627170]
2023-05-26 19:13:17.618: epoch 45:	0.02523346  	0.18638903  	0.10026917  
2023-05-26 19:13:17.619: Find a better model.
2023-05-26 19:13:24.256: [iter 46 : loss : 0.4399 = 0.1025 + 0.3343 + 0.0031, time: 6.636015]
2023-05-26 19:13:24.412: epoch 46:	0.02535342  	0.18741462  	0.10098146  
2023-05-26 19:13:24.412: Find a better model.
2023-05-26 19:13:31.049: [iter 47 : loss : 0.4366 = 0.0998 + 0.3336 + 0.0032, time: 6.635062]
2023-05-26 19:13:31.208: epoch 47:	0.02531814  	0.18720473  	0.10125151  
2023-05-26 19:13:37.841: [iter 48 : loss : 0.4313 = 0.0950 + 0.3331 + 0.0032, time: 6.632022]
2023-05-26 19:13:37.997: epoch 48:	0.02544516  	0.18822250  	0.10185024  
2023-05-26 19:13:37.997: Find a better model.
2023-05-26 19:13:44.450: [iter 49 : loss : 0.4268 = 0.0910 + 0.3325 + 0.0033, time: 6.452430]
2023-05-26 19:13:44.605: epoch 49:	0.02559335  	0.18903971  	0.10247834  
2023-05-26 19:13:44.605: Find a better model.
2023-05-26 19:13:51.228: [iter 50 : loss : 0.4238 = 0.0885 + 0.3320 + 0.0034, time: 6.622023]
2023-05-26 19:13:51.383: epoch 50:	0.02566390  	0.18951471  	0.10286330  
2023-05-26 19:13:51.383: Find a better model.
2023-05-26 19:13:58.017: [iter 51 : loss : 0.4198 = 0.0848 + 0.3315 + 0.0035, time: 6.633007]
2023-05-26 19:13:58.181: epoch 51:	0.02578386  	0.19060752  	0.10342834  
2023-05-26 19:13:58.181: Find a better model.
2023-05-26 19:14:04.639: [iter 52 : loss : 0.4178 = 0.0833 + 0.3309 + 0.0036, time: 6.456033]
2023-05-26 19:14:04.793: epoch 52:	0.02590382  	0.19155687  	0.10399558  
2023-05-26 19:14:04.794: Find a better model.
2023-05-26 19:14:11.415: [iter 53 : loss : 0.4143 = 0.0803 + 0.3305 + 0.0036, time: 6.619004]
2023-05-26 19:14:11.569: epoch 53:	0.02587559  	0.19127105  	0.10417134  
2023-05-26 19:14:18.210: [iter 54 : loss : 0.4111 = 0.0775 + 0.3299 + 0.0037, time: 6.640017]
2023-05-26 19:14:18.354: epoch 54:	0.02594616  	0.19159524  	0.10435758  
2023-05-26 19:14:18.354: Find a better model.
2023-05-26 19:14:25.015: [iter 55 : loss : 0.4087 = 0.0753 + 0.3296 + 0.0038, time: 6.659009]
2023-05-26 19:14:25.174: epoch 55:	0.02602378  	0.19233549  	0.10473789  
2023-05-26 19:14:25.175: Find a better model.
2023-05-26 19:14:31.808: [iter 56 : loss : 0.4055 = 0.0726 + 0.3290 + 0.0038, time: 6.632004]
2023-05-26 19:14:31.964: epoch 56:	0.02608729  	0.19295378  	0.10496452  
2023-05-26 19:14:31.965: Find a better model.
2023-05-26 19:14:38.635: [iter 57 : loss : 0.4030 = 0.0703 + 0.3288 + 0.0039, time: 6.668571]
2023-05-26 19:14:38.779: epoch 57:	0.02606612  	0.19302586  	0.10518946  
2023-05-26 19:14:38.779: Find a better model.
2023-05-26 19:14:45.414: [iter 58 : loss : 0.4005 = 0.0682 + 0.3283 + 0.0040, time: 6.634065]
2023-05-26 19:14:45.574: epoch 58:	0.02605906  	0.19283541  	0.10544541  
2023-05-26 19:14:52.199: [iter 59 : loss : 0.3986 = 0.0668 + 0.3278 + 0.0040, time: 6.624013]
2023-05-26 19:14:52.343: epoch 59:	0.02612257  	0.19311804  	0.10581274  
2023-05-26 19:14:52.343: Find a better model.
2023-05-26 19:14:59.033: [iter 60 : loss : 0.3965 = 0.0648 + 0.3276 + 0.0041, time: 6.687707]
2023-05-26 19:14:59.193: epoch 60:	0.02619314  	0.19354142  	0.10599627  
2023-05-26 19:14:59.193: Find a better model.
2023-05-26 19:15:05.824: [iter 61 : loss : 0.3945 = 0.0631 + 0.3272 + 0.0042, time: 6.628209]
2023-05-26 19:15:05.966: epoch 61:	0.02619314  	0.19366035  	0.10615892  
2023-05-26 19:15:05.966: Find a better model.
2023-05-26 19:15:12.605: [iter 62 : loss : 0.3924 = 0.0613 + 0.3269 + 0.0042, time: 6.637533]
2023-05-26 19:15:12.749: epoch 62:	0.02619314  	0.19376324  	0.10627453  
2023-05-26 19:15:12.749: Find a better model.
2023-05-26 19:15:19.405: [iter 63 : loss : 0.3906 = 0.0597 + 0.3265 + 0.0043, time: 6.654180]
2023-05-26 19:15:19.559: epoch 63:	0.02630604  	0.19445267  	0.10674449  
2023-05-26 19:15:19.559: Find a better model.
2023-05-26 19:15:26.229: [iter 64 : loss : 0.3888 = 0.0583 + 0.3262 + 0.0044, time: 6.669015]
2023-05-26 19:15:26.388: epoch 64:	0.02633427  	0.19449477  	0.10683773  
2023-05-26 19:15:26.388: Find a better model.
2023-05-26 19:15:33.019: [iter 65 : loss : 0.3872 = 0.0569 + 0.3259 + 0.0044, time: 6.629565]
2023-05-26 19:15:33.175: epoch 65:	0.02639071  	0.19482753  	0.10702604  
2023-05-26 19:15:33.175: Find a better model.
2023-05-26 19:15:39.811: [iter 66 : loss : 0.3852 = 0.0551 + 0.3256 + 0.0045, time: 6.635003]
2023-05-26 19:15:39.966: epoch 66:	0.02641894  	0.19526856  	0.10740890  
2023-05-26 19:15:39.967: Find a better model.
2023-05-26 19:15:46.585: [iter 67 : loss : 0.3835 = 0.0536 + 0.3253 + 0.0046, time: 6.617000]
2023-05-26 19:15:46.744: epoch 67:	0.02646833  	0.19560318  	0.10762072  
2023-05-26 19:15:46.744: Find a better model.
2023-05-26 19:15:53.205: [iter 68 : loss : 0.3825 = 0.0528 + 0.3250 + 0.0046, time: 6.459003]
2023-05-26 19:15:53.358: epoch 68:	0.02653184  	0.19578533  	0.10800016  
2023-05-26 19:15:53.358: Find a better model.
2023-05-26 19:16:00.007: [iter 69 : loss : 0.3806 = 0.0511 + 0.3248 + 0.0047, time: 6.648016]
2023-05-26 19:16:00.164: epoch 69:	0.02651772  	0.19560575  	0.10797007  
2023-05-26 19:16:06.626: [iter 70 : loss : 0.3789 = 0.0496 + 0.3246 + 0.0047, time: 6.461009]
2023-05-26 19:16:06.781: epoch 70:	0.02654595  	0.19614500  	0.10813651  
2023-05-26 19:16:06.781: Find a better model.
2023-05-26 19:16:13.382: [iter 71 : loss : 0.3776 = 0.0485 + 0.3243 + 0.0048, time: 6.599008]
2023-05-26 19:16:13.538: epoch 71:	0.02653184  	0.19581193  	0.10803458  
2023-05-26 19:16:20.194: [iter 72 : loss : 0.3765 = 0.0475 + 0.3241 + 0.0049, time: 6.654585]
2023-05-26 19:16:20.348: epoch 72:	0.02653890  	0.19587782  	0.10821004  
2023-05-26 19:16:26.978: [iter 73 : loss : 0.3750 = 0.0462 + 0.3238 + 0.0049, time: 6.629106]
2023-05-26 19:16:27.141: epoch 73:	0.02655301  	0.19610190  	0.10843011  
2023-05-26 19:16:33.769: [iter 74 : loss : 0.3738 = 0.0452 + 0.3236 + 0.0050, time: 6.626078]
2023-05-26 19:16:33.925: epoch 74:	0.02662358  	0.19626659  	0.10857198  
2023-05-26 19:16:33.925: Find a better model.
2023-05-26 19:16:40.576: [iter 75 : loss : 0.3729 = 0.0444 + 0.3234 + 0.0050, time: 6.649444]
2023-05-26 19:16:40.720: epoch 75:	0.02658829  	0.19594529  	0.10877099  
2023-05-26 19:16:47.377: [iter 76 : loss : 0.3719 = 0.0436 + 0.3232 + 0.0051, time: 6.654994]
2023-05-26 19:16:47.535: epoch 76:	0.02656712  	0.19581038  	0.10867977  
2023-05-26 19:16:54.173: [iter 77 : loss : 0.3706 = 0.0425 + 0.3229 + 0.0051, time: 6.637074]
2023-05-26 19:16:54.330: epoch 77:	0.02661652  	0.19610807  	0.10878604  
2023-05-26 19:17:00.977: [iter 78 : loss : 0.3700 = 0.0419 + 0.3229 + 0.0052, time: 6.646084]
2023-05-26 19:17:01.138: epoch 78:	0.02658829  	0.19571926  	0.10886982  
2023-05-26 19:17:07.781: [iter 79 : loss : 0.3683 = 0.0404 + 0.3226 + 0.0053, time: 6.642314]
2023-05-26 19:17:07.938: epoch 79:	0.02665886  	0.19608146  	0.10917289  
2023-05-26 19:17:14.549: [iter 80 : loss : 0.3676 = 0.0398 + 0.3225 + 0.0053, time: 6.609340]
2023-05-26 19:17:14.702: epoch 80:	0.02660241  	0.19565818  	0.10884228  
2023-05-26 19:17:21.365: [iter 81 : loss : 0.3669 = 0.0392 + 0.3223 + 0.0054, time: 6.662008]
2023-05-26 19:17:21.521: epoch 81:	0.02667297  	0.19615598  	0.10916308  
2023-05-26 19:17:28.150: [iter 82 : loss : 0.3657 = 0.0382 + 0.3222 + 0.0054, time: 6.628408]
2023-05-26 19:17:28.304: epoch 82:	0.02672237  	0.19625182  	0.10928017  
2023-05-26 19:17:34.960: [iter 83 : loss : 0.3646 = 0.0371 + 0.3220 + 0.0055, time: 6.655013]
2023-05-26 19:17:35.121: epoch 83:	0.02676471  	0.19663517  	0.10957085  
2023-05-26 19:17:35.121: Find a better model.
2023-05-26 19:17:41.563: [iter 84 : loss : 0.3645 = 0.0371 + 0.3219 + 0.0055, time: 6.441011]
2023-05-26 19:17:41.719: epoch 84:	0.02670826  	0.19601752  	0.10931721  
2023-05-26 19:17:48.162: [iter 85 : loss : 0.3635 = 0.0363 + 0.3217 + 0.0056, time: 6.441014]
2023-05-26 19:17:48.319: epoch 85:	0.02665180  	0.19553764  	0.10914460  
2023-05-26 19:17:54.956: [iter 86 : loss : 0.3627 = 0.0356 + 0.3214 + 0.0056, time: 6.636003]
2023-05-26 19:17:55.113: epoch 86:	0.02665180  	0.19539915  	0.10903858  
2023-05-26 19:18:01.741: [iter 87 : loss : 0.3612 = 0.0342 + 0.3214 + 0.0057, time: 6.624015]
2023-05-26 19:18:01.886: epoch 87:	0.02673648  	0.19611360  	0.10929301  
2023-05-26 19:18:08.359: [iter 88 : loss : 0.3605 = 0.0335 + 0.3212 + 0.0057, time: 6.472006]
2023-05-26 19:18:08.515: epoch 88:	0.02665886  	0.19582944  	0.10923623  
2023-05-26 19:18:15.160: [iter 89 : loss : 0.3597 = 0.0328 + 0.3211 + 0.0058, time: 6.642997]
2023-05-26 19:18:15.315: epoch 89:	0.02664474  	0.19512513  	0.10909869  
2023-05-26 19:18:21.965: [iter 90 : loss : 0.3598 = 0.0331 + 0.3209 + 0.0058, time: 6.647611]
2023-05-26 19:18:22.126: epoch 90:	0.02668002  	0.19546482  	0.10928490  
2023-05-26 19:18:28.743: [iter 91 : loss : 0.3590 = 0.0324 + 0.3208 + 0.0059, time: 6.616333]
2023-05-26 19:18:28.897: epoch 91:	0.02659535  	0.19478409  	0.10889689  
2023-05-26 19:18:35.530: [iter 92 : loss : 0.3580 = 0.0314 + 0.3207 + 0.0059, time: 6.631027]
2023-05-26 19:18:35.687: epoch 92:	0.02661651  	0.19491221  	0.10906421  
2023-05-26 19:18:42.338: [iter 93 : loss : 0.3581 = 0.0315 + 0.3206 + 0.0060, time: 6.650101]
2023-05-26 19:18:42.492: epoch 93:	0.02653889  	0.19427972  	0.10901087  
2023-05-26 19:18:49.134: [iter 94 : loss : 0.3567 = 0.0302 + 0.3205 + 0.0060, time: 6.641103]
2023-05-26 19:18:49.288: epoch 94:	0.02654595  	0.19437608  	0.10904390  
2023-05-26 19:18:55.921: [iter 95 : loss : 0.3558 = 0.0294 + 0.3203 + 0.0060, time: 6.632105]
2023-05-26 19:18:56.073: epoch 95:	0.02655300  	0.19429411  	0.10912421  
2023-05-26 19:19:02.753: [iter 96 : loss : 0.3558 = 0.0295 + 0.3202 + 0.0061, time: 6.678104]
2023-05-26 19:19:02.907: epoch 96:	0.02653889  	0.19430183  	0.10900117  
2023-05-26 19:19:09.525: [iter 97 : loss : 0.3546 = 0.0284 + 0.3201 + 0.0061, time: 6.617028]
2023-05-26 19:19:09.679: epoch 97:	0.02660240  	0.19440974  	0.10895084  
2023-05-26 19:19:16.342: [iter 98 : loss : 0.3544 = 0.0282 + 0.3200 + 0.0062, time: 6.662011]
2023-05-26 19:19:16.496: epoch 98:	0.02663063  	0.19472206  	0.10918769  
2023-05-26 19:19:23.140: [iter 99 : loss : 0.3538 = 0.0276 + 0.3199 + 0.0062, time: 6.642999]
2023-05-26 19:19:23.296: epoch 99:	0.02674353  	0.19570354  	0.10959913  
2023-05-26 19:19:29.939: [iter 100 : loss : 0.3534 = 0.0274 + 0.3197 + 0.0063, time: 6.642023]
2023-05-26 19:19:30.095: epoch 100:	0.02675764  	0.19578789  	0.10964856  
2023-05-26 19:19:36.908: [iter 101 : loss : 0.3527 = 0.0268 + 0.3196 + 0.0063, time: 6.811015]
2023-05-26 19:19:37.063: epoch 101:	0.02671531  	0.19567508  	0.10957097  
2023-05-26 19:19:43.910: [iter 102 : loss : 0.3522 = 0.0263 + 0.3195 + 0.0064, time: 6.846018]
2023-05-26 19:19:44.062: epoch 102:	0.02672236  	0.19594097  	0.10961730  
2023-05-26 19:19:50.717: [iter 103 : loss : 0.3518 = 0.0261 + 0.3193 + 0.0064, time: 6.654006]
2023-05-26 19:19:50.861: epoch 103:	0.02671531  	0.19568448  	0.10983679  
2023-05-26 19:19:57.531: [iter 104 : loss : 0.3519 = 0.0261 + 0.3193 + 0.0065, time: 6.668004]
2023-05-26 19:19:57.683: epoch 104:	0.02668003  	0.19537511  	0.10967048  
2023-05-26 19:20:04.508: [iter 105 : loss : 0.3514 = 0.0257 + 0.3192 + 0.0065, time: 6.824353]
2023-05-26 19:20:04.651: epoch 105:	0.02663769  	0.19483964  	0.10942284  
2023-05-26 19:20:11.323: [iter 106 : loss : 0.3509 = 0.0252 + 0.3191 + 0.0065, time: 6.671066]
2023-05-26 19:20:11.479: epoch 106:	0.02663063  	0.19466297  	0.10927998  
2023-05-26 19:20:18.296: [iter 107 : loss : 0.3502 = 0.0246 + 0.3191 + 0.0066, time: 6.816207]
2023-05-26 19:20:18.451: epoch 107:	0.02658124  	0.19444646  	0.10923471  
2023-05-26 19:20:25.296: [iter 108 : loss : 0.3498 = 0.0241 + 0.3190 + 0.0066, time: 6.843383]
2023-05-26 19:20:25.438: epoch 108:	0.02661652  	0.19466248  	0.10948469  
2023-05-26 19:20:25.438: Early stopping is trigger at epoch: 108
2023-05-26 19:20:25.438: best_result@epoch 83:

2023-05-26 19:20:25.438: 		0.0268      	0.1966      	0.1096      
2023-05-26 19:22:29.639: my pid: 2512
2023-05-26 19:22:29.640: model: model.general_recommender.SGL
2023-05-26 19:22:29.640: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 19:22:29.640: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 19:22:33.311: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 19:22:40.705: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.393646]
2023-05-26 19:22:40.864: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-26 19:22:40.864: Find a better model.
2023-05-26 19:22:48.311: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.446228]
2023-05-26 19:22:48.522: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-26 19:22:48.522: Find a better model.
2023-05-26 19:22:56.059: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.534092]
2023-05-26 19:22:56.243: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-26 19:22:56.244: Find a better model.
2023-05-26 19:23:03.449: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.203993]
2023-05-26 19:23:03.616: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-26 19:23:03.616: Find a better model.
2023-05-26 19:23:10.850: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.233052]
2023-05-26 19:23:11.013: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-26 19:23:11.013: Find a better model.
2023-05-26 19:23:17.860: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 6.846064]
2023-05-26 19:23:18.018: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-26 19:23:18.018: Find a better model.
2023-05-26 19:23:24.838: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.818554]
2023-05-26 19:23:24.994: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-26 19:23:24.994: Find a better model.
2023-05-26 19:23:31.836: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.840079]
2023-05-26 19:23:31.992: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-26 19:23:31.992: Find a better model.
2023-05-26 19:23:38.833: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.839322]
2023-05-26 19:23:38.991: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-26 19:23:38.991: Find a better model.
2023-05-26 19:23:45.645: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.652031]
2023-05-26 19:23:45.802: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-26 19:23:45.802: Find a better model.
2023-05-26 19:23:52.634: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.831160]
2023-05-26 19:23:52.790: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-26 19:23:52.790: Find a better model.
2023-05-26 19:23:59.637: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.844471]
2023-05-26 19:23:59.792: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-26 19:23:59.792: Find a better model.
2023-05-26 19:24:06.438: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.645113]
2023-05-26 19:24:06.583: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-26 19:24:06.583: Find a better model.
2023-05-26 19:24:13.117: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.531471]
2023-05-26 19:24:13.262: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-26 19:24:13.263: Find a better model.
2023-05-26 19:24:20.040: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.775994]
2023-05-26 19:24:20.198: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-26 19:24:26.824: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.624994]
2023-05-26 19:24:26.970: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-26 19:24:26.970: Find a better model.
2023-05-26 19:24:33.608: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.637994]
2023-05-26 19:24:33.766: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-26 19:24:33.766: Find a better model.
2023-05-26 19:24:40.441: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.672994]
2023-05-26 19:24:40.599: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-26 19:24:40.600: Find a better model.
2023-05-26 19:24:47.215: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.613108]
2023-05-26 19:24:47.373: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-26 19:24:47.373: Find a better model.
2023-05-26 19:24:53.993: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.618015]
2023-05-26 19:24:54.139: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-26 19:24:54.139: Find a better model.
2023-05-26 19:25:00.801: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.661030]
2023-05-26 19:25:00.946: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-26 19:25:00.946: Find a better model.
2023-05-26 19:25:07.608: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.660053]
2023-05-26 19:25:07.768: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-26 19:25:07.768: Find a better model.
2023-05-26 19:25:14.420: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.650158]
2023-05-26 19:25:14.578: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-26 19:25:14.578: Find a better model.
2023-05-26 19:25:21.227: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.646756]
2023-05-26 19:25:21.387: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-26 19:25:21.387: Find a better model.
2023-05-26 19:25:28.015: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.627017]
2023-05-26 19:25:28.172: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-26 19:25:28.172: Find a better model.
2023-05-26 19:25:34.999: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.825017]
2023-05-26 19:25:35.143: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-26 19:25:35.144: Find a better model.
2023-05-26 19:25:41.996: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.851011]
2023-05-26 19:25:42.153: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-26 19:25:42.153: Find a better model.
2023-05-26 19:25:48.969: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.815007]
2023-05-26 19:25:49.115: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-26 19:25:49.115: Find a better model.
2023-05-26 19:25:55.979: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.862003]
2023-05-26 19:25:56.138: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-26 19:25:56.139: Find a better model.
2023-05-26 19:26:02.805: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.664016]
2023-05-26 19:26:02.948: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-26 19:26:02.948: Find a better model.
2023-05-26 19:26:09.813: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.864019]
2023-05-26 19:26:09.969: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-26 19:26:09.969: Find a better model.
2023-05-26 19:26:16.789: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.819016]
2023-05-26 19:26:16.947: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-26 19:26:16.947: Find a better model.
2023-05-26 19:26:23.790: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.841999]
2023-05-26 19:26:23.938: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-26 19:26:23.938: Find a better model.
2023-05-26 19:26:30.773: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.834008]
2023-05-26 19:26:30.929: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-26 19:26:30.929: Find a better model.
2023-05-26 19:26:37.765: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.834359]
2023-05-26 19:26:37.912: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-26 19:26:37.912: Find a better model.
2023-05-26 19:26:44.590: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.677428]
2023-05-26 19:26:44.745: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-26 19:26:44.745: Find a better model.
2023-05-26 19:26:51.568: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.822015]
2023-05-26 19:26:51.728: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-26 19:26:51.729: Find a better model.
2023-05-26 19:26:58.574: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.843328]
2023-05-26 19:26:58.719: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-26 19:26:58.719: Find a better model.
2023-05-26 19:27:05.567: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.846022]
2023-05-26 19:27:05.724: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-26 19:27:05.724: Find a better model.
2023-05-26 19:27:12.552: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.827072]
2023-05-26 19:27:12.711: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-26 19:27:12.711: Find a better model.
2023-05-26 19:27:19.373: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.660012]
2023-05-26 19:27:19.533: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-26 19:27:19.534: Find a better model.
2023-05-26 19:27:26.353: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.818208]
2023-05-26 19:27:26.502: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-26 19:27:26.502: Find a better model.
2023-05-26 19:27:33.341: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.838032]
2023-05-26 19:27:33.502: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-26 19:27:33.502: Find a better model.
2023-05-26 19:27:40.373: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.868020]
2023-05-26 19:27:40.533: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-26 19:27:40.533: Find a better model.
2023-05-26 19:27:47.369: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.835359]
2023-05-26 19:27:47.530: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-26 19:27:47.530: Find a better model.
2023-05-26 19:27:54.170: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.638344]
2023-05-26 19:27:54.327: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-26 19:27:54.327: Find a better model.
2023-05-26 19:28:00.936: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.607975]
2023-05-26 19:28:01.080: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-26 19:28:01.080: Find a better model.
2023-05-26 19:28:07.742: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.661007]
2023-05-26 19:28:07.899: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-26 19:28:07.899: Find a better model.
2023-05-26 19:28:14.551: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.651053]
2023-05-26 19:28:14.708: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-26 19:28:21.371: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.660003]
2023-05-26 19:28:21.532: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-26 19:28:21.532: Find a better model.
2023-05-26 19:28:28.132: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.598025]
2023-05-26 19:28:28.276: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-26 19:28:28.277: Find a better model.
2023-05-26 19:28:34.934: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.655994]
2023-05-26 19:28:35.092: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-26 19:28:35.093: Find a better model.
2023-05-26 19:28:41.748: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.653158]
2023-05-26 19:28:41.903: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-26 19:28:41.903: Find a better model.
2023-05-26 19:28:48.548: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.642130]
2023-05-26 19:28:48.705: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-26 19:28:48.705: Find a better model.
2023-05-26 19:28:55.515: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.808994]
2023-05-26 19:28:55.658: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-26 19:29:02.332: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.671104]
2023-05-26 19:29:02.480: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-26 19:29:02.480: Find a better model.
2023-05-26 19:29:09.147: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.664036]
2023-05-26 19:29:09.291: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-26 19:29:09.291: Find a better model.
2023-05-26 19:29:15.908: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.616007]
2023-05-26 19:29:16.066: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-26 19:29:22.718: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.651501]
2023-05-26 19:29:22.863: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-26 19:29:22.864: Find a better model.
2023-05-26 19:29:29.695: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.830008]
2023-05-26 19:29:29.857: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-26 19:29:29.857: Find a better model.
2023-05-26 19:29:36.713: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.854374]
2023-05-26 19:29:36.870: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-26 19:29:36.870: Find a better model.
2023-05-26 19:29:43.715: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.843019]
2023-05-26 19:29:43.870: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-26 19:29:43.870: Find a better model.
2023-05-26 19:29:50.710: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.838054]
2023-05-26 19:29:50.868: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-26 19:29:50.868: Find a better model.
2023-05-26 19:29:57.695: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.825013]
2023-05-26 19:29:57.854: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-26 19:29:57.854: Find a better model.
2023-05-26 19:30:04.510: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.655482]
2023-05-26 19:30:04.655: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-26 19:30:04.655: Find a better model.
2023-05-26 19:30:11.320: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.663040]
2023-05-26 19:30:11.483: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-26 19:30:11.483: Find a better model.
2023-05-26 19:30:18.104: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.618475]
2023-05-26 19:30:18.259: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-26 19:30:24.914: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.651998]
2023-05-26 19:30:25.074: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-26 19:30:25.074: Find a better model.
2023-05-26 19:30:31.704: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.628024]
2023-05-26 19:30:31.859: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-26 19:30:31.859: Find a better model.
2023-05-26 19:30:38.522: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.662017]
2023-05-26 19:30:38.666: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-26 19:30:38.666: Find a better model.
2023-05-26 19:30:45.316: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.649035]
2023-05-26 19:30:45.473: epoch 71:	0.02632721  	0.19467905  	0.10684208  
2023-05-26 19:30:45.473: Find a better model.
2023-05-26 19:30:52.075: [iter 72 : loss : 0.2190 = 0.0478 + 0.1664 + 0.0048, time: 6.599029]
2023-05-26 19:30:52.219: epoch 72:	0.02639778  	0.19526137  	0.10706843  
2023-05-26 19:30:52.219: Find a better model.
2023-05-26 19:30:58.693: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.472101]
2023-05-26 19:30:58.853: epoch 73:	0.02641189  	0.19549032  	0.10711851  
2023-05-26 19:30:58.853: Find a better model.
2023-05-26 19:31:05.478: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.624204]
2023-05-26 19:31:05.633: epoch 74:	0.02646128  	0.19566278  	0.10750105  
2023-05-26 19:31:05.633: Find a better model.
2023-05-26 19:31:12.270: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.636456]
2023-05-26 19:31:12.414: epoch 75:	0.02654596  	0.19655427  	0.10756438  
2023-05-26 19:31:12.414: Find a better model.
2023-05-26 19:31:19.085: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.669069]
2023-05-26 19:31:19.240: epoch 76:	0.02658124  	0.19694291  	0.10773618  
2023-05-26 19:31:19.240: Find a better model.
2023-05-26 19:31:25.855: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.614119]
2023-05-26 19:31:26.005: epoch 77:	0.02659536  	0.19693758  	0.10767362  
2023-05-26 19:31:32.656: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.649038]
2023-05-26 19:31:32.800: epoch 78:	0.02667298  	0.19745006  	0.10793771  
2023-05-26 19:31:32.800: Find a better model.
2023-05-26 19:31:39.290: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.488210]
2023-05-26 19:31:39.446: epoch 79:	0.02668003  	0.19723570  	0.10796165  
2023-05-26 19:31:45.866: [iter 80 : loss : 0.2113 = 0.0410 + 0.1652 + 0.0051, time: 6.418037]
2023-05-26 19:31:46.009: epoch 80:	0.02660241  	0.19668077  	0.10794093  
2023-05-26 19:31:52.675: [iter 81 : loss : 0.2109 = 0.0408 + 0.1649 + 0.0052, time: 6.664444]
2023-05-26 19:31:52.819: epoch 81:	0.02660241  	0.19662951  	0.10788891  
2023-05-26 19:31:59.470: [iter 82 : loss : 0.2098 = 0.0398 + 0.1648 + 0.0052, time: 6.649149]
2023-05-26 19:31:59.627: epoch 82:	0.02648950  	0.19595857  	0.10781746  
2023-05-26 19:32:06.272: [iter 83 : loss : 0.2089 = 0.0390 + 0.1647 + 0.0053, time: 6.643175]
2023-05-26 19:32:06.416: epoch 83:	0.02652479  	0.19590060  	0.10785619  
2023-05-26 19:32:13.075: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.658071]
2023-05-26 19:32:13.233: epoch 84:	0.02666592  	0.19686697  	0.10816617  
2023-05-26 19:32:19.861: [iter 85 : loss : 0.2080 = 0.0382 + 0.1645 + 0.0053, time: 6.627191]
2023-05-26 19:32:20.017: epoch 85:	0.02672943  	0.19742045  	0.10843536  
2023-05-26 19:32:26.859: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.840056]
2023-05-26 19:32:27.014: epoch 86:	0.02670827  	0.19729351  	0.10853507  
2023-05-26 19:32:33.837: [iter 87 : loss : 0.2056 = 0.0359 + 0.1642 + 0.0054, time: 6.820999]
2023-05-26 19:32:33.993: epoch 87:	0.02684939  	0.19807866  	0.10880879  
2023-05-26 19:32:33.993: Find a better model.
2023-05-26 19:32:40.824: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.829031]
2023-05-26 19:32:40.970: epoch 88:	0.02677882  	0.19743504  	0.10857370  
2023-05-26 19:32:47.653: [iter 89 : loss : 0.2044 = 0.0349 + 0.1640 + 0.0055, time: 6.682004]
2023-05-26 19:32:47.812: epoch 89:	0.02676470  	0.19737278  	0.10859726  
2023-05-26 19:32:54.648: [iter 90 : loss : 0.2048 = 0.0354 + 0.1639 + 0.0056, time: 6.835038]
2023-05-26 19:32:54.805: epoch 90:	0.02679999  	0.19747011  	0.10859205  
2023-05-26 19:33:01.647: [iter 91 : loss : 0.2039 = 0.0346 + 0.1637 + 0.0056, time: 6.841009]
2023-05-26 19:33:01.803: epoch 91:	0.02690584  	0.19799265  	0.10877316  
2023-05-26 19:33:08.443: [iter 92 : loss : 0.2027 = 0.0334 + 0.1637 + 0.0056, time: 6.638451]
2023-05-26 19:33:08.588: epoch 92:	0.02691289  	0.19826379  	0.10894978  
2023-05-26 19:33:08.588: Find a better model.
2023-05-26 19:33:15.244: [iter 93 : loss : 0.2032 = 0.0340 + 0.1635 + 0.0057, time: 6.654660]
2023-05-26 19:33:15.387: epoch 93:	0.02687056  	0.19816786  	0.10876648  
2023-05-26 19:33:22.040: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.652031]
2023-05-26 19:33:22.185: epoch 94:	0.02691995  	0.19847873  	0.10902533  
2023-05-26 19:33:22.185: Find a better model.
2023-05-26 19:33:28.852: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.666049]
2023-05-26 19:33:28.997: epoch 95:	0.02691290  	0.19845925  	0.10908383  
2023-05-26 19:33:35.668: [iter 96 : loss : 0.2008 = 0.0318 + 0.1633 + 0.0058, time: 6.670039]
2023-05-26 19:33:35.826: epoch 96:	0.02686350  	0.19797319  	0.10892721  
2023-05-26 19:33:42.433: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.604003]
2023-05-26 19:33:42.593: epoch 97:	0.02693406  	0.19836716  	0.10927581  
2023-05-26 19:33:49.232: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.637359]
2023-05-26 19:33:49.390: epoch 98:	0.02695524  	0.19872387  	0.10946166  
2023-05-26 19:33:49.390: Find a better model.
2023-05-26 19:33:56.029: [iter 99 : loss : 0.1990 = 0.0301 + 0.1630 + 0.0059, time: 6.638174]
2023-05-26 19:33:56.186: epoch 99:	0.02705402  	0.19926168  	0.10963143  
2023-05-26 19:33:56.186: Find a better model.
2023-05-26 19:34:02.828: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.641080]
2023-05-26 19:34:02.986: epoch 100:	0.02703991  	0.19906844  	0.10961413  
2023-05-26 19:34:09.620: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.633005]
2023-05-26 19:34:09.778: epoch 101:	0.02706107  	0.19923046  	0.10964537  
2023-05-26 19:34:16.450: [iter 102 : loss : 0.1975 = 0.0287 + 0.1627 + 0.0060, time: 6.670156]
2023-05-26 19:34:16.608: epoch 102:	0.02708930  	0.19924369  	0.10959242  
2023-05-26 19:34:23.399: [iter 103 : loss : 0.1972 = 0.0285 + 0.1626 + 0.0061, time: 6.789007]
2023-05-26 19:34:23.543: epoch 103:	0.02708224  	0.19955929  	0.10977312  
2023-05-26 19:34:23.543: Find a better model.
2023-05-26 19:34:30.399: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.853492]
2023-05-26 19:34:30.557: epoch 104:	0.02706107  	0.19939709  	0.10980644  
2023-05-26 19:34:37.408: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.850005]
2023-05-26 19:34:37.568: epoch 105:	0.02699757  	0.19933391  	0.10972740  
2023-05-26 19:34:44.209: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.640008]
2023-05-26 19:34:44.353: epoch 106:	0.02701167  	0.19937827  	0.10984536  
2023-05-26 19:34:51.190: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.836004]
2023-05-26 19:34:51.349: epoch 107:	0.02707519  	0.19996868  	0.11013308  
2023-05-26 19:34:51.349: Find a better model.
2023-05-26 19:34:58.017: [iter 108 : loss : 0.1954 = 0.0268 + 0.1623 + 0.0063, time: 6.667007]
2023-05-26 19:34:58.174: epoch 108:	0.02701168  	0.19960755  	0.10998865  
2023-05-26 19:35:04.830: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.653016]
2023-05-26 19:35:04.986: epoch 109:	0.02703990  	0.19999591  	0.10987853  
2023-05-26 19:35:04.986: Find a better model.
2023-05-26 19:35:11.769: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.782007]
2023-05-26 19:35:11.925: epoch 110:	0.02702579  	0.20002608  	0.11001720  
2023-05-26 19:35:11.926: Find a better model.
2023-05-26 19:35:18.594: [iter 111 : loss : 0.1938 = 0.0254 + 0.1621 + 0.0064, time: 6.667282]
2023-05-26 19:35:18.739: epoch 111:	0.02699051  	0.19939613  	0.10990490  
2023-05-26 19:35:25.402: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.662166]
2023-05-26 19:35:25.560: epoch 112:	0.02703285  	0.19921325  	0.10983845  
2023-05-26 19:35:32.210: [iter 113 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0065, time: 6.648041]
2023-05-26 19:35:32.365: epoch 113:	0.02704696  	0.19930387  	0.10986166  
2023-05-26 19:35:38.999: [iter 114 : loss : 0.1929 = 0.0245 + 0.1619 + 0.0065, time: 6.632533]
2023-05-26 19:35:39.155: epoch 114:	0.02710341  	0.19960372  	0.10997800  
2023-05-26 19:35:45.804: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.647866]
2023-05-26 19:35:45.962: epoch 115:	0.02707519  	0.19947191  	0.10994811  
2023-05-26 19:35:52.581: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.618129]
2023-05-26 19:35:52.726: epoch 116:	0.02702579  	0.19887725  	0.10993224  
2023-05-26 19:35:59.393: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.666319]
2023-05-26 19:35:59.552: epoch 117:	0.02700462  	0.19904368  	0.10988788  
2023-05-26 19:36:06.188: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.635105]
2023-05-26 19:36:06.346: epoch 118:	0.02699050  	0.19841708  	0.10980463  
2023-05-26 19:36:13.164: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.817016]
2023-05-26 19:36:13.322: epoch 119:	0.02702578  	0.19877067  	0.10976239  
2023-05-26 19:36:19.994: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.671015]
2023-05-26 19:36:20.151: epoch 120:	0.02700462  	0.19849151  	0.10983420  
2023-05-26 19:36:26.785: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.632475]
2023-05-26 19:36:26.929: epoch 121:	0.02702579  	0.19868699  	0.10997424  
2023-05-26 19:36:33.577: [iter 122 : loss : 0.1906 = 0.0224 + 0.1614 + 0.0068, time: 6.647042]
2023-05-26 19:36:33.718: epoch 122:	0.02695522  	0.19836260  	0.10984993  
2023-05-26 19:36:40.356: [iter 123 : loss : 0.1904 = 0.0223 + 0.1613 + 0.0068, time: 6.637004]
2023-05-26 19:36:40.516: epoch 123:	0.02696933  	0.19824928  	0.10984535  
2023-05-26 19:36:47.183: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.666202]
2023-05-26 19:36:47.339: epoch 124:	0.02697639  	0.19827297  	0.10989806  
2023-05-26 19:36:53.961: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.620755]
2023-05-26 19:36:54.106: epoch 125:	0.02701872  	0.19851157  	0.10995675  
2023-05-26 19:37:00.750: [iter 126 : loss : 0.1894 = 0.0213 + 0.1612 + 0.0069, time: 6.642154]
2023-05-26 19:37:00.894: epoch 126:	0.02695522  	0.19831711  	0.11001152  
2023-05-26 19:37:07.549: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.654025]
2023-05-26 19:37:07.690: epoch 127:	0.02687760  	0.19777001  	0.10988597  
2023-05-26 19:37:14.374: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.681058]
2023-05-26 19:37:14.529: epoch 128:	0.02695521  	0.19822221  	0.10991577  
2023-05-26 19:37:21.169: [iter 129 : loss : 0.1886 = 0.0205 + 0.1611 + 0.0070, time: 6.639154]
2023-05-26 19:37:21.313: epoch 129:	0.02696227  	0.19817300  	0.10982906  
2023-05-26 19:37:27.952: [iter 130 : loss : 0.1887 = 0.0207 + 0.1610 + 0.0070, time: 6.637452]
2023-05-26 19:37:28.109: epoch 130:	0.02689171  	0.19778901  	0.10981072  
2023-05-26 19:37:34.759: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.648997]
2023-05-26 19:37:34.902: epoch 131:	0.02694110  	0.19793582  	0.10987618  
2023-05-26 19:37:41.538: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.634019]
2023-05-26 19:37:41.692: epoch 132:	0.02691288  	0.19796647  	0.10992124  
2023-05-26 19:37:48.361: [iter 133 : loss : 0.1871 = 0.0191 + 0.1609 + 0.0071, time: 6.668005]
2023-05-26 19:37:48.521: epoch 133:	0.02696227  	0.19811496  	0.10994389  
2023-05-26 19:37:55.155: [iter 134 : loss : 0.1876 = 0.0197 + 0.1608 + 0.0071, time: 6.633018]
2023-05-26 19:37:55.311: epoch 134:	0.02693404  	0.19767804  	0.10982610  
2023-05-26 19:38:01.967: [iter 135 : loss : 0.1874 = 0.0195 + 0.1607 + 0.0072, time: 6.655001]
2023-05-26 19:38:02.121: epoch 135:	0.02690582  	0.19751948  	0.10986010  
2023-05-26 19:38:02.121: Early stopping is trigger at epoch: 135
2023-05-26 19:38:02.121: best_result@epoch 110:

2023-05-26 19:38:02.121: 		0.0270      	0.2000      	0.1100      
2023-05-26 20:09:34.093: my pid: 4084
2023-05-26 20:09:34.093: model: model.general_recommender.SGL
2023-05-26 20:09:34.093: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 20:09:34.093: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 20:09:37.760: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 20:09:45.172: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.411234]
2023-05-26 20:09:45.316: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-26 20:09:45.316: Find a better model.
2023-05-26 20:09:52.890: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.573120]
2023-05-26 20:09:53.093: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-26 20:09:53.093: Find a better model.
2023-05-26 20:10:00.317: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.222720]
2023-05-26 20:10:00.493: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-26 20:10:00.493: Find a better model.
2023-05-26 20:10:07.498: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.003239]
2023-05-26 20:10:07.659: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-26 20:10:07.659: Find a better model.
2023-05-26 20:10:14.693: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.033029]
2023-05-26 20:10:14.839: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-26 20:10:14.839: Find a better model.
2023-05-26 20:10:21.665: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 6.824044]
2023-05-26 20:10:21.807: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-26 20:10:21.807: Find a better model.
2023-05-26 20:10:28.481: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.672330]
2023-05-26 20:10:28.623: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-26 20:10:28.623: Find a better model.
2023-05-26 20:10:35.270: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.646132]
2023-05-26 20:10:35.410: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-26 20:10:35.410: Find a better model.
2023-05-26 20:10:41.889: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.477939]
2023-05-26 20:10:42.046: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-26 20:10:42.046: Find a better model.
2023-05-26 20:10:48.473: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.426003]
2023-05-26 20:10:48.626: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-26 20:10:48.626: Find a better model.
2023-05-26 20:10:55.094: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.467189]
2023-05-26 20:10:55.249: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-26 20:10:55.249: Find a better model.
2023-05-26 20:11:01.836: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.585019]
2023-05-26 20:11:01.995: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-26 20:11:01.996: Find a better model.
2023-05-26 20:11:08.461: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.464083]
2023-05-26 20:11:08.601: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-26 20:11:08.601: Find a better model.
2023-05-26 20:11:15.063: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.460605]
2023-05-26 20:11:15.219: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-26 20:11:15.219: Find a better model.
2023-05-26 20:11:21.661: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.441179]
2023-05-26 20:11:21.800: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-26 20:11:21.800: Find a better model.
2023-05-26 20:11:28.254: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.453002]
2023-05-26 20:11:28.405: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-26 20:11:28.405: Find a better model.
2023-05-26 20:11:34.867: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.460056]
2023-05-26 20:11:35.010: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-26 20:11:35.010: Find a better model.
2023-05-26 20:11:41.473: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.462013]
2023-05-26 20:11:41.628: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-26 20:11:41.628: Find a better model.
2023-05-26 20:11:48.256: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.627040]
2023-05-26 20:11:48.413: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-26 20:11:48.413: Find a better model.
2023-05-26 20:11:55.025: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.610016]
2023-05-26 20:11:55.182: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-26 20:11:55.182: Find a better model.
2023-05-26 20:12:01.827: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.643999]
2023-05-26 20:12:01.990: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-26 20:12:01.990: Find a better model.
2023-05-26 20:12:08.630: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.639018]
2023-05-26 20:12:08.787: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-26 20:12:08.787: Find a better model.
2023-05-26 20:12:15.257: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.469014]
2023-05-26 20:12:15.412: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-26 20:12:15.412: Find a better model.
2023-05-26 20:12:22.024: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.610997]
2023-05-26 20:12:22.179: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-26 20:12:22.179: Find a better model.
2023-05-26 20:12:28.644: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.464052]
2023-05-26 20:12:28.799: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-26 20:12:28.799: Find a better model.
2023-05-26 20:12:35.241: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.441009]
2023-05-26 20:12:35.397: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-26 20:12:35.397: Find a better model.
2023-05-26 20:12:41.836: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.438281]
2023-05-26 20:12:41.994: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-26 20:12:41.994: Find a better model.
2023-05-26 20:12:48.404: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.408007]
2023-05-26 20:12:48.561: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-26 20:12:48.561: Find a better model.
2023-05-26 20:12:55.029: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.465499]
2023-05-26 20:12:55.181: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-26 20:12:55.181: Find a better model.
2023-05-26 20:13:01.629: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.446499]
2023-05-26 20:13:01.781: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-26 20:13:01.781: Find a better model.
2023-05-26 20:13:08.243: [iter 31 : loss : 0.4376 = 0.1715 + 0.2641 + 0.0020, time: 6.461404]
2023-05-26 20:13:08.387: epoch 31:	0.02313064  	0.17113926  	0.08933837  
2023-05-26 20:13:08.387: Find a better model.
2023-05-26 20:13:14.824: [iter 32 : loss : 0.4271 = 0.1616 + 0.2634 + 0.0021, time: 6.435279]
2023-05-26 20:13:14.982: epoch 32:	0.02339173  	0.17321081  	0.09051806  
2023-05-26 20:13:14.982: Find a better model.
2023-05-26 20:13:21.410: [iter 33 : loss : 0.4190 = 0.1543 + 0.2625 + 0.0022, time: 6.427399]
2023-05-26 20:13:21.564: epoch 33:	0.02348345  	0.17394656  	0.09135464  
2023-05-26 20:13:21.564: Find a better model.
2023-05-26 20:13:28.006: [iter 34 : loss : 0.4108 = 0.1468 + 0.2617 + 0.0023, time: 6.441052]
2023-05-26 20:13:28.158: epoch 34:	0.02362458  	0.17503196  	0.09213932  
2023-05-26 20:13:28.159: Find a better model.
2023-05-26 20:13:34.629: [iter 35 : loss : 0.4034 = 0.1401 + 0.2609 + 0.0024, time: 6.468459]
2023-05-26 20:13:34.784: epoch 35:	0.02374454  	0.17582044  	0.09307712  
2023-05-26 20:13:34.784: Find a better model.
2023-05-26 20:13:41.200: [iter 36 : loss : 0.3969 = 0.1343 + 0.2602 + 0.0025, time: 6.415106]
2023-05-26 20:13:41.345: epoch 36:	0.02394918  	0.17751829  	0.09400745  
2023-05-26 20:13:41.345: Find a better model.
2023-05-26 20:13:47.819: [iter 37 : loss : 0.3898 = 0.1279 + 0.2594 + 0.0026, time: 6.473046]
2023-05-26 20:13:47.978: epoch 37:	0.02409736  	0.17887959  	0.09480833  
2023-05-26 20:13:47.978: Find a better model.
2023-05-26 20:13:54.409: [iter 38 : loss : 0.3854 = 0.1241 + 0.2587 + 0.0026, time: 6.428786]
2023-05-26 20:13:54.564: epoch 38:	0.02423850  	0.18015358  	0.09577529  
2023-05-26 20:13:54.564: Find a better model.
2023-05-26 20:14:01.190: [iter 39 : loss : 0.3787 = 0.1180 + 0.2580 + 0.0027, time: 6.625027]
2023-05-26 20:14:01.344: epoch 39:	0.02442196  	0.18145519  	0.09665413  
2023-05-26 20:14:01.344: Find a better model.
2023-05-26 20:14:07.804: [iter 40 : loss : 0.3734 = 0.1134 + 0.2572 + 0.0028, time: 6.459014]
2023-05-26 20:14:07.962: epoch 40:	0.02451370  	0.18158165  	0.09718434  
2023-05-26 20:14:07.963: Find a better model.
2023-05-26 20:14:14.416: [iter 41 : loss : 0.3697 = 0.1101 + 0.2567 + 0.0029, time: 6.450009]
2023-05-26 20:14:14.567: epoch 41:	0.02464778  	0.18233761  	0.09772446  
2023-05-26 20:14:14.568: Find a better model.
2023-05-26 20:14:21.016: [iter 42 : loss : 0.3651 = 0.1062 + 0.2560 + 0.0030, time: 6.447397]
2023-05-26 20:14:21.171: epoch 42:	0.02473952  	0.18298288  	0.09838484  
2023-05-26 20:14:21.171: Find a better model.
2023-05-26 20:14:27.780: [iter 43 : loss : 0.3601 = 0.1017 + 0.2554 + 0.0030, time: 6.608064]
2023-05-26 20:14:27.925: epoch 43:	0.02488770  	0.18432704  	0.09910157  
2023-05-26 20:14:27.925: Find a better model.
2023-05-26 20:14:34.392: [iter 44 : loss : 0.3556 = 0.0977 + 0.2547 + 0.0031, time: 6.465017]
2023-05-26 20:14:34.543: epoch 44:	0.02507822  	0.18588677  	0.09982639  
2023-05-26 20:14:34.544: Find a better model.
2023-05-26 20:14:41.002: [iter 45 : loss : 0.3515 = 0.0940 + 0.2543 + 0.0032, time: 6.457034]
2023-05-26 20:14:41.141: epoch 45:	0.02515584  	0.18642087  	0.10033828  
2023-05-26 20:14:41.141: Find a better model.
2023-05-26 20:14:47.610: [iter 46 : loss : 0.3483 = 0.0913 + 0.2537 + 0.0033, time: 6.467322]
2023-05-26 20:14:47.762: epoch 46:	0.02521935  	0.18701465  	0.10066313  
2023-05-26 20:14:47.763: Find a better model.
2023-05-26 20:14:54.183: [iter 47 : loss : 0.3462 = 0.0896 + 0.2532 + 0.0033, time: 6.419171]
2023-05-26 20:14:54.340: epoch 47:	0.02525463  	0.18704106  	0.10091247  
2023-05-26 20:14:54.340: Find a better model.
2023-05-26 20:15:00.782: [iter 48 : loss : 0.3417 = 0.0856 + 0.2528 + 0.0034, time: 6.439994]
2023-05-26 20:15:00.936: epoch 48:	0.02530403  	0.18767536  	0.10141196  
2023-05-26 20:15:00.936: Find a better model.
2023-05-26 20:15:07.401: [iter 49 : loss : 0.3380 = 0.0822 + 0.2523 + 0.0035, time: 6.463352]
2023-05-26 20:15:07.555: epoch 49:	0.02539576  	0.18800889  	0.10192321  
2023-05-26 20:15:07.555: Find a better model.
2023-05-26 20:15:14.008: [iter 50 : loss : 0.3358 = 0.0804 + 0.2519 + 0.0036, time: 6.451276]
2023-05-26 20:15:14.153: epoch 50:	0.02547338  	0.18860294  	0.10243494  
2023-05-26 20:15:14.153: Find a better model.
2023-05-26 20:15:20.771: [iter 51 : loss : 0.3325 = 0.0774 + 0.2515 + 0.0036, time: 6.617158]
2023-05-26 20:15:20.924: epoch 51:	0.02562157  	0.18948242  	0.10301709  
2023-05-26 20:15:20.924: Find a better model.
2023-05-26 20:15:27.368: [iter 52 : loss : 0.3312 = 0.0765 + 0.2510 + 0.0037, time: 6.443014]
2023-05-26 20:15:27.520: epoch 52:	0.02579092  	0.19067582  	0.10377309  
2023-05-26 20:15:27.520: Find a better model.
2023-05-26 20:15:33.979: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.458011]
2023-05-26 20:15:34.131: epoch 53:	0.02586148  	0.19149116  	0.10428696  
2023-05-26 20:15:34.131: Find a better model.
2023-05-26 20:15:40.577: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.443941]
2023-05-26 20:15:40.732: epoch 54:	0.02589676  	0.19195156  	0.10455631  
2023-05-26 20:15:40.732: Find a better model.
2023-05-26 20:15:47.174: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.440969]
2023-05-26 20:15:47.328: epoch 55:	0.02591793  	0.19219516  	0.10478327  
2023-05-26 20:15:47.328: Find a better model.
2023-05-26 20:15:53.938: [iter 56 : loss : 0.3210 = 0.0676 + 0.2494 + 0.0040, time: 6.609089]
2023-05-26 20:15:54.088: epoch 56:	0.02593205  	0.19196197  	0.10502896  
2023-05-26 20:16:00.598: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.509025]
2023-05-26 20:16:00.754: epoch 57:	0.02595321  	0.19218220  	0.10519829  
2023-05-26 20:16:07.337: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.582435]
2023-05-26 20:16:07.491: epoch 58:	0.02606612  	0.19308290  	0.10578318  
2023-05-26 20:16:07.491: Find a better model.
2023-05-26 20:16:13.967: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.475003]
2023-05-26 20:16:14.120: epoch 59:	0.02609434  	0.19337738  	0.10590531  
2023-05-26 20:16:14.120: Find a better model.
2023-05-26 20:16:20.727: [iter 60 : loss : 0.3135 = 0.0611 + 0.2482 + 0.0042, time: 6.606022]
2023-05-26 20:16:20.870: epoch 60:	0.02620725  	0.19395447  	0.10629762  
2023-05-26 20:16:20.870: Find a better model.
2023-05-26 20:16:27.344: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.471505]
2023-05-26 20:16:27.501: epoch 61:	0.02620725  	0.19454296  	0.10651705  
2023-05-26 20:16:27.501: Find a better model.
2023-05-26 20:16:33.971: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.469035]
2023-05-26 20:16:34.126: epoch 62:	0.02617196  	0.19414380  	0.10654917  
2023-05-26 20:16:40.723: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.595027]
2023-05-26 20:16:40.866: epoch 63:	0.02618607  	0.19401701  	0.10670833  
2023-05-26 20:16:47.363: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.495083]
2023-05-26 20:16:47.516: epoch 64:	0.02620725  	0.19436824  	0.10687846  
2023-05-26 20:16:53.950: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.433075]
2023-05-26 20:16:54.092: epoch 65:	0.02627075  	0.19462110  	0.10707077  
2023-05-26 20:16:54.092: Find a better model.
2023-05-26 20:17:00.716: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.621993]
2023-05-26 20:17:00.858: epoch 66:	0.02630604  	0.19498673  	0.10724138  
2023-05-26 20:17:00.858: Find a better model.
2023-05-26 20:17:07.340: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.479994]
2023-05-26 20:17:07.492: epoch 67:	0.02628487  	0.19462584  	0.10712864  
2023-05-26 20:17:13.937: [iter 68 : loss : 0.3017 = 0.0509 + 0.2460 + 0.0047, time: 6.444026]
2023-05-26 20:17:14.091: epoch 68:	0.02644717  	0.19577003  	0.10764769  
2023-05-26 20:17:14.091: Find a better model.
2023-05-26 20:17:20.538: [iter 69 : loss : 0.2999 = 0.0493 + 0.2459 + 0.0047, time: 6.445912]
2023-05-26 20:17:20.692: epoch 69:	0.02650362  	0.19595338  	0.10772637  
2023-05-26 20:17:20.692: Find a better model.
2023-05-26 20:17:27.158: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.465014]
2023-05-26 20:17:27.312: epoch 70:	0.02664475  	0.19702859  	0.10820810  
2023-05-26 20:17:27.312: Find a better model.
2023-05-26 20:17:33.739: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.426045]
2023-05-26 20:17:33.894: epoch 71:	0.02656713  	0.19665308  	0.10810143  
2023-05-26 20:17:40.328: [iter 72 : loss : 0.2963 = 0.0462 + 0.2452 + 0.0049, time: 6.433023]
2023-05-26 20:17:40.483: epoch 72:	0.02656007  	0.19652425  	0.10810161  
2023-05-26 20:17:46.923: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.439004]
2023-05-26 20:17:47.077: epoch 73:	0.02660241  	0.19657025  	0.10818605  
2023-05-26 20:17:53.697: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.618003]
2023-05-26 20:17:53.841: epoch 74:	0.02668002  	0.19708768  	0.10849189  
2023-05-26 20:17:53.841: Find a better model.
2023-05-26 20:18:00.303: [iter 75 : loss : 0.2931 = 0.0434 + 0.2446 + 0.0050, time: 6.461012]
2023-05-26 20:18:00.446: epoch 75:	0.02665886  	0.19705616  	0.10869642  
2023-05-26 20:18:06.928: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.480341]
2023-05-26 20:18:07.069: epoch 76:	0.02672237  	0.19759066  	0.10885058  
2023-05-26 20:18:07.069: Find a better model.
2023-05-26 20:18:13.508: [iter 77 : loss : 0.2910 = 0.0416 + 0.2442 + 0.0051, time: 6.438004]
2023-05-26 20:18:13.662: epoch 77:	0.02660241  	0.19694234  	0.10861786  
2023-05-26 20:18:20.123: [iter 78 : loss : 0.2905 = 0.0411 + 0.2442 + 0.0052, time: 6.460101]
2023-05-26 20:18:20.275: epoch 78:	0.02660946  	0.19709215  	0.10860539  
2023-05-26 20:18:26.723: [iter 79 : loss : 0.2889 = 0.0398 + 0.2439 + 0.0052, time: 6.446994]
2023-05-26 20:18:26.868: epoch 79:	0.02658829  	0.19694187  	0.10879070  
2023-05-26 20:18:33.319: [iter 80 : loss : 0.2882 = 0.0391 + 0.2438 + 0.0053, time: 6.450052]
2023-05-26 20:18:33.473: epoch 80:	0.02657419  	0.19640031  	0.10893568  
2023-05-26 20:18:40.108: [iter 81 : loss : 0.2876 = 0.0387 + 0.2435 + 0.0053, time: 6.634015]
2023-05-26 20:18:40.265: epoch 81:	0.02662358  	0.19639891  	0.10882948  
2023-05-26 20:18:46.902: [iter 82 : loss : 0.2866 = 0.0377 + 0.2434 + 0.0054, time: 6.636038]
2023-05-26 20:18:47.057: epoch 82:	0.02664475  	0.19643548  	0.10897954  
2023-05-26 20:18:53.726: [iter 83 : loss : 0.2856 = 0.0368 + 0.2433 + 0.0054, time: 6.667009]
2023-05-26 20:18:53.881: epoch 83:	0.02664474  	0.19625504  	0.10897398  
2023-05-26 20:19:00.480: [iter 84 : loss : 0.2854 = 0.0368 + 0.2432 + 0.0055, time: 6.598003]
2023-05-26 20:19:00.622: epoch 84:	0.02665180  	0.19655758  	0.10916634  
2023-05-26 20:19:07.106: [iter 85 : loss : 0.2846 = 0.0361 + 0.2430 + 0.0055, time: 6.483632]
2023-05-26 20:19:07.261: epoch 85:	0.02671531  	0.19679391  	0.10921872  
2023-05-26 20:19:13.892: [iter 86 : loss : 0.2839 = 0.0355 + 0.2428 + 0.0056, time: 6.629155]
2023-05-26 20:19:14.049: epoch 86:	0.02675059  	0.19694127  	0.10930033  
2023-05-26 20:19:20.686: [iter 87 : loss : 0.2823 = 0.0339 + 0.2428 + 0.0056, time: 6.636014]
2023-05-26 20:19:20.838: epoch 87:	0.02675764  	0.19671313  	0.10924387  
2023-05-26 20:19:27.497: [iter 88 : loss : 0.2816 = 0.0334 + 0.2426 + 0.0057, time: 6.658009]
2023-05-26 20:19:27.652: epoch 88:	0.02679999  	0.19743767  	0.10942207  
2023-05-26 20:19:34.298: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.644014]
2023-05-26 20:19:34.450: epoch 89:	0.02684939  	0.19788803  	0.10946749  
2023-05-26 20:19:34.450: Find a better model.
2023-05-26 20:19:41.095: [iter 90 : loss : 0.2812 = 0.0331 + 0.2424 + 0.0058, time: 6.643178]
2023-05-26 20:19:41.251: epoch 90:	0.02680704  	0.19743480  	0.10953626  
2023-05-26 20:19:47.881: [iter 91 : loss : 0.2804 = 0.0324 + 0.2422 + 0.0058, time: 6.628258]
2023-05-26 20:19:48.035: epoch 91:	0.02679999  	0.19720061  	0.10942179  
2023-05-26 20:19:54.680: [iter 92 : loss : 0.2794 = 0.0314 + 0.2421 + 0.0059, time: 6.644054]
2023-05-26 20:19:54.824: epoch 92:	0.02684233  	0.19764683  	0.10956964  
2023-05-26 20:20:01.475: [iter 93 : loss : 0.2796 = 0.0317 + 0.2420 + 0.0059, time: 6.650013]
2023-05-26 20:20:01.631: epoch 93:	0.02683527  	0.19732410  	0.10942319  
2023-05-26 20:20:08.266: [iter 94 : loss : 0.2781 = 0.0303 + 0.2419 + 0.0059, time: 6.633017]
2023-05-26 20:20:08.421: epoch 94:	0.02688467  	0.19769357  	0.10951661  
2023-05-26 20:20:15.076: [iter 95 : loss : 0.2773 = 0.0295 + 0.2418 + 0.0060, time: 6.654014]
2023-05-26 20:20:15.233: epoch 95:	0.02691289  	0.19751687  	0.10961682  
2023-05-26 20:20:21.897: [iter 96 : loss : 0.2773 = 0.0296 + 0.2417 + 0.0060, time: 6.663015]
2023-05-26 20:20:22.054: epoch 96:	0.02691289  	0.19757000  	0.10966053  
2023-05-26 20:20:28.672: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.616047]
2023-05-26 20:20:28.815: epoch 97:	0.02695522  	0.19788107  	0.10953988  
2023-05-26 20:20:35.289: [iter 98 : loss : 0.2762 = 0.0285 + 0.2415 + 0.0061, time: 6.472994]
2023-05-26 20:20:35.444: epoch 98:	0.02700462  	0.19844425  	0.10980920  
2023-05-26 20:20:35.444: Find a better model.
2023-05-26 20:20:42.078: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.632102]
2023-05-26 20:20:42.234: epoch 99:	0.02700462  	0.19818346  	0.10982536  
2023-05-26 20:20:48.884: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.648388]
2023-05-26 20:20:49.040: epoch 100:	0.02701873  	0.19844089  	0.11000974  
2023-05-26 20:20:55.666: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0062, time: 6.624443]
2023-05-26 20:20:55.819: epoch 101:	0.02694111  	0.19778022  	0.10990904  
2023-05-26 20:21:02.459: [iter 102 : loss : 0.2740 = 0.0266 + 0.2411 + 0.0063, time: 6.639032]
2023-05-26 20:21:02.614: epoch 102:	0.02696228  	0.19787811  	0.10996224  
2023-05-26 20:21:09.077: [iter 103 : loss : 0.2737 = 0.0264 + 0.2410 + 0.0063, time: 6.461010]
2023-05-26 20:21:09.232: epoch 103:	0.02688466  	0.19749592  	0.10999902  
2023-05-26 20:21:15.851: [iter 104 : loss : 0.2739 = 0.0265 + 0.2410 + 0.0064, time: 6.618049]
2023-05-26 20:21:16.008: epoch 104:	0.02694817  	0.19784074  	0.11006626  
2023-05-26 20:21:22.676: [iter 105 : loss : 0.2734 = 0.0261 + 0.2409 + 0.0064, time: 6.666994]
2023-05-26 20:21:22.832: epoch 105:	0.02691288  	0.19767874  	0.10999887  
2023-05-26 20:21:29.445: [iter 106 : loss : 0.2728 = 0.0256 + 0.2408 + 0.0064, time: 6.612107]
2023-05-26 20:21:29.598: epoch 106:	0.02690583  	0.19772007  	0.10999474  
2023-05-26 20:21:36.248: [iter 107 : loss : 0.2722 = 0.0250 + 0.2407 + 0.0065, time: 6.648433]
2023-05-26 20:21:36.403: epoch 107:	0.02698345  	0.19822273  	0.11025540  
2023-05-26 20:21:43.033: [iter 108 : loss : 0.2718 = 0.0246 + 0.2407 + 0.0065, time: 6.629027]
2023-05-26 20:21:43.173: epoch 108:	0.02695522  	0.19820224  	0.11018248  
2023-05-26 20:21:49.854: [iter 109 : loss : 0.2710 = 0.0239 + 0.2405 + 0.0066, time: 6.679348]
2023-05-26 20:21:50.012: epoch 109:	0.02701167  	0.19867304  	0.11033682  
2023-05-26 20:21:50.012: Find a better model.
2023-05-26 20:21:56.643: [iter 110 : loss : 0.2707 = 0.0236 + 0.2405 + 0.0066, time: 6.629994]
2023-05-26 20:21:56.786: epoch 110:	0.02691288  	0.19797565  	0.11020956  
2023-05-26 20:22:03.414: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.627009]
2023-05-26 20:22:03.571: epoch 111:	0.02694111  	0.19832711  	0.11024847  
2023-05-26 20:22:10.212: [iter 112 : loss : 0.2702 = 0.0231 + 0.2403 + 0.0067, time: 6.640013]
2023-05-26 20:22:10.372: epoch 112:	0.02688466  	0.19778535  	0.11014106  
2023-05-26 20:22:17.016: [iter 113 : loss : 0.2701 = 0.0232 + 0.2403 + 0.0067, time: 6.642031]
2023-05-26 20:22:17.157: epoch 113:	0.02686349  	0.19749074  	0.10998349  
2023-05-26 20:22:23.826: [iter 114 : loss : 0.2694 = 0.0225 + 0.2402 + 0.0068, time: 6.666032]
2023-05-26 20:22:23.985: epoch 114:	0.02689877  	0.19772485  	0.11004275  
2023-05-26 20:22:30.622: [iter 115 : loss : 0.2692 = 0.0223 + 0.2401 + 0.0068, time: 6.635006]
2023-05-26 20:22:30.766: epoch 115:	0.02693406  	0.19803935  	0.11015212  
2023-05-26 20:22:37.416: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.649070]
2023-05-26 20:22:37.573: epoch 116:	0.02683526  	0.19692279  	0.10980484  
2023-05-26 20:22:44.225: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.651492]
2023-05-26 20:22:44.380: epoch 117:	0.02680704  	0.19651401  	0.10974305  
2023-05-26 20:22:51.007: [iter 118 : loss : 0.2683 = 0.0215 + 0.2399 + 0.0069, time: 6.626008]
2023-05-26 20:22:51.152: epoch 118:	0.02672941  	0.19601068  	0.10968585  
2023-05-26 20:22:57.814: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.661019]
2023-05-26 20:22:57.957: epoch 119:	0.02682114  	0.19664471  	0.10988603  
2023-05-26 20:23:04.602: [iter 120 : loss : 0.2678 = 0.0211 + 0.2398 + 0.0070, time: 6.640998]
2023-05-26 20:23:04.755: epoch 120:	0.02680703  	0.19616537  	0.10971799  
2023-05-26 20:23:11.393: [iter 121 : loss : 0.2677 = 0.0209 + 0.2397 + 0.0070, time: 6.636013]
2023-05-26 20:23:11.546: epoch 121:	0.02679998  	0.19594070  	0.10962106  
2023-05-26 20:23:18.034: [iter 122 : loss : 0.2672 = 0.0205 + 0.2397 + 0.0070, time: 6.486004]
2023-05-26 20:23:18.187: epoch 122:	0.02677175  	0.19575155  	0.10966523  
2023-05-26 20:23:24.795: [iter 123 : loss : 0.2670 = 0.0203 + 0.2396 + 0.0071, time: 6.606197]
2023-05-26 20:23:24.952: epoch 123:	0.02679292  	0.19597507  	0.10970287  
2023-05-26 20:23:31.407: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.453011]
2023-05-26 20:23:31.563: epoch 124:	0.02672941  	0.19554050  	0.10967202  
2023-05-26 20:23:38.181: [iter 125 : loss : 0.2660 = 0.0193 + 0.2395 + 0.0071, time: 6.617110]
2023-05-26 20:23:38.337: epoch 125:	0.02677175  	0.19571957  	0.10974053  
2023-05-26 20:23:45.014: [iter 126 : loss : 0.2661 = 0.0195 + 0.2394 + 0.0072, time: 6.675003]
2023-05-26 20:23:45.168: epoch 126:	0.02675764  	0.19561198  	0.10968725  
2023-05-26 20:23:51.812: [iter 127 : loss : 0.2653 = 0.0186 + 0.2394 + 0.0072, time: 6.643004]
2023-05-26 20:23:51.971: epoch 127:	0.02678587  	0.19623688  	0.10979077  
2023-05-26 20:23:58.601: [iter 128 : loss : 0.2658 = 0.0192 + 0.2393 + 0.0073, time: 6.629003]
2023-05-26 20:23:58.757: epoch 128:	0.02682114  	0.19617824  	0.10973947  
2023-05-26 20:24:05.191: [iter 129 : loss : 0.2653 = 0.0186 + 0.2393 + 0.0073, time: 6.433023]
2023-05-26 20:24:05.334: epoch 129:	0.02675058  	0.19556324  	0.10939351  
2023-05-26 20:24:11.997: [iter 130 : loss : 0.2654 = 0.0188 + 0.2392 + 0.0073, time: 6.661074]
2023-05-26 20:24:12.150: epoch 130:	0.02675764  	0.19550906  	0.10938886  
2023-05-26 20:24:18.779: [iter 131 : loss : 0.2647 = 0.0181 + 0.2392 + 0.0073, time: 6.628008]
2023-05-26 20:24:18.923: epoch 131:	0.02667296  	0.19476336  	0.10940970  
2023-05-26 20:24:25.402: [iter 132 : loss : 0.2646 = 0.0181 + 0.2391 + 0.0074, time: 6.477070]
2023-05-26 20:24:25.560: epoch 132:	0.02660945  	0.19419864  	0.10919825  
2023-05-26 20:24:32.189: [iter 133 : loss : 0.2639 = 0.0174 + 0.2391 + 0.0074, time: 6.628050]
2023-05-26 20:24:32.343: epoch 133:	0.02662356  	0.19442834  	0.10920586  
2023-05-26 20:24:38.800: [iter 134 : loss : 0.2643 = 0.0178 + 0.2390 + 0.0074, time: 6.456039]
2023-05-26 20:24:38.952: epoch 134:	0.02659534  	0.19398254  	0.10918355  
2023-05-26 20:24:38.952: Early stopping is trigger at epoch: 134
2023-05-26 20:24:38.952: best_result@epoch 109:

2023-05-26 20:24:38.952: 		0.0270      	0.1987      	0.1103      
2023-05-26 20:34:38.800: my pid: 15712
2023-05-26 20:34:38.800: model: model.general_recommender.SGL
2023-05-26 20:34:38.800: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 20:34:38.800: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 20:34:42.475: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 20:34:49.824: [iter 1 : loss : 1.0070 = 0.6930 + 0.3140 + 0.0000, time: 7.349015]
2023-05-26 20:34:49.982: epoch 1:	0.00148180  	0.01007288  	0.00518638  
2023-05-26 20:34:49.983: Find a better model.
2023-05-26 20:34:57.411: [iter 2 : loss : 1.0056 = 0.6929 + 0.3127 + 0.0000, time: 7.427641]
2023-05-26 20:34:57.623: epoch 2:	0.00215214  	0.01506323  	0.00759623  
2023-05-26 20:34:57.623: Find a better model.
2023-05-26 20:35:05.196: [iter 3 : loss : 1.0053 = 0.6928 + 0.3125 + 0.0000, time: 7.572034]
2023-05-26 20:35:05.374: epoch 3:	0.00323877  	0.02255323  	0.01167415  
2023-05-26 20:35:05.374: Find a better model.
2023-05-26 20:35:12.602: [iter 4 : loss : 1.0051 = 0.6927 + 0.3124 + 0.0000, time: 7.226457]
2023-05-26 20:35:12.767: epoch 4:	0.00409961  	0.02849601  	0.01466823  
2023-05-26 20:35:12.767: Find a better model.
2023-05-26 20:35:19.818: [iter 5 : loss : 1.0049 = 0.6925 + 0.3124 + 0.0000, time: 7.050070]
2023-05-26 20:35:19.970: epoch 5:	0.00508747  	0.03545045  	0.01763683  
2023-05-26 20:35:19.970: Find a better model.
2023-05-26 20:35:26.974: [iter 6 : loss : 1.0049 = 0.6923 + 0.3125 + 0.0000, time: 7.003014]
2023-05-26 20:35:27.130: epoch 6:	0.00594831  	0.04169608  	0.02087439  
2023-05-26 20:35:27.130: Find a better model.
2023-05-26 20:35:33.779: [iter 7 : loss : 1.0045 = 0.6920 + 0.3124 + 0.0000, time: 6.647151]
2023-05-26 20:35:33.934: epoch 7:	0.00666097  	0.04731534  	0.02407812  
2023-05-26 20:35:33.934: Find a better model.
2023-05-26 20:35:40.754: [iter 8 : loss : 1.0043 = 0.6918 + 0.3126 + 0.0000, time: 6.819291]
2023-05-26 20:35:40.910: epoch 8:	0.00738069  	0.05191480  	0.02677541  
2023-05-26 20:35:40.910: Find a better model.
2023-05-26 20:35:47.751: [iter 9 : loss : 1.0040 = 0.6913 + 0.3127 + 0.0000, time: 6.839993]
2023-05-26 20:35:47.895: epoch 9:	0.00829798  	0.05921273  	0.03056381  
2023-05-26 20:35:47.895: Find a better model.
2023-05-26 20:35:54.552: [iter 10 : loss : 1.0036 = 0.6908 + 0.3128 + 0.0000, time: 6.656061]
2023-05-26 20:35:54.694: epoch 10:	0.00963162  	0.06750149  	0.03438413  
2023-05-26 20:35:54.694: Find a better model.
2023-05-26 20:36:01.370: [iter 11 : loss : 1.0030 = 0.6901 + 0.3129 + 0.0000, time: 6.674454]
2023-05-26 20:36:01.527: epoch 11:	0.01059835  	0.07446928  	0.03832243  
2023-05-26 20:36:01.527: Find a better model.
2023-05-26 20:36:08.154: [iter 12 : loss : 1.0022 = 0.6891 + 0.3130 + 0.0000, time: 6.626482]
2023-05-26 20:36:08.298: epoch 12:	0.01136046  	0.08116855  	0.04098159  
2023-05-26 20:36:08.298: Find a better model.
2023-05-26 20:36:14.952: [iter 13 : loss : 1.0010 = 0.6878 + 0.3132 + 0.0000, time: 6.653025]
2023-05-26 20:36:15.109: epoch 13:	0.01239775  	0.08946972  	0.04417939  
2023-05-26 20:36:15.109: Find a better model.
2023-05-26 20:36:21.572: [iter 14 : loss : 0.9993 = 0.6858 + 0.3134 + 0.0000, time: 6.462006]
2023-05-26 20:36:21.733: epoch 14:	0.01337860  	0.09696855  	0.04757192  
2023-05-26 20:36:21.733: Find a better model.
2023-05-26 20:36:28.327: [iter 15 : loss : 0.9967 = 0.6830 + 0.3137 + 0.0000, time: 6.593030]
2023-05-26 20:36:28.485: epoch 15:	0.01452174  	0.10474711  	0.05135924  
2023-05-26 20:36:28.485: Find a better model.
2023-05-26 20:36:34.955: [iter 16 : loss : 0.9927 = 0.6785 + 0.3141 + 0.0000, time: 6.469005]
2023-05-26 20:36:35.112: epoch 16:	0.01546730  	0.11179481  	0.05466865  
2023-05-26 20:36:35.112: Find a better model.
2023-05-26 20:36:41.738: [iter 17 : loss : 0.9865 = 0.6718 + 0.3147 + 0.0001, time: 6.624044]
2023-05-26 20:36:41.894: epoch 17:	0.01671629  	0.12208136  	0.05999736  
2023-05-26 20:36:41.894: Find a better model.
2023-05-26 20:36:48.544: [iter 18 : loss : 0.9772 = 0.6616 + 0.3155 + 0.0001, time: 6.648762]
2023-05-26 20:36:48.700: epoch 18:	0.01781003  	0.13029225  	0.06439240  
2023-05-26 20:36:48.700: Find a better model.
2023-05-26 20:36:55.343: [iter 19 : loss : 0.9631 = 0.6460 + 0.3169 + 0.0001, time: 6.641994]
2023-05-26 20:36:55.503: epoch 19:	0.01876969  	0.13692948  	0.06849489  
2023-05-26 20:36:55.503: Find a better model.
2023-05-26 20:37:02.125: [iter 20 : loss : 0.9430 = 0.6239 + 0.3190 + 0.0002, time: 6.619416]
2023-05-26 20:37:02.284: epoch 20:	0.01959530  	0.14298858  	0.07248525  
2023-05-26 20:37:02.284: Find a better model.
2023-05-26 20:37:08.923: [iter 21 : loss : 0.9149 = 0.5928 + 0.3219 + 0.0002, time: 6.638433]
2023-05-26 20:37:09.079: epoch 21:	0.02002576  	0.14709623  	0.07509179  
2023-05-26 20:37:09.079: Find a better model.
2023-05-26 20:37:15.742: [iter 22 : loss : 0.8791 = 0.5533 + 0.3255 + 0.0003, time: 6.661493]
2023-05-26 20:37:15.899: epoch 22:	0.02035036  	0.14914866  	0.07656167  
2023-05-26 20:37:15.899: Find a better model.
2023-05-26 20:37:22.523: [iter 23 : loss : 0.8370 = 0.5066 + 0.3299 + 0.0005, time: 6.623379]
2023-05-26 20:37:22.668: epoch 23:	0.02071024  	0.15207280  	0.07861388  
2023-05-26 20:37:22.668: Find a better model.
2023-05-26 20:37:29.331: [iter 24 : loss : 0.7915 = 0.4567 + 0.3343 + 0.0006, time: 6.661070]
2023-05-26 20:37:29.489: epoch 24:	0.02112658  	0.15577087  	0.08042523  
2023-05-26 20:37:29.489: Find a better model.
2023-05-26 20:37:35.929: [iter 25 : loss : 0.7469 = 0.4081 + 0.3381 + 0.0007, time: 6.439062]
2023-05-26 20:37:36.085: epoch 25:	0.02139472  	0.15815508  	0.08172884  
2023-05-26 20:37:36.085: Find a better model.
2023-05-26 20:37:42.531: [iter 26 : loss : 0.7068 = 0.3648 + 0.3411 + 0.0009, time: 6.445339]
2023-05-26 20:37:42.690: epoch 26:	0.02162759  	0.15912354  	0.08272821  
2023-05-26 20:37:42.690: Find a better model.
2023-05-26 20:37:49.132: [iter 27 : loss : 0.6704 = 0.3262 + 0.3432 + 0.0010, time: 6.440231]
2023-05-26 20:37:49.291: epoch 27:	0.02183224  	0.16129296  	0.08379698  
2023-05-26 20:37:49.291: Find a better model.
2023-05-26 20:37:55.746: [iter 28 : loss : 0.6398 = 0.2941 + 0.3445 + 0.0012, time: 6.454279]
2023-05-26 20:37:55.904: epoch 28:	0.02202982  	0.16227755  	0.08456451  
2023-05-26 20:37:55.904: Find a better model.
2023-05-26 20:38:02.524: [iter 29 : loss : 0.6146 = 0.2682 + 0.3451 + 0.0013, time: 6.619078]
2023-05-26 20:38:02.680: epoch 29:	0.02222740  	0.16435389  	0.08586542  
2023-05-26 20:38:02.680: Find a better model.
2023-05-26 20:38:09.314: [iter 30 : loss : 0.5914 = 0.2445 + 0.3454 + 0.0014, time: 6.632921]
2023-05-26 20:38:09.474: epoch 30:	0.02251671  	0.16634847  	0.08708978  
2023-05-26 20:38:09.474: Find a better model.
2023-05-26 20:38:16.126: [iter 31 : loss : 0.5726 = 0.2259 + 0.3451 + 0.0016, time: 6.650993]
2023-05-26 20:38:16.282: epoch 31:	0.02273547  	0.16816933  	0.08820927  
2023-05-26 20:38:16.282: Find a better model.
2023-05-26 20:38:22.885: [iter 32 : loss : 0.5557 = 0.2092 + 0.3448 + 0.0017, time: 6.601408]
2023-05-26 20:38:23.029: epoch 32:	0.02301773  	0.17058854  	0.08936694  
2023-05-26 20:38:23.030: Find a better model.
2023-05-26 20:38:29.703: [iter 33 : loss : 0.5418 = 0.1958 + 0.3441 + 0.0018, time: 6.672210]
2023-05-26 20:38:29.858: epoch 33:	0.02325766  	0.17228720  	0.09050984  
2023-05-26 20:38:29.858: Find a better model.
2023-05-26 20:38:36.495: [iter 34 : loss : 0.5289 = 0.1836 + 0.3434 + 0.0019, time: 6.636175]
2023-05-26 20:38:36.639: epoch 34:	0.02351168  	0.17402668  	0.09165509  
2023-05-26 20:38:36.639: Find a better model.
2023-05-26 20:38:43.287: [iter 35 : loss : 0.5173 = 0.1726 + 0.3426 + 0.0020, time: 6.647056]
2023-05-26 20:38:43.437: epoch 35:	0.02361048  	0.17472023  	0.09246583  
2023-05-26 20:38:43.437: Find a better model.
2023-05-26 20:38:50.109: [iter 36 : loss : 0.5073 = 0.1632 + 0.3419 + 0.0021, time: 6.671149]
2023-05-26 20:38:50.252: epoch 36:	0.02378688  	0.17620981  	0.09341335  
2023-05-26 20:38:50.252: Find a better model.
2023-05-26 20:38:56.890: [iter 37 : loss : 0.4971 = 0.1538 + 0.3410 + 0.0023, time: 6.636050]
2023-05-26 20:38:57.034: epoch 37:	0.02397740  	0.17784250  	0.09445093  
2023-05-26 20:38:57.035: Find a better model.
2023-05-26 20:39:03.687: [iter 38 : loss : 0.4900 = 0.1473 + 0.3402 + 0.0024, time: 6.650983]
2023-05-26 20:39:03.845: epoch 38:	0.02416087  	0.17913727  	0.09532082  
2023-05-26 20:39:03.845: Find a better model.
2023-05-26 20:39:10.510: [iter 39 : loss : 0.4809 = 0.1390 + 0.3394 + 0.0025, time: 6.664008]
2023-05-26 20:39:10.663: epoch 39:	0.02430200  	0.18023491  	0.09610991  
2023-05-26 20:39:10.663: Find a better model.
2023-05-26 20:39:17.299: [iter 40 : loss : 0.4736 = 0.1325 + 0.3385 + 0.0025, time: 6.634125]
2023-05-26 20:39:17.458: epoch 40:	0.02445725  	0.18119749  	0.09695539  
2023-05-26 20:39:17.458: Find a better model.
2023-05-26 20:39:24.111: [iter 41 : loss : 0.4680 = 0.1275 + 0.3379 + 0.0026, time: 6.651143]
2023-05-26 20:39:24.268: epoch 41:	0.02465483  	0.18251188  	0.09764455  
2023-05-26 20:39:24.268: Find a better model.
2023-05-26 20:39:30.907: [iter 42 : loss : 0.4616 = 0.1219 + 0.3370 + 0.0027, time: 6.637013]
2023-05-26 20:39:31.063: epoch 42:	0.02472540  	0.18241698  	0.09809777  
2023-05-26 20:39:37.695: [iter 43 : loss : 0.4552 = 0.1161 + 0.3363 + 0.0028, time: 6.630295]
2023-05-26 20:39:37.851: epoch 43:	0.02494415  	0.18405953  	0.09889601  
2023-05-26 20:39:37.851: Find a better model.
2023-05-26 20:39:44.520: [iter 44 : loss : 0.4494 = 0.1111 + 0.3355 + 0.0029, time: 6.667716]
2023-05-26 20:39:44.675: epoch 44:	0.02504999  	0.18522117  	0.09964625  
2023-05-26 20:39:44.676: Find a better model.
2023-05-26 20:39:51.478: [iter 45 : loss : 0.4442 = 0.1062 + 0.3350 + 0.0030, time: 6.801014]
2023-05-26 20:39:51.632: epoch 45:	0.02523346  	0.18638903  	0.10026917  
2023-05-26 20:39:51.632: Find a better model.
2023-05-26 20:39:58.281: [iter 46 : loss : 0.4399 = 0.1025 + 0.3343 + 0.0031, time: 6.648221]
2023-05-26 20:39:58.430: epoch 46:	0.02535342  	0.18741462  	0.10098146  
2023-05-26 20:39:58.430: Find a better model.
2023-05-26 20:40:05.255: [iter 47 : loss : 0.4366 = 0.0998 + 0.3336 + 0.0032, time: 6.824236]
2023-05-26 20:40:05.402: epoch 47:	0.02531814  	0.18720473  	0.10125151  
2023-05-26 20:40:12.084: [iter 48 : loss : 0.4313 = 0.0950 + 0.3331 + 0.0032, time: 6.681063]
2023-05-26 20:40:12.241: epoch 48:	0.02544516  	0.18822250  	0.10185024  
2023-05-26 20:40:12.241: Find a better model.
2023-05-26 20:40:18.893: [iter 49 : loss : 0.4268 = 0.0910 + 0.3325 + 0.0033, time: 6.651052]
2023-05-26 20:40:19.051: epoch 49:	0.02559335  	0.18903971  	0.10247834  
2023-05-26 20:40:19.051: Find a better model.
2023-05-26 20:40:25.704: [iter 50 : loss : 0.4238 = 0.0885 + 0.3320 + 0.0034, time: 6.650627]
2023-05-26 20:40:25.860: epoch 50:	0.02566390  	0.18951471  	0.10286330  
2023-05-26 20:40:25.860: Find a better model.
2023-05-26 20:40:32.647: [iter 51 : loss : 0.4198 = 0.0848 + 0.3315 + 0.0035, time: 6.786009]
2023-05-26 20:40:32.805: epoch 51:	0.02578386  	0.19060752  	0.10342834  
2023-05-26 20:40:32.805: Find a better model.
2023-05-26 20:40:39.468: [iter 52 : loss : 0.4178 = 0.0833 + 0.3309 + 0.0036, time: 6.660764]
2023-05-26 20:40:39.623: epoch 52:	0.02590382  	0.19155687  	0.10399558  
2023-05-26 20:40:39.623: Find a better model.
2023-05-26 20:40:46.270: [iter 53 : loss : 0.4143 = 0.0803 + 0.3305 + 0.0036, time: 6.646009]
2023-05-26 20:40:46.428: epoch 53:	0.02587559  	0.19127105  	0.10417134  
2023-05-26 20:40:53.044: [iter 54 : loss : 0.4111 = 0.0775 + 0.3299 + 0.0037, time: 6.614050]
2023-05-26 20:40:53.199: epoch 54:	0.02594616  	0.19159524  	0.10435758  
2023-05-26 20:40:53.199: Find a better model.
2023-05-26 20:40:59.864: [iter 55 : loss : 0.4087 = 0.0753 + 0.3296 + 0.0038, time: 6.664016]
2023-05-26 20:41:00.025: epoch 55:	0.02602378  	0.19233549  	0.10473789  
2023-05-26 20:41:00.025: Find a better model.
2023-05-26 20:41:06.639: [iter 56 : loss : 0.4055 = 0.0726 + 0.3290 + 0.0038, time: 6.611004]
2023-05-26 20:41:06.780: epoch 56:	0.02608729  	0.19295378  	0.10496452  
2023-05-26 20:41:06.780: Find a better model.
2023-05-26 20:41:13.284: [iter 57 : loss : 0.4030 = 0.0703 + 0.3288 + 0.0039, time: 6.501036]
2023-05-26 20:41:13.442: epoch 57:	0.02606612  	0.19302586  	0.10518946  
2023-05-26 20:41:13.442: Find a better model.
2023-05-26 20:41:20.052: [iter 58 : loss : 0.4005 = 0.0682 + 0.3283 + 0.0040, time: 6.608203]
2023-05-26 20:41:20.196: epoch 58:	0.02605906  	0.19283541  	0.10544541  
2023-05-26 20:41:26.824: [iter 59 : loss : 0.3986 = 0.0668 + 0.3278 + 0.0040, time: 6.627021]
2023-05-26 20:41:26.981: epoch 59:	0.02612257  	0.19311804  	0.10581274  
2023-05-26 20:41:26.982: Find a better model.
2023-05-26 20:41:33.653: [iter 60 : loss : 0.3965 = 0.0648 + 0.3276 + 0.0041, time: 6.670155]
2023-05-26 20:41:33.807: epoch 60:	0.02619314  	0.19354142  	0.10599627  
2023-05-26 20:41:33.807: Find a better model.
2023-05-26 20:41:40.447: [iter 61 : loss : 0.3945 = 0.0631 + 0.3272 + 0.0042, time: 6.638107]
2023-05-26 20:41:40.602: epoch 61:	0.02619314  	0.19366035  	0.10615892  
2023-05-26 20:41:40.602: Find a better model.
2023-05-26 20:41:47.253: [iter 62 : loss : 0.3924 = 0.0613 + 0.3269 + 0.0042, time: 6.650043]
2023-05-26 20:41:47.416: epoch 62:	0.02619314  	0.19376324  	0.10627453  
2023-05-26 20:41:47.416: Find a better model.
2023-05-26 20:41:54.057: [iter 63 : loss : 0.3906 = 0.0597 + 0.3265 + 0.0043, time: 6.640194]
2023-05-26 20:41:54.210: epoch 63:	0.02630604  	0.19445267  	0.10674449  
2023-05-26 20:41:54.211: Find a better model.
2023-05-26 20:42:00.823: [iter 64 : loss : 0.3888 = 0.0583 + 0.3262 + 0.0044, time: 6.611003]
2023-05-26 20:42:00.966: epoch 64:	0.02633427  	0.19449477  	0.10683773  
2023-05-26 20:42:00.966: Find a better model.
2023-05-26 20:42:07.627: [iter 65 : loss : 0.3872 = 0.0569 + 0.3259 + 0.0044, time: 6.658024]
2023-05-26 20:42:07.784: epoch 65:	0.02639071  	0.19482753  	0.10702604  
2023-05-26 20:42:07.784: Find a better model.
2023-05-26 20:42:14.430: [iter 66 : loss : 0.3852 = 0.0551 + 0.3256 + 0.0045, time: 6.644005]
2023-05-26 20:42:14.587: epoch 66:	0.02641894  	0.19526856  	0.10740890  
2023-05-26 20:42:14.587: Find a better model.
2023-05-26 20:42:21.238: [iter 67 : loss : 0.3835 = 0.0536 + 0.3253 + 0.0046, time: 6.648994]
2023-05-26 20:42:21.392: epoch 67:	0.02646833  	0.19560318  	0.10762072  
2023-05-26 20:42:21.392: Find a better model.
2023-05-26 20:42:28.041: [iter 68 : loss : 0.3825 = 0.0528 + 0.3250 + 0.0046, time: 6.646666]
2023-05-26 20:42:28.199: epoch 68:	0.02653184  	0.19578533  	0.10800016  
2023-05-26 20:42:28.199: Find a better model.
2023-05-26 20:42:34.837: [iter 69 : loss : 0.3806 = 0.0511 + 0.3248 + 0.0047, time: 6.637001]
2023-05-26 20:42:34.993: epoch 69:	0.02651772  	0.19560575  	0.10797007  
2023-05-26 20:42:41.646: [iter 70 : loss : 0.3789 = 0.0496 + 0.3246 + 0.0047, time: 6.650154]
2023-05-26 20:42:41.802: epoch 70:	0.02654595  	0.19614500  	0.10813651  
2023-05-26 20:42:41.802: Find a better model.
2023-05-26 20:42:48.412: [iter 71 : loss : 0.3776 = 0.0485 + 0.3243 + 0.0048, time: 6.608055]
2023-05-26 20:42:48.568: epoch 71:	0.02653184  	0.19581193  	0.10803458  
2023-05-26 20:42:55.219: [iter 72 : loss : 0.3765 = 0.0475 + 0.3241 + 0.0049, time: 6.650003]
2023-05-26 20:42:55.364: epoch 72:	0.02653890  	0.19587782  	0.10821004  
2023-05-26 20:43:01.817: [iter 73 : loss : 0.3750 = 0.0462 + 0.3238 + 0.0049, time: 6.452262]
2023-05-26 20:43:01.974: epoch 73:	0.02655301  	0.19610190  	0.10843011  
2023-05-26 20:43:08.617: [iter 74 : loss : 0.3738 = 0.0452 + 0.3236 + 0.0050, time: 6.642015]
2023-05-26 20:43:08.775: epoch 74:	0.02662358  	0.19626659  	0.10857198  
2023-05-26 20:43:08.775: Find a better model.
2023-05-26 20:43:15.428: [iter 75 : loss : 0.3729 = 0.0444 + 0.3234 + 0.0050, time: 6.652019]
2023-05-26 20:43:15.584: epoch 75:	0.02658829  	0.19594529  	0.10877099  
2023-05-26 20:43:22.235: [iter 76 : loss : 0.3719 = 0.0436 + 0.3232 + 0.0051, time: 6.649017]
2023-05-26 20:43:22.391: epoch 76:	0.02656712  	0.19581038  	0.10867977  
2023-05-26 20:43:28.995: [iter 77 : loss : 0.3706 = 0.0425 + 0.3229 + 0.0051, time: 6.602004]
2023-05-26 20:43:29.138: epoch 77:	0.02661652  	0.19610807  	0.10878604  
2023-05-26 20:43:35.811: [iter 78 : loss : 0.3700 = 0.0419 + 0.3229 + 0.0052, time: 6.671021]
2023-05-26 20:43:35.965: epoch 78:	0.02658829  	0.19571926  	0.10886982  
2023-05-26 20:43:42.611: [iter 79 : loss : 0.3683 = 0.0404 + 0.3226 + 0.0053, time: 6.644020]
2023-05-26 20:43:42.768: epoch 79:	0.02665886  	0.19608146  	0.10917289  
2023-05-26 20:43:49.409: [iter 80 : loss : 0.3676 = 0.0398 + 0.3225 + 0.0053, time: 6.639207]
2023-05-26 20:43:49.564: epoch 80:	0.02660241  	0.19565818  	0.10884228  
2023-05-26 20:43:56.405: [iter 81 : loss : 0.3668 = 0.0392 + 0.3222 + 0.0054, time: 6.838025]
2023-05-26 20:43:56.558: epoch 81:	0.02667297  	0.19615598  	0.10917326  
2023-05-26 20:44:03.391: [iter 82 : loss : 0.3657 = 0.0382 + 0.3221 + 0.0054, time: 6.831046]
2023-05-26 20:44:03.547: epoch 82:	0.02671531  	0.19611071  	0.10924837  
2023-05-26 20:44:10.425: [iter 83 : loss : 0.3645 = 0.0371 + 0.3219 + 0.0055, time: 6.876935]
2023-05-26 20:44:10.581: epoch 83:	0.02676471  	0.19663517  	0.10956565  
2023-05-26 20:44:10.581: Find a better model.
2023-05-26 20:44:17.393: [iter 84 : loss : 0.3644 = 0.0371 + 0.3218 + 0.0055, time: 6.810594]
2023-05-26 20:44:17.549: epoch 84:	0.02669415  	0.19598928  	0.10928155  
2023-05-26 20:44:24.377: [iter 85 : loss : 0.3635 = 0.0363 + 0.3216 + 0.0056, time: 6.826043]
2023-05-26 20:44:24.531: epoch 85:	0.02664474  	0.19547884  	0.10908054  
2023-05-26 20:44:31.391: [iter 86 : loss : 0.3626 = 0.0356 + 0.3214 + 0.0056, time: 6.859346]
2023-05-26 20:44:31.549: epoch 86:	0.02664475  	0.19546974  	0.10906222  
2023-05-26 20:44:38.360: [iter 87 : loss : 0.3612 = 0.0342 + 0.3213 + 0.0057, time: 6.809064]
2023-05-26 20:44:38.516: epoch 87:	0.02674353  	0.19618616  	0.10932925  
2023-05-26 20:44:45.192: [iter 88 : loss : 0.3604 = 0.0335 + 0.3212 + 0.0057, time: 6.674025]
2023-05-26 20:44:45.349: epoch 88:	0.02668003  	0.19599743  	0.10929459  
2023-05-26 20:44:52.151: [iter 89 : loss : 0.3596 = 0.0328 + 0.3210 + 0.0058, time: 6.801054]
2023-05-26 20:44:52.309: epoch 89:	0.02665886  	0.19534288  	0.10915130  
2023-05-26 20:44:59.156: [iter 90 : loss : 0.3597 = 0.0331 + 0.3209 + 0.0058, time: 6.845018]
2023-05-26 20:44:59.299: epoch 90:	0.02668002  	0.19557011  	0.10923841  
2023-05-26 20:45:06.140: [iter 91 : loss : 0.3589 = 0.0324 + 0.3207 + 0.0059, time: 6.839005]
2023-05-26 20:45:06.287: epoch 91:	0.02660240  	0.19493346  	0.10896840  
2023-05-26 20:45:13.170: [iter 92 : loss : 0.3579 = 0.0314 + 0.3206 + 0.0059, time: 6.881931]
2023-05-26 20:45:13.331: epoch 92:	0.02663768  	0.19492726  	0.10900769  
2023-05-26 20:45:20.168: [iter 93 : loss : 0.3580 = 0.0315 + 0.3205 + 0.0060, time: 6.836183]
2023-05-26 20:45:20.326: epoch 93:	0.02653889  	0.19423972  	0.10899338  
2023-05-26 20:45:27.140: [iter 94 : loss : 0.3566 = 0.0302 + 0.3204 + 0.0060, time: 6.813208]
2023-05-26 20:45:27.296: epoch 94:	0.02657417  	0.19452216  	0.10909594  
2023-05-26 20:45:34.165: [iter 95 : loss : 0.3557 = 0.0294 + 0.3203 + 0.0060, time: 6.867160]
2023-05-26 20:45:34.320: epoch 95:	0.02654595  	0.19432059  	0.10914962  
2023-05-26 20:45:41.181: [iter 96 : loss : 0.3557 = 0.0295 + 0.3201 + 0.0061, time: 6.859044]
2023-05-26 20:45:41.337: epoch 96:	0.02652477  	0.19412920  	0.10895195  
2023-05-26 20:45:48.163: [iter 97 : loss : 0.3545 = 0.0284 + 0.3200 + 0.0061, time: 6.824039]
2023-05-26 20:45:48.320: epoch 97:	0.02659534  	0.19435094  	0.10893353  
2023-05-26 20:45:55.154: [iter 98 : loss : 0.3544 = 0.0282 + 0.3199 + 0.0062, time: 6.833003]
2023-05-26 20:45:55.299: epoch 98:	0.02660240  	0.19451287  	0.10915563  
2023-05-26 20:46:02.146: [iter 99 : loss : 0.3537 = 0.0276 + 0.3198 + 0.0062, time: 6.846409]
2023-05-26 20:46:02.301: epoch 99:	0.02672942  	0.19557889  	0.10957950  
2023-05-26 20:46:09.144: [iter 100 : loss : 0.3534 = 0.0274 + 0.3197 + 0.0063, time: 6.841221]
2023-05-26 20:46:09.300: epoch 100:	0.02675059  	0.19575262  	0.10966080  
2023-05-26 20:46:16.153: [iter 101 : loss : 0.3527 = 0.0268 + 0.3196 + 0.0063, time: 6.851004]
2023-05-26 20:46:16.310: epoch 101:	0.02672236  	0.19576915  	0.10961102  
2023-05-26 20:46:23.139: [iter 102 : loss : 0.3522 = 0.0263 + 0.3195 + 0.0064, time: 6.826153]
2023-05-26 20:46:23.294: epoch 102:	0.02672942  	0.19586974  	0.10961901  
2023-05-26 20:46:29.957: [iter 103 : loss : 0.3519 = 0.0261 + 0.3193 + 0.0064, time: 6.662013]
2023-05-26 20:46:30.115: epoch 103:	0.02672942  	0.19576344  	0.10985539  
2023-05-26 20:46:36.919: [iter 104 : loss : 0.3519 = 0.0261 + 0.3193 + 0.0065, time: 6.803026]
2023-05-26 20:46:37.076: epoch 104:	0.02665886  	0.19519873  	0.10964206  
2023-05-26 20:46:43.760: [iter 105 : loss : 0.3514 = 0.0257 + 0.3193 + 0.0065, time: 6.683017]
2023-05-26 20:46:43.917: epoch 105:	0.02665180  	0.19492903  	0.10942134  
2023-05-26 20:46:50.550: [iter 106 : loss : 0.3509 = 0.0252 + 0.3192 + 0.0065, time: 6.631008]
2023-05-26 20:46:50.706: epoch 106:	0.02663063  	0.19471340  	0.10923199  
2023-05-26 20:46:57.526: [iter 107 : loss : 0.3503 = 0.0246 + 0.3191 + 0.0066, time: 6.818488]
2023-05-26 20:46:57.671: epoch 107:	0.02658124  	0.19438769  	0.10924303  
2023-05-26 20:47:04.334: [iter 108 : loss : 0.3498 = 0.0241 + 0.3191 + 0.0066, time: 6.662069]
2023-05-26 20:47:04.492: epoch 108:	0.02665180  	0.19499312  	0.10952955  
2023-05-26 20:47:04.492: Early stopping is trigger at epoch: 108
2023-05-26 20:47:04.493: best_result@epoch 83:

2023-05-26 20:47:04.493: 		0.0268      	0.1966      	0.1096      
2023-05-26 20:56:59.419: my pid: 1056
2023-05-26 20:56:59.420: model: model.general_recommender.SGL
2023-05-26 20:56:59.420: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 20:56:59.420: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 20:57:03.067: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 20:57:10.402: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.334965]
2023-05-26 20:57:10.550: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-26 20:57:10.550: Find a better model.
2023-05-26 20:57:18.173: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.621163]
2023-05-26 20:57:18.389: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-26 20:57:18.389: Find a better model.
2023-05-26 20:57:25.745: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.355224]
2023-05-26 20:57:25.928: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-26 20:57:25.928: Find a better model.
2023-05-26 20:57:33.113: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.183101]
2023-05-26 20:57:33.286: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-26 20:57:33.286: Find a better model.
2023-05-26 20:57:40.338: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.050996]
2023-05-26 20:57:40.503: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-26 20:57:40.503: Find a better model.
2023-05-26 20:57:47.484: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.980068]
2023-05-26 20:57:47.643: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-26 20:57:47.643: Find a better model.
2023-05-26 20:57:54.675: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 7.030003]
2023-05-26 20:57:54.820: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-26 20:57:54.820: Find a better model.
2023-05-26 20:58:01.701: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.880015]
2023-05-26 20:58:01.862: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-26 20:58:01.862: Find a better model.
2023-05-26 20:58:08.683: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.819372]
2023-05-26 20:58:08.829: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-26 20:58:15.502: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.672033]
2023-05-26 20:58:15.661: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-26 20:58:22.305: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.642027]
2023-05-26 20:58:22.464: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-26 20:58:29.104: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.639491]
2023-05-26 20:58:29.263: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-26 20:58:35.901: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.635537]
2023-05-26 20:58:36.060: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-26 20:58:42.874: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.813001]
2023-05-26 20:58:43.035: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-26 20:58:49.858: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.822116]
2023-05-26 20:58:50.017: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-26 20:58:50.017: Find a better model.
2023-05-26 20:58:56.875: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.857015]
2023-05-26 20:58:57.021: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-26 20:58:57.021: Find a better model.
2023-05-26 20:59:03.683: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.660000]
2023-05-26 20:59:03.843: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-26 20:59:03.843: Find a better model.
2023-05-26 20:59:10.498: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.653047]
2023-05-26 20:59:10.642: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-26 20:59:10.642: Find a better model.
2023-05-26 20:59:17.278: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.634323]
2023-05-26 20:59:17.437: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-26 20:59:17.437: Find a better model.
2023-05-26 20:59:24.090: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.652008]
2023-05-26 20:59:24.248: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-26 20:59:24.248: Find a better model.
2023-05-26 20:59:31.048: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.799007]
2023-05-26 20:59:31.205: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-26 20:59:31.205: Find a better model.
2023-05-26 20:59:38.061: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.854034]
2023-05-26 20:59:38.219: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-26 20:59:38.219: Find a better model.
2023-05-26 20:59:44.874: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.654003]
2023-05-26 20:59:45.034: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-26 20:59:45.034: Find a better model.
2023-05-26 20:59:51.863: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.827007]
2023-05-26 20:59:52.022: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-26 20:59:52.022: Find a better model.
2023-05-26 20:59:58.661: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.637024]
2023-05-26 20:59:58.807: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-26 20:59:58.807: Find a better model.
2023-05-26 21:00:05.479: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.669994]
2023-05-26 21:00:05.634: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-26 21:00:05.634: Find a better model.
2023-05-26 21:00:12.256: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.621024]
2023-05-26 21:00:12.415: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-26 21:00:12.415: Find a better model.
2023-05-26 21:00:19.052: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.635004]
2023-05-26 21:00:19.208: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-26 21:00:19.208: Find a better model.
2023-05-26 21:00:25.857: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.648030]
2023-05-26 21:00:26.015: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-26 21:00:26.015: Find a better model.
2023-05-26 21:00:32.646: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.629035]
2023-05-26 21:00:32.804: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-26 21:00:32.804: Find a better model.
2023-05-26 21:00:39.470: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.665456]
2023-05-26 21:00:39.629: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-26 21:00:39.629: Find a better model.
2023-05-26 21:00:46.246: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.616004]
2023-05-26 21:00:46.388: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-26 21:00:46.388: Find a better model.
2023-05-26 21:00:53.054: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.664338]
2023-05-26 21:00:53.212: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-26 21:00:53.212: Find a better model.
2023-05-26 21:00:59.863: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.650021]
2023-05-26 21:01:00.027: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-26 21:01:00.027: Find a better model.
2023-05-26 21:01:06.814: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.785401]
2023-05-26 21:01:06.972: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-26 21:01:06.972: Find a better model.
2023-05-26 21:01:13.637: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.663021]
2023-05-26 21:01:13.797: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-26 21:01:13.797: Find a better model.
2023-05-26 21:01:20.637: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.839058]
2023-05-26 21:01:20.795: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-26 21:01:20.795: Find a better model.
2023-05-26 21:01:27.632: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.835493]
2023-05-26 21:01:27.790: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-26 21:01:27.790: Find a better model.
2023-05-26 21:01:34.614: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.822997]
2023-05-26 21:01:34.762: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-26 21:01:34.762: Find a better model.
2023-05-26 21:01:41.427: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.664031]
2023-05-26 21:01:41.586: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-26 21:01:48.223: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.636006]
2023-05-26 21:01:48.379: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-26 21:01:48.379: Find a better model.
2023-05-26 21:01:55.020: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.640506]
2023-05-26 21:01:55.177: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-26 21:01:55.177: Find a better model.
2023-05-26 21:02:01.829: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.650019]
2023-05-26 21:02:01.986: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-26 21:02:01.986: Find a better model.
2023-05-26 21:02:08.815: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.828262]
2023-05-26 21:02:08.974: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-26 21:02:08.974: Find a better model.
2023-05-26 21:02:15.793: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.816851]
2023-05-26 21:02:15.950: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-26 21:02:15.951: Find a better model.
2023-05-26 21:02:22.612: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.660530]
2023-05-26 21:02:22.770: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-26 21:02:22.770: Find a better model.
2023-05-26 21:02:29.413: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.641001]
2023-05-26 21:02:29.557: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-26 21:02:29.557: Find a better model.
2023-05-26 21:02:36.233: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.675062]
2023-05-26 21:02:36.389: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-26 21:02:36.389: Find a better model.
2023-05-26 21:02:43.012: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.620009]
2023-05-26 21:02:43.171: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-26 21:02:43.171: Find a better model.
2023-05-26 21:02:49.830: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.657255]
2023-05-26 21:02:49.987: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-26 21:02:49.987: Find a better model.
2023-05-26 21:02:56.613: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.625302]
2023-05-26 21:02:56.772: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-26 21:03:03.405: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.630010]
2023-05-26 21:03:03.548: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-26 21:03:03.548: Find a better model.
2023-05-26 21:03:10.206: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.655010]
2023-05-26 21:03:10.363: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-26 21:03:10.363: Find a better model.
2023-05-26 21:03:17.176: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.812011]
2023-05-26 21:03:17.333: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-26 21:03:17.334: Find a better model.
2023-05-26 21:03:24.000: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.664008]
2023-05-26 21:03:24.157: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-26 21:03:24.157: Find a better model.
2023-05-26 21:03:30.967: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.809175]
2023-05-26 21:03:31.125: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-26 21:03:31.126: Find a better model.
2023-05-26 21:03:38.001: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.873045]
2023-05-26 21:03:38.156: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-26 21:03:38.157: Find a better model.
2023-05-26 21:03:44.973: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.815019]
2023-05-26 21:03:45.130: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-26 21:03:45.130: Find a better model.
2023-05-26 21:03:51.953: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.821228]
2023-05-26 21:03:52.097: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-26 21:03:52.097: Find a better model.
2023-05-26 21:03:58.958: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.860804]
2023-05-26 21:03:59.117: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-26 21:03:59.117: Find a better model.
2023-05-26 21:04:05.972: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.854007]
2023-05-26 21:04:06.131: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-26 21:04:06.131: Find a better model.
2023-05-26 21:04:12.968: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.836082]
2023-05-26 21:04:13.124: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-26 21:04:13.124: Find a better model.
2023-05-26 21:04:19.952: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.825003]
2023-05-26 21:04:20.106: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-26 21:04:26.768: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.659015]
2023-05-26 21:04:26.928: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-26 21:04:26.928: Find a better model.
2023-05-26 21:04:33.744: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.814008]
2023-05-26 21:04:33.902: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-26 21:04:33.902: Find a better model.
2023-05-26 21:04:40.566: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.662010]
2023-05-26 21:04:40.726: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-26 21:04:40.726: Find a better model.
2023-05-26 21:04:47.374: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.646015]
2023-05-26 21:04:47.518: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-26 21:04:47.518: Find a better model.
2023-05-26 21:04:54.177: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.657006]
2023-05-26 21:04:54.332: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-26 21:04:54.332: Find a better model.
2023-05-26 21:05:01.137: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.803017]
2023-05-26 21:05:01.297: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-26 21:05:01.297: Find a better model.
2023-05-26 21:05:07.978: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.679016]
2023-05-26 21:05:08.135: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-26 21:05:08.135: Find a better model.
2023-05-26 21:05:14.938: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.802019]
2023-05-26 21:05:15.093: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-26 21:05:21.741: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.646095]
2023-05-26 21:05:21.887: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-26 21:05:21.887: Find a better model.
2023-05-26 21:05:28.742: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.852993]
2023-05-26 21:05:28.898: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-26 21:05:28.899: Find a better model.
2023-05-26 21:05:35.757: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.857114]
2023-05-26 21:05:35.914: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-26 21:05:42.745: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.829004]
2023-05-26 21:05:42.901: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-26 21:05:49.736: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.834004]
2023-05-26 21:05:49.897: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-26 21:05:49.897: Find a better model.
2023-05-26 21:05:56.536: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.638099]
2023-05-26 21:05:56.681: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-26 21:05:56.681: Find a better model.
2023-05-26 21:06:03.337: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.654442]
2023-05-26 21:06:03.493: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-26 21:06:03.493: Find a better model.
2023-05-26 21:06:10.124: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.628106]
2023-05-26 21:06:10.268: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-26 21:06:16.937: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.668018]
2023-05-26 21:06:17.095: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-26 21:06:17.096: Find a better model.
2023-05-26 21:06:23.922: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.824993]
2023-05-26 21:06:24.077: epoch 81:	0.02575562  	0.19010241  	0.10375397  
2023-05-26 21:06:24.077: Find a better model.
2023-05-26 21:06:30.732: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.654410]
2023-05-26 21:06:30.889: epoch 82:	0.02593909  	0.19127873  	0.10442533  
2023-05-26 21:06:30.889: Find a better model.
2023-05-26 21:06:37.545: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.655015]
2023-05-26 21:06:37.687: epoch 83:	0.02591792  	0.19122753  	0.10434162  
2023-05-26 21:06:44.306: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.618141]
2023-05-26 21:06:44.465: epoch 84:	0.02591792  	0.19129056  	0.10438651  
2023-05-26 21:06:44.465: Find a better model.
2023-05-26 21:06:51.117: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.650415]
2023-05-26 21:06:51.276: epoch 85:	0.02591087  	0.19136642  	0.10479141  
2023-05-26 21:06:51.276: Find a better model.
2023-05-26 21:06:57.928: [iter 86 : loss : 0.1368 = 0.0466 + 0.0854 + 0.0049, time: 6.651239]
2023-05-26 21:06:58.087: epoch 86:	0.02597438  	0.19166841  	0.10489704  
2023-05-26 21:06:58.087: Find a better model.
2023-05-26 21:07:04.720: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.632034]
2023-05-26 21:07:04.864: epoch 87:	0.02607317  	0.19224219  	0.10512664  
2023-05-26 21:07:04.864: Find a better model.
2023-05-26 21:07:11.519: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.652945]
2023-05-26 21:07:11.677: epoch 88:	0.02608023  	0.19226837  	0.10511711  
2023-05-26 21:07:11.677: Find a better model.
2023-05-26 21:07:18.319: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.640010]
2023-05-26 21:07:18.476: epoch 89:	0.02603083  	0.19170186  	0.10493099  
2023-05-26 21:07:25.121: [iter 90 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 6.643885]
2023-05-26 21:07:25.280: epoch 90:	0.02620724  	0.19286238  	0.10541573  
2023-05-26 21:07:25.280: Find a better model.
2023-05-26 21:07:32.103: [iter 91 : loss : 0.1326 = 0.0427 + 0.0849 + 0.0050, time: 6.822006]
2023-05-26 21:07:32.260: epoch 91:	0.02622841  	0.19313850  	0.10552373  
2023-05-26 21:07:32.261: Find a better model.
2023-05-26 21:07:39.099: [iter 92 : loss : 0.1314 = 0.0415 + 0.0848 + 0.0051, time: 6.837039]
2023-05-26 21:07:39.253: epoch 92:	0.02627075  	0.19332008  	0.10576090  
2023-05-26 21:07:39.253: Find a better model.
2023-05-26 21:07:46.098: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.843083]
2023-05-26 21:07:46.256: epoch 93:	0.02627075  	0.19348899  	0.10588790  
2023-05-26 21:07:46.256: Find a better model.
2023-05-26 21:07:53.112: [iter 94 : loss : 0.1300 = 0.0402 + 0.0847 + 0.0052, time: 6.855007]
2023-05-26 21:07:53.270: epoch 94:	0.02635543  	0.19406378  	0.10619053  
2023-05-26 21:07:53.270: Find a better model.
2023-05-26 21:08:00.101: [iter 95 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.830003]
2023-05-26 21:08:00.247: epoch 95:	0.02633426  	0.19389744  	0.10619268  
2023-05-26 21:08:07.103: [iter 96 : loss : 0.1293 = 0.0395 + 0.0845 + 0.0052, time: 6.854441]
2023-05-26 21:08:07.260: epoch 96:	0.02634132  	0.19409056  	0.10637274  
2023-05-26 21:08:07.260: Find a better model.
2023-05-26 21:08:14.106: [iter 97 : loss : 0.1278 = 0.0380 + 0.0844 + 0.0053, time: 6.844474]
2023-05-26 21:08:14.262: epoch 97:	0.02636249  	0.19429554  	0.10640383  
2023-05-26 21:08:14.262: Find a better model.
2023-05-26 21:08:21.092: [iter 98 : loss : 0.1283 = 0.0386 + 0.0844 + 0.0053, time: 6.828012]
2023-05-26 21:08:21.248: epoch 98:	0.02648244  	0.19523402  	0.10681716  
2023-05-26 21:08:21.248: Find a better model.
2023-05-26 21:08:28.079: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 6.830019]
2023-05-26 21:08:28.220: epoch 99:	0.02655301  	0.19598447  	0.10705537  
2023-05-26 21:08:28.221: Find a better model.
2023-05-26 21:08:35.107: [iter 100 : loss : 0.1269 = 0.0373 + 0.0842 + 0.0054, time: 6.884993]
2023-05-26 21:08:35.264: epoch 100:	0.02659534  	0.19634457  	0.10703243  
2023-05-26 21:08:35.264: Find a better model.
2023-05-26 21:08:42.087: [iter 101 : loss : 0.1264 = 0.0369 + 0.0842 + 0.0054, time: 6.821065]
2023-05-26 21:08:42.246: epoch 101:	0.02660240  	0.19647186  	0.10709044  
2023-05-26 21:08:42.247: Find a better model.
2023-05-26 21:08:49.074: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0055, time: 6.826007]
2023-05-26 21:08:49.231: epoch 102:	0.02668708  	0.19690756  	0.10741451  
2023-05-26 21:08:49.231: Find a better model.
2023-05-26 21:08:55.889: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.657007]
2023-05-26 21:08:56.045: epoch 103:	0.02675059  	0.19726913  	0.10752033  
2023-05-26 21:08:56.046: Find a better model.
2023-05-26 21:09:02.868: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.821026]
2023-05-26 21:09:03.024: epoch 104:	0.02677882  	0.19760688  	0.10782767  
2023-05-26 21:09:03.024: Find a better model.
2023-05-26 21:09:09.861: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.836020]
2023-05-26 21:09:10.009: epoch 105:	0.02672236  	0.19744344  	0.10785587  
2023-05-26 21:09:16.852: [iter 106 : loss : 0.1245 = 0.0351 + 0.0838 + 0.0056, time: 6.842467]
2023-05-26 21:09:17.012: epoch 106:	0.02668708  	0.19671057  	0.10751266  
2023-05-26 21:09:23.887: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.874008]
2023-05-26 21:09:24.047: epoch 107:	0.02674353  	0.19702877  	0.10767464  
2023-05-26 21:09:30.878: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 6.830047]
2023-05-26 21:09:31.037: epoch 108:	0.02673647  	0.19723104  	0.10775126  
2023-05-26 21:09:37.895: [iter 109 : loss : 0.1221 = 0.0328 + 0.0837 + 0.0057, time: 6.857422]
2023-05-26 21:09:38.052: epoch 109:	0.02679998  	0.19769494  	0.10783163  
2023-05-26 21:09:38.052: Find a better model.
2023-05-26 21:09:44.850: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.797015]
2023-05-26 21:09:44.994: epoch 110:	0.02684232  	0.19785798  	0.10784698  
2023-05-26 21:09:44.994: Find a better model.
2023-05-26 21:09:51.866: [iter 111 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0058, time: 6.870023]
2023-05-26 21:09:52.022: epoch 111:	0.02684937  	0.19813547  	0.10797223  
2023-05-26 21:09:52.022: Find a better model.
2023-05-26 21:09:58.853: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.830013]
2023-05-26 21:09:58.995: epoch 112:	0.02691288  	0.19853370  	0.10813242  
2023-05-26 21:09:58.996: Find a better model.
2023-05-26 21:10:05.851: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.853345]
2023-05-26 21:10:06.008: epoch 113:	0.02695522  	0.19914421  	0.10828746  
2023-05-26 21:10:06.008: Find a better model.
2023-05-26 21:10:12.850: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.841013]
2023-05-26 21:10:12.994: epoch 114:	0.02696933  	0.19924569  	0.10850157  
2023-05-26 21:10:12.994: Find a better model.
2023-05-26 21:10:19.860: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.863033]
2023-05-26 21:10:20.017: epoch 115:	0.02697638  	0.19884273  	0.10851567  
2023-05-26 21:10:26.837: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.819233]
2023-05-26 21:10:26.996: epoch 116:	0.02691287  	0.19814719  	0.10833178  
2023-05-26 21:10:33.859: [iter 117 : loss : 0.1192 = 0.0301 + 0.0832 + 0.0060, time: 6.862014]
2023-05-26 21:10:34.018: epoch 117:	0.02690581  	0.19802162  	0.10819709  
2023-05-26 21:10:40.855: [iter 118 : loss : 0.1190 = 0.0299 + 0.0832 + 0.0060, time: 6.836012]
2023-05-26 21:10:41.013: epoch 118:	0.02696932  	0.19853675  	0.10840362  
2023-05-26 21:10:47.854: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.840071]
2023-05-26 21:10:48.009: epoch 119:	0.02692698  	0.19821595  	0.10849445  
2023-05-26 21:10:54.826: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.816004]
2023-05-26 21:10:54.984: epoch 120:	0.02700461  	0.19877870  	0.10873750  
2023-05-26 21:11:01.851: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.865929]
2023-05-26 21:11:02.009: epoch 121:	0.02697637  	0.19845463  	0.10880523  
2023-05-26 21:11:08.839: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.829166]
2023-05-26 21:11:08.984: epoch 122:	0.02701871  	0.19882029  	0.10885829  
2023-05-26 21:11:15.824: [iter 123 : loss : 0.1175 = 0.0284 + 0.0829 + 0.0061, time: 6.838993]
2023-05-26 21:11:15.969: epoch 123:	0.02699048  	0.19863144  	0.10860813  
2023-05-26 21:11:22.827: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.856996]
2023-05-26 21:11:22.988: epoch 124:	0.02703282  	0.19897887  	0.10865592  
2023-05-26 21:11:29.835: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.844994]
2023-05-26 21:11:29.992: epoch 125:	0.02707516  	0.19940683  	0.10877539  
2023-05-26 21:11:29.992: Find a better model.
2023-05-26 21:11:36.811: [iter 126 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 6.817997]
2023-05-26 21:11:36.956: epoch 126:	0.02702577  	0.19909544  	0.10870935  
2023-05-26 21:11:43.829: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.871019]
2023-05-26 21:11:43.983: epoch 127:	0.02699754  	0.19921534  	0.10893293  
2023-05-26 21:11:50.799: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 6.815003]
2023-05-26 21:11:50.944: epoch 128:	0.02707517  	0.19976747  	0.10906865  
2023-05-26 21:11:50.944: Find a better model.
2023-05-26 21:11:57.803: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.857017]
2023-05-26 21:11:57.962: epoch 129:	0.02713162  	0.20003416  	0.10923973  
2023-05-26 21:11:57.962: Find a better model.
2023-05-26 21:12:04.803: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.840014]
2023-05-26 21:12:04.963: epoch 130:	0.02713868  	0.20039493  	0.10947837  
2023-05-26 21:12:04.963: Find a better model.
2023-05-26 21:12:11.824: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.860077]
2023-05-26 21:12:11.981: epoch 131:	0.02713163  	0.20014569  	0.10954256  
2023-05-26 21:12:18.802: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.820061]
2023-05-26 21:12:18.959: epoch 132:	0.02717396  	0.20073940  	0.10959067  
2023-05-26 21:12:18.960: Find a better model.
2023-05-26 21:12:25.796: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.834014]
2023-05-26 21:12:25.952: epoch 133:	0.02711750  	0.20035318  	0.10961362  
2023-05-26 21:12:32.783: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.830005]
2023-05-26 21:12:32.942: epoch 134:	0.02712456  	0.20007493  	0.10961859  
2023-05-26 21:12:39.628: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.683317]
2023-05-26 21:12:39.790: epoch 135:	0.02708222  	0.19980015  	0.10945706  
2023-05-26 21:12:46.397: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.605014]
2023-05-26 21:12:46.540: epoch 136:	0.02701166  	0.19974458  	0.10927424  
2023-05-26 21:12:53.371: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.829279]
2023-05-26 21:12:53.528: epoch 137:	0.02710338  	0.20006296  	0.10945144  
2023-05-26 21:13:00.208: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.679128]
2023-05-26 21:13:00.355: epoch 138:	0.02703284  	0.19962664  	0.10926732  
2023-05-26 21:13:07.208: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.851031]
2023-05-26 21:13:07.371: epoch 139:	0.02702577  	0.19934210  	0.10923915  
2023-05-26 21:13:14.222: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.850016]
2023-05-26 21:13:14.368: epoch 140:	0.02706105  	0.19958234  	0.10930841  
2023-05-26 21:13:21.169: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.798457]
2023-05-26 21:13:21.326: epoch 141:	0.02706105  	0.19944294  	0.10951823  
2023-05-26 21:13:27.981: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.652917]
2023-05-26 21:13:28.139: epoch 142:	0.02708222  	0.19971006  	0.10960936  
2023-05-26 21:13:34.956: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.815992]
2023-05-26 21:13:35.101: epoch 143:	0.02708222  	0.19972038  	0.10966024  
2023-05-26 21:13:41.955: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.853008]
2023-05-26 21:13:42.112: epoch 144:	0.02706106  	0.19966052  	0.10969264  
2023-05-26 21:13:48.982: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.868022]
2023-05-26 21:13:49.128: epoch 145:	0.02711751  	0.20007227  	0.10976930  
2023-05-26 21:13:55.774: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.645023]
2023-05-26 21:13:55.930: epoch 146:	0.02702578  	0.19929959  	0.10950433  
2023-05-26 21:14:02.587: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.655570]
2023-05-26 21:14:02.748: epoch 147:	0.02708223  	0.19976455  	0.10977425  
2023-05-26 21:14:09.386: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.637016]
2023-05-26 21:14:09.544: epoch 148:	0.02710340  	0.19970337  	0.10965259  
2023-05-26 21:14:16.166: [iter 149 : loss : 0.1105 = 0.0217 + 0.0819 + 0.0069, time: 6.621024]
2023-05-26 21:14:16.310: epoch 149:	0.02716691  	0.20001476  	0.10982654  
2023-05-26 21:14:22.971: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.659153]
2023-05-26 21:14:23.126: epoch 150:	0.02717396  	0.20009175  	0.11014605  
2023-05-26 21:14:29.771: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.644018]
2023-05-26 21:14:29.920: epoch 151:	0.02716691  	0.19984920  	0.11004481  
2023-05-26 21:14:36.567: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.646030]
2023-05-26 21:14:36.731: epoch 152:	0.02711751  	0.19952758  	0.11002443  
2023-05-26 21:14:43.352: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.620007]
2023-05-26 21:14:43.499: epoch 153:	0.02711045  	0.19939202  	0.10988323  
2023-05-26 21:14:50.145: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.645107]
2023-05-26 21:14:50.301: epoch 154:	0.02722335  	0.20031428  	0.11021179  
2023-05-26 21:14:56.927: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.625004]
2023-05-26 21:14:57.073: epoch 155:	0.02713868  	0.19976681  	0.10998006  
2023-05-26 21:15:03.729: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.653999]
2023-05-26 21:15:03.886: epoch 156:	0.02713163  	0.19980206  	0.10985493  
2023-05-26 21:15:10.548: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.661004]
2023-05-26 21:15:10.710: epoch 157:	0.02713163  	0.19979949  	0.10979497  
2023-05-26 21:15:10.710: Early stopping is trigger at epoch: 157
2023-05-26 21:15:10.710: best_result@epoch 132:

2023-05-26 21:15:10.710: 		0.0272      	0.2007      	0.1096      
2023-05-26 21:26:24.232: my pid: 13436
2023-05-26 21:26:24.232: model: model.general_recommender.SGL
2023-05-26 21:26:24.232: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-26 21:26:24.232: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-26 21:26:27.883: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-26 21:26:35.352: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.467047]
2023-05-26 21:26:35.510: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-26 21:26:35.510: Find a better model.
2023-05-26 21:26:42.965: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.454632]
2023-05-26 21:26:43.153: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-26 21:26:43.153: Find a better model.
2023-05-26 21:26:50.587: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.432992]
2023-05-26 21:26:50.771: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-26 21:26:50.771: Find a better model.
2023-05-26 21:26:57.930: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.157757]
2023-05-26 21:26:58.086: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-26 21:26:58.086: Find a better model.
2023-05-26 21:27:05.135: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.047463]
2023-05-26 21:27:05.289: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-26 21:27:05.289: Find a better model.
2023-05-26 21:27:12.093: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 6.802155]
2023-05-26 21:27:12.233: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-26 21:27:12.233: Find a better model.
2023-05-26 21:27:18.919: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.684994]
2023-05-26 21:27:19.073: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-26 21:27:19.073: Find a better model.
2023-05-26 21:27:25.881: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.807489]
2023-05-26 21:27:26.032: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-26 21:27:26.032: Find a better model.
2023-05-26 21:27:32.688: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.654994]
2023-05-26 21:27:32.844: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-26 21:27:32.844: Find a better model.
2023-05-26 21:27:39.502: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.657229]
2023-05-26 21:27:39.659: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-26 21:27:39.659: Find a better model.
2023-05-26 21:27:46.305: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.644109]
2023-05-26 21:27:46.463: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-26 21:27:46.463: Find a better model.
2023-05-26 21:27:53.092: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.627496]
2023-05-26 21:27:53.248: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-26 21:27:53.248: Find a better model.
2023-05-26 21:27:59.887: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.638005]
2023-05-26 21:28:00.050: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-26 21:28:00.050: Find a better model.
2023-05-26 21:28:06.703: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.652000]
2023-05-26 21:28:06.860: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-26 21:28:06.860: Find a better model.
2023-05-26 21:28:13.502: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.641458]
2023-05-26 21:28:13.658: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-26 21:28:20.465: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.804503]
2023-05-26 21:28:20.622: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-26 21:28:20.622: Find a better model.
2023-05-26 21:28:27.274: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.651473]
2023-05-26 21:28:27.421: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-26 21:28:27.421: Find a better model.
2023-05-26 21:28:33.895: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.473095]
2023-05-26 21:28:34.037: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-26 21:28:34.037: Find a better model.
2023-05-26 21:28:40.647: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.609065]
2023-05-26 21:28:40.804: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-26 21:28:40.804: Find a better model.
2023-05-26 21:28:47.272: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.465240]
2023-05-26 21:28:47.432: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-26 21:28:47.432: Find a better model.
2023-05-26 21:28:53.873: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.440008]
2023-05-26 21:28:54.030: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-26 21:28:54.030: Find a better model.
2023-05-26 21:29:00.664: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.633004]
2023-05-26 21:29:00.805: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-26 21:29:00.805: Find a better model.
2023-05-26 21:29:07.264: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.458055]
2023-05-26 21:29:07.422: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-26 21:29:07.422: Find a better model.
2023-05-26 21:29:13.871: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.448016]
2023-05-26 21:29:14.024: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-26 21:29:14.024: Find a better model.
2023-05-26 21:29:20.472: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.447034]
2023-05-26 21:29:20.614: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-26 21:29:20.614: Find a better model.
2023-05-26 21:29:27.055: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.439001]
2023-05-26 21:29:27.197: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-26 21:29:27.197: Find a better model.
2023-05-26 21:29:33.670: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.472003]
2023-05-26 21:29:33.839: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-26 21:29:33.839: Find a better model.
2023-05-26 21:29:40.253: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.412112]
2023-05-26 21:29:40.396: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-26 21:29:40.397: Find a better model.
2023-05-26 21:29:46.850: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.452016]
2023-05-26 21:29:47.007: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-26 21:29:47.007: Find a better model.
2023-05-26 21:29:53.450: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.442012]
2023-05-26 21:29:53.606: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-26 21:29:53.606: Find a better model.
2023-05-26 21:30:00.061: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.454120]
2023-05-26 21:30:00.203: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-26 21:30:00.203: Find a better model.
2023-05-26 21:30:06.619: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.414062]
2023-05-26 21:30:06.772: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-26 21:30:06.772: Find a better model.
2023-05-26 21:30:13.222: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.448004]
2023-05-26 21:30:13.374: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-26 21:30:13.374: Find a better model.
2023-05-26 21:30:19.826: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.450017]
2023-05-26 21:30:19.980: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-26 21:30:19.980: Find a better model.
2023-05-26 21:30:26.437: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.456136]
2023-05-26 21:30:26.591: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-26 21:30:26.591: Find a better model.
2023-05-26 21:30:33.209: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.617045]
2023-05-26 21:30:33.363: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-26 21:30:33.363: Find a better model.
2023-05-26 21:30:39.833: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.469003]
2023-05-26 21:30:39.984: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-26 21:30:39.985: Find a better model.
2023-05-26 21:30:46.614: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.628024]
2023-05-26 21:30:46.769: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-26 21:30:46.769: Find a better model.
2023-05-26 21:30:53.414: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.644004]
2023-05-26 21:30:53.565: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-26 21:30:53.565: Find a better model.
2023-05-26 21:31:00.199: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.633014]
2023-05-26 21:31:00.339: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-26 21:31:00.340: Find a better model.
2023-05-26 21:31:06.811: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.470025]
2023-05-26 21:31:06.963: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-26 21:31:06.963: Find a better model.
2023-05-26 21:31:13.598: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.633041]
2023-05-26 21:31:13.750: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-26 21:31:13.750: Find a better model.
2023-05-26 21:31:20.401: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.649375]
2023-05-26 21:31:20.554: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-26 21:31:20.554: Find a better model.
2023-05-26 21:31:27.044: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.489441]
2023-05-26 21:31:27.196: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-26 21:31:27.196: Find a better model.
2023-05-26 21:31:33.783: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.585043]
2023-05-26 21:31:33.935: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-26 21:31:33.936: Find a better model.
2023-05-26 21:31:40.406: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.469007]
2023-05-26 21:31:40.559: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-26 21:31:40.560: Find a better model.
2023-05-26 21:31:46.998: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.437002]
2023-05-26 21:31:47.149: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-26 21:31:47.149: Find a better model.
2023-05-26 21:31:53.592: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.442108]
2023-05-26 21:31:53.743: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-26 21:31:53.743: Find a better model.
2023-05-26 21:32:00.197: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.453003]
2023-05-26 21:32:00.336: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-26 21:32:06.785: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.448054]
2023-05-26 21:32:06.938: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-26 21:32:06.938: Find a better model.
2023-05-26 21:32:13.386: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.447023]
2023-05-26 21:32:13.541: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-26 21:32:13.541: Find a better model.
2023-05-26 21:32:20.158: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.616003]
2023-05-26 21:32:20.309: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-26 21:32:20.309: Find a better model.
2023-05-26 21:32:26.769: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.459003]
2023-05-26 21:32:26.920: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-26 21:32:26.920: Find a better model.
2023-05-26 21:32:33.379: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.457012]
2023-05-26 21:32:33.531: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-26 21:32:33.531: Find a better model.
2023-05-26 21:32:40.181: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.649031]
2023-05-26 21:32:40.333: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-26 21:32:46.787: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.453031]
2023-05-26 21:32:46.938: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-26 21:32:46.938: Find a better model.
2023-05-26 21:32:53.579: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.639994]
2023-05-26 21:32:53.731: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-26 21:32:53.731: Find a better model.
2023-05-26 21:33:00.177: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.445022]
2023-05-26 21:33:00.316: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-26 21:33:06.763: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.445017]
2023-05-26 21:33:06.914: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-26 21:33:06.914: Find a better model.
2023-05-26 21:33:13.563: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.648003]
2023-05-26 21:33:13.718: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-26 21:33:13.718: Find a better model.
2023-05-26 21:33:20.352: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.632030]
2023-05-26 21:33:20.507: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-26 21:33:20.507: Find a better model.
2023-05-26 21:33:27.150: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.642002]
2023-05-26 21:33:27.292: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-26 21:33:27.292: Find a better model.
2023-05-26 21:33:33.765: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.472009]
2023-05-26 21:33:33.917: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-26 21:33:33.917: Find a better model.
2023-05-26 21:33:40.367: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.449006]
2023-05-26 21:33:40.522: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-26 21:33:40.522: Find a better model.
2023-05-26 21:33:46.963: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.440046]
2023-05-26 21:33:47.114: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-26 21:33:47.114: Find a better model.
2023-05-26 21:33:53.553: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.437009]
2023-05-26 21:33:53.706: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-26 21:33:53.706: Find a better model.
2023-05-26 21:34:00.173: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.466103]
2023-05-26 21:34:00.315: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-26 21:34:06.755: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.439033]
2023-05-26 21:34:06.908: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-26 21:34:06.908: Find a better model.
2023-05-26 21:34:13.346: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.437003]
2023-05-26 21:34:13.500: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-26 21:34:13.500: Find a better model.
2023-05-26 21:34:19.967: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.466394]
2023-05-26 21:34:20.119: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-26 21:34:20.119: Find a better model.
2023-05-26 21:34:26.538: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.418198]
2023-05-26 21:34:26.691: epoch 71:	0.02632721  	0.19467905  	0.10684208  
2023-05-26 21:34:26.692: Find a better model.
2023-05-26 21:34:33.334: [iter 72 : loss : 0.2190 = 0.0478 + 0.1664 + 0.0048, time: 6.641012]
2023-05-26 21:34:33.490: epoch 72:	0.02639778  	0.19526137  	0.10706843  
2023-05-26 21:34:33.490: Find a better model.
2023-05-26 21:34:39.952: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.461032]
2023-05-26 21:34:40.104: epoch 73:	0.02641189  	0.19549032  	0.10711851  
2023-05-26 21:34:40.104: Find a better model.
2023-05-26 21:34:46.542: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.437003]
2023-05-26 21:34:46.693: epoch 74:	0.02646128  	0.19566278  	0.10750105  
2023-05-26 21:34:46.693: Find a better model.
2023-05-26 21:34:53.141: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.447098]
2023-05-26 21:34:53.292: epoch 75:	0.02654596  	0.19655427  	0.10756438  
2023-05-26 21:34:53.293: Find a better model.
2023-05-26 21:34:59.727: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.431084]
2023-05-26 21:34:59.877: epoch 76:	0.02658124  	0.19694291  	0.10773618  
2023-05-26 21:34:59.877: Find a better model.
2023-05-26 21:35:06.325: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.447049]
2023-05-26 21:35:06.478: epoch 77:	0.02659536  	0.19693758  	0.10767362  
2023-05-26 21:35:12.932: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.452063]
2023-05-26 21:35:13.084: epoch 78:	0.02667298  	0.19745006  	0.10793771  
2023-05-26 21:35:13.084: Find a better model.
2023-05-26 21:35:19.521: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.436046]
2023-05-26 21:35:19.677: epoch 79:	0.02668003  	0.19723570  	0.10796165  
2023-05-26 21:35:26.122: [iter 80 : loss : 0.2113 = 0.0410 + 0.1652 + 0.0051, time: 6.444054]
2023-05-26 21:35:26.275: epoch 80:	0.02660241  	0.19668077  	0.10794093  
2023-05-26 21:35:32.707: [iter 81 : loss : 0.2110 = 0.0408 + 0.1650 + 0.0052, time: 6.430195]
2023-05-26 21:35:32.859: epoch 81:	0.02660241  	0.19662951  	0.10788923  
2023-05-26 21:35:39.313: [iter 82 : loss : 0.2099 = 0.0398 + 0.1649 + 0.0052, time: 6.453072]
2023-05-26 21:35:39.468: epoch 82:	0.02649656  	0.19609496  	0.10785156  
2023-05-26 21:35:45.741: [iter 83 : loss : 0.2090 = 0.0390 + 0.1648 + 0.0053, time: 6.272003]
2023-05-26 21:35:45.891: epoch 83:	0.02653890  	0.19600566  	0.10790281  
2023-05-26 21:35:52.303: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.411016]
2023-05-26 21:35:52.459: epoch 84:	0.02667298  	0.19690226  	0.10819490  
2023-05-26 21:35:58.898: [iter 85 : loss : 0.2081 = 0.0382 + 0.1645 + 0.0053, time: 6.437005]
2023-05-26 21:35:59.051: epoch 85:	0.02675060  	0.19757095  	0.10846379  
2023-05-26 21:35:59.052: Find a better model.
2023-05-26 21:36:05.503: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.450139]
2023-05-26 21:36:05.659: epoch 86:	0.02669415  	0.19715470  	0.10848830  
2023-05-26 21:36:12.121: [iter 87 : loss : 0.2057 = 0.0359 + 0.1643 + 0.0054, time: 6.461029]
2023-05-26 21:36:12.274: epoch 87:	0.02686350  	0.19811502  	0.10885072  
2023-05-26 21:36:12.274: Find a better model.
2023-05-26 21:36:18.714: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.439004]
2023-05-26 21:36:18.866: epoch 88:	0.02678588  	0.19745855  	0.10858166  
2023-05-26 21:36:25.328: [iter 89 : loss : 0.2045 = 0.0349 + 0.1640 + 0.0055, time: 6.460025]
2023-05-26 21:36:25.483: epoch 89:	0.02673648  	0.19694941  	0.10849094  
2023-05-26 21:36:31.890: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.406004]
2023-05-26 21:36:32.042: epoch 90:	0.02682822  	0.19769356  	0.10869770  
2023-05-26 21:36:38.498: [iter 91 : loss : 0.2039 = 0.0346 + 0.1637 + 0.0056, time: 6.455004]
2023-05-26 21:36:38.651: epoch 91:	0.02691289  	0.19807483  	0.10884359  
2023-05-26 21:36:45.287: [iter 92 : loss : 0.2027 = 0.0334 + 0.1636 + 0.0056, time: 6.634086]
2023-05-26 21:36:45.445: epoch 92:	0.02691289  	0.19837055  	0.10896593  
2023-05-26 21:36:45.445: Find a better model.
2023-05-26 21:36:52.071: [iter 93 : loss : 0.2032 = 0.0340 + 0.1635 + 0.0057, time: 6.625496]
2023-05-26 21:36:52.220: epoch 93:	0.02685644  	0.19816089  	0.10876575  
2023-05-26 21:36:58.693: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.471014]
2023-05-26 21:36:58.847: epoch 94:	0.02691995  	0.19861799  	0.10906227  
2023-05-26 21:36:58.847: Find a better model.
2023-05-26 21:37:05.456: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.608035]
2023-05-26 21:37:05.607: epoch 95:	0.02692701  	0.19858223  	0.10915027  
2023-05-26 21:37:12.288: [iter 96 : loss : 0.2008 = 0.0318 + 0.1633 + 0.0058, time: 6.679003]
2023-05-26 21:37:12.443: epoch 96:	0.02686350  	0.19796261  	0.10892848  
2023-05-26 21:37:19.063: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.618682]
2023-05-26 21:37:19.216: epoch 97:	0.02693406  	0.19827308  	0.10926932  
2023-05-26 21:37:25.846: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.629004]
2023-05-26 21:37:26.000: epoch 98:	0.02696229  	0.19866505  	0.10947383  
2023-05-26 21:37:26.000: Find a better model.
2023-05-26 21:37:32.674: [iter 99 : loss : 0.1990 = 0.0301 + 0.1630 + 0.0059, time: 6.673016]
2023-05-26 21:37:32.826: epoch 99:	0.02704696  	0.19919112  	0.10960194  
2023-05-26 21:37:32.826: Find a better model.
2023-05-26 21:37:39.460: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.633005]
2023-05-26 21:37:39.613: epoch 100:	0.02704697  	0.19910374  	0.10962466  
2023-05-26 21:37:46.261: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.647038]
2023-05-26 21:37:46.417: epoch 101:	0.02705401  	0.19919518  	0.10958475  
2023-05-26 21:37:46.417: Find a better model.
2023-05-26 21:37:52.898: [iter 102 : loss : 0.1974 = 0.0287 + 0.1627 + 0.0060, time: 6.480237]
2023-05-26 21:37:53.051: epoch 102:	0.02708224  	0.19923192  	0.10958505  
2023-05-26 21:37:53.051: Find a better model.
2023-05-26 21:37:59.668: [iter 103 : loss : 0.1972 = 0.0285 + 0.1626 + 0.0061, time: 6.615933]
2023-05-26 21:37:59.821: epoch 103:	0.02708224  	0.19955929  	0.10977739  
2023-05-26 21:37:59.822: Find a better model.
2023-05-26 21:38:06.450: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.626994]
2023-05-26 21:38:06.602: epoch 104:	0.02704696  	0.19927947  	0.10974072  
2023-05-26 21:38:13.249: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.646026]
2023-05-26 21:38:13.403: epoch 105:	0.02699756  	0.19940211  	0.10973746  
2023-05-26 21:38:19.861: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.457014]
2023-05-26 21:38:20.016: epoch 106:	0.02700462  	0.19934300  	0.10980065  
2023-05-26 21:38:26.655: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.638013]
2023-05-26 21:38:26.807: epoch 107:	0.02709636  	0.20013331  	0.11017127  
2023-05-26 21:38:26.807: Find a better model.
2023-05-26 21:38:33.441: [iter 108 : loss : 0.1954 = 0.0268 + 0.1623 + 0.0063, time: 6.633060]
2023-05-26 21:38:33.594: epoch 108:	0.02701168  	0.19948994  	0.10994335  
2023-05-26 21:38:40.273: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.678084]
2023-05-26 21:38:40.429: epoch 109:	0.02703990  	0.19995077  	0.10987403  
2023-05-26 21:38:47.033: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.601002]
2023-05-26 21:38:47.184: epoch 110:	0.02702579  	0.20006639  	0.11004224  
2023-05-26 21:38:53.654: [iter 111 : loss : 0.1938 = 0.0254 + 0.1621 + 0.0064, time: 6.469011]
2023-05-26 21:38:53.806: epoch 111:	0.02700462  	0.19943981  	0.10992552  
2023-05-26 21:39:00.435: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.627547]
2023-05-26 21:39:00.588: epoch 112:	0.02703990  	0.19926029  	0.10989875  
2023-05-26 21:39:07.237: [iter 113 : loss : 0.1936 = 0.0252 + 0.1619 + 0.0065, time: 6.648036]
2023-05-26 21:39:07.390: epoch 113:	0.02703991  	0.19923331  	0.10981081  
2023-05-26 21:39:14.018: [iter 114 : loss : 0.1928 = 0.0245 + 0.1619 + 0.0065, time: 6.626993]
2023-05-26 21:39:14.172: epoch 114:	0.02712458  	0.19982009  	0.11002634  
2023-05-26 21:39:20.653: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.480117]
2023-05-26 21:39:20.804: epoch 115:	0.02708224  	0.19951895  	0.10995702  
2023-05-26 21:39:27.408: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.603431]
2023-05-26 21:39:27.561: epoch 116:	0.02703990  	0.19897604  	0.10996704  
2023-05-26 21:39:34.225: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.663020]
2023-05-26 21:39:34.379: epoch 117:	0.02699756  	0.19897310  	0.10987782  
2023-05-26 21:39:41.008: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.628008]
2023-05-26 21:39:41.160: epoch 118:	0.02699050  	0.19841708  	0.10980519  
2023-05-26 21:39:47.635: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.474012]
2023-05-26 21:39:47.789: epoch 119:	0.02703284  	0.19879419  	0.10976622  
2023-05-26 21:39:54.403: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.613003]
2023-05-26 21:39:54.556: epoch 120:	0.02701167  	0.19857386  	0.10984606  
2023-05-26 21:40:01.026: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.469006]
2023-05-26 21:40:01.178: epoch 121:	0.02701873  	0.19863996  	0.10994435  
2023-05-26 21:40:07.654: [iter 122 : loss : 0.1906 = 0.0224 + 0.1614 + 0.0068, time: 6.475111]
2023-05-26 21:40:07.807: epoch 122:	0.02695522  	0.19826147  	0.10981735  
2023-05-26 21:40:14.391: [iter 123 : loss : 0.1904 = 0.0223 + 0.1613 + 0.0068, time: 6.582047]
2023-05-26 21:40:14.545: epoch 123:	0.02695522  	0.19808462  	0.10980849  
2023-05-26 21:40:21.193: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.647014]
2023-05-26 21:40:21.335: epoch 124:	0.02699050  	0.19832473  	0.10993187  
2023-05-26 21:40:27.810: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.473005]
2023-05-26 21:40:27.965: epoch 125:	0.02702578  	0.19851798  	0.10995517  
2023-05-26 21:40:34.591: [iter 126 : loss : 0.1893 = 0.0213 + 0.1612 + 0.0069, time: 6.624993]
2023-05-26 21:40:34.743: epoch 126:	0.02694816  	0.19828182  	0.10998717  
2023-05-26 21:40:41.384: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.639087]
2023-05-26 21:40:41.538: epoch 127:	0.02688466  	0.19781704  	0.10989792  
2023-05-26 21:40:48.193: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.654003]
2023-05-26 21:40:48.347: epoch 128:	0.02695521  	0.19820340  	0.10989744  
2023-05-26 21:40:54.799: [iter 129 : loss : 0.1885 = 0.0205 + 0.1611 + 0.0070, time: 6.451004]
2023-05-26 21:40:54.953: epoch 129:	0.02696227  	0.19817300  	0.10987659  
2023-05-26 21:41:01.573: [iter 130 : loss : 0.1887 = 0.0206 + 0.1610 + 0.0070, time: 6.618994]
2023-05-26 21:41:01.727: epoch 130:	0.02689171  	0.19781253  	0.10982230  
2023-05-26 21:41:08.378: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.650006]
2023-05-26 21:41:08.534: epoch 131:	0.02694816  	0.19798289  	0.10988791  
2023-05-26 21:41:15.001: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.466029]
2023-05-26 21:41:15.155: epoch 132:	0.02689877  	0.19789122  	0.10990109  
2023-05-26 21:41:15.155: Early stopping is trigger at epoch: 132
2023-05-26 21:41:15.155: best_result@epoch 107:

2023-05-26 21:41:15.155: 		0.0271      	0.2001      	0.1102      
2023-05-27 13:31:22.060: my pid: 2992
2023-05-27 13:31:22.060: model: model.general_recommender.SGL
2023-05-27 13:31:22.060: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-27 13:31:22.060: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-27 13:31:25.682: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-27 13:31:33.080: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.397999]
2023-05-27 13:31:33.236: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-27 13:31:33.236: Find a better model.
2023-05-27 13:31:40.872: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.634313]
2023-05-27 13:31:41.078: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-27 13:31:41.078: Find a better model.
2023-05-27 13:31:48.682: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.602885]
2023-05-27 13:31:48.870: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-27 13:31:48.870: Find a better model.
2023-05-27 13:31:56.052: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.181031]
2023-05-27 13:31:56.223: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-27 13:31:56.223: Find a better model.
2023-05-27 13:32:03.426: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.202254]
2023-05-27 13:32:03.576: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-27 13:32:03.576: Find a better model.
2023-05-27 13:32:10.617: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 7.040517]
2023-05-27 13:32:10.778: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-27 13:32:10.779: Find a better model.
2023-05-27 13:32:17.627: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.847044]
2023-05-27 13:32:17.782: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-27 13:32:17.782: Find a better model.
2023-05-27 13:32:24.602: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.817484]
2023-05-27 13:32:24.759: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-27 13:32:24.759: Find a better model.
2023-05-27 13:32:31.612: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.852024]
2023-05-27 13:32:31.769: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-27 13:32:31.769: Find a better model.
2023-05-27 13:32:38.407: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.636338]
2023-05-27 13:32:38.561: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-27 13:32:38.561: Find a better model.
2023-05-27 13:32:45.213: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.651022]
2023-05-27 13:32:45.368: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-27 13:32:45.369: Find a better model.
2023-05-27 13:32:52.005: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.635128]
2023-05-27 13:32:52.159: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-27 13:32:52.159: Find a better model.
2023-05-27 13:32:58.796: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.636056]
2023-05-27 13:32:58.954: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-27 13:32:58.954: Find a better model.
2023-05-27 13:33:05.608: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.653022]
2023-05-27 13:33:05.763: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-27 13:33:05.763: Find a better model.
2023-05-27 13:33:12.389: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.625015]
2023-05-27 13:33:12.544: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-27 13:33:12.544: Find a better model.
2023-05-27 13:33:19.200: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.653447]
2023-05-27 13:33:19.354: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-27 13:33:19.354: Find a better model.
2023-05-27 13:33:25.984: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.629012]
2023-05-27 13:33:26.141: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-27 13:33:26.141: Find a better model.
2023-05-27 13:33:32.832: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.690003]
2023-05-27 13:33:32.992: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-27 13:33:32.992: Find a better model.
2023-05-27 13:33:39.595: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.601800]
2023-05-27 13:33:39.749: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-27 13:33:39.749: Find a better model.
2023-05-27 13:33:46.387: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.636023]
2023-05-27 13:33:46.540: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-27 13:33:46.540: Find a better model.
2023-05-27 13:33:53.168: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.626112]
2023-05-27 13:33:53.310: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-27 13:33:53.311: Find a better model.
2023-05-27 13:33:59.999: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.686993]
2023-05-27 13:34:00.151: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-27 13:34:00.151: Find a better model.
2023-05-27 13:34:06.797: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.645038]
2023-05-27 13:34:06.957: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-27 13:34:06.957: Find a better model.
2023-05-27 13:34:13.788: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.828938]
2023-05-27 13:34:13.947: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-27 13:34:13.947: Find a better model.
2023-05-27 13:34:20.603: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.654023]
2023-05-27 13:34:20.757: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-27 13:34:20.757: Find a better model.
2023-05-27 13:34:27.572: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.812551]
2023-05-27 13:34:27.727: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-27 13:34:27.727: Find a better model.
2023-05-27 13:34:34.391: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.662324]
2023-05-27 13:34:34.534: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-27 13:34:34.534: Find a better model.
2023-05-27 13:34:41.178: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.641494]
2023-05-27 13:34:41.334: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-27 13:34:41.334: Find a better model.
2023-05-27 13:34:47.975: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.638030]
2023-05-27 13:34:48.130: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-27 13:34:48.130: Find a better model.
2023-05-27 13:34:54.940: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.808003]
2023-05-27 13:34:55.094: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-27 13:34:55.094: Find a better model.
2023-05-27 13:35:01.772: [iter 31 : loss : 0.4376 = 0.1715 + 0.2641 + 0.0020, time: 6.677086]
2023-05-27 13:35:01.930: epoch 31:	0.02313064  	0.17113926  	0.08933837  
2023-05-27 13:35:01.930: Find a better model.
2023-05-27 13:35:08.536: [iter 32 : loss : 0.4271 = 0.1616 + 0.2634 + 0.0021, time: 6.604013]
2023-05-27 13:35:08.690: epoch 32:	0.02339173  	0.17321081  	0.09051806  
2023-05-27 13:35:08.690: Find a better model.
2023-05-27 13:35:15.348: [iter 33 : loss : 0.4190 = 0.1543 + 0.2625 + 0.0022, time: 6.657004]
2023-05-27 13:35:15.501: epoch 33:	0.02348345  	0.17394656  	0.09135464  
2023-05-27 13:35:15.501: Find a better model.
2023-05-27 13:35:22.151: [iter 34 : loss : 0.4108 = 0.1468 + 0.2617 + 0.0023, time: 6.649071]
2023-05-27 13:35:22.305: epoch 34:	0.02362458  	0.17503196  	0.09213932  
2023-05-27 13:35:22.305: Find a better model.
2023-05-27 13:35:28.961: [iter 35 : loss : 0.4034 = 0.1401 + 0.2609 + 0.0024, time: 6.655055]
2023-05-27 13:35:29.114: epoch 35:	0.02374454  	0.17582044  	0.09307712  
2023-05-27 13:35:29.114: Find a better model.
2023-05-27 13:35:35.765: [iter 36 : loss : 0.3969 = 0.1343 + 0.2602 + 0.0025, time: 6.650524]
2023-05-27 13:35:35.922: epoch 36:	0.02394918  	0.17751829  	0.09400745  
2023-05-27 13:35:35.922: Find a better model.
2023-05-27 13:35:42.754: [iter 37 : loss : 0.3898 = 0.1279 + 0.2594 + 0.0026, time: 6.830043]
2023-05-27 13:35:42.911: epoch 37:	0.02409736  	0.17887959  	0.09480833  
2023-05-27 13:35:42.911: Find a better model.
2023-05-27 13:35:49.752: [iter 38 : loss : 0.3854 = 0.1241 + 0.2587 + 0.0026, time: 6.839029]
2023-05-27 13:35:49.905: epoch 38:	0.02423850  	0.18015358  	0.09577529  
2023-05-27 13:35:49.905: Find a better model.
2023-05-27 13:35:56.561: [iter 39 : loss : 0.3787 = 0.1180 + 0.2580 + 0.0027, time: 6.654060]
2023-05-27 13:35:56.715: epoch 39:	0.02442196  	0.18145519  	0.09665413  
2023-05-27 13:35:56.715: Find a better model.
2023-05-27 13:36:03.343: [iter 40 : loss : 0.3734 = 0.1134 + 0.2572 + 0.0028, time: 6.627004]
2023-05-27 13:36:03.498: epoch 40:	0.02451370  	0.18158165  	0.09718434  
2023-05-27 13:36:03.499: Find a better model.
2023-05-27 13:36:10.138: [iter 41 : loss : 0.3697 = 0.1101 + 0.2567 + 0.0029, time: 6.637620]
2023-05-27 13:36:10.291: epoch 41:	0.02464778  	0.18233761  	0.09772446  
2023-05-27 13:36:10.292: Find a better model.
2023-05-27 13:36:16.946: [iter 42 : loss : 0.3651 = 0.1062 + 0.2560 + 0.0030, time: 6.652008]
2023-05-27 13:36:17.099: epoch 42:	0.02473952  	0.18298288  	0.09838484  
2023-05-27 13:36:17.099: Find a better model.
2023-05-27 13:36:23.741: [iter 43 : loss : 0.3601 = 0.1017 + 0.2554 + 0.0030, time: 6.640023]
2023-05-27 13:36:23.895: epoch 43:	0.02488770  	0.18432704  	0.09910157  
2023-05-27 13:36:23.895: Find a better model.
2023-05-27 13:36:30.539: [iter 44 : loss : 0.3556 = 0.0977 + 0.2547 + 0.0031, time: 6.643034]
2023-05-27 13:36:30.693: epoch 44:	0.02507822  	0.18588677  	0.09982639  
2023-05-27 13:36:30.693: Find a better model.
2023-05-27 13:36:37.339: [iter 45 : loss : 0.3515 = 0.0940 + 0.2543 + 0.0032, time: 6.645259]
2023-05-27 13:36:37.493: epoch 45:	0.02515584  	0.18642087  	0.10033828  
2023-05-27 13:36:37.493: Find a better model.
2023-05-27 13:36:44.137: [iter 46 : loss : 0.3483 = 0.0913 + 0.2537 + 0.0033, time: 6.643013]
2023-05-27 13:36:44.291: epoch 46:	0.02521935  	0.18701465  	0.10066313  
2023-05-27 13:36:44.291: Find a better model.
2023-05-27 13:36:50.947: [iter 47 : loss : 0.3462 = 0.0896 + 0.2532 + 0.0033, time: 6.654083]
2023-05-27 13:36:51.099: epoch 47:	0.02525463  	0.18704106  	0.10091247  
2023-05-27 13:36:51.100: Find a better model.
2023-05-27 13:36:57.734: [iter 48 : loss : 0.3417 = 0.0856 + 0.2528 + 0.0034, time: 6.632144]
2023-05-27 13:36:57.888: epoch 48:	0.02530403  	0.18767536  	0.10141196  
2023-05-27 13:36:57.888: Find a better model.
2023-05-27 13:37:04.524: [iter 49 : loss : 0.3380 = 0.0822 + 0.2523 + 0.0035, time: 6.635314]
2023-05-27 13:37:04.678: epoch 49:	0.02539576  	0.18800889  	0.10192321  
2023-05-27 13:37:04.678: Find a better model.
2023-05-27 13:37:11.325: [iter 50 : loss : 0.3358 = 0.0804 + 0.2519 + 0.0036, time: 6.645994]
2023-05-27 13:37:11.478: epoch 50:	0.02547338  	0.18860294  	0.10243494  
2023-05-27 13:37:11.478: Find a better model.
2023-05-27 13:37:18.102: [iter 51 : loss : 0.3325 = 0.0774 + 0.2515 + 0.0036, time: 6.622173]
2023-05-27 13:37:18.255: epoch 51:	0.02562157  	0.18948242  	0.10301709  
2023-05-27 13:37:18.255: Find a better model.
2023-05-27 13:37:24.908: [iter 52 : loss : 0.3312 = 0.0765 + 0.2510 + 0.0037, time: 6.652054]
2023-05-27 13:37:25.064: epoch 52:	0.02579092  	0.19067582  	0.10377309  
2023-05-27 13:37:25.064: Find a better model.
2023-05-27 13:37:31.716: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.651006]
2023-05-27 13:37:31.871: epoch 53:	0.02586148  	0.19149116  	0.10428696  
2023-05-27 13:37:31.871: Find a better model.
2023-05-27 13:37:38.506: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.633339]
2023-05-27 13:37:38.660: epoch 54:	0.02589676  	0.19195156  	0.10455631  
2023-05-27 13:37:38.660: Find a better model.
2023-05-27 13:37:45.301: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.639004]
2023-05-27 13:37:45.453: epoch 55:	0.02591793  	0.19219516  	0.10478327  
2023-05-27 13:37:45.453: Find a better model.
2023-05-27 13:37:52.109: [iter 56 : loss : 0.3210 = 0.0676 + 0.2494 + 0.0040, time: 6.655076]
2023-05-27 13:37:52.264: epoch 56:	0.02593205  	0.19196197  	0.10502896  
2023-05-27 13:37:58.936: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.671000]
2023-05-27 13:37:59.091: epoch 57:	0.02595321  	0.19218220  	0.10519829  
2023-05-27 13:38:05.712: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.620001]
2023-05-27 13:38:05.867: epoch 58:	0.02606612  	0.19308290  	0.10578318  
2023-05-27 13:38:05.867: Find a better model.
2023-05-27 13:38:12.500: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.632089]
2023-05-27 13:38:12.654: epoch 59:	0.02609434  	0.19337738  	0.10590531  
2023-05-27 13:38:12.655: Find a better model.
2023-05-27 13:38:19.311: [iter 60 : loss : 0.3135 = 0.0611 + 0.2482 + 0.0042, time: 6.655138]
2023-05-27 13:38:19.464: epoch 60:	0.02620725  	0.19395447  	0.10629762  
2023-05-27 13:38:19.464: Find a better model.
2023-05-27 13:38:26.275: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.809067]
2023-05-27 13:38:26.429: epoch 61:	0.02620725  	0.19454296  	0.10651705  
2023-05-27 13:38:26.429: Find a better model.
2023-05-27 13:38:33.093: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.663003]
2023-05-27 13:38:33.234: epoch 62:	0.02617196  	0.19414380  	0.10654917  
2023-05-27 13:38:39.895: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.659035]
2023-05-27 13:38:40.050: epoch 63:	0.02618607  	0.19401701  	0.10670833  
2023-05-27 13:38:46.684: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.633092]
2023-05-27 13:38:46.828: epoch 64:	0.02620725  	0.19436824  	0.10687846  
2023-05-27 13:38:53.469: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.638012]
2023-05-27 13:38:53.622: epoch 65:	0.02627075  	0.19462110  	0.10707077  
2023-05-27 13:38:53.623: Find a better model.
2023-05-27 13:39:00.291: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.667025]
2023-05-27 13:39:00.447: epoch 66:	0.02630604  	0.19498673  	0.10724138  
2023-05-27 13:39:00.447: Find a better model.
2023-05-27 13:39:07.085: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.637004]
2023-05-27 13:39:07.238: epoch 67:	0.02628487  	0.19462584  	0.10712864  
2023-05-27 13:39:13.879: [iter 68 : loss : 0.3017 = 0.0509 + 0.2460 + 0.0047, time: 6.640030]
2023-05-27 13:39:14.038: epoch 68:	0.02644717  	0.19577003  	0.10764769  
2023-05-27 13:39:14.038: Find a better model.
2023-05-27 13:39:20.678: [iter 69 : loss : 0.2999 = 0.0493 + 0.2459 + 0.0047, time: 6.639403]
2023-05-27 13:39:20.832: epoch 69:	0.02650362  	0.19595338  	0.10772637  
2023-05-27 13:39:20.832: Find a better model.
2023-05-27 13:39:27.493: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.660014]
2023-05-27 13:39:27.646: epoch 70:	0.02664475  	0.19702859  	0.10820810  
2023-05-27 13:39:27.646: Find a better model.
2023-05-27 13:39:34.257: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.609004]
2023-05-27 13:39:34.398: epoch 71:	0.02656713  	0.19665308  	0.10810143  
2023-05-27 13:39:41.062: [iter 72 : loss : 0.2963 = 0.0462 + 0.2452 + 0.0049, time: 6.662067]
2023-05-27 13:39:41.217: epoch 72:	0.02656007  	0.19652425  	0.10810161  
2023-05-27 13:39:48.055: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.837201]
2023-05-27 13:39:48.208: epoch 73:	0.02660241  	0.19657025  	0.10818605  
2023-05-27 13:39:54.857: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.647015]
2023-05-27 13:39:55.001: epoch 74:	0.02668002  	0.19708768  	0.10849189  
2023-05-27 13:39:55.001: Find a better model.
2023-05-27 13:40:01.655: [iter 75 : loss : 0.2931 = 0.0434 + 0.2446 + 0.0050, time: 6.653016]
2023-05-27 13:40:01.810: epoch 75:	0.02665886  	0.19705616  	0.10869642  
2023-05-27 13:40:08.465: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.654012]
2023-05-27 13:40:08.619: epoch 76:	0.02672237  	0.19759066  	0.10885058  
2023-05-27 13:40:08.619: Find a better model.
2023-05-27 13:40:15.245: [iter 77 : loss : 0.2910 = 0.0416 + 0.2442 + 0.0051, time: 6.625056]
2023-05-27 13:40:15.389: epoch 77:	0.02660241  	0.19694234  	0.10861786  
2023-05-27 13:40:22.053: [iter 78 : loss : 0.2905 = 0.0411 + 0.2442 + 0.0052, time: 6.662036]
2023-05-27 13:40:22.211: epoch 78:	0.02660946  	0.19709215  	0.10860539  
2023-05-27 13:40:28.862: [iter 79 : loss : 0.2889 = 0.0398 + 0.2439 + 0.0052, time: 6.650112]
2023-05-27 13:40:29.018: epoch 79:	0.02658829  	0.19694187  	0.10879070  
2023-05-27 13:40:35.659: [iter 80 : loss : 0.2882 = 0.0391 + 0.2438 + 0.0053, time: 6.639154]
2023-05-27 13:40:35.813: epoch 80:	0.02657419  	0.19640031  	0.10893568  
2023-05-27 13:40:42.458: [iter 81 : loss : 0.2877 = 0.0387 + 0.2436 + 0.0053, time: 6.644012]
2023-05-27 13:40:42.611: epoch 81:	0.02663063  	0.19645067  	0.10885140  
2023-05-27 13:40:49.254: [iter 82 : loss : 0.2866 = 0.0377 + 0.2435 + 0.0054, time: 6.641091]
2023-05-27 13:40:49.407: epoch 82:	0.02665180  	0.19645311  	0.10897100  
2023-05-27 13:40:56.251: [iter 83 : loss : 0.2856 = 0.0368 + 0.2434 + 0.0054, time: 6.843050]
2023-05-27 13:40:56.405: epoch 83:	0.02663768  	0.19620799  	0.10897882  
2023-05-27 13:41:03.051: [iter 84 : loss : 0.2855 = 0.0368 + 0.2432 + 0.0055, time: 6.644087]
2023-05-27 13:41:03.204: epoch 84:	0.02666592  	0.19664326  	0.10921748  
2023-05-27 13:41:09.856: [iter 85 : loss : 0.2847 = 0.0361 + 0.2431 + 0.0055, time: 6.651004]
2023-05-27 13:41:10.012: epoch 85:	0.02669414  	0.19661751  	0.10919429  
2023-05-27 13:41:16.849: [iter 86 : loss : 0.2839 = 0.0355 + 0.2429 + 0.0056, time: 6.836003]
2023-05-27 13:41:17.004: epoch 86:	0.02673648  	0.19685894  	0.10923503  
2023-05-27 13:41:23.839: [iter 87 : loss : 0.2824 = 0.0339 + 0.2428 + 0.0056, time: 6.834010]
2023-05-27 13:41:23.996: epoch 87:	0.02677176  	0.19690131  	0.10928166  
2023-05-27 13:41:30.821: [iter 88 : loss : 0.2817 = 0.0334 + 0.2426 + 0.0057, time: 6.822563]
2023-05-27 13:41:30.976: epoch 88:	0.02679293  	0.19745335  	0.10944445  
2023-05-27 13:41:37.817: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.840003]
2023-05-27 13:41:37.975: epoch 89:	0.02687055  	0.19797975  	0.10950413  
2023-05-27 13:41:37.975: Find a better model.
2023-05-27 13:41:44.802: [iter 90 : loss : 0.2813 = 0.0331 + 0.2424 + 0.0058, time: 6.825963]
2023-05-27 13:41:44.959: epoch 90:	0.02679293  	0.19731720  	0.10949855  
2023-05-27 13:41:51.815: [iter 91 : loss : 0.2804 = 0.0324 + 0.2422 + 0.0058, time: 6.855025]
2023-05-27 13:41:51.973: epoch 91:	0.02680705  	0.19715656  	0.10941418  
2023-05-27 13:41:58.837: [iter 92 : loss : 0.2794 = 0.0314 + 0.2421 + 0.0059, time: 6.863006]
2023-05-27 13:41:58.995: epoch 92:	0.02684233  	0.19765759  	0.10955634  
2023-05-27 13:42:05.823: [iter 93 : loss : 0.2796 = 0.0317 + 0.2420 + 0.0059, time: 6.827189]
2023-05-27 13:42:05.978: epoch 93:	0.02683527  	0.19732408  	0.10942291  
2023-05-27 13:42:12.816: [iter 94 : loss : 0.2781 = 0.0303 + 0.2419 + 0.0059, time: 6.837118]
2023-05-27 13:42:12.970: epoch 94:	0.02689878  	0.19774197  	0.10954650  
2023-05-27 13:42:19.984: [iter 95 : loss : 0.2773 = 0.0295 + 0.2418 + 0.0060, time: 7.012013]
2023-05-27 13:42:20.127: epoch 95:	0.02690583  	0.19744883  	0.10961021  
2023-05-27 13:42:27.056: [iter 96 : loss : 0.2773 = 0.0296 + 0.2417 + 0.0060, time: 6.927278]
2023-05-27 13:42:27.211: epoch 96:	0.02690584  	0.19746080  	0.10964301  
2023-05-27 13:42:34.196: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.984041]
2023-05-27 13:42:34.351: epoch 97:	0.02695522  	0.19775072  	0.10953180  
2023-05-27 13:42:41.196: [iter 98 : loss : 0.2761 = 0.0285 + 0.2415 + 0.0061, time: 6.844007]
2023-05-27 13:42:41.352: epoch 98:	0.02699051  	0.19823256  	0.10975881  
2023-05-27 13:42:41.352: Find a better model.
2023-05-27 13:42:48.229: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.874999]
2023-05-27 13:42:48.384: epoch 99:	0.02699757  	0.19815995  	0.10982832  
2023-05-27 13:42:55.218: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.833071]
2023-05-27 13:42:55.372: epoch 100:	0.02699756  	0.19827156  	0.10996747  
2023-05-27 13:42:55.372: Find a better model.
2023-05-27 13:43:02.203: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0062, time: 6.830045]
2023-05-27 13:43:02.356: epoch 101:	0.02693405  	0.19774495  	0.10990875  
2023-05-27 13:43:09.376: [iter 102 : loss : 0.2740 = 0.0266 + 0.2411 + 0.0063, time: 7.019003]
2023-05-27 13:43:09.530: epoch 102:	0.02696228  	0.19787811  	0.10997374  
2023-05-27 13:43:16.394: [iter 103 : loss : 0.2737 = 0.0264 + 0.2410 + 0.0063, time: 6.863572]
2023-05-27 13:43:16.549: epoch 103:	0.02688466  	0.19747239  	0.10999017  
2023-05-27 13:43:23.401: [iter 104 : loss : 0.2739 = 0.0265 + 0.2409 + 0.0064, time: 6.850293]
2023-05-27 13:43:23.556: epoch 104:	0.02696228  	0.19795834  	0.11009163  
2023-05-27 13:43:30.396: [iter 105 : loss : 0.2734 = 0.0261 + 0.2409 + 0.0064, time: 6.839423]
2023-05-27 13:43:30.550: epoch 105:	0.02689877  	0.19761994  	0.10998505  
2023-05-27 13:43:37.377: [iter 106 : loss : 0.2728 = 0.0256 + 0.2408 + 0.0064, time: 6.826031]
2023-05-27 13:43:37.532: epoch 106:	0.02689877  	0.19767302  	0.10995324  
2023-05-27 13:43:44.391: [iter 107 : loss : 0.2722 = 0.0250 + 0.2407 + 0.0065, time: 6.858037]
2023-05-27 13:43:44.546: epoch 107:	0.02696933  	0.19813648  	0.11021585  
2023-05-27 13:43:51.377: [iter 108 : loss : 0.2718 = 0.0246 + 0.2407 + 0.0065, time: 6.830052]
2023-05-27 13:43:51.531: epoch 108:	0.02694111  	0.19813600  	0.11015494  
2023-05-27 13:43:58.403: [iter 109 : loss : 0.2710 = 0.0239 + 0.2405 + 0.0066, time: 6.870353]
2023-05-27 13:43:58.556: epoch 109:	0.02701167  	0.19867304  	0.11035313  
2023-05-27 13:43:58.556: Find a better model.
2023-05-27 13:44:05.383: [iter 110 : loss : 0.2707 = 0.0236 + 0.2405 + 0.0066, time: 6.826010]
2023-05-27 13:44:05.538: epoch 110:	0.02692699  	0.19811678  	0.11023941  
2023-05-27 13:44:12.388: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.849012]
2023-05-27 13:44:12.542: epoch 111:	0.02694111  	0.19827671  	0.11026344  
2023-05-27 13:44:19.381: [iter 112 : loss : 0.2702 = 0.0231 + 0.2403 + 0.0067, time: 6.837004]
2023-05-27 13:44:19.535: epoch 112:	0.02689877  	0.19784415  	0.11014915  
2023-05-27 13:44:26.360: [iter 113 : loss : 0.2701 = 0.0232 + 0.2402 + 0.0067, time: 6.824024]
2023-05-27 13:44:26.516: epoch 113:	0.02687760  	0.19755660  	0.11000875  
2023-05-27 13:44:33.368: [iter 114 : loss : 0.2694 = 0.0225 + 0.2402 + 0.0068, time: 6.851013]
2023-05-27 13:44:33.522: epoch 114:	0.02689877  	0.19768956  	0.11005072  
2023-05-27 13:44:40.358: [iter 115 : loss : 0.2692 = 0.0223 + 0.2401 + 0.0068, time: 6.835003]
2023-05-27 13:44:40.511: epoch 115:	0.02694817  	0.19813344  	0.11018854  
2023-05-27 13:44:47.375: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.862066]
2023-05-27 13:44:47.531: epoch 116:	0.02684938  	0.19709812  	0.10987369  
2023-05-27 13:44:54.376: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.843059]
2023-05-27 13:44:54.530: epoch 117:	0.02680703  	0.19654930  	0.10974883  
2023-05-27 13:45:01.363: [iter 118 : loss : 0.2683 = 0.0215 + 0.2399 + 0.0069, time: 6.831994]
2023-05-27 13:45:01.517: epoch 118:	0.02673646  	0.19605771  	0.10969716  
2023-05-27 13:45:08.370: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.852026]
2023-05-27 13:45:08.524: epoch 119:	0.02682820  	0.19671528  	0.10988656  
2023-05-27 13:45:15.379: [iter 120 : loss : 0.2678 = 0.0211 + 0.2398 + 0.0070, time: 6.853994]
2023-05-27 13:45:15.532: epoch 120:	0.02679998  	0.19615597  	0.10971038  
2023-05-27 13:45:22.362: [iter 121 : loss : 0.2677 = 0.0209 + 0.2397 + 0.0070, time: 6.829085]
2023-05-27 13:45:22.516: epoch 121:	0.02679998  	0.19594070  	0.10961055  
2023-05-27 13:45:29.364: [iter 122 : loss : 0.2672 = 0.0205 + 0.2397 + 0.0070, time: 6.847242]
2023-05-27 13:45:29.519: epoch 122:	0.02676470  	0.19574147  	0.10964695  
2023-05-27 13:45:36.534: [iter 123 : loss : 0.2670 = 0.0203 + 0.2396 + 0.0071, time: 7.013079]
2023-05-27 13:45:36.687: epoch 123:	0.02676470  	0.19568343  	0.10962537  
2023-05-27 13:45:43.538: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.850004]
2023-05-27 13:45:43.693: epoch 124:	0.02675059  	0.19568162  	0.10970312  
2023-05-27 13:45:50.539: [iter 125 : loss : 0.2659 = 0.0193 + 0.2395 + 0.0071, time: 6.845013]
2023-05-27 13:45:50.693: epoch 125:	0.02677175  	0.19569606  	0.10970739  
2023-05-27 13:45:57.538: [iter 126 : loss : 0.2661 = 0.0195 + 0.2394 + 0.0072, time: 6.844012]
2023-05-27 13:45:57.695: epoch 126:	0.02675764  	0.19561198  	0.10969565  
2023-05-27 13:46:04.547: [iter 127 : loss : 0.2653 = 0.0186 + 0.2394 + 0.0072, time: 6.851509]
2023-05-27 13:46:04.701: epoch 127:	0.02677175  	0.19620956  	0.10978165  
2023-05-27 13:46:11.555: [iter 128 : loss : 0.2658 = 0.0192 + 0.2393 + 0.0073, time: 6.853013]
2023-05-27 13:46:11.708: epoch 128:	0.02682114  	0.19617824  	0.10974364  
2023-05-27 13:46:18.534: [iter 129 : loss : 0.2653 = 0.0186 + 0.2393 + 0.0073, time: 6.824031]
2023-05-27 13:46:18.690: epoch 129:	0.02677175  	0.19572410  	0.10943527  
2023-05-27 13:46:25.531: [iter 130 : loss : 0.2653 = 0.0188 + 0.2392 + 0.0073, time: 6.840108]
2023-05-27 13:46:25.675: epoch 130:	0.02675058  	0.19543850  	0.10936064  
2023-05-27 13:46:32.531: [iter 131 : loss : 0.2647 = 0.0181 + 0.2392 + 0.0073, time: 6.855079]
2023-05-27 13:46:32.685: epoch 131:	0.02668002  	0.19483392  	0.10944074  
2023-05-27 13:46:39.531: [iter 132 : loss : 0.2646 = 0.0181 + 0.2391 + 0.0074, time: 6.845010]
2023-05-27 13:46:39.686: epoch 132:	0.02660239  	0.19413984  	0.10917457  
2023-05-27 13:46:46.705: [iter 133 : loss : 0.2639 = 0.0174 + 0.2391 + 0.0074, time: 7.018013]
2023-05-27 13:46:46.861: epoch 133:	0.02663062  	0.19449891  	0.10923333  
2023-05-27 13:46:53.719: [iter 134 : loss : 0.2643 = 0.0178 + 0.2390 + 0.0074, time: 6.857003]
2023-05-27 13:46:53.862: epoch 134:	0.02661650  	0.19409032  	0.10918200  
2023-05-27 13:46:53.862: Early stopping is trigger at epoch: 134
2023-05-27 13:46:53.862: best_result@epoch 109:

2023-05-27 13:46:53.862: 		0.0270      	0.1987      	0.1104      
2023-05-27 19:20:56.024: my pid: 10096
2023-05-27 19:20:56.024: model: model.general_recommender.SGL
2023-05-27 19:20:56.024: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-27 19:20:56.024: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-27 19:20:59.652: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-27 19:21:06.907: [iter 1 : loss : 1.0070 = 0.6930 + 0.3140 + 0.0000, time: 7.254046]
2023-05-27 19:21:07.057: epoch 1:	0.00148180  	0.01007288  	0.00518638  
2023-05-27 19:21:07.057: Find a better model.
2023-05-27 19:21:14.669: [iter 2 : loss : 1.0056 = 0.6929 + 0.3127 + 0.0000, time: 7.611637]
2023-05-27 19:21:14.873: epoch 2:	0.00215214  	0.01506323  	0.00759623  
2023-05-27 19:21:14.874: Find a better model.
2023-05-27 19:21:22.292: [iter 3 : loss : 1.0053 = 0.6928 + 0.3125 + 0.0000, time: 7.417400]
2023-05-27 19:21:22.483: epoch 3:	0.00323877  	0.02255323  	0.01167415  
2023-05-27 19:21:22.484: Find a better model.
2023-05-27 19:21:29.658: [iter 4 : loss : 1.0051 = 0.6927 + 0.3124 + 0.0000, time: 7.172563]
2023-05-27 19:21:29.812: epoch 4:	0.00409961  	0.02849601  	0.01466823  
2023-05-27 19:21:29.812: Find a better model.
2023-05-27 19:21:36.873: [iter 5 : loss : 1.0049 = 0.6925 + 0.3124 + 0.0000, time: 7.058073]
2023-05-27 19:21:37.021: epoch 5:	0.00508747  	0.03545045  	0.01763683  
2023-05-27 19:21:37.021: Find a better model.
2023-05-27 19:21:44.056: [iter 6 : loss : 1.0049 = 0.6923 + 0.3125 + 0.0000, time: 7.033410]
2023-05-27 19:21:44.217: epoch 6:	0.00594831  	0.04169608  	0.02087439  
2023-05-27 19:21:44.217: Find a better model.
2023-05-27 19:21:51.214: [iter 7 : loss : 1.0045 = 0.6920 + 0.3124 + 0.0000, time: 6.995029]
2023-05-27 19:21:51.361: epoch 7:	0.00666097  	0.04731534  	0.02407812  
2023-05-27 19:21:51.361: Find a better model.
2023-05-27 19:21:58.252: [iter 8 : loss : 1.0043 = 0.6918 + 0.3126 + 0.0000, time: 6.890356]
2023-05-27 19:21:58.407: epoch 8:	0.00738069  	0.05191480  	0.02677541  
2023-05-27 19:21:58.407: Find a better model.
2023-05-27 19:22:05.223: [iter 9 : loss : 1.0040 = 0.6913 + 0.3127 + 0.0000, time: 6.814396]
2023-05-27 19:22:05.367: epoch 9:	0.00829798  	0.05921273  	0.03056381  
2023-05-27 19:22:05.367: Find a better model.
2023-05-27 19:22:12.045: [iter 10 : loss : 1.0036 = 0.6908 + 0.3128 + 0.0000, time: 6.677002]
2023-05-27 19:22:12.199: epoch 10:	0.00963162  	0.06750149  	0.03438413  
2023-05-27 19:22:12.200: Find a better model.
2023-05-27 19:22:18.863: [iter 11 : loss : 1.0030 = 0.6901 + 0.3129 + 0.0000, time: 6.662097]
2023-05-27 19:22:19.005: epoch 11:	0.01059835  	0.07446928  	0.03832243  
2023-05-27 19:22:19.005: Find a better model.
2023-05-27 19:22:25.629: [iter 12 : loss : 1.0022 = 0.6891 + 0.3130 + 0.0000, time: 6.622034]
2023-05-27 19:22:25.787: epoch 12:	0.01136046  	0.08116855  	0.04098159  
2023-05-27 19:22:25.787: Find a better model.
2023-05-27 19:22:32.452: [iter 13 : loss : 1.0010 = 0.6878 + 0.3132 + 0.0000, time: 6.663004]
2023-05-27 19:22:32.602: epoch 13:	0.01239775  	0.08946972  	0.04417939  
2023-05-27 19:22:32.602: Find a better model.
2023-05-27 19:22:39.233: [iter 14 : loss : 0.9993 = 0.6858 + 0.3134 + 0.0000, time: 6.628552]
2023-05-27 19:22:39.389: epoch 14:	0.01337860  	0.09696855  	0.04757192  
2023-05-27 19:22:39.389: Find a better model.
2023-05-27 19:22:46.025: [iter 15 : loss : 0.9967 = 0.6830 + 0.3137 + 0.0000, time: 6.634202]
2023-05-27 19:22:46.181: epoch 15:	0.01452174  	0.10474711  	0.05135924  
2023-05-27 19:22:46.181: Find a better model.
2023-05-27 19:22:52.645: [iter 16 : loss : 0.9927 = 0.6785 + 0.3141 + 0.0000, time: 6.463058]
2023-05-27 19:22:52.798: epoch 16:	0.01546730  	0.11179481  	0.05466865  
2023-05-27 19:22:52.798: Find a better model.
2023-05-27 19:22:59.238: [iter 17 : loss : 0.9865 = 0.6718 + 0.3147 + 0.0001, time: 6.439018]
2023-05-27 19:22:59.391: epoch 17:	0.01671629  	0.12208136  	0.05999736  
2023-05-27 19:22:59.391: Find a better model.
2023-05-27 19:23:05.843: [iter 18 : loss : 0.9772 = 0.6616 + 0.3155 + 0.0001, time: 6.451033]
2023-05-27 19:23:05.986: epoch 18:	0.01781003  	0.13029225  	0.06439240  
2023-05-27 19:23:05.986: Find a better model.
2023-05-27 19:23:12.452: [iter 19 : loss : 0.9631 = 0.6460 + 0.3169 + 0.0001, time: 6.464298]
2023-05-27 19:23:12.595: epoch 19:	0.01876969  	0.13692948  	0.06849489  
2023-05-27 19:23:12.595: Find a better model.
2023-05-27 19:23:19.032: [iter 20 : loss : 0.9430 = 0.6239 + 0.3190 + 0.0002, time: 6.435468]
2023-05-27 19:23:19.186: epoch 20:	0.01959530  	0.14298858  	0.07248525  
2023-05-27 19:23:19.186: Find a better model.
2023-05-27 19:23:25.616: [iter 21 : loss : 0.9149 = 0.5928 + 0.3219 + 0.0002, time: 6.427544]
2023-05-27 19:23:25.759: epoch 21:	0.02002576  	0.14709623  	0.07509179  
2023-05-27 19:23:25.759: Find a better model.
2023-05-27 19:23:32.224: [iter 22 : loss : 0.8791 = 0.5533 + 0.3255 + 0.0003, time: 6.463022]
2023-05-27 19:23:32.378: epoch 22:	0.02035036  	0.14914866  	0.07656167  
2023-05-27 19:23:32.379: Find a better model.
2023-05-27 19:23:38.814: [iter 23 : loss : 0.8370 = 0.5066 + 0.3299 + 0.0005, time: 6.434047]
2023-05-27 19:23:38.954: epoch 23:	0.02071024  	0.15207280  	0.07861388  
2023-05-27 19:23:38.954: Find a better model.
2023-05-27 19:23:45.423: [iter 24 : loss : 0.7915 = 0.4567 + 0.3343 + 0.0006, time: 6.467024]
2023-05-27 19:23:45.577: epoch 24:	0.02112658  	0.15577087  	0.08042523  
2023-05-27 19:23:45.577: Find a better model.
2023-05-27 19:23:52.189: [iter 25 : loss : 0.7469 = 0.4081 + 0.3381 + 0.0007, time: 6.611011]
2023-05-27 19:23:52.341: epoch 25:	0.02139472  	0.15815508  	0.08172884  
2023-05-27 19:23:52.341: Find a better model.
2023-05-27 19:23:58.806: [iter 26 : loss : 0.7068 = 0.3648 + 0.3411 + 0.0009, time: 6.464026]
2023-05-27 19:23:58.948: epoch 26:	0.02162759  	0.15912354  	0.08272821  
2023-05-27 19:23:58.948: Find a better model.
2023-05-27 19:24:05.403: [iter 27 : loss : 0.6704 = 0.3262 + 0.3432 + 0.0010, time: 6.453267]
2023-05-27 19:24:05.555: epoch 27:	0.02183224  	0.16129296  	0.08379698  
2023-05-27 19:24:05.555: Find a better model.
2023-05-27 19:24:12.025: [iter 28 : loss : 0.6398 = 0.2941 + 0.3445 + 0.0012, time: 6.469052]
2023-05-27 19:24:12.181: epoch 28:	0.02202982  	0.16227755  	0.08456451  
2023-05-27 19:24:12.181: Find a better model.
2023-05-27 19:24:18.788: [iter 29 : loss : 0.6146 = 0.2682 + 0.3451 + 0.0013, time: 6.606046]
2023-05-27 19:24:18.943: epoch 29:	0.02222740  	0.16435389  	0.08586542  
2023-05-27 19:24:18.944: Find a better model.
2023-05-27 19:24:25.387: [iter 30 : loss : 0.5914 = 0.2445 + 0.3454 + 0.0014, time: 6.442018]
2023-05-27 19:24:25.528: epoch 30:	0.02251671  	0.16634847  	0.08708978  
2023-05-27 19:24:25.528: Find a better model.
2023-05-27 19:24:32.011: [iter 31 : loss : 0.5726 = 0.2259 + 0.3451 + 0.0016, time: 6.482017]
2023-05-27 19:24:32.165: epoch 31:	0.02273547  	0.16816933  	0.08820927  
2023-05-27 19:24:32.165: Find a better model.
2023-05-27 19:24:38.600: [iter 32 : loss : 0.5557 = 0.2092 + 0.3448 + 0.0017, time: 6.433002]
2023-05-27 19:24:38.742: epoch 32:	0.02301773  	0.17058854  	0.08936694  
2023-05-27 19:24:38.742: Find a better model.
2023-05-27 19:24:45.196: [iter 33 : loss : 0.5418 = 0.1958 + 0.3441 + 0.0018, time: 6.452301]
2023-05-27 19:24:45.349: epoch 33:	0.02325766  	0.17228720  	0.09050984  
2023-05-27 19:24:45.349: Find a better model.
2023-05-27 19:24:51.963: [iter 34 : loss : 0.5289 = 0.1836 + 0.3434 + 0.0019, time: 6.613016]
2023-05-27 19:24:52.119: epoch 34:	0.02351168  	0.17402668  	0.09165509  
2023-05-27 19:24:52.119: Find a better model.
2023-05-27 19:24:58.598: [iter 35 : loss : 0.5173 = 0.1726 + 0.3426 + 0.0020, time: 6.478341]
2023-05-27 19:24:58.750: epoch 35:	0.02361048  	0.17472023  	0.09246583  
2023-05-27 19:24:58.750: Find a better model.
2023-05-27 19:25:05.368: [iter 36 : loss : 0.5073 = 0.1632 + 0.3419 + 0.0021, time: 6.617149]
2023-05-27 19:25:05.523: epoch 36:	0.02378688  	0.17620981  	0.09341335  
2023-05-27 19:25:05.523: Find a better model.
2023-05-27 19:25:12.189: [iter 37 : loss : 0.4971 = 0.1538 + 0.3410 + 0.0023, time: 6.665037]
2023-05-27 19:25:12.344: epoch 37:	0.02397740  	0.17784250  	0.09445093  
2023-05-27 19:25:12.344: Find a better model.
2023-05-27 19:25:18.980: [iter 38 : loss : 0.4900 = 0.1473 + 0.3402 + 0.0024, time: 6.633052]
2023-05-27 19:25:19.134: epoch 38:	0.02416087  	0.17913727  	0.09532082  
2023-05-27 19:25:19.134: Find a better model.
2023-05-27 19:25:25.599: [iter 39 : loss : 0.4809 = 0.1390 + 0.3394 + 0.0025, time: 6.464027]
2023-05-27 19:25:25.752: epoch 39:	0.02430200  	0.18023491  	0.09610991  
2023-05-27 19:25:25.752: Find a better model.
2023-05-27 19:25:32.185: [iter 40 : loss : 0.4736 = 0.1325 + 0.3385 + 0.0025, time: 6.431563]
2023-05-27 19:25:32.340: epoch 40:	0.02445725  	0.18119749  	0.09695539  
2023-05-27 19:25:32.340: Find a better model.
2023-05-27 19:25:38.968: [iter 41 : loss : 0.4680 = 0.1275 + 0.3379 + 0.0026, time: 6.627027]
2023-05-27 19:25:39.124: epoch 41:	0.02465483  	0.18251188  	0.09764455  
2023-05-27 19:25:39.124: Find a better model.
2023-05-27 19:25:45.572: [iter 42 : loss : 0.4616 = 0.1219 + 0.3370 + 0.0027, time: 6.447041]
2023-05-27 19:25:45.722: epoch 42:	0.02472540  	0.18241698  	0.09809777  
2023-05-27 19:25:52.368: [iter 43 : loss : 0.4552 = 0.1161 + 0.3363 + 0.0028, time: 6.644022]
2023-05-27 19:25:52.522: epoch 43:	0.02494415  	0.18405953  	0.09889601  
2023-05-27 19:25:52.522: Find a better model.
2023-05-27 19:25:59.176: [iter 44 : loss : 0.4494 = 0.1111 + 0.3355 + 0.0029, time: 6.653154]
2023-05-27 19:25:59.333: epoch 44:	0.02504999  	0.18522117  	0.09964625  
2023-05-27 19:25:59.333: Find a better model.
2023-05-27 19:26:05.971: [iter 45 : loss : 0.4442 = 0.1062 + 0.3350 + 0.0030, time: 6.637026]
2023-05-27 19:26:06.128: epoch 45:	0.02523346  	0.18638903  	0.10026917  
2023-05-27 19:26:06.129: Find a better model.
2023-05-27 19:26:12.751: [iter 46 : loss : 0.4399 = 0.1025 + 0.3343 + 0.0031, time: 6.621017]
2023-05-27 19:26:12.893: epoch 46:	0.02535342  	0.18741462  	0.10098146  
2023-05-27 19:26:12.893: Find a better model.
2023-05-27 19:26:19.390: [iter 47 : loss : 0.4366 = 0.0998 + 0.3336 + 0.0032, time: 6.496394]
2023-05-27 19:26:19.543: epoch 47:	0.02531814  	0.18720473  	0.10125151  
2023-05-27 19:26:26.176: [iter 48 : loss : 0.4313 = 0.0950 + 0.3331 + 0.0032, time: 6.632061]
2023-05-27 19:26:26.332: epoch 48:	0.02544516  	0.18822250  	0.10185024  
2023-05-27 19:26:26.332: Find a better model.
2023-05-27 19:26:32.958: [iter 49 : loss : 0.4268 = 0.0910 + 0.3325 + 0.0033, time: 6.623998]
2023-05-27 19:26:33.116: epoch 49:	0.02559335  	0.18903971  	0.10247834  
2023-05-27 19:26:33.116: Find a better model.
2023-05-27 19:26:39.753: [iter 50 : loss : 0.4238 = 0.0885 + 0.3320 + 0.0034, time: 6.635931]
2023-05-27 19:26:39.904: epoch 50:	0.02566390  	0.18951471  	0.10286330  
2023-05-27 19:26:39.904: Find a better model.
2023-05-27 19:26:46.544: [iter 51 : loss : 0.4198 = 0.0848 + 0.3315 + 0.0035, time: 6.639056]
2023-05-27 19:26:46.698: epoch 51:	0.02578386  	0.19060752  	0.10342834  
2023-05-27 19:26:46.699: Find a better model.
2023-05-27 19:26:53.320: [iter 52 : loss : 0.4178 = 0.0833 + 0.3309 + 0.0036, time: 6.620064]
2023-05-27 19:26:53.462: epoch 52:	0.02590382  	0.19155687  	0.10399558  
2023-05-27 19:26:53.462: Find a better model.
2023-05-27 19:27:00.148: [iter 53 : loss : 0.4143 = 0.0803 + 0.3305 + 0.0036, time: 6.685579]
2023-05-27 19:27:00.290: epoch 53:	0.02587559  	0.19127105  	0.10417134  
2023-05-27 19:27:06.763: [iter 54 : loss : 0.4111 = 0.0775 + 0.3299 + 0.0037, time: 6.472013]
2023-05-27 19:27:06.918: epoch 54:	0.02594616  	0.19159524  	0.10435758  
2023-05-27 19:27:06.918: Find a better model.
2023-05-27 19:27:13.533: [iter 55 : loss : 0.4087 = 0.0753 + 0.3296 + 0.0038, time: 6.613993]
2023-05-27 19:27:13.674: epoch 55:	0.02602378  	0.19233549  	0.10473789  
2023-05-27 19:27:13.674: Find a better model.
2023-05-27 19:27:20.340: [iter 56 : loss : 0.4055 = 0.0726 + 0.3290 + 0.0038, time: 6.663397]
2023-05-27 19:27:20.495: epoch 56:	0.02608729  	0.19295378  	0.10496452  
2023-05-27 19:27:20.495: Find a better model.
2023-05-27 19:27:27.185: [iter 57 : loss : 0.4030 = 0.0703 + 0.3288 + 0.0039, time: 6.689019]
2023-05-27 19:27:27.342: epoch 57:	0.02606612  	0.19302586  	0.10518946  
2023-05-27 19:27:27.342: Find a better model.
2023-05-27 19:27:33.926: [iter 58 : loss : 0.4005 = 0.0682 + 0.3283 + 0.0040, time: 6.582994]
2023-05-27 19:27:34.071: epoch 58:	0.02605906  	0.19283541  	0.10544541  
2023-05-27 19:27:40.542: [iter 59 : loss : 0.3986 = 0.0668 + 0.3278 + 0.0040, time: 6.470019]
2023-05-27 19:27:40.694: epoch 59:	0.02612257  	0.19311804  	0.10581274  
2023-05-27 19:27:40.694: Find a better model.
2023-05-27 19:27:47.339: [iter 60 : loss : 0.3965 = 0.0648 + 0.3276 + 0.0041, time: 6.643967]
2023-05-27 19:27:47.491: epoch 60:	0.02619314  	0.19354142  	0.10599627  
2023-05-27 19:27:47.491: Find a better model.
2023-05-27 19:27:53.941: [iter 61 : loss : 0.3945 = 0.0631 + 0.3272 + 0.0042, time: 6.448994]
2023-05-27 19:27:54.097: epoch 61:	0.02619314  	0.19366035  	0.10615892  
2023-05-27 19:27:54.097: Find a better model.
2023-05-27 19:28:00.704: [iter 62 : loss : 0.3924 = 0.0613 + 0.3269 + 0.0042, time: 6.604741]
2023-05-27 19:28:00.847: epoch 62:	0.02619314  	0.19376324  	0.10627453  
2023-05-27 19:28:00.847: Find a better model.
2023-05-27 19:28:07.341: [iter 63 : loss : 0.3906 = 0.0597 + 0.3265 + 0.0043, time: 6.493212]
2023-05-27 19:28:07.496: epoch 63:	0.02630604  	0.19445267  	0.10674449  
2023-05-27 19:28:07.496: Find a better model.
2023-05-27 19:28:14.107: [iter 64 : loss : 0.3888 = 0.0583 + 0.3262 + 0.0044, time: 6.609202]
2023-05-27 19:28:14.265: epoch 64:	0.02633427  	0.19449477  	0.10683773  
2023-05-27 19:28:14.265: Find a better model.
2023-05-27 19:28:20.901: [iter 65 : loss : 0.3872 = 0.0569 + 0.3259 + 0.0044, time: 6.635078]
2023-05-27 19:28:21.052: epoch 65:	0.02639071  	0.19482753  	0.10702604  
2023-05-27 19:28:21.052: Find a better model.
2023-05-27 19:28:27.529: [iter 66 : loss : 0.3852 = 0.0551 + 0.3256 + 0.0045, time: 6.474345]
2023-05-27 19:28:27.684: epoch 66:	0.02641894  	0.19526856  	0.10740890  
2023-05-27 19:28:27.684: Find a better model.
2023-05-27 19:28:34.128: [iter 67 : loss : 0.3835 = 0.0536 + 0.3253 + 0.0046, time: 6.442440]
2023-05-27 19:28:34.282: epoch 67:	0.02646833  	0.19560318  	0.10762072  
2023-05-27 19:28:34.282: Find a better model.
2023-05-27 19:28:40.906: [iter 68 : loss : 0.3825 = 0.0528 + 0.3250 + 0.0046, time: 6.622646]
2023-05-27 19:28:41.063: epoch 68:	0.02653184  	0.19578533  	0.10800016  
2023-05-27 19:28:41.063: Find a better model.
2023-05-27 19:28:47.514: [iter 69 : loss : 0.3806 = 0.0511 + 0.3248 + 0.0047, time: 6.449023]
2023-05-27 19:28:47.669: epoch 69:	0.02651772  	0.19560575  	0.10797007  
2023-05-27 19:28:54.151: [iter 70 : loss : 0.3789 = 0.0496 + 0.3246 + 0.0047, time: 6.480291]
2023-05-27 19:28:54.305: epoch 70:	0.02654595  	0.19614500  	0.10813651  
2023-05-27 19:28:54.305: Find a better model.
2023-05-27 19:29:00.708: [iter 71 : loss : 0.3776 = 0.0485 + 0.3243 + 0.0048, time: 6.402021]
2023-05-27 19:29:00.852: epoch 71:	0.02653184  	0.19581193  	0.10803458  
2023-05-27 19:29:07.292: [iter 72 : loss : 0.3765 = 0.0475 + 0.3241 + 0.0049, time: 6.439075]
2023-05-27 19:29:07.434: epoch 72:	0.02653890  	0.19587782  	0.10821004  
2023-05-27 19:29:13.923: [iter 73 : loss : 0.3750 = 0.0462 + 0.3238 + 0.0049, time: 6.488115]
2023-05-27 19:29:14.080: epoch 73:	0.02655301  	0.19610190  	0.10843011  
2023-05-27 19:29:20.501: [iter 74 : loss : 0.3738 = 0.0452 + 0.3236 + 0.0050, time: 6.417998]
2023-05-27 19:29:20.653: epoch 74:	0.02662358  	0.19626659  	0.10857198  
2023-05-27 19:29:20.653: Find a better model.
2023-05-27 19:29:27.102: [iter 75 : loss : 0.3729 = 0.0444 + 0.3234 + 0.0050, time: 6.448066]
2023-05-27 19:29:27.254: epoch 75:	0.02658829  	0.19594529  	0.10877099  
2023-05-27 19:29:33.713: [iter 76 : loss : 0.3719 = 0.0436 + 0.3232 + 0.0051, time: 6.458051]
2023-05-27 19:29:33.866: epoch 76:	0.02656712  	0.19581038  	0.10867977  
2023-05-27 19:29:40.298: [iter 77 : loss : 0.3706 = 0.0425 + 0.3229 + 0.0051, time: 6.431065]
2023-05-27 19:29:40.450: epoch 77:	0.02661652  	0.19610807  	0.10878604  
2023-05-27 19:29:46.887: [iter 78 : loss : 0.3700 = 0.0419 + 0.3229 + 0.0052, time: 6.435016]
2023-05-27 19:29:47.030: epoch 78:	0.02658829  	0.19571926  	0.10886982  
2023-05-27 19:29:53.473: [iter 79 : loss : 0.3683 = 0.0404 + 0.3226 + 0.0053, time: 6.442091]
2023-05-27 19:29:53.624: epoch 79:	0.02665886  	0.19608146  	0.10917289  
2023-05-27 19:30:00.091: [iter 80 : loss : 0.3676 = 0.0398 + 0.3225 + 0.0053, time: 6.465518]
2023-05-27 19:30:00.233: epoch 80:	0.02660241  	0.19565818  	0.10884228  
2023-05-27 19:30:06.685: [iter 81 : loss : 0.3669 = 0.0392 + 0.3223 + 0.0054, time: 6.451007]
2023-05-27 19:30:06.840: epoch 81:	0.02667297  	0.19615598  	0.10916308  
2023-05-27 19:30:13.288: [iter 82 : loss : 0.3657 = 0.0382 + 0.3222 + 0.0054, time: 6.447258]
2023-05-27 19:30:13.444: epoch 82:	0.02672237  	0.19625182  	0.10928017  
2023-05-27 19:30:20.072: [iter 83 : loss : 0.3646 = 0.0371 + 0.3220 + 0.0055, time: 6.626068]
2023-05-27 19:30:20.226: epoch 83:	0.02676471  	0.19663517  	0.10957085  
2023-05-27 19:30:20.226: Find a better model.
2023-05-27 19:30:26.689: [iter 84 : loss : 0.3645 = 0.0371 + 0.3219 + 0.0055, time: 6.461999]
2023-05-27 19:30:26.843: epoch 84:	0.02670826  	0.19601752  	0.10931721  
2023-05-27 19:30:33.281: [iter 85 : loss : 0.3635 = 0.0363 + 0.3217 + 0.0056, time: 6.436973]
2023-05-27 19:30:33.436: epoch 85:	0.02665180  	0.19553764  	0.10914460  
2023-05-27 19:30:40.060: [iter 86 : loss : 0.3627 = 0.0356 + 0.3214 + 0.0056, time: 6.623229]
2023-05-27 19:30:40.225: epoch 86:	0.02665180  	0.19539915  	0.10903858  
2023-05-27 19:30:46.672: [iter 87 : loss : 0.3612 = 0.0342 + 0.3214 + 0.0057, time: 6.445518]
2023-05-27 19:30:46.826: epoch 87:	0.02673648  	0.19611360  	0.10929301  
2023-05-27 19:30:53.273: [iter 88 : loss : 0.3605 = 0.0335 + 0.3212 + 0.0057, time: 6.446006]
2023-05-27 19:30:53.426: epoch 88:	0.02665886  	0.19582944  	0.10923623  
2023-05-27 19:30:59.885: [iter 89 : loss : 0.3597 = 0.0328 + 0.3211 + 0.0058, time: 6.456005]
2023-05-27 19:31:00.028: epoch 89:	0.02664474  	0.19512513  	0.10909869  
2023-05-27 19:31:06.463: [iter 90 : loss : 0.3598 = 0.0331 + 0.3209 + 0.0058, time: 6.434003]
2023-05-27 19:31:06.619: epoch 90:	0.02668002  	0.19546482  	0.10928490  
2023-05-27 19:31:13.262: [iter 91 : loss : 0.3589 = 0.0324 + 0.3207 + 0.0059, time: 6.642003]
2023-05-27 19:31:13.418: epoch 91:	0.02658829  	0.19471353  	0.10888091  
2023-05-27 19:31:20.046: [iter 92 : loss : 0.3579 = 0.0314 + 0.3206 + 0.0059, time: 6.626962]
2023-05-27 19:31:20.203: epoch 92:	0.02663063  	0.19502984  	0.10910840  
2023-05-27 19:31:26.866: [iter 93 : loss : 0.3579 = 0.0315 + 0.3205 + 0.0060, time: 6.661003]
2023-05-27 19:31:27.022: epoch 93:	0.02654595  	0.19428584  	0.10900161  
2023-05-27 19:31:33.636: [iter 94 : loss : 0.3566 = 0.0302 + 0.3204 + 0.0060, time: 6.612002]
2023-05-27 19:31:33.792: epoch 94:	0.02653889  	0.19431609  	0.10906950  
2023-05-27 19:31:40.440: [iter 95 : loss : 0.3557 = 0.0294 + 0.3202 + 0.0060, time: 6.646524]
2023-05-27 19:31:40.594: epoch 95:	0.02655300  	0.19439115  	0.10913129  
2023-05-27 19:31:47.270: [iter 96 : loss : 0.3557 = 0.0295 + 0.3201 + 0.0061, time: 6.674370]
2023-05-27 19:31:47.425: epoch 96:	0.02651772  	0.19409551  	0.10892376  
2023-05-27 19:31:54.038: [iter 97 : loss : 0.3545 = 0.0284 + 0.3200 + 0.0061, time: 6.611171]
2023-05-27 19:31:54.178: epoch 97:	0.02660240  	0.19442150  	0.10894597  
2023-05-27 19:32:01.009: [iter 98 : loss : 0.3543 = 0.0282 + 0.3199 + 0.0062, time: 6.829023]
2023-05-27 19:32:01.152: epoch 98:	0.02662357  	0.19467753  	0.10917643  
2023-05-27 19:32:07.830: [iter 99 : loss : 0.3537 = 0.0276 + 0.3198 + 0.0062, time: 6.676003]
2023-05-27 19:32:07.984: epoch 99:	0.02675059  	0.19574352  	0.10961247  
2023-05-27 19:32:14.624: [iter 100 : loss : 0.3534 = 0.0274 + 0.3197 + 0.0063, time: 6.638994]
2023-05-27 19:32:14.781: epoch 100:	0.02674353  	0.19568205  	0.10962147  
2023-05-27 19:32:21.248: [iter 101 : loss : 0.3527 = 0.0268 + 0.3196 + 0.0063, time: 6.466012]
2023-05-27 19:32:21.401: epoch 101:	0.02671531  	0.19572212  	0.10954504  
2023-05-27 19:32:28.026: [iter 102 : loss : 0.3522 = 0.0263 + 0.3195 + 0.0064, time: 6.624029]
2023-05-27 19:32:28.182: epoch 102:	0.02672942  	0.19596449  	0.10962563  
2023-05-27 19:32:34.640: [iter 103 : loss : 0.3518 = 0.0261 + 0.3193 + 0.0064, time: 6.457548]
2023-05-27 19:32:34.782: epoch 103:	0.02672236  	0.19574328  	0.10985937  
2023-05-27 19:32:41.401: [iter 104 : loss : 0.3519 = 0.0261 + 0.3193 + 0.0065, time: 6.617994]
2023-05-27 19:32:41.559: epoch 104:	0.02668709  	0.19544570  	0.10970550  
2023-05-27 19:32:48.201: [iter 105 : loss : 0.3514 = 0.0257 + 0.3193 + 0.0065, time: 6.641046]
2023-05-27 19:32:48.355: epoch 105:	0.02665180  	0.19492903  	0.10940032  
2023-05-27 19:32:54.833: [iter 106 : loss : 0.3509 = 0.0252 + 0.3192 + 0.0065, time: 6.476060]
2023-05-27 19:32:54.987: epoch 106:	0.02662358  	0.19459242  	0.10925812  
2023-05-27 19:33:01.603: [iter 107 : loss : 0.3503 = 0.0246 + 0.3191 + 0.0066, time: 6.614451]
2023-05-27 19:33:01.756: epoch 107:	0.02658829  	0.19445825  	0.10928605  
2023-05-27 19:33:08.228: [iter 108 : loss : 0.3498 = 0.0241 + 0.3191 + 0.0066, time: 6.470012]
2023-05-27 19:33:08.383: epoch 108:	0.02665180  	0.19493434  	0.10950672  
2023-05-27 19:33:08.383: Early stopping is trigger at epoch: 108
2023-05-27 19:33:08.383: best_result@epoch 83:

2023-05-27 19:33:08.383: 		0.0268      	0.1966      	0.1096      
2023-05-27 19:39:27.110: my pid: 4216
2023-05-27 19:39:27.110: model: model.general_recommender.SGL
2023-05-27 19:39:27.110: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-27 19:39:27.110: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-27 19:39:30.786: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-27 19:39:38.129: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.342026]
2023-05-27 19:39:38.285: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-27 19:39:38.285: Find a better model.
2023-05-27 19:39:45.727: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.441095]
2023-05-27 19:39:45.936: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-27 19:39:45.936: Find a better model.
2023-05-27 19:39:53.113: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.175213]
2023-05-27 19:39:53.289: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-27 19:39:53.289: Find a better model.
2023-05-27 19:40:00.289: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 6.999021]
2023-05-27 19:40:00.438: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-27 19:40:00.438: Find a better model.
2023-05-27 19:40:07.310: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 6.871372]
2023-05-27 19:40:07.470: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-27 19:40:07.470: Find a better model.
2023-05-27 19:40:14.287: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.816006]
2023-05-27 19:40:14.447: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-27 19:40:14.447: Find a better model.
2023-05-27 19:40:21.261: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.813179]
2023-05-27 19:40:21.418: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-27 19:40:21.418: Find a better model.
2023-05-27 19:40:28.241: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.822232]
2023-05-27 19:40:28.400: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-27 19:40:28.400: Find a better model.
2023-05-27 19:40:35.059: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.658000]
2023-05-27 19:40:35.215: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-27 19:40:41.853: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.637060]
2023-05-27 19:40:42.009: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-27 19:40:48.685: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.674109]
2023-05-27 19:40:48.839: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-27 19:40:55.446: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.605046]
2023-05-27 19:40:55.600: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-27 19:41:02.074: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.473398]
2023-05-27 19:41:02.228: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-27 19:41:08.666: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.436981]
2023-05-27 19:41:08.819: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-27 19:41:15.442: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.622016]
2023-05-27 19:41:15.586: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-27 19:41:15.586: Find a better model.
2023-05-27 19:41:22.242: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.654012]
2023-05-27 19:41:22.389: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-27 19:41:22.389: Find a better model.
2023-05-27 19:41:29.060: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.668040]
2023-05-27 19:41:29.204: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-27 19:41:29.205: Find a better model.
2023-05-27 19:41:35.861: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.655016]
2023-05-27 19:41:36.005: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-27 19:41:36.005: Find a better model.
2023-05-27 19:41:42.452: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.446124]
2023-05-27 19:41:42.597: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-27 19:41:42.598: Find a better model.
2023-05-27 19:41:49.245: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.645026]
2023-05-27 19:41:49.403: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-27 19:41:49.403: Find a better model.
2023-05-27 19:41:56.046: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.641333]
2023-05-27 19:41:56.193: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-27 19:41:56.193: Find a better model.
2023-05-27 19:42:02.829: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.635011]
2023-05-27 19:42:02.976: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-27 19:42:02.977: Find a better model.
2023-05-27 19:42:09.638: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.659994]
2023-05-27 19:42:09.795: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-27 19:42:09.796: Find a better model.
2023-05-27 19:42:16.448: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.650994]
2023-05-27 19:42:16.604: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-27 19:42:16.604: Find a better model.
2023-05-27 19:42:23.236: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.630995]
2023-05-27 19:42:23.384: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-27 19:42:23.384: Find a better model.
2023-05-27 19:42:30.027: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.641283]
2023-05-27 19:42:30.168: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-27 19:42:30.168: Find a better model.
2023-05-27 19:42:36.816: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.646063]
2023-05-27 19:42:36.971: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-27 19:42:36.971: Find a better model.
2023-05-27 19:42:43.619: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.646987]
2023-05-27 19:42:43.773: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-27 19:42:43.773: Find a better model.
2023-05-27 19:42:50.437: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.663001]
2023-05-27 19:42:50.591: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-27 19:42:50.591: Find a better model.
2023-05-27 19:42:57.220: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.628026]
2023-05-27 19:42:57.378: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-27 19:42:57.378: Find a better model.
2023-05-27 19:43:04.024: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.645010]
2023-05-27 19:43:04.170: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-27 19:43:04.170: Find a better model.
2023-05-27 19:43:10.805: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.634012]
2023-05-27 19:43:10.960: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-27 19:43:10.960: Find a better model.
2023-05-27 19:43:17.608: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.647108]
2023-05-27 19:43:17.766: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-27 19:43:17.766: Find a better model.
2023-05-27 19:43:24.422: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.653681]
2023-05-27 19:43:24.579: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-27 19:43:24.579: Find a better model.
2023-05-27 19:43:31.210: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.630064]
2023-05-27 19:43:31.368: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-27 19:43:31.368: Find a better model.
2023-05-27 19:43:37.982: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.613003]
2023-05-27 19:43:38.136: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-27 19:43:38.136: Find a better model.
2023-05-27 19:43:44.804: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.667000]
2023-05-27 19:43:44.959: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-27 19:43:44.960: Find a better model.
2023-05-27 19:43:51.598: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.636451]
2023-05-27 19:43:51.756: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-27 19:43:51.756: Find a better model.
2023-05-27 19:43:58.405: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.648016]
2023-05-27 19:43:58.560: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-27 19:43:58.560: Find a better model.
2023-05-27 19:44:05.200: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.639022]
2023-05-27 19:44:05.362: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-27 19:44:12.005: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.642018]
2023-05-27 19:44:12.162: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-27 19:44:12.162: Find a better model.
2023-05-27 19:44:18.785: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.621004]
2023-05-27 19:44:18.926: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-27 19:44:18.926: Find a better model.
2023-05-27 19:44:25.589: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.662477]
2023-05-27 19:44:25.746: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-27 19:44:25.746: Find a better model.
2023-05-27 19:44:32.426: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.678499]
2023-05-27 19:44:32.582: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-27 19:44:32.582: Find a better model.
2023-05-27 19:44:39.366: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.783630]
2023-05-27 19:44:39.522: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-27 19:44:39.522: Find a better model.
2023-05-27 19:44:46.374: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.850003]
2023-05-27 19:44:46.516: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-27 19:44:46.516: Find a better model.
2023-05-27 19:44:53.195: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.677059]
2023-05-27 19:44:53.354: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-27 19:44:53.354: Find a better model.
2023-05-27 19:45:00.184: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.829026]
2023-05-27 19:45:00.329: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-27 19:45:00.330: Find a better model.
2023-05-27 19:45:06.995: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.664085]
2023-05-27 19:45:07.149: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-27 19:45:07.149: Find a better model.
2023-05-27 19:45:13.786: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.636007]
2023-05-27 19:45:13.941: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-27 19:45:13.941: Find a better model.
2023-05-27 19:45:20.580: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.636551]
2023-05-27 19:45:20.733: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-27 19:45:27.562: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.828050]
2023-05-27 19:45:27.707: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-27 19:45:27.707: Find a better model.
2023-05-27 19:45:34.365: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.657027]
2023-05-27 19:45:34.519: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-27 19:45:34.519: Find a better model.
2023-05-27 19:45:41.156: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.636011]
2023-05-27 19:45:41.297: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-27 19:45:41.297: Find a better model.
2023-05-27 19:45:47.951: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.651013]
2023-05-27 19:45:48.105: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-27 19:45:48.105: Find a better model.
2023-05-27 19:45:54.764: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.658039]
2023-05-27 19:45:54.919: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-27 19:45:54.919: Find a better model.
2023-05-27 19:46:01.598: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.678033]
2023-05-27 19:46:01.752: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-27 19:46:01.753: Find a better model.
2023-05-27 19:46:08.347: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.593019]
2023-05-27 19:46:08.491: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-27 19:46:08.491: Find a better model.
2023-05-27 19:46:15.123: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.631006]
2023-05-27 19:46:15.265: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-27 19:46:15.265: Find a better model.
2023-05-27 19:46:21.955: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.688513]
2023-05-27 19:46:22.109: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-27 19:46:22.109: Find a better model.
2023-05-27 19:46:28.749: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.638089]
2023-05-27 19:46:28.902: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-27 19:46:28.902: Find a better model.
2023-05-27 19:46:35.551: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.646003]
2023-05-27 19:46:35.707: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-27 19:46:35.708: Find a better model.
2023-05-27 19:46:42.389: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.680086]
2023-05-27 19:46:42.531: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-27 19:46:49.313: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.781041]
2023-05-27 19:46:49.455: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-27 19:46:49.455: Find a better model.
2023-05-27 19:46:56.318: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.862381]
2023-05-27 19:46:56.461: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-27 19:46:56.461: Find a better model.
2023-05-27 19:47:03.142: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.679078]
2023-05-27 19:47:03.286: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-27 19:47:03.286: Find a better model.
2023-05-27 19:47:09.953: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.664001]
2023-05-27 19:47:10.106: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-27 19:47:10.106: Find a better model.
2023-05-27 19:47:16.753: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.646078]
2023-05-27 19:47:16.907: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-27 19:47:16.907: Find a better model.
2023-05-27 19:47:23.537: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.629066]
2023-05-27 19:47:23.692: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-27 19:47:23.692: Find a better model.
2023-05-27 19:47:30.349: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.654035]
2023-05-27 19:47:30.503: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-27 19:47:30.503: Find a better model.
2023-05-27 19:47:37.318: [iter 71 : loss : 0.1488 = 0.0576 + 0.0870 + 0.0043, time: 6.812092]
2023-05-27 19:47:37.472: epoch 71:	0.02543808  	0.18768108  	0.10186037  
2023-05-27 19:47:44.307: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.834007]
2023-05-27 19:47:44.449: epoch 72:	0.02543102  	0.18797305  	0.10207389  
2023-05-27 19:47:44.449: Find a better model.
2023-05-27 19:47:51.326: [iter 73 : loss : 0.1472 = 0.0562 + 0.0867 + 0.0043, time: 6.875070]
2023-05-27 19:47:51.470: epoch 73:	0.02548747  	0.18821423  	0.10245861  
2023-05-27 19:47:51.470: Find a better model.
2023-05-27 19:47:58.313: [iter 74 : loss : 0.1459 = 0.0548 + 0.0866 + 0.0044, time: 6.840993]
2023-05-27 19:47:58.456: epoch 74:	0.02549453  	0.18799621  	0.10253018  
2023-05-27 19:48:05.321: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.864004]
2023-05-27 19:48:05.477: epoch 75:	0.02545924  	0.18779024  	0.10253959  
2023-05-27 19:48:12.489: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 7.011007]
2023-05-27 19:48:12.634: epoch 76:	0.02556509  	0.18843055  	0.10298465  
2023-05-27 19:48:12.634: Find a better model.
2023-05-27 19:48:19.520: [iter 77 : loss : 0.1435 = 0.0528 + 0.0863 + 0.0045, time: 6.885001]
2023-05-27 19:48:19.674: epoch 77:	0.02564272  	0.18906085  	0.10322937  
2023-05-27 19:48:19.674: Find a better model.
2023-05-27 19:48:26.516: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.840005]
2023-05-27 19:48:26.672: epoch 78:	0.02568506  	0.18941851  	0.10334646  
2023-05-27 19:48:26.672: Find a better model.
2023-05-27 19:48:33.498: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.825122]
2023-05-27 19:48:33.642: epoch 79:	0.02565683  	0.18933600  	0.10335580  
2023-05-27 19:48:40.514: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.870097]
2023-05-27 19:48:40.668: epoch 80:	0.02573445  	0.18994674  	0.10369636  
2023-05-27 19:48:40.668: Find a better model.
2023-05-27 19:48:47.512: [iter 81 : loss : 0.1404 = 0.0499 + 0.0858 + 0.0047, time: 6.842022]
2023-05-27 19:48:47.667: epoch 81:	0.02574856  	0.18996128  	0.10371687  
2023-05-27 19:48:47.667: Find a better model.
2023-05-27 19:48:54.514: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.845624]
2023-05-27 19:48:54.671: epoch 82:	0.02595320  	0.19146687  	0.10448496  
2023-05-27 19:48:54.671: Find a better model.
2023-05-27 19:49:01.524: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.852507]
2023-05-27 19:49:01.679: epoch 83:	0.02591087  	0.19120401  	0.10432982  
2023-05-27 19:49:08.516: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.835163]
2023-05-27 19:49:08.668: epoch 84:	0.02591087  	0.19124350  	0.10439519  
2023-05-27 19:49:15.491: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.821475]
2023-05-27 19:49:15.647: epoch 85:	0.02592499  	0.19143361  	0.10480354  
2023-05-27 19:49:22.490: [iter 86 : loss : 0.1368 = 0.0466 + 0.0853 + 0.0049, time: 6.841999]
2023-05-27 19:49:22.646: epoch 86:	0.02598144  	0.19180954  	0.10491684  
2023-05-27 19:49:22.646: Find a better model.
2023-05-27 19:49:29.478: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.831024]
2023-05-27 19:49:29.630: epoch 87:	0.02605906  	0.19217947  	0.10507733  
2023-05-27 19:49:29.630: Find a better model.
2023-05-27 19:49:36.488: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.857033]
2023-05-27 19:49:36.645: epoch 88:	0.02609434  	0.19233893  	0.10512113  
2023-05-27 19:49:36.645: Find a better model.
2023-05-27 19:49:43.673: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 7.027003]
2023-05-27 19:49:43.817: epoch 89:	0.02603789  	0.19177690  	0.10494585  
2023-05-27 19:49:50.668: [iter 90 : loss : 0.1341 = 0.0440 + 0.0850 + 0.0050, time: 6.849994]
2023-05-27 19:49:50.810: epoch 90:	0.02620724  	0.19282709  	0.10541335  
2023-05-27 19:49:50.810: Find a better model.
2023-05-27 19:49:57.686: [iter 91 : loss : 0.1326 = 0.0427 + 0.0849 + 0.0050, time: 6.874978]
2023-05-27 19:49:57.841: epoch 91:	0.02622841  	0.19316201  	0.10560033  
2023-05-27 19:49:57.841: Find a better model.
2023-05-27 19:50:04.669: [iter 92 : loss : 0.1314 = 0.0415 + 0.0848 + 0.0051, time: 6.827017]
2023-05-27 19:50:04.825: epoch 92:	0.02627075  	0.19329657  	0.10572476  
2023-05-27 19:50:04.825: Find a better model.
2023-05-27 19:50:11.676: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.850184]
2023-05-27 19:50:11.832: epoch 93:	0.02628486  	0.19351923  	0.10589959  
2023-05-27 19:50:11.832: Find a better model.
2023-05-27 19:50:18.668: [iter 94 : loss : 0.1300 = 0.0402 + 0.0847 + 0.0052, time: 6.835084]
2023-05-27 19:50:18.825: epoch 94:	0.02637660  	0.19428018  	0.10624499  
2023-05-27 19:50:18.826: Find a better model.
2023-05-27 19:50:25.657: [iter 95 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.830015]
2023-05-27 19:50:25.799: epoch 95:	0.02632720  	0.19385040  	0.10619501  
2023-05-27 19:50:32.687: [iter 96 : loss : 0.1293 = 0.0395 + 0.0845 + 0.0052, time: 6.887021]
2023-05-27 19:50:32.842: epoch 96:	0.02631309  	0.19378476  	0.10633411  
2023-05-27 19:50:39.647: [iter 97 : loss : 0.1278 = 0.0381 + 0.0845 + 0.0053, time: 6.804013]
2023-05-27 19:50:39.801: epoch 97:	0.02639071  	0.19447196  	0.10644874  
2023-05-27 19:50:39.801: Find a better model.
2023-05-27 19:50:46.649: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.844515]
2023-05-27 19:50:46.800: epoch 98:	0.02648950  	0.19530457  	0.10684249  
2023-05-27 19:50:46.800: Find a better model.
2023-05-27 19:50:53.633: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 6.832007]
2023-05-27 19:50:53.789: epoch 99:	0.02654595  	0.19579294  	0.10703380  
2023-05-27 19:50:53.789: Find a better model.
2023-05-27 19:51:00.630: [iter 100 : loss : 0.1269 = 0.0373 + 0.0842 + 0.0054, time: 6.840030]
2023-05-27 19:51:00.773: epoch 100:	0.02659534  	0.19630365  	0.10702921  
2023-05-27 19:51:00.773: Find a better model.
2023-05-27 19:51:07.641: [iter 101 : loss : 0.1264 = 0.0369 + 0.0842 + 0.0054, time: 6.866021]
2023-05-27 19:51:07.794: epoch 101:	0.02660240  	0.19649538  	0.10713183  
2023-05-27 19:51:07.795: Find a better model.
2023-05-27 19:51:14.647: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0055, time: 6.850006]
2023-05-27 19:51:14.800: epoch 102:	0.02668002  	0.19677821  	0.10737970  
2023-05-27 19:51:14.800: Find a better model.
2023-05-27 19:51:21.629: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.828003]
2023-05-27 19:51:21.783: epoch 103:	0.02674353  	0.19726442  	0.10753223  
2023-05-27 19:51:21.783: Find a better model.
2023-05-27 19:51:28.626: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.842090]
2023-05-27 19:51:28.784: epoch 104:	0.02676470  	0.19756219  	0.10781818  
2023-05-27 19:51:28.784: Find a better model.
2023-05-27 19:51:35.631: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.846006]
2023-05-27 19:51:35.786: epoch 105:	0.02672236  	0.19736582  	0.10783488  
2023-05-27 19:51:42.631: [iter 106 : loss : 0.1245 = 0.0351 + 0.0838 + 0.0056, time: 6.844400]
2023-05-27 19:51:42.785: epoch 106:	0.02670120  	0.19685170  	0.10756116  
2023-05-27 19:51:49.638: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.852042]
2023-05-27 19:51:49.794: epoch 107:	0.02674353  	0.19704916  	0.10767850  
2023-05-27 19:51:56.829: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 7.032028]
2023-05-27 19:51:56.984: epoch 108:	0.02672941  	0.19716047  	0.10772790  
2023-05-27 19:52:03.841: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.856277]
2023-05-27 19:52:03.994: epoch 109:	0.02680703  	0.19766437  	0.10783334  
2023-05-27 19:52:03.994: Find a better model.
2023-05-27 19:52:10.838: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.842136]
2023-05-27 19:52:10.992: epoch 110:	0.02684232  	0.19785625  	0.10784779  
2023-05-27 19:52:10.992: Find a better model.
2023-05-27 19:52:17.828: [iter 111 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0058, time: 6.835372]
2023-05-27 19:52:17.982: epoch 111:	0.02685643  	0.19818251  	0.10798550  
2023-05-27 19:52:17.982: Find a better model.
2023-05-27 19:52:24.827: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.843232]
2023-05-27 19:52:24.983: epoch 112:	0.02689171  	0.19838083  	0.10807753  
2023-05-27 19:52:24.983: Find a better model.
2023-05-27 19:52:31.829: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.845612]
2023-05-27 19:52:31.983: epoch 113:	0.02694110  	0.19904543  	0.10827850  
2023-05-27 19:52:31.983: Find a better model.
2023-05-27 19:52:38.801: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.817269]
2023-05-27 19:52:38.956: epoch 114:	0.02698344  	0.19929743  	0.10852559  
2023-05-27 19:52:38.957: Find a better model.
2023-05-27 19:52:45.823: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.865405]
2023-05-27 19:52:45.977: epoch 115:	0.02699049  	0.19890624  	0.10854208  
2023-05-27 19:52:52.824: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.846009]
2023-05-27 19:52:52.978: epoch 116:	0.02692698  	0.19826479  	0.10835240  
2023-05-27 19:52:59.792: [iter 117 : loss : 0.1193 = 0.0301 + 0.0832 + 0.0060, time: 6.813069]
2023-05-27 19:52:59.938: epoch 117:	0.02691993  	0.19823329  	0.10824537  
2023-05-27 19:53:06.621: [iter 118 : loss : 0.1191 = 0.0299 + 0.0832 + 0.0060, time: 6.681859]
2023-05-27 19:53:06.773: epoch 118:	0.02697638  	0.19860731  	0.10839922  
2023-05-27 19:53:13.612: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.836019]
2023-05-27 19:53:13.770: epoch 119:	0.02691993  	0.19818303  	0.10849641  
2023-05-27 19:53:20.597: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0060, time: 6.825994]
2023-05-27 19:53:20.741: epoch 120:	0.02701166  	0.19881399  	0.10874552  
2023-05-27 19:53:27.597: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.855189]
2023-05-27 19:53:27.749: epoch 121:	0.02697637  	0.19845463  	0.10879885  
2023-05-27 19:53:34.615: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.864036]
2023-05-27 19:53:34.770: epoch 122:	0.02701871  	0.19877794  	0.10886750  
2023-05-27 19:53:41.588: [iter 123 : loss : 0.1175 = 0.0285 + 0.0829 + 0.0061, time: 6.816036]
2023-05-27 19:53:41.743: epoch 123:	0.02699048  	0.19863144  	0.10863070  
2023-05-27 19:53:48.592: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.846573]
2023-05-27 19:53:48.744: epoch 124:	0.02703282  	0.19897416  	0.10862983  
2023-05-27 19:53:55.581: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.836040]
2023-05-27 19:53:55.737: epoch 125:	0.02708222  	0.19944212  	0.10877951  
2023-05-27 19:53:55.737: Find a better model.
2023-05-27 19:54:02.597: [iter 126 : loss : 0.1161 = 0.0270 + 0.0828 + 0.0062, time: 6.858030]
2023-05-27 19:54:02.752: epoch 126:	0.02704694  	0.19924128  	0.10876483  
2023-05-27 19:54:09.580: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.827155]
2023-05-27 19:54:09.735: epoch 127:	0.02699755  	0.19923887  	0.10890996  
2023-05-27 19:54:16.582: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 6.845015]
2023-05-27 19:54:16.734: epoch 128:	0.02706811  	0.19969688  	0.10903610  
2023-05-27 19:54:16.735: Find a better model.
2023-05-27 19:54:23.573: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.836993]
2023-05-27 19:54:23.728: epoch 129:	0.02712456  	0.19999887  	0.10923928  
2023-05-27 19:54:23.728: Find a better model.
2023-05-27 19:54:30.567: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.838120]
2023-05-27 19:54:30.721: epoch 130:	0.02714573  	0.20038788  	0.10945308  
2023-05-27 19:54:30.721: Find a better model.
2023-05-27 19:54:37.584: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.862097]
2023-05-27 19:54:37.738: epoch 131:	0.02711751  	0.20002809  	0.10950513  
2023-05-27 19:54:44.566: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.826011]
2023-05-27 19:54:44.724: epoch 132:	0.02715984  	0.20060162  	0.10956918  
2023-05-27 19:54:44.724: Find a better model.
2023-05-27 19:54:51.573: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.848030]
2023-05-27 19:54:51.727: epoch 133:	0.02711045  	0.20034035  	0.10963194  
2023-05-27 19:54:58.566: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.837006]
2023-05-27 19:54:58.719: epoch 134:	0.02712456  	0.20007493  	0.10961327  
2023-05-27 19:55:05.386: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.666543]
2023-05-27 19:55:05.532: epoch 135:	0.02708928  	0.19984719  	0.10949532  
2023-05-27 19:55:12.171: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.638003]
2023-05-27 19:55:12.331: epoch 136:	0.02703989  	0.19994451  	0.10932730  
2023-05-27 19:55:19.160: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.828400]
2023-05-27 19:55:19.318: epoch 137:	0.02711044  	0.20013352  	0.10945937  
2023-05-27 19:55:26.139: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.818013]
2023-05-27 19:55:26.292: epoch 138:	0.02703989  	0.19963494  	0.10928164  
2023-05-27 19:55:33.156: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.862613]
2023-05-27 19:55:33.314: epoch 139:	0.02703283  	0.19941264  	0.10925976  
2023-05-27 19:55:39.957: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.640051]
2023-05-27 19:55:40.100: epoch 140:	0.02706105  	0.19963543  	0.10932929  
2023-05-27 19:55:46.955: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.852467]
2023-05-27 19:55:47.109: epoch 141:	0.02706105  	0.19944294  	0.10951345  
2023-05-27 19:55:53.754: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.643014]
2023-05-27 19:55:53.899: epoch 142:	0.02707517  	0.19963950  	0.10954686  
2023-05-27 19:56:00.735: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.835031]
2023-05-27 19:56:00.880: epoch 143:	0.02708222  	0.19975567  	0.10967370  
2023-05-27 19:56:07.731: [iter 144 : loss : 0.1113 = 0.0225 + 0.0821 + 0.0068, time: 6.848090]
2023-05-27 19:56:07.885: epoch 144:	0.02705400  	0.19964875  	0.10968246  
2023-05-27 19:56:14.732: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.846474]
2023-05-27 19:56:14.887: epoch 145:	0.02711751  	0.20003700  	0.10976334  
2023-05-27 19:56:21.741: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.852489]
2023-05-27 19:56:21.896: epoch 146:	0.02702578  	0.19929959  	0.10948770  
2023-05-27 19:56:28.552: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.654203]
2023-05-27 19:56:28.705: epoch 147:	0.02706106  	0.19962148  	0.10972972  
2023-05-27 19:56:35.562: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.856046]
2023-05-27 19:56:35.716: epoch 148:	0.02711751  	0.19978274  	0.10971002  
2023-05-27 19:56:42.523: [iter 149 : loss : 0.1105 = 0.0218 + 0.0819 + 0.0069, time: 6.804149]
2023-05-27 19:56:42.667: epoch 149:	0.02715279  	0.19997163  	0.10980726  
2023-05-27 19:56:49.348: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.679013]
2023-05-27 19:56:49.504: epoch 150:	0.02716691  	0.20002118  	0.11011983  
2023-05-27 19:56:56.340: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.835035]
2023-05-27 19:56:56.497: epoch 151:	0.02716691  	0.19978747  	0.11005402  
2023-05-27 19:57:03.300: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.802011]
2023-05-27 19:57:03.445: epoch 152:	0.02710340  	0.19948760  	0.11000174  
2023-05-27 19:57:10.142: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.695060]
2023-05-27 19:57:10.297: epoch 153:	0.02712457  	0.19950961  	0.10990855  
2023-05-27 19:57:17.103: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.805021]
2023-05-27 19:57:17.246: epoch 154:	0.02722335  	0.20035940  	0.11020384  
2023-05-27 19:57:23.934: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.687046]
2023-05-27 19:57:24.088: epoch 155:	0.02711751  	0.19959040  	0.10992879  
2023-05-27 19:57:30.739: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.649417]
2023-05-27 19:57:30.894: epoch 156:	0.02711751  	0.19968447  	0.10984320  
2023-05-27 19:57:37.690: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.795156]
2023-05-27 19:57:37.845: epoch 157:	0.02712457  	0.19975244  	0.10977825  
2023-05-27 19:57:37.845: Early stopping is trigger at epoch: 157
2023-05-27 19:57:37.845: best_result@epoch 132:

2023-05-27 19:57:37.845: 		0.0272      	0.2006      	0.1096      
2023-05-27 20:00:14.135: my pid: 14812
2023-05-27 20:00:14.135: model: model.general_recommender.SGL
2023-05-27 20:00:14.135: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-27 20:00:14.135: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-27 20:00:17.829: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-27 20:00:25.111: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.282069]
2023-05-27 20:00:25.267: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-27 20:00:25.267: Find a better model.
2023-05-27 20:00:32.873: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.605459]
2023-05-27 20:00:33.072: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-27 20:00:33.072: Find a better model.
2023-05-27 20:00:40.481: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.407991]
2023-05-27 20:00:40.654: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-27 20:00:40.654: Find a better model.
2023-05-27 20:00:47.691: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.035041]
2023-05-27 20:00:47.860: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-27 20:00:47.860: Find a better model.
2023-05-27 20:00:55.060: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.199166]
2023-05-27 20:00:55.227: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-27 20:00:55.228: Find a better model.
2023-05-27 20:01:02.253: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 7.024023]
2023-05-27 20:01:02.413: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-27 20:01:02.413: Find a better model.
2023-05-27 20:01:09.240: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.825007]
2023-05-27 20:01:09.397: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-27 20:01:09.397: Find a better model.
2023-05-27 20:01:16.041: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.643045]
2023-05-27 20:01:16.188: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-27 20:01:16.188: Find a better model.
2023-05-27 20:01:22.846: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.655143]
2023-05-27 20:01:23.005: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-27 20:01:23.005: Find a better model.
2023-05-27 20:01:29.645: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.639309]
2023-05-27 20:01:29.791: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-27 20:01:29.791: Find a better model.
2023-05-27 20:01:36.434: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.641288]
2023-05-27 20:01:36.577: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-27 20:01:36.577: Find a better model.
2023-05-27 20:01:43.218: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.639304]
2023-05-27 20:01:43.373: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-27 20:01:43.373: Find a better model.
2023-05-27 20:01:50.031: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.656469]
2023-05-27 20:01:50.188: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-27 20:01:50.188: Find a better model.
2023-05-27 20:01:56.842: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.653008]
2023-05-27 20:01:57.001: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-27 20:01:57.001: Find a better model.
2023-05-27 20:02:03.622: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.619001]
2023-05-27 20:02:03.766: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-27 20:02:10.419: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.651446]
2023-05-27 20:02:10.574: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-27 20:02:10.574: Find a better model.
2023-05-27 20:02:17.221: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.646245]
2023-05-27 20:02:17.377: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-27 20:02:17.377: Find a better model.
2023-05-27 20:02:23.835: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.457046]
2023-05-27 20:02:23.982: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-27 20:02:23.982: Find a better model.
2023-05-27 20:02:30.428: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.445325]
2023-05-27 20:02:30.587: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-27 20:02:30.587: Find a better model.
2023-05-27 20:02:37.200: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.610069]
2023-05-27 20:02:37.358: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-27 20:02:37.359: Find a better model.
2023-05-27 20:02:43.799: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.439042]
2023-05-27 20:02:43.950: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-27 20:02:43.950: Find a better model.
2023-05-27 20:02:50.374: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.423003]
2023-05-27 20:02:50.517: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-27 20:02:50.517: Find a better model.
2023-05-27 20:02:56.983: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.465052]
2023-05-27 20:02:57.138: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-27 20:02:57.138: Find a better model.
2023-05-27 20:03:03.597: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.458058]
2023-05-27 20:03:03.752: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-27 20:03:03.752: Find a better model.
2023-05-27 20:03:10.200: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.445911]
2023-05-27 20:03:10.353: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-27 20:03:10.353: Find a better model.
2023-05-27 20:03:16.784: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.430003]
2023-05-27 20:03:16.940: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-27 20:03:16.940: Find a better model.
2023-05-27 20:03:23.381: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.440775]
2023-05-27 20:03:23.535: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-27 20:03:23.535: Find a better model.
2023-05-27 20:03:30.000: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.463371]
2023-05-27 20:03:30.155: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-27 20:03:30.155: Find a better model.
2023-05-27 20:03:36.592: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.435084]
2023-05-27 20:03:36.745: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-27 20:03:36.745: Find a better model.
2023-05-27 20:03:43.188: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.442083]
2023-05-27 20:03:43.343: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-27 20:03:43.343: Find a better model.
2023-05-27 20:03:49.799: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.455533]
2023-05-27 20:03:49.956: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-27 20:03:49.956: Find a better model.
2023-05-27 20:03:56.373: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.416013]
2023-05-27 20:03:56.516: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-27 20:03:56.516: Find a better model.
2023-05-27 20:04:03.148: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.629074]
2023-05-27 20:04:03.306: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-27 20:04:03.306: Find a better model.
2023-05-27 20:04:09.770: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.463004]
2023-05-27 20:04:09.928: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-27 20:04:09.928: Find a better model.
2023-05-27 20:04:16.552: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.622013]
2023-05-27 20:04:16.707: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-27 20:04:16.707: Find a better model.
2023-05-27 20:04:23.349: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.640356]
2023-05-27 20:04:23.504: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-27 20:04:23.504: Find a better model.
2023-05-27 20:04:30.177: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.672072]
2023-05-27 20:04:30.332: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-27 20:04:30.332: Find a better model.
2023-05-27 20:04:36.962: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.629140]
2023-05-27 20:04:37.116: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-27 20:04:37.116: Find a better model.
2023-05-27 20:04:43.934: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.816169]
2023-05-27 20:04:44.089: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-27 20:04:44.089: Find a better model.
2023-05-27 20:04:50.762: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.672085]
2023-05-27 20:04:50.917: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-27 20:04:50.917: Find a better model.
2023-05-27 20:04:57.367: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.449004]
2023-05-27 20:04:57.522: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-27 20:04:57.522: Find a better model.
2023-05-27 20:05:04.151: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.628041]
2023-05-27 20:05:04.305: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-27 20:05:04.305: Find a better model.
2023-05-27 20:05:10.951: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.645005]
2023-05-27 20:05:11.107: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-27 20:05:11.107: Find a better model.
2023-05-27 20:05:17.772: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.664245]
2023-05-27 20:05:17.929: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-27 20:05:17.930: Find a better model.
2023-05-27 20:05:24.522: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.591005]
2023-05-27 20:05:24.678: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-27 20:05:24.678: Find a better model.
2023-05-27 20:05:31.140: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.461012]
2023-05-27 20:05:31.295: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-27 20:05:31.295: Find a better model.
2023-05-27 20:05:37.916: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.620013]
2023-05-27 20:05:38.072: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-27 20:05:38.073: Find a better model.
2023-05-27 20:05:44.532: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.457024]
2023-05-27 20:05:44.689: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-27 20:05:44.690: Find a better model.
2023-05-27 20:05:51.141: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.449466]
2023-05-27 20:05:51.295: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-27 20:05:57.758: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.461013]
2023-05-27 20:05:57.912: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-27 20:05:57.913: Find a better model.
2023-05-27 20:06:04.337: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.423007]
2023-05-27 20:06:04.492: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-27 20:06:04.492: Find a better model.
2023-05-27 20:06:10.919: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.425994]
2023-05-27 20:06:11.072: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-27 20:06:11.072: Find a better model.
2023-05-27 20:06:17.530: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.457030]
2023-05-27 20:06:17.682: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-27 20:06:17.682: Find a better model.
2023-05-27 20:06:24.128: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.445003]
2023-05-27 20:06:24.280: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-27 20:06:24.280: Find a better model.
2023-05-27 20:06:30.893: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.612003]
2023-05-27 20:06:31.046: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-27 20:06:37.505: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.458004]
2023-05-27 20:06:37.657: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-27 20:06:37.657: Find a better model.
2023-05-27 20:06:44.139: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.480994]
2023-05-27 20:06:44.291: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-27 20:06:44.292: Find a better model.
2023-05-27 20:06:50.883: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.589024]
2023-05-27 20:06:51.036: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-27 20:06:57.686: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.649004]
2023-05-27 20:06:57.840: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-27 20:06:57.840: Find a better model.
2023-05-27 20:07:04.307: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.466029]
2023-05-27 20:07:04.463: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-27 20:07:04.463: Find a better model.
2023-05-27 20:07:10.907: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.441242]
2023-05-27 20:07:11.064: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-27 20:07:11.064: Find a better model.
2023-05-27 20:07:17.676: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.611006]
2023-05-27 20:07:17.828: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-27 20:07:17.828: Find a better model.
2023-05-27 20:07:24.331: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.501142]
2023-05-27 20:07:24.484: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-27 20:07:24.484: Find a better model.
2023-05-27 20:07:31.108: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.623006]
2023-05-27 20:07:31.260: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-27 20:07:31.260: Find a better model.
2023-05-27 20:07:37.899: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.638016]
2023-05-27 20:07:38.052: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-27 20:07:38.053: Find a better model.
2023-05-27 20:07:44.680: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.626016]
2023-05-27 20:07:44.822: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-27 20:07:44.822: Find a better model.
2023-05-27 20:07:51.292: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.469139]
2023-05-27 20:07:51.446: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-27 20:07:58.085: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.638042]
2023-05-27 20:07:58.237: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-27 20:07:58.238: Find a better model.
2023-05-27 20:08:04.887: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.647053]
2023-05-27 20:08:05.040: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-27 20:08:05.040: Find a better model.
2023-05-27 20:08:11.509: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.467517]
2023-05-27 20:08:11.662: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-27 20:08:11.662: Find a better model.
2023-05-27 20:08:18.275: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.612003]
2023-05-27 20:08:18.428: epoch 71:	0.02634132  	0.19477312  	0.10686713  
2023-05-27 20:08:18.428: Find a better model.
2023-05-27 20:08:25.078: [iter 72 : loss : 0.2189 = 0.0478 + 0.1663 + 0.0048, time: 6.649003]
2023-05-27 20:08:25.234: epoch 72:	0.02639778  	0.19526137  	0.10706930  
2023-05-27 20:08:25.234: Find a better model.
2023-05-27 20:08:31.874: [iter 73 : loss : 0.2177 = 0.0467 + 0.1661 + 0.0048, time: 6.639004]
2023-05-27 20:08:32.031: epoch 73:	0.02641189  	0.19549032  	0.10712060  
2023-05-27 20:08:32.031: Find a better model.
2023-05-27 20:08:38.680: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.648318]
2023-05-27 20:08:38.834: epoch 74:	0.02645423  	0.19565572  	0.10749721  
2023-05-27 20:08:38.834: Find a better model.
2023-05-27 20:08:45.476: [iter 75 : loss : 0.2159 = 0.0452 + 0.1658 + 0.0049, time: 6.641294]
2023-05-27 20:08:45.629: epoch 75:	0.02653890  	0.19656603  	0.10756122  
2023-05-27 20:08:45.630: Find a better model.
2023-05-27 20:08:52.274: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.642973]
2023-05-27 20:08:52.427: epoch 76:	0.02656713  	0.19688411  	0.10770557  
2023-05-27 20:08:52.427: Find a better model.
2023-05-27 20:08:59.064: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.634094]
2023-05-27 20:08:59.216: epoch 77:	0.02659536  	0.19693758  	0.10763092  
2023-05-27 20:08:59.216: Find a better model.
2023-05-27 20:09:06.045: [iter 78 : loss : 0.2134 = 0.0430 + 0.1654 + 0.0050, time: 6.827034]
2023-05-27 20:09:06.199: epoch 78:	0.02670120  	0.19770929  	0.10801657  
2023-05-27 20:09:06.199: Find a better model.
2023-05-27 20:09:12.845: [iter 79 : loss : 0.2120 = 0.0417 + 0.1652 + 0.0051, time: 6.645042]
2023-05-27 20:09:13.003: epoch 79:	0.02667298  	0.19721286  	0.10801782  
2023-05-27 20:09:19.674: [iter 80 : loss : 0.2113 = 0.0410 + 0.1651 + 0.0051, time: 6.670022]
2023-05-27 20:09:19.828: epoch 80:	0.02660947  	0.19674742  	0.10795204  
2023-05-27 20:09:26.470: [iter 81 : loss : 0.2110 = 0.0408 + 0.1649 + 0.0052, time: 6.640002]
2023-05-27 20:09:26.623: epoch 81:	0.02660946  	0.19662948  	0.10791162  
2023-05-27 20:09:33.248: [iter 82 : loss : 0.2098 = 0.0398 + 0.1648 + 0.0052, time: 6.623997]
2023-05-27 20:09:33.400: epoch 82:	0.02646834  	0.19574217  	0.10775305  
2023-05-27 20:09:40.078: [iter 83 : loss : 0.2089 = 0.0390 + 0.1647 + 0.0053, time: 6.677152]
2023-05-27 20:09:40.231: epoch 83:	0.02651773  	0.19587474  	0.10783078  
2023-05-27 20:09:46.861: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.629003]
2023-05-27 20:09:47.015: epoch 84:	0.02665886  	0.19685286  	0.10815754  
2023-05-27 20:09:53.827: [iter 85 : loss : 0.2080 = 0.0382 + 0.1645 + 0.0053, time: 6.810094]
2023-05-27 20:09:53.981: epoch 85:	0.02672943  	0.19743219  	0.10840376  
2023-05-27 20:10:00.661: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.679019]
2023-05-27 20:10:00.814: epoch 86:	0.02670827  	0.19712137  	0.10848574  
2023-05-27 20:10:07.451: [iter 87 : loss : 0.2056 = 0.0359 + 0.1642 + 0.0054, time: 6.636106]
2023-05-27 20:10:07.603: epoch 87:	0.02684939  	0.19795123  	0.10879831  
2023-05-27 20:10:07.603: Find a better model.
2023-05-27 20:10:14.241: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.637079]
2023-05-27 20:10:14.395: epoch 88:	0.02677177  	0.19745384  	0.10856124  
2023-05-27 20:10:21.058: [iter 89 : loss : 0.2044 = 0.0349 + 0.1640 + 0.0055, time: 6.662061]
2023-05-27 20:10:21.213: epoch 89:	0.02675059  	0.19729751  	0.10856724  
2023-05-27 20:10:28.043: [iter 90 : loss : 0.2048 = 0.0354 + 0.1639 + 0.0056, time: 6.828044]
2023-05-27 20:10:28.196: epoch 90:	0.02680705  	0.19757488  	0.10860566  
2023-05-27 20:10:35.008: [iter 91 : loss : 0.2039 = 0.0346 + 0.1637 + 0.0056, time: 6.811013]
2023-05-27 20:10:35.149: epoch 91:	0.02689173  	0.19790798  	0.10873196  
2023-05-27 20:10:41.840: [iter 92 : loss : 0.2027 = 0.0334 + 0.1637 + 0.0056, time: 6.690065]
2023-05-27 20:10:41.995: epoch 92:	0.02691995  	0.19840491  	0.10893800  
2023-05-27 20:10:41.995: Find a better model.
2023-05-27 20:10:48.641: [iter 93 : loss : 0.2032 = 0.0340 + 0.1635 + 0.0057, time: 6.645025]
2023-05-27 20:10:48.793: epoch 93:	0.02684939  	0.19805415  	0.10871894  
2023-05-27 20:10:55.424: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.629083]
2023-05-27 20:10:55.577: epoch 94:	0.02691289  	0.19844683  	0.10902059  
2023-05-27 20:10:55.578: Find a better model.
2023-05-27 20:11:02.222: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.643070]
2023-05-27 20:11:02.374: epoch 95:	0.02689878  	0.19834162  	0.10903258  
2023-05-27 20:11:09.047: [iter 96 : loss : 0.2008 = 0.0318 + 0.1633 + 0.0058, time: 6.669275]
2023-05-27 20:11:09.201: epoch 96:	0.02687056  	0.19800140  	0.10894188  
2023-05-27 20:11:16.011: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.809023]
2023-05-27 20:11:16.167: epoch 97:	0.02692700  	0.19829661  	0.10925259  
2023-05-27 20:11:22.828: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.659013]
2023-05-27 20:11:22.983: epoch 98:	0.02695524  	0.19876622  	0.10946140  
2023-05-27 20:11:22.983: Find a better model.
2023-05-27 20:11:29.629: [iter 99 : loss : 0.1990 = 0.0301 + 0.1630 + 0.0059, time: 6.644245]
2023-05-27 20:11:29.781: epoch 99:	0.02703991  	0.19915584  	0.10957378  
2023-05-27 20:11:29.781: Find a better model.
2023-05-27 20:11:36.425: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.643039]
2023-05-27 20:11:36.579: epoch 100:	0.02703991  	0.19906844  	0.10962223  
2023-05-27 20:11:43.211: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.630148]
2023-05-27 20:11:43.365: epoch 101:	0.02706107  	0.19923046  	0.10962985  
2023-05-27 20:11:43.366: Find a better model.
2023-05-27 20:11:50.021: [iter 102 : loss : 0.1975 = 0.0287 + 0.1627 + 0.0060, time: 6.653060]
2023-05-27 20:11:50.176: epoch 102:	0.02708930  	0.19924369  	0.10958864  
2023-05-27 20:11:50.176: Find a better model.
2023-05-27 20:11:56.803: [iter 103 : loss : 0.1973 = 0.0285 + 0.1626 + 0.0061, time: 6.625887]
2023-05-27 20:11:56.960: epoch 103:	0.02709636  	0.19972393  	0.10980638  
2023-05-27 20:11:56.960: Find a better model.
2023-05-27 20:12:03.588: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.627024]
2023-05-27 20:12:03.728: epoch 104:	0.02706813  	0.19937879  	0.10983965  
2023-05-27 20:12:10.213: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.484025]
2023-05-27 20:12:10.366: epoch 105:	0.02699757  	0.19931275  	0.10970929  
2023-05-27 20:12:17.001: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.634027]
2023-05-27 20:12:17.153: epoch 106:	0.02701873  	0.19951940  	0.10982935  
2023-05-27 20:12:23.804: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.648109]
2023-05-27 20:12:23.960: epoch 107:	0.02708930  	0.20006277  	0.11016982  
2023-05-27 20:12:23.960: Find a better model.
2023-05-27 20:12:30.597: [iter 108 : loss : 0.1954 = 0.0268 + 0.1624 + 0.0063, time: 6.636003]
2023-05-27 20:12:30.740: epoch 108:	0.02703991  	0.19990155  	0.11003801  
2023-05-27 20:12:37.415: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.674021]
2023-05-27 20:12:37.568: epoch 109:	0.02701873  	0.19974895  	0.10981499  
2023-05-27 20:12:44.182: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.613056]
2023-05-27 20:12:44.335: epoch 110:	0.02704696  	0.20017895  	0.11006186  
2023-05-27 20:12:44.335: Find a better model.
2023-05-27 20:12:50.986: [iter 111 : loss : 0.1939 = 0.0254 + 0.1621 + 0.0064, time: 6.650003]
2023-05-27 20:12:51.139: epoch 111:	0.02698345  	0.19930877  	0.10984683  
2023-05-27 20:12:57.793: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.653003]
2023-05-27 20:12:57.939: epoch 112:	0.02702579  	0.19918504  	0.10982775  
2023-05-27 20:13:04.578: [iter 113 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0065, time: 6.637878]
2023-05-27 20:13:04.730: epoch 113:	0.02704696  	0.19931798  	0.10988194  
2023-05-27 20:13:11.188: [iter 114 : loss : 0.1929 = 0.0245 + 0.1619 + 0.0065, time: 6.456012]
2023-05-27 20:13:11.343: epoch 114:	0.02711047  	0.19965076  	0.10995568  
2023-05-27 20:13:17.969: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.624013]
2023-05-27 20:13:18.126: epoch 115:	0.02706107  	0.19930254  	0.10991859  
2023-05-27 20:13:24.781: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.654003]
2023-05-27 20:13:24.939: epoch 116:	0.02702579  	0.19885574  	0.10993920  
2023-05-27 20:13:31.562: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.621014]
2023-05-27 20:13:31.716: epoch 117:	0.02699050  	0.19896430  	0.10985579  
2023-05-27 20:13:38.377: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.659104]
2023-05-27 20:13:38.530: epoch 118:	0.02699756  	0.19855820  	0.10982481  
2023-05-27 20:13:45.166: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.634037]
2023-05-27 20:13:45.320: epoch 119:	0.02703990  	0.19888829  	0.10980096  
2023-05-27 20:13:51.966: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.645011]
2023-05-27 20:13:52.122: epoch 120:	0.02701167  	0.19856207  	0.10984062  
2023-05-27 20:13:58.764: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.640003]
2023-05-27 20:13:58.921: epoch 121:	0.02701873  	0.19863996  	0.10995935  
2023-05-27 20:14:05.569: [iter 122 : loss : 0.1906 = 0.0225 + 0.1614 + 0.0068, time: 6.647040]
2023-05-27 20:14:05.721: epoch 122:	0.02695522  	0.19829205  	0.10981786  
2023-05-27 20:14:12.352: [iter 123 : loss : 0.1905 = 0.0223 + 0.1614 + 0.0068, time: 6.629003]
2023-05-27 20:14:12.504: epoch 123:	0.02695522  	0.19808462  	0.10979919  
2023-05-27 20:14:19.157: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.652012]
2023-05-27 20:14:19.311: epoch 124:	0.02699050  	0.19833179  	0.10992666  
2023-05-27 20:14:25.944: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.632012]
2023-05-27 20:14:26.084: epoch 125:	0.02701873  	0.19846451  	0.10995240  
2023-05-27 20:14:32.748: [iter 126 : loss : 0.1894 = 0.0213 + 0.1612 + 0.0069, time: 6.660993]
2023-05-27 20:14:32.901: epoch 126:	0.02694110  	0.19823478  	0.10998827  
2023-05-27 20:14:39.541: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.638051]
2023-05-27 20:14:39.683: epoch 127:	0.02688466  	0.19781706  	0.10989679  
2023-05-27 20:14:46.366: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.681064]
2023-05-27 20:14:46.520: epoch 128:	0.02696227  	0.19824573  	0.10991606  
2023-05-27 20:14:53.137: [iter 129 : loss : 0.1886 = 0.0205 + 0.1611 + 0.0070, time: 6.616385]
2023-05-27 20:14:53.295: epoch 129:	0.02696227  	0.19817300  	0.10987628  
2023-05-27 20:14:59.950: [iter 130 : loss : 0.1887 = 0.0207 + 0.1610 + 0.0070, time: 6.654013]
2023-05-27 20:15:00.106: epoch 130:	0.02687054  	0.19764791  	0.10976049  
2023-05-27 20:15:06.734: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.626994]
2023-05-27 20:15:06.888: epoch 131:	0.02695522  	0.19800641  	0.10990401  
2023-05-27 20:15:13.345: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.456069]
2023-05-27 20:15:13.498: epoch 132:	0.02691288  	0.19796647  	0.10992735  
2023-05-27 20:15:20.126: [iter 133 : loss : 0.1871 = 0.0191 + 0.1609 + 0.0071, time: 6.627393]
2023-05-27 20:15:20.279: epoch 133:	0.02696227  	0.19808911  	0.10991266  
2023-05-27 20:15:26.926: [iter 134 : loss : 0.1876 = 0.0197 + 0.1608 + 0.0071, time: 6.646037]
2023-05-27 20:15:27.079: epoch 134:	0.02691287  	0.19748987  	0.10977025  
2023-05-27 20:15:33.738: [iter 135 : loss : 0.1874 = 0.0195 + 0.1607 + 0.0072, time: 6.656994]
2023-05-27 20:15:33.892: epoch 135:	0.02690582  	0.19751948  	0.10987766  
2023-05-27 20:15:33.892: Early stopping is trigger at epoch: 135
2023-05-27 20:15:33.892: best_result@epoch 110:

2023-05-27 20:15:33.892: 		0.0270      	0.2002      	0.1101      
2023-05-28 11:02:56.037: my pid: 15388
2023-05-28 11:02:56.037: model: model.general_recommender.SGL
2023-05-28 11:02:56.037: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 11:02:56.037: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 11:02:59.672: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 11:03:07.078: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.406040]
2023-05-28 11:03:07.235: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-28 11:03:07.235: Find a better model.
2023-05-28 11:03:14.862: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.625034]
2023-05-28 11:03:15.070: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-28 11:03:15.070: Find a better model.
2023-05-28 11:03:22.429: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.356129]
2023-05-28 11:03:22.613: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-28 11:03:22.614: Find a better model.
2023-05-28 11:03:29.628: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.012061]
2023-05-28 11:03:29.789: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-28 11:03:29.789: Find a better model.
2023-05-28 11:03:36.833: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.042002]
2023-05-28 11:03:36.993: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-28 11:03:36.993: Find a better model.
2023-05-28 11:03:43.811: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 6.817004]
2023-05-28 11:03:43.955: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-28 11:03:43.955: Find a better model.
2023-05-28 11:03:50.795: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.839057]
2023-05-28 11:03:50.950: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-28 11:03:50.950: Find a better model.
2023-05-28 11:03:57.597: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.646019]
2023-05-28 11:03:57.751: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-28 11:03:57.751: Find a better model.
2023-05-28 11:04:04.396: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.644017]
2023-05-28 11:04:04.550: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-28 11:04:04.551: Find a better model.
2023-05-28 11:04:11.201: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.649040]
2023-05-28 11:04:11.355: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-28 11:04:11.355: Find a better model.
2023-05-28 11:04:18.009: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.653049]
2023-05-28 11:04:18.170: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-28 11:04:18.170: Find a better model.
2023-05-28 11:04:24.799: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.628039]
2023-05-28 11:04:24.955: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-28 11:04:24.955: Find a better model.
2023-05-28 11:04:31.411: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.454078]
2023-05-28 11:04:31.568: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-28 11:04:31.568: Find a better model.
2023-05-28 11:04:38.205: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.636088]
2023-05-28 11:04:38.362: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-28 11:04:38.362: Find a better model.
2023-05-28 11:04:44.999: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.635004]
2023-05-28 11:04:45.157: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-28 11:04:45.157: Find a better model.
2023-05-28 11:04:51.807: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.648041]
2023-05-28 11:04:51.951: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-28 11:04:51.951: Find a better model.
2023-05-28 11:04:58.578: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.625003]
2023-05-28 11:04:58.732: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-28 11:04:58.732: Find a better model.
2023-05-28 11:05:05.387: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.653938]
2023-05-28 11:05:05.543: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-28 11:05:05.543: Find a better model.
2023-05-28 11:05:12.200: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.656099]
2023-05-28 11:05:12.354: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-28 11:05:12.354: Find a better model.
2023-05-28 11:05:18.971: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.616037]
2023-05-28 11:05:19.129: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-28 11:05:19.129: Find a better model.
2023-05-28 11:05:25.586: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.454036]
2023-05-28 11:05:25.739: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-28 11:05:25.740: Find a better model.
2023-05-28 11:05:32.372: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.631039]
2023-05-28 11:05:32.527: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-28 11:05:32.528: Find a better model.
2023-05-28 11:05:39.175: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.646047]
2023-05-28 11:05:39.317: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-28 11:05:39.317: Find a better model.
2023-05-28 11:05:45.988: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.668153]
2023-05-28 11:05:46.145: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-28 11:05:46.145: Find a better model.
2023-05-28 11:05:52.779: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.632993]
2023-05-28 11:05:52.922: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-28 11:05:52.922: Find a better model.
2023-05-28 11:05:59.381: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.458099]
2023-05-28 11:05:59.523: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-28 11:05:59.523: Find a better model.
2023-05-28 11:06:05.979: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.454003]
2023-05-28 11:06:06.139: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-28 11:06:06.139: Find a better model.
2023-05-28 11:06:12.569: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.428994]
2023-05-28 11:06:12.725: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-28 11:06:12.725: Find a better model.
2023-05-28 11:06:19.349: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.623036]
2023-05-28 11:06:19.504: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-28 11:06:19.504: Find a better model.
2023-05-28 11:06:25.975: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.470053]
2023-05-28 11:06:26.135: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-28 11:06:26.135: Find a better model.
2023-05-28 11:06:32.571: [iter 31 : loss : 0.4376 = 0.1715 + 0.2641 + 0.0020, time: 6.434994]
2023-05-28 11:06:32.714: epoch 31:	0.02313064  	0.17113926  	0.08933837  
2023-05-28 11:06:32.714: Find a better model.
2023-05-28 11:06:39.146: [iter 32 : loss : 0.4271 = 0.1616 + 0.2634 + 0.0021, time: 6.431014]
2023-05-28 11:06:39.302: epoch 32:	0.02339173  	0.17321081  	0.09051806  
2023-05-28 11:06:39.302: Find a better model.
2023-05-28 11:06:45.768: [iter 33 : loss : 0.4190 = 0.1543 + 0.2625 + 0.0022, time: 6.464013]
2023-05-28 11:06:45.911: epoch 33:	0.02348345  	0.17394656  	0.09135464  
2023-05-28 11:06:45.911: Find a better model.
2023-05-28 11:06:52.357: [iter 34 : loss : 0.4108 = 0.1468 + 0.2617 + 0.0023, time: 6.445035]
2023-05-28 11:06:52.513: epoch 34:	0.02362458  	0.17503196  	0.09213932  
2023-05-28 11:06:52.513: Find a better model.
2023-05-28 11:06:58.964: [iter 35 : loss : 0.4034 = 0.1401 + 0.2609 + 0.0024, time: 6.448314]
2023-05-28 11:06:59.124: epoch 35:	0.02374454  	0.17582044  	0.09307712  
2023-05-28 11:06:59.124: Find a better model.
2023-05-28 11:07:05.750: [iter 36 : loss : 0.3969 = 0.1343 + 0.2602 + 0.0025, time: 6.625546]
2023-05-28 11:07:05.906: epoch 36:	0.02394918  	0.17751829  	0.09400745  
2023-05-28 11:07:05.906: Find a better model.
2023-05-28 11:07:12.557: [iter 37 : loss : 0.3898 = 0.1279 + 0.2594 + 0.0026, time: 6.649081]
2023-05-28 11:07:12.712: epoch 37:	0.02409736  	0.17887959  	0.09480833  
2023-05-28 11:07:12.712: Find a better model.
2023-05-28 11:07:19.345: [iter 38 : loss : 0.3854 = 0.1241 + 0.2587 + 0.0026, time: 6.631055]
2023-05-28 11:07:19.500: epoch 38:	0.02423850  	0.18015358  	0.09577529  
2023-05-28 11:07:19.500: Find a better model.
2023-05-28 11:07:26.148: [iter 39 : loss : 0.3787 = 0.1180 + 0.2580 + 0.0027, time: 6.646045]
2023-05-28 11:07:26.303: epoch 39:	0.02442196  	0.18145519  	0.09665413  
2023-05-28 11:07:26.303: Find a better model.
2023-05-28 11:07:32.934: [iter 40 : loss : 0.3734 = 0.1134 + 0.2572 + 0.0028, time: 6.630045]
2023-05-28 11:07:33.090: epoch 40:	0.02451370  	0.18158165  	0.09718434  
2023-05-28 11:07:33.090: Find a better model.
2023-05-28 11:07:39.707: [iter 41 : loss : 0.3697 = 0.1101 + 0.2567 + 0.0029, time: 6.616012]
2023-05-28 11:07:39.863: epoch 41:	0.02464778  	0.18233761  	0.09772446  
2023-05-28 11:07:39.863: Find a better model.
2023-05-28 11:07:46.509: [iter 42 : loss : 0.3651 = 0.1062 + 0.2560 + 0.0030, time: 6.645030]
2023-05-28 11:07:46.667: epoch 42:	0.02473952  	0.18298288  	0.09838484  
2023-05-28 11:07:46.667: Find a better model.
2023-05-28 11:07:53.331: [iter 43 : loss : 0.3601 = 0.1017 + 0.2554 + 0.0030, time: 6.663073]
2023-05-28 11:07:53.486: epoch 43:	0.02488770  	0.18432704  	0.09910157  
2023-05-28 11:07:53.486: Find a better model.
2023-05-28 11:08:00.351: [iter 44 : loss : 0.3556 = 0.0977 + 0.2547 + 0.0031, time: 6.864095]
2023-05-28 11:08:00.493: epoch 44:	0.02507822  	0.18588677  	0.09982639  
2023-05-28 11:08:00.494: Find a better model.
2023-05-28 11:08:07.137: [iter 45 : loss : 0.3515 = 0.0940 + 0.2543 + 0.0032, time: 6.642054]
2023-05-28 11:08:07.292: epoch 45:	0.02515584  	0.18642087  	0.10033828  
2023-05-28 11:08:07.292: Find a better model.
2023-05-28 11:08:13.936: [iter 46 : loss : 0.3483 = 0.0913 + 0.2537 + 0.0033, time: 6.643080]
2023-05-28 11:08:14.091: epoch 46:	0.02521935  	0.18701465  	0.10066313  
2023-05-28 11:08:14.091: Find a better model.
2023-05-28 11:08:20.710: [iter 47 : loss : 0.3462 = 0.0896 + 0.2532 + 0.0033, time: 6.617014]
2023-05-28 11:08:20.864: epoch 47:	0.02525463  	0.18704106  	0.10091247  
2023-05-28 11:08:20.864: Find a better model.
2023-05-28 11:08:27.543: [iter 48 : loss : 0.3417 = 0.0856 + 0.2528 + 0.0034, time: 6.678028]
2023-05-28 11:08:27.699: epoch 48:	0.02530403  	0.18767536  	0.10141196  
2023-05-28 11:08:27.699: Find a better model.
2023-05-28 11:08:34.320: [iter 49 : loss : 0.3380 = 0.0822 + 0.2523 + 0.0035, time: 6.620109]
2023-05-28 11:08:34.475: epoch 49:	0.02539576  	0.18800889  	0.10192321  
2023-05-28 11:08:34.475: Find a better model.
2023-05-28 11:08:41.130: [iter 50 : loss : 0.3358 = 0.0804 + 0.2519 + 0.0036, time: 6.653047]
2023-05-28 11:08:41.285: epoch 50:	0.02547338  	0.18860294  	0.10243494  
2023-05-28 11:08:41.286: Find a better model.
2023-05-28 11:08:47.917: [iter 51 : loss : 0.3325 = 0.0774 + 0.2515 + 0.0036, time: 6.629003]
2023-05-28 11:08:48.072: epoch 51:	0.02562157  	0.18948242  	0.10301709  
2023-05-28 11:08:48.072: Find a better model.
2023-05-28 11:08:54.709: [iter 52 : loss : 0.3312 = 0.0765 + 0.2510 + 0.0037, time: 6.636061]
2023-05-28 11:08:54.866: epoch 52:	0.02579092  	0.19067582  	0.10377309  
2023-05-28 11:08:54.866: Find a better model.
2023-05-28 11:09:01.528: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.660114]
2023-05-28 11:09:01.684: epoch 53:	0.02586148  	0.19149116  	0.10428696  
2023-05-28 11:09:01.684: Find a better model.
2023-05-28 11:09:08.307: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.621073]
2023-05-28 11:09:08.462: epoch 54:	0.02589676  	0.19195156  	0.10455631  
2023-05-28 11:09:08.462: Find a better model.
2023-05-28 11:09:15.286: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.823017]
2023-05-28 11:09:15.440: epoch 55:	0.02591793  	0.19219516  	0.10478327  
2023-05-28 11:09:15.440: Find a better model.
2023-05-28 11:09:22.097: [iter 56 : loss : 0.3210 = 0.0676 + 0.2494 + 0.0040, time: 6.656012]
2023-05-28 11:09:22.253: epoch 56:	0.02593205  	0.19196197  	0.10502896  
2023-05-28 11:09:28.923: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.669022]
2023-05-28 11:09:29.078: epoch 57:	0.02595321  	0.19218220  	0.10519829  
2023-05-28 11:09:35.681: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.601687]
2023-05-28 11:09:35.836: epoch 58:	0.02606612  	0.19308290  	0.10578318  
2023-05-28 11:09:35.836: Find a better model.
2023-05-28 11:09:42.470: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.633004]
2023-05-28 11:09:42.629: epoch 59:	0.02609434  	0.19337738  	0.10590531  
2023-05-28 11:09:42.629: Find a better model.
2023-05-28 11:09:49.299: [iter 60 : loss : 0.3135 = 0.0611 + 0.2482 + 0.0042, time: 6.669003]
2023-05-28 11:09:49.453: epoch 60:	0.02620725  	0.19395447  	0.10629762  
2023-05-28 11:09:49.453: Find a better model.
2023-05-28 11:09:56.085: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.631034]
2023-05-28 11:09:56.241: epoch 61:	0.02620725  	0.19454296  	0.10651705  
2023-05-28 11:09:56.241: Find a better model.
2023-05-28 11:10:02.897: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.653046]
2023-05-28 11:10:03.052: epoch 62:	0.02617196  	0.19414380  	0.10654917  
2023-05-28 11:10:09.706: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.653025]
2023-05-28 11:10:09.861: epoch 63:	0.02618607  	0.19401701  	0.10670833  
2023-05-28 11:10:16.486: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.624079]
2023-05-28 11:10:16.641: epoch 64:	0.02620725  	0.19436824  	0.10687846  
2023-05-28 11:10:23.273: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.631023]
2023-05-28 11:10:23.429: epoch 65:	0.02627075  	0.19462110  	0.10707077  
2023-05-28 11:10:23.429: Find a better model.
2023-05-28 11:10:30.066: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.636012]
2023-05-28 11:10:30.222: epoch 66:	0.02630604  	0.19498673  	0.10724138  
2023-05-28 11:10:30.222: Find a better model.
2023-05-28 11:10:36.881: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.657386]
2023-05-28 11:10:37.042: epoch 67:	0.02628487  	0.19462584  	0.10712864  
2023-05-28 11:10:43.668: [iter 68 : loss : 0.3017 = 0.0509 + 0.2460 + 0.0047, time: 6.624198]
2023-05-28 11:10:43.825: epoch 68:	0.02644717  	0.19577003  	0.10764769  
2023-05-28 11:10:43.825: Find a better model.
2023-05-28 11:10:50.459: [iter 69 : loss : 0.2999 = 0.0493 + 0.2459 + 0.0047, time: 6.633004]
2023-05-28 11:10:50.613: epoch 69:	0.02650362  	0.19595338  	0.10772637  
2023-05-28 11:10:50.613: Find a better model.
2023-05-28 11:10:57.278: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.664042]
2023-05-28 11:10:57.433: epoch 70:	0.02664475  	0.19702859  	0.10820810  
2023-05-28 11:10:57.433: Find a better model.
2023-05-28 11:11:04.066: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.632035]
2023-05-28 11:11:04.222: epoch 71:	0.02655301  	0.19653548  	0.10806789  
2023-05-28 11:11:10.869: [iter 72 : loss : 0.2962 = 0.0462 + 0.2452 + 0.0049, time: 6.645328]
2023-05-28 11:11:11.022: epoch 72:	0.02654596  	0.19644192  	0.10807268  
2023-05-28 11:11:17.676: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.651085]
2023-05-28 11:11:17.830: epoch 73:	0.02660946  	0.19664080  	0.10822845  
2023-05-28 11:11:24.643: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.812068]
2023-05-28 11:11:24.797: epoch 74:	0.02669414  	0.19717656  	0.10853165  
2023-05-28 11:11:24.797: Find a better model.
2023-05-28 11:11:31.460: [iter 75 : loss : 0.2930 = 0.0434 + 0.2446 + 0.0050, time: 6.661159]
2023-05-28 11:11:31.615: epoch 75:	0.02665886  	0.19714671  	0.10874516  
2023-05-28 11:11:38.285: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.669026]
2023-05-28 11:11:38.441: epoch 76:	0.02671531  	0.19737896  	0.10882153  
2023-05-28 11:11:38.441: Find a better model.
2023-05-28 11:11:45.063: [iter 77 : loss : 0.2910 = 0.0416 + 0.2442 + 0.0051, time: 6.621003]
2023-05-28 11:11:45.218: epoch 77:	0.02660946  	0.19708347  	0.10864842  
2023-05-28 11:11:52.033: [iter 78 : loss : 0.2904 = 0.0411 + 0.2441 + 0.0052, time: 6.814024]
2023-05-28 11:11:52.190: epoch 78:	0.02660946  	0.19708508  	0.10858147  
2023-05-28 11:11:59.036: [iter 79 : loss : 0.2889 = 0.0397 + 0.2439 + 0.0052, time: 6.845014]
2023-05-28 11:11:59.191: epoch 79:	0.02660946  	0.19707203  	0.10880718  
2023-05-28 11:12:06.038: [iter 80 : loss : 0.2882 = 0.0391 + 0.2437 + 0.0053, time: 6.845085]
2023-05-28 11:12:06.193: epoch 80:	0.02657419  	0.19635327  	0.10896850  
2023-05-28 11:12:13.050: [iter 81 : loss : 0.2877 = 0.0387 + 0.2436 + 0.0053, time: 6.856005]
2023-05-28 11:12:13.207: epoch 81:	0.02661652  	0.19639106  	0.10880402  
2023-05-28 11:12:19.859: [iter 82 : loss : 0.2866 = 0.0377 + 0.2435 + 0.0054, time: 6.651014]
2023-05-28 11:12:20.014: epoch 82:	0.02665180  	0.19637004  	0.10893934  
2023-05-28 11:12:26.673: [iter 83 : loss : 0.2856 = 0.0368 + 0.2433 + 0.0054, time: 6.657029]
2023-05-28 11:12:26.829: epoch 83:	0.02668708  	0.19664903  	0.10911708  
2023-05-28 11:12:33.613: [iter 84 : loss : 0.2854 = 0.0368 + 0.2432 + 0.0055, time: 6.782981]
2023-05-28 11:12:33.766: epoch 84:	0.02665886  	0.19662812  	0.10919288  
2023-05-28 11:12:40.445: [iter 85 : loss : 0.2846 = 0.0361 + 0.2430 + 0.0055, time: 6.676066]
2023-05-28 11:12:40.599: epoch 85:	0.02669414  	0.19661751  	0.10916100  
2023-05-28 11:12:47.430: [iter 86 : loss : 0.2839 = 0.0355 + 0.2428 + 0.0056, time: 6.830182]
2023-05-28 11:12:47.586: epoch 86:	0.02675764  	0.19695069  	0.10930486  
2023-05-28 11:12:54.230: [iter 87 : loss : 0.2823 = 0.0339 + 0.2428 + 0.0056, time: 6.642305]
2023-05-28 11:12:54.386: epoch 87:	0.02675059  	0.19666274  	0.10923614  
2023-05-28 11:13:01.213: [iter 88 : loss : 0.2817 = 0.0334 + 0.2426 + 0.0057, time: 6.826095]
2023-05-28 11:13:01.368: epoch 88:	0.02679293  	0.19741751  	0.10936072  
2023-05-28 11:13:01.368: Find a better model.
2023-05-28 11:13:08.235: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.866057]
2023-05-28 11:13:08.389: epoch 89:	0.02682822  	0.19762929  	0.10935978  
2023-05-28 11:13:08.390: Find a better model.
2023-05-28 11:13:15.214: [iter 90 : loss : 0.2812 = 0.0331 + 0.2424 + 0.0058, time: 6.823073]
2023-05-28 11:13:15.371: epoch 90:	0.02679293  	0.19738305  	0.10950707  
2023-05-28 11:13:22.208: [iter 91 : loss : 0.2804 = 0.0324 + 0.2422 + 0.0058, time: 6.835003]
2023-05-28 11:13:22.362: epoch 91:	0.02679999  	0.19720061  	0.10941732  
2023-05-28 11:13:29.190: [iter 92 : loss : 0.2794 = 0.0314 + 0.2421 + 0.0059, time: 6.826025]
2023-05-28 11:13:29.347: epoch 92:	0.02683527  	0.19753511  	0.10953356  
2023-05-28 11:13:36.011: [iter 93 : loss : 0.2796 = 0.0317 + 0.2420 + 0.0059, time: 6.663603]
2023-05-28 11:13:36.158: epoch 93:	0.02682116  	0.19724984  	0.10939097  
2023-05-28 11:13:42.826: [iter 94 : loss : 0.2782 = 0.0303 + 0.2419 + 0.0059, time: 6.665134]
2023-05-28 11:13:42.981: epoch 94:	0.02687761  	0.19757010  	0.10947096  
2023-05-28 11:13:49.800: [iter 95 : loss : 0.2773 = 0.0295 + 0.2418 + 0.0060, time: 6.818020]
2023-05-28 11:13:49.941: epoch 95:	0.02691995  	0.19758745  	0.10962299  
2023-05-28 11:13:56.631: [iter 96 : loss : 0.2773 = 0.0296 + 0.2417 + 0.0060, time: 6.687012]
2023-05-28 11:13:56.784: epoch 96:	0.02691289  	0.19754085  	0.10965400  
2023-05-28 11:14:03.418: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.631442]
2023-05-28 11:14:03.572: epoch 97:	0.02695522  	0.19785993  	0.10952189  
2023-05-28 11:14:03.572: Find a better model.
2023-05-28 11:14:10.384: [iter 98 : loss : 0.2762 = 0.0285 + 0.2415 + 0.0061, time: 6.811112]
2023-05-28 11:14:10.539: epoch 98:	0.02699756  	0.19835877  	0.10977393  
2023-05-28 11:14:10.539: Find a better model.
2023-05-28 11:14:17.370: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.830003]
2023-05-28 11:14:17.524: epoch 99:	0.02702579  	0.19835424  	0.10987154  
2023-05-28 11:14:24.388: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.863031]
2023-05-28 11:14:24.542: epoch 100:	0.02701873  	0.19844089  	0.11001658  
2023-05-28 11:14:24.542: Find a better model.
2023-05-28 11:14:31.199: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0062, time: 6.655068]
2023-05-28 11:14:31.353: epoch 101:	0.02694817  	0.19787431  	0.10994638  
2023-05-28 11:14:38.198: [iter 102 : loss : 0.2740 = 0.0266 + 0.2411 + 0.0063, time: 6.844075]
2023-05-28 11:14:38.353: epoch 102:	0.02696933  	0.19794868  	0.11000299  
2023-05-28 11:14:45.183: [iter 103 : loss : 0.2738 = 0.0264 + 0.2410 + 0.0063, time: 6.829181]
2023-05-28 11:14:45.342: epoch 103:	0.02689172  	0.19761351  	0.10999522  
2023-05-28 11:14:52.193: [iter 104 : loss : 0.2739 = 0.0265 + 0.2410 + 0.0064, time: 6.849993]
2023-05-28 11:14:52.347: epoch 104:	0.02694817  	0.19784074  	0.11003777  
2023-05-28 11:14:59.192: [iter 105 : loss : 0.2734 = 0.0261 + 0.2409 + 0.0064, time: 6.844012]
2023-05-28 11:14:59.347: epoch 105:	0.02691994  	0.19774930  	0.11001427  
2023-05-28 11:15:06.163: [iter 106 : loss : 0.2728 = 0.0256 + 0.2408 + 0.0064, time: 6.815013]
2023-05-28 11:15:06.319: epoch 106:	0.02692700  	0.19784236  	0.11000141  
2023-05-28 11:15:13.179: [iter 107 : loss : 0.2722 = 0.0250 + 0.2407 + 0.0065, time: 6.859003]
2023-05-28 11:15:13.336: epoch 107:	0.02698345  	0.19825409  	0.11025528  
2023-05-28 11:15:20.198: [iter 108 : loss : 0.2718 = 0.0246 + 0.2407 + 0.0065, time: 6.861046]
2023-05-28 11:15:20.352: epoch 108:	0.02694111  	0.19815816  	0.11014650  
2023-05-28 11:15:27.204: [iter 109 : loss : 0.2710 = 0.0239 + 0.2405 + 0.0066, time: 6.851054]
2023-05-28 11:15:27.360: epoch 109:	0.02700461  	0.19853191  	0.11031403  
2023-05-28 11:15:27.360: Find a better model.
2023-05-28 11:15:34.171: [iter 110 : loss : 0.2708 = 0.0236 + 0.2405 + 0.0066, time: 6.810050]
2023-05-28 11:15:34.327: epoch 110:	0.02691288  	0.19803445  	0.11024196  
2023-05-28 11:15:41.155: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.827073]
2023-05-28 11:15:41.308: epoch 111:	0.02694817  	0.19833553  	0.11029203  
2023-05-28 11:15:48.175: [iter 112 : loss : 0.2702 = 0.0231 + 0.2404 + 0.0067, time: 6.866046]
2023-05-28 11:15:48.331: epoch 112:	0.02687761  	0.19771479  	0.11007229  
2023-05-28 11:15:55.345: [iter 113 : loss : 0.2701 = 0.0232 + 0.2403 + 0.0067, time: 7.012985]
2023-05-28 11:15:55.498: epoch 113:	0.02687055  	0.19745076  	0.10997290  
2023-05-28 11:16:02.361: [iter 114 : loss : 0.2694 = 0.0225 + 0.2402 + 0.0068, time: 6.860022]
2023-05-28 11:16:02.516: epoch 114:	0.02689877  	0.19763468  	0.11002050  
2023-05-28 11:16:09.383: [iter 115 : loss : 0.2692 = 0.0223 + 0.2401 + 0.0068, time: 6.866024]
2023-05-28 11:16:09.536: epoch 115:	0.02691994  	0.19783594  	0.11008230  
2023-05-28 11:16:16.351: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.814306]
2023-05-28 11:16:16.506: epoch 116:	0.02683526  	0.19692279  	0.10981438  
2023-05-28 11:16:23.378: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.869761]
2023-05-28 11:16:23.533: epoch 117:	0.02678587  	0.19632584  	0.10968410  
2023-05-28 11:16:30.339: [iter 118 : loss : 0.2683 = 0.0215 + 0.2399 + 0.0069, time: 6.804041]
2023-05-28 11:16:30.492: epoch 118:	0.02672941  	0.19597539  	0.10962798  
2023-05-28 11:16:37.368: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.874038]
2023-05-28 11:16:37.523: epoch 119:	0.02681409  	0.19662455  	0.10983584  
2023-05-28 11:16:44.341: [iter 120 : loss : 0.2678 = 0.0211 + 0.2398 + 0.0070, time: 6.816046]
2023-05-28 11:16:44.496: epoch 120:	0.02682820  	0.19628406  	0.10975915  
2023-05-28 11:16:51.349: [iter 121 : loss : 0.2677 = 0.0209 + 0.2397 + 0.0070, time: 6.850994]
2023-05-28 11:16:51.505: epoch 121:	0.02680703  	0.19603479  	0.10964748  
2023-05-28 11:16:58.370: [iter 122 : loss : 0.2672 = 0.0205 + 0.2397 + 0.0070, time: 6.863024]
2023-05-28 11:16:58.524: epoch 122:	0.02676470  	0.19568099  	0.10964517  
2023-05-28 11:17:05.350: [iter 123 : loss : 0.2670 = 0.0204 + 0.2396 + 0.0071, time: 6.824057]
2023-05-28 11:17:05.503: epoch 123:	0.02676470  	0.19575164  	0.10964435  
2023-05-28 11:17:12.341: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.837104]
2023-05-28 11:17:12.495: epoch 124:	0.02673647  	0.19558047  	0.10968914  
2023-05-28 11:17:19.336: [iter 125 : loss : 0.2660 = 0.0193 + 0.2395 + 0.0071, time: 6.838148]
2023-05-28 11:17:19.480: epoch 125:	0.02675764  	0.19563136  	0.10970610  
2023-05-28 11:17:26.340: [iter 126 : loss : 0.2661 = 0.0195 + 0.2394 + 0.0072, time: 6.858994]
2023-05-28 11:17:26.494: epoch 126:	0.02675764  	0.19561198  	0.10966383  
2023-05-28 11:17:33.345: [iter 127 : loss : 0.2653 = 0.0186 + 0.2394 + 0.0072, time: 6.848312]
2023-05-28 11:17:33.497: epoch 127:	0.02679292  	0.19630745  	0.10979590  
2023-05-28 11:17:40.329: [iter 128 : loss : 0.2658 = 0.0192 + 0.2393 + 0.0073, time: 6.830059]
2023-05-28 11:17:40.482: epoch 128:	0.02681408  	0.19603711  	0.10971346  
2023-05-28 11:17:47.327: [iter 129 : loss : 0.2653 = 0.0186 + 0.2393 + 0.0073, time: 6.844519]
2023-05-28 11:17:47.481: epoch 129:	0.02674352  	0.19555238  	0.10939941  
2023-05-28 11:17:54.342: [iter 130 : loss : 0.2654 = 0.0188 + 0.2392 + 0.0073, time: 6.859021]
2023-05-28 11:17:54.495: epoch 130:	0.02675764  	0.19550906  	0.10939965  
2023-05-28 11:18:01.321: [iter 131 : loss : 0.2647 = 0.0181 + 0.2392 + 0.0073, time: 6.824062]
2023-05-28 11:18:01.474: epoch 131:	0.02668002  	0.19479863  	0.10938501  
2023-05-28 11:18:08.308: [iter 132 : loss : 0.2646 = 0.0181 + 0.2391 + 0.0074, time: 6.833090]
2023-05-28 11:18:08.462: epoch 132:	0.02659534  	0.19417512  	0.10917594  
2023-05-28 11:18:15.325: [iter 133 : loss : 0.2639 = 0.0174 + 0.2391 + 0.0074, time: 6.862036]
2023-05-28 11:18:15.480: epoch 133:	0.02661650  	0.19433534  	0.10914472  
2023-05-28 11:18:22.318: [iter 134 : loss : 0.2643 = 0.0178 + 0.2390 + 0.0074, time: 6.837038]
2023-05-28 11:18:22.461: epoch 134:	0.02660239  	0.19402958  	0.10919819  
2023-05-28 11:18:22.461: Early stopping is trigger at epoch: 134
2023-05-28 11:18:22.461: best_result@epoch 109:

2023-05-28 11:18:22.461: 		0.0270      	0.1985      	0.1103      
2023-05-28 14:20:25.764: my pid: 9680
2023-05-28 14:20:25.764: model: model.general_recommender.SGL
2023-05-28 14:20:25.764: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 14:20:25.764: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 14:20:29.366: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 14:20:36.814: [iter 1 : loss : 1.0070 = 0.6930 + 0.3140 + 0.0000, time: 7.448055]
2023-05-28 14:20:36.970: epoch 1:	0.00148180  	0.01007288  	0.00518638  
2023-05-28 14:20:36.970: Find a better model.
2023-05-28 14:20:44.426: [iter 2 : loss : 1.0056 = 0.6929 + 0.3127 + 0.0000, time: 7.453175]
2023-05-28 14:20:44.605: epoch 2:	0.00215214  	0.01506323  	0.00759623  
2023-05-28 14:20:44.606: Find a better model.
2023-05-28 14:20:52.019: [iter 3 : loss : 1.0053 = 0.6928 + 0.3125 + 0.0000, time: 7.412039]
2023-05-28 14:20:52.196: epoch 3:	0.00323877  	0.02255323  	0.01167415  
2023-05-28 14:20:52.196: Find a better model.
2023-05-28 14:20:59.369: [iter 4 : loss : 1.0051 = 0.6927 + 0.3124 + 0.0000, time: 7.172007]
2023-05-28 14:20:59.530: epoch 4:	0.00409961  	0.02849601  	0.01466823  
2023-05-28 14:20:59.530: Find a better model.
2023-05-28 14:21:06.616: [iter 5 : loss : 1.0049 = 0.6925 + 0.3124 + 0.0000, time: 7.084040]
2023-05-28 14:21:06.768: epoch 5:	0.00508747  	0.03545045  	0.01763683  
2023-05-28 14:21:06.768: Find a better model.
2023-05-28 14:21:13.780: [iter 6 : loss : 1.0049 = 0.6923 + 0.3125 + 0.0000, time: 7.010197]
2023-05-28 14:21:13.934: epoch 6:	0.00594831  	0.04169608  	0.02087439  
2023-05-28 14:21:13.934: Find a better model.
2023-05-28 14:21:20.780: [iter 7 : loss : 1.0045 = 0.6920 + 0.3124 + 0.0000, time: 6.845098]
2023-05-28 14:21:20.932: epoch 7:	0.00666097  	0.04731534  	0.02407812  
2023-05-28 14:21:20.932: Find a better model.
2023-05-28 14:21:27.748: [iter 8 : loss : 1.0043 = 0.6918 + 0.3126 + 0.0000, time: 6.815035]
2023-05-28 14:21:27.900: epoch 8:	0.00738069  	0.05191480  	0.02677541  
2023-05-28 14:21:27.900: Find a better model.
2023-05-28 14:21:34.565: [iter 9 : loss : 1.0040 = 0.6913 + 0.3127 + 0.0000, time: 6.664038]
2023-05-28 14:21:34.717: epoch 9:	0.00829798  	0.05921273  	0.03056381  
2023-05-28 14:21:34.717: Find a better model.
2023-05-28 14:21:41.153: [iter 10 : loss : 1.0036 = 0.6908 + 0.3128 + 0.0000, time: 6.435026]
2023-05-28 14:21:41.294: epoch 10:	0.00963162  	0.06750149  	0.03438413  
2023-05-28 14:21:41.295: Find a better model.
2023-05-28 14:21:47.771: [iter 11 : loss : 1.0030 = 0.6901 + 0.3129 + 0.0000, time: 6.474447]
2023-05-28 14:21:47.925: epoch 11:	0.01059835  	0.07446928  	0.03832243  
2023-05-28 14:21:47.925: Find a better model.
2023-05-28 14:21:54.529: [iter 12 : loss : 1.0022 = 0.6891 + 0.3130 + 0.0000, time: 6.602130]
2023-05-28 14:21:54.682: epoch 12:	0.01136046  	0.08116855  	0.04098159  
2023-05-28 14:21:54.683: Find a better model.
2023-05-28 14:22:01.150: [iter 13 : loss : 1.0010 = 0.6878 + 0.3132 + 0.0000, time: 6.466138]
2023-05-28 14:22:01.303: epoch 13:	0.01239775  	0.08946972  	0.04417939  
2023-05-28 14:22:01.303: Find a better model.
2023-05-28 14:22:07.742: [iter 14 : loss : 0.9993 = 0.6858 + 0.3134 + 0.0000, time: 6.438207]
2023-05-28 14:22:07.895: epoch 14:	0.01337860  	0.09696855  	0.04757192  
2023-05-28 14:22:07.895: Find a better model.
2023-05-28 14:22:14.531: [iter 15 : loss : 0.9967 = 0.6830 + 0.3137 + 0.0000, time: 6.635038]
2023-05-28 14:22:14.684: epoch 15:	0.01452174  	0.10474711  	0.05135924  
2023-05-28 14:22:14.684: Find a better model.
2023-05-28 14:22:21.350: [iter 16 : loss : 0.9927 = 0.6785 + 0.3141 + 0.0000, time: 6.665094]
2023-05-28 14:22:21.508: epoch 16:	0.01546730  	0.11179481  	0.05466865  
2023-05-28 14:22:21.508: Find a better model.
2023-05-28 14:22:27.949: [iter 17 : loss : 0.9865 = 0.6718 + 0.3147 + 0.0001, time: 6.439950]
2023-05-28 14:22:28.101: epoch 17:	0.01671629  	0.12208136  	0.05999736  
2023-05-28 14:22:28.101: Find a better model.
2023-05-28 14:22:34.577: [iter 18 : loss : 0.9772 = 0.6616 + 0.3155 + 0.0001, time: 6.475024]
2023-05-28 14:22:34.730: epoch 18:	0.01781003  	0.13029225  	0.06439240  
2023-05-28 14:22:34.730: Find a better model.
2023-05-28 14:22:41.299: [iter 19 : loss : 0.9631 = 0.6460 + 0.3169 + 0.0001, time: 6.568013]
2023-05-28 14:22:41.444: epoch 19:	0.01876969  	0.13692948  	0.06849489  
2023-05-28 14:22:41.444: Find a better model.
2023-05-28 14:22:47.729: [iter 20 : loss : 0.9430 = 0.6239 + 0.3190 + 0.0002, time: 6.284243]
2023-05-28 14:22:47.882: epoch 20:	0.01959530  	0.14298858  	0.07248525  
2023-05-28 14:22:47.882: Find a better model.
2023-05-28 14:22:54.320: [iter 21 : loss : 0.9149 = 0.5928 + 0.3219 + 0.0002, time: 6.435099]
2023-05-28 14:22:54.464: epoch 21:	0.02002576  	0.14709623  	0.07509179  
2023-05-28 14:22:54.464: Find a better model.
2023-05-28 14:23:00.917: [iter 22 : loss : 0.8791 = 0.5533 + 0.3255 + 0.0003, time: 6.451199]
2023-05-28 14:23:01.073: epoch 22:	0.02035036  	0.14914866  	0.07656167  
2023-05-28 14:23:01.073: Find a better model.
2023-05-28 14:23:07.517: [iter 23 : loss : 0.8370 = 0.5066 + 0.3299 + 0.0005, time: 6.443122]
2023-05-28 14:23:07.670: epoch 23:	0.02071024  	0.15207280  	0.07861388  
2023-05-28 14:23:07.670: Find a better model.
2023-05-28 14:23:14.126: [iter 24 : loss : 0.7915 = 0.4567 + 0.3343 + 0.0006, time: 6.455028]
2023-05-28 14:23:14.269: epoch 24:	0.02112658  	0.15577087  	0.08042523  
2023-05-28 14:23:14.269: Find a better model.
2023-05-28 14:23:20.693: [iter 25 : loss : 0.7469 = 0.4081 + 0.3381 + 0.0007, time: 6.423013]
2023-05-28 14:23:20.837: epoch 25:	0.02139472  	0.15815508  	0.08172884  
2023-05-28 14:23:20.837: Find a better model.
2023-05-28 14:23:27.320: [iter 26 : loss : 0.7068 = 0.3648 + 0.3411 + 0.0009, time: 6.479994]
2023-05-28 14:23:27.476: epoch 26:	0.02162759  	0.15912354  	0.08272821  
2023-05-28 14:23:27.476: Find a better model.
2023-05-28 14:23:33.924: [iter 27 : loss : 0.6704 = 0.3262 + 0.3432 + 0.0010, time: 6.446569]
2023-05-28 14:23:34.078: epoch 27:	0.02183224  	0.16129296  	0.08379698  
2023-05-28 14:23:34.078: Find a better model.
2023-05-28 14:23:40.698: [iter 28 : loss : 0.6398 = 0.2941 + 0.3445 + 0.0012, time: 6.619044]
2023-05-28 14:23:40.853: epoch 28:	0.02202982  	0.16227755  	0.08456451  
2023-05-28 14:23:40.853: Find a better model.
2023-05-28 14:23:47.319: [iter 29 : loss : 0.6146 = 0.2682 + 0.3451 + 0.0013, time: 6.465008]
2023-05-28 14:23:47.477: epoch 29:	0.02222740  	0.16435389  	0.08586542  
2023-05-28 14:23:47.477: Find a better model.
2023-05-28 14:23:53.932: [iter 30 : loss : 0.5914 = 0.2445 + 0.3454 + 0.0014, time: 6.453698]
2023-05-28 14:23:54.087: epoch 30:	0.02251671  	0.16634847  	0.08708978  
2023-05-28 14:23:54.087: Find a better model.
2023-05-28 14:24:00.711: [iter 31 : loss : 0.5726 = 0.2259 + 0.3451 + 0.0016, time: 6.623007]
2023-05-28 14:24:00.853: epoch 31:	0.02273547  	0.16816933  	0.08820927  
2023-05-28 14:24:00.853: Find a better model.
2023-05-28 14:24:07.320: [iter 32 : loss : 0.5557 = 0.2092 + 0.3448 + 0.0017, time: 6.466103]
2023-05-28 14:24:07.476: epoch 32:	0.02301773  	0.17058854  	0.08936694  
2023-05-28 14:24:07.476: Find a better model.
2023-05-28 14:24:13.916: [iter 33 : loss : 0.5418 = 0.1958 + 0.3441 + 0.0018, time: 6.439069]
2023-05-28 14:24:14.072: epoch 33:	0.02325766  	0.17228720  	0.09050984  
2023-05-28 14:24:14.072: Find a better model.
2023-05-28 14:24:20.700: [iter 34 : loss : 0.5289 = 0.1836 + 0.3434 + 0.0019, time: 6.627008]
2023-05-28 14:24:20.868: epoch 34:	0.02351168  	0.17402668  	0.09165509  
2023-05-28 14:24:20.868: Find a better model.
2023-05-28 14:24:27.307: [iter 35 : loss : 0.5173 = 0.1726 + 0.3426 + 0.0020, time: 6.438101]
2023-05-28 14:24:27.465: epoch 35:	0.02361048  	0.17472023  	0.09246583  
2023-05-28 14:24:27.465: Find a better model.
2023-05-28 14:24:33.905: [iter 36 : loss : 0.5073 = 0.1632 + 0.3419 + 0.0021, time: 6.439046]
2023-05-28 14:24:34.059: epoch 36:	0.02378688  	0.17620981  	0.09341335  
2023-05-28 14:24:34.059: Find a better model.
2023-05-28 14:24:40.677: [iter 37 : loss : 0.4971 = 0.1538 + 0.3410 + 0.0023, time: 6.617094]
2023-05-28 14:24:40.833: epoch 37:	0.02397740  	0.17784250  	0.09445093  
2023-05-28 14:24:40.833: Find a better model.
2023-05-28 14:24:47.301: [iter 38 : loss : 0.4900 = 0.1473 + 0.3402 + 0.0024, time: 6.466014]
2023-05-28 14:24:47.458: epoch 38:	0.02416087  	0.17913727  	0.09532082  
2023-05-28 14:24:47.458: Find a better model.
2023-05-28 14:24:53.898: [iter 39 : loss : 0.4809 = 0.1390 + 0.3394 + 0.0025, time: 6.438003]
2023-05-28 14:24:54.052: epoch 39:	0.02430200  	0.18023491  	0.09610991  
2023-05-28 14:24:54.052: Find a better model.
2023-05-28 14:25:00.683: [iter 40 : loss : 0.4736 = 0.1325 + 0.3385 + 0.0025, time: 6.630026]
2023-05-28 14:25:00.824: epoch 40:	0.02445725  	0.18119749  	0.09695539  
2023-05-28 14:25:00.824: Find a better model.
2023-05-28 14:25:07.294: [iter 41 : loss : 0.4680 = 0.1275 + 0.3379 + 0.0026, time: 6.469205]
2023-05-28 14:25:07.452: epoch 41:	0.02465483  	0.18251188  	0.09764455  
2023-05-28 14:25:07.452: Find a better model.
2023-05-28 14:25:14.061: [iter 42 : loss : 0.4616 = 0.1219 + 0.3370 + 0.0027, time: 6.608013]
2023-05-28 14:25:14.215: epoch 42:	0.02472540  	0.18241698  	0.09809777  
2023-05-28 14:25:20.691: [iter 43 : loss : 0.4552 = 0.1161 + 0.3363 + 0.0028, time: 6.474003]
2023-05-28 14:25:20.845: epoch 43:	0.02494415  	0.18405953  	0.09889601  
2023-05-28 14:25:20.845: Find a better model.
2023-05-28 14:25:27.483: [iter 44 : loss : 0.4494 = 0.1111 + 0.3355 + 0.0029, time: 6.636993]
2023-05-28 14:25:27.635: epoch 44:	0.02504999  	0.18522117  	0.09964625  
2023-05-28 14:25:27.636: Find a better model.
2023-05-28 14:25:34.267: [iter 45 : loss : 0.4442 = 0.1062 + 0.3350 + 0.0030, time: 6.630041]
2023-05-28 14:25:34.422: epoch 45:	0.02523346  	0.18638903  	0.10026917  
2023-05-28 14:25:34.422: Find a better model.
2023-05-28 14:25:40.864: [iter 46 : loss : 0.4399 = 0.1025 + 0.3343 + 0.0031, time: 6.441061]
2023-05-28 14:25:41.019: epoch 46:	0.02535342  	0.18741462  	0.10098146  
2023-05-28 14:25:41.019: Find a better model.
2023-05-28 14:25:47.646: [iter 47 : loss : 0.4366 = 0.0998 + 0.3336 + 0.0032, time: 6.625009]
2023-05-28 14:25:47.799: epoch 47:	0.02531814  	0.18720473  	0.10125151  
2023-05-28 14:25:54.270: [iter 48 : loss : 0.4313 = 0.0950 + 0.3331 + 0.0032, time: 6.470008]
2023-05-28 14:25:54.426: epoch 48:	0.02544516  	0.18822250  	0.10185024  
2023-05-28 14:25:54.427: Find a better model.
2023-05-28 14:26:01.041: [iter 49 : loss : 0.4268 = 0.0910 + 0.3325 + 0.0033, time: 6.611160]
2023-05-28 14:26:01.183: epoch 49:	0.02559335  	0.18903971  	0.10247834  
2023-05-28 14:26:01.183: Find a better model.
2023-05-28 14:26:07.687: [iter 50 : loss : 0.4238 = 0.0885 + 0.3320 + 0.0034, time: 6.503085]
2023-05-28 14:26:07.842: epoch 50:	0.02566390  	0.18951471  	0.10286330  
2023-05-28 14:26:07.842: Find a better model.
2023-05-28 14:26:14.446: [iter 51 : loss : 0.4198 = 0.0848 + 0.3315 + 0.0035, time: 6.603012]
2023-05-28 14:26:14.601: epoch 51:	0.02578386  	0.19060752  	0.10342834  
2023-05-28 14:26:14.601: Find a better model.
2023-05-28 14:26:21.258: [iter 52 : loss : 0.4178 = 0.0833 + 0.3309 + 0.0036, time: 6.656078]
2023-05-28 14:26:21.400: epoch 52:	0.02590382  	0.19155687  	0.10399558  
2023-05-28 14:26:21.401: Find a better model.
2023-05-28 14:26:27.865: [iter 53 : loss : 0.4143 = 0.0803 + 0.3305 + 0.0036, time: 6.463129]
2023-05-28 14:26:28.020: epoch 53:	0.02587559  	0.19127105  	0.10417134  
2023-05-28 14:26:34.634: [iter 54 : loss : 0.4111 = 0.0775 + 0.3299 + 0.0037, time: 6.613060]
2023-05-28 14:26:34.776: epoch 54:	0.02594616  	0.19159524  	0.10435758  
2023-05-28 14:26:34.776: Find a better model.
2023-05-28 14:26:41.250: [iter 55 : loss : 0.4087 = 0.0753 + 0.3296 + 0.0038, time: 6.473008]
2023-05-28 14:26:41.404: epoch 55:	0.02602378  	0.19233549  	0.10473789  
2023-05-28 14:26:41.404: Find a better model.
2023-05-28 14:26:47.839: [iter 56 : loss : 0.4055 = 0.0726 + 0.3290 + 0.0038, time: 6.431597]
2023-05-28 14:26:47.993: epoch 56:	0.02608729  	0.19295378  	0.10496452  
2023-05-28 14:26:47.993: Find a better model.
2023-05-28 14:26:54.643: [iter 57 : loss : 0.4030 = 0.0703 + 0.3288 + 0.0039, time: 6.648003]
2023-05-28 14:26:54.795: epoch 57:	0.02606612  	0.19302586  	0.10518946  
2023-05-28 14:26:54.805: Find a better model.
2023-05-28 14:27:01.440: [iter 58 : loss : 0.4005 = 0.0682 + 0.3283 + 0.0040, time: 6.634187]
2023-05-28 14:27:01.596: epoch 58:	0.02605906  	0.19283541  	0.10544541  
2023-05-28 14:27:08.235: [iter 59 : loss : 0.3986 = 0.0668 + 0.3278 + 0.0040, time: 6.638007]
2023-05-28 14:27:08.389: epoch 59:	0.02612257  	0.19311804  	0.10581274  
2023-05-28 14:27:08.390: Find a better model.
2023-05-28 14:27:14.849: [iter 60 : loss : 0.3965 = 0.0648 + 0.3276 + 0.0041, time: 6.457097]
2023-05-28 14:27:15.002: epoch 60:	0.02619314  	0.19354142  	0.10599627  
2023-05-28 14:27:15.002: Find a better model.
2023-05-28 14:27:21.640: [iter 61 : loss : 0.3945 = 0.0631 + 0.3272 + 0.0042, time: 6.637040]
2023-05-28 14:27:21.782: epoch 61:	0.02619314  	0.19366035  	0.10615892  
2023-05-28 14:27:21.782: Find a better model.
2023-05-28 14:27:28.434: [iter 62 : loss : 0.3924 = 0.0613 + 0.3269 + 0.0042, time: 6.651117]
2023-05-28 14:27:28.590: epoch 62:	0.02619314  	0.19376324  	0.10627453  
2023-05-28 14:27:28.590: Find a better model.
2023-05-28 14:27:35.222: [iter 63 : loss : 0.3906 = 0.0597 + 0.3265 + 0.0043, time: 6.630993]
2023-05-28 14:27:35.365: epoch 63:	0.02630604  	0.19445267  	0.10674449  
2023-05-28 14:27:35.365: Find a better model.
2023-05-28 14:27:41.831: [iter 64 : loss : 0.3888 = 0.0583 + 0.3262 + 0.0044, time: 6.463994]
2023-05-28 14:27:41.973: epoch 64:	0.02633427  	0.19449477  	0.10683773  
2023-05-28 14:27:41.973: Find a better model.
2023-05-28 14:27:48.605: [iter 65 : loss : 0.3872 = 0.0569 + 0.3259 + 0.0044, time: 6.631085]
2023-05-28 14:27:48.762: epoch 65:	0.02639071  	0.19482753  	0.10702604  
2023-05-28 14:27:48.762: Find a better model.
2023-05-28 14:27:55.408: [iter 66 : loss : 0.3852 = 0.0551 + 0.3256 + 0.0045, time: 6.645038]
2023-05-28 14:27:55.566: epoch 66:	0.02641894  	0.19526856  	0.10740890  
2023-05-28 14:27:55.566: Find a better model.
2023-05-28 14:28:02.196: [iter 67 : loss : 0.3835 = 0.0536 + 0.3253 + 0.0046, time: 6.628462]
2023-05-28 14:28:02.350: epoch 67:	0.02646833  	0.19560318  	0.10762072  
2023-05-28 14:28:02.350: Find a better model.
2023-05-28 14:28:08.833: [iter 68 : loss : 0.3825 = 0.0528 + 0.3250 + 0.0046, time: 6.482047]
2023-05-28 14:28:08.987: epoch 68:	0.02653184  	0.19578533  	0.10800016  
2023-05-28 14:28:08.987: Find a better model.
2023-05-28 14:28:15.607: [iter 69 : loss : 0.3806 = 0.0511 + 0.3248 + 0.0047, time: 6.619015]
2023-05-28 14:28:15.761: epoch 69:	0.02651772  	0.19560575  	0.10797007  
2023-05-28 14:28:22.431: [iter 70 : loss : 0.3789 = 0.0496 + 0.3246 + 0.0047, time: 6.669099]
2023-05-28 14:28:22.586: epoch 70:	0.02654595  	0.19614500  	0.10813651  
2023-05-28 14:28:22.586: Find a better model.
2023-05-28 14:28:29.218: [iter 71 : loss : 0.3776 = 0.0485 + 0.3243 + 0.0048, time: 6.631052]
2023-05-28 14:28:29.372: epoch 71:	0.02652478  	0.19577664  	0.10802325  
2023-05-28 14:28:36.012: [iter 72 : loss : 0.3764 = 0.0475 + 0.3240 + 0.0049, time: 6.638005]
2023-05-28 14:28:36.166: epoch 72:	0.02653890  	0.19588840  	0.10818246  
2023-05-28 14:28:42.807: [iter 73 : loss : 0.3749 = 0.0462 + 0.3238 + 0.0049, time: 6.640132]
2023-05-28 14:28:42.964: epoch 73:	0.02654595  	0.19609106  	0.10841785  
2023-05-28 14:28:49.590: [iter 74 : loss : 0.3738 = 0.0452 + 0.3236 + 0.0050, time: 6.625113]
2023-05-28 14:28:49.743: epoch 74:	0.02663063  	0.19633716  	0.10857491  
2023-05-28 14:28:49.743: Find a better model.
2023-05-28 14:28:56.405: [iter 75 : loss : 0.3728 = 0.0444 + 0.3234 + 0.0050, time: 6.660014]
2023-05-28 14:28:56.562: epoch 75:	0.02658829  	0.19593941  	0.10873320  
2023-05-28 14:29:03.187: [iter 76 : loss : 0.3718 = 0.0436 + 0.3231 + 0.0051, time: 6.624043]
2023-05-28 14:29:03.344: epoch 76:	0.02659535  	0.19590797  	0.10874274  
2023-05-28 14:29:09.798: [iter 77 : loss : 0.3705 = 0.0425 + 0.3229 + 0.0051, time: 6.452994]
2023-05-28 14:29:09.951: epoch 77:	0.02663063  	0.19613399  	0.10880592  
2023-05-28 14:29:16.600: [iter 78 : loss : 0.3699 = 0.0419 + 0.3228 + 0.0052, time: 6.646115]
2023-05-28 14:29:16.756: epoch 78:	0.02661652  	0.19584185  	0.10890732  
2023-05-28 14:29:23.385: [iter 79 : loss : 0.3683 = 0.0404 + 0.3226 + 0.0053, time: 6.627012]
2023-05-28 14:29:23.541: epoch 79:	0.02665180  	0.19595797  	0.10915917  
2023-05-28 14:29:30.178: [iter 80 : loss : 0.3675 = 0.0398 + 0.3224 + 0.0053, time: 6.636001]
2023-05-28 14:29:30.334: epoch 80:	0.02662358  	0.19586986  	0.10895410  
2023-05-28 14:29:36.975: [iter 81 : loss : 0.3668 = 0.0392 + 0.3222 + 0.0054, time: 6.640014]
2023-05-28 14:29:37.130: epoch 81:	0.02669414  	0.19631809  	0.10924674  
2023-05-28 14:29:43.764: [iter 82 : loss : 0.3657 = 0.0382 + 0.3221 + 0.0054, time: 6.632087]
2023-05-28 14:29:43.920: epoch 82:	0.02673648  	0.19640693  	0.10931000  
2023-05-28 14:29:43.920: Find a better model.
2023-05-28 14:29:50.600: [iter 83 : loss : 0.3645 = 0.0371 + 0.3219 + 0.0055, time: 6.679005]
2023-05-28 14:29:50.754: epoch 83:	0.02679293  	0.19682579  	0.10959120  
2023-05-28 14:29:50.754: Find a better model.
2023-05-28 14:29:57.374: [iter 84 : loss : 0.3644 = 0.0371 + 0.3218 + 0.0055, time: 6.619327]
2023-05-28 14:29:57.532: epoch 84:	0.02670826  	0.19612382  	0.10931811  
2023-05-28 14:30:04.155: [iter 85 : loss : 0.3635 = 0.0363 + 0.3216 + 0.0056, time: 6.621029]
2023-05-28 14:30:04.310: epoch 85:	0.02665180  	0.19560629  	0.10908754  
2023-05-28 14:30:10.779: [iter 86 : loss : 0.3626 = 0.0356 + 0.3214 + 0.0056, time: 6.468038]
2023-05-28 14:30:10.935: epoch 86:	0.02664474  	0.19538212  	0.10904016  
2023-05-28 14:30:17.561: [iter 87 : loss : 0.3612 = 0.0342 + 0.3213 + 0.0057, time: 6.624122]
2023-05-28 14:30:17.717: epoch 87:	0.02673648  	0.19613203  	0.10931382  
2023-05-28 14:30:24.360: [iter 88 : loss : 0.3604 = 0.0335 + 0.3212 + 0.0057, time: 6.640999]
2023-05-28 14:30:24.516: epoch 88:	0.02665180  	0.19566411  	0.10920058  
2023-05-28 14:30:31.177: [iter 89 : loss : 0.3596 = 0.0328 + 0.3210 + 0.0058, time: 6.660034]
2023-05-28 14:30:31.320: epoch 89:	0.02663063  	0.19514926  	0.10909789  
2023-05-28 14:30:37.955: [iter 90 : loss : 0.3598 = 0.0331 + 0.3209 + 0.0058, time: 6.633101]
2023-05-28 14:30:38.112: epoch 90:	0.02668002  	0.19557011  	0.10926904  
2023-05-28 14:30:44.762: [iter 91 : loss : 0.3589 = 0.0324 + 0.3207 + 0.0059, time: 6.649012]
2023-05-28 14:30:44.919: epoch 91:	0.02663768  	0.19526860  	0.10905284  
2023-05-28 14:30:51.557: [iter 92 : loss : 0.3579 = 0.0314 + 0.3207 + 0.0059, time: 6.637035]
2023-05-28 14:30:51.714: epoch 92:	0.02663063  	0.19485089  	0.10901365  
2023-05-28 14:30:58.344: [iter 93 : loss : 0.3580 = 0.0315 + 0.3205 + 0.0060, time: 6.628022]
2023-05-28 14:30:58.503: epoch 93:	0.02656006  	0.19436161  	0.10901237  
2023-05-28 14:31:05.155: [iter 94 : loss : 0.3566 = 0.0302 + 0.3204 + 0.0060, time: 6.651063]
2023-05-28 14:31:05.311: epoch 94:	0.02654595  	0.19436339  	0.10904299  
2023-05-28 14:31:11.940: [iter 95 : loss : 0.3557 = 0.0294 + 0.3203 + 0.0060, time: 6.627966]
2023-05-28 14:31:12.097: epoch 95:	0.02654595  	0.19438735  	0.10916382  
2023-05-28 14:31:18.765: [iter 96 : loss : 0.3557 = 0.0295 + 0.3201 + 0.0061, time: 6.666993]
2023-05-28 14:31:18.919: epoch 96:	0.02653889  	0.19427788  	0.10897160  
2023-05-28 14:31:25.556: [iter 97 : loss : 0.3545 = 0.0284 + 0.3200 + 0.0061, time: 6.635994]
2023-05-28 14:31:25.710: epoch 97:	0.02661651  	0.19447090  	0.10900257  
2023-05-28 14:31:32.351: [iter 98 : loss : 0.3544 = 0.0282 + 0.3199 + 0.0062, time: 6.639994]
2023-05-28 14:31:32.508: epoch 98:	0.02662357  	0.19474275  	0.10916628  
2023-05-28 14:31:39.347: [iter 99 : loss : 0.3537 = 0.0276 + 0.3198 + 0.0062, time: 6.837045]
2023-05-28 14:31:39.505: epoch 99:	0.02672942  	0.19556712  	0.10958362  
2023-05-28 14:31:46.139: [iter 100 : loss : 0.3534 = 0.0274 + 0.3197 + 0.0063, time: 6.633071]
2023-05-28 14:31:46.284: epoch 100:	0.02674353  	0.19567029  	0.10963818  
2023-05-28 14:31:52.933: [iter 101 : loss : 0.3527 = 0.0268 + 0.3196 + 0.0063, time: 6.647078]
2023-05-28 14:31:53.088: epoch 101:	0.02668708  	0.19548221  	0.10954502  
2023-05-28 14:31:59.735: [iter 102 : loss : 0.3522 = 0.0263 + 0.3195 + 0.0064, time: 6.645000]
2023-05-28 14:31:59.891: epoch 102:	0.02672236  	0.19586034  	0.10961424  
2023-05-28 14:32:06.541: [iter 103 : loss : 0.3519 = 0.0261 + 0.3194 + 0.0064, time: 6.648029]
2023-05-28 14:32:06.694: epoch 103:	0.02671531  	0.19569993  	0.10983105  
2023-05-28 14:32:13.339: [iter 104 : loss : 0.3519 = 0.0261 + 0.3194 + 0.0065, time: 6.643994]
2023-05-28 14:32:13.496: epoch 104:	0.02668003  	0.19538692  	0.10971400  
2023-05-28 14:32:20.125: [iter 105 : loss : 0.3514 = 0.0257 + 0.3193 + 0.0065, time: 6.628246]
2023-05-28 14:32:20.281: epoch 105:	0.02665886  	0.19502310  	0.10947708  
2023-05-28 14:32:26.916: [iter 106 : loss : 0.3509 = 0.0252 + 0.3192 + 0.0065, time: 6.634004]
2023-05-28 14:32:27.074: epoch 106:	0.02660240  	0.19447348  	0.10920135  
2023-05-28 14:32:33.722: [iter 107 : loss : 0.3503 = 0.0246 + 0.3191 + 0.0066, time: 6.646993]
2023-05-28 14:32:33.876: epoch 107:	0.02658124  	0.19435240  	0.10921982  
2023-05-28 14:32:40.536: [iter 108 : loss : 0.3498 = 0.0241 + 0.3191 + 0.0066, time: 6.658026]
2023-05-28 14:32:40.689: epoch 108:	0.02665180  	0.19500490  	0.10950039  
2023-05-28 14:32:40.689: Early stopping is trigger at epoch: 108
2023-05-28 14:32:40.689: best_result@epoch 83:

2023-05-28 14:32:40.689: 		0.0268      	0.1968      	0.1096      
2023-05-28 17:49:17.480: my pid: 14884
2023-05-28 17:49:17.480: model: model.general_recommender.SGL
2023-05-28 17:49:17.480: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 17:49:17.481: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 17:49:21.123: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 17:49:28.529: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.406030]
2023-05-28 17:49:28.687: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-28 17:49:28.687: Find a better model.
2023-05-28 17:49:36.118: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.430765]
2023-05-28 17:49:36.320: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-28 17:49:36.320: Find a better model.
2023-05-28 17:49:43.721: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.400484]
2023-05-28 17:49:43.913: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-28 17:49:43.913: Find a better model.
2023-05-28 17:49:51.276: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.362073]
2023-05-28 17:49:51.424: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-28 17:49:51.424: Find a better model.
2023-05-28 17:49:58.500: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.075009]
2023-05-28 17:49:58.661: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-28 17:49:58.661: Find a better model.
2023-05-28 17:50:05.671: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 7.007014]
2023-05-28 17:50:05.833: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-28 17:50:05.833: Find a better model.
2023-05-28 17:50:12.875: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 7.041056]
2023-05-28 17:50:13.021: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-28 17:50:13.021: Find a better model.
2023-05-28 17:50:19.859: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.837044]
2023-05-28 17:50:20.003: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-28 17:50:20.004: Find a better model.
2023-05-28 17:50:26.680: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.675408]
2023-05-28 17:50:26.837: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-28 17:50:33.485: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.647003]
2023-05-28 17:50:33.628: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-28 17:50:40.300: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.670028]
2023-05-28 17:50:40.458: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-28 17:50:47.242: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.783530]
2023-05-28 17:50:47.398: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-28 17:50:54.249: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.850027]
2023-05-28 17:50:54.394: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-28 17:51:01.258: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.862383]
2023-05-28 17:51:01.414: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-28 17:51:08.255: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.839998]
2023-05-28 17:51:08.409: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-28 17:51:08.409: Find a better model.
2023-05-28 17:51:15.232: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.822018]
2023-05-28 17:51:15.377: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-28 17:51:15.377: Find a better model.
2023-05-28 17:51:22.057: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.678013]
2023-05-28 17:51:22.215: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-28 17:51:22.215: Find a better model.
2023-05-28 17:51:28.851: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.634028]
2023-05-28 17:51:29.006: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-28 17:51:29.007: Find a better model.
2023-05-28 17:51:35.650: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.642007]
2023-05-28 17:51:35.806: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-28 17:51:35.806: Find a better model.
2023-05-28 17:51:42.437: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.629994]
2023-05-28 17:51:42.593: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-28 17:51:42.593: Find a better model.
2023-05-28 17:51:49.232: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.638013]
2023-05-28 17:51:49.374: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-28 17:51:49.374: Find a better model.
2023-05-28 17:51:56.023: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.647015]
2023-05-28 17:51:56.183: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-28 17:51:56.184: Find a better model.
2023-05-28 17:52:02.838: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.653049]
2023-05-28 17:52:02.997: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-28 17:52:02.997: Find a better model.
2023-05-28 17:52:09.651: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.653077]
2023-05-28 17:52:09.808: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-28 17:52:09.808: Find a better model.
2023-05-28 17:52:16.445: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.636012]
2023-05-28 17:52:16.590: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-28 17:52:16.590: Find a better model.
2023-05-28 17:52:23.436: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.844062]
2023-05-28 17:52:23.591: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-28 17:52:23.591: Find a better model.
2023-05-28 17:52:30.233: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.640007]
2023-05-28 17:52:30.391: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-28 17:52:30.391: Find a better model.
2023-05-28 17:52:37.008: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.615072]
2023-05-28 17:52:37.153: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-28 17:52:37.153: Find a better model.
2023-05-28 17:52:43.823: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.669009]
2023-05-28 17:52:43.978: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-28 17:52:43.978: Find a better model.
2023-05-28 17:52:50.601: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.620996]
2023-05-28 17:52:50.757: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-28 17:52:50.757: Find a better model.
2023-05-28 17:52:57.456: [iter 31 : loss : 0.2364 = 0.1382 + 0.0959 + 0.0023, time: 6.698064]
2023-05-28 17:52:57.615: epoch 31:	0.02198748  	0.16152731  	0.08374861  
2023-05-28 17:52:57.616: Find a better model.
2023-05-28 17:53:04.411: [iter 32 : loss : 0.2309 = 0.1329 + 0.0956 + 0.0024, time: 6.794005]
2023-05-28 17:53:04.569: epoch 32:	0.02222034  	0.16361333  	0.08482385  
2023-05-28 17:53:04.570: Find a better model.
2023-05-28 17:53:11.436: [iter 33 : loss : 0.2281 = 0.1305 + 0.0952 + 0.0024, time: 6.863748]
2023-05-28 17:53:11.585: epoch 33:	0.02241087  	0.16538045  	0.08561383  
2023-05-28 17:53:11.585: Find a better model.
2023-05-28 17:53:18.428: [iter 34 : loss : 0.2241 = 0.1268 + 0.0948 + 0.0025, time: 6.842547]
2023-05-28 17:53:18.586: epoch 34:	0.02249554  	0.16585720  	0.08620444  
2023-05-28 17:53:18.586: Find a better model.
2023-05-28 17:53:25.408: [iter 35 : loss : 0.2208 = 0.1237 + 0.0946 + 0.0025, time: 6.821160]
2023-05-28 17:53:25.566: epoch 35:	0.02255905  	0.16647111  	0.08653931  
2023-05-28 17:53:25.566: Find a better model.
2023-05-28 17:53:32.404: [iter 36 : loss : 0.2175 = 0.1207 + 0.0942 + 0.0026, time: 6.835997]
2023-05-28 17:53:32.558: epoch 36:	0.02273547  	0.16769096  	0.08747324  
2023-05-28 17:53:32.559: Find a better model.
2023-05-28 17:53:39.406: [iter 37 : loss : 0.2137 = 0.1171 + 0.0939 + 0.0026, time: 6.846032]
2023-05-28 17:53:39.562: epoch 37:	0.02288366  	0.16880982  	0.08824537  
2023-05-28 17:53:39.562: Find a better model.
2023-05-28 17:53:46.403: [iter 38 : loss : 0.2121 = 0.1158 + 0.0936 + 0.0027, time: 6.838993]
2023-05-28 17:53:46.548: epoch 38:	0.02298244  	0.16991451  	0.08882745  
2023-05-28 17:53:46.548: Find a better model.
2023-05-28 17:53:53.403: [iter 39 : loss : 0.2076 = 0.1116 + 0.0933 + 0.0028, time: 6.854017]
2023-05-28 17:53:53.558: epoch 39:	0.02309535  	0.17147504  	0.08946259  
2023-05-28 17:53:53.559: Find a better model.
2023-05-28 17:54:00.402: [iter 40 : loss : 0.2044 = 0.1086 + 0.0930 + 0.0028, time: 6.842015]
2023-05-28 17:54:00.547: epoch 40:	0.02310240  	0.17105164  	0.08974066  
2023-05-28 17:54:07.408: [iter 41 : loss : 0.2030 = 0.1074 + 0.0928 + 0.0029, time: 6.860008]
2023-05-28 17:54:07.564: epoch 41:	0.02329999  	0.17194302  	0.09029184  
2023-05-28 17:54:07.564: Find a better model.
2023-05-28 17:54:14.401: [iter 42 : loss : 0.2010 = 0.1056 + 0.0924 + 0.0029, time: 6.836013]
2023-05-28 17:54:14.558: epoch 42:	0.02334233  	0.17219265  	0.09072889  
2023-05-28 17:54:14.559: Find a better model.
2023-05-28 17:54:21.387: [iter 43 : loss : 0.1968 = 0.1017 + 0.0922 + 0.0030, time: 6.826211]
2023-05-28 17:54:21.530: epoch 43:	0.02339878  	0.17239256  	0.09113028  
2023-05-28 17:54:21.530: Find a better model.
2023-05-28 17:54:28.224: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.693438]
2023-05-28 17:54:28.381: epoch 44:	0.02350463  	0.17327063  	0.09174261  
2023-05-28 17:54:28.381: Find a better model.
2023-05-28 17:54:35.184: [iter 45 : loss : 0.1912 = 0.0964 + 0.0917 + 0.0031, time: 6.801013]
2023-05-28 17:54:35.339: epoch 45:	0.02359636  	0.17404579  	0.09218445  
2023-05-28 17:54:35.339: Find a better model.
2023-05-28 17:54:42.163: [iter 46 : loss : 0.1888 = 0.0943 + 0.0914 + 0.0031, time: 6.823002]
2023-05-28 17:54:42.318: epoch 46:	0.02365282  	0.17442510  	0.09256991  
2023-05-28 17:54:42.318: Find a better model.
2023-05-28 17:54:48.998: [iter 47 : loss : 0.1883 = 0.0940 + 0.0911 + 0.0032, time: 6.678021]
2023-05-28 17:54:49.152: epoch 47:	0.02377278  	0.17558673  	0.09303655  
2023-05-28 17:54:49.153: Find a better model.
2023-05-28 17:54:55.962: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.808017]
2023-05-28 17:54:56.117: epoch 48:	0.02387157  	0.17616647  	0.09319612  
2023-05-28 17:54:56.117: Find a better model.
2023-05-28 17:55:02.769: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.651014]
2023-05-28 17:55:02.924: epoch 49:	0.02388568  	0.17655869  	0.09362529  
2023-05-28 17:55:02.924: Find a better model.
2023-05-28 17:55:09.589: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.664194]
2023-05-28 17:55:09.745: epoch 50:	0.02401975  	0.17768233  	0.09419967  
2023-05-28 17:55:09.746: Find a better model.
2023-05-28 17:55:16.368: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.620538]
2023-05-28 17:55:16.522: epoch 51:	0.02399858  	0.17749181  	0.09439772  
2023-05-28 17:55:23.167: [iter 52 : loss : 0.1776 = 0.0841 + 0.0901 + 0.0034, time: 6.644015]
2023-05-28 17:55:23.322: epoch 52:	0.02409736  	0.17813653  	0.09492709  
2023-05-28 17:55:23.322: Find a better model.
2023-05-28 17:55:29.975: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.652009]
2023-05-28 17:55:30.129: epoch 53:	0.02418909  	0.17902479  	0.09543481  
2023-05-28 17:55:30.129: Find a better model.
2023-05-28 17:55:36.778: [iter 54 : loss : 0.1735 = 0.0803 + 0.0897 + 0.0035, time: 6.648040]
2023-05-28 17:55:36.932: epoch 54:	0.02428788  	0.18011364  	0.09604108  
2023-05-28 17:55:36.932: Find a better model.
2023-05-28 17:55:43.575: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.642019]
2023-05-28 17:55:43.731: epoch 55:	0.02433727  	0.18052189  	0.09626227  
2023-05-28 17:55:43.731: Find a better model.
2023-05-28 17:55:50.366: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.634023]
2023-05-28 17:55:50.508: epoch 56:	0.02442196  	0.18118976  	0.09665569  
2023-05-28 17:55:50.508: Find a better model.
2023-05-28 17:55:57.184: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.674020]
2023-05-28 17:55:57.340: epoch 57:	0.02448546  	0.18160756  	0.09683972  
2023-05-28 17:55:57.340: Find a better model.
2023-05-28 17:56:04.143: [iter 58 : loss : 0.1663 = 0.0736 + 0.0890 + 0.0037, time: 6.802016]
2023-05-28 17:56:04.299: epoch 58:	0.02457719  	0.18285018  	0.09747005  
2023-05-28 17:56:04.299: Find a better model.
2023-05-28 17:56:10.958: [iter 59 : loss : 0.1651 = 0.0726 + 0.0888 + 0.0037, time: 6.658013]
2023-05-28 17:56:11.114: epoch 59:	0.02461953  	0.18269846  	0.09752955  
2023-05-28 17:56:17.745: [iter 60 : loss : 0.1636 = 0.0712 + 0.0886 + 0.0038, time: 6.630004]
2023-05-28 17:56:17.902: epoch 60:	0.02465482  	0.18315892  	0.09796911  
2023-05-28 17:56:17.902: Find a better model.
2023-05-28 17:56:24.553: [iter 61 : loss : 0.1622 = 0.0699 + 0.0885 + 0.0038, time: 6.650022]
2023-05-28 17:56:24.707: epoch 61:	0.02473244  	0.18359081  	0.09832223  
2023-05-28 17:56:24.707: Find a better model.
2023-05-28 17:56:31.356: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.648004]
2023-05-28 17:56:31.510: epoch 62:	0.02481712  	0.18403558  	0.09873773  
2023-05-28 17:56:31.510: Find a better model.
2023-05-28 17:56:38.181: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.667419]
2023-05-28 17:56:38.337: epoch 63:	0.02483123  	0.18400325  	0.09892930  
2023-05-28 17:56:44.945: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.607105]
2023-05-28 17:56:45.101: epoch 64:	0.02493707  	0.18471114  	0.09926739  
2023-05-28 17:56:45.101: Find a better model.
2023-05-28 17:56:51.746: [iter 65 : loss : 0.1571 = 0.0652 + 0.0878 + 0.0040, time: 6.644031]
2023-05-28 17:56:51.900: epoch 65:	0.02497941  	0.18488623  	0.09989791  
2023-05-28 17:56:51.900: Find a better model.
2023-05-28 17:56:58.540: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.638294]
2023-05-28 17:56:58.696: epoch 66:	0.02511349  	0.18588178  	0.10047095  
2023-05-28 17:56:58.696: Find a better model.
2023-05-28 17:57:05.531: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.833058]
2023-05-28 17:57:05.685: epoch 67:	0.02514877  	0.18598960  	0.10078301  
2023-05-28 17:57:05.685: Find a better model.
2023-05-28 17:57:12.341: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.654994]
2023-05-28 17:57:12.486: epoch 68:	0.02526873  	0.18671283  	0.10101739  
2023-05-28 17:57:12.487: Find a better model.
2023-05-28 17:57:19.329: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.841286]
2023-05-28 17:57:19.485: epoch 69:	0.02528284  	0.18693843  	0.10119535  
2023-05-28 17:57:19.485: Find a better model.
2023-05-28 17:57:26.151: [iter 70 : loss : 0.1503 = 0.0589 + 0.0871 + 0.0042, time: 6.665019]
2023-05-28 17:57:26.307: epoch 70:	0.02542397  	0.18775471  	0.10159777  
2023-05-28 17:57:26.307: Find a better model.
2023-05-28 17:57:33.107: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.799023]
2023-05-28 17:57:33.266: epoch 71:	0.02545925  	0.18778692  	0.10185392  
2023-05-28 17:57:33.267: Find a better model.
2023-05-28 17:57:39.941: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.673023]
2023-05-28 17:57:40.095: epoch 72:	0.02542397  	0.18775615  	0.10200133  
2023-05-28 17:57:46.906: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.809007]
2023-05-28 17:57:47.062: epoch 73:	0.02548042  	0.18822935  	0.10243368  
2023-05-28 17:57:47.063: Find a better model.
2023-05-28 17:57:53.909: [iter 74 : loss : 0.1459 = 0.0549 + 0.0867 + 0.0044, time: 6.844016]
2023-05-28 17:57:54.065: epoch 74:	0.02549453  	0.18806598  	0.10253042  
2023-05-28 17:58:00.719: [iter 75 : loss : 0.1455 = 0.0545 + 0.0865 + 0.0044, time: 6.653001]
2023-05-28 17:58:00.862: epoch 75:	0.02545924  	0.18780240  	0.10252031  
2023-05-28 17:58:07.513: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.650036]
2023-05-28 17:58:07.658: epoch 76:	0.02557920  	0.18864223  	0.10301083  
2023-05-28 17:58:07.658: Find a better model.
2023-05-28 17:58:14.326: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.666039]
2023-05-28 17:58:14.483: epoch 77:	0.02563566  	0.18901381  	0.10320117  
2023-05-28 17:58:14.483: Find a better model.
2023-05-28 17:58:21.287: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.803126]
2023-05-28 17:58:21.442: epoch 78:	0.02569917  	0.18950087  	0.10337805  
2023-05-28 17:58:21.442: Find a better model.
2023-05-28 17:58:28.107: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.664004]
2023-05-28 17:58:28.266: epoch 79:	0.02567800  	0.18938303  	0.10340759  
2023-05-28 17:58:34.911: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.644216]
2023-05-28 17:58:35.054: epoch 80:	0.02575562  	0.19002596  	0.10368609  
2023-05-28 17:58:35.055: Find a better model.
2023-05-28 17:58:41.712: [iter 81 : loss : 0.1405 = 0.0500 + 0.0859 + 0.0047, time: 6.655993]
2023-05-28 17:58:41.868: epoch 81:	0.02577679  	0.19017769  	0.10378321  
2023-05-28 17:58:41.868: Find a better model.
2023-05-28 17:58:48.507: [iter 82 : loss : 0.1391 = 0.0487 + 0.0858 + 0.0047, time: 6.637994]
2023-05-28 17:58:48.663: epoch 82:	0.02594615  	0.19141982  	0.10442085  
2023-05-28 17:58:48.663: Find a better model.
2023-05-28 17:58:55.336: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.671993]
2023-05-28 17:58:55.490: epoch 83:	0.02591087  	0.19117969  	0.10435142  
2023-05-28 17:59:02.284: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.793227]
2023-05-28 17:59:02.444: epoch 84:	0.02592498  	0.19129896  	0.10440473  
2023-05-28 17:59:09.100: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.654132]
2023-05-28 17:59:09.257: epoch 85:	0.02591087  	0.19136894  	0.10478976  
2023-05-28 17:59:16.092: [iter 86 : loss : 0.1368 = 0.0466 + 0.0853 + 0.0049, time: 6.834014]
2023-05-28 17:59:16.253: epoch 86:	0.02598849  	0.19185658  	0.10491765  
2023-05-28 17:59:16.253: Find a better model.
2023-05-28 17:59:23.061: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.806994]
2023-05-28 17:59:23.219: epoch 87:	0.02607317  	0.19228531  	0.10510247  
2023-05-28 17:59:23.219: Find a better model.
2023-05-28 17:59:29.898: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.678055]
2023-05-28 17:59:30.054: epoch 88:	0.02611551  	0.19253215  	0.10514323  
2023-05-28 17:59:30.054: Find a better model.
2023-05-28 17:59:36.712: [iter 89 : loss : 0.1335 = 0.0435 + 0.0851 + 0.0050, time: 6.657134]
2023-05-28 17:59:36.854: epoch 89:	0.02607317  	0.19212422  	0.10504641  
2023-05-28 17:59:43.483: [iter 90 : loss : 0.1341 = 0.0440 + 0.0850 + 0.0050, time: 6.628013]
2023-05-28 17:59:43.639: epoch 90:	0.02620724  	0.19280358  	0.10541946  
2023-05-28 17:59:43.640: Find a better model.
2023-05-28 17:59:50.473: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.832067]
2023-05-28 17:59:50.628: epoch 91:	0.02622841  	0.19310322  	0.10559718  
2023-05-28 17:59:50.637: Find a better model.
2023-05-28 17:59:57.287: [iter 92 : loss : 0.1315 = 0.0415 + 0.0849 + 0.0051, time: 6.649046]
2023-05-28 17:59:57.445: epoch 92:	0.02627781  	0.19333185  	0.10574193  
2023-05-28 17:59:57.445: Find a better model.
2023-05-28 18:00:04.092: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.645011]
2023-05-28 18:00:04.250: epoch 93:	0.02629192  	0.19352315  	0.10589471  
2023-05-28 18:00:04.250: Find a better model.
2023-05-28 18:00:10.878: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.627051]
2023-05-28 18:00:11.023: epoch 94:	0.02636954  	0.19435073  	0.10622913  
2023-05-28 18:00:11.024: Find a better model.
2023-05-28 18:00:17.664: [iter 95 : loss : 0.1292 = 0.0394 + 0.0846 + 0.0052, time: 6.638997]
2023-05-28 18:00:17.808: epoch 95:	0.02632720  	0.19387393  	0.10622533  
2023-05-28 18:00:24.485: [iter 96 : loss : 0.1293 = 0.0395 + 0.0845 + 0.0052, time: 6.676013]
2023-05-28 18:00:24.640: epoch 96:	0.02632014  	0.19393848  	0.10634997  
2023-05-28 18:00:31.267: [iter 97 : loss : 0.1278 = 0.0381 + 0.0845 + 0.0053, time: 6.625747]
2023-05-28 18:00:31.422: epoch 97:	0.02639777  	0.19438259  	0.10644364  
2023-05-28 18:00:31.422: Find a better model.
2023-05-28 18:00:38.052: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 6.629009]
2023-05-28 18:00:38.209: epoch 98:	0.02647539  	0.19517130  	0.10677482  
2023-05-28 18:00:38.209: Find a better model.
2023-05-28 18:00:44.858: [iter 99 : loss : 0.1274 = 0.0378 + 0.0843 + 0.0053, time: 6.648520]
2023-05-28 18:00:45.013: epoch 99:	0.02655301  	0.19582823  	0.10707228  
2023-05-28 18:00:45.013: Find a better model.
2023-05-28 18:00:51.641: [iter 100 : loss : 0.1270 = 0.0373 + 0.0842 + 0.0054, time: 6.627047]
2023-05-28 18:00:51.799: epoch 100:	0.02658829  	0.19625662  	0.10701554  
2023-05-28 18:00:51.799: Find a better model.
2023-05-28 18:00:58.437: [iter 101 : loss : 0.1265 = 0.0369 + 0.0842 + 0.0054, time: 6.637004]
2023-05-28 18:00:58.591: epoch 101:	0.02663063  	0.19661433  	0.10721381  
2023-05-28 18:00:58.591: Find a better model.
2023-05-28 18:01:05.256: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0054, time: 6.663316]
2023-05-28 18:01:05.412: epoch 102:	0.02669413  	0.19691932  	0.10742136  
2023-05-28 18:01:05.412: Find a better model.
2023-05-28 18:01:12.060: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.647007]
2023-05-28 18:01:12.219: epoch 103:	0.02674353  	0.19722205  	0.10752247  
2023-05-28 18:01:12.219: Find a better model.
2023-05-28 18:01:18.864: [iter 104 : loss : 0.1257 = 0.0362 + 0.0840 + 0.0055, time: 6.644021]
2023-05-28 18:01:19.020: epoch 104:	0.02677882  	0.19770332  	0.10787418  
2023-05-28 18:01:19.020: Find a better model.
2023-05-28 18:01:25.656: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 6.635016]
2023-05-28 18:01:25.812: epoch 105:	0.02673647  	0.19747634  	0.10784737  
2023-05-28 18:01:32.446: [iter 106 : loss : 0.1245 = 0.0351 + 0.0839 + 0.0056, time: 6.632028]
2023-05-28 18:01:32.588: epoch 106:	0.02671531  	0.19686815  	0.10767137  
2023-05-28 18:01:39.255: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.666004]
2023-05-28 18:01:39.415: epoch 107:	0.02675059  	0.19714323  	0.10761061  
2023-05-28 18:01:46.047: [iter 108 : loss : 0.1234 = 0.0339 + 0.0838 + 0.0056, time: 6.631013]
2023-05-28 18:01:46.193: epoch 108:	0.02677175  	0.19749446  	0.10783190  
2023-05-28 18:01:52.860: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.665022]
2023-05-28 18:01:53.003: epoch 109:	0.02680703  	0.19764553  	0.10780975  
2023-05-28 18:01:59.649: [iter 110 : loss : 0.1215 = 0.0322 + 0.0836 + 0.0057, time: 6.644013]
2023-05-28 18:01:59.803: epoch 110:	0.02684937  	0.19789937  	0.10788774  
2023-05-28 18:01:59.803: Find a better model.
2023-05-28 18:02:06.453: [iter 111 : loss : 0.1215 = 0.0322 + 0.0836 + 0.0058, time: 6.647042]
2023-05-28 18:02:06.613: epoch 111:	0.02684232  	0.19807667  	0.10794735  
2023-05-28 18:02:06.613: Find a better model.
2023-05-28 18:02:13.235: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.620013]
2023-05-28 18:02:13.392: epoch 112:	0.02691993  	0.19863367  	0.10815966  
2023-05-28 18:02:13.392: Find a better model.
2023-05-28 18:02:20.036: [iter 113 : loss : 0.1212 = 0.0319 + 0.0835 + 0.0058, time: 6.643007]
2023-05-28 18:02:20.193: epoch 113:	0.02694110  	0.19902189  	0.10827690  
2023-05-28 18:02:20.193: Find a better model.
2023-05-28 18:02:26.843: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.648670]
2023-05-28 18:02:27.001: epoch 114:	0.02699755  	0.19942036  	0.10851276  
2023-05-28 18:02:27.001: Find a better model.
2023-05-28 18:02:33.629: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.627002]
2023-05-28 18:02:33.785: epoch 115:	0.02697638  	0.19875123  	0.10850380  
2023-05-28 18:02:40.421: [iter 116 : loss : 0.1193 = 0.0301 + 0.0833 + 0.0059, time: 6.635022]
2023-05-28 18:02:40.576: epoch 116:	0.02692698  	0.19838578  	0.10834983  
2023-05-28 18:02:47.224: [iter 117 : loss : 0.1193 = 0.0301 + 0.0832 + 0.0060, time: 6.647378]
2023-05-28 18:02:47.368: epoch 117:	0.02691287  	0.19823329  	0.10820244  
2023-05-28 18:02:54.013: [iter 118 : loss : 0.1191 = 0.0299 + 0.0832 + 0.0060, time: 6.644019]
2023-05-28 18:02:54.174: epoch 118:	0.02697638  	0.19863082  	0.10845006  
2023-05-28 18:03:00.813: [iter 119 : loss : 0.1181 = 0.0289 + 0.0831 + 0.0060, time: 6.636008]
2023-05-28 18:03:00.959: epoch 119:	0.02694815  	0.19847704  	0.10854238  
2023-05-28 18:03:07.627: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0060, time: 6.665052]
2023-05-28 18:03:07.782: epoch 120:	0.02699049  	0.19856702  	0.10865782  
2023-05-28 18:03:14.429: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.646079]
2023-05-28 18:03:14.584: epoch 121:	0.02698343  	0.19842406  	0.10879666  
2023-05-28 18:03:21.238: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.652997]
2023-05-28 18:03:21.393: epoch 122:	0.02701166  	0.19878502  	0.10886861  
2023-05-28 18:03:28.024: [iter 123 : loss : 0.1175 = 0.0285 + 0.0829 + 0.0061, time: 6.629061]
2023-05-28 18:03:28.184: epoch 123:	0.02699754  	0.19864790  	0.10862579  
2023-05-28 18:03:34.801: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.613484]
2023-05-28 18:03:34.944: epoch 124:	0.02701166  	0.19877514  	0.10855011  
2023-05-28 18:03:41.580: [iter 125 : loss : 0.1160 = 0.0269 + 0.0828 + 0.0062, time: 6.634004]
2023-05-28 18:03:41.736: epoch 125:	0.02706105  	0.19938758  	0.10877197  
2023-05-28 18:03:48.406: [iter 126 : loss : 0.1161 = 0.0271 + 0.0828 + 0.0062, time: 6.669041]
2023-05-28 18:03:48.561: epoch 126:	0.02703988  	0.19919792  	0.10875628  
2023-05-28 18:03:55.389: [iter 127 : loss : 0.1152 = 0.0262 + 0.0828 + 0.0063, time: 6.827101]
2023-05-28 18:03:55.544: epoch 127:	0.02701166  	0.19935647  	0.10896672  
2023-05-28 18:04:02.216: [iter 128 : loss : 0.1163 = 0.0273 + 0.0827 + 0.0063, time: 6.671088]
2023-05-28 18:04:02.375: epoch 128:	0.02708222  	0.19974394  	0.10904901  
2023-05-28 18:04:02.375: Find a better model.
2023-05-28 18:04:09.181: [iter 129 : loss : 0.1152 = 0.0263 + 0.0827 + 0.0063, time: 6.804305]
2023-05-28 18:04:09.337: epoch 129:	0.02712456  	0.19999887  	0.10921801  
2023-05-28 18:04:09.337: Find a better model.
2023-05-28 18:04:15.984: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.645438]
2023-05-28 18:04:16.139: epoch 130:	0.02711751  	0.20013618  	0.10937148  
2023-05-28 18:04:16.139: Find a better model.
2023-05-28 18:04:22.792: [iter 131 : loss : 0.1144 = 0.0255 + 0.0826 + 0.0064, time: 6.650007]
2023-05-28 18:04:22.949: epoch 131:	0.02711046  	0.19996931  	0.10947834  
2023-05-28 18:04:29.580: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.630001]
2023-05-28 18:04:29.734: epoch 132:	0.02717396  	0.20080996  	0.10965919  
2023-05-28 18:04:29.734: Find a better model.
2023-05-28 18:04:36.370: [iter 133 : loss : 0.1134 = 0.0244 + 0.0825 + 0.0064, time: 6.634318]
2023-05-28 18:04:36.515: epoch 133:	0.02712456  	0.20042738  	0.10966394  
2023-05-28 18:04:43.190: [iter 134 : loss : 0.1143 = 0.0254 + 0.0824 + 0.0065, time: 6.673278]
2023-05-28 18:04:43.331: epoch 134:	0.02713162  	0.20017371  	0.10963427  
2023-05-28 18:04:49.999: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.665062]
2023-05-28 18:04:50.156: epoch 135:	0.02709633  	0.19994126  	0.10951638  
2023-05-28 18:04:56.768: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.611006]
2023-05-28 18:04:56.923: epoch 136:	0.02704694  	0.19995457  	0.10929630  
2023-05-28 18:05:03.575: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.651000]
2023-05-28 18:05:03.729: epoch 137:	0.02708927  	0.19996886  	0.10945810  
2023-05-28 18:05:10.361: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.630031]
2023-05-28 18:05:10.514: epoch 138:	0.02701872  	0.19954194  	0.10923640  
2023-05-28 18:05:17.157: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.642023]
2023-05-28 18:05:17.302: epoch 139:	0.02703283  	0.19948320  	0.10926136  
2023-05-28 18:05:23.941: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0066, time: 6.638050]
2023-05-28 18:05:24.099: epoch 140:	0.02703988  	0.19928263  	0.10921964  
2023-05-28 18:05:30.754: [iter 141 : loss : 0.1128 = 0.0239 + 0.0822 + 0.0067, time: 6.653189]
2023-05-28 18:05:30.898: epoch 141:	0.02706811  	0.19949001  	0.10950807  
2023-05-28 18:05:37.365: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.466020]
2023-05-28 18:05:37.520: epoch 142:	0.02708928  	0.19978063  	0.10958034  
2023-05-28 18:05:44.150: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.628053]
2023-05-28 18:05:44.306: epoch 143:	0.02709633  	0.19983797  	0.10972515  
2023-05-28 18:05:50.950: [iter 144 : loss : 0.1113 = 0.0225 + 0.0821 + 0.0068, time: 6.642070]
2023-05-28 18:05:51.105: epoch 144:	0.02706811  	0.19973108  	0.10971838  
2023-05-28 18:05:57.751: [iter 145 : loss : 0.1114 = 0.0226 + 0.0820 + 0.0068, time: 6.644993]
2023-05-28 18:05:57.908: epoch 145:	0.02711751  	0.20004287  	0.10974620  
2023-05-28 18:06:04.550: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.640994]
2023-05-28 18:06:04.705: epoch 146:	0.02701872  	0.19926432  	0.10944347  
2023-05-28 18:06:11.344: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.636994]
2023-05-28 18:06:11.501: epoch 147:	0.02708223  	0.19982377  	0.10978828  
2023-05-28 18:06:18.171: [iter 148 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 6.669077]
2023-05-28 18:06:18.325: epoch 148:	0.02713868  	0.19991045  	0.10981442  
2023-05-28 18:06:24.941: [iter 149 : loss : 0.1106 = 0.0218 + 0.0819 + 0.0069, time: 6.614045]
2023-05-28 18:06:25.099: epoch 149:	0.02712457  	0.19965412  	0.10973541  
2023-05-28 18:06:31.551: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.451017]
2023-05-28 18:06:31.707: epoch 150:	0.02716691  	0.19999765  	0.11012077  
2023-05-28 18:06:38.335: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.626012]
2023-05-28 18:06:38.488: epoch 151:	0.02716691  	0.19970617  	0.11002252  
2023-05-28 18:06:45.127: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.636011]
2023-05-28 18:06:45.282: epoch 152:	0.02711045  	0.19951583  	0.11003271  
2023-05-28 18:06:51.946: [iter 153 : loss : 0.1086 = 0.0198 + 0.0818 + 0.0070, time: 6.663104]
2023-05-28 18:06:52.088: epoch 153:	0.02709634  	0.19926265  	0.10982441  
2023-05-28 18:06:58.728: [iter 154 : loss : 0.1092 = 0.0204 + 0.0817 + 0.0070, time: 6.638997]
2023-05-28 18:06:58.871: epoch 154:	0.02720924  	0.20028961  	0.11017007  
2023-05-28 18:07:05.331: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.458020]
2023-05-28 18:07:05.487: epoch 155:	0.02713162  	0.19973153  	0.10996623  
2023-05-28 18:07:12.109: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.621420]
2023-05-28 18:07:12.253: epoch 156:	0.02709634  	0.19950414  	0.10973961  
2023-05-28 18:07:18.922: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.667001]
2023-05-28 18:07:19.078: epoch 157:	0.02711046  	0.19961943  	0.10977919  
2023-05-28 18:07:19.078: Early stopping is trigger at epoch: 157
2023-05-28 18:07:19.078: best_result@epoch 132:

2023-05-28 18:07:19.079: 		0.0272      	0.2008      	0.1097      
2023-05-28 18:37:59.045: my pid: 3256
2023-05-28 18:37:59.045: model: model.general_recommender.SGL
2023-05-28 18:37:59.045: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 18:37:59.045: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 18:38:02.704: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 18:38:09.948: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.242028]
2023-05-28 18:38:10.105: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-28 18:38:10.105: Find a better model.
2023-05-28 18:38:17.527: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.420030]
2023-05-28 18:38:17.707: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-28 18:38:17.707: Find a better model.
2023-05-28 18:38:25.122: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.413046]
2023-05-28 18:38:25.290: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-28 18:38:25.290: Find a better model.
2023-05-28 18:38:32.497: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.205701]
2023-05-28 18:38:32.651: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-28 18:38:32.651: Find a better model.
2023-05-28 18:38:39.716: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.064013]
2023-05-28 18:38:39.872: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-28 18:38:39.872: Find a better model.
2023-05-28 18:38:46.880: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 7.007012]
2023-05-28 18:38:47.038: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-28 18:38:47.038: Find a better model.
2023-05-28 18:38:53.880: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.840001]
2023-05-28 18:38:54.043: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-28 18:38:54.043: Find a better model.
2023-05-28 18:39:01.068: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 7.023959]
2023-05-28 18:39:01.226: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-28 18:39:01.226: Find a better model.
2023-05-28 18:39:08.080: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.853011]
2023-05-28 18:39:08.235: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-28 18:39:08.235: Find a better model.
2023-05-28 18:39:15.077: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.841294]
2023-05-28 18:39:15.232: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-28 18:39:15.232: Find a better model.
2023-05-28 18:39:22.072: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.838997]
2023-05-28 18:39:22.226: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-28 18:39:22.226: Find a better model.
2023-05-28 18:39:28.870: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.642016]
2023-05-28 18:39:29.017: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-28 18:39:29.017: Find a better model.
2023-05-28 18:39:35.646: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.627003]
2023-05-28 18:39:35.799: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-28 18:39:35.800: Find a better model.
2023-05-28 18:39:42.454: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.653003]
2023-05-28 18:39:42.611: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-28 18:39:42.612: Find a better model.
2023-05-28 18:39:49.254: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.641217]
2023-05-28 18:39:49.409: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-28 18:39:56.035: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.625002]
2023-05-28 18:39:56.190: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-28 18:39:56.191: Find a better model.
2023-05-28 18:40:02.652: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.460013]
2023-05-28 18:40:02.805: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-28 18:40:02.805: Find a better model.
2023-05-28 18:40:09.267: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.460004]
2023-05-28 18:40:09.421: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-28 18:40:09.421: Find a better model.
2023-05-28 18:40:15.861: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.439044]
2023-05-28 18:40:16.019: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-28 18:40:16.019: Find a better model.
2023-05-28 18:40:22.623: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.602144]
2023-05-28 18:40:22.783: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-28 18:40:22.783: Find a better model.
2023-05-28 18:40:29.420: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.636007]
2023-05-28 18:40:29.575: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-28 18:40:29.575: Find a better model.
2023-05-28 18:40:36.233: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.656012]
2023-05-28 18:40:36.389: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-28 18:40:36.390: Find a better model.
2023-05-28 18:40:42.854: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.463026]
2023-05-28 18:40:43.010: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-28 18:40:43.010: Find a better model.
2023-05-28 18:40:49.449: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.438107]
2023-05-28 18:40:49.603: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-28 18:40:49.603: Find a better model.
2023-05-28 18:40:56.051: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.447018]
2023-05-28 18:40:56.207: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-28 18:40:56.207: Find a better model.
2023-05-28 18:41:02.811: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.603004]
2023-05-28 18:41:02.963: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-28 18:41:02.963: Find a better model.
2023-05-28 18:41:09.432: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.468009]
2023-05-28 18:41:09.585: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-28 18:41:09.585: Find a better model.
2023-05-28 18:41:16.037: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.449994]
2023-05-28 18:41:16.191: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-28 18:41:16.191: Find a better model.
2023-05-28 18:41:22.644: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.451008]
2023-05-28 18:41:22.798: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-28 18:41:22.798: Find a better model.
2023-05-28 18:41:29.246: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.447020]
2023-05-28 18:41:29.401: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-28 18:41:29.401: Find a better model.
2023-05-28 18:41:36.041: [iter 31 : loss : 0.3267 = 0.1432 + 0.1813 + 0.0023, time: 6.637976]
2023-05-28 18:41:36.195: epoch 31:	0.02291894  	0.16888899  	0.08838752  
2023-05-28 18:41:36.195: Find a better model.
2023-05-28 18:41:42.811: [iter 32 : loss : 0.3194 = 0.1365 + 0.1806 + 0.0024, time: 6.613988]
2023-05-28 18:41:42.956: epoch 32:	0.02308829  	0.17047727  	0.08936028  
2023-05-28 18:41:42.956: Find a better model.
2023-05-28 18:41:49.606: [iter 33 : loss : 0.3146 = 0.1323 + 0.1799 + 0.0024, time: 6.649033]
2023-05-28 18:41:49.761: epoch 33:	0.02324354  	0.17171101  	0.09021017  
2023-05-28 18:41:49.761: Find a better model.
2023-05-28 18:41:56.418: [iter 34 : loss : 0.3091 = 0.1273 + 0.1793 + 0.0025, time: 6.655993]
2023-05-28 18:41:56.570: epoch 34:	0.02349757  	0.17358223  	0.09111759  
2023-05-28 18:41:56.570: Find a better model.
2023-05-28 18:42:03.406: [iter 35 : loss : 0.3042 = 0.1229 + 0.1787 + 0.0026, time: 6.834354]
2023-05-28 18:42:03.563: epoch 35:	0.02363165  	0.17475149  	0.09201396  
2023-05-28 18:42:03.563: Find a better model.
2023-05-28 18:42:10.219: [iter 36 : loss : 0.2998 = 0.1190 + 0.1781 + 0.0027, time: 6.655519]
2023-05-28 18:42:10.371: epoch 36:	0.02366692  	0.17498364  	0.09248841  
2023-05-28 18:42:10.371: Find a better model.
2023-05-28 18:42:17.205: [iter 37 : loss : 0.2946 = 0.1144 + 0.1775 + 0.0027, time: 6.831439]
2023-05-28 18:42:17.362: epoch 37:	0.02377277  	0.17574090  	0.09314939  
2023-05-28 18:42:17.362: Find a better model.
2023-05-28 18:42:24.175: [iter 38 : loss : 0.2919 = 0.1121 + 0.1770 + 0.0028, time: 6.812065]
2023-05-28 18:42:24.320: epoch 38:	0.02387862  	0.17677593  	0.09385292  
2023-05-28 18:42:24.320: Find a better model.
2023-05-28 18:42:31.012: [iter 39 : loss : 0.2866 = 0.1073 + 0.1764 + 0.0029, time: 6.691079]
2023-05-28 18:42:31.168: epoch 39:	0.02402681  	0.17825380  	0.09455747  
2023-05-28 18:42:31.168: Find a better model.
2023-05-28 18:42:37.975: [iter 40 : loss : 0.2827 = 0.1038 + 0.1759 + 0.0029, time: 6.806422]
2023-05-28 18:42:38.129: epoch 40:	0.02414677  	0.17906693  	0.09517957  
2023-05-28 18:42:38.129: Find a better model.
2023-05-28 18:42:44.982: [iter 41 : loss : 0.2803 = 0.1018 + 0.1755 + 0.0030, time: 6.850381]
2023-05-28 18:42:45.138: epoch 41:	0.02429495  	0.18000928  	0.09589946  
2023-05-28 18:42:45.138: Find a better model.
2023-05-28 18:42:51.978: [iter 42 : loss : 0.2770 = 0.0990 + 0.1749 + 0.0031, time: 6.839110]
2023-05-28 18:42:52.133: epoch 42:	0.02437257  	0.18037735  	0.09628025  
2023-05-28 18:42:52.133: Find a better model.
2023-05-28 18:42:58.800: [iter 43 : loss : 0.2727 = 0.0951 + 0.1745 + 0.0031, time: 6.666029]
2023-05-28 18:42:58.952: epoch 43:	0.02445019  	0.18053766  	0.09673792  
2023-05-28 18:42:58.952: Find a better model.
2023-05-28 18:43:05.606: [iter 44 : loss : 0.2689 = 0.0918 + 0.1740 + 0.0032, time: 6.653013]
2023-05-28 18:43:05.761: epoch 44:	0.02461249  	0.18205947  	0.09747238  
2023-05-28 18:43:05.761: Find a better model.
2023-05-28 18:43:12.396: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.634009]
2023-05-28 18:43:12.551: epoch 45:	0.02469012  	0.18258721  	0.09812225  
2023-05-28 18:43:12.551: Find a better model.
2023-05-28 18:43:19.180: [iter 46 : loss : 0.2633 = 0.0867 + 0.1732 + 0.0033, time: 6.628004]
2023-05-28 18:43:19.333: epoch 46:	0.02469012  	0.18245828  	0.09840753  
2023-05-28 18:43:25.985: [iter 47 : loss : 0.2619 = 0.0858 + 0.1728 + 0.0034, time: 6.651256]
2023-05-28 18:43:26.141: epoch 47:	0.02481714  	0.18364134  	0.09905311  
2023-05-28 18:43:26.141: Find a better model.
2023-05-28 18:43:32.776: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.634012]
2023-05-28 18:43:32.920: epoch 48:	0.02491592  	0.18440734  	0.09955309  
2023-05-28 18:43:32.920: Find a better model.
2023-05-28 18:43:39.557: [iter 49 : loss : 0.2547 = 0.0791 + 0.1721 + 0.0035, time: 6.635014]
2023-05-28 18:43:39.712: epoch 49:	0.02491592  	0.18407397  	0.09973110  
2023-05-28 18:43:46.210: [iter 50 : loss : 0.2533 = 0.0779 + 0.1718 + 0.0036, time: 6.495000]
2023-05-28 18:43:46.365: epoch 50:	0.02499354  	0.18456900  	0.10026960  
2023-05-28 18:43:46.365: Find a better model.
2023-05-28 18:43:52.975: [iter 51 : loss : 0.2503 = 0.0752 + 0.1715 + 0.0036, time: 6.608001]
2023-05-28 18:43:53.122: epoch 51:	0.02503588  	0.18492042  	0.10065741  
2023-05-28 18:43:53.122: Find a better model.
2023-05-28 18:43:59.766: [iter 52 : loss : 0.2497 = 0.0749 + 0.1711 + 0.0037, time: 6.642025]
2023-05-28 18:43:59.922: epoch 52:	0.02518406  	0.18603538  	0.10132890  
2023-05-28 18:43:59.922: Find a better model.
2023-05-28 18:44:06.373: [iter 53 : loss : 0.2473 = 0.0728 + 0.1708 + 0.0038, time: 6.450006]
2023-05-28 18:44:06.529: epoch 53:	0.02526874  	0.18687075  	0.10181700  
2023-05-28 18:44:06.529: Find a better model.
2023-05-28 18:44:12.978: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.448009]
2023-05-28 18:44:13.133: epoch 54:	0.02533225  	0.18721153  	0.10215355  
2023-05-28 18:44:13.133: Find a better model.
2023-05-28 18:44:19.577: [iter 55 : loss : 0.2432 = 0.0691 + 0.1702 + 0.0039, time: 6.442098]
2023-05-28 18:44:19.729: epoch 55:	0.02533930  	0.18706019  	0.10219377  
2023-05-28 18:44:26.172: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.441005]
2023-05-28 18:44:26.325: epoch 56:	0.02544515  	0.18804905  	0.10278706  
2023-05-28 18:44:26.326: Find a better model.
2023-05-28 18:44:32.794: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.466994]
2023-05-28 18:44:32.949: epoch 57:	0.02551571  	0.18835798  	0.10293701  
2023-05-28 18:44:32.949: Find a better model.
2023-05-28 18:44:39.366: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.416006]
2023-05-28 18:44:39.520: epoch 58:	0.02552277  	0.18864776  	0.10316802  
2023-05-28 18:44:39.521: Find a better model.
2023-05-28 18:44:46.134: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.612000]
2023-05-28 18:44:46.289: epoch 59:	0.02562862  	0.18946125  	0.10358328  
2023-05-28 18:44:46.289: Find a better model.
2023-05-28 18:44:52.764: [iter 60 : loss : 0.2344 = 0.0614 + 0.1689 + 0.0041, time: 6.474027]
2023-05-28 18:44:52.917: epoch 60:	0.02573446  	0.19015287  	0.10389689  
2023-05-28 18:44:52.917: Find a better model.
2023-05-28 18:44:59.352: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.434010]
2023-05-28 18:44:59.506: epoch 61:	0.02578386  	0.19056726  	0.10430671  
2023-05-28 18:44:59.506: Find a better model.
2023-05-28 18:45:05.948: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.441007]
2023-05-28 18:45:06.103: epoch 62:	0.02591793  	0.19171944  	0.10473230  
2023-05-28 18:45:06.103: Find a better model.
2023-05-28 18:45:12.741: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.636234]
2023-05-28 18:45:12.897: epoch 63:	0.02593204  	0.19192429  	0.10494655  
2023-05-28 18:45:12.897: Find a better model.
2023-05-28 18:45:19.341: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0043, time: 6.443151]
2023-05-28 18:45:19.495: epoch 64:	0.02596028  	0.19228688  	0.10530337  
2023-05-28 18:45:19.495: Find a better model.
2023-05-28 18:45:25.953: [iter 65 : loss : 0.2276 = 0.0556 + 0.1677 + 0.0044, time: 6.457011]
2023-05-28 18:45:26.106: epoch 65:	0.02601672  	0.19275469  	0.10568421  
2023-05-28 18:45:26.107: Find a better model.
2023-05-28 18:45:32.739: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.631040]
2023-05-28 18:45:32.893: epoch 66:	0.02605906  	0.19278862  	0.10568578  
2023-05-28 18:45:32.893: Find a better model.
2023-05-28 18:45:39.350: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.455467]
2023-05-28 18:45:39.504: epoch 67:	0.02608728  	0.19301192  	0.10593826  
2023-05-28 18:45:39.505: Find a better model.
2023-05-28 18:45:46.144: [iter 68 : loss : 0.2240 = 0.0524 + 0.1670 + 0.0046, time: 6.638024]
2023-05-28 18:45:46.298: epoch 68:	0.02622136  	0.19368896  	0.10635779  
2023-05-28 18:45:46.298: Find a better model.
2023-05-28 18:45:52.923: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.624054]
2023-05-28 18:45:53.080: epoch 69:	0.02627075  	0.19417898  	0.10649467  
2023-05-28 18:45:53.080: Find a better model.
2023-05-28 18:45:59.570: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.488003]
2023-05-28 18:45:59.724: epoch 70:	0.02630604  	0.19456846  	0.10674424  
2023-05-28 18:45:59.724: Find a better model.
2023-05-28 18:46:06.315: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.590004]
2023-05-28 18:46:06.468: epoch 71:	0.02636249  	0.19503327  	0.10698242  
2023-05-28 18:46:06.468: Find a better model.
2023-05-28 18:46:13.111: [iter 72 : loss : 0.2190 = 0.0479 + 0.1664 + 0.0048, time: 6.642025]
2023-05-28 18:46:13.268: epoch 72:	0.02638366  	0.19508496  	0.10700345  
2023-05-28 18:46:13.268: Find a better model.
2023-05-28 18:46:19.924: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.655023]
2023-05-28 18:46:20.070: epoch 73:	0.02642600  	0.19555302  	0.10709398  
2023-05-28 18:46:20.070: Find a better model.
2023-05-28 18:46:26.727: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.656004]
2023-05-28 18:46:26.881: epoch 74:	0.02646128  	0.19574979  	0.10739667  
2023-05-28 18:46:26.881: Find a better model.
2023-05-28 18:46:33.520: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.638007]
2023-05-28 18:46:33.673: epoch 75:	0.02656007  	0.19670130  	0.10760277  
2023-05-28 18:46:33.673: Find a better model.
2023-05-28 18:46:40.315: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.641020]
2023-05-28 18:46:40.469: epoch 76:	0.02658830  	0.19700566  	0.10770502  
2023-05-28 18:46:40.469: Find a better model.
2023-05-28 18:46:47.094: [iter 77 : loss : 0.2141 = 0.0436 + 0.1655 + 0.0050, time: 6.623012]
2023-05-28 18:46:47.250: epoch 77:	0.02660241  	0.19691770  	0.10764361  
2023-05-28 18:46:53.918: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.666699]
2023-05-28 18:46:54.073: epoch 78:	0.02669415  	0.19762699  	0.10793436  
2023-05-28 18:46:54.073: Find a better model.
2023-05-28 18:47:00.709: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.635034]
2023-05-28 18:47:00.862: epoch 79:	0.02668003  	0.19730759  	0.10799006  
2023-05-28 18:47:07.496: [iter 80 : loss : 0.2113 = 0.0411 + 0.1651 + 0.0051, time: 6.633016]
2023-05-28 18:47:07.650: epoch 80:	0.02666592  	0.19703864  	0.10806374  
2023-05-28 18:47:14.289: [iter 81 : loss : 0.2110 = 0.0409 + 0.1650 + 0.0052, time: 6.638176]
2023-05-28 18:47:14.442: epoch 81:	0.02660241  	0.19650483  	0.10789774  
2023-05-28 18:47:21.084: [iter 82 : loss : 0.2098 = 0.0398 + 0.1648 + 0.0052, time: 6.640994]
2023-05-28 18:47:21.239: epoch 82:	0.02653890  	0.19606633  	0.10787225  
2023-05-28 18:47:27.931: [iter 83 : loss : 0.2090 = 0.0390 + 0.1647 + 0.0053, time: 6.691024]
2023-05-28 18:47:28.088: epoch 83:	0.02654596  	0.19603232  	0.10790433  
2023-05-28 18:47:34.702: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.613018]
2023-05-28 18:47:34.855: epoch 84:	0.02666592  	0.19684875  	0.10815755  
2023-05-28 18:47:41.477: [iter 85 : loss : 0.2080 = 0.0382 + 0.1645 + 0.0053, time: 6.619664]
2023-05-28 18:47:41.631: epoch 85:	0.02672237  	0.19724494  	0.10832337  
2023-05-28 18:47:48.105: [iter 86 : loss : 0.2074 = 0.0378 + 0.1643 + 0.0054, time: 6.473034]
2023-05-28 18:47:48.260: epoch 86:	0.02674355  	0.19744280  	0.10858455  
2023-05-28 18:47:54.884: [iter 87 : loss : 0.2056 = 0.0360 + 0.1642 + 0.0054, time: 6.623043]
2023-05-28 18:47:55.043: epoch 87:	0.02687762  	0.19813158  	0.10881984  
2023-05-28 18:47:55.043: Find a better model.
2023-05-28 18:48:01.491: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.446994]
2023-05-28 18:48:01.636: epoch 88:	0.02680705  	0.19774562  	0.10872193  
2023-05-28 18:48:08.276: [iter 89 : loss : 0.2045 = 0.0350 + 0.1640 + 0.0055, time: 6.638681]
2023-05-28 18:48:08.419: epoch 89:	0.02670826  	0.19703417  	0.10845287  
2023-05-28 18:48:14.898: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.478039]
2023-05-28 18:48:15.058: epoch 90:	0.02679999  	0.19752392  	0.10858572  
2023-05-28 18:48:21.664: [iter 91 : loss : 0.2039 = 0.0346 + 0.1637 + 0.0056, time: 6.605000]
2023-05-28 18:48:21.825: epoch 91:	0.02687056  	0.19780216  	0.10868587  
2023-05-28 18:48:28.461: [iter 92 : loss : 0.2028 = 0.0335 + 0.1637 + 0.0056, time: 6.635000]
2023-05-28 18:48:28.616: epoch 92:	0.02688467  	0.19811770  	0.10883161  
2023-05-28 18:48:35.274: [iter 93 : loss : 0.2033 = 0.0340 + 0.1636 + 0.0057, time: 6.657000]
2023-05-28 18:48:35.417: epoch 93:	0.02686350  	0.19805729  	0.10874438  
2023-05-28 18:48:42.071: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.653008]
2023-05-28 18:48:42.215: epoch 94:	0.02694112  	0.19865941  	0.10910799  
2023-05-28 18:48:42.215: Find a better model.
2023-05-28 18:48:48.866: [iter 95 : loss : 0.2008 = 0.0317 + 0.1634 + 0.0058, time: 6.649004]
2023-05-28 18:48:49.024: epoch 95:	0.02690584  	0.19843571  	0.10908110  
2023-05-28 18:48:55.501: [iter 96 : loss : 0.2009 = 0.0318 + 0.1633 + 0.0058, time: 6.475997]
2023-05-28 18:48:55.655: epoch 96:	0.02689173  	0.19812019  	0.10896569  
2023-05-28 18:49:02.267: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0058, time: 6.611326]
2023-05-28 18:49:02.425: epoch 97:	0.02690583  	0.19816490  	0.10922033  
2023-05-28 18:49:09.041: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.615046]
2023-05-28 18:49:09.198: epoch 98:	0.02691996  	0.19842516  	0.10933039  
2023-05-28 18:49:15.866: [iter 99 : loss : 0.1991 = 0.0301 + 0.1630 + 0.0059, time: 6.667111]
2023-05-28 18:49:16.023: epoch 99:	0.02703991  	0.19926874  	0.10960153  
2023-05-28 18:49:16.024: Find a better model.
2023-05-28 18:49:22.466: [iter 100 : loss : 0.1987 = 0.0299 + 0.1629 + 0.0060, time: 6.441005]
2023-05-28 18:49:22.622: epoch 100:	0.02706108  	0.19927408  	0.10965916  
2023-05-28 18:49:22.622: Find a better model.
2023-05-28 18:49:29.076: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.453004]
2023-05-28 18:49:29.232: epoch 101:	0.02703990  	0.19900820  	0.10949749  
2023-05-28 18:49:35.842: [iter 102 : loss : 0.1975 = 0.0287 + 0.1628 + 0.0060, time: 6.609000]
2023-05-28 18:49:35.984: epoch 102:	0.02709635  	0.19917314  	0.10960772  
2023-05-28 18:49:42.471: [iter 103 : loss : 0.1973 = 0.0286 + 0.1626 + 0.0061, time: 6.486019]
2023-05-28 18:49:42.627: epoch 103:	0.02710341  	0.19946577  	0.10977890  
2023-05-28 18:49:42.627: Find a better model.
2023-05-28 18:49:49.247: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.618511]
2023-05-28 18:49:49.404: epoch 104:	0.02708930  	0.19958752  	0.10983873  
2023-05-28 18:49:49.404: Find a better model.
2023-05-28 18:49:56.048: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.643570]
2023-05-28 18:49:56.203: epoch 105:	0.02701874  	0.19939336  	0.10979553  
2023-05-28 18:50:02.850: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.646000]
2023-05-28 18:50:03.011: epoch 106:	0.02702579  	0.19952334  	0.10985466  
2023-05-28 18:50:09.833: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.820487]
2023-05-28 18:50:09.989: epoch 107:	0.02706813  	0.19988637  	0.11013897  
2023-05-28 18:50:09.989: Find a better model.
2023-05-28 18:50:16.443: [iter 108 : loss : 0.1955 = 0.0268 + 0.1624 + 0.0063, time: 6.453391]
2023-05-28 18:50:16.598: epoch 108:	0.02703991  	0.19965692  	0.10999133  
2023-05-28 18:50:23.071: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.472012]
2023-05-28 18:50:23.227: epoch 109:	0.02703285  	0.19971980  	0.10990158  
2023-05-28 18:50:29.819: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.590248]
2023-05-28 18:50:29.962: epoch 110:	0.02701874  	0.19988388  	0.10998959  
2023-05-28 18:50:36.447: [iter 111 : loss : 0.1939 = 0.0254 + 0.1621 + 0.0064, time: 6.484332]
2023-05-28 18:50:36.602: epoch 111:	0.02701168  	0.19936205  	0.10986938  
2023-05-28 18:50:43.220: [iter 112 : loss : 0.1937 = 0.0252 + 0.1620 + 0.0064, time: 6.617013]
2023-05-28 18:50:43.375: epoch 112:	0.02700462  	0.19904393  	0.10977869  
2023-05-28 18:50:50.015: [iter 113 : loss : 0.1937 = 0.0252 + 0.1620 + 0.0065, time: 6.639404]
2023-05-28 18:50:50.173: epoch 113:	0.02704696  	0.19934623  	0.10981185  
2023-05-28 18:50:56.638: [iter 114 : loss : 0.1929 = 0.0245 + 0.1619 + 0.0065, time: 6.463003]
2023-05-28 18:50:56.793: epoch 114:	0.02711047  	0.19958489  	0.10995792  
2023-05-28 18:51:03.257: [iter 115 : loss : 0.1928 = 0.0244 + 0.1618 + 0.0065, time: 6.463062]
2023-05-28 18:51:03.412: epoch 115:	0.02706107  	0.19924678  	0.10985100  
2023-05-28 18:51:10.002: [iter 116 : loss : 0.1921 = 0.0237 + 0.1618 + 0.0066, time: 6.588014]
2023-05-28 18:51:10.155: epoch 116:	0.02703284  	0.19888866  	0.11001915  
2023-05-28 18:51:16.810: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.653529]
2023-05-28 18:51:16.968: epoch 117:	0.02699050  	0.19892195  	0.10985369  
2023-05-28 18:51:23.432: [iter 118 : loss : 0.1918 = 0.0235 + 0.1616 + 0.0066, time: 6.463096]
2023-05-28 18:51:23.587: epoch 118:	0.02699050  	0.19846413  	0.10973787  
2023-05-28 18:51:30.197: [iter 119 : loss : 0.1911 = 0.0228 + 0.1616 + 0.0067, time: 6.608014]
2023-05-28 18:51:30.346: epoch 119:	0.02706812  	0.19918226  	0.10988447  
2023-05-28 18:51:36.991: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.644006]
2023-05-28 18:51:37.148: epoch 120:	0.02698345  	0.19834571  	0.10985730  
2023-05-28 18:51:43.624: [iter 121 : loss : 0.1911 = 0.0230 + 0.1615 + 0.0067, time: 6.475003]
2023-05-28 18:51:43.781: epoch 121:	0.02701167  	0.19857134  	0.10989974  
2023-05-28 18:51:50.243: [iter 122 : loss : 0.1906 = 0.0225 + 0.1614 + 0.0068, time: 6.461057]
2023-05-28 18:51:50.399: epoch 122:	0.02694111  	0.19796552  	0.10976306  
2023-05-28 18:51:57.014: [iter 123 : loss : 0.1905 = 0.0223 + 0.1614 + 0.0068, time: 6.613008]
2023-05-28 18:51:57.169: epoch 123:	0.02695522  	0.19790168  	0.10978401  
2023-05-28 18:52:03.780: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.610021]
2023-05-28 18:52:03.923: epoch 124:	0.02702578  	0.19849502  	0.10997903  
2023-05-28 18:52:10.423: [iter 125 : loss : 0.1892 = 0.0211 + 0.1613 + 0.0069, time: 6.497994]
2023-05-28 18:52:10.578: epoch 125:	0.02702578  	0.19851157  	0.11002082  
2023-05-28 18:52:17.200: [iter 126 : loss : 0.1894 = 0.0213 + 0.1612 + 0.0069, time: 6.621004]
2023-05-28 18:52:17.356: epoch 126:	0.02694111  	0.19830534  	0.10998055  
2023-05-28 18:52:23.995: [iter 127 : loss : 0.1886 = 0.0205 + 0.1612 + 0.0069, time: 6.638009]
2023-05-28 18:52:24.152: epoch 127:	0.02690583  	0.19791926  	0.10994755  
2023-05-28 18:52:30.779: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.626002]
2023-05-28 18:52:30.921: epoch 128:	0.02694816  	0.19809753  	0.10989174  
2023-05-28 18:52:37.390: [iter 129 : loss : 0.1886 = 0.0205 + 0.1611 + 0.0070, time: 6.467999]
2023-05-28 18:52:37.544: epoch 129:	0.02694110  	0.19789548  	0.10979701  
2023-05-28 18:52:44.170: [iter 130 : loss : 0.1887 = 0.0207 + 0.1610 + 0.0070, time: 6.625251]
2023-05-28 18:52:44.326: epoch 130:	0.02688465  	0.19765732  	0.10978940  
2023-05-28 18:52:50.811: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0070, time: 6.484051]
2023-05-28 18:52:50.968: epoch 131:	0.02695522  	0.19816163  	0.10990453  
2023-05-28 18:52:57.571: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.602009]
2023-05-28 18:52:57.731: epoch 132:	0.02690583  	0.19783543  	0.10991339  
2023-05-28 18:52:57.731: Early stopping is trigger at epoch: 132
2023-05-28 18:52:57.731: best_result@epoch 107:

2023-05-28 18:52:57.731: 		0.0271      	0.1999      	0.1101      
2023-05-28 18:55:07.603: my pid: 15960
2023-05-28 18:55:07.603: model: model.general_recommender.SGL
2023-05-28 18:55:07.603: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 18:55:07.603: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 18:55:11.276: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 18:55:18.675: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.398205]
2023-05-28 18:55:18.834: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-28 18:55:18.834: Find a better model.
2023-05-28 18:55:26.347: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.511544]
2023-05-28 18:55:26.532: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-28 18:55:26.532: Find a better model.
2023-05-28 18:55:34.078: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.543667]
2023-05-28 18:55:34.246: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-28 18:55:34.246: Find a better model.
2023-05-28 18:55:41.700: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.453024]
2023-05-28 18:55:41.889: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-28 18:55:41.890: Find a better model.
2023-05-28 18:55:49.191: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.299657]
2023-05-28 18:55:49.346: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-28 18:55:49.346: Find a better model.
2023-05-28 18:55:56.602: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 7.255079]
2023-05-28 18:55:56.749: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-28 18:55:56.749: Find a better model.
2023-05-28 18:56:04.126: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 7.374886]
2023-05-28 18:56:04.288: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-28 18:56:04.288: Find a better model.
2023-05-28 18:56:11.199: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.907762]
2023-05-28 18:56:11.361: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-28 18:56:11.361: Find a better model.
2023-05-28 18:56:18.299: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.935247]
2023-05-28 18:56:18.456: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-28 18:56:18.457: Find a better model.
2023-05-28 18:56:25.207: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.749047]
2023-05-28 18:56:25.379: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-28 18:56:25.379: Find a better model.
2023-05-28 18:56:32.098: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.717070]
2023-05-28 18:56:32.241: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-28 18:56:32.242: Find a better model.
2023-05-28 18:56:38.730: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.487034]
2023-05-28 18:56:38.886: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-28 18:56:38.886: Find a better model.
2023-05-28 18:56:45.482: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.595038]
2023-05-28 18:56:45.625: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-28 18:56:45.625: Find a better model.
2023-05-28 18:56:52.294: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.668023]
2023-05-28 18:56:52.450: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-28 18:56:52.450: Find a better model.
2023-05-28 18:56:59.092: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.641045]
2023-05-28 18:56:59.235: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-28 18:56:59.236: Find a better model.
2023-05-28 18:57:05.710: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.473016]
2023-05-28 18:57:05.882: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-28 18:57:05.882: Find a better model.
2023-05-28 18:57:12.505: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.622016]
2023-05-28 18:57:12.663: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-28 18:57:12.663: Find a better model.
2023-05-28 18:57:19.320: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.655341]
2023-05-28 18:57:19.475: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-28 18:57:19.475: Find a better model.
2023-05-28 18:57:26.107: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.631035]
2023-05-28 18:57:26.252: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-28 18:57:26.252: Find a better model.
2023-05-28 18:57:32.706: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.452026]
2023-05-28 18:57:32.862: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-28 18:57:32.862: Find a better model.
2023-05-28 18:57:39.495: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.631029]
2023-05-28 18:57:39.650: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-28 18:57:39.650: Find a better model.
2023-05-28 18:57:46.282: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.631006]
2023-05-28 18:57:46.427: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-28 18:57:46.427: Find a better model.
2023-05-28 18:57:53.072: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.643013]
2023-05-28 18:57:53.227: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-28 18:57:53.227: Find a better model.
2023-05-28 18:57:59.883: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.655005]
2023-05-28 18:58:00.048: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-28 18:58:00.048: Find a better model.
2023-05-28 18:58:06.494: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.444237]
2023-05-28 18:58:06.650: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-28 18:58:06.650: Find a better model.
2023-05-28 18:58:13.300: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.646981]
2023-05-28 18:58:13.456: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-28 18:58:13.456: Find a better model.
2023-05-28 18:58:20.056: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.599013]
2023-05-28 18:58:20.212: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-28 18:58:20.212: Find a better model.
2023-05-28 18:58:26.687: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.474333]
2023-05-28 18:58:26.843: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-28 18:58:26.843: Find a better model.
2023-05-28 18:58:33.271: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.426007]
2023-05-28 18:58:33.415: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-28 18:58:33.415: Find a better model.
2023-05-28 18:58:39.867: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.451005]
2023-05-28 18:58:40.023: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-28 18:58:40.023: Find a better model.
2023-05-28 18:58:46.666: [iter 31 : loss : 0.4379 = 0.1715 + 0.2645 + 0.0020, time: 6.641993]
2023-05-28 18:58:46.810: epoch 31:	0.02313064  	0.17116277  	0.08934029  
2023-05-28 18:58:46.810: Find a better model.
2023-05-28 18:58:53.455: [iter 32 : loss : 0.4273 = 0.1616 + 0.2636 + 0.0021, time: 6.644014]
2023-05-28 18:58:53.598: epoch 32:	0.02339878  	0.17325784  	0.09053610  
2023-05-28 18:58:53.598: Find a better model.
2023-05-28 18:59:00.261: [iter 33 : loss : 0.4192 = 0.1543 + 0.2628 + 0.0022, time: 6.661032]
2023-05-28 18:59:00.407: epoch 33:	0.02344817  	0.17374352  	0.09125193  
2023-05-28 18:59:00.407: Find a better model.
2023-05-28 18:59:07.089: [iter 34 : loss : 0.4110 = 0.1468 + 0.2619 + 0.0023, time: 6.681013]
2023-05-28 18:59:07.244: epoch 34:	0.02363164  	0.17507116  	0.09215519  
2023-05-28 18:59:07.244: Find a better model.
2023-05-28 18:59:13.863: [iter 35 : loss : 0.4036 = 0.1401 + 0.2612 + 0.0024, time: 6.618091]
2023-05-28 18:59:14.007: epoch 35:	0.02375159  	0.17583299  	0.09308629  
2023-05-28 18:59:14.008: Find a better model.
2023-05-28 18:59:20.666: [iter 36 : loss : 0.3971 = 0.1342 + 0.2604 + 0.0025, time: 6.657007]
2023-05-28 18:59:20.822: epoch 36:	0.02397740  	0.17773336  	0.09405097  
2023-05-28 18:59:20.822: Find a better model.
2023-05-28 18:59:27.493: [iter 37 : loss : 0.3900 = 0.1279 + 0.2596 + 0.0026, time: 6.669038]
2023-05-28 18:59:27.649: epoch 37:	0.02409030  	0.17880903  	0.09484430  
2023-05-28 18:59:27.649: Find a better model.
2023-05-28 18:59:34.442: [iter 38 : loss : 0.3856 = 0.1240 + 0.2589 + 0.0026, time: 6.792011]
2023-05-28 18:59:34.599: epoch 38:	0.02423850  	0.18011594  	0.09577531  
2023-05-28 18:59:34.599: Find a better model.
2023-05-28 18:59:41.260: [iter 39 : loss : 0.3788 = 0.1179 + 0.2582 + 0.0027, time: 6.659514]
2023-05-28 18:59:41.419: epoch 39:	0.02444313  	0.18158896  	0.09670579  
2023-05-28 18:59:41.419: Find a better model.
2023-05-28 18:59:48.049: [iter 40 : loss : 0.3735 = 0.1133 + 0.2574 + 0.0028, time: 6.629011]
2023-05-28 18:59:48.192: epoch 40:	0.02453487  	0.18176064  	0.09724715  
2023-05-28 18:59:48.192: Find a better model.
2023-05-28 18:59:54.854: [iter 41 : loss : 0.3699 = 0.1101 + 0.2569 + 0.0029, time: 6.660002]
2023-05-28 18:59:55.010: epoch 41:	0.02464072  	0.18227881  	0.09768538  
2023-05-28 18:59:55.010: Find a better model.
2023-05-28 19:00:01.664: [iter 42 : loss : 0.3652 = 0.1061 + 0.2561 + 0.0030, time: 6.653008]
2023-05-28 19:00:01.822: epoch 42:	0.02475363  	0.18301225  	0.09845174  
2023-05-28 19:00:01.822: Find a better model.
2023-05-28 19:00:08.639: [iter 43 : loss : 0.3602 = 0.1017 + 0.2555 + 0.0030, time: 6.816077]
2023-05-28 19:00:08.795: epoch 43:	0.02488770  	0.18424600  	0.09910753  
2023-05-28 19:00:08.795: Find a better model.
2023-05-28 19:00:15.478: [iter 44 : loss : 0.3556 = 0.0977 + 0.2548 + 0.0031, time: 6.682007]
2023-05-28 19:00:15.634: epoch 44:	0.02507116  	0.18574898  	0.09978049  
2023-05-28 19:00:15.634: Find a better model.
2023-05-28 19:00:22.428: [iter 45 : loss : 0.3516 = 0.0940 + 0.2544 + 0.0032, time: 6.793060]
2023-05-28 19:00:22.584: epoch 45:	0.02516290  	0.18649478  	0.10036256  
2023-05-28 19:00:22.585: Find a better model.
2023-05-28 19:00:29.247: [iter 46 : loss : 0.3484 = 0.0913 + 0.2538 + 0.0033, time: 6.661102]
2023-05-28 19:00:29.422: epoch 46:	0.02521935  	0.18687713  	0.10062297  
2023-05-28 19:00:29.422: Find a better model.
2023-05-28 19:00:36.031: [iter 47 : loss : 0.3462 = 0.0896 + 0.2533 + 0.0033, time: 6.606395]
2023-05-28 19:00:36.176: epoch 47:	0.02526169  	0.18714686  	0.10097364  
2023-05-28 19:00:36.176: Find a better model.
2023-05-28 19:00:42.847: [iter 48 : loss : 0.3418 = 0.0855 + 0.2528 + 0.0034, time: 6.669112]
2023-05-28 19:00:43.002: epoch 48:	0.02533226  	0.18783253  	0.10144319  
2023-05-28 19:00:43.002: Find a better model.
2023-05-28 19:00:49.635: [iter 49 : loss : 0.3380 = 0.0822 + 0.2524 + 0.0035, time: 6.631033]
2023-05-28 19:00:49.789: epoch 49:	0.02538871  	0.18801226  	0.10196733  
2023-05-28 19:00:49.789: Find a better model.
2023-05-28 19:00:56.460: [iter 50 : loss : 0.3359 = 0.0804 + 0.2519 + 0.0036, time: 6.669054]
2023-05-28 19:00:56.615: epoch 50:	0.02550161  	0.18871351  	0.10243879  
2023-05-28 19:00:56.615: Find a better model.
2023-05-28 19:01:03.221: [iter 51 : loss : 0.3325 = 0.0774 + 0.2516 + 0.0036, time: 6.604036]
2023-05-28 19:01:03.367: epoch 51:	0.02560746  	0.18936093  	0.10288253  
2023-05-28 19:01:03.367: Find a better model.
2023-05-28 19:01:10.197: [iter 52 : loss : 0.3313 = 0.0765 + 0.2511 + 0.0037, time: 6.829049]
2023-05-28 19:01:10.343: epoch 52:	0.02578386  	0.19064052  	0.10380208  
2023-05-28 19:01:10.343: Find a better model.
2023-05-28 19:01:17.027: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.683312]
2023-05-28 19:01:17.182: epoch 53:	0.02587560  	0.19149543  	0.10430879  
2023-05-28 19:01:17.182: Find a better model.
2023-05-28 19:01:23.809: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.625994]
2023-05-28 19:01:23.964: epoch 54:	0.02588971  	0.19184537  	0.10463808  
2023-05-28 19:01:23.964: Find a better model.
2023-05-28 19:01:30.604: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.638994]
2023-05-28 19:01:30.759: epoch 55:	0.02591793  	0.19216667  	0.10476056  
2023-05-28 19:01:30.759: Find a better model.
2023-05-28 19:01:37.408: [iter 56 : loss : 0.3210 = 0.0676 + 0.2495 + 0.0039, time: 6.647994]
2023-05-28 19:01:37.562: epoch 56:	0.02596027  	0.19203646  	0.10509688  
2023-05-28 19:01:44.232: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.668993]
2023-05-28 19:01:44.377: epoch 57:	0.02594616  	0.19203518  	0.10513464  
2023-05-28 19:01:50.826: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.447096]
2023-05-28 19:01:50.983: epoch 58:	0.02608729  	0.19311586  	0.10579136  
2023-05-28 19:01:50.983: Find a better model.
2023-05-28 19:01:57.586: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.601994]
2023-05-28 19:01:57.742: epoch 59:	0.02612257  	0.19351500  	0.10597168  
2023-05-28 19:01:57.742: Find a better model.
2023-05-28 19:02:04.386: [iter 60 : loss : 0.3136 = 0.0611 + 0.2482 + 0.0042, time: 6.642995]
2023-05-28 19:02:04.529: epoch 60:	0.02618608  	0.19382532  	0.10627364  
2023-05-28 19:02:04.530: Find a better model.
2023-05-28 19:02:11.191: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.660263]
2023-05-28 19:02:11.351: epoch 61:	0.02621430  	0.19445413  	0.10646302  
2023-05-28 19:02:11.351: Find a better model.
2023-05-28 19:02:18.004: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.650994]
2023-05-28 19:02:18.147: epoch 62:	0.02617197  	0.19411556  	0.10655409  
2023-05-28 19:02:24.795: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.646994]
2023-05-28 19:02:24.951: epoch 63:	0.02621430  	0.19435297  	0.10672376  
2023-05-28 19:02:31.600: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.648075]
2023-05-28 19:02:31.755: epoch 64:	0.02620725  	0.19443658  	0.10694608  
2023-05-28 19:02:38.382: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.624770]
2023-05-28 19:02:38.538: epoch 65:	0.02624958  	0.19445434  	0.10703045  
2023-05-28 19:02:38.539: Find a better model.
2023-05-28 19:02:45.171: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.631062]
2023-05-28 19:02:45.318: epoch 66:	0.02632721  	0.19524233  	0.10723274  
2023-05-28 19:02:45.319: Find a better model.
2023-05-28 19:02:51.792: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.471036]
2023-05-28 19:02:51.935: epoch 67:	0.02634132  	0.19505978  	0.10725378  
2023-05-28 19:02:58.392: [iter 68 : loss : 0.3016 = 0.0509 + 0.2460 + 0.0047, time: 6.455002]
2023-05-28 19:02:58.547: epoch 68:	0.02646128  	0.19584237  	0.10764252  
2023-05-28 19:02:58.547: Find a better model.
2023-05-28 19:03:05.167: [iter 69 : loss : 0.2999 = 0.0493 + 0.2458 + 0.0047, time: 6.618008]
2023-05-28 19:03:05.314: epoch 69:	0.02653890  	0.19628012  	0.10778995  
2023-05-28 19:03:05.314: Find a better model.
2023-05-28 19:03:11.820: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.504027]
2023-05-28 19:03:11.977: epoch 70:	0.02666592  	0.19725598  	0.10821562  
2023-05-28 19:03:11.978: Find a better model.
2023-05-28 19:03:18.560: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.579993]
2023-05-28 19:03:18.714: epoch 71:	0.02657419  	0.19652234  	0.10799598  
2023-05-28 19:03:25.361: [iter 72 : loss : 0.2963 = 0.0462 + 0.2452 + 0.0049, time: 6.645011]
2023-05-28 19:03:25.517: epoch 72:	0.02658124  	0.19669552  	0.10808378  
2023-05-28 19:03:32.170: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.651581]
2023-05-28 19:03:32.331: epoch 73:	0.02660241  	0.19668958  	0.10819595  
2023-05-28 19:03:38.971: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.637994]
2023-05-28 19:03:39.115: epoch 74:	0.02665886  	0.19680710  	0.10846632  
2023-05-28 19:03:45.585: [iter 75 : loss : 0.2930 = 0.0434 + 0.2446 + 0.0050, time: 6.469003]
2023-05-28 19:03:45.741: epoch 75:	0.02665180  	0.19693285  	0.10859542  
2023-05-28 19:03:52.380: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.637994]
2023-05-28 19:03:52.537: epoch 76:	0.02673648  	0.19749659  	0.10886959  
2023-05-28 19:03:52.537: Find a better model.
2023-05-28 19:03:59.156: [iter 77 : loss : 0.2910 = 0.0417 + 0.2442 + 0.0051, time: 6.617993]
2023-05-28 19:03:59.301: epoch 77:	0.02663769  	0.19711173  	0.10871462  
2023-05-28 19:04:05.774: [iter 78 : loss : 0.2904 = 0.0411 + 0.2441 + 0.0052, time: 6.471993]
2023-05-28 19:04:05.931: epoch 78:	0.02662358  	0.19707178  	0.10860588  
2023-05-28 19:04:12.563: [iter 79 : loss : 0.2889 = 0.0398 + 0.2439 + 0.0052, time: 6.630993]
2023-05-28 19:04:12.720: epoch 79:	0.02662358  	0.19709419  	0.10881768  
2023-05-28 19:04:19.363: [iter 80 : loss : 0.2882 = 0.0391 + 0.2438 + 0.0053, time: 6.640993]
2023-05-28 19:04:19.517: epoch 80:	0.02660947  	0.19665536  	0.10910086  
2023-05-28 19:04:26.162: [iter 81 : loss : 0.2877 = 0.0388 + 0.2436 + 0.0053, time: 6.642994]
2023-05-28 19:04:26.323: epoch 81:	0.02661652  	0.19639105  	0.10883600  
2023-05-28 19:04:32.934: [iter 82 : loss : 0.2866 = 0.0378 + 0.2435 + 0.0054, time: 6.609993]
2023-05-28 19:04:33.090: epoch 82:	0.02663769  	0.19630910  	0.10891740  
2023-05-28 19:04:39.748: [iter 83 : loss : 0.2856 = 0.0368 + 0.2433 + 0.0054, time: 6.657038]
2023-05-28 19:04:39.906: epoch 83:	0.02674353  	0.19706015  	0.10920392  
2023-05-28 19:04:46.530: [iter 84 : loss : 0.2855 = 0.0368 + 0.2432 + 0.0055, time: 6.623333]
2023-05-28 19:04:46.687: epoch 84:	0.02667297  	0.19663978  	0.10920135  
2023-05-28 19:04:53.328: [iter 85 : loss : 0.2847 = 0.0361 + 0.2430 + 0.0055, time: 6.638437]
2023-05-28 19:04:53.483: epoch 85:	0.02667297  	0.19643275  	0.10901652  
2023-05-28 19:05:00.135: [iter 86 : loss : 0.2839 = 0.0355 + 0.2428 + 0.0056, time: 6.650033]
2023-05-28 19:05:00.278: epoch 86:	0.02675764  	0.19684720  	0.10929873  
2023-05-28 19:05:06.941: [iter 87 : loss : 0.2824 = 0.0340 + 0.2428 + 0.0056, time: 6.662017]
2023-05-28 19:05:07.097: epoch 87:	0.02674353  	0.19674136  	0.10916658  
2023-05-28 19:05:13.734: [iter 88 : loss : 0.2817 = 0.0334 + 0.2426 + 0.0057, time: 6.636023]
2023-05-28 19:05:13.891: epoch 88:	0.02682116  	0.19774212  	0.10941640  
2023-05-28 19:05:13.891: Find a better model.
2023-05-28 19:05:20.524: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.632057]
2023-05-28 19:05:20.682: epoch 89:	0.02682822  	0.19769515  	0.10937427  
2023-05-28 19:05:27.330: [iter 90 : loss : 0.2812 = 0.0331 + 0.2424 + 0.0058, time: 6.645033]
2023-05-28 19:05:27.489: epoch 90:	0.02675765  	0.19691512  	0.10940129  
2023-05-28 19:05:34.121: [iter 91 : loss : 0.2804 = 0.0324 + 0.2422 + 0.0058, time: 6.631005]
2023-05-28 19:05:34.279: epoch 91:	0.02679293  	0.19707732  	0.10937522  
2023-05-28 19:05:40.924: [iter 92 : loss : 0.2794 = 0.0314 + 0.2422 + 0.0059, time: 6.644007]
2023-05-28 19:05:41.080: epoch 92:	0.02682822  	0.19739769  	0.10950483  
2023-05-28 19:05:47.725: [iter 93 : loss : 0.2796 = 0.0317 + 0.2420 + 0.0059, time: 6.642001]
2023-05-28 19:05:47.881: epoch 93:	0.02684939  	0.19732629  	0.10939693  
2023-05-28 19:05:54.521: [iter 94 : loss : 0.2782 = 0.0303 + 0.2419 + 0.0059, time: 6.638116]
2023-05-28 19:05:54.679: epoch 94:	0.02688467  	0.19735798  	0.10943636  
2023-05-28 19:06:01.321: [iter 95 : loss : 0.2774 = 0.0295 + 0.2418 + 0.0060, time: 6.641011]
2023-05-28 19:06:01.478: epoch 95:	0.02691995  	0.19755697  	0.10963143  
2023-05-28 19:06:08.138: [iter 96 : loss : 0.2774 = 0.0296 + 0.2417 + 0.0060, time: 6.659030]
2023-05-28 19:06:08.297: epoch 96:	0.02689878  	0.19737956  	0.10962166  
2023-05-28 19:06:14.906: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.608010]
2023-05-28 19:06:15.064: epoch 97:	0.02697639  	0.19801809  	0.10961242  
2023-05-28 19:06:15.064: Find a better model.
2023-05-28 19:06:21.508: [iter 98 : loss : 0.2762 = 0.0286 + 0.2415 + 0.0061, time: 6.442080]
2023-05-28 19:06:21.652: epoch 98:	0.02696934  	0.19799897  	0.10967955  
2023-05-28 19:06:28.290: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.636049]
2023-05-28 19:06:28.434: epoch 99:	0.02706107  	0.19858561  	0.10992822  
2023-05-28 19:06:28.434: Find a better model.
2023-05-28 19:06:35.107: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.672004]
2023-05-28 19:06:35.264: epoch 100:	0.02703990  	0.19863503  	0.11002906  
2023-05-28 19:06:35.264: Find a better model.
2023-05-28 19:06:41.725: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0062, time: 6.459014]
2023-05-28 19:06:41.882: epoch 101:	0.02698345  	0.19811317  	0.10999906  
2023-05-28 19:06:48.499: [iter 102 : loss : 0.2740 = 0.0266 + 0.2411 + 0.0063, time: 6.616003]
2023-05-28 19:06:48.656: epoch 102:	0.02700462  	0.19823091  	0.11009389  
2023-05-28 19:06:55.288: [iter 103 : loss : 0.2738 = 0.0265 + 0.2410 + 0.0063, time: 6.631013]
2023-05-28 19:06:55.447: epoch 103:	0.02693405  	0.19778042  	0.11007858  
2023-05-28 19:07:02.092: [iter 104 : loss : 0.2739 = 0.0266 + 0.2410 + 0.0064, time: 6.644014]
2023-05-28 19:07:02.249: epoch 104:	0.02694817  	0.19796225  	0.11001620  
2023-05-28 19:07:08.701: [iter 105 : loss : 0.2734 = 0.0261 + 0.2409 + 0.0064, time: 6.451033]
2023-05-28 19:07:08.859: epoch 105:	0.02694817  	0.19790217  	0.11010819  
2023-05-28 19:07:15.478: [iter 106 : loss : 0.2729 = 0.0256 + 0.2408 + 0.0064, time: 6.617050]
2023-05-28 19:07:15.633: epoch 106:	0.02694111  	0.19782053  	0.11000481  
2023-05-28 19:07:22.301: [iter 107 : loss : 0.2722 = 0.0250 + 0.2407 + 0.0065, time: 6.667003]
2023-05-28 19:07:22.460: epoch 107:	0.02697639  	0.19808489  	0.11020306  
2023-05-28 19:07:28.903: [iter 108 : loss : 0.2719 = 0.0246 + 0.2407 + 0.0065, time: 6.442003]
2023-05-28 19:07:29.059: epoch 108:	0.02695522  	0.19813961  	0.11019482  
2023-05-28 19:07:35.520: [iter 109 : loss : 0.2710 = 0.0239 + 0.2405 + 0.0066, time: 6.460005]
2023-05-28 19:07:35.678: epoch 109:	0.02696933  	0.19854310  	0.11025995  
2023-05-28 19:07:42.274: [iter 110 : loss : 0.2708 = 0.0237 + 0.2405 + 0.0066, time: 6.594911]
2023-05-28 19:07:42.434: epoch 110:	0.02694816  	0.19837235  	0.11031604  
2023-05-28 19:07:49.059: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.624027]
2023-05-28 19:07:49.215: epoch 111:	0.02694111  	0.19812408  	0.11026719  
2023-05-28 19:07:55.705: [iter 112 : loss : 0.2702 = 0.0232 + 0.2404 + 0.0067, time: 6.489186]
2023-05-28 19:07:55.858: epoch 112:	0.02684938  	0.19749011  	0.11002108  
2023-05-28 19:08:02.482: [iter 113 : loss : 0.2702 = 0.0232 + 0.2403 + 0.0067, time: 6.622911]
2023-05-28 19:08:02.639: epoch 113:	0.02685643  	0.19742018  	0.10997601  
2023-05-28 19:08:09.260: [iter 114 : loss : 0.2694 = 0.0225 + 0.2402 + 0.0068, time: 6.619994]
2023-05-28 19:08:09.418: epoch 114:	0.02687054  	0.19736768  	0.10995941  
2023-05-28 19:08:15.906: [iter 115 : loss : 0.2693 = 0.0223 + 0.2401 + 0.0068, time: 6.487010]
2023-05-28 19:08:16.061: epoch 115:	0.02691994  	0.19803347  	0.11008638  
2023-05-28 19:08:22.489: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.426003]
2023-05-28 19:08:22.645: epoch 116:	0.02681409  	0.19698760  	0.10983852  
2023-05-28 19:08:29.068: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.422004]
2023-05-28 19:08:29.214: epoch 117:	0.02677881  	0.19627880  	0.10962930  
2023-05-28 19:08:35.677: [iter 118 : loss : 0.2683 = 0.0215 + 0.2399 + 0.0069, time: 6.461016]
2023-05-28 19:08:35.832: epoch 118:	0.02674352  	0.19624522  	0.10974567  
2023-05-28 19:08:42.454: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.620994]
2023-05-28 19:08:42.607: epoch 119:	0.02679998  	0.19652106  	0.10981203  
2023-05-28 19:08:49.258: [iter 120 : loss : 0.2679 = 0.0211 + 0.2398 + 0.0070, time: 6.650062]
2023-05-28 19:08:49.403: epoch 120:	0.02680703  	0.19622447  	0.10973178  
2023-05-28 19:08:56.049: [iter 121 : loss : 0.2677 = 0.0210 + 0.2397 + 0.0070, time: 6.645061]
2023-05-28 19:08:56.205: epoch 121:	0.02682115  	0.19618192  	0.10972864  
2023-05-28 19:09:02.679: [iter 122 : loss : 0.2672 = 0.0205 + 0.2397 + 0.0070, time: 6.473017]
2023-05-28 19:09:02.835: epoch 122:	0.02675058  	0.19565329  	0.10964023  
2023-05-28 19:09:09.439: [iter 123 : loss : 0.2671 = 0.0204 + 0.2396 + 0.0071, time: 6.602932]
2023-05-28 19:09:09.596: epoch 123:	0.02675764  	0.19567798  	0.10972660  
2023-05-28 19:09:16.062: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.465094]
2023-05-28 19:09:16.217: epoch 124:	0.02670119  	0.19514880  	0.10957295  
2023-05-28 19:09:22.663: [iter 125 : loss : 0.2660 = 0.0193 + 0.2395 + 0.0071, time: 6.445024]
2023-05-28 19:09:22.818: epoch 125:	0.02677881  	0.19580549  	0.10964160  
2023-05-28 19:09:22.818: Early stopping is trigger at epoch: 125
2023-05-28 19:09:22.818: best_result@epoch 100:

2023-05-28 19:09:22.818: 		0.0270      	0.1986      	0.1100      
2023-05-28 19:13:10.955: my pid: 9784
2023-05-28 19:13:10.955: model: model.general_recommender.SGL
2023-05-28 19:13:10.955: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 19:13:10.955: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.04
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 19:13:14.744: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 19:13:22.250: [iter 1 : loss : 1.0070 = 0.6930 + 0.3140 + 0.0000, time: 7.506027]
2023-05-28 19:13:22.403: epoch 1:	0.00148180  	0.01007288  	0.00518638  
2023-05-28 19:13:22.403: Find a better model.
2023-05-28 19:13:30.067: [iter 2 : loss : 1.0056 = 0.6929 + 0.3127 + 0.0000, time: 7.660356]
2023-05-28 19:13:30.262: epoch 2:	0.00215214  	0.01506323  	0.00759623  
2023-05-28 19:13:30.262: Find a better model.
2023-05-28 19:13:37.732: [iter 3 : loss : 1.0053 = 0.6928 + 0.3125 + 0.0000, time: 7.468287]
2023-05-28 19:13:37.917: epoch 3:	0.00323877  	0.02255323  	0.01167415  
2023-05-28 19:13:37.918: Find a better model.
2023-05-28 19:13:45.190: [iter 4 : loss : 1.0051 = 0.6927 + 0.3124 + 0.0000, time: 7.271121]
2023-05-28 19:13:45.350: epoch 4:	0.00409961  	0.02849601  	0.01466823  
2023-05-28 19:13:45.350: Find a better model.
2023-05-28 19:13:52.419: [iter 5 : loss : 1.0049 = 0.6925 + 0.3124 + 0.0000, time: 7.066579]
2023-05-28 19:13:52.573: epoch 5:	0.00508747  	0.03545045  	0.01763683  
2023-05-28 19:13:52.573: Find a better model.
2023-05-28 19:13:59.594: [iter 6 : loss : 1.0049 = 0.6923 + 0.3125 + 0.0000, time: 7.020921]
2023-05-28 19:13:59.748: epoch 6:	0.00594831  	0.04169608  	0.02087439  
2023-05-28 19:13:59.748: Find a better model.
2023-05-28 19:14:06.593: [iter 7 : loss : 1.0045 = 0.6920 + 0.3124 + 0.0000, time: 6.842157]
2023-05-28 19:14:06.746: epoch 7:	0.00666097  	0.04731534  	0.02407812  
2023-05-28 19:14:06.746: Find a better model.
2023-05-28 19:14:22.442: my pid: 14320
2023-05-28 19:14:22.442: model: model.general_recommender.SGL
2023-05-28 19:14:22.442: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 19:14:22.442: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 19:14:26.174: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 19:14:33.569: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.394563]
2023-05-28 19:14:33.721: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-28 19:14:33.721: Find a better model.
2023-05-28 19:14:41.155: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.432043]
2023-05-28 19:14:41.348: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-28 19:14:41.348: Find a better model.
2023-05-28 19:14:48.764: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.414036]
2023-05-28 19:14:48.945: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-28 19:14:48.946: Find a better model.
2023-05-28 19:14:56.159: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.212046]
2023-05-28 19:14:56.316: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-28 19:14:56.316: Find a better model.
2023-05-28 19:15:03.338: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 7.020140]
2023-05-28 19:15:03.491: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-28 19:15:03.491: Find a better model.
2023-05-28 19:15:10.363: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.871330]
2023-05-28 19:15:10.514: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-28 19:15:10.514: Find a better model.
2023-05-28 19:15:17.151: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.636015]
2023-05-28 19:15:17.318: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-28 19:15:17.318: Find a better model.
2023-05-28 19:15:23.947: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.626996]
2023-05-28 19:15:24.094: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-28 19:15:24.095: Find a better model.
2023-05-28 19:15:30.927: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.830049]
2023-05-28 19:15:31.078: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-28 19:15:37.745: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.664994]
2023-05-28 19:15:37.905: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-28 19:15:44.542: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.634993]
2023-05-28 19:15:44.710: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-28 19:15:51.079: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.367994]
2023-05-28 19:15:51.230: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-28 19:15:57.922: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.690012]
2023-05-28 19:15:58.073: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-28 19:15:58.073: Find a better model.
2023-05-28 19:16:04.743: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.668059]
2023-05-28 19:16:04.894: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-28 19:16:04.894: Find a better model.
2023-05-28 19:16:11.533: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.637496]
2023-05-28 19:16:11.680: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-28 19:16:11.680: Find a better model.
2023-05-28 19:16:18.303: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.622015]
2023-05-28 19:16:18.450: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-28 19:16:18.450: Find a better model.
2023-05-28 19:16:25.104: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.651688]
2023-05-28 19:16:25.251: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-28 19:16:25.251: Find a better model.
2023-05-28 19:16:31.910: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.658291]
2023-05-28 19:16:32.075: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-28 19:16:32.075: Find a better model.
2023-05-28 19:16:38.721: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.644459]
2023-05-28 19:16:38.874: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-28 19:16:38.874: Find a better model.
2023-05-28 19:16:45.499: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.623323]
2023-05-28 19:16:45.647: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-28 19:16:45.647: Find a better model.
2023-05-28 19:16:52.302: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.653025]
2023-05-28 19:16:52.468: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-28 19:16:52.469: Find a better model.
2023-05-28 19:16:59.107: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.637001]
2023-05-28 19:16:59.259: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-28 19:16:59.260: Find a better model.
2023-05-28 19:17:05.913: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.652018]
2023-05-28 19:17:06.063: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-28 19:17:06.063: Find a better model.
2023-05-28 19:17:12.721: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.657001]
2023-05-28 19:17:12.875: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-28 19:17:12.875: Find a better model.
2023-05-28 19:17:19.513: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.636821]
2023-05-28 19:17:19.663: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-28 19:17:19.663: Find a better model.
2023-05-28 19:17:26.288: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.623996]
2023-05-28 19:17:26.440: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-28 19:17:26.440: Find a better model.
2023-05-28 19:17:33.110: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.669034]
2023-05-28 19:17:33.277: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-28 19:17:33.278: Find a better model.
2023-05-28 19:17:39.906: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.627499]
2023-05-28 19:17:40.057: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-28 19:17:40.057: Find a better model.
2023-05-28 19:17:46.690: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.631994]
2023-05-28 19:17:46.843: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-28 19:17:46.843: Find a better model.
2023-05-28 19:17:53.301: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.456227]
2023-05-28 19:17:53.450: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-28 19:17:53.450: Find a better model.
2023-05-28 19:18:00.101: [iter 31 : loss : 0.2378 = 0.1388 + 0.0967 + 0.0023, time: 6.649424]
2023-05-28 19:18:00.249: epoch 31:	0.02208628  	0.16282843  	0.08343192  
2023-05-28 19:18:00.249: Find a better model.
2023-05-28 19:18:07.091: [iter 32 : loss : 0.2322 = 0.1336 + 0.0963 + 0.0024, time: 6.839997]
2023-05-28 19:18:07.254: epoch 32:	0.02229797  	0.16417737  	0.08421503  
2023-05-28 19:18:07.254: Find a better model.
2023-05-28 19:18:13.891: [iter 33 : loss : 0.2298 = 0.1314 + 0.0959 + 0.0024, time: 6.636038]
2023-05-28 19:18:14.039: epoch 33:	0.02239675  	0.16530859  	0.08477320  
2023-05-28 19:18:14.040: Find a better model.
2023-05-28 19:18:20.689: [iter 34 : loss : 0.2256 = 0.1276 + 0.0956 + 0.0025, time: 6.648028]
2023-05-28 19:18:20.854: epoch 34:	0.02243203  	0.16575743  	0.08517438  
2023-05-28 19:18:20.854: Find a better model.
2023-05-28 19:18:27.488: [iter 35 : loss : 0.2222 = 0.1244 + 0.0953 + 0.0025, time: 6.633085]
2023-05-28 19:18:27.637: epoch 35:	0.02255199  	0.16632408  	0.08579959  
2023-05-28 19:18:27.637: Find a better model.
2023-05-28 19:18:34.278: [iter 36 : loss : 0.2189 = 0.1214 + 0.0950 + 0.0026, time: 6.640034]
2023-05-28 19:18:34.440: epoch 36:	0.02260139  	0.16666549  	0.08641180  
2023-05-28 19:18:34.440: Find a better model.
2023-05-28 19:18:41.079: [iter 37 : loss : 0.2150 = 0.1178 + 0.0946 + 0.0026, time: 6.636793]
2023-05-28 19:18:41.229: epoch 37:	0.02269312  	0.16723008  	0.08701210  
2023-05-28 19:18:41.229: Find a better model.
2023-05-28 19:18:47.876: [iter 38 : loss : 0.2137 = 0.1167 + 0.0943 + 0.0027, time: 6.646041]
2023-05-28 19:18:48.024: epoch 38:	0.02277074  	0.16776994  	0.08751650  
2023-05-28 19:18:48.024: Find a better model.
2023-05-28 19:18:54.673: [iter 39 : loss : 0.2091 = 0.1124 + 0.0940 + 0.0028, time: 6.648015]
2023-05-28 19:18:54.827: epoch 39:	0.02289070  	0.16851188  	0.08817933  
2023-05-28 19:18:54.827: Find a better model.
2023-05-28 19:19:01.464: [iter 40 : loss : 0.2058 = 0.1093 + 0.0937 + 0.0028, time: 6.636071]
2023-05-28 19:19:01.620: epoch 40:	0.02296832  	0.16944526  	0.08861575  
2023-05-28 19:19:01.620: Find a better model.
2023-05-28 19:19:08.270: [iter 41 : loss : 0.2044 = 0.1081 + 0.0935 + 0.0029, time: 6.649004]
2023-05-28 19:19:08.419: epoch 41:	0.02304595  	0.17016615  	0.08919139  
2023-05-28 19:19:08.419: Find a better model.
2023-05-28 19:19:15.072: [iter 42 : loss : 0.2022 = 0.1061 + 0.0932 + 0.0029, time: 6.652109]
2023-05-28 19:19:15.222: epoch 42:	0.02316590  	0.17131220  	0.08974062  
2023-05-28 19:19:15.222: Find a better model.
2023-05-28 19:19:22.055: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.831017]
2023-05-28 19:19:22.203: epoch 43:	0.02320119  	0.17132421  	0.09008523  
2023-05-28 19:19:22.203: Find a better model.
2023-05-28 19:19:29.047: [iter 44 : loss : 0.1949 = 0.0993 + 0.0926 + 0.0030, time: 6.841994]
2023-05-28 19:19:29.214: epoch 44:	0.02324353  	0.17146684  	0.09048539  
2023-05-28 19:19:29.214: Find a better model.
2023-05-28 19:19:36.027: [iter 45 : loss : 0.1927 = 0.0972 + 0.0924 + 0.0031, time: 6.812016]
2023-05-28 19:19:36.176: epoch 45:	0.02340583  	0.17263691  	0.09116724  
2023-05-28 19:19:36.176: Find a better model.
2023-05-28 19:19:42.860: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.682015]
2023-05-28 19:19:43.009: epoch 46:	0.02356812  	0.17387484  	0.09193981  
2023-05-28 19:19:43.009: Find a better model.
2023-05-28 19:19:49.823: [iter 47 : loss : 0.1898 = 0.0947 + 0.0919 + 0.0032, time: 6.813003]
2023-05-28 19:19:49.970: epoch 47:	0.02365986  	0.17437126  	0.09231025  
2023-05-28 19:19:49.970: Find a better model.
2023-05-28 19:19:56.655: [iter 48 : loss : 0.1859 = 0.0910 + 0.0917 + 0.0032, time: 6.682382]
2023-05-28 19:19:56.822: epoch 48:	0.02375159  	0.17476259  	0.09279061  
2023-05-28 19:19:56.822: Find a better model.
2023-05-28 19:20:03.645: [iter 49 : loss : 0.1828 = 0.0881 + 0.0914 + 0.0033, time: 6.821005]
2023-05-28 19:20:03.814: epoch 49:	0.02381510  	0.17505930  	0.09294336  
2023-05-28 19:20:03.815: Find a better model.
2023-05-28 19:20:10.448: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.631030]
2023-05-28 19:20:10.611: epoch 50:	0.02382216  	0.17521159  	0.09321536  
2023-05-28 19:20:10.611: Find a better model.
2023-05-28 19:20:17.248: [iter 51 : loss : 0.1789 = 0.0845 + 0.0911 + 0.0034, time: 6.634029]
2023-05-28 19:20:17.415: epoch 51:	0.02386450  	0.17551927  	0.09349652  
2023-05-28 19:20:17.415: Find a better model.
2023-05-28 19:20:24.059: [iter 52 : loss : 0.1789 = 0.0846 + 0.0908 + 0.0034, time: 6.642037]
2023-05-28 19:20:24.209: epoch 52:	0.02397035  	0.17620304  	0.09398963  
2023-05-28 19:20:24.209: Find a better model.
2023-05-28 19:20:30.838: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.627004]
2023-05-28 19:20:30.988: epoch 53:	0.02406208  	0.17694885  	0.09432301  
2023-05-28 19:20:30.988: Find a better model.
2023-05-28 19:20:37.808: [iter 54 : loss : 0.1751 = 0.0811 + 0.0904 + 0.0035, time: 6.818577]
2023-05-28 19:20:37.960: epoch 54:	0.02418909  	0.17794658  	0.09491940  
2023-05-28 19:20:37.960: Find a better model.
2023-05-28 19:20:44.630: [iter 55 : loss : 0.1731 = 0.0793 + 0.0903 + 0.0035, time: 6.668994]
2023-05-28 19:20:44.779: epoch 55:	0.02422438  	0.17832384  	0.09534466  
2023-05-28 19:20:44.779: Find a better model.
2023-05-28 19:20:51.443: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.662018]
2023-05-28 19:20:51.594: epoch 56:	0.02433728  	0.17897154  	0.09572835  
2023-05-28 19:20:51.594: Find a better model.
2023-05-28 19:20:58.228: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.632994]
2023-05-28 19:20:58.380: epoch 57:	0.02446430  	0.18023935  	0.09625740  
2023-05-28 19:20:58.380: Find a better model.
2023-05-28 19:21:05.196: [iter 58 : loss : 0.1676 = 0.0741 + 0.0897 + 0.0037, time: 6.814994]
2023-05-28 19:21:05.345: epoch 58:	0.02451369  	0.18070017  	0.09662949  
2023-05-28 19:21:05.345: Find a better model.
2023-05-28 19:21:12.028: [iter 59 : loss : 0.1665 = 0.0732 + 0.0895 + 0.0037, time: 6.682018]
2023-05-28 19:21:12.180: epoch 59:	0.02455603  	0.18127462  	0.09684177  
2023-05-28 19:21:12.181: Find a better model.
2023-05-28 19:21:18.832: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.648953]
2023-05-28 19:21:18.999: epoch 60:	0.02458426  	0.18129744  	0.09710963  
2023-05-28 19:21:18.999: Find a better model.
2023-05-28 19:21:25.801: [iter 61 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 6.799176]
2023-05-28 19:21:25.953: epoch 61:	0.02472539  	0.18246689  	0.09780641  
2023-05-28 19:21:25.954: Find a better model.
2023-05-28 19:21:32.614: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.659035]
2023-05-28 19:21:32.762: epoch 62:	0.02473950  	0.18248074  	0.09801480  
2023-05-28 19:21:32.763: Find a better model.
2023-05-28 19:21:39.416: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.652012]
2023-05-28 19:21:39.567: epoch 63:	0.02486651  	0.18363361  	0.09858558  
2023-05-28 19:21:39.568: Find a better model.
2023-05-28 19:21:46.201: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.632266]
2023-05-28 19:21:46.354: epoch 64:	0.02490179  	0.18376118  	0.09893467  
2023-05-28 19:21:46.354: Find a better model.
2023-05-28 19:21:53.011: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.655006]
2023-05-28 19:21:53.160: epoch 65:	0.02484534  	0.18339384  	0.09908592  
2023-05-28 19:21:59.978: [iter 66 : loss : 0.1569 = 0.0644 + 0.0884 + 0.0040, time: 6.817023]
2023-05-28 19:22:00.132: epoch 66:	0.02494413  	0.18405391  	0.09931978  
2023-05-28 19:22:00.133: Find a better model.
2023-05-28 19:22:06.806: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.671015]
2023-05-28 19:22:06.959: epoch 67:	0.02504292  	0.18462647  	0.09977543  
2023-05-28 19:22:06.959: Find a better model.
2023-05-28 19:22:13.795: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.834929]
2023-05-28 19:22:13.964: epoch 68:	0.02509937  	0.18486504  	0.10010450  
2023-05-28 19:22:13.964: Find a better model.
2023-05-28 19:22:20.787: [iter 69 : loss : 0.1533 = 0.0612 + 0.0880 + 0.0042, time: 6.822012]
2023-05-28 19:22:20.940: epoch 69:	0.02510642  	0.18489738  	0.10031281  
2023-05-28 19:22:20.940: Find a better model.
2023-05-28 19:22:27.597: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.655005]
2023-05-28 19:22:27.745: epoch 70:	0.02522638  	0.18607423  	0.10066570  
2023-05-28 19:22:27.745: Find a better model.
2023-05-28 19:22:34.401: [iter 71 : loss : 0.1503 = 0.0583 + 0.0878 + 0.0042, time: 6.654015]
2023-05-28 19:22:34.549: epoch 71:	0.02527578  	0.18630695  	0.10094027  
2023-05-28 19:22:34.549: Find a better model.
2023-05-28 19:22:41.198: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.647331]
2023-05-28 19:22:41.348: epoch 72:	0.02533224  	0.18696634  	0.10125165  
2023-05-28 19:22:41.348: Find a better model.
2023-05-28 19:22:48.000: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.650994]
2023-05-28 19:22:48.148: epoch 73:	0.02534635  	0.18715927  	0.10136312  
2023-05-28 19:22:48.148: Find a better model.
2023-05-28 19:22:54.962: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.813013]
2023-05-28 19:22:55.128: epoch 74:	0.02544514  	0.18791388  	0.10183105  
2023-05-28 19:22:55.128: Find a better model.
2023-05-28 19:23:01.799: [iter 75 : loss : 0.1468 = 0.0552 + 0.0873 + 0.0044, time: 6.670016]
2023-05-28 19:23:01.951: epoch 75:	0.02545220  	0.18799609  	0.10187864  
2023-05-28 19:23:01.951: Find a better model.
2023-05-28 19:23:08.590: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.638038]
2023-05-28 19:23:08.754: epoch 76:	0.02555805  	0.18905693  	0.10232901  
2023-05-28 19:23:08.754: Find a better model.
2023-05-28 19:23:15.561: [iter 77 : loss : 0.1449 = 0.0534 + 0.0870 + 0.0045, time: 6.805400]
2023-05-28 19:23:15.709: epoch 77:	0.02550159  	0.18842892  	0.10221797  
2023-05-28 19:23:22.402: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.692004]
2023-05-28 19:23:22.549: epoch 78:	0.02557215  	0.18913417  	0.10252641  
2023-05-28 19:23:22.549: Find a better model.
2023-05-28 19:23:29.178: [iter 79 : loss : 0.1425 = 0.0511 + 0.0868 + 0.0046, time: 6.627539]
2023-05-28 19:23:29.326: epoch 79:	0.02566389  	0.18979087  	0.10278413  
2023-05-28 19:23:29.326: Find a better model.
2023-05-28 19:23:35.984: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.656244]
2023-05-28 19:23:36.133: epoch 80:	0.02568505  	0.19001406  	0.10305227  
2023-05-28 19:23:36.133: Find a better model.
2023-05-28 19:23:42.945: [iter 81 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 6.811003]
2023-05-28 19:23:43.099: epoch 81:	0.02572034  	0.19033565  	0.10341468  
2023-05-28 19:23:43.099: Find a better model.
2023-05-28 19:23:49.770: [iter 82 : loss : 0.1402 = 0.0490 + 0.0865 + 0.0047, time: 6.668360]
2023-05-28 19:23:49.927: epoch 82:	0.02567800  	0.18981352  	0.10336649  
2023-05-28 19:23:56.739: [iter 83 : loss : 0.1396 = 0.0484 + 0.0865 + 0.0047, time: 6.811012]
2023-05-28 19:23:56.893: epoch 83:	0.02576268  	0.19056626  	0.10362168  
2023-05-28 19:23:56.893: Find a better model.
2023-05-28 19:24:03.567: [iter 84 : loss : 0.1394 = 0.0482 + 0.0864 + 0.0048, time: 6.672977]
2023-05-28 19:24:03.720: epoch 84:	0.02566389  	0.18971828  	0.10355888  
2023-05-28 19:24:10.370: [iter 85 : loss : 0.1384 = 0.0474 + 0.0862 + 0.0048, time: 6.648004]
2023-05-28 19:24:10.519: epoch 85:	0.02574151  	0.19040145  	0.10383262  
2023-05-28 19:24:17.176: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.654037]
2023-05-28 19:24:17.343: epoch 86:	0.02581913  	0.19092783  	0.10406092  
2023-05-28 19:24:17.343: Find a better model.
2023-05-28 19:24:23.967: [iter 87 : loss : 0.1355 = 0.0446 + 0.0861 + 0.0049, time: 6.623003]
2023-05-28 19:24:24.125: epoch 87:	0.02590381  	0.19156374  	0.10431638  
2023-05-28 19:24:24.125: Find a better model.
2023-05-28 19:24:30.933: [iter 88 : loss : 0.1349 = 0.0441 + 0.0860 + 0.0049, time: 6.806026]
2023-05-28 19:24:31.084: epoch 88:	0.02598849  	0.19220266  	0.10469809  
2023-05-28 19:24:31.085: Find a better model.
2023-05-28 19:24:37.923: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.836929]
2023-05-28 19:24:38.073: epoch 89:	0.02595320  	0.19176972  	0.10474481  
2023-05-28 19:24:44.767: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.692601]
2023-05-28 19:24:44.923: epoch 90:	0.02600259  	0.19227742  	0.10504197  
2023-05-28 19:24:44.923: Find a better model.
2023-05-28 19:24:51.546: [iter 91 : loss : 0.1337 = 0.0430 + 0.0857 + 0.0050, time: 6.622003]
2023-05-28 19:24:51.694: epoch 91:	0.02608022  	0.19300483  	0.10520301  
2023-05-28 19:24:51.694: Find a better model.
2023-05-28 19:24:58.344: [iter 92 : loss : 0.1328 = 0.0422 + 0.0856 + 0.0051, time: 6.647208]
2023-05-28 19:24:58.495: epoch 92:	0.02605199  	0.19314724  	0.10532437  
2023-05-28 19:24:58.495: Find a better model.
2023-05-28 19:25:05.158: [iter 93 : loss : 0.1331 = 0.0425 + 0.0856 + 0.0051, time: 6.661158]
2023-05-28 19:25:05.308: epoch 93:	0.02607317  	0.19370262  	0.10547975  
2023-05-28 19:25:05.309: Find a better model.
2023-05-28 19:25:11.944: [iter 94 : loss : 0.1312 = 0.0406 + 0.0855 + 0.0051, time: 6.633004]
2023-05-28 19:25:12.095: epoch 94:	0.02604493  	0.19331138  	0.10544594  
2023-05-28 19:25:18.775: [iter 95 : loss : 0.1305 = 0.0400 + 0.0854 + 0.0052, time: 6.677402]
2023-05-28 19:25:18.938: epoch 95:	0.02605905  	0.19326019  	0.10557022  
2023-05-28 19:25:25.736: [iter 96 : loss : 0.1306 = 0.0400 + 0.0854 + 0.0052, time: 6.797082]
2023-05-28 19:25:25.896: epoch 96:	0.02608727  	0.19372499  	0.10577172  
2023-05-28 19:25:25.897: Find a better model.
2023-05-28 19:25:32.536: [iter 97 : loss : 0.1289 = 0.0385 + 0.0852 + 0.0052, time: 6.637055]
2023-05-28 19:25:32.684: epoch 97:	0.02606610  	0.19323447  	0.10567994  
2023-05-28 19:25:39.317: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.631482]
2023-05-28 19:25:39.467: epoch 98:	0.02605904  	0.19339868  	0.10578249  
2023-05-28 19:25:46.144: [iter 99 : loss : 0.1285 = 0.0381 + 0.0851 + 0.0053, time: 6.676257]
2023-05-28 19:25:46.294: epoch 99:	0.02608727  	0.19378406  	0.10599092  
2023-05-28 19:25:46.294: Find a better model.
2023-05-28 19:25:53.108: [iter 100 : loss : 0.1281 = 0.0377 + 0.0850 + 0.0053, time: 6.811039]
2023-05-28 19:25:53.259: epoch 100:	0.02617901  	0.19450688  	0.10620708  
2023-05-28 19:25:53.259: Find a better model.
2023-05-28 19:26:00.121: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.860786]
2023-05-28 19:26:00.274: epoch 101:	0.02621429  	0.19452716  	0.10633942  
2023-05-28 19:26:00.274: Find a better model.
2023-05-28 19:26:06.930: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.655063]
2023-05-28 19:26:07.078: epoch 102:	0.02622840  	0.19462410  	0.10640569  
2023-05-28 19:26:07.078: Find a better model.
2023-05-28 19:26:13.734: [iter 103 : loss : 0.1264 = 0.0361 + 0.0848 + 0.0055, time: 6.653994]
2023-05-28 19:26:13.895: epoch 103:	0.02622134  	0.19470681  	0.10656621  
2023-05-28 19:26:13.895: Find a better model.
2023-05-28 19:26:20.513: [iter 104 : loss : 0.1269 = 0.0366 + 0.0848 + 0.0055, time: 6.617019]
2023-05-28 19:26:20.661: epoch 104:	0.02624957  	0.19496903  	0.10680412  
2023-05-28 19:26:20.662: Find a better model.
2023-05-28 19:26:27.313: [iter 105 : loss : 0.1262 = 0.0360 + 0.0847 + 0.0055, time: 6.650038]
2023-05-28 19:26:27.477: epoch 105:	0.02620018  	0.19456498  	0.10678725  
2023-05-28 19:26:34.118: [iter 106 : loss : 0.1256 = 0.0354 + 0.0846 + 0.0056, time: 6.639938]
2023-05-28 19:26:34.266: epoch 106:	0.02619312  	0.19442521  	0.10665287  
2023-05-28 19:26:40.915: [iter 107 : loss : 0.1247 = 0.0346 + 0.0846 + 0.0056, time: 6.647337]
2023-05-28 19:26:41.081: epoch 107:	0.02622841  	0.19480985  	0.10671636  
2023-05-28 19:26:47.714: [iter 108 : loss : 0.1245 = 0.0343 + 0.0846 + 0.0056, time: 6.631322]
2023-05-28 19:26:47.880: epoch 108:	0.02622841  	0.19501215  	0.10682039  
2023-05-28 19:26:47.880: Find a better model.
2023-05-28 19:26:54.517: [iter 109 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 6.635026]
2023-05-28 19:26:54.682: epoch 109:	0.02629897  	0.19566965  	0.10701114  
2023-05-28 19:26:54.682: Find a better model.
2023-05-28 19:27:01.317: [iter 110 : loss : 0.1226 = 0.0325 + 0.0844 + 0.0057, time: 6.634014]
2023-05-28 19:27:01.467: epoch 110:	0.02631308  	0.19572483  	0.10697730  
2023-05-28 19:27:01.467: Find a better model.
2023-05-28 19:27:08.090: [iter 111 : loss : 0.1225 = 0.0324 + 0.0844 + 0.0057, time: 6.622013]
2023-05-28 19:27:08.243: epoch 111:	0.02634837  	0.19594511  	0.10722199  
2023-05-28 19:27:08.243: Find a better model.
2023-05-28 19:27:14.888: [iter 112 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.643620]
2023-05-28 19:27:15.052: epoch 112:	0.02634837  	0.19570652  	0.10719418  
2023-05-28 19:27:21.684: [iter 113 : loss : 0.1223 = 0.0323 + 0.0842 + 0.0058, time: 6.630355]
2023-05-28 19:27:21.841: epoch 113:	0.02631308  	0.19547839  	0.10709560  
2023-05-28 19:27:28.290: [iter 114 : loss : 0.1215 = 0.0315 + 0.0842 + 0.0058, time: 6.447097]
2023-05-28 19:27:28.443: epoch 114:	0.02637659  	0.19576804  	0.10726687  
2023-05-28 19:27:35.079: [iter 115 : loss : 0.1211 = 0.0311 + 0.0841 + 0.0059, time: 6.635426]
2023-05-28 19:27:35.232: epoch 115:	0.02636248  	0.19595346  	0.10717712  
2023-05-28 19:27:35.232: Find a better model.
2023-05-28 19:27:41.868: [iter 116 : loss : 0.1204 = 0.0304 + 0.0841 + 0.0059, time: 6.635013]
2023-05-28 19:27:42.018: epoch 116:	0.02639071  	0.19613279  	0.10720391  
2023-05-28 19:27:42.018: Find a better model.
2023-05-28 19:27:48.678: [iter 117 : loss : 0.1202 = 0.0303 + 0.0840 + 0.0059, time: 6.659026]
2023-05-28 19:27:48.832: epoch 117:	0.02648950  	0.19676898  	0.10740199  
2023-05-28 19:27:48.832: Find a better model.
2023-05-28 19:27:55.288: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.453994]
2023-05-28 19:27:55.438: epoch 118:	0.02655301  	0.19724254  	0.10766405  
2023-05-28 19:27:55.438: Find a better model.
2023-05-28 19:28:02.066: [iter 119 : loss : 0.1192 = 0.0293 + 0.0839 + 0.0060, time: 6.626035]
2023-05-28 19:28:02.233: epoch 119:	0.02656712  	0.19697028  	0.10765814  
2023-05-28 19:28:08.877: [iter 120 : loss : 0.1195 = 0.0296 + 0.0839 + 0.0060, time: 6.643126]
2023-05-28 19:28:09.030: epoch 120:	0.02645422  	0.19588590  	0.10737147  
2023-05-28 19:28:15.668: [iter 121 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0060, time: 6.637319]
2023-05-28 19:28:15.838: epoch 121:	0.02644716  	0.19606008  	0.10749782  
2023-05-28 19:28:22.283: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.443001]
2023-05-28 19:28:22.436: epoch 122:	0.02646127  	0.19620040  	0.10761304  
2023-05-28 19:28:28.892: [iter 123 : loss : 0.1184 = 0.0286 + 0.0837 + 0.0061, time: 6.455106]
2023-05-28 19:28:29.042: epoch 123:	0.02645422  	0.19628873  	0.10763126  
2023-05-28 19:28:35.660: [iter 124 : loss : 0.1176 = 0.0277 + 0.0837 + 0.0061, time: 6.616008]
2023-05-28 19:28:35.828: epoch 124:	0.02647539  	0.19617957  	0.10758467  
2023-05-28 19:28:42.454: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.623018]
2023-05-28 19:28:42.608: epoch 125:	0.02653890  	0.19701876  	0.10776535  
2023-05-28 19:28:49.251: [iter 126 : loss : 0.1171 = 0.0273 + 0.0836 + 0.0062, time: 6.641021]
2023-05-28 19:28:49.401: epoch 126:	0.02651773  	0.19660413  	0.10775883  
2023-05-28 19:28:56.055: [iter 127 : loss : 0.1162 = 0.0264 + 0.0836 + 0.0062, time: 6.652027]
2023-05-28 19:28:56.206: epoch 127:	0.02643305  	0.19593038  	0.10763299  
2023-05-28 19:29:02.840: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.633015]
2023-05-28 19:29:03.011: epoch 128:	0.02653183  	0.19600956  	0.10759494  
2023-05-28 19:29:09.650: [iter 129 : loss : 0.1164 = 0.0266 + 0.0835 + 0.0063, time: 6.637370]
2023-05-28 19:29:09.823: epoch 129:	0.02651772  	0.19623220  	0.10775168  
2023-05-28 19:29:16.266: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.441001]
2023-05-28 19:29:16.417: epoch 130:	0.02644716  	0.19557649  	0.10768811  
2023-05-28 19:29:23.035: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0063, time: 6.616012]
2023-05-28 19:29:23.186: epoch 131:	0.02648244  	0.19597204  	0.10768794  
2023-05-28 19:29:29.844: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.656049]
2023-05-28 19:29:29.995: epoch 132:	0.02644010  	0.19584988  	0.10768515  
2023-05-28 19:29:36.459: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.463001]
2023-05-28 19:29:36.625: epoch 133:	0.02638365  	0.19525148  	0.10770609  
2023-05-28 19:29:43.251: [iter 134 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0064, time: 6.625007]
2023-05-28 19:29:43.402: epoch 134:	0.02639776  	0.19524734  	0.10774174  
2023-05-28 19:29:50.027: [iter 135 : loss : 0.1150 = 0.0253 + 0.0832 + 0.0065, time: 6.623029]
2023-05-28 19:29:50.192: epoch 135:	0.02644010  	0.19576082  	0.10790625  
2023-05-28 19:29:56.821: [iter 136 : loss : 0.1146 = 0.0249 + 0.0832 + 0.0065, time: 6.628036]
2023-05-28 19:29:56.984: epoch 136:	0.02644010  	0.19577610  	0.10782269  
2023-05-28 19:30:03.642: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.655994]
2023-05-28 19:30:03.813: epoch 137:	0.02645421  	0.19607194  	0.10785469  
2023-05-28 19:30:10.420: [iter 138 : loss : 0.1139 = 0.0243 + 0.0831 + 0.0066, time: 6.603993]
2023-05-28 19:30:10.571: epoch 138:	0.02644715  	0.19588816  	0.10795940  
2023-05-28 19:30:17.227: [iter 139 : loss : 0.1138 = 0.0241 + 0.0831 + 0.0066, time: 6.655326]
2023-05-28 19:30:17.379: epoch 139:	0.02644715  	0.19580917  	0.10789607  
2023-05-28 19:30:24.003: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.621994]
2023-05-28 19:30:24.156: epoch 140:	0.02645421  	0.19571586  	0.10789403  
2023-05-28 19:30:30.836: [iter 141 : loss : 0.1136 = 0.0240 + 0.0830 + 0.0066, time: 6.679047]
2023-05-28 19:30:31.005: epoch 141:	0.02644010  	0.19579037  	0.10786166  
2023-05-28 19:30:37.626: [iter 142 : loss : 0.1127 = 0.0231 + 0.0829 + 0.0067, time: 6.619020]
2023-05-28 19:30:37.791: epoch 142:	0.02638365  	0.19577844  	0.10795098  
2023-05-28 19:30:44.408: [iter 143 : loss : 0.1129 = 0.0233 + 0.0829 + 0.0067, time: 6.614053]
2023-05-28 19:30:44.559: epoch 143:	0.02640481  	0.19588704  	0.10817418  
2023-05-28 19:30:44.559: Early stopping is trigger at epoch: 143
2023-05-28 19:30:44.559: best_result@epoch 118:

2023-05-28 19:30:44.559: 		0.0266      	0.1972      	0.1077      
2023-05-28 20:31:34.173: my pid: 6412
2023-05-28 20:31:34.173: model: model.general_recommender.SGL
2023-05-28 20:31:34.173: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 20:31:34.173: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 20:31:37.880: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 20:31:45.212: [iter 1 : loss : 0.8509 = 0.6930 + 0.1579 + 0.0000, time: 7.330042]
2023-05-28 20:31:45.369: epoch 1:	0.00182049  	0.01257730  	0.00631620  
2023-05-28 20:31:45.369: Find a better model.
2023-05-28 20:31:52.764: [iter 2 : loss : 0.8504 = 0.6928 + 0.1575 + 0.0000, time: 7.394360]
2023-05-28 20:31:52.960: epoch 2:	0.00309060  	0.02227302  	0.01125003  
2023-05-28 20:31:52.960: Find a better model.
2023-05-28 20:32:00.179: [iter 3 : loss : 0.8502 = 0.6926 + 0.1576 + 0.0000, time: 7.216856]
2023-05-28 20:32:00.357: epoch 3:	0.00471350  	0.03300283  	0.01637530  
2023-05-28 20:32:00.358: Find a better model.
2023-05-28 20:32:07.555: [iter 4 : loss : 0.8500 = 0.6923 + 0.1576 + 0.0000, time: 7.196016]
2023-05-28 20:32:07.710: epoch 4:	0.00647046  	0.04646729  	0.02317370  
2023-05-28 20:32:07.710: Find a better model.
2023-05-28 20:32:14.574: [iter 5 : loss : 0.8496 = 0.6918 + 0.1577 + 0.0000, time: 6.862075]
2023-05-28 20:32:14.726: epoch 5:	0.00802280  	0.05754824  	0.02800300  
2023-05-28 20:32:14.727: Find a better model.
2023-05-28 20:32:21.531: [iter 6 : loss : 0.8491 = 0.6912 + 0.1580 + 0.0000, time: 6.802997]
2023-05-28 20:32:21.682: epoch 6:	0.01010440  	0.07213809  	0.03463454  
2023-05-28 20:32:21.682: Find a better model.
2023-05-28 20:32:28.343: [iter 7 : loss : 0.8481 = 0.6900 + 0.1581 + 0.0000, time: 6.659407]
2023-05-28 20:32:28.491: epoch 7:	0.01216489  	0.08796038  	0.04186844  
2023-05-28 20:32:28.492: Find a better model.
2023-05-28 20:32:35.155: [iter 8 : loss : 0.8465 = 0.6881 + 0.1584 + 0.0000, time: 6.661927]
2023-05-28 20:32:35.320: epoch 8:	0.01399956  	0.10044158  	0.04797134  
2023-05-28 20:32:35.320: Find a better model.
2023-05-28 20:32:41.963: [iter 9 : loss : 0.8433 = 0.6845 + 0.1589 + 0.0000, time: 6.640994]
2023-05-28 20:32:42.121: epoch 9:	0.01579190  	0.11539306  	0.05509090  
2023-05-28 20:32:42.121: Find a better model.
2023-05-28 20:32:48.756: [iter 10 : loss : 0.8374 = 0.6777 + 0.1596 + 0.0000, time: 6.633398]
2023-05-28 20:32:48.908: epoch 10:	0.01754188  	0.12823911  	0.06156940  
2023-05-28 20:32:48.908: Find a better model.
2023-05-28 20:32:55.356: [iter 11 : loss : 0.8261 = 0.6652 + 0.1608 + 0.0001, time: 6.446994]
2023-05-28 20:32:55.510: epoch 11:	0.01847332  	0.13445282  	0.06638263  
2023-05-28 20:32:55.510: Find a better model.
2023-05-28 20:33:02.142: [iter 12 : loss : 0.8057 = 0.6425 + 0.1631 + 0.0001, time: 6.630968]
2023-05-28 20:33:02.295: epoch 12:	0.01910840  	0.13861975  	0.07002954  
2023-05-28 20:33:02.295: Find a better model.
2023-05-28 20:33:08.751: [iter 13 : loss : 0.7729 = 0.6060 + 0.1667 + 0.0002, time: 6.454141]
2023-05-28 20:33:08.904: epoch 13:	0.01929187  	0.14125884  	0.07119749  
2023-05-28 20:33:08.904: Find a better model.
2023-05-28 20:33:15.344: [iter 14 : loss : 0.7244 = 0.5523 + 0.1717 + 0.0003, time: 6.439405]
2023-05-28 20:33:15.493: epoch 14:	0.01944713  	0.14289038  	0.07193728  
2023-05-28 20:33:15.494: Find a better model.
2023-05-28 20:33:21.955: [iter 15 : loss : 0.6666 = 0.4890 + 0.1772 + 0.0004, time: 6.460114]
2023-05-28 20:33:22.122: epoch 15:	0.01960237  	0.14386059  	0.07259672  
2023-05-28 20:33:22.122: Find a better model.
2023-05-28 20:33:28.718: [iter 16 : loss : 0.6082 = 0.4258 + 0.1818 + 0.0006, time: 6.594994]
2023-05-28 20:33:28.889: epoch 16:	0.01966589  	0.14472330  	0.07367177  
2023-05-28 20:33:28.890: Find a better model.
2023-05-28 20:33:35.345: [iter 17 : loss : 0.5578 = 0.3721 + 0.1850 + 0.0007, time: 6.453871]
2023-05-28 20:33:35.494: epoch 17:	0.01986347  	0.14594685  	0.07458277  
2023-05-28 20:33:35.494: Find a better model.
2023-05-28 20:33:41.942: [iter 18 : loss : 0.5164 = 0.3283 + 0.1871 + 0.0009, time: 6.446059]
2023-05-28 20:33:42.098: epoch 18:	0.02001871  	0.14714244  	0.07526811  
2023-05-28 20:33:42.098: Find a better model.
2023-05-28 20:33:48.540: [iter 19 : loss : 0.4823 = 0.2931 + 0.1882 + 0.0010, time: 6.439478]
2023-05-28 20:33:48.691: epoch 19:	0.02020924  	0.14849310  	0.07627525  
2023-05-28 20:33:48.691: Find a better model.
2023-05-28 20:33:55.301: [iter 20 : loss : 0.4572 = 0.2674 + 0.1886 + 0.0012, time: 6.609035]
2023-05-28 20:33:55.456: epoch 20:	0.02046327  	0.15061714  	0.07727117  
2023-05-28 20:33:55.456: Find a better model.
2023-05-28 20:34:01.939: [iter 21 : loss : 0.4353 = 0.2454 + 0.1886 + 0.0013, time: 6.482066]
2023-05-28 20:34:02.090: epoch 21:	0.02068202  	0.15248005  	0.07828405  
2023-05-28 20:34:02.090: Find a better model.
2023-05-28 20:34:08.711: [iter 22 : loss : 0.4175 = 0.2278 + 0.1883 + 0.0014, time: 6.620018]
2023-05-28 20:34:08.861: epoch 22:	0.02090077  	0.15403169  	0.07927296  
2023-05-28 20:34:08.861: Find a better model.
2023-05-28 20:34:15.325: [iter 23 : loss : 0.4019 = 0.2125 + 0.1879 + 0.0015, time: 6.462294]
2023-05-28 20:34:15.474: epoch 23:	0.02121126  	0.15593685  	0.08035315  
2023-05-28 20:34:15.475: Find a better model.
2023-05-28 20:34:22.114: [iter 24 : loss : 0.3895 = 0.2006 + 0.1873 + 0.0016, time: 6.637001]
2023-05-28 20:34:22.264: epoch 24:	0.02145119  	0.15808329  	0.08120009  
2023-05-28 20:34:22.264: Find a better model.
2023-05-28 20:34:28.916: [iter 25 : loss : 0.3775 = 0.1891 + 0.1867 + 0.0017, time: 6.650017]
2023-05-28 20:34:29.068: epoch 25:	0.02171228  	0.15998071  	0.08223280  
2023-05-28 20:34:29.068: Find a better model.
2023-05-28 20:34:35.711: [iter 26 : loss : 0.3691 = 0.1813 + 0.1859 + 0.0018, time: 6.642004]
2023-05-28 20:34:35.862: epoch 26:	0.02181813  	0.16051458  	0.08271481  
2023-05-28 20:34:35.863: Find a better model.
2023-05-28 20:34:42.333: [iter 27 : loss : 0.3581 = 0.1710 + 0.1852 + 0.0019, time: 6.469063]
2023-05-28 20:34:42.485: epoch 27:	0.02203688  	0.16232726  	0.08363575  
2023-05-28 20:34:42.485: Find a better model.
2023-05-28 20:34:49.109: [iter 28 : loss : 0.3499 = 0.1634 + 0.1845 + 0.0020, time: 6.623015]
2023-05-28 20:34:49.257: epoch 28:	0.02225563  	0.16381980  	0.08441518  
2023-05-28 20:34:49.257: Find a better model.
2023-05-28 20:34:55.902: [iter 29 : loss : 0.3428 = 0.1569 + 0.1838 + 0.0021, time: 6.643018]
2023-05-28 20:34:56.056: epoch 29:	0.02251672  	0.16609854  	0.08552445  
2023-05-28 20:34:56.056: Find a better model.
2023-05-28 20:35:02.710: [iter 30 : loss : 0.3339 = 0.1486 + 0.1832 + 0.0022, time: 6.653037]
2023-05-28 20:35:02.860: epoch 30:	0.02274958  	0.16812645  	0.08654292  
2023-05-28 20:35:02.860: Find a better model.
2023-05-28 20:35:09.709: [iter 31 : loss : 0.3284 = 0.1434 + 0.1827 + 0.0023, time: 6.847016]
2023-05-28 20:35:09.860: epoch 31:	0.02287660  	0.16917893  	0.08748454  
2023-05-28 20:35:09.860: Find a better model.
2023-05-28 20:35:16.870: [iter 32 : loss : 0.3211 = 0.1367 + 0.1820 + 0.0024, time: 7.009007]
2023-05-28 20:35:17.025: epoch 32:	0.02305301  	0.17068093  	0.08848243  
2023-05-28 20:35:17.025: Find a better model.
2023-05-28 20:35:23.902: [iter 33 : loss : 0.3167 = 0.1329 + 0.1813 + 0.0024, time: 6.874184]
2023-05-28 20:35:24.067: epoch 33:	0.02323648  	0.17202120  	0.08911721  
2023-05-28 20:35:24.067: Find a better model.
2023-05-28 20:35:30.898: [iter 34 : loss : 0.3111 = 0.1278 + 0.1808 + 0.0025, time: 6.830047]
2023-05-28 20:35:31.057: epoch 34:	0.02337056  	0.17282499  	0.08993259  
2023-05-28 20:35:31.058: Find a better model.
2023-05-28 20:35:37.894: [iter 35 : loss : 0.3061 = 0.1233 + 0.1802 + 0.0026, time: 6.834216]
2023-05-28 20:35:38.052: epoch 35:	0.02349757  	0.17329098  	0.09057235  
2023-05-28 20:35:38.053: Find a better model.
2023-05-28 20:35:44.883: [iter 36 : loss : 0.3016 = 0.1194 + 0.1796 + 0.0027, time: 6.829003]
2023-05-28 20:35:45.034: epoch 36:	0.02368810  	0.17448439  	0.09145527  
2023-05-28 20:35:45.034: Find a better model.
2023-05-28 20:35:51.895: [iter 37 : loss : 0.2965 = 0.1148 + 0.1790 + 0.0027, time: 6.860394]
2023-05-28 20:35:52.055: epoch 37:	0.02389274  	0.17653473  	0.09246694  
2023-05-28 20:35:52.055: Find a better model.
2023-05-28 20:35:58.884: [iter 38 : loss : 0.2939 = 0.1126 + 0.1785 + 0.0028, time: 6.825935]
2023-05-28 20:35:59.055: epoch 38:	0.02400564  	0.17702630  	0.09297845  
2023-05-28 20:35:59.055: Find a better model.
2023-05-28 20:36:05.884: [iter 39 : loss : 0.2886 = 0.1078 + 0.1779 + 0.0029, time: 6.827430]
2023-05-28 20:36:06.034: epoch 39:	0.02420321  	0.17853896  	0.09405847  
2023-05-28 20:36:06.035: Find a better model.
2023-05-28 20:36:12.867: [iter 40 : loss : 0.2846 = 0.1043 + 0.1773 + 0.0029, time: 6.831164]
2023-05-28 20:36:13.032: epoch 40:	0.02434434  	0.17969370  	0.09467210  
2023-05-28 20:36:13.032: Find a better model.
2023-05-28 20:36:19.883: [iter 41 : loss : 0.2822 = 0.1022 + 0.1770 + 0.0030, time: 6.850337]
2023-05-28 20:36:20.048: epoch 41:	0.02445019  	0.18045230  	0.09511758  
2023-05-28 20:36:20.048: Find a better model.
2023-05-28 20:36:26.868: [iter 42 : loss : 0.2789 = 0.0993 + 0.1764 + 0.0031, time: 6.818019]
2023-05-28 20:36:27.022: epoch 42:	0.02454898  	0.18106027  	0.09561400  
2023-05-28 20:36:27.022: Find a better model.
2023-05-28 20:36:33.872: [iter 43 : loss : 0.2747 = 0.0955 + 0.1760 + 0.0031, time: 6.847014]
2023-05-28 20:36:34.022: epoch 43:	0.02471834  	0.18240821  	0.09630772  
2023-05-28 20:36:34.022: Find a better model.
2023-05-28 20:36:40.865: [iter 44 : loss : 0.2709 = 0.0921 + 0.1755 + 0.0032, time: 6.841013]
2023-05-28 20:36:41.017: epoch 44:	0.02471834  	0.18229142  	0.09675737  
2023-05-28 20:36:47.863: [iter 45 : loss : 0.2679 = 0.0894 + 0.1752 + 0.0033, time: 6.843387]
2023-05-28 20:36:48.018: epoch 45:	0.02485240  	0.18326561  	0.09746201  
2023-05-28 20:36:48.018: Find a better model.
2023-05-28 20:36:54.882: [iter 46 : loss : 0.2652 = 0.0872 + 0.1747 + 0.0033, time: 6.863345]
2023-05-28 20:36:55.040: epoch 46:	0.02492297  	0.18376353  	0.09792881  
2023-05-28 20:36:55.040: Find a better model.
2023-05-28 20:37:01.848: [iter 47 : loss : 0.2639 = 0.0862 + 0.1743 + 0.0034, time: 6.806039]
2023-05-28 20:37:02.001: epoch 47:	0.02502881  	0.18476555  	0.09839988  
2023-05-28 20:37:02.001: Find a better model.
2023-05-28 20:37:08.854: [iter 48 : loss : 0.2601 = 0.0826 + 0.1740 + 0.0035, time: 6.851131]
2023-05-28 20:37:09.023: epoch 48:	0.02512055  	0.18560889  	0.09885000  
2023-05-28 20:37:09.023: Find a better model.
2023-05-28 20:37:15.855: [iter 49 : loss : 0.2566 = 0.0795 + 0.1736 + 0.0035, time: 6.829956]
2023-05-28 20:37:16.009: epoch 49:	0.02513466  	0.18547174  	0.09905911  
2023-05-28 20:37:22.849: [iter 50 : loss : 0.2551 = 0.0783 + 0.1732 + 0.0036, time: 6.838040]
2023-05-28 20:37:23.005: epoch 50:	0.02510643  	0.18538465  	0.09943635  
2023-05-28 20:37:29.844: [iter 51 : loss : 0.2522 = 0.0756 + 0.1730 + 0.0036, time: 6.838004]
2023-05-28 20:37:30.012: epoch 51:	0.02519817  	0.18586946  	0.09980462  
2023-05-28 20:37:30.013: Find a better model.
2023-05-28 20:37:36.846: [iter 52 : loss : 0.2515 = 0.0752 + 0.1726 + 0.0037, time: 6.832024]
2023-05-28 20:37:37.000: epoch 52:	0.02524050  	0.18611155  	0.10016123  
2023-05-28 20:37:37.000: Find a better model.
2023-05-28 20:37:43.843: [iter 53 : loss : 0.2493 = 0.0732 + 0.1723 + 0.0038, time: 6.842008]
2023-05-28 20:37:44.009: epoch 53:	0.02525462  	0.18629527  	0.10063002  
2023-05-28 20:37:44.009: Find a better model.
2023-05-28 20:37:50.844: [iter 54 : loss : 0.2473 = 0.0715 + 0.1720 + 0.0038, time: 6.833108]
2023-05-28 20:37:51.012: epoch 54:	0.02535341  	0.18700689  	0.10109490  
2023-05-28 20:37:51.012: Find a better model.
2023-05-28 20:37:57.653: [iter 55 : loss : 0.2453 = 0.0697 + 0.1717 + 0.0039, time: 6.640163]
2023-05-28 20:37:57.806: epoch 55:	0.02542397  	0.18769653  	0.10154164  
2023-05-28 20:37:57.806: Find a better model.
2023-05-28 20:38:04.450: [iter 56 : loss : 0.2429 = 0.0677 + 0.1713 + 0.0039, time: 6.642419]
2023-05-28 20:38:04.598: epoch 56:	0.02547337  	0.18805192  	0.10196878  
2023-05-28 20:38:04.598: Find a better model.
2023-05-28 20:38:11.247: [iter 57 : loss : 0.2411 = 0.0660 + 0.1712 + 0.0040, time: 6.647014]
2023-05-28 20:38:11.397: epoch 57:	0.02545925  	0.18811300  	0.10208744  
2023-05-28 20:38:11.397: Find a better model.
2023-05-28 20:38:18.242: [iter 58 : loss : 0.2392 = 0.0643 + 0.1709 + 0.0040, time: 6.844004]
2023-05-28 20:38:18.392: epoch 58:	0.02544514  	0.18799421  	0.10222971  
2023-05-28 20:38:25.239: [iter 59 : loss : 0.2379 = 0.0633 + 0.1706 + 0.0041, time: 6.845052]
2023-05-28 20:38:25.406: epoch 59:	0.02547336  	0.18813416  	0.10243503  
2023-05-28 20:38:25.406: Find a better model.
2023-05-28 20:38:32.236: [iter 60 : loss : 0.2363 = 0.0618 + 0.1704 + 0.0041, time: 6.826994]
2023-05-28 20:38:32.403: epoch 60:	0.02554392  	0.18837383  	0.10275771  
2023-05-28 20:38:32.403: Find a better model.
2023-05-28 20:38:39.225: [iter 61 : loss : 0.2350 = 0.0607 + 0.1701 + 0.0042, time: 6.821002]
2023-05-28 20:38:39.389: epoch 61:	0.02560743  	0.18886234  	0.10298183  
2023-05-28 20:38:39.389: Find a better model.
2023-05-28 20:38:46.226: [iter 62 : loss : 0.2333 = 0.0591 + 0.1699 + 0.0042, time: 6.833966]
2023-05-28 20:38:46.396: epoch 62:	0.02560743  	0.18859293  	0.10301259  
2023-05-28 20:38:53.197: [iter 63 : loss : 0.2319 = 0.0580 + 0.1696 + 0.0043, time: 6.799002]
2023-05-28 20:38:53.347: epoch 63:	0.02560038  	0.18856749  	0.10323723  
2023-05-28 20:39:00.196: [iter 64 : loss : 0.2307 = 0.0570 + 0.1694 + 0.0043, time: 6.847401]
2023-05-28 20:39:00.350: epoch 64:	0.02562155  	0.18919133  	0.10342050  
2023-05-28 20:39:00.350: Find a better model.
2023-05-28 20:39:07.205: [iter 65 : loss : 0.2295 = 0.0559 + 0.1692 + 0.0044, time: 6.852630]
2023-05-28 20:39:07.356: epoch 65:	0.02570623  	0.19025406  	0.10372917  
2023-05-28 20:39:07.356: Find a better model.
2023-05-28 20:39:14.217: [iter 66 : loss : 0.2279 = 0.0545 + 0.1690 + 0.0044, time: 6.860314]
2023-05-28 20:39:14.367: epoch 66:	0.02584736  	0.19119479  	0.10422641  
2023-05-28 20:39:14.367: Find a better model.
2023-05-28 20:39:21.212: [iter 67 : loss : 0.2266 = 0.0533 + 0.1688 + 0.0045, time: 6.844010]
2023-05-28 20:39:21.381: epoch 67:	0.02594615  	0.19199917  	0.10461409  
2023-05-28 20:39:21.381: Find a better model.
2023-05-28 20:39:28.193: [iter 68 : loss : 0.2260 = 0.0529 + 0.1686 + 0.0046, time: 6.810994]
2023-05-28 20:39:28.344: epoch 68:	0.02595321  	0.19194908  	0.10468829  
2023-05-28 20:39:35.186: [iter 69 : loss : 0.2242 = 0.0512 + 0.1684 + 0.0046, time: 6.840994]
2023-05-28 20:39:35.337: epoch 69:	0.02595321  	0.19177559  	0.10493816  
2023-05-28 20:39:42.185: [iter 70 : loss : 0.2228 = 0.0499 + 0.1682 + 0.0046, time: 6.846004]
2023-05-28 20:39:42.351: epoch 70:	0.02608728  	0.19275904  	0.10527963  
2023-05-28 20:39:42.352: Find a better model.
2023-05-28 20:39:49.182: [iter 71 : loss : 0.2215 = 0.0488 + 0.1680 + 0.0047, time: 6.828454]
2023-05-28 20:39:49.332: epoch 71:	0.02603788  	0.19248536  	0.10540829  
2023-05-28 20:39:56.004: [iter 72 : loss : 0.2208 = 0.0481 + 0.1679 + 0.0047, time: 6.671129]
2023-05-28 20:39:56.153: epoch 72:	0.02616490  	0.19321908  	0.10565857  
2023-05-28 20:39:56.153: Find a better model.
2023-05-28 20:40:02.798: [iter 73 : loss : 0.2197 = 0.0472 + 0.1677 + 0.0048, time: 6.642994]
2023-05-28 20:40:02.948: epoch 73:	0.02620018  	0.19349837  	0.10598888  
2023-05-28 20:40:02.948: Find a better model.
2023-05-28 20:40:09.802: [iter 74 : loss : 0.2182 = 0.0458 + 0.1676 + 0.0048, time: 6.851017]
2023-05-28 20:40:09.951: epoch 74:	0.02614373  	0.19297174  	0.10598074  
2023-05-28 20:40:16.790: [iter 75 : loss : 0.2179 = 0.0456 + 0.1674 + 0.0049, time: 6.837006]
2023-05-28 20:40:16.938: epoch 75:	0.02619313  	0.19358431  	0.10627617  
2023-05-28 20:40:16.938: Find a better model.
2023-05-28 20:40:23.799: [iter 76 : loss : 0.2168 = 0.0446 + 0.1672 + 0.0049, time: 6.860008]
2023-05-28 20:40:23.949: epoch 76:	0.02627075  	0.19395831  	0.10651269  
2023-05-28 20:40:23.949: Find a better model.
2023-05-28 20:40:30.765: [iter 77 : loss : 0.2159 = 0.0439 + 0.1671 + 0.0050, time: 6.815040]
2023-05-28 20:40:30.935: epoch 77:	0.02622841  	0.19376415  	0.10655122  
2023-05-28 20:40:37.610: [iter 78 : loss : 0.2153 = 0.0433 + 0.1670 + 0.0050, time: 6.674355]
2023-05-28 20:40:37.780: epoch 78:	0.02618607  	0.19352925  	0.10645970  
2023-05-28 20:40:44.392: [iter 79 : loss : 0.2138 = 0.0420 + 0.1668 + 0.0051, time: 6.611025]
2023-05-28 20:40:44.542: epoch 79:	0.02616491  	0.19334094  	0.10634041  
2023-05-28 20:40:51.197: [iter 80 : loss : 0.2130 = 0.0412 + 0.1667 + 0.0051, time: 6.653499]
2023-05-28 20:40:51.363: epoch 80:	0.02618607  	0.19367789  	0.10650009  
2023-05-28 20:40:57.982: [iter 81 : loss : 0.2128 = 0.0411 + 0.1665 + 0.0052, time: 6.617108]
2023-05-28 20:40:58.133: epoch 81:	0.02620018  	0.19416648  	0.10686809  
2023-05-28 20:40:58.133: Find a better model.
2023-05-28 20:41:04.795: [iter 82 : loss : 0.2114 = 0.0398 + 0.1664 + 0.0052, time: 6.659045]
2023-05-28 20:41:04.961: epoch 82:	0.02621430  	0.19420269  	0.10692365  
2023-05-28 20:41:04.961: Find a better model.
2023-05-28 20:41:11.587: [iter 83 : loss : 0.2109 = 0.0394 + 0.1663 + 0.0052, time: 6.625015]
2023-05-28 20:41:11.737: epoch 83:	0.02632720  	0.19491641  	0.10729400  
2023-05-28 20:41:11.738: Find a better model.
2023-05-28 20:41:18.383: [iter 84 : loss : 0.2106 = 0.0391 + 0.1662 + 0.0053, time: 6.643013]
2023-05-28 20:41:18.533: epoch 84:	0.02633425  	0.19485356  	0.10735063  
2023-05-28 20:41:25.185: [iter 85 : loss : 0.2099 = 0.0385 + 0.1660 + 0.0053, time: 6.651016]
2023-05-28 20:41:25.333: epoch 85:	0.02639776  	0.19516456  	0.10741442  
2023-05-28 20:41:25.333: Find a better model.
2023-05-28 20:41:31.985: [iter 86 : loss : 0.2093 = 0.0381 + 0.1659 + 0.0054, time: 6.649035]
2023-05-28 20:41:32.147: epoch 86:	0.02642598  	0.19563623  	0.10773169  
2023-05-28 20:41:32.147: Find a better model.
2023-05-28 20:41:38.946: [iter 87 : loss : 0.2074 = 0.0362 + 0.1658 + 0.0054, time: 6.798113]
2023-05-28 20:41:39.094: epoch 87:	0.02645421  	0.19585200  	0.10792069  
2023-05-28 20:41:39.094: Find a better model.
2023-05-28 20:41:45.771: [iter 88 : loss : 0.2069 = 0.0357 + 0.1657 + 0.0055, time: 6.675997]
2023-05-28 20:41:45.918: epoch 88:	0.02646127  	0.19568017  	0.10788272  
2023-05-28 20:41:52.760: [iter 89 : loss : 0.2062 = 0.0351 + 0.1656 + 0.0055, time: 6.840994]
2023-05-28 20:41:52.910: epoch 89:	0.02645421  	0.19570979  	0.10798243  
2023-05-28 20:41:59.774: [iter 90 : loss : 0.2067 = 0.0357 + 0.1655 + 0.0055, time: 6.861362]
2023-05-28 20:41:59.923: epoch 90:	0.02649656  	0.19594097  	0.10803846  
2023-05-28 20:41:59.923: Find a better model.
2023-05-28 20:42:06.763: [iter 91 : loss : 0.2055 = 0.0346 + 0.1653 + 0.0056, time: 6.838109]
2023-05-28 20:42:06.910: epoch 91:	0.02651067  	0.19615981  	0.10808169  
2023-05-28 20:42:06.910: Find a better model.
2023-05-28 20:42:13.747: [iter 92 : loss : 0.2047 = 0.0338 + 0.1652 + 0.0056, time: 6.836021]
2023-05-28 20:42:13.895: epoch 92:	0.02646833  	0.19608849  	0.10795525  
2023-05-28 20:42:20.732: [iter 93 : loss : 0.2049 = 0.0341 + 0.1652 + 0.0057, time: 6.836000]
2023-05-28 20:42:20.880: epoch 93:	0.02647538  	0.19635986  	0.10802782  
2023-05-28 20:42:20.880: Find a better model.
2023-05-28 20:42:27.744: [iter 94 : loss : 0.2033 = 0.0326 + 0.1651 + 0.0057, time: 6.861181]
2023-05-28 20:42:27.893: epoch 94:	0.02634836  	0.19554439  	0.10789605  
2023-05-28 20:42:34.741: [iter 95 : loss : 0.2027 = 0.0320 + 0.1650 + 0.0057, time: 6.846039]
2023-05-28 20:42:34.889: epoch 95:	0.02640481  	0.19595715  	0.10820185  
2023-05-28 20:42:41.750: [iter 96 : loss : 0.2027 = 0.0320 + 0.1649 + 0.0058, time: 6.860001]
2023-05-28 20:42:41.900: epoch 96:	0.02641187  	0.19598733  	0.10830095  
2023-05-28 20:42:48.764: [iter 97 : loss : 0.2013 = 0.0307 + 0.1647 + 0.0058, time: 6.863011]
2023-05-28 20:42:48.927: epoch 97:	0.02638365  	0.19595456  	0.10826007  
2023-05-28 20:42:55.740: [iter 98 : loss : 0.2017 = 0.0311 + 0.1647 + 0.0059, time: 6.811116]
2023-05-28 20:42:55.888: epoch 98:	0.02639776  	0.19580990  	0.10828524  
2023-05-28 20:43:02.741: [iter 99 : loss : 0.2007 = 0.0302 + 0.1646 + 0.0059, time: 6.851008]
2023-05-28 20:43:02.890: epoch 99:	0.02648243  	0.19658715  	0.10855080  
2023-05-28 20:43:02.891: Find a better model.
2023-05-28 20:43:09.731: [iter 100 : loss : 0.2004 = 0.0300 + 0.1645 + 0.0059, time: 6.839134]
2023-05-28 20:43:09.881: epoch 100:	0.02641187  	0.19614963  	0.10845903  
2023-05-28 20:43:16.725: [iter 101 : loss : 0.1999 = 0.0295 + 0.1644 + 0.0060, time: 6.842204]
2023-05-28 20:43:16.875: epoch 101:	0.02648949  	0.19625472  	0.10862999  
2023-05-28 20:43:23.722: [iter 102 : loss : 0.1994 = 0.0291 + 0.1643 + 0.0060, time: 6.846014]
2023-05-28 20:43:23.872: epoch 102:	0.02646832  	0.19598623  	0.10863955  
2023-05-28 20:43:30.719: [iter 103 : loss : 0.1989 = 0.0286 + 0.1642 + 0.0061, time: 6.846005]
2023-05-28 20:43:30.869: epoch 103:	0.02647538  	0.19615139  	0.10864387  
2023-05-28 20:43:37.529: [iter 104 : loss : 0.1993 = 0.0291 + 0.1642 + 0.0061, time: 6.659033]
2023-05-28 20:43:37.675: epoch 104:	0.02648949  	0.19617699  	0.10867041  
2023-05-28 20:43:44.328: [iter 105 : loss : 0.1987 = 0.0285 + 0.1641 + 0.0061, time: 6.652004]
2023-05-28 20:43:44.477: epoch 105:	0.02648949  	0.19613118  	0.10863804  
2023-05-28 20:43:51.315: [iter 106 : loss : 0.1980 = 0.0278 + 0.1640 + 0.0062, time: 6.836056]
2023-05-28 20:43:51.478: epoch 106:	0.02656711  	0.19663142  	0.10873444  
2023-05-28 20:43:51.478: Find a better model.
2023-05-28 20:43:58.145: [iter 107 : loss : 0.1974 = 0.0272 + 0.1640 + 0.0062, time: 6.666000]
2023-05-28 20:43:58.309: epoch 107:	0.02645420  	0.19563024  	0.10840784  
2023-05-28 20:44:05.112: [iter 108 : loss : 0.1972 = 0.0270 + 0.1640 + 0.0062, time: 6.801008]
2023-05-28 20:44:05.261: epoch 108:	0.02649654  	0.19586909  	0.10858419  
2023-05-28 20:44:12.110: [iter 109 : loss : 0.1961 = 0.0260 + 0.1638 + 0.0063, time: 6.847045]
2023-05-28 20:44:12.262: epoch 109:	0.02656005  	0.19655815  	0.10878576  
2023-05-28 20:44:19.095: [iter 110 : loss : 0.1958 = 0.0257 + 0.1638 + 0.0063, time: 6.832103]
2023-05-28 20:44:19.244: epoch 110:	0.02648948  	0.19595064  	0.10855438  
2023-05-28 20:44:25.923: [iter 111 : loss : 0.1956 = 0.0255 + 0.1637 + 0.0064, time: 6.678396]
2023-05-28 20:44:26.073: epoch 111:	0.02652477  	0.19634345  	0.10870305  
2023-05-28 20:44:32.708: [iter 112 : loss : 0.1956 = 0.0255 + 0.1636 + 0.0064, time: 6.634004]
2023-05-28 20:44:32.856: epoch 112:	0.02653182  	0.19605781  	0.10867904  
2023-05-28 20:44:39.515: [iter 113 : loss : 0.1954 = 0.0254 + 0.1636 + 0.0064, time: 6.656955]
2023-05-28 20:44:39.663: epoch 113:	0.02655299  	0.19632283  	0.10865598  
2023-05-28 20:44:46.312: [iter 114 : loss : 0.1946 = 0.0247 + 0.1635 + 0.0065, time: 6.647094]
2023-05-28 20:44:46.476: epoch 114:	0.02653887  	0.19619776  	0.10863727  
2023-05-28 20:44:53.100: [iter 115 : loss : 0.1944 = 0.0245 + 0.1634 + 0.0065, time: 6.623003]
2023-05-28 20:44:53.248: epoch 115:	0.02648242  	0.19553566  	0.10853362  
2023-05-28 20:44:59.888: [iter 116 : loss : 0.1938 = 0.0239 + 0.1634 + 0.0065, time: 6.638008]
2023-05-28 20:45:00.041: epoch 116:	0.02658827  	0.19625354  	0.10884143  
2023-05-28 20:45:06.701: [iter 117 : loss : 0.1936 = 0.0237 + 0.1633 + 0.0066, time: 6.657110]
2023-05-28 20:45:06.851: epoch 117:	0.02655298  	0.19610575  	0.10891648  
2023-05-28 20:45:13.507: [iter 118 : loss : 0.1934 = 0.0236 + 0.1632 + 0.0066, time: 6.655004]
2023-05-28 20:45:13.654: epoch 118:	0.02649653  	0.19571614  	0.10901328  
2023-05-28 20:45:20.305: [iter 119 : loss : 0.1928 = 0.0229 + 0.1632 + 0.0066, time: 6.649191]
2023-05-28 20:45:20.466: epoch 119:	0.02658827  	0.19665094  	0.10915856  
2023-05-28 20:45:20.466: Find a better model.
2023-05-28 20:45:27.104: [iter 120 : loss : 0.1930 = 0.0232 + 0.1631 + 0.0067, time: 6.637022]
2023-05-28 20:45:27.268: epoch 120:	0.02660238  	0.19654900  	0.10907821  
2023-05-28 20:45:33.901: [iter 121 : loss : 0.1929 = 0.0231 + 0.1630 + 0.0067, time: 6.631995]
2023-05-28 20:45:34.059: epoch 121:	0.02653887  	0.19612961  	0.10900258  
2023-05-28 20:45:40.691: [iter 122 : loss : 0.1924 = 0.0227 + 0.1630 + 0.0067, time: 6.631010]
2023-05-28 20:45:40.841: epoch 122:	0.02658121  	0.19656675  	0.10928911  
2023-05-28 20:45:47.476: [iter 123 : loss : 0.1920 = 0.0223 + 0.1630 + 0.0068, time: 6.634090]
2023-05-28 20:45:47.624: epoch 123:	0.02660944  	0.19671483  	0.10947834  
2023-05-28 20:45:47.624: Find a better model.
2023-05-28 20:45:54.288: [iter 124 : loss : 0.1914 = 0.0217 + 0.1629 + 0.0068, time: 6.662014]
2023-05-28 20:45:54.436: epoch 124:	0.02654593  	0.19628309  	0.10934006  
2023-05-28 20:46:01.077: [iter 125 : loss : 0.1909 = 0.0213 + 0.1628 + 0.0068, time: 6.639210]
2023-05-28 20:46:01.226: epoch 125:	0.02658827  	0.19648954  	0.10935852  
2023-05-28 20:46:07.893: [iter 126 : loss : 0.1910 = 0.0214 + 0.1628 + 0.0069, time: 6.665050]
2023-05-28 20:46:08.061: epoch 126:	0.02656710  	0.19632193  	0.10944160  
2023-05-28 20:46:14.688: [iter 127 : loss : 0.1904 = 0.0207 + 0.1628 + 0.0069, time: 6.626033]
2023-05-28 20:46:14.838: epoch 127:	0.02657416  	0.19659731  	0.10957196  
2023-05-28 20:46:21.459: [iter 128 : loss : 0.1909 = 0.0213 + 0.1627 + 0.0069, time: 6.619008]
2023-05-28 20:46:21.606: epoch 128:	0.02656006  	0.19646347  	0.10947241  
2023-05-28 20:46:28.262: [iter 129 : loss : 0.1905 = 0.0208 + 0.1627 + 0.0070, time: 6.654950]
2023-05-28 20:46:28.411: epoch 129:	0.02656006  	0.19650359  	0.10936069  
2023-05-28 20:46:35.053: [iter 130 : loss : 0.1903 = 0.0207 + 0.1626 + 0.0070, time: 6.641003]
2023-05-28 20:46:35.200: epoch 130:	0.02654594  	0.19638464  	0.10929969  
2023-05-28 20:46:41.841: [iter 131 : loss : 0.1897 = 0.0201 + 0.1625 + 0.0070, time: 6.638003]
2023-05-28 20:46:41.995: epoch 131:	0.02653888  	0.19649042  	0.10944568  
2023-05-28 20:46:48.466: [iter 132 : loss : 0.1898 = 0.0202 + 0.1625 + 0.0070, time: 6.468956]
2023-05-28 20:46:48.616: epoch 132:	0.02656711  	0.19630691  	0.10946345  
2023-05-28 20:46:55.260: [iter 133 : loss : 0.1888 = 0.0193 + 0.1625 + 0.0071, time: 6.643041]
2023-05-28 20:46:55.409: epoch 133:	0.02641893  	0.19518003  	0.10903091  
2023-05-28 20:47:02.059: [iter 134 : loss : 0.1893 = 0.0198 + 0.1624 + 0.0071, time: 6.648010]
2023-05-28 20:47:02.221: epoch 134:	0.02643304  	0.19506139  	0.10905414  
2023-05-28 20:47:08.858: [iter 135 : loss : 0.1892 = 0.0197 + 0.1624 + 0.0071, time: 6.635994]
2023-05-28 20:47:09.025: epoch 135:	0.02639069  	0.19463305  	0.10900831  
2023-05-28 20:47:15.652: [iter 136 : loss : 0.1890 = 0.0194 + 0.1624 + 0.0072, time: 6.626486]
2023-05-28 20:47:15.803: epoch 136:	0.02635541  	0.19431278  	0.10883197  
2023-05-28 20:47:22.435: [iter 137 : loss : 0.1885 = 0.0190 + 0.1623 + 0.0072, time: 6.630140]
2023-05-28 20:47:22.583: epoch 137:	0.02639775  	0.19463661  	0.10900687  
2023-05-28 20:47:29.244: [iter 138 : loss : 0.1884 = 0.0189 + 0.1622 + 0.0072, time: 6.660009]
2023-05-28 20:47:29.410: epoch 138:	0.02637657  	0.19429831  	0.10908500  
2023-05-28 20:47:36.038: [iter 139 : loss : 0.1882 = 0.0188 + 0.1622 + 0.0073, time: 6.627028]
2023-05-28 20:47:36.186: epoch 139:	0.02639775  	0.19463982  	0.10910813  
2023-05-28 20:47:42.821: [iter 140 : loss : 0.1877 = 0.0183 + 0.1621 + 0.0073, time: 6.634003]
2023-05-28 20:47:42.972: epoch 140:	0.02643303  	0.19476394  	0.10920545  
2023-05-28 20:47:49.453: [iter 141 : loss : 0.1880 = 0.0186 + 0.1621 + 0.0073, time: 6.479005]
2023-05-28 20:47:49.601: epoch 141:	0.02639775  	0.19454013  	0.10907369  
2023-05-28 20:47:56.246: [iter 142 : loss : 0.1874 = 0.0180 + 0.1621 + 0.0073, time: 6.644011]
2023-05-28 20:47:56.412: epoch 142:	0.02636953  	0.19401604  	0.10915129  
2023-05-28 20:48:03.035: [iter 143 : loss : 0.1874 = 0.0181 + 0.1620 + 0.0074, time: 6.622443]
2023-05-28 20:48:03.184: epoch 143:	0.02634130  	0.19387284  	0.10903539  
2023-05-28 20:48:09.838: [iter 144 : loss : 0.1870 = 0.0176 + 0.1620 + 0.0074, time: 6.652009]
2023-05-28 20:48:10.004: epoch 144:	0.02632719  	0.19385220  	0.10894445  
2023-05-28 20:48:16.630: [iter 145 : loss : 0.1871 = 0.0177 + 0.1620 + 0.0074, time: 6.623000]
2023-05-28 20:48:16.777: epoch 145:	0.02627074  	0.19358119  	0.10871964  
2023-05-28 20:48:23.239: [iter 146 : loss : 0.1871 = 0.0177 + 0.1620 + 0.0074, time: 6.461004]
2023-05-28 20:48:23.390: epoch 146:	0.02636952  	0.19406927  	0.10887925  
2023-05-28 20:48:29.834: [iter 147 : loss : 0.1869 = 0.0176 + 0.1619 + 0.0075, time: 6.443037]
2023-05-28 20:48:29.991: epoch 147:	0.02639775  	0.19427493  	0.10905454  
2023-05-28 20:48:36.623: [iter 148 : loss : 0.1859 = 0.0166 + 0.1618 + 0.0075, time: 6.629999]
2023-05-28 20:48:36.775: epoch 148:	0.02639775  	0.19421774  	0.10932521  
2023-05-28 20:48:36.775: Early stopping is trigger at epoch: 148
2023-05-28 20:48:36.775: best_result@epoch 123:

2023-05-28 20:48:36.775: 		0.0266      	0.1967      	0.1095      
2023-05-28 21:05:08.288: my pid: 16004
2023-05-28 21:05:08.288: model: model.general_recommender.SGL
2023-05-28 21:05:08.288: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-28 21:05:08.288: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-28 21:05:12.054: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-28 21:05:19.319: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.264025]
2023-05-28 21:05:19.474: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-28 21:05:19.474: Find a better model.
2023-05-28 21:05:26.861: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.386049]
2023-05-28 21:05:27.063: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-28 21:05:27.063: Find a better model.
2023-05-28 21:05:34.288: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.223045]
2023-05-28 21:05:34.463: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-28 21:05:34.463: Find a better model.
2023-05-28 21:05:41.662: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.197222]
2023-05-28 21:05:41.820: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-28 21:05:41.820: Find a better model.
2023-05-28 21:05:48.891: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.070010]
2023-05-28 21:05:49.048: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-28 21:05:49.048: Find a better model.
2023-05-28 21:05:56.228: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 7.179333]
2023-05-28 21:05:56.384: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-28 21:05:56.384: Find a better model.
2023-05-28 21:06:03.242: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.857029]
2023-05-28 21:06:03.397: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-28 21:06:03.397: Find a better model.
2023-05-28 21:06:10.230: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.832064]
2023-05-28 21:06:10.381: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-28 21:06:10.381: Find a better model.
2023-05-28 21:06:17.044: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.662028]
2023-05-28 21:06:17.196: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-28 21:06:24.030: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.833138]
2023-05-28 21:06:24.184: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-28 21:06:30.851: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.665161]
2023-05-28 21:06:31.007: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-28 21:06:37.647: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.639041]
2023-05-28 21:06:37.792: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-28 21:06:44.419: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.625041]
2023-05-28 21:06:44.577: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-28 21:06:51.225: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.647106]
2023-05-28 21:06:51.380: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-28 21:06:58.027: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.645965]
2023-05-28 21:06:58.184: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-28 21:06:58.184: Find a better model.
2023-05-28 21:07:04.833: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.648029]
2023-05-28 21:07:04.976: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-28 21:07:04.976: Find a better model.
2023-05-28 21:07:11.604: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.627017]
2023-05-28 21:07:11.758: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-28 21:07:11.758: Find a better model.
2023-05-28 21:07:18.431: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.670902]
2023-05-28 21:07:18.584: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-28 21:07:18.584: Find a better model.
2023-05-28 21:07:25.206: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.621134]
2023-05-28 21:07:25.359: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-28 21:07:25.360: Find a better model.
2023-05-28 21:07:32.010: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.649100]
2023-05-28 21:07:32.166: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-28 21:07:32.166: Find a better model.
2023-05-28 21:07:38.985: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.818421]
2023-05-28 21:07:39.141: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-28 21:07:39.141: Find a better model.
2023-05-28 21:07:45.806: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.663008]
2023-05-28 21:07:45.963: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-28 21:07:45.963: Find a better model.
2023-05-28 21:07:52.616: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.652057]
2023-05-28 21:07:52.772: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-28 21:07:52.772: Find a better model.
2023-05-28 21:07:59.407: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.634061]
2023-05-28 21:07:59.560: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-28 21:07:59.561: Find a better model.
2023-05-28 21:08:06.220: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.658013]
2023-05-28 21:08:06.375: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-28 21:08:06.375: Find a better model.
2023-05-28 21:08:13.213: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.837468]
2023-05-28 21:08:13.367: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-28 21:08:13.367: Find a better model.
2023-05-28 21:08:20.191: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.822994]
2023-05-28 21:08:20.335: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-28 21:08:20.335: Find a better model.
2023-05-28 21:08:26.997: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.660254]
2023-05-28 21:08:27.151: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-28 21:08:27.151: Find a better model.
2023-05-28 21:08:33.796: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.644000]
2023-05-28 21:08:33.955: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-28 21:08:33.955: Find a better model.
2023-05-28 21:08:40.601: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.645993]
2023-05-28 21:08:40.745: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-28 21:08:40.745: Find a better model.
2023-05-28 21:08:47.411: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.663110]
2023-05-28 21:08:47.564: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-28 21:08:47.564: Find a better model.
2023-05-28 21:08:54.195: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.629004]
2023-05-28 21:08:54.350: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-28 21:08:54.350: Find a better model.
2023-05-28 21:09:00.973: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.621350]
2023-05-28 21:09:01.128: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-28 21:09:01.128: Find a better model.
2023-05-28 21:09:07.798: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.668075]
2023-05-28 21:09:07.955: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-28 21:09:07.955: Find a better model.
2023-05-28 21:09:14.602: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.646010]
2023-05-28 21:09:14.756: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-28 21:09:14.756: Find a better model.
2023-05-28 21:09:21.380: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.623015]
2023-05-28 21:09:21.533: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-28 21:09:21.533: Find a better model.
2023-05-28 21:09:28.195: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.661000]
2023-05-28 21:09:28.347: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-28 21:09:28.347: Find a better model.
2023-05-28 21:09:35.151: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.802217]
2023-05-28 21:09:35.307: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-28 21:09:35.307: Find a better model.
2023-05-28 21:09:41.975: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.667052]
2023-05-28 21:09:42.129: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-28 21:09:42.129: Find a better model.
2023-05-28 21:09:48.766: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.634465]
2023-05-28 21:09:48.921: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-28 21:09:55.757: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.835026]
2023-05-28 21:09:55.908: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-28 21:09:55.908: Find a better model.
2023-05-28 21:10:02.576: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.665993]
2023-05-28 21:10:02.718: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-28 21:10:02.718: Find a better model.
2023-05-28 21:10:09.166: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.446002]
2023-05-28 21:10:09.319: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-28 21:10:09.319: Find a better model.
2023-05-28 21:10:15.985: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.665208]
2023-05-28 21:10:16.139: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-28 21:10:16.139: Find a better model.
2023-05-28 21:10:22.946: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.806055]
2023-05-28 21:10:23.102: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-28 21:10:23.102: Find a better model.
2023-05-28 21:10:29.753: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.650191]
2023-05-28 21:10:29.895: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-28 21:10:29.895: Find a better model.
2023-05-28 21:10:36.360: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.463998]
2023-05-28 21:10:36.512: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-28 21:10:36.512: Find a better model.
2023-05-28 21:10:43.131: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.616996]
2023-05-28 21:10:43.282: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-28 21:10:43.282: Find a better model.
2023-05-28 21:10:49.755: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.470994]
2023-05-28 21:10:49.906: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-28 21:10:49.906: Find a better model.
2023-05-28 21:10:56.372: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.464994]
2023-05-28 21:10:56.526: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-28 21:10:56.526: Find a better model.
2023-05-28 21:11:03.142: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.615066]
2023-05-28 21:11:03.294: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-28 21:11:09.912: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.617062]
2023-05-28 21:11:10.068: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-28 21:11:10.068: Find a better model.
2023-05-28 21:11:16.737: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.668021]
2023-05-28 21:11:16.893: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-28 21:11:16.893: Find a better model.
2023-05-28 21:11:23.340: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.445195]
2023-05-28 21:11:23.493: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-28 21:11:23.493: Find a better model.
2023-05-28 21:11:30.149: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.655052]
2023-05-28 21:11:30.301: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-28 21:11:30.301: Find a better model.
2023-05-28 21:11:36.904: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.601994]
2023-05-28 21:11:37.046: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-28 21:11:37.047: Find a better model.
2023-05-28 21:11:43.548: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.500432]
2023-05-28 21:11:43.702: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-28 21:11:43.702: Find a better model.
2023-05-28 21:11:50.130: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.426993]
2023-05-28 21:11:50.283: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-28 21:11:50.284: Find a better model.
2023-05-28 21:11:56.917: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.631994]
2023-05-28 21:11:57.061: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-28 21:11:57.062: Find a better model.
2023-05-28 21:12:03.703: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.640080]
2023-05-28 21:12:03.843: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-28 21:12:03.843: Find a better model.
2023-05-28 21:12:10.313: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.468004]
2023-05-28 21:12:10.465: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-28 21:12:10.465: Find a better model.
2023-05-28 21:12:17.102: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.635994]
2023-05-28 21:12:17.255: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-28 21:12:17.255: Find a better model.
2023-05-28 21:12:23.898: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.642104]
2023-05-28 21:12:24.054: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-28 21:12:30.515: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.458994]
2023-05-28 21:12:30.669: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-28 21:12:30.669: Find a better model.
2023-05-28 21:12:37.114: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.442994]
2023-05-28 21:12:37.266: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-28 21:12:37.266: Find a better model.
2023-05-28 21:12:43.706: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.438994]
2023-05-28 21:12:43.865: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-28 21:12:43.865: Find a better model.
2023-05-28 21:12:50.487: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.620096]
2023-05-28 21:12:50.640: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-28 21:12:50.641: Find a better model.
2023-05-28 21:12:57.107: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.465143]
2023-05-28 21:12:57.261: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-28 21:12:57.261: Find a better model.
2023-05-28 21:13:03.705: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.442510]
2023-05-28 21:13:03.857: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-28 21:13:03.857: Find a better model.
2023-05-28 21:13:10.333: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.473994]
2023-05-28 21:13:10.491: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-28 21:13:10.491: Find a better model.
2023-05-28 21:13:17.100: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.607024]
2023-05-28 21:13:17.251: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-28 21:13:24.083: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.830993]
2023-05-28 21:13:24.236: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-28 21:13:24.236: Find a better model.
2023-05-28 21:13:31.064: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.827023]
2023-05-28 21:13:31.221: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-28 21:13:31.221: Find a better model.
2023-05-28 21:13:37.878: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.656047]
2023-05-28 21:13:38.034: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-28 21:13:44.693: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.657508]
2023-05-28 21:13:44.847: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-28 21:13:51.310: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.462193]
2023-05-28 21:13:51.464: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-28 21:13:51.464: Find a better model.
2023-05-28 21:13:57.885: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.419994]
2023-05-28 21:13:58.040: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-28 21:13:58.040: Find a better model.
2023-05-28 21:14:04.671: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.628415]
2023-05-28 21:14:04.823: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-28 21:14:04.823: Find a better model.
2023-05-28 21:14:11.275: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.450295]
2023-05-28 21:14:11.431: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-28 21:14:18.061: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.628999]
2023-05-28 21:14:18.221: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-28 21:14:18.221: Find a better model.
2023-05-28 21:14:24.849: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.626999]
2023-05-28 21:14:25.009: epoch 81:	0.02575562  	0.19010241  	0.10375397  
2023-05-28 21:14:25.009: Find a better model.
2023-05-28 21:14:31.480: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.469088]
2023-05-28 21:14:31.635: epoch 82:	0.02593909  	0.19127873  	0.10442533  
2023-05-28 21:14:31.635: Find a better model.
2023-05-28 21:14:38.097: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.461590]
2023-05-28 21:14:38.252: epoch 83:	0.02591792  	0.19122753  	0.10434162  
2023-05-28 21:14:44.672: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.418098]
2023-05-28 21:14:44.824: epoch 84:	0.02591792  	0.19129056  	0.10438651  
2023-05-28 21:14:44.824: Find a better model.
2023-05-28 21:14:51.273: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.448153]
2023-05-28 21:14:51.427: epoch 85:	0.02591087  	0.19136642  	0.10479141  
2023-05-28 21:14:51.427: Find a better model.
2023-05-28 21:14:58.053: [iter 86 : loss : 0.1368 = 0.0466 + 0.0854 + 0.0049, time: 6.623994]
2023-05-28 21:14:58.207: epoch 86:	0.02597438  	0.19166841  	0.10489704  
2023-05-28 21:14:58.207: Find a better model.
2023-05-28 21:15:04.846: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.636077]
2023-05-28 21:15:05.003: epoch 87:	0.02607317  	0.19224219  	0.10512664  
2023-05-28 21:15:05.003: Find a better model.
2023-05-28 21:15:11.461: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.457542]
2023-05-28 21:15:11.614: epoch 88:	0.02608023  	0.19226837  	0.10511711  
2023-05-28 21:15:11.614: Find a better model.
2023-05-28 21:15:18.086: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.471112]
2023-05-28 21:15:18.242: epoch 89:	0.02603083  	0.19170186  	0.10493099  
2023-05-28 21:15:24.853: [iter 90 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 6.610137]
2023-05-28 21:15:24.997: epoch 90:	0.02620724  	0.19286238  	0.10541573  
2023-05-28 21:15:24.997: Find a better model.
2023-05-28 21:15:31.622: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.623012]
2023-05-28 21:15:31.777: epoch 91:	0.02622136  	0.19309144  	0.10551340  
2023-05-28 21:15:31.777: Find a better model.
2023-05-28 21:15:38.437: [iter 92 : loss : 0.1315 = 0.0415 + 0.0849 + 0.0051, time: 6.658065]
2023-05-28 21:15:38.592: epoch 92:	0.02627075  	0.19332008  	0.10576107  
2023-05-28 21:15:38.592: Find a better model.
2023-05-28 21:15:45.049: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.456000]
2023-05-28 21:15:45.202: epoch 93:	0.02626370  	0.19348286  	0.10588794  
2023-05-28 21:15:45.202: Find a better model.
2023-05-28 21:15:51.829: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.625017]
2023-05-28 21:15:51.985: epoch 94:	0.02635543  	0.19406378  	0.10619074  
2023-05-28 21:15:51.985: Find a better model.
2023-05-28 21:15:58.439: [iter 95 : loss : 0.1292 = 0.0394 + 0.0847 + 0.0052, time: 6.453016]
2023-05-28 21:15:58.591: epoch 95:	0.02632015  	0.19381511  	0.10616567  
2023-05-28 21:16:05.279: [iter 96 : loss : 0.1293 = 0.0395 + 0.0846 + 0.0052, time: 6.687086]
2023-05-28 21:16:05.440: epoch 96:	0.02631309  	0.19380218  	0.10632121  
2023-05-28 21:16:12.012: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 6.569993]
2023-05-28 21:16:12.166: epoch 97:	0.02635543  	0.19422498  	0.10641174  
2023-05-28 21:16:12.166: Find a better model.
2023-05-28 21:16:18.830: [iter 98 : loss : 0.1284 = 0.0386 + 0.0844 + 0.0053, time: 6.663000]
2023-05-28 21:16:18.987: epoch 98:	0.02649656  	0.19535162  	0.10685667  
2023-05-28 21:16:18.988: Find a better model.
2023-05-28 21:16:25.632: [iter 99 : loss : 0.1274 = 0.0377 + 0.0844 + 0.0053, time: 6.642993]
2023-05-28 21:16:25.787: epoch 99:	0.02656006  	0.19601974  	0.10707307  
2023-05-28 21:16:25.787: Find a better model.
2023-05-28 21:16:32.248: [iter 100 : loss : 0.1269 = 0.0373 + 0.0843 + 0.0054, time: 6.459106]
2023-05-28 21:16:32.402: epoch 100:	0.02658829  	0.19632106  	0.10702197  
2023-05-28 21:16:32.402: Find a better model.
2023-05-28 21:16:39.027: [iter 101 : loss : 0.1264 = 0.0369 + 0.0842 + 0.0054, time: 6.624025]
2023-05-28 21:16:39.180: epoch 101:	0.02660946  	0.19651890  	0.10707853  
2023-05-28 21:16:39.180: Find a better model.
2023-05-28 21:16:45.814: [iter 102 : loss : 0.1254 = 0.0359 + 0.0841 + 0.0055, time: 6.632993]
2023-05-28 21:16:45.970: epoch 102:	0.02668708  	0.19693109  	0.10740847  
2023-05-28 21:16:45.970: Find a better model.
2023-05-28 21:16:52.421: [iter 103 : loss : 0.1254 = 0.0359 + 0.0840 + 0.0055, time: 6.449977]
2023-05-28 21:16:52.577: epoch 103:	0.02673648  	0.19711666  	0.10746574  
2023-05-28 21:16:52.577: Find a better model.
2023-05-28 21:16:59.198: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 6.618994]
2023-05-28 21:16:59.352: epoch 104:	0.02677176  	0.19759600  	0.10782146  
2023-05-28 21:16:59.352: Find a better model.
2023-05-28 21:17:06.015: [iter 105 : loss : 0.1250 = 0.0356 + 0.0839 + 0.0056, time: 6.661781]
2023-05-28 21:17:06.170: epoch 105:	0.02671531  	0.19737288  	0.10782990  
2023-05-28 21:17:12.805: [iter 106 : loss : 0.1245 = 0.0351 + 0.0838 + 0.0056, time: 6.634005]
2023-05-28 21:17:12.969: epoch 106:	0.02669414  	0.19675760  	0.10753261  
2023-05-28 21:17:19.426: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 6.455029]
2023-05-28 21:17:19.579: epoch 107:	0.02675059  	0.19707580  	0.10767967  
2023-05-28 21:17:26.189: [iter 108 : loss : 0.1233 = 0.0339 + 0.0838 + 0.0057, time: 6.609025]
2023-05-28 21:17:26.343: epoch 108:	0.02674353  	0.19727808  	0.10775982  
2023-05-28 21:17:33.022: [iter 109 : loss : 0.1221 = 0.0328 + 0.0836 + 0.0057, time: 6.678114]
2023-05-28 21:17:33.175: epoch 109:	0.02679998  	0.19769494  	0.10781121  
2023-05-28 21:17:33.175: Find a better model.
2023-05-28 21:17:39.784: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 6.608097]
2023-05-28 21:17:39.944: epoch 110:	0.02684232  	0.19785798  	0.10784786  
2023-05-28 21:17:39.944: Find a better model.
2023-05-28 21:17:46.409: [iter 111 : loss : 0.1214 = 0.0321 + 0.0835 + 0.0058, time: 6.464458]
2023-05-28 21:17:46.562: epoch 111:	0.02683526  	0.19808450  	0.10796522  
2023-05-28 21:17:46.562: Find a better model.
2023-05-28 21:17:53.174: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.611136]
2023-05-28 21:17:53.329: epoch 112:	0.02691993  	0.19867483  	0.10817447  
2023-05-28 21:17:53.329: Find a better model.
2023-05-28 21:17:59.980: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.649337]
2023-05-28 21:18:00.133: epoch 113:	0.02695522  	0.19914421  	0.10828193  
2023-05-28 21:18:00.133: Find a better model.
2023-05-28 21:18:06.613: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.479477]
2023-05-28 21:18:06.766: epoch 114:	0.02696933  	0.19924569  	0.10849025  
2023-05-28 21:18:06.766: Find a better model.
2023-05-28 21:18:13.217: [iter 115 : loss : 0.1201 = 0.0309 + 0.0833 + 0.0059, time: 6.450177]
2023-05-28 21:18:13.371: epoch 115:	0.02695521  	0.19859578  	0.10845681  
2023-05-28 21:18:19.795: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.420466]
2023-05-28 21:18:19.955: epoch 116:	0.02690581  	0.19806486  	0.10830446  
2023-05-28 21:18:26.572: [iter 117 : loss : 0.1192 = 0.0301 + 0.0832 + 0.0060, time: 6.615023]
2023-05-28 21:18:26.725: epoch 117:	0.02690581  	0.19802162  	0.10818756  
2023-05-28 21:18:33.173: [iter 118 : loss : 0.1190 = 0.0299 + 0.0832 + 0.0060, time: 6.447015]
2023-05-28 21:18:33.329: epoch 118:	0.02696932  	0.19853675  	0.10840670  
2023-05-28 21:18:39.798: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.468022]
2023-05-28 21:18:39.954: epoch 119:	0.02693404  	0.19828652  	0.10854238  
2023-05-28 21:18:46.389: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.433004]
2023-05-28 21:18:46.543: epoch 120:	0.02699755  	0.19873168  	0.10873766  
2023-05-28 21:18:53.160: [iter 121 : loss : 0.1184 = 0.0293 + 0.0830 + 0.0061, time: 6.616381]
2023-05-28 21:18:53.313: epoch 121:	0.02697637  	0.19845463  	0.10879749  
2023-05-28 21:18:59.971: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.657013]
2023-05-28 21:19:00.129: epoch 122:	0.02702577  	0.19889085  	0.10889582  
2023-05-28 21:19:06.767: [iter 123 : loss : 0.1175 = 0.0284 + 0.0829 + 0.0061, time: 6.635023]
2023-05-28 21:19:06.921: epoch 123:	0.02698343  	0.19858441  	0.10859056  
2023-05-28 21:19:13.564: [iter 124 : loss : 0.1164 = 0.0273 + 0.0829 + 0.0062, time: 6.641009]
2023-05-28 21:19:13.719: epoch 124:	0.02703282  	0.19897889  	0.10867114  
2023-05-28 21:19:20.178: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 6.458106]
2023-05-28 21:19:20.332: epoch 125:	0.02706811  	0.19938666  	0.10877192  
2023-05-28 21:19:20.333: Find a better model.
2023-05-28 21:19:26.967: [iter 126 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 6.633076]
2023-05-28 21:19:27.112: epoch 126:	0.02701166  	0.19890256  	0.10865973  
2023-05-28 21:19:33.766: [iter 127 : loss : 0.1152 = 0.0261 + 0.0828 + 0.0063, time: 6.652036]
2023-05-28 21:19:33.920: epoch 127:	0.02699754  	0.19921534  	0.10892340  
2023-05-28 21:19:40.375: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 6.453030]
2023-05-28 21:19:40.528: epoch 128:	0.02706811  	0.19974394  	0.10905816  
2023-05-28 21:19:40.528: Find a better model.
2023-05-28 21:19:47.150: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.621053]
2023-05-28 21:19:47.305: epoch 129:	0.02712456  	0.19999887  	0.10922831  
2023-05-28 21:19:47.305: Find a better model.
2023-05-28 21:19:53.764: [iter 130 : loss : 0.1153 = 0.0264 + 0.0826 + 0.0064, time: 6.457994]
2023-05-28 21:19:53.922: epoch 130:	0.02713868  	0.20039493  	0.10947259  
2023-05-28 21:19:53.922: Find a better model.
2023-05-28 21:20:00.544: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.621047]
2023-05-28 21:20:00.689: epoch 131:	0.02713163  	0.20014569  	0.10956270  
2023-05-28 21:20:07.163: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.472610]
2023-05-28 21:20:07.317: epoch 132:	0.02715279  	0.20053107  	0.10953291  
2023-05-28 21:20:07.317: Find a better model.
2023-05-28 21:20:13.954: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.635081]
2023-05-28 21:20:14.110: epoch 133:	0.02712456  	0.20042375  	0.10964710  
2023-05-28 21:20:20.738: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.627023]
2023-05-28 21:20:20.892: epoch 134:	0.02712456  	0.20007493  	0.10961022  
2023-05-28 21:20:27.373: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.479007]
2023-05-28 21:20:27.530: epoch 135:	0.02708928  	0.19983542  	0.10947565  
2023-05-28 21:20:34.148: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.617021]
2023-05-28 21:20:34.305: epoch 136:	0.02701166  	0.19975971  	0.10928407  
2023-05-28 21:20:40.737: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.429994]
2023-05-28 21:20:40.880: epoch 137:	0.02710338  	0.20006296  	0.10944772  
2023-05-28 21:20:47.349: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.467994]
2023-05-28 21:20:47.502: epoch 138:	0.02703284  	0.19962664  	0.10925742  
2023-05-28 21:20:53.953: [iter 139 : loss : 0.1126 = 0.0237 + 0.0822 + 0.0066, time: 6.450350]
2023-05-28 21:20:54.106: epoch 139:	0.02703988  	0.19944791  	0.10927588  
2023-05-28 21:21:00.542: [iter 140 : loss : 0.1121 = 0.0233 + 0.0822 + 0.0067, time: 6.432997]
2023-05-28 21:21:00.698: epoch 140:	0.02705400  	0.19950998  	0.10928700  
2023-05-28 21:21:07.157: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 6.458452]
2023-05-28 21:21:07.312: epoch 141:	0.02705400  	0.19939590  	0.10950647  
2023-05-28 21:21:13.736: [iter 142 : loss : 0.1118 = 0.0229 + 0.0821 + 0.0067, time: 6.421039]
2023-05-28 21:21:13.891: epoch 142:	0.02706811  	0.19956894  	0.10957257  
2023-05-28 21:21:20.336: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.444013]
2023-05-28 21:21:20.491: epoch 143:	0.02708928  	0.19979094  	0.10967638  
2023-05-28 21:21:27.116: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.624012]
2023-05-28 21:21:27.272: epoch 144:	0.02704694  	0.19960172  	0.10965959  
2023-05-28 21:21:33.902: [iter 145 : loss : 0.1114 = 0.0225 + 0.0820 + 0.0068, time: 6.629012]
2023-05-28 21:21:34.056: epoch 145:	0.02712457  	0.20008992  	0.10977585  
2023-05-28 21:21:40.713: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.654593]
2023-05-28 21:21:40.871: epoch 146:	0.02703284  	0.19933487  	0.10950205  
2023-05-28 21:21:47.329: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.456994]
2023-05-28 21:21:47.483: epoch 147:	0.02708223  	0.19976455  	0.10977522  
2023-05-28 21:21:54.139: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.654269]
2023-05-28 21:21:54.292: epoch 148:	0.02712457  	0.19982803  	0.10969271  
2023-05-28 21:22:00.717: [iter 149 : loss : 0.1105 = 0.0217 + 0.0819 + 0.0069, time: 6.422999]
2023-05-28 21:22:00.860: epoch 149:	0.02714574  	0.19987169  	0.10978123  
2023-05-28 21:22:07.299: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.438062]
2023-05-28 21:22:07.455: epoch 150:	0.02717396  	0.20009175  	0.11015426  
2023-05-28 21:22:14.087: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.630101]
2023-05-28 21:22:14.240: epoch 151:	0.02715985  	0.19977865  	0.11002725  
2023-05-28 21:22:20.904: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.661072]
2023-05-28 21:22:21.058: epoch 152:	0.02711751  	0.19952758  	0.11003788  
2023-05-28 21:22:27.678: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.618504]
2023-05-28 21:22:27.840: epoch 153:	0.02709634  	0.19928616  	0.10985070  
2023-05-28 21:22:34.309: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.467994]
2023-05-28 21:22:34.463: epoch 154:	0.02721630  	0.20027706  	0.11020282  
2023-05-28 21:22:41.076: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.611993]
2023-05-28 21:22:41.230: epoch 155:	0.02714574  	0.19984443  	0.11000567  
2023-05-28 21:22:47.692: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.461098]
2023-05-28 21:22:47.852: epoch 156:	0.02713163  	0.19980206  	0.10985455  
2023-05-28 21:22:54.305: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.452008]
2023-05-28 21:22:54.460: epoch 157:	0.02713163  	0.19979949  	0.10979664  
2023-05-28 21:22:54.460: Early stopping is trigger at epoch: 157
2023-05-28 21:22:54.460: best_result@epoch 132:

2023-05-28 21:22:54.460: 		0.0272      	0.2005      	0.1095      
2023-05-29 09:13:54.137: my pid: 15176
2023-05-29 09:13:54.137: model: model.general_recommender.SGL
2023-05-29 09:13:54.137: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 09:13:54.137: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 09:13:57.842: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 09:14:05.157: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.313993]
2023-05-29 09:14:05.301: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-29 09:14:05.301: Find a better model.
2023-05-29 09:14:12.715: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.412613]
2023-05-29 09:14:12.923: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-29 09:14:12.923: Find a better model.
2023-05-29 09:14:20.160: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.236003]
2023-05-29 09:14:20.322: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-29 09:14:20.322: Find a better model.
2023-05-29 09:14:27.502: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.179038]
2023-05-29 09:14:27.672: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-29 09:14:27.672: Find a better model.
2023-05-29 09:14:34.736: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.062999]
2023-05-29 09:14:34.897: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-29 09:14:34.897: Find a better model.
2023-05-29 09:14:41.870: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 6.972176]
2023-05-29 09:14:42.014: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-29 09:14:42.014: Find a better model.
2023-05-29 09:14:48.708: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.693018]
2023-05-29 09:14:48.851: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-29 09:14:48.851: Find a better model.
2023-05-29 09:14:55.671: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.818014]
2023-05-29 09:14:55.814: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-29 09:14:55.814: Find a better model.
2023-05-29 09:15:02.481: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.665220]
2023-05-29 09:15:02.640: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-29 09:15:02.640: Find a better model.
2023-05-29 09:15:09.293: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.652029]
2023-05-29 09:15:09.437: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-29 09:15:09.437: Find a better model.
2023-05-29 09:15:15.900: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.462155]
2023-05-29 09:15:16.043: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-29 09:15:16.043: Find a better model.
2023-05-29 09:15:22.487: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.443174]
2023-05-29 09:15:22.634: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-29 09:15:22.635: Find a better model.
2023-05-29 09:15:29.079: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.442006]
2023-05-29 09:15:29.233: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-29 09:15:29.234: Find a better model.
2023-05-29 09:15:35.861: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.626011]
2023-05-29 09:15:36.016: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-29 09:15:36.016: Find a better model.
2023-05-29 09:15:42.478: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.461015]
2023-05-29 09:15:42.636: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-29 09:15:49.084: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.447018]
2023-05-29 09:15:49.238: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-29 09:15:49.239: Find a better model.
2023-05-29 09:15:55.876: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.636037]
2023-05-29 09:15:56.031: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-29 09:15:56.031: Find a better model.
2023-05-29 09:16:02.508: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.476015]
2023-05-29 09:16:02.667: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-29 09:16:02.667: Find a better model.
2023-05-29 09:16:09.250: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.581028]
2023-05-29 09:16:09.407: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-29 09:16:09.407: Find a better model.
2023-05-29 09:16:15.887: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.479315]
2023-05-29 09:16:16.045: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-29 09:16:16.046: Find a better model.
2023-05-29 09:16:22.679: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.632010]
2023-05-29 09:16:22.822: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-29 09:16:22.822: Find a better model.
2023-05-29 09:16:29.446: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.622190]
2023-05-29 09:16:29.591: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-29 09:16:29.591: Find a better model.
2023-05-29 09:16:36.069: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.476003]
2023-05-29 09:16:36.226: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-29 09:16:36.226: Find a better model.
2023-05-29 09:16:42.888: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.661535]
2023-05-29 09:16:43.044: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-29 09:16:43.044: Find a better model.
2023-05-29 09:16:49.648: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.601927]
2023-05-29 09:16:49.804: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-29 09:16:49.804: Find a better model.
2023-05-29 09:16:56.435: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.629994]
2023-05-29 09:16:56.583: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-29 09:16:56.583: Find a better model.
2023-05-29 09:17:03.269: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.685042]
2023-05-29 09:17:03.424: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-29 09:17:03.424: Find a better model.
2023-05-29 09:17:10.062: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.636011]
2023-05-29 09:17:10.218: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-29 09:17:10.218: Find a better model.
2023-05-29 09:17:16.859: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.640199]
2023-05-29 09:17:17.006: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-29 09:17:17.006: Find a better model.
2023-05-29 09:17:23.466: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.459224]
2023-05-29 09:17:23.629: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-29 09:17:23.629: Find a better model.
2023-05-29 09:17:30.266: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.635993]
2023-05-29 09:17:30.421: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-29 09:17:30.421: Find a better model.
2023-05-29 09:17:37.055: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.631567]
2023-05-29 09:17:37.211: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-29 09:17:37.211: Find a better model.
2023-05-29 09:17:43.839: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.626994]
2023-05-29 09:17:43.994: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-29 09:17:43.995: Find a better model.
2023-05-29 09:17:50.623: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.625984]
2023-05-29 09:17:50.769: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-29 09:17:50.769: Find a better model.
2023-05-29 09:17:57.434: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.664024]
2023-05-29 09:17:57.588: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-29 09:17:57.588: Find a better model.
2023-05-29 09:18:04.220: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.631011]
2023-05-29 09:18:04.376: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-29 09:18:04.376: Find a better model.
2023-05-29 09:18:11.026: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.649016]
2023-05-29 09:18:11.182: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-29 09:18:11.182: Find a better model.
2023-05-29 09:18:17.832: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.648478]
2023-05-29 09:18:17.976: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-29 09:18:17.976: Find a better model.
2023-05-29 09:18:24.630: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.653002]
2023-05-29 09:18:24.786: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-29 09:18:24.787: Find a better model.
2023-05-29 09:18:31.426: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.638351]
2023-05-29 09:18:31.584: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-29 09:18:31.584: Find a better model.
2023-05-29 09:18:38.213: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.628015]
2023-05-29 09:18:38.371: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-29 09:18:38.371: Find a better model.
2023-05-29 09:18:45.022: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.649015]
2023-05-29 09:18:45.180: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-29 09:18:45.180: Find a better model.
2023-05-29 09:18:51.818: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.637004]
2023-05-29 09:18:51.974: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-29 09:18:51.974: Find a better model.
2023-05-29 09:18:58.631: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.655399]
2023-05-29 09:18:58.786: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-29 09:18:58.786: Find a better model.
2023-05-29 09:19:05.416: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.629009]
2023-05-29 09:19:05.570: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-29 09:19:05.570: Find a better model.
2023-05-29 09:19:12.016: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.445017]
2023-05-29 09:19:12.171: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-29 09:19:12.171: Find a better model.
2023-05-29 09:19:18.810: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.638033]
2023-05-29 09:19:18.966: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-29 09:19:18.966: Find a better model.
2023-05-29 09:19:25.622: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.655058]
2023-05-29 09:19:25.778: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-29 09:19:25.778: Find a better model.
2023-05-29 09:19:32.420: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.639101]
2023-05-29 09:19:32.577: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-29 09:19:39.392: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.814038]
2023-05-29 09:19:39.547: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-29 09:19:39.547: Find a better model.
2023-05-29 09:19:46.179: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.631004]
2023-05-29 09:19:46.325: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-29 09:19:46.325: Find a better model.
2023-05-29 09:19:52.812: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.486009]
2023-05-29 09:19:52.970: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-29 09:19:52.970: Find a better model.
2023-05-29 09:19:59.598: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.626993]
2023-05-29 09:19:59.754: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-29 09:19:59.755: Find a better model.
2023-05-29 09:20:06.383: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.626029]
2023-05-29 09:20:06.528: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-29 09:20:06.528: Find a better model.
2023-05-29 09:20:13.180: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.651008]
2023-05-29 09:20:13.337: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-29 09:20:19.994: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.656516]
2023-05-29 09:20:20.149: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-29 09:20:20.149: Find a better model.
2023-05-29 09:20:26.813: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.663287]
2023-05-29 09:20:26.957: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-29 09:20:26.957: Find a better model.
2023-05-29 09:20:33.578: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.619011]
2023-05-29 09:20:33.724: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-29 09:20:40.385: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.658546]
2023-05-29 09:20:40.528: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-29 09:20:40.528: Find a better model.
2023-05-29 09:20:46.985: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.456005]
2023-05-29 09:20:47.143: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-29 09:20:47.143: Find a better model.
2023-05-29 09:20:53.787: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.643004]
2023-05-29 09:20:53.945: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-29 09:20:53.945: Find a better model.
2023-05-29 09:21:00.568: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.622021]
2023-05-29 09:21:00.716: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-29 09:21:00.716: Find a better model.
2023-05-29 09:21:07.204: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.486825]
2023-05-29 09:21:07.351: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-29 09:21:07.351: Find a better model.
2023-05-29 09:21:13.939: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.587425]
2023-05-29 09:21:14.085: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-29 09:21:14.085: Find a better model.
2023-05-29 09:21:20.564: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.477013]
2023-05-29 09:21:20.711: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-29 09:21:20.711: Find a better model.
2023-05-29 09:21:27.177: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.463126]
2023-05-29 09:21:27.332: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-29 09:21:27.332: Find a better model.
2023-05-29 09:21:33.777: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.443999]
2023-05-29 09:21:33.935: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-29 09:21:40.562: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.626018]
2023-05-29 09:21:40.723: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-29 09:21:40.723: Find a better model.
2023-05-29 09:21:47.342: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.617069]
2023-05-29 09:21:47.496: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-29 09:21:47.496: Find a better model.
2023-05-29 09:21:53.985: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.486358]
2023-05-29 09:21:54.148: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-29 09:21:54.148: Find a better model.
2023-05-29 09:22:00.727: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.577027]
2023-05-29 09:22:00.872: epoch 71:	0.02632721  	0.19467905  	0.10684208  
2023-05-29 09:22:00.873: Find a better model.
2023-05-29 09:22:07.340: [iter 72 : loss : 0.2190 = 0.0478 + 0.1664 + 0.0048, time: 6.466005]
2023-05-29 09:22:07.484: epoch 72:	0.02639778  	0.19526137  	0.10706843  
2023-05-29 09:22:07.484: Find a better model.
2023-05-29 09:22:13.965: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.478488]
2023-05-29 09:22:14.121: epoch 73:	0.02641189  	0.19549032  	0.10711851  
2023-05-29 09:22:14.121: Find a better model.
2023-05-29 09:22:20.753: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.629357]
2023-05-29 09:22:20.912: epoch 74:	0.02646128  	0.19566278  	0.10750105  
2023-05-29 09:22:20.912: Find a better model.
2023-05-29 09:22:27.551: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.636003]
2023-05-29 09:22:27.714: epoch 75:	0.02654596  	0.19655427  	0.10756438  
2023-05-29 09:22:27.714: Find a better model.
2023-05-29 09:22:34.326: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.611018]
2023-05-29 09:22:34.471: epoch 76:	0.02658124  	0.19694291  	0.10773618  
2023-05-29 09:22:34.471: Find a better model.
2023-05-29 09:22:40.947: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.474005]
2023-05-29 09:22:41.105: epoch 77:	0.02659536  	0.19693758  	0.10767362  
2023-05-29 09:22:47.718: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.611004]
2023-05-29 09:22:47.863: epoch 78:	0.02667298  	0.19745006  	0.10793771  
2023-05-29 09:22:47.863: Find a better model.
2023-05-29 09:22:54.517: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.653069]
2023-05-29 09:22:54.674: epoch 79:	0.02668003  	0.19723570  	0.10796165  
2023-05-29 09:23:01.310: [iter 80 : loss : 0.2113 = 0.0410 + 0.1652 + 0.0051, time: 6.635017]
2023-05-29 09:23:01.468: epoch 80:	0.02660241  	0.19668077  	0.10794093  
2023-05-29 09:23:08.120: [iter 81 : loss : 0.2110 = 0.0408 + 0.1650 + 0.0052, time: 6.651044]
2023-05-29 09:23:08.277: epoch 81:	0.02660241  	0.19662951  	0.10788923  
2023-05-29 09:23:14.724: [iter 82 : loss : 0.2099 = 0.0398 + 0.1649 + 0.0052, time: 6.446009]
2023-05-29 09:23:14.867: epoch 82:	0.02649656  	0.19609496  	0.10785156  
2023-05-29 09:23:21.345: [iter 83 : loss : 0.2090 = 0.0390 + 0.1648 + 0.0053, time: 6.475993]
2023-05-29 09:23:21.502: epoch 83:	0.02653890  	0.19600566  	0.10790281  
2023-05-29 09:23:27.949: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.444085]
2023-05-29 09:23:28.107: epoch 84:	0.02667298  	0.19690226  	0.10819490  
2023-05-29 09:23:34.529: [iter 85 : loss : 0.2081 = 0.0382 + 0.1645 + 0.0053, time: 6.420014]
2023-05-29 09:23:34.689: epoch 85:	0.02675060  	0.19757095  	0.10846379  
2023-05-29 09:23:34.689: Find a better model.
2023-05-29 09:23:41.134: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.443091]
2023-05-29 09:23:41.290: epoch 86:	0.02669415  	0.19715470  	0.10848830  
2023-05-29 09:23:47.918: [iter 87 : loss : 0.2057 = 0.0359 + 0.1643 + 0.0054, time: 6.625001]
2023-05-29 09:23:48.074: epoch 87:	0.02686350  	0.19811502  	0.10885072  
2023-05-29 09:23:48.075: Find a better model.
2023-05-29 09:23:54.698: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.621067]
2023-05-29 09:23:54.843: epoch 88:	0.02678588  	0.19745855  	0.10858166  
2023-05-29 09:24:01.324: [iter 89 : loss : 0.2045 = 0.0349 + 0.1640 + 0.0055, time: 6.479027]
2023-05-29 09:24:01.469: epoch 89:	0.02673648  	0.19694941  	0.10849094  
2023-05-29 09:24:07.932: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.462417]
2023-05-29 09:24:08.088: epoch 90:	0.02682822  	0.19769356  	0.10869770  
2023-05-29 09:24:14.687: [iter 91 : loss : 0.2039 = 0.0346 + 0.1638 + 0.0056, time: 6.598498]
2023-05-29 09:24:14.845: epoch 91:	0.02691289  	0.19807483  	0.10884054  
2023-05-29 09:24:21.321: [iter 92 : loss : 0.2028 = 0.0334 + 0.1637 + 0.0056, time: 6.475029]
2023-05-29 09:24:21.477: epoch 92:	0.02691289  	0.19834703  	0.10895094  
2023-05-29 09:24:21.478: Find a better model.
2023-05-29 09:24:28.088: [iter 93 : loss : 0.2033 = 0.0340 + 0.1636 + 0.0057, time: 6.609003]
2023-05-29 09:24:28.245: epoch 93:	0.02688467  	0.19837846  	0.10883533  
2023-05-29 09:24:28.245: Find a better model.
2023-05-29 09:24:34.705: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.458027]
2023-05-29 09:24:34.852: epoch 94:	0.02689878  	0.19840631  	0.10900953  
2023-05-29 09:24:34.852: Find a better model.
2023-05-29 09:24:41.477: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.624017]
2023-05-29 09:24:41.626: epoch 95:	0.02692701  	0.19853988  	0.10915195  
2023-05-29 09:24:41.626: Find a better model.
2023-05-29 09:24:48.137: [iter 96 : loss : 0.2009 = 0.0318 + 0.1633 + 0.0058, time: 6.508013]
2023-05-29 09:24:48.296: epoch 96:	0.02686350  	0.19797775  	0.10893095  
2023-05-29 09:24:54.893: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.596003]
2023-05-29 09:24:55.048: epoch 97:	0.02694112  	0.19834363  	0.10928166  
2023-05-29 09:25:01.683: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.634011]
2023-05-29 09:25:01.829: epoch 98:	0.02694818  	0.19854747  	0.10942093  
2023-05-29 09:25:01.829: Find a better model.
2023-05-29 09:25:08.493: [iter 99 : loss : 0.1991 = 0.0301 + 0.1630 + 0.0059, time: 6.663002]
2023-05-29 09:25:08.655: epoch 99:	0.02703285  	0.19904999  	0.10957264  
2023-05-29 09:25:08.655: Find a better model.
2023-05-29 09:25:15.303: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.647678]
2023-05-29 09:25:15.460: epoch 100:	0.02705402  	0.19908023  	0.10961760  
2023-05-29 09:25:15.461: Find a better model.
2023-05-29 09:25:22.104: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.642006]
2023-05-29 09:25:22.261: epoch 101:	0.02705401  	0.19917580  	0.10956462  
2023-05-29 09:25:22.261: Find a better model.
2023-05-29 09:25:28.884: [iter 102 : loss : 0.1974 = 0.0287 + 0.1627 + 0.0061, time: 6.621089]
2023-05-29 09:25:29.029: epoch 102:	0.02708929  	0.19923764  	0.10959043  
2023-05-29 09:25:29.030: Find a better model.
2023-05-29 09:25:35.701: [iter 103 : loss : 0.1972 = 0.0285 + 0.1626 + 0.0061, time: 6.670006]
2023-05-29 09:25:35.858: epoch 103:	0.02707519  	0.19948873  	0.10976166  
2023-05-29 09:25:35.858: Find a better model.
2023-05-29 09:25:42.476: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.617029]
2023-05-29 09:25:42.619: epoch 104:	0.02704696  	0.19932652  	0.10971819  
2023-05-29 09:25:49.483: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.861014]
2023-05-29 09:25:49.644: epoch 105:	0.02699051  	0.19933046  	0.10973314  
2023-05-29 09:25:56.467: [iter 106 : loss : 0.1964 = 0.0278 + 0.1624 + 0.0062, time: 6.821482]
2023-05-29 09:25:56.626: epoch 106:	0.02701167  	0.19937827  	0.10981102  
2023-05-29 09:26:03.289: [iter 107 : loss : 0.1957 = 0.0271 + 0.1624 + 0.0062, time: 6.661276]
2023-05-29 09:26:03.447: epoch 107:	0.02706813  	0.19989811  	0.11013356  
2023-05-29 09:26:03.447: Find a better model.
2023-05-29 09:26:10.075: [iter 108 : loss : 0.1954 = 0.0268 + 0.1623 + 0.0063, time: 6.627007]
2023-05-29 09:26:10.229: epoch 108:	0.02700462  	0.19952522  	0.10990442  
2023-05-29 09:26:16.889: [iter 109 : loss : 0.1945 = 0.0260 + 0.1622 + 0.0063, time: 6.658020]
2023-05-29 09:26:17.043: epoch 109:	0.02704696  	0.20016053  	0.10989905  
2023-05-29 09:26:17.044: Find a better model.
2023-05-29 09:26:23.657: [iter 110 : loss : 0.1941 = 0.0256 + 0.1622 + 0.0063, time: 6.612006]
2023-05-29 09:26:23.802: epoch 110:	0.02701874  	0.20001934  	0.11001527  
2023-05-29 09:26:30.467: [iter 111 : loss : 0.1938 = 0.0254 + 0.1621 + 0.0064, time: 6.664103]
2023-05-29 09:26:30.625: epoch 111:	0.02700462  	0.19943477  	0.10989597  
2023-05-29 09:26:37.424: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.796043]
2023-05-29 09:26:37.572: epoch 112:	0.02703285  	0.19921325  	0.10984495  
2023-05-29 09:26:44.267: [iter 113 : loss : 0.1936 = 0.0252 + 0.1619 + 0.0065, time: 6.694057]
2023-05-29 09:26:44.421: epoch 113:	0.02703991  	0.19920979  	0.10981870  
2023-05-29 09:26:51.068: [iter 114 : loss : 0.1928 = 0.0245 + 0.1619 + 0.0065, time: 6.646095]
2023-05-29 09:26:51.225: epoch 114:	0.02713164  	0.19981673  	0.11002791  
2023-05-29 09:26:57.844: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.618008]
2023-05-29 09:26:57.989: epoch 115:	0.02708224  	0.19955315  	0.10994995  
2023-05-29 09:27:04.646: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.655648]
2023-05-29 09:27:04.801: epoch 116:	0.02704696  	0.19898276  	0.10995645  
2023-05-29 09:27:11.470: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.668004]
2023-05-29 09:27:11.633: epoch 117:	0.02699050  	0.19892606  	0.10984875  
2023-05-29 09:27:18.258: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.624007]
2023-05-29 09:27:18.413: epoch 118:	0.02698344  	0.19834651  	0.10981710  
2023-05-29 09:27:25.051: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.635482]
2023-05-29 09:27:25.208: epoch 119:	0.02701873  	0.19867659  	0.10980324  
2023-05-29 09:27:31.841: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.631003]
2023-05-29 09:27:31.984: epoch 120:	0.02701167  	0.19857386  	0.10987627  
2023-05-29 09:27:38.638: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.651006]
2023-05-29 09:27:38.794: epoch 121:	0.02700462  	0.19842827  	0.10991929  
2023-05-29 09:27:45.455: [iter 122 : loss : 0.1906 = 0.0224 + 0.1614 + 0.0068, time: 6.659953]
2023-05-29 09:27:45.613: epoch 122:	0.02694816  	0.19816545  	0.10981948  
2023-05-29 09:27:52.233: [iter 123 : loss : 0.1904 = 0.0223 + 0.1613 + 0.0068, time: 6.619006]
2023-05-29 09:27:52.388: epoch 123:	0.02695522  	0.19808462  	0.10980198  
2023-05-29 09:27:59.026: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.637031]
2023-05-29 09:27:59.182: epoch 124:	0.02696933  	0.19822593  	0.10990788  
2023-05-29 09:28:05.830: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.647171]
2023-05-29 09:28:05.987: epoch 125:	0.02702578  	0.19851798  	0.10997351  
2023-05-29 09:28:12.634: [iter 126 : loss : 0.1893 = 0.0213 + 0.1612 + 0.0069, time: 6.645058]
2023-05-29 09:28:12.790: epoch 126:	0.02692699  	0.19814073  	0.10991263  
2023-05-29 09:28:19.439: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.648082]
2023-05-29 09:28:19.597: epoch 127:	0.02687760  	0.19777001  	0.10988648  
2023-05-29 09:28:26.216: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.617077]
2023-05-29 09:28:26.363: epoch 128:	0.02695521  	0.19816811  	0.10989755  
2023-05-29 09:28:33.024: [iter 129 : loss : 0.1885 = 0.0205 + 0.1611 + 0.0070, time: 6.660534]
2023-05-29 09:28:33.180: epoch 129:	0.02695522  	0.19814949  	0.10989751  
2023-05-29 09:28:39.807: [iter 130 : loss : 0.1886 = 0.0206 + 0.1610 + 0.0070, time: 6.626004]
2023-05-29 09:28:39.964: epoch 130:	0.02688465  	0.19776551  	0.10980804  
2023-05-29 09:28:46.629: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.663014]
2023-05-29 09:28:46.786: epoch 131:	0.02694111  	0.19801711  	0.10991438  
2023-05-29 09:28:53.415: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.628014]
2023-05-29 09:28:53.572: epoch 132:	0.02689877  	0.19782066  	0.10988849  
2023-05-29 09:29:00.231: [iter 133 : loss : 0.1871 = 0.0191 + 0.1609 + 0.0071, time: 6.658027]
2023-05-29 09:29:00.385: epoch 133:	0.02697638  	0.19819023  	0.10998309  
2023-05-29 09:29:07.009: [iter 134 : loss : 0.1876 = 0.0197 + 0.1608 + 0.0071, time: 6.622041]
2023-05-29 09:29:07.166: epoch 134:	0.02691288  	0.19745693  	0.10976485  
2023-05-29 09:29:07.166: Early stopping is trigger at epoch: 134
2023-05-29 09:29:07.166: best_result@epoch 109:

2023-05-29 09:29:07.166: 		0.0270      	0.2002      	0.1099      
2023-05-29 09:37:31.942: my pid: 12908
2023-05-29 09:37:31.942: model: model.general_recommender.SGL
2023-05-29 09:37:31.942: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 09:37:31.942: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 09:37:35.689: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 09:37:43.060: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.371029]
2023-05-29 09:37:43.217: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-29 09:37:43.217: Find a better model.
2023-05-29 09:37:50.637: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.416275]
2023-05-29 09:37:50.838: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-29 09:37:50.838: Find a better model.
2023-05-29 09:37:58.236: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.397112]
2023-05-29 09:37:58.399: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-29 09:37:58.399: Find a better model.
2023-05-29 09:38:05.612: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.211048]
2023-05-29 09:38:05.764: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-29 09:38:05.764: Find a better model.
2023-05-29 09:38:12.832: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.067214]
2023-05-29 09:38:12.985: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-29 09:38:12.985: Find a better model.
2023-05-29 09:38:19.816: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.829086]
2023-05-29 09:38:19.968: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-29 09:38:19.968: Find a better model.
2023-05-29 09:38:26.796: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.827282]
2023-05-29 09:38:26.939: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-29 09:38:26.939: Find a better model.
2023-05-29 09:38:33.798: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.858169]
2023-05-29 09:38:33.940: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-29 09:38:33.940: Find a better model.
2023-05-29 09:38:40.618: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.677026]
2023-05-29 09:38:40.770: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-29 09:38:47.409: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.637045]
2023-05-29 09:38:47.556: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-29 09:38:54.217: [iter 11 : loss : 0.5368 = 0.4393 + 0.0970 + 0.0005, time: 6.660191]
2023-05-29 09:38:54.372: epoch 11:	0.01850861  	0.13691495  	0.06865198  
2023-05-29 09:39:00.996: [iter 12 : loss : 0.4761 = 0.3759 + 0.0996 + 0.0006, time: 6.623012]
2023-05-29 09:39:01.150: epoch 12:	0.01858623  	0.13745318  	0.06901583  
2023-05-29 09:39:07.781: [iter 13 : loss : 0.4326 = 0.3309 + 0.1009 + 0.0008, time: 6.629356]
2023-05-29 09:39:07.937: epoch 13:	0.01872736  	0.13896972  	0.06985795  
2023-05-29 09:39:14.572: [iter 14 : loss : 0.3995 = 0.2971 + 0.1015 + 0.0009, time: 6.634010]
2023-05-29 09:39:14.715: epoch 14:	0.01889672  	0.14063664  	0.07081176  
2023-05-29 09:39:21.197: [iter 15 : loss : 0.3761 = 0.2734 + 0.1017 + 0.0010, time: 6.480200]
2023-05-29 09:39:21.340: epoch 15:	0.01914369  	0.14243539  	0.07182342  
2023-05-29 09:39:21.340: Find a better model.
2023-05-29 09:39:27.805: [iter 16 : loss : 0.3559 = 0.2532 + 0.1016 + 0.0012, time: 6.464080]
2023-05-29 09:39:27.959: epoch 16:	0.01927071  	0.14290677  	0.07245020  
2023-05-29 09:39:27.959: Find a better model.
2023-05-29 09:39:34.676: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 6.716001]
2023-05-29 09:39:34.841: epoch 17:	0.01960943  	0.14526026  	0.07359558  
2023-05-29 09:39:34.841: Find a better model.
2023-05-29 09:39:41.397: [iter 18 : loss : 0.3266 = 0.2242 + 0.1011 + 0.0014, time: 6.555064]
2023-05-29 09:39:41.553: epoch 18:	0.01967294  	0.14559437  	0.07430208  
2023-05-29 09:39:41.554: Find a better model.
2023-05-29 09:39:47.990: [iter 19 : loss : 0.3132 = 0.2111 + 0.1007 + 0.0014, time: 6.434007]
2023-05-29 09:39:48.130: epoch 19:	0.01989875  	0.14657883  	0.07509720  
2023-05-29 09:39:48.130: Find a better model.
2023-05-29 09:39:54.572: [iter 20 : loss : 0.3041 = 0.2023 + 0.1003 + 0.0015, time: 6.440057]
2023-05-29 09:39:54.726: epoch 20:	0.02016690  	0.14910676  	0.07598241  
2023-05-29 09:39:54.726: Find a better model.
2023-05-29 09:40:01.169: [iter 21 : loss : 0.2949 = 0.1934 + 0.0999 + 0.0016, time: 6.442035]
2023-05-29 09:40:01.311: epoch 21:	0.02035742  	0.15022154  	0.07656878  
2023-05-29 09:40:01.312: Find a better model.
2023-05-29 09:40:07.762: [iter 22 : loss : 0.2871 = 0.1859 + 0.0994 + 0.0017, time: 6.449639]
2023-05-29 09:40:07.916: epoch 22:	0.02051267  	0.15160389  	0.07734576  
2023-05-29 09:40:07.917: Find a better model.
2023-05-29 09:40:14.368: [iter 23 : loss : 0.2791 = 0.1783 + 0.0991 + 0.0018, time: 6.450003]
2023-05-29 09:40:14.528: epoch 23:	0.02075965  	0.15319948  	0.07830640  
2023-05-29 09:40:14.529: Find a better model.
2023-05-29 09:40:20.977: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 6.446014]
2023-05-29 09:40:21.132: epoch 24:	0.02090783  	0.15384437  	0.07869246  
2023-05-29 09:40:21.132: Find a better model.
2023-05-29 09:40:27.561: [iter 25 : loss : 0.2661 = 0.1660 + 0.0982 + 0.0019, time: 6.426610]
2023-05-29 09:40:27.704: epoch 25:	0.02107013  	0.15483871  	0.07913984  
2023-05-29 09:40:27.704: Find a better model.
2023-05-29 09:40:34.165: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 6.460027]
2023-05-29 09:40:34.308: epoch 26:	0.02119010  	0.15590744  	0.07988256  
2023-05-29 09:40:34.308: Find a better model.
2023-05-29 09:40:40.759: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 6.450034]
2023-05-29 09:40:40.915: epoch 27:	0.02134534  	0.15717445  	0.08065405  
2023-05-29 09:40:40.915: Find a better model.
2023-05-29 09:40:47.355: [iter 28 : loss : 0.2502 = 0.1512 + 0.0969 + 0.0021, time: 6.438050]
2023-05-29 09:40:47.501: epoch 28:	0.02163466  	0.15920985  	0.08182187  
2023-05-29 09:40:47.501: Find a better model.
2023-05-29 09:40:53.949: [iter 29 : loss : 0.2461 = 0.1474 + 0.0965 + 0.0022, time: 6.446999]
2023-05-29 09:40:54.094: epoch 29:	0.02176873  	0.15970962  	0.08236754  
2023-05-29 09:40:54.094: Find a better model.
2023-05-29 09:41:00.566: [iter 30 : loss : 0.2395 = 0.1411 + 0.0962 + 0.0022, time: 6.469989]
2023-05-29 09:41:00.710: epoch 30:	0.02190281  	0.16077378  	0.08322922  
2023-05-29 09:41:00.711: Find a better model.
2023-05-29 09:41:07.166: [iter 31 : loss : 0.2363 = 0.1382 + 0.0958 + 0.0023, time: 6.453339]
2023-05-29 09:41:07.310: epoch 31:	0.02199453  	0.16159788  	0.08376351  
2023-05-29 09:41:07.310: Find a better model.
2023-05-29 09:41:13.740: [iter 32 : loss : 0.2308 = 0.1329 + 0.0955 + 0.0024, time: 6.428994]
2023-05-29 09:41:13.887: epoch 32:	0.02222740  	0.16368392  	0.08487266  
2023-05-29 09:41:13.887: Find a better model.
2023-05-29 09:41:20.365: [iter 33 : loss : 0.2280 = 0.1305 + 0.0951 + 0.0024, time: 6.476994]
2023-05-29 09:41:20.525: epoch 33:	0.02241087  	0.16538045  	0.08559931  
2023-05-29 09:41:20.525: Find a better model.
2023-05-29 09:41:26.954: [iter 34 : loss : 0.2240 = 0.1268 + 0.0947 + 0.0025, time: 6.427994]
2023-05-29 09:41:27.108: epoch 34:	0.02250260  	0.16587289  	0.08620764  
2023-05-29 09:41:27.108: Find a better model.
2023-05-29 09:41:33.557: [iter 35 : loss : 0.2207 = 0.1237 + 0.0944 + 0.0025, time: 6.448065]
2023-05-29 09:41:33.711: epoch 35:	0.02255905  	0.16647111  	0.08655562  
2023-05-29 09:41:33.712: Find a better model.
2023-05-29 09:41:40.165: [iter 36 : loss : 0.2175 = 0.1207 + 0.0941 + 0.0026, time: 6.451008]
2023-05-29 09:41:40.308: epoch 36:	0.02274252  	0.16776656  	0.08749903  
2023-05-29 09:41:40.308: Find a better model.
2023-05-29 09:41:46.735: [iter 37 : loss : 0.2136 = 0.1171 + 0.0938 + 0.0026, time: 6.426064]
2023-05-29 09:41:46.892: epoch 37:	0.02289777  	0.16885702  	0.08826023  
2023-05-29 09:41:46.892: Find a better model.
2023-05-29 09:41:53.347: [iter 38 : loss : 0.2120 = 0.1158 + 0.0935 + 0.0027, time: 6.454008]
2023-05-29 09:41:53.503: epoch 38:	0.02300361  	0.17008778  	0.08887066  
2023-05-29 09:41:53.503: Find a better model.
2023-05-29 09:41:59.927: [iter 39 : loss : 0.2075 = 0.1116 + 0.0932 + 0.0028, time: 6.421409]
2023-05-29 09:42:00.087: epoch 39:	0.02308830  	0.17137153  	0.08943509  
2023-05-29 09:42:00.087: Find a better model.
2023-05-29 09:42:06.534: [iter 40 : loss : 0.2043 = 0.1086 + 0.0929 + 0.0028, time: 6.446014]
2023-05-29 09:42:06.677: epoch 40:	0.02310240  	0.17106701  	0.08975488  
2023-05-29 09:42:13.138: [iter 41 : loss : 0.2029 = 0.1074 + 0.0927 + 0.0029, time: 6.460024]
2023-05-29 09:42:13.282: epoch 41:	0.02328588  	0.17184421  	0.09026152  
2023-05-29 09:42:13.282: Find a better model.
2023-05-29 09:42:19.748: [iter 42 : loss : 0.2009 = 0.1056 + 0.0924 + 0.0029, time: 6.465487]
2023-05-29 09:42:19.905: epoch 42:	0.02333527  	0.17211032  	0.09071115  
2023-05-29 09:42:19.905: Find a better model.
2023-05-29 09:42:26.509: [iter 43 : loss : 0.1968 = 0.1017 + 0.0921 + 0.0030, time: 6.602993]
2023-05-29 09:42:26.663: epoch 43:	0.02339172  	0.17233039  	0.09111787  
2023-05-29 09:42:26.663: Find a better model.
2023-05-29 09:42:33.137: [iter 44 : loss : 0.1934 = 0.0985 + 0.0918 + 0.0030, time: 6.471455]
2023-05-29 09:42:33.292: epoch 44:	0.02349052  	0.17316480  	0.09173588  
2023-05-29 09:42:33.292: Find a better model.
2023-05-29 09:42:39.740: [iter 45 : loss : 0.1911 = 0.0964 + 0.0916 + 0.0031, time: 6.447177]
2023-05-29 09:42:39.884: epoch 45:	0.02358931  	0.17408000  	0.09217816  
2023-05-29 09:42:39.884: Find a better model.
2023-05-29 09:42:46.342: [iter 46 : loss : 0.1888 = 0.0943 + 0.0913 + 0.0031, time: 6.456220]
2023-05-29 09:42:46.499: epoch 46:	0.02364576  	0.17438981  	0.09259961  
2023-05-29 09:42:46.500: Find a better model.
2023-05-29 09:42:52.914: [iter 47 : loss : 0.1882 = 0.0939 + 0.0911 + 0.0032, time: 6.413001]
2023-05-29 09:42:53.069: epoch 47:	0.02377983  	0.17565258  	0.09305206  
2023-05-29 09:42:53.069: Find a better model.
2023-05-29 09:42:59.514: [iter 48 : loss : 0.1844 = 0.0903 + 0.0909 + 0.0032, time: 6.444004]
2023-05-29 09:42:59.670: epoch 48:	0.02386451  	0.17612143  	0.09322586  
2023-05-29 09:42:59.670: Find a better model.
2023-05-29 09:43:06.110: [iter 49 : loss : 0.1812 = 0.0873 + 0.0907 + 0.0033, time: 6.438010]
2023-05-29 09:43:06.266: epoch 49:	0.02391391  	0.17681403  	0.09374502  
2023-05-29 09:43:06.266: Find a better model.
2023-05-29 09:43:12.720: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 6.453008]
2023-05-29 09:43:12.876: epoch 50:	0.02401975  	0.17767057  	0.09421176  
2023-05-29 09:43:12.876: Find a better model.
2023-05-29 09:43:19.308: [iter 51 : loss : 0.1774 = 0.0837 + 0.0903 + 0.0034, time: 6.429949]
2023-05-29 09:43:19.464: epoch 51:	0.02399858  	0.17744949  	0.09439223  
2023-05-29 09:43:25.909: [iter 52 : loss : 0.1775 = 0.0841 + 0.0901 + 0.0034, time: 6.444058]
2023-05-29 09:43:26.065: epoch 52:	0.02411148  	0.17826590  	0.09497780  
2023-05-29 09:43:26.065: Find a better model.
2023-05-29 09:43:32.518: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 6.452222]
2023-05-29 09:43:32.673: epoch 53:	0.02419615  	0.17914237  	0.09549371  
2023-05-29 09:43:32.673: Find a better model.
2023-05-29 09:43:39.297: [iter 54 : loss : 0.1734 = 0.0803 + 0.0897 + 0.0035, time: 6.622473]
2023-05-29 09:43:39.441: epoch 54:	0.02428083  	0.18012710  	0.09605225  
2023-05-29 09:43:39.441: Find a better model.
2023-05-29 09:43:45.893: [iter 55 : loss : 0.1715 = 0.0784 + 0.0895 + 0.0036, time: 6.451107]
2023-05-29 09:43:46.050: epoch 55:	0.02433022  	0.18046056  	0.09623124  
2023-05-29 09:43:46.050: Find a better model.
2023-05-29 09:43:52.673: [iter 56 : loss : 0.1697 = 0.0768 + 0.0893 + 0.0036, time: 6.622036]
2023-05-29 09:43:52.826: epoch 56:	0.02442901  	0.18125899  	0.09665595  
2023-05-29 09:43:52.826: Find a better model.
2023-05-29 09:43:59.329: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 6.502007]
2023-05-29 09:43:59.485: epoch 57:	0.02448546  	0.18160756  	0.09683183  
2023-05-29 09:43:59.485: Find a better model.
2023-05-29 09:44:05.907: [iter 58 : loss : 0.1662 = 0.0736 + 0.0890 + 0.0037, time: 6.421216]
2023-05-29 09:44:06.063: epoch 58:	0.02457014  	0.18275611  	0.09741189  
2023-05-29 09:44:06.063: Find a better model.
2023-05-29 09:44:12.496: [iter 59 : loss : 0.1651 = 0.0726 + 0.0887 + 0.0037, time: 6.432016]
2023-05-29 09:44:12.652: epoch 59:	0.02464070  	0.18297189  	0.09763648  
2023-05-29 09:44:12.652: Find a better model.
2023-05-29 09:44:19.270: [iter 60 : loss : 0.1636 = 0.0711 + 0.0886 + 0.0038, time: 6.616994]
2023-05-29 09:44:19.427: epoch 60:	0.02467599  	0.18333533  	0.09806347  
2023-05-29 09:44:19.427: Find a better model.
2023-05-29 09:44:25.885: [iter 61 : loss : 0.1621 = 0.0699 + 0.0884 + 0.0038, time: 6.457031]
2023-05-29 09:44:26.043: epoch 61:	0.02470421  	0.18344264  	0.09827115  
2023-05-29 09:44:26.043: Find a better model.
2023-05-29 09:44:32.662: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 6.618018]
2023-05-29 09:44:32.816: epoch 62:	0.02479595  	0.18408902  	0.09873377  
2023-05-29 09:44:32.816: Find a better model.
2023-05-29 09:44:39.315: [iter 63 : loss : 0.1593 = 0.0673 + 0.0881 + 0.0039, time: 6.497262]
2023-05-29 09:44:39.472: epoch 63:	0.02483123  	0.18399853  	0.09894913  
2023-05-29 09:44:45.890: [iter 64 : loss : 0.1583 = 0.0664 + 0.0880 + 0.0040, time: 6.416715]
2023-05-29 09:44:46.046: epoch 64:	0.02491590  	0.18449946  	0.09924375  
2023-05-29 09:44:46.046: Find a better model.
2023-05-29 09:44:52.669: [iter 65 : loss : 0.1570 = 0.0652 + 0.0878 + 0.0040, time: 6.622007]
2023-05-29 09:44:52.827: epoch 65:	0.02496530  	0.18467455  	0.09985550  
2023-05-29 09:44:52.827: Find a better model.
2023-05-29 09:44:59.460: [iter 66 : loss : 0.1555 = 0.0638 + 0.0877 + 0.0040, time: 6.631018]
2023-05-29 09:44:59.619: epoch 66:	0.02509937  	0.18574341  	0.10045318  
2023-05-29 09:44:59.619: Find a better model.
2023-05-29 09:45:06.260: [iter 67 : loss : 0.1542 = 0.0626 + 0.0875 + 0.0041, time: 6.640011]
2023-05-29 09:45:06.404: epoch 67:	0.02514171  	0.18596473  	0.10079805  
2023-05-29 09:45:06.404: Find a better model.
2023-05-29 09:45:12.880: [iter 68 : loss : 0.1538 = 0.0623 + 0.0874 + 0.0041, time: 6.473994]
2023-05-29 09:45:13.023: epoch 68:	0.02527578  	0.18675987  	0.10108743  
2023-05-29 09:45:13.023: Find a better model.
2023-05-29 09:45:19.650: [iter 69 : loss : 0.1519 = 0.0604 + 0.0873 + 0.0042, time: 6.625545]
2023-05-29 09:45:19.807: epoch 69:	0.02526167  	0.18677229  	0.10115211  
2023-05-29 09:45:19.807: Find a better model.
2023-05-29 09:45:26.294: [iter 70 : loss : 0.1503 = 0.0589 + 0.0872 + 0.0042, time: 6.486006]
2023-05-29 09:45:26.451: epoch 70:	0.02541691  	0.18768413  	0.10161213  
2023-05-29 09:45:26.451: Find a better model.
2023-05-29 09:45:32.857: [iter 71 : loss : 0.1489 = 0.0576 + 0.0870 + 0.0043, time: 6.405181]
2023-05-29 09:45:33.012: epoch 71:	0.02543808  	0.18768108  	0.10186193  
2023-05-29 09:45:39.639: [iter 72 : loss : 0.1486 = 0.0574 + 0.0869 + 0.0043, time: 6.625028]
2023-05-29 09:45:39.794: epoch 72:	0.02543102  	0.18794952  	0.10208131  
2023-05-29 09:45:39.794: Find a better model.
2023-05-29 09:45:46.441: [iter 73 : loss : 0.1473 = 0.0562 + 0.0868 + 0.0043, time: 6.646497]
2023-05-29 09:45:46.600: epoch 73:	0.02548747  	0.18821423  	0.10246452  
2023-05-29 09:45:46.600: Find a better model.
2023-05-29 09:45:53.058: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 6.457004]
2023-05-29 09:45:53.213: epoch 74:	0.02548747  	0.18798445  	0.10252696  
2023-05-29 09:45:59.660: [iter 75 : loss : 0.1454 = 0.0545 + 0.0865 + 0.0044, time: 6.445011]
2023-05-29 09:45:59.815: epoch 75:	0.02548041  	0.18802546  	0.10261449  
2023-05-29 09:46:06.450: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 6.633088]
2023-05-29 09:46:06.595: epoch 76:	0.02555803  	0.18840702  	0.10296714  
2023-05-29 09:46:06.595: Find a better model.
2023-05-29 09:46:13.061: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 6.465029]
2023-05-29 09:46:13.216: epoch 77:	0.02564272  	0.18906085  	0.10323063  
2023-05-29 09:46:13.216: Find a better model.
2023-05-29 09:46:19.650: [iter 78 : loss : 0.1427 = 0.0520 + 0.0862 + 0.0045, time: 6.432999]
2023-05-29 09:46:19.806: epoch 78:	0.02567800  	0.18934795  	0.10333364  
2023-05-29 09:46:19.806: Find a better model.
2023-05-29 09:46:26.247: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 6.438472]
2023-05-29 09:46:26.389: epoch 79:	0.02565683  	0.18933600  	0.10335689  
2023-05-29 09:46:32.849: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 6.458032]
2023-05-29 09:46:33.004: epoch 80:	0.02573445  	0.18994674  	0.10368660  
2023-05-29 09:46:33.004: Find a better model.
2023-05-29 09:46:39.633: [iter 81 : loss : 0.1405 = 0.0499 + 0.0859 + 0.0047, time: 6.628070]
2023-05-29 09:46:39.790: epoch 81:	0.02575562  	0.19010241  	0.10375397  
2023-05-29 09:46:39.790: Find a better model.
2023-05-29 09:46:46.421: [iter 82 : loss : 0.1391 = 0.0486 + 0.0858 + 0.0047, time: 6.630398]
2023-05-29 09:46:46.579: epoch 82:	0.02593909  	0.19127873  	0.10442533  
2023-05-29 09:46:46.580: Find a better model.
2023-05-29 09:46:53.059: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 6.478004]
2023-05-29 09:46:53.203: epoch 83:	0.02591792  	0.19122753  	0.10434162  
2023-05-29 09:46:59.819: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 6.614422]
2023-05-29 09:46:59.975: epoch 84:	0.02591792  	0.19129056  	0.10438651  
2023-05-29 09:46:59.975: Find a better model.
2023-05-29 09:47:06.443: [iter 85 : loss : 0.1371 = 0.0468 + 0.0855 + 0.0048, time: 6.465003]
2023-05-29 09:47:06.588: epoch 85:	0.02591087  	0.19136642  	0.10479141  
2023-05-29 09:47:06.588: Find a better model.
2023-05-29 09:47:13.042: [iter 86 : loss : 0.1368 = 0.0466 + 0.0854 + 0.0049, time: 6.453008]
2023-05-29 09:47:13.197: epoch 86:	0.02597438  	0.19166841  	0.10489704  
2023-05-29 09:47:13.197: Find a better model.
2023-05-29 09:47:19.815: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 6.617003]
2023-05-29 09:47:19.971: epoch 87:	0.02607317  	0.19224219  	0.10512664  
2023-05-29 09:47:19.971: Find a better model.
2023-05-29 09:47:26.621: [iter 88 : loss : 0.1337 = 0.0436 + 0.0852 + 0.0049, time: 6.648997]
2023-05-29 09:47:26.776: epoch 88:	0.02608023  	0.19226837  	0.10511711  
2023-05-29 09:47:26.776: Find a better model.
2023-05-29 09:47:33.427: [iter 89 : loss : 0.1335 = 0.0434 + 0.0851 + 0.0050, time: 6.650291]
2023-05-29 09:47:33.572: epoch 89:	0.02603083  	0.19170186  	0.10493099  
2023-05-29 09:47:40.013: [iter 90 : loss : 0.1341 = 0.0440 + 0.0851 + 0.0050, time: 6.440007]
2023-05-29 09:47:40.159: epoch 90:	0.02620724  	0.19286238  	0.10541573  
2023-05-29 09:47:40.159: Find a better model.
2023-05-29 09:47:46.637: [iter 91 : loss : 0.1327 = 0.0427 + 0.0849 + 0.0050, time: 6.477003]
2023-05-29 09:47:46.794: epoch 91:	0.02622136  	0.19309144  	0.10551340  
2023-05-29 09:47:46.794: Find a better model.
2023-05-29 09:47:53.409: [iter 92 : loss : 0.1315 = 0.0415 + 0.0849 + 0.0051, time: 6.613153]
2023-05-29 09:47:53.567: epoch 92:	0.02627075  	0.19332008  	0.10576107  
2023-05-29 09:47:53.567: Find a better model.
2023-05-29 09:48:00.200: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 6.631994]
2023-05-29 09:48:00.345: epoch 93:	0.02626370  	0.19348286  	0.10588794  
2023-05-29 09:48:00.346: Find a better model.
2023-05-29 09:48:06.800: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 6.453092]
2023-05-29 09:48:06.959: epoch 94:	0.02635543  	0.19406378  	0.10619074  
2023-05-29 09:48:06.959: Find a better model.
2023-05-29 09:48:13.614: [iter 95 : loss : 0.1292 = 0.0394 + 0.0847 + 0.0052, time: 6.653372]
2023-05-29 09:48:13.771: epoch 95:	0.02632015  	0.19381511  	0.10616567  
2023-05-29 09:48:20.228: [iter 96 : loss : 0.1293 = 0.0395 + 0.0846 + 0.0052, time: 6.456710]
2023-05-29 09:48:20.372: epoch 96:	0.02631309  	0.19380218  	0.10632121  
2023-05-29 09:48:26.806: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 6.431084]
2023-05-29 09:48:26.960: epoch 97:	0.02635543  	0.19422498  	0.10641174  
2023-05-29 09:48:26.960: Find a better model.
2023-05-29 09:48:33.590: [iter 98 : loss : 0.1284 = 0.0386 + 0.0844 + 0.0053, time: 6.629117]
2023-05-29 09:48:33.747: epoch 98:	0.02649656  	0.19535162  	0.10685667  
2023-05-29 09:48:33.747: Find a better model.
2023-05-29 09:48:40.206: [iter 99 : loss : 0.1274 = 0.0377 + 0.0844 + 0.0053, time: 6.458033]
2023-05-29 09:48:40.362: epoch 99:	0.02656006  	0.19601974  	0.10707307  
2023-05-29 09:48:40.362: Find a better model.
2023-05-29 09:48:46.979: [iter 100 : loss : 0.1269 = 0.0373 + 0.0843 + 0.0054, time: 6.616004]
2023-05-29 09:48:47.135: epoch 100:	0.02658829  	0.19632106  	0.10702197  
2023-05-29 09:48:47.135: Find a better model.
2023-05-29 09:48:53.602: [iter 101 : loss : 0.1265 = 0.0369 + 0.0842 + 0.0054, time: 6.463976]
2023-05-29 09:48:53.745: epoch 101:	0.02660946  	0.19651890  	0.10707858  
2023-05-29 09:48:53.745: Find a better model.
2023-05-29 09:49:00.236: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0055, time: 6.490010]
2023-05-29 09:49:00.381: epoch 102:	0.02668002  	0.19689581  	0.10739435  
2023-05-29 09:49:00.381: Find a better model.
2023-05-29 09:49:06.784: [iter 103 : loss : 0.1254 = 0.0359 + 0.0841 + 0.0055, time: 6.402033]
2023-05-29 09:49:06.939: epoch 103:	0.02672942  	0.19708845  	0.10746172  
2023-05-29 09:49:06.940: Find a better model.
2023-05-29 09:49:13.387: [iter 104 : loss : 0.1257 = 0.0361 + 0.0840 + 0.0055, time: 6.446101]
2023-05-29 09:49:13.546: epoch 104:	0.02676470  	0.19758858  	0.10781977  
2023-05-29 09:49:13.546: Find a better model.
2023-05-29 09:49:19.980: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 6.433453]
2023-05-29 09:49:20.138: epoch 105:	0.02670825  	0.19723174  	0.10779316  
2023-05-29 09:49:26.572: [iter 106 : loss : 0.1245 = 0.0351 + 0.0839 + 0.0056, time: 6.432994]
2023-05-29 09:49:26.718: epoch 106:	0.02668708  	0.19672938  	0.10751413  
2023-05-29 09:49:33.372: [iter 107 : loss : 0.1236 = 0.0341 + 0.0838 + 0.0056, time: 6.652010]
2023-05-29 09:49:33.520: epoch 107:	0.02674353  	0.19700524  	0.10766010  
2023-05-29 09:49:39.971: [iter 108 : loss : 0.1234 = 0.0339 + 0.0838 + 0.0057, time: 6.449018]
2023-05-29 09:49:40.125: epoch 108:	0.02674353  	0.19727808  	0.10775302  
2023-05-29 09:49:46.600: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 6.473017]
2023-05-29 09:49:46.754: epoch 109:	0.02679998  	0.19769494  	0.10778759  
2023-05-29 09:49:46.755: Find a better model.
2023-05-29 09:49:53.348: [iter 110 : loss : 0.1215 = 0.0321 + 0.0837 + 0.0057, time: 6.592020]
2023-05-29 09:49:53.508: epoch 110:	0.02684937  	0.19792853  	0.10786643  
2023-05-29 09:49:53.508: Find a better model.
2023-05-29 09:50:00.224: [iter 111 : loss : 0.1214 = 0.0321 + 0.0835 + 0.0058, time: 6.714004]
2023-05-29 09:50:00.385: epoch 111:	0.02684232  	0.19815508  	0.10798548  
2023-05-29 09:50:00.385: Find a better model.
2023-05-29 09:50:07.241: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.854158]
2023-05-29 09:50:07.404: epoch 112:	0.02690582  	0.19857737  	0.10814305  
2023-05-29 09:50:07.404: Find a better model.
2023-05-29 09:50:14.186: [iter 113 : loss : 0.1212 = 0.0319 + 0.0834 + 0.0058, time: 6.781025]
2023-05-29 09:50:14.339: epoch 113:	0.02694816  	0.19922990  	0.10830060  
2023-05-29 09:50:14.339: Find a better model.
2023-05-29 09:50:21.028: [iter 114 : loss : 0.1204 = 0.0312 + 0.0834 + 0.0059, time: 6.688033]
2023-05-29 09:50:21.188: epoch 114:	0.02696227  	0.19918688  	0.10846816  
2023-05-29 09:50:27.998: [iter 115 : loss : 0.1201 = 0.0308 + 0.0833 + 0.0059, time: 6.809153]
2023-05-29 09:50:28.166: epoch 115:	0.02694816  	0.19856049  	0.10844053  
2023-05-29 09:50:34.761: [iter 116 : loss : 0.1192 = 0.0300 + 0.0833 + 0.0059, time: 6.594028]
2023-05-29 09:50:34.916: epoch 116:	0.02691287  	0.19813544  	0.10831242  
2023-05-29 09:50:41.569: [iter 117 : loss : 0.1192 = 0.0300 + 0.0832 + 0.0060, time: 6.652253]
2023-05-29 09:50:41.724: epoch 117:	0.02692698  	0.19819802  	0.10824005  
2023-05-29 09:50:48.563: [iter 118 : loss : 0.1190 = 0.0299 + 0.0832 + 0.0060, time: 6.837062]
2023-05-29 09:50:48.705: epoch 118:	0.02696932  	0.19853675  	0.10840329  
2023-05-29 09:50:55.573: [iter 119 : loss : 0.1180 = 0.0289 + 0.0831 + 0.0060, time: 6.865649]
2023-05-29 09:50:55.722: epoch 119:	0.02694109  	0.19831474  	0.10855779  
2023-05-29 09:51:02.681: [iter 120 : loss : 0.1185 = 0.0294 + 0.0831 + 0.0061, time: 6.957033]
2023-05-29 09:51:02.837: epoch 120:	0.02699755  	0.19879439  	0.10874864  
2023-05-29 09:51:09.554: [iter 121 : loss : 0.1183 = 0.0293 + 0.0830 + 0.0061, time: 6.716027]
2023-05-29 09:51:09.709: epoch 121:	0.02697637  	0.19854870  	0.10881762  
2023-05-29 09:51:16.381: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 6.670459]
2023-05-29 09:51:16.531: epoch 122:	0.02702577  	0.19889085  	0.10889284  
2023-05-29 09:51:23.349: [iter 123 : loss : 0.1175 = 0.0284 + 0.0829 + 0.0061, time: 6.815024]
2023-05-29 09:51:23.494: epoch 123:	0.02698343  	0.19852665  	0.10860945  
2023-05-29 09:51:30.453: [iter 124 : loss : 0.1163 = 0.0273 + 0.0829 + 0.0062, time: 6.957994]
2023-05-29 09:51:30.628: epoch 124:	0.02703283  	0.19904944  	0.10868035  
2023-05-29 09:51:37.636: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 7.006994]
2023-05-29 09:51:37.798: epoch 125:	0.02707516  	0.19939952  	0.10877541  
2023-05-29 09:51:37.798: Find a better model.
2023-05-29 09:51:44.796: [iter 126 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 6.996197]
2023-05-29 09:51:44.957: epoch 126:	0.02701871  	0.19894959  	0.10867184  
2023-05-29 09:51:52.159: [iter 127 : loss : 0.1151 = 0.0261 + 0.0827 + 0.0063, time: 7.201416]
2023-05-29 09:51:52.305: epoch 127:	0.02699754  	0.19921534  	0.10889537  
2023-05-29 09:51:59.338: [iter 128 : loss : 0.1162 = 0.0272 + 0.0827 + 0.0063, time: 7.032364]
2023-05-29 09:51:59.482: epoch 128:	0.02706811  	0.19974394  	0.10903402  
2023-05-29 09:51:59.482: Find a better model.
2023-05-29 09:52:06.096: [iter 129 : loss : 0.1152 = 0.0262 + 0.0827 + 0.0063, time: 6.612026]
2023-05-29 09:52:06.264: epoch 129:	0.02712456  	0.19999886  	0.10922662  
2023-05-29 09:52:06.264: Find a better model.
2023-05-29 09:52:13.379: [iter 130 : loss : 0.1153 = 0.0264 + 0.0826 + 0.0064, time: 7.113132]
2023-05-29 09:52:13.555: epoch 130:	0.02714573  	0.20043491  	0.10948991  
2023-05-29 09:52:13.555: Find a better model.
2023-05-29 09:52:20.414: [iter 131 : loss : 0.1144 = 0.0254 + 0.0826 + 0.0064, time: 6.856360]
2023-05-29 09:52:20.588: epoch 131:	0.02713162  	0.20020686  	0.10956822  
2023-05-29 09:52:27.633: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 7.044055]
2023-05-29 09:52:27.782: epoch 132:	0.02715984  	0.20060162  	0.10953895  
2023-05-29 09:52:27.782: Find a better model.
2023-05-29 09:52:34.542: [iter 133 : loss : 0.1133 = 0.0244 + 0.0825 + 0.0064, time: 6.759050]
2023-05-29 09:52:34.697: epoch 133:	0.02713162  	0.20045197  	0.10965587  
2023-05-29 09:52:41.538: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.838885]
2023-05-29 09:52:41.691: epoch 134:	0.02712456  	0.20008670  	0.10960761  
2023-05-29 09:52:48.580: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.887694]
2023-05-29 09:52:48.740: epoch 135:	0.02708928  	0.19987464  	0.10947080  
2023-05-29 09:52:55.178: [iter 136 : loss : 0.1136 = 0.0247 + 0.0824 + 0.0065, time: 6.437311]
2023-05-29 09:52:55.320: epoch 136:	0.02700461  	0.19972444  	0.10924624  
2023-05-29 09:53:01.882: [iter 137 : loss : 0.1132 = 0.0243 + 0.0823 + 0.0066, time: 6.560047]
2023-05-29 09:53:02.025: epoch 137:	0.02709633  	0.19999237  	0.10942844  
2023-05-29 09:53:08.740: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.713376]
2023-05-29 09:53:08.889: epoch 138:	0.02702578  	0.19952185  	0.10922310  
2023-05-29 09:53:15.780: [iter 139 : loss : 0.1125 = 0.0237 + 0.0822 + 0.0066, time: 6.889019]
2023-05-29 09:53:15.935: epoch 139:	0.02703988  	0.19944791  	0.10928187  
2023-05-29 09:53:22.761: [iter 140 : loss : 0.1121 = 0.0232 + 0.0822 + 0.0067, time: 6.825029]
2023-05-29 09:53:22.904: epoch 140:	0.02704694  	0.19950166  	0.10928306  
2023-05-29 09:53:29.981: [iter 141 : loss : 0.1127 = 0.0239 + 0.0822 + 0.0067, time: 7.075362]
2023-05-29 09:53:30.125: epoch 141:	0.02705400  	0.19939590  	0.10950025  
2023-05-29 09:53:36.786: [iter 142 : loss : 0.1117 = 0.0229 + 0.0821 + 0.0067, time: 6.659101]
2023-05-29 09:53:36.945: epoch 142:	0.02706811  	0.19954564  	0.10957107  
2023-05-29 09:53:43.885: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.937599]
2023-05-29 09:53:44.039: epoch 143:	0.02708222  	0.19972038  	0.10965429  
2023-05-29 09:53:50.738: [iter 144 : loss : 0.1113 = 0.0224 + 0.0821 + 0.0068, time: 6.697083]
2023-05-29 09:53:50.891: epoch 144:	0.02706106  	0.19966052  	0.10967819  
2023-05-29 09:53:57.740: [iter 145 : loss : 0.1113 = 0.0225 + 0.0820 + 0.0068, time: 6.848031]
2023-05-29 09:53:57.914: epoch 145:	0.02712457  	0.20008992  	0.10978374  
2023-05-29 09:54:04.702: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.786006]
2023-05-29 09:54:04.849: epoch 146:	0.02703284  	0.19933487  	0.10948694  
2023-05-29 09:54:11.683: [iter 147 : loss : 0.1112 = 0.0224 + 0.0820 + 0.0068, time: 6.833431]
2023-05-29 09:54:11.839: epoch 147:	0.02708223  	0.19976455  	0.10976118  
2023-05-29 09:54:18.496: [iter 148 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.655006]
2023-05-29 09:54:18.651: epoch 148:	0.02711751  	0.19978099  	0.10970251  
2023-05-29 09:54:25.278: [iter 149 : loss : 0.1105 = 0.0217 + 0.0819 + 0.0069, time: 6.626044]
2023-05-29 09:54:25.421: epoch 149:	0.02715279  	0.19992656  	0.10979959  
2023-05-29 09:54:32.090: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.668051]
2023-05-29 09:54:32.246: epoch 150:	0.02717396  	0.20009175  	0.11015885  
2023-05-29 09:54:38.885: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.636388]
2023-05-29 09:54:39.043: epoch 151:	0.02715985  	0.19977865  	0.11002841  
2023-05-29 09:54:45.674: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.629017]
2023-05-29 09:54:45.830: epoch 152:	0.02714573  	0.19978631  	0.11011723  
2023-05-29 09:54:52.460: [iter 153 : loss : 0.1085 = 0.0198 + 0.0818 + 0.0070, time: 6.629226]
2023-05-29 09:54:52.618: epoch 153:	0.02709634  	0.19927441  	0.10983893  
2023-05-29 09:54:59.466: [iter 154 : loss : 0.1091 = 0.0204 + 0.0817 + 0.0070, time: 6.847023]
2023-05-29 09:54:59.624: epoch 154:	0.02723041  	0.20035702  	0.11022659  
2023-05-29 09:55:06.269: [iter 155 : loss : 0.1098 = 0.0211 + 0.0817 + 0.0070, time: 6.644021]
2023-05-29 09:55:06.427: epoch 155:	0.02713868  	0.19980915  	0.10998906  
2023-05-29 09:55:13.073: [iter 156 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.645032]
2023-05-29 09:55:13.226: epoch 156:	0.02712457  	0.19975503  	0.10982355  
2023-05-29 09:55:19.852: [iter 157 : loss : 0.1090 = 0.0203 + 0.0816 + 0.0071, time: 6.625022]
2023-05-29 09:55:20.007: epoch 157:	0.02712457  	0.19972892  	0.10978328  
2023-05-29 09:55:20.007: Early stopping is trigger at epoch: 157
2023-05-29 09:55:20.007: best_result@epoch 132:

2023-05-29 09:55:20.007: 		0.0272      	0.2006      	0.1095      
2023-05-29 10:09:15.233: my pid: 2092
2023-05-29 10:09:15.233: model: model.general_recommender.SGL
2023-05-29 10:09:15.233: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 10:09:15.233: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 10:09:18.887: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 10:09:26.225: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.336016]
2023-05-29 10:09:26.387: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-29 10:09:26.387: Find a better model.
2023-05-29 10:09:33.806: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.416043]
2023-05-29 10:09:33.977: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-29 10:09:33.978: Find a better model.
2023-05-29 10:09:41.245: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.265043]
2023-05-29 10:09:41.421: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-29 10:09:41.421: Find a better model.
2023-05-29 10:09:48.595: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.173071]
2023-05-29 10:09:48.750: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-29 10:09:48.751: Find a better model.
2023-05-29 10:09:55.806: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.054065]
2023-05-29 10:09:55.962: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-29 10:09:55.962: Find a better model.
2023-05-29 10:10:02.780: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 6.817318]
2023-05-29 10:10:02.936: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-29 10:10:02.936: Find a better model.
2023-05-29 10:10:09.551: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.614050]
2023-05-29 10:10:09.693: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-29 10:10:09.693: Find a better model.
2023-05-29 10:10:16.339: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.645331]
2023-05-29 10:10:16.485: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-29 10:10:16.485: Find a better model.
2023-05-29 10:10:23.141: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.654420]
2023-05-29 10:10:23.295: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-29 10:10:23.296: Find a better model.
2023-05-29 10:10:29.761: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.464022]
2023-05-29 10:10:29.916: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-29 10:10:29.916: Find a better model.
2023-05-29 10:10:36.361: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.444022]
2023-05-29 10:10:36.516: epoch 11:	0.01792997  	0.13071378  	0.06561104  
2023-05-29 10:10:36.516: Find a better model.
2023-05-29 10:10:42.958: [iter 12 : loss : 0.8124 = 0.6521 + 0.1602 + 0.0001, time: 6.441021]
2023-05-29 10:10:43.112: epoch 12:	0.01906606  	0.13890964  	0.07020870  
2023-05-29 10:10:43.112: Find a better model.
2023-05-29 10:10:49.555: [iter 13 : loss : 0.7836 = 0.6201 + 0.1633 + 0.0002, time: 6.441409]
2023-05-29 10:10:49.710: epoch 13:	0.01940478  	0.14273208  	0.07212908  
2023-05-29 10:10:49.710: Find a better model.
2023-05-29 10:10:56.151: [iter 14 : loss : 0.7389 = 0.5706 + 0.1680 + 0.0003, time: 6.440014]
2023-05-29 10:10:56.307: epoch 14:	0.01970116  	0.14504859  	0.07354332  
2023-05-29 10:10:56.308: Find a better model.
2023-05-29 10:11:02.748: [iter 15 : loss : 0.6820 = 0.5080 + 0.1735 + 0.0004, time: 6.439014]
2023-05-29 10:11:02.906: epoch 15:	0.01960237  	0.14494573  	0.07367033  
2023-05-29 10:11:09.530: [iter 16 : loss : 0.6210 = 0.4418 + 0.1787 + 0.0005, time: 6.623025]
2023-05-29 10:11:09.682: epoch 16:	0.01980702  	0.14624931  	0.07437406  
2023-05-29 10:11:09.682: Find a better model.
2023-05-29 10:11:16.137: [iter 17 : loss : 0.5669 = 0.3838 + 0.1824 + 0.0007, time: 6.454020]
2023-05-29 10:11:16.279: epoch 17:	0.01999755  	0.14784198  	0.07520582  
2023-05-29 10:11:16.279: Find a better model.
2023-05-29 10:11:22.744: [iter 18 : loss : 0.5221 = 0.3362 + 0.1850 + 0.0009, time: 6.464003]
2023-05-29 10:11:22.903: epoch 18:	0.02018807  	0.14921135  	0.07606281  
2023-05-29 10:11:22.903: Find a better model.
2023-05-29 10:11:29.523: [iter 19 : loss : 0.4857 = 0.2984 + 0.1863 + 0.0010, time: 6.618117]
2023-05-29 10:11:29.679: epoch 19:	0.02036449  	0.15031588  	0.07704230  
2023-05-29 10:11:29.679: Find a better model.
2023-05-29 10:11:36.334: [iter 20 : loss : 0.4589 = 0.2709 + 0.1869 + 0.0011, time: 6.653512]
2023-05-29 10:11:36.480: epoch 20:	0.02055501  	0.15174694  	0.07799698  
2023-05-29 10:11:36.480: Find a better model.
2023-05-29 10:11:43.106: [iter 21 : loss : 0.4360 = 0.2477 + 0.1870 + 0.0013, time: 6.623994]
2023-05-29 10:11:43.249: epoch 21:	0.02087961  	0.15459664  	0.07932968  
2023-05-29 10:11:43.249: Find a better model.
2023-05-29 10:11:49.746: [iter 22 : loss : 0.4176 = 0.2295 + 0.1867 + 0.0014, time: 6.495015]
2023-05-29 10:11:49.903: epoch 22:	0.02106308  	0.15567601  	0.08007116  
2023-05-29 10:11:49.903: Find a better model.
2023-05-29 10:11:56.514: [iter 23 : loss : 0.4016 = 0.2137 + 0.1864 + 0.0015, time: 6.609032]
2023-05-29 10:11:56.670: epoch 23:	0.02125360  	0.15722056  	0.08101661  
2023-05-29 10:11:56.670: Find a better model.
2023-05-29 10:12:03.295: [iter 24 : loss : 0.3885 = 0.2011 + 0.1858 + 0.0016, time: 6.624102]
2023-05-29 10:12:03.441: epoch 24:	0.02147942  	0.15902002  	0.08210165  
2023-05-29 10:12:03.441: Find a better model.
2023-05-29 10:12:09.943: [iter 25 : loss : 0.3765 = 0.1896 + 0.1852 + 0.0017, time: 6.501225]
2023-05-29 10:12:10.098: epoch 25:	0.02172640  	0.16076252  	0.08286550  
2023-05-29 10:12:10.098: Find a better model.
2023-05-29 10:12:16.722: [iter 26 : loss : 0.3678 = 0.1814 + 0.1845 + 0.0018, time: 6.622044]
2023-05-29 10:12:16.877: epoch 26:	0.02200160  	0.16225316  	0.08398231  
2023-05-29 10:12:16.877: Find a better model.
2023-05-29 10:12:23.504: [iter 27 : loss : 0.3568 = 0.1710 + 0.1838 + 0.0019, time: 6.625004]
2023-05-29 10:12:23.648: epoch 27:	0.02220624  	0.16342269  	0.08502527  
2023-05-29 10:12:23.648: Find a better model.
2023-05-29 10:12:30.298: [iter 28 : loss : 0.3482 = 0.1631 + 0.1831 + 0.0020, time: 6.649017]
2023-05-29 10:12:30.442: epoch 28:	0.02233326  	0.16468820  	0.08580623  
2023-05-29 10:12:30.443: Find a better model.
2023-05-29 10:12:36.934: [iter 29 : loss : 0.3410 = 0.1566 + 0.1824 + 0.0021, time: 6.489034]
2023-05-29 10:12:37.088: epoch 29:	0.02262257  	0.16678733  	0.08686202  
2023-05-29 10:12:37.088: Find a better model.
2023-05-29 10:12:43.688: [iter 30 : loss : 0.3323 = 0.1484 + 0.1817 + 0.0022, time: 6.598024]
2023-05-29 10:12:43.847: epoch 30:	0.02277076  	0.16804229  	0.08770016  
2023-05-29 10:12:43.847: Find a better model.
2023-05-29 10:12:50.510: [iter 31 : loss : 0.3265 = 0.1432 + 0.1810 + 0.0023, time: 6.662003]
2023-05-29 10:12:50.664: epoch 31:	0.02291894  	0.16888899  	0.08838385  
2023-05-29 10:12:50.665: Find a better model.
2023-05-29 10:12:57.115: [iter 32 : loss : 0.3193 = 0.1365 + 0.1804 + 0.0024, time: 6.449016]
2023-05-29 10:12:57.261: epoch 32:	0.02307418  	0.17045374  	0.08935601  
2023-05-29 10:12:57.261: Find a better model.
2023-05-29 10:13:03.709: [iter 33 : loss : 0.3145 = 0.1323 + 0.1797 + 0.0024, time: 6.447057]
2023-05-29 10:13:03.864: epoch 33:	0.02324354  	0.17168748  	0.09021499  
2023-05-29 10:13:03.864: Find a better model.
2023-05-29 10:13:10.493: [iter 34 : loss : 0.3089 = 0.1274 + 0.1791 + 0.0025, time: 6.627994]
2023-05-29 10:13:10.648: epoch 34:	0.02349051  	0.17362219  	0.09113641  
2023-05-29 10:13:10.648: Find a better model.
2023-05-29 10:13:17.303: [iter 35 : loss : 0.3040 = 0.1229 + 0.1785 + 0.0026, time: 6.654008]
2023-05-29 10:13:17.462: epoch 35:	0.02363870  	0.17478678  	0.09204610  
2023-05-29 10:13:17.462: Find a better model.
2023-05-29 10:13:24.081: [iter 36 : loss : 0.2997 = 0.1190 + 0.1780 + 0.0027, time: 6.618028]
2023-05-29 10:13:24.240: epoch 36:	0.02366692  	0.17498364  	0.09249083  
2023-05-29 10:13:24.240: Find a better model.
2023-05-29 10:13:30.884: [iter 37 : loss : 0.2945 = 0.1144 + 0.1774 + 0.0027, time: 6.643221]
2023-05-29 10:13:31.041: epoch 37:	0.02377277  	0.17577618  	0.09317782  
2023-05-29 10:13:31.041: Find a better model.
2023-05-29 10:13:37.505: [iter 38 : loss : 0.2918 = 0.1121 + 0.1769 + 0.0028, time: 6.461997]
2023-05-29 10:13:37.648: epoch 38:	0.02387862  	0.17681120  	0.09385397  
2023-05-29 10:13:37.648: Find a better model.
2023-05-29 10:13:44.292: [iter 39 : loss : 0.2865 = 0.1073 + 0.1763 + 0.0029, time: 6.641342]
2023-05-29 10:13:44.451: epoch 39:	0.02401975  	0.17824097  	0.09452537  
2023-05-29 10:13:44.451: Find a better model.
2023-05-29 10:13:51.066: [iter 40 : loss : 0.2825 = 0.1038 + 0.1758 + 0.0029, time: 6.613072]
2023-05-29 10:13:51.210: epoch 40:	0.02413971  	0.17909671  	0.09523196  
2023-05-29 10:13:51.210: Find a better model.
2023-05-29 10:13:57.706: [iter 41 : loss : 0.2801 = 0.1018 + 0.1754 + 0.0030, time: 6.495008]
2023-05-29 10:13:57.861: epoch 41:	0.02428789  	0.17998107  	0.09589046  
2023-05-29 10:13:57.861: Find a better model.
2023-05-29 10:14:04.493: [iter 42 : loss : 0.2769 = 0.0990 + 0.1748 + 0.0031, time: 6.630121]
2023-05-29 10:14:04.650: epoch 42:	0.02437257  	0.18044792  	0.09631388  
2023-05-29 10:14:04.651: Find a better model.
2023-05-29 10:14:11.286: [iter 43 : loss : 0.2726 = 0.0951 + 0.1744 + 0.0031, time: 6.632949]
2023-05-29 10:14:11.444: epoch 43:	0.02443608  	0.18054365  	0.09671379  
2023-05-29 10:14:11.444: Find a better model.
2023-05-29 10:14:17.908: [iter 44 : loss : 0.2689 = 0.0918 + 0.1739 + 0.0032, time: 6.462001]
2023-05-29 10:14:18.065: epoch 44:	0.02461249  	0.18202053  	0.09746043  
2023-05-29 10:14:18.065: Find a better model.
2023-05-29 10:14:24.668: [iter 45 : loss : 0.2658 = 0.0889 + 0.1736 + 0.0033, time: 6.601005]
2023-05-29 10:14:24.823: epoch 45:	0.02468306  	0.18257780  	0.09811670  
2023-05-29 10:14:24.823: Find a better model.
2023-05-29 10:14:31.287: [iter 46 : loss : 0.2632 = 0.0867 + 0.1731 + 0.0033, time: 6.463003]
2023-05-29 10:14:31.445: epoch 46:	0.02470423  	0.18279934  	0.09847412  
2023-05-29 10:14:31.445: Find a better model.
2023-05-29 10:14:37.879: [iter 47 : loss : 0.2619 = 0.0858 + 0.1727 + 0.0034, time: 6.433225]
2023-05-29 10:14:38.036: epoch 47:	0.02482419  	0.18363900  	0.09906432  
2023-05-29 10:14:38.036: Find a better model.
2023-05-29 10:14:44.482: [iter 48 : loss : 0.2580 = 0.0821 + 0.1724 + 0.0035, time: 6.444473]
2023-05-29 10:14:44.636: epoch 48:	0.02492298  	0.18453434  	0.09955564  
2023-05-29 10:14:44.636: Find a better model.
2023-05-29 10:14:51.273: [iter 49 : loss : 0.2547 = 0.0791 + 0.1720 + 0.0035, time: 6.636003]
2023-05-29 10:14:51.429: epoch 49:	0.02490886  	0.18412247  	0.09973050  
2023-05-29 10:14:58.065: [iter 50 : loss : 0.2532 = 0.0779 + 0.1717 + 0.0036, time: 6.635204]
2023-05-29 10:14:58.210: epoch 50:	0.02500765  	0.18466312  	0.10032822  
2023-05-29 10:14:58.210: Find a better model.
2023-05-29 10:15:04.677: [iter 51 : loss : 0.2503 = 0.0752 + 0.1714 + 0.0036, time: 6.465965]
2023-05-29 10:15:04.833: epoch 51:	0.02500060  	0.18472648  	0.10063584  
2023-05-29 10:15:04.833: Find a better model.
2023-05-29 10:15:11.463: [iter 52 : loss : 0.2497 = 0.0749 + 0.1710 + 0.0037, time: 6.627433]
2023-05-29 10:15:11.619: epoch 52:	0.02517700  	0.18598363  	0.10134856  
2023-05-29 10:15:11.619: Find a better model.
2023-05-29 10:15:18.261: [iter 53 : loss : 0.2473 = 0.0728 + 0.1707 + 0.0038, time: 6.640016]
2023-05-29 10:15:18.421: epoch 53:	0.02526874  	0.18683045  	0.10181724  
2023-05-29 10:15:18.421: Find a better model.
2023-05-29 10:15:24.869: [iter 54 : loss : 0.2451 = 0.0709 + 0.1704 + 0.0038, time: 6.446033]
2023-05-29 10:15:25.025: epoch 54:	0.02531813  	0.18709393  	0.10207483  
2023-05-29 10:15:25.025: Find a better model.
2023-05-29 10:15:31.655: [iter 55 : loss : 0.2431 = 0.0691 + 0.1702 + 0.0039, time: 6.628011]
2023-05-29 10:15:31.807: epoch 55:	0.02532519  	0.18705156  	0.10219557  
2023-05-29 10:15:38.451: [iter 56 : loss : 0.2410 = 0.0672 + 0.1698 + 0.0039, time: 6.643003]
2023-05-29 10:15:38.607: epoch 56:	0.02545220  	0.18805295  	0.10284378  
2023-05-29 10:15:38.607: Find a better model.
2023-05-29 10:15:45.276: [iter 57 : loss : 0.2391 = 0.0655 + 0.1696 + 0.0040, time: 6.668168]
2023-05-29 10:15:45.437: epoch 57:	0.02554394  	0.18842538  	0.10300972  
2023-05-29 10:15:45.437: Find a better model.
2023-05-29 10:15:52.033: [iter 58 : loss : 0.2373 = 0.0639 + 0.1694 + 0.0040, time: 6.595006]
2023-05-29 10:15:52.191: epoch 58:	0.02548043  	0.18829681  	0.10308183  
2023-05-29 10:15:58.846: [iter 59 : loss : 0.2361 = 0.0630 + 0.1690 + 0.0041, time: 6.653013]
2023-05-29 10:15:59.001: epoch 59:	0.02562156  	0.18947124  	0.10358077  
2023-05-29 10:15:59.001: Find a better model.
2023-05-29 10:16:05.654: [iter 60 : loss : 0.2344 = 0.0614 + 0.1688 + 0.0041, time: 6.652020]
2023-05-29 10:16:05.808: epoch 60:	0.02573446  	0.19017640  	0.10392965  
2023-05-29 10:16:05.808: Find a better model.
2023-05-29 10:16:12.441: [iter 61 : loss : 0.2330 = 0.0602 + 0.1686 + 0.0042, time: 6.630015]
2023-05-29 10:16:12.595: epoch 61:	0.02580503  	0.19079204  	0.10435820  
2023-05-29 10:16:12.595: Find a better model.
2023-05-29 10:16:19.242: [iter 62 : loss : 0.2314 = 0.0588 + 0.1684 + 0.0043, time: 6.645072]
2023-05-29 10:16:19.400: epoch 62:	0.02593205  	0.19182459  	0.10478167  
2023-05-29 10:16:19.400: Find a better model.
2023-05-29 10:16:26.055: [iter 63 : loss : 0.2300 = 0.0576 + 0.1681 + 0.0043, time: 6.654018]
2023-05-29 10:16:26.198: epoch 63:	0.02592499  	0.19189371  	0.10494910  
2023-05-29 10:16:26.198: Find a better model.
2023-05-29 10:16:32.830: [iter 64 : loss : 0.2288 = 0.0566 + 0.1679 + 0.0044, time: 6.629347]
2023-05-29 10:16:32.986: epoch 64:	0.02593910  	0.19215515  	0.10528122  
2023-05-29 10:16:32.986: Find a better model.
2023-05-29 10:16:39.613: [iter 65 : loss : 0.2276 = 0.0555 + 0.1677 + 0.0044, time: 6.624994]
2023-05-29 10:16:39.766: epoch 65:	0.02599555  	0.19265322  	0.10565656  
2023-05-29 10:16:39.767: Find a better model.
2023-05-29 10:16:46.414: [iter 66 : loss : 0.2259 = 0.0540 + 0.1674 + 0.0045, time: 6.646014]
2023-05-29 10:16:46.568: epoch 66:	0.02606611  	0.19300090  	0.10574072  
2023-05-29 10:16:46.568: Find a better model.
2023-05-29 10:16:53.207: [iter 67 : loss : 0.2247 = 0.0529 + 0.1672 + 0.0045, time: 6.638305]
2023-05-29 10:16:53.366: epoch 67:	0.02608023  	0.19295995  	0.10592163  
2023-05-29 10:17:00.020: [iter 68 : loss : 0.2240 = 0.0524 + 0.1671 + 0.0046, time: 6.652013]
2023-05-29 10:17:00.171: epoch 68:	0.02621430  	0.19359656  	0.10632011  
2023-05-29 10:17:00.172: Find a better model.
2023-05-29 10:17:06.795: [iter 69 : loss : 0.2223 = 0.0508 + 0.1669 + 0.0046, time: 6.621949]
2023-05-29 10:17:06.949: epoch 69:	0.02622136  	0.19406603  	0.10644325  
2023-05-29 10:17:06.950: Find a better model.
2023-05-29 10:17:13.606: [iter 70 : loss : 0.2208 = 0.0494 + 0.1667 + 0.0047, time: 6.655034]
2023-05-29 10:17:13.751: epoch 70:	0.02627075  	0.19439574  	0.10669833  
2023-05-29 10:17:13.751: Find a better model.
2023-05-29 10:17:20.229: [iter 71 : loss : 0.2196 = 0.0484 + 0.1665 + 0.0047, time: 6.477001]
2023-05-29 10:17:20.391: epoch 71:	0.02632721  	0.19467905  	0.10684208  
2023-05-29 10:17:20.391: Find a better model.
2023-05-29 10:17:26.815: [iter 72 : loss : 0.2190 = 0.0478 + 0.1664 + 0.0048, time: 6.423023]
2023-05-29 10:17:26.969: epoch 72:	0.02639778  	0.19526137  	0.10706843  
2023-05-29 10:17:26.970: Find a better model.
2023-05-29 10:17:33.604: [iter 73 : loss : 0.2177 = 0.0467 + 0.1662 + 0.0048, time: 6.633008]
2023-05-29 10:17:33.761: epoch 73:	0.02641189  	0.19549032  	0.10711851  
2023-05-29 10:17:33.761: Find a better model.
2023-05-29 10:17:40.383: [iter 74 : loss : 0.2166 = 0.0457 + 0.1660 + 0.0049, time: 6.620034]
2023-05-29 10:17:40.541: epoch 74:	0.02646128  	0.19566278  	0.10750105  
2023-05-29 10:17:40.541: Find a better model.
2023-05-29 10:17:47.189: [iter 75 : loss : 0.2159 = 0.0452 + 0.1659 + 0.0049, time: 6.647053]
2023-05-29 10:17:47.346: epoch 75:	0.02654596  	0.19655427  	0.10756438  
2023-05-29 10:17:47.347: Find a better model.
2023-05-29 10:17:53.997: [iter 76 : loss : 0.2150 = 0.0444 + 0.1657 + 0.0049, time: 6.649004]
2023-05-29 10:17:54.141: epoch 76:	0.02658124  	0.19694291  	0.10773618  
2023-05-29 10:17:54.142: Find a better model.
2023-05-29 10:18:00.595: [iter 77 : loss : 0.2140 = 0.0435 + 0.1655 + 0.0050, time: 6.450334]
2023-05-29 10:18:00.737: epoch 77:	0.02659536  	0.19693758  	0.10767362  
2023-05-29 10:18:07.375: [iter 78 : loss : 0.2135 = 0.0430 + 0.1654 + 0.0050, time: 6.635940]
2023-05-29 10:18:07.521: epoch 78:	0.02667298  	0.19745006  	0.10793771  
2023-05-29 10:18:07.521: Find a better model.
2023-05-29 10:18:14.193: [iter 79 : loss : 0.2120 = 0.0417 + 0.1653 + 0.0051, time: 6.671026]
2023-05-29 10:18:14.348: epoch 79:	0.02668003  	0.19723570  	0.10796165  
2023-05-29 10:18:20.984: [iter 80 : loss : 0.2113 = 0.0410 + 0.1652 + 0.0051, time: 6.635309]
2023-05-29 10:18:21.142: epoch 80:	0.02660241  	0.19668077  	0.10794093  
2023-05-29 10:18:27.791: [iter 81 : loss : 0.2110 = 0.0408 + 0.1650 + 0.0052, time: 6.648136]
2023-05-29 10:18:27.937: epoch 81:	0.02660241  	0.19662951  	0.10788923  
2023-05-29 10:18:34.588: [iter 82 : loss : 0.2099 = 0.0398 + 0.1649 + 0.0052, time: 6.649263]
2023-05-29 10:18:34.741: epoch 82:	0.02649656  	0.19609496  	0.10785156  
2023-05-29 10:18:41.384: [iter 83 : loss : 0.2090 = 0.0390 + 0.1648 + 0.0053, time: 6.641012]
2023-05-29 10:18:41.538: epoch 83:	0.02653890  	0.19600566  	0.10790281  
2023-05-29 10:18:48.171: [iter 84 : loss : 0.2088 = 0.0389 + 0.1646 + 0.0053, time: 6.631021]
2023-05-29 10:18:48.326: epoch 84:	0.02667298  	0.19690226  	0.10819490  
2023-05-29 10:18:54.960: [iter 85 : loss : 0.2081 = 0.0382 + 0.1645 + 0.0053, time: 6.631998]
2023-05-29 10:18:55.118: epoch 85:	0.02675060  	0.19757095  	0.10846379  
2023-05-29 10:18:55.118: Find a better model.
2023-05-29 10:19:01.773: [iter 86 : loss : 0.2074 = 0.0377 + 0.1643 + 0.0054, time: 6.654209]
2023-05-29 10:19:01.927: epoch 86:	0.02669415  	0.19715470  	0.10848830  
2023-05-29 10:19:08.574: [iter 87 : loss : 0.2057 = 0.0359 + 0.1643 + 0.0054, time: 6.645052]
2023-05-29 10:19:08.730: epoch 87:	0.02686350  	0.19811502  	0.10885072  
2023-05-29 10:19:08.730: Find a better model.
2023-05-29 10:19:15.385: [iter 88 : loss : 0.2050 = 0.0354 + 0.1641 + 0.0055, time: 6.651994]
2023-05-29 10:19:15.542: epoch 88:	0.02678588  	0.19745855  	0.10858166  
2023-05-29 10:19:22.180: [iter 89 : loss : 0.2045 = 0.0349 + 0.1640 + 0.0055, time: 6.637227]
2023-05-29 10:19:22.336: epoch 89:	0.02673648  	0.19694941  	0.10849094  
2023-05-29 10:19:28.966: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.629009]
2023-05-29 10:19:29.123: epoch 90:	0.02682822  	0.19769356  	0.10869770  
2023-05-29 10:19:35.757: [iter 91 : loss : 0.2039 = 0.0346 + 0.1638 + 0.0056, time: 6.632998]
2023-05-29 10:19:35.903: epoch 91:	0.02691289  	0.19807483  	0.10884054  
2023-05-29 10:19:42.530: [iter 92 : loss : 0.2028 = 0.0334 + 0.1637 + 0.0056, time: 6.624449]
2023-05-29 10:19:42.674: epoch 92:	0.02691289  	0.19834703  	0.10895094  
2023-05-29 10:19:42.674: Find a better model.
2023-05-29 10:19:49.344: [iter 93 : loss : 0.2033 = 0.0340 + 0.1636 + 0.0057, time: 6.669106]
2023-05-29 10:19:49.502: epoch 93:	0.02688467  	0.19837846  	0.10883533  
2023-05-29 10:19:49.503: Find a better model.
2023-05-29 10:19:56.141: [iter 94 : loss : 0.2016 = 0.0324 + 0.1635 + 0.0057, time: 6.637003]
2023-05-29 10:19:56.296: epoch 94:	0.02689878  	0.19840631  	0.10900953  
2023-05-29 10:19:56.296: Find a better model.
2023-05-29 10:20:02.748: [iter 95 : loss : 0.2008 = 0.0316 + 0.1634 + 0.0058, time: 6.450145]
2023-05-29 10:20:02.893: epoch 95:	0.02692701  	0.19853988  	0.10915195  
2023-05-29 10:20:02.893: Find a better model.
2023-05-29 10:20:09.398: [iter 96 : loss : 0.2009 = 0.0318 + 0.1633 + 0.0058, time: 6.502999]
2023-05-29 10:20:09.555: epoch 96:	0.02686350  	0.19797775  	0.10893095  
2023-05-29 10:20:16.152: [iter 97 : loss : 0.1996 = 0.0306 + 0.1632 + 0.0059, time: 6.596022]
2023-05-29 10:20:16.311: epoch 97:	0.02694112  	0.19834363  	0.10928166  
2023-05-29 10:20:22.755: [iter 98 : loss : 0.1998 = 0.0308 + 0.1631 + 0.0059, time: 6.443055]
2023-05-29 10:20:22.916: epoch 98:	0.02694818  	0.19854747  	0.10942093  
2023-05-29 10:20:22.916: Find a better model.
2023-05-29 10:20:29.535: [iter 99 : loss : 0.1991 = 0.0301 + 0.1630 + 0.0059, time: 6.617935]
2023-05-29 10:20:29.693: epoch 99:	0.02703285  	0.19904999  	0.10957264  
2023-05-29 10:20:29.693: Find a better model.
2023-05-29 10:20:36.167: [iter 100 : loss : 0.1987 = 0.0298 + 0.1629 + 0.0060, time: 6.472063]
2023-05-29 10:20:36.325: epoch 100:	0.02705402  	0.19908023  	0.10961760  
2023-05-29 10:20:36.325: Find a better model.
2023-05-29 10:20:42.757: [iter 101 : loss : 0.1982 = 0.0294 + 0.1628 + 0.0060, time: 6.430003]
2023-05-29 10:20:42.912: epoch 101:	0.02705401  	0.19917580  	0.10956997  
2023-05-29 10:20:42.912: Find a better model.
2023-05-29 10:20:49.547: [iter 102 : loss : 0.1975 = 0.0287 + 0.1628 + 0.0061, time: 6.633055]
2023-05-29 10:20:49.704: epoch 102:	0.02708224  	0.19919060  	0.10958463  
2023-05-29 10:20:49.704: Find a better model.
2023-05-29 10:20:56.162: [iter 103 : loss : 0.1973 = 0.0285 + 0.1627 + 0.0061, time: 6.456995]
2023-05-29 10:20:56.317: epoch 103:	0.02707519  	0.19951224  	0.10975942  
2023-05-29 10:20:56.317: Find a better model.
2023-05-29 10:21:02.743: [iter 104 : loss : 0.1975 = 0.0288 + 0.1626 + 0.0061, time: 6.425198]
2023-05-29 10:21:02.902: epoch 104:	0.02704696  	0.19928829  	0.10972080  
2023-05-29 10:21:09.345: [iter 105 : loss : 0.1970 = 0.0283 + 0.1625 + 0.0062, time: 6.442086]
2023-05-29 10:21:09.504: epoch 105:	0.02699756  	0.19941136  	0.10974967  
2023-05-29 10:21:16.103: [iter 106 : loss : 0.1964 = 0.0278 + 0.1625 + 0.0062, time: 6.598008]
2023-05-29 10:21:16.247: epoch 106:	0.02700462  	0.19917053  	0.10977346  
2023-05-29 10:21:22.729: [iter 107 : loss : 0.1958 = 0.0271 + 0.1624 + 0.0062, time: 6.480069]
2023-05-29 10:21:22.884: epoch 107:	0.02706813  	0.19990988  	0.11013278  
2023-05-29 10:21:22.884: Find a better model.
2023-05-29 10:21:29.507: [iter 108 : loss : 0.1955 = 0.0268 + 0.1624 + 0.0063, time: 6.622015]
2023-05-29 10:21:29.663: epoch 108:	0.02701874  	0.19963068  	0.10990123  
2023-05-29 10:21:36.144: [iter 109 : loss : 0.1945 = 0.0260 + 0.1623 + 0.0063, time: 6.480348]
2023-05-29 10:21:36.289: epoch 109:	0.02705402  	0.20017423  	0.10992157  
2023-05-29 10:21:36.289: Find a better model.
2023-05-29 10:21:42.721: [iter 110 : loss : 0.1942 = 0.0256 + 0.1622 + 0.0063, time: 6.429011]
2023-05-29 10:21:42.878: epoch 110:	0.02701874  	0.19998406  	0.11001419  
2023-05-29 10:21:49.507: [iter 111 : loss : 0.1938 = 0.0254 + 0.1621 + 0.0064, time: 6.627007]
2023-05-29 10:21:49.665: epoch 111:	0.02700462  	0.19940342  	0.10989229  
2023-05-29 10:21:56.310: [iter 112 : loss : 0.1936 = 0.0252 + 0.1620 + 0.0064, time: 6.644003]
2023-05-29 10:21:56.469: epoch 112:	0.02704696  	0.19943359  	0.10994285  
2023-05-29 10:22:03.119: [iter 113 : loss : 0.1936 = 0.0252 + 0.1619 + 0.0065, time: 6.649038]
2023-05-29 10:22:03.274: epoch 113:	0.02703285  	0.19911492  	0.10981858  
2023-05-29 10:22:09.909: [iter 114 : loss : 0.1928 = 0.0245 + 0.1619 + 0.0065, time: 6.634001]
2023-05-29 10:22:10.065: epoch 114:	0.02711753  	0.19988762  	0.11002198  
2023-05-29 10:22:16.689: [iter 115 : loss : 0.1927 = 0.0244 + 0.1618 + 0.0065, time: 6.623022]
2023-05-29 10:22:16.835: epoch 115:	0.02708930  	0.19961196  	0.10995730  
2023-05-29 10:22:23.476: [iter 116 : loss : 0.1920 = 0.0237 + 0.1618 + 0.0066, time: 6.639416]
2023-05-29 10:22:23.622: epoch 116:	0.02706813  	0.19917308  	0.11002062  
2023-05-29 10:22:30.108: [iter 117 : loss : 0.1920 = 0.0237 + 0.1617 + 0.0066, time: 6.485003]
2023-05-29 10:22:30.253: epoch 117:	0.02698345  	0.19891776  	0.10990220  
2023-05-29 10:22:36.705: [iter 118 : loss : 0.1917 = 0.0235 + 0.1616 + 0.0066, time: 6.450010]
2023-05-29 10:22:36.862: epoch 118:	0.02699050  	0.19839355  	0.10982122  
2023-05-29 10:22:43.488: [iter 119 : loss : 0.1910 = 0.0228 + 0.1616 + 0.0067, time: 6.623111]
2023-05-29 10:22:43.642: epoch 119:	0.02701167  	0.19867045  	0.10980599  
2023-05-29 10:22:50.271: [iter 120 : loss : 0.1913 = 0.0231 + 0.1615 + 0.0067, time: 6.627099]
2023-05-29 10:22:50.429: epoch 120:	0.02701873  	0.19864441  	0.10990722  
2023-05-29 10:22:57.116: [iter 121 : loss : 0.1911 = 0.0229 + 0.1614 + 0.0067, time: 6.686213]
2023-05-29 10:22:57.270: epoch 121:	0.02699050  	0.19838358  	0.10990680  
2023-05-29 10:23:03.726: [iter 122 : loss : 0.1906 = 0.0224 + 0.1614 + 0.0068, time: 6.453727]
2023-05-29 10:23:03.884: epoch 122:	0.02696228  	0.19833203  	0.10984802  
2023-05-29 10:23:10.463: [iter 123 : loss : 0.1904 = 0.0223 + 0.1613 + 0.0068, time: 6.577015]
2023-05-29 10:23:10.607: epoch 123:	0.02696933  	0.19822575  	0.10978938  
2023-05-29 10:23:17.109: [iter 124 : loss : 0.1894 = 0.0213 + 0.1613 + 0.0068, time: 6.500177]
2023-05-29 10:23:17.266: epoch 124:	0.02698344  	0.19830120  	0.10995372  
2023-05-29 10:23:23.690: [iter 125 : loss : 0.1892 = 0.0211 + 0.1612 + 0.0069, time: 6.423060]
2023-05-29 10:23:23.848: epoch 125:	0.02702578  	0.19863088  	0.10998978  
2023-05-29 10:23:30.465: [iter 126 : loss : 0.1893 = 0.0213 + 0.1612 + 0.0069, time: 6.616014]
2023-05-29 10:23:30.619: epoch 126:	0.02694110  	0.19819416  	0.10996490  
2023-05-29 10:23:37.075: [iter 127 : loss : 0.1885 = 0.0204 + 0.1612 + 0.0069, time: 6.452993]
2023-05-29 10:23:37.219: epoch 127:	0.02689171  	0.19784057  	0.10993040  
2023-05-29 10:23:43.702: [iter 128 : loss : 0.1893 = 0.0213 + 0.1611 + 0.0070, time: 6.480848]
2023-05-29 10:23:43.859: epoch 128:	0.02696227  	0.19825749  	0.10994646  
2023-05-29 10:23:50.294: [iter 129 : loss : 0.1885 = 0.0205 + 0.1611 + 0.0070, time: 6.432693]
2023-05-29 10:23:50.452: epoch 129:	0.02695522  	0.19819652  	0.10993694  
2023-05-29 10:23:56.883: [iter 130 : loss : 0.1886 = 0.0206 + 0.1610 + 0.0070, time: 6.429147]
2023-05-29 10:23:57.042: epoch 130:	0.02689171  	0.19788311  	0.10984435  
2023-05-29 10:24:03.480: [iter 131 : loss : 0.1879 = 0.0199 + 0.1609 + 0.0071, time: 6.435482]
2023-05-29 10:24:03.636: epoch 131:	0.02695522  	0.19810048  	0.10989992  
2023-05-29 10:24:10.251: [iter 132 : loss : 0.1880 = 0.0200 + 0.1609 + 0.0071, time: 6.614026]
2023-05-29 10:24:10.412: epoch 132:	0.02688466  	0.19770305  	0.10983593  
2023-05-29 10:24:16.872: [iter 133 : loss : 0.1871 = 0.0191 + 0.1609 + 0.0071, time: 6.459168]
2023-05-29 10:24:17.030: epoch 133:	0.02696227  	0.19809614  	0.10995980  
2023-05-29 10:24:23.471: [iter 134 : loss : 0.1876 = 0.0197 + 0.1608 + 0.0071, time: 6.440056]
2023-05-29 10:24:23.629: epoch 134:	0.02691993  	0.19752750  	0.10980211  
2023-05-29 10:24:23.629: Early stopping is trigger at epoch: 134
2023-05-29 10:24:23.629: best_result@epoch 109:

2023-05-29 10:24:23.629: 		0.0271      	0.2002      	0.1099      
2023-05-29 10:39:51.506: my pid: 3544
2023-05-29 10:39:51.506: model: model.general_recommender.SGL
2023-05-29 10:39:51.506: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 10:39:51.506: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 10:39:55.142: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 10:40:02.400: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.258163]
2023-05-29 10:40:02.559: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-29 10:40:02.559: Find a better model.
2023-05-29 10:40:09.952: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.392044]
2023-05-29 10:40:10.129: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-29 10:40:10.129: Find a better model.
2023-05-29 10:40:17.386: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.255067]
2023-05-29 10:40:17.565: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-29 10:40:17.565: Find a better model.
2023-05-29 10:40:24.740: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.173993]
2023-05-29 10:40:24.893: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-29 10:40:24.893: Find a better model.
2023-05-29 10:40:31.983: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 7.088765]
2023-05-29 10:40:32.138: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-29 10:40:32.138: Find a better model.
2023-05-29 10:40:38.956: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 6.817005]
2023-05-29 10:40:39.109: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-29 10:40:39.109: Find a better model.
2023-05-29 10:40:45.932: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.822007]
2023-05-29 10:40:46.083: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-29 10:40:46.084: Find a better model.
2023-05-29 10:40:52.742: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.656308]
2023-05-29 10:40:52.882: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-29 10:40:52.882: Find a better model.
2023-05-29 10:40:59.549: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.663319]
2023-05-29 10:40:59.706: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-29 10:40:59.706: Find a better model.
2023-05-29 10:41:06.323: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.616037]
2023-05-29 10:41:06.465: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-29 10:41:06.465: Find a better model.
2023-05-29 10:41:13.129: [iter 11 : loss : 0.9228 = 0.6877 + 0.2351 + 0.0000, time: 6.663005]
2023-05-29 10:41:13.270: epoch 11:	0.01307517  	0.09411153  	0.04634727  
2023-05-29 10:41:13.270: Find a better model.
2023-05-29 10:41:19.920: [iter 12 : loss : 0.9204 = 0.6851 + 0.2353 + 0.0000, time: 6.648287]
2023-05-29 10:41:20.074: epoch 12:	0.01426770  	0.10294784  	0.05051097  
2023-05-29 10:41:20.074: Find a better model.
2023-05-29 10:41:26.919: [iter 13 : loss : 0.9165 = 0.6807 + 0.2357 + 0.0000, time: 6.842994]
2023-05-29 10:41:27.071: epoch 13:	0.01563665  	0.11387421  	0.05546398  
2023-05-29 10:41:27.072: Find a better model.
2023-05-29 10:41:33.930: [iter 14 : loss : 0.9099 = 0.6734 + 0.2364 + 0.0001, time: 6.856060]
2023-05-29 10:41:34.084: epoch 14:	0.01686446  	0.12371607  	0.06058269  
2023-05-29 10:41:34.084: Find a better model.
2023-05-29 10:41:40.928: [iter 15 : loss : 0.8990 = 0.6615 + 0.2374 + 0.0001, time: 6.841993]
2023-05-29 10:41:41.082: epoch 15:	0.01804993  	0.13222155  	0.06596004  
2023-05-29 10:41:41.082: Find a better model.
2023-05-29 10:41:47.903: [iter 16 : loss : 0.8815 = 0.6421 + 0.2393 + 0.0001, time: 6.820041]
2023-05-29 10:41:48.057: epoch 16:	0.01899549  	0.13880761  	0.07060266  
2023-05-29 10:41:48.057: Find a better model.
2023-05-29 10:41:54.723: [iter 17 : loss : 0.8550 = 0.6129 + 0.2420 + 0.0002, time: 6.663016]
2023-05-29 10:41:54.878: epoch 17:	0.01979995  	0.14521930  	0.07369364  
2023-05-29 10:41:54.878: Find a better model.
2023-05-29 10:42:01.556: [iter 18 : loss : 0.8183 = 0.5722 + 0.2459 + 0.0003, time: 6.677052]
2023-05-29 10:42:01.707: epoch 18:	0.02011750  	0.14799829  	0.07561638  
2023-05-29 10:42:01.707: Find a better model.
2023-05-29 10:42:08.493: [iter 19 : loss : 0.7709 = 0.5198 + 0.2507 + 0.0004, time: 6.785018]
2023-05-29 10:42:08.647: epoch 19:	0.02037858  	0.15008213  	0.07713588  
2023-05-29 10:42:08.647: Find a better model.
2023-05-29 10:42:15.308: [iter 20 : loss : 0.7199 = 0.4637 + 0.2556 + 0.0005, time: 6.660041]
2023-05-29 10:42:15.451: epoch 20:	0.02040682  	0.15037818  	0.07757227  
2023-05-29 10:42:15.451: Find a better model.
2023-05-29 10:42:22.083: [iter 21 : loss : 0.6690 = 0.4083 + 0.2600 + 0.0007, time: 6.631317]
2023-05-29 10:42:22.239: epoch 21:	0.02064674  	0.15228854  	0.07863678  
2023-05-29 10:42:22.239: Find a better model.
2023-05-29 10:42:28.880: [iter 22 : loss : 0.6243 = 0.3602 + 0.2632 + 0.0008, time: 6.639518]
2023-05-29 10:42:29.033: epoch 22:	0.02083727  	0.15354992  	0.07949636  
2023-05-29 10:42:29.033: Find a better model.
2023-05-29 10:42:35.688: [iter 23 : loss : 0.5864 = 0.3200 + 0.2654 + 0.0010, time: 6.653014]
2023-05-29 10:42:35.845: epoch 23:	0.02119009  	0.15602374  	0.08069836  
2023-05-29 10:42:35.845: Find a better model.
2023-05-29 10:42:42.488: [iter 24 : loss : 0.5559 = 0.2882 + 0.2665 + 0.0011, time: 6.641009]
2023-05-29 10:42:42.641: epoch 24:	0.02128889  	0.15685892  	0.08153878  
2023-05-29 10:42:42.641: Find a better model.
2023-05-29 10:42:49.290: [iter 25 : loss : 0.5300 = 0.2616 + 0.2671 + 0.0013, time: 6.648049]
2023-05-29 10:42:49.448: epoch 25:	0.02166288  	0.15960729  	0.08288231  
2023-05-29 10:42:49.448: Find a better model.
2023-05-29 10:42:56.093: [iter 26 : loss : 0.5096 = 0.2411 + 0.2671 + 0.0014, time: 6.643994]
2023-05-29 10:42:56.249: epoch 26:	0.02185342  	0.16130887  	0.08367607  
2023-05-29 10:42:56.249: Find a better model.
2023-05-29 10:43:02.898: [iter 27 : loss : 0.4903 = 0.2220 + 0.2668 + 0.0015, time: 6.647704]
2023-05-29 10:43:03.050: epoch 27:	0.02209334  	0.16330951  	0.08472287  
2023-05-29 10:43:03.050: Find a better model.
2023-05-29 10:43:09.662: [iter 28 : loss : 0.4744 = 0.2066 + 0.2662 + 0.0017, time: 6.611281]
2023-05-29 10:43:09.805: epoch 28:	0.02236149  	0.16524892  	0.08595698  
2023-05-29 10:43:09.805: Find a better model.
2023-05-29 10:43:16.280: [iter 29 : loss : 0.4614 = 0.1940 + 0.2656 + 0.0018, time: 6.474299]
2023-05-29 10:43:16.425: epoch 29:	0.02263668  	0.16721749  	0.08729301  
2023-05-29 10:43:16.425: Find a better model.
2023-05-29 10:43:22.880: [iter 30 : loss : 0.4479 = 0.1810 + 0.2650 + 0.0019, time: 6.454051]
2023-05-29 10:43:23.024: epoch 30:	0.02289777  	0.16927090  	0.08823260  
2023-05-29 10:43:23.024: Find a better model.
2023-05-29 10:43:29.496: [iter 31 : loss : 0.4376 = 0.1715 + 0.2641 + 0.0020, time: 6.469997]
2023-05-29 10:43:29.640: epoch 31:	0.02313064  	0.17113926  	0.08933837  
2023-05-29 10:43:29.640: Find a better model.
2023-05-29 10:43:36.077: [iter 32 : loss : 0.4271 = 0.1616 + 0.2634 + 0.0021, time: 6.435106]
2023-05-29 10:43:36.220: epoch 32:	0.02339173  	0.17321081  	0.09051806  
2023-05-29 10:43:36.220: Find a better model.
2023-05-29 10:43:42.694: [iter 33 : loss : 0.4190 = 0.1543 + 0.2625 + 0.0022, time: 6.471511]
2023-05-29 10:43:42.851: epoch 33:	0.02348345  	0.17394656  	0.09135464  
2023-05-29 10:43:42.851: Find a better model.
2023-05-29 10:43:49.466: [iter 34 : loss : 0.4108 = 0.1468 + 0.2617 + 0.0023, time: 6.613765]
2023-05-29 10:43:49.611: epoch 34:	0.02362458  	0.17503196  	0.09213932  
2023-05-29 10:43:49.611: Find a better model.
2023-05-29 10:43:56.092: [iter 35 : loss : 0.4034 = 0.1401 + 0.2609 + 0.0024, time: 6.479023]
2023-05-29 10:43:56.245: epoch 35:	0.02374454  	0.17582044  	0.09307712  
2023-05-29 10:43:56.245: Find a better model.
2023-05-29 10:44:02.668: [iter 36 : loss : 0.3969 = 0.1343 + 0.2602 + 0.0025, time: 6.422009]
2023-05-29 10:44:02.809: epoch 36:	0.02394918  	0.17751829  	0.09400745  
2023-05-29 10:44:02.809: Find a better model.
2023-05-29 10:44:09.301: [iter 37 : loss : 0.3898 = 0.1279 + 0.2594 + 0.0026, time: 6.490402]
2023-05-29 10:44:09.453: epoch 37:	0.02409736  	0.17887959  	0.09480833  
2023-05-29 10:44:09.453: Find a better model.
2023-05-29 10:44:15.881: [iter 38 : loss : 0.3854 = 0.1241 + 0.2587 + 0.0026, time: 6.425373]
2023-05-29 10:44:16.035: epoch 38:	0.02423850  	0.18015358  	0.09577529  
2023-05-29 10:44:16.035: Find a better model.
2023-05-29 10:44:22.672: [iter 39 : loss : 0.3787 = 0.1180 + 0.2580 + 0.0027, time: 6.635998]
2023-05-29 10:44:22.827: epoch 39:	0.02442196  	0.18145519  	0.09665413  
2023-05-29 10:44:22.827: Find a better model.
2023-05-29 10:44:29.266: [iter 40 : loss : 0.3734 = 0.1134 + 0.2572 + 0.0028, time: 6.438431]
2023-05-29 10:44:29.421: epoch 40:	0.02451370  	0.18158165  	0.09718434  
2023-05-29 10:44:29.421: Find a better model.
2023-05-29 10:44:35.872: [iter 41 : loss : 0.3697 = 0.1101 + 0.2567 + 0.0029, time: 6.450004]
2023-05-29 10:44:36.026: epoch 41:	0.02464778  	0.18233761  	0.09772446  
2023-05-29 10:44:36.026: Find a better model.
2023-05-29 10:44:42.652: [iter 42 : loss : 0.3651 = 0.1062 + 0.2560 + 0.0030, time: 6.625084]
2023-05-29 10:44:42.811: epoch 42:	0.02473952  	0.18298288  	0.09838484  
2023-05-29 10:44:42.811: Find a better model.
2023-05-29 10:44:49.463: [iter 43 : loss : 0.3601 = 0.1017 + 0.2554 + 0.0030, time: 6.650471]
2023-05-29 10:44:49.620: epoch 43:	0.02488770  	0.18432704  	0.09910157  
2023-05-29 10:44:49.620: Find a better model.
2023-05-29 10:44:56.092: [iter 44 : loss : 0.3556 = 0.0977 + 0.2547 + 0.0031, time: 6.470994]
2023-05-29 10:44:56.247: epoch 44:	0.02507822  	0.18588677  	0.09982639  
2023-05-29 10:44:56.247: Find a better model.
2023-05-29 10:45:02.667: [iter 45 : loss : 0.3515 = 0.0940 + 0.2543 + 0.0032, time: 6.419451]
2023-05-29 10:45:02.825: epoch 45:	0.02515584  	0.18642087  	0.10033828  
2023-05-29 10:45:02.825: Find a better model.
2023-05-29 10:45:09.267: [iter 46 : loss : 0.3483 = 0.0913 + 0.2537 + 0.0033, time: 6.440999]
2023-05-29 10:45:09.421: epoch 46:	0.02521935  	0.18701465  	0.10066313  
2023-05-29 10:45:09.421: Find a better model.
2023-05-29 10:45:15.842: [iter 47 : loss : 0.3462 = 0.0896 + 0.2532 + 0.0033, time: 6.420134]
2023-05-29 10:45:15.996: epoch 47:	0.02525463  	0.18704106  	0.10091247  
2023-05-29 10:45:15.996: Find a better model.
2023-05-29 10:45:22.454: [iter 48 : loss : 0.3417 = 0.0856 + 0.2528 + 0.0034, time: 6.457007]
2023-05-29 10:45:22.609: epoch 48:	0.02530403  	0.18767536  	0.10141196  
2023-05-29 10:45:22.609: Find a better model.
2023-05-29 10:45:29.042: [iter 49 : loss : 0.3380 = 0.0822 + 0.2523 + 0.0035, time: 6.430973]
2023-05-29 10:45:29.194: epoch 49:	0.02539576  	0.18800889  	0.10192321  
2023-05-29 10:45:29.194: Find a better model.
2023-05-29 10:45:35.636: [iter 50 : loss : 0.3358 = 0.0804 + 0.2519 + 0.0036, time: 6.440523]
2023-05-29 10:45:35.778: epoch 50:	0.02547338  	0.18860294  	0.10243494  
2023-05-29 10:45:35.778: Find a better model.
2023-05-29 10:45:42.237: [iter 51 : loss : 0.3325 = 0.0774 + 0.2515 + 0.0036, time: 6.458009]
2023-05-29 10:45:42.389: epoch 51:	0.02562157  	0.18948242  	0.10301709  
2023-05-29 10:45:42.389: Find a better model.
2023-05-29 10:45:48.847: [iter 52 : loss : 0.3312 = 0.0765 + 0.2510 + 0.0037, time: 6.457023]
2023-05-29 10:45:49.001: epoch 52:	0.02579092  	0.19067582  	0.10377309  
2023-05-29 10:45:49.001: Find a better model.
2023-05-29 10:45:55.642: [iter 53 : loss : 0.3284 = 0.0741 + 0.2506 + 0.0038, time: 6.639358]
2023-05-29 10:45:55.794: epoch 53:	0.02586148  	0.19149116  	0.10428696  
2023-05-29 10:45:55.794: Find a better model.
2023-05-29 10:46:02.232: [iter 54 : loss : 0.3258 = 0.0718 + 0.2502 + 0.0038, time: 6.437005]
2023-05-29 10:46:02.384: epoch 54:	0.02589676  	0.19195156  	0.10455631  
2023-05-29 10:46:02.384: Find a better model.
2023-05-29 10:46:08.829: [iter 55 : loss : 0.3237 = 0.0699 + 0.2499 + 0.0039, time: 6.443920]
2023-05-29 10:46:08.980: epoch 55:	0.02591793  	0.19219516  	0.10478327  
2023-05-29 10:46:08.980: Find a better model.
2023-05-29 10:46:15.601: [iter 56 : loss : 0.3210 = 0.0676 + 0.2494 + 0.0040, time: 6.620006]
2023-05-29 10:46:15.754: epoch 56:	0.02593205  	0.19196197  	0.10502896  
2023-05-29 10:46:22.423: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.667056]
2023-05-29 10:46:22.580: epoch 57:	0.02595321  	0.19218220  	0.10519829  
2023-05-29 10:46:29.205: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.624008]
2023-05-29 10:46:29.358: epoch 58:	0.02606612  	0.19308290  	0.10578318  
2023-05-29 10:46:29.358: Find a better model.
2023-05-29 10:46:35.820: [iter 59 : loss : 0.3154 = 0.0628 + 0.2484 + 0.0041, time: 6.461083]
2023-05-29 10:46:35.963: epoch 59:	0.02609434  	0.19337738  	0.10590531  
2023-05-29 10:46:35.963: Find a better model.
2023-05-29 10:46:42.617: [iter 60 : loss : 0.3135 = 0.0611 + 0.2482 + 0.0042, time: 6.653054]
2023-05-29 10:46:42.769: epoch 60:	0.02620725  	0.19395447  	0.10629762  
2023-05-29 10:46:42.769: Find a better model.
2023-05-29 10:46:49.412: [iter 61 : loss : 0.3119 = 0.0597 + 0.2479 + 0.0043, time: 6.641003]
2023-05-29 10:46:49.569: epoch 61:	0.02620725  	0.19454296  	0.10651705  
2023-05-29 10:46:49.569: Find a better model.
2023-05-29 10:46:56.020: [iter 62 : loss : 0.3101 = 0.0582 + 0.2476 + 0.0043, time: 6.449187]
2023-05-29 10:46:56.172: epoch 62:	0.02617196  	0.19414380  	0.10654917  
2023-05-29 10:47:02.640: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.466019]
2023-05-29 10:47:02.793: epoch 63:	0.02618607  	0.19401701  	0.10670833  
2023-05-29 10:47:09.204: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.409999]
2023-05-29 10:47:09.346: epoch 64:	0.02620725  	0.19436824  	0.10687846  
2023-05-29 10:47:15.806: [iter 65 : loss : 0.3057 = 0.0545 + 0.2468 + 0.0045, time: 6.459103]
2023-05-29 10:47:15.960: epoch 65:	0.02627075  	0.19462110  	0.10707077  
2023-05-29 10:47:15.960: Find a better model.
2023-05-29 10:47:22.418: [iter 66 : loss : 0.3039 = 0.0528 + 0.2465 + 0.0045, time: 6.457011]
2023-05-29 10:47:22.579: epoch 66:	0.02630604  	0.19498673  	0.10724138  
2023-05-29 10:47:22.579: Find a better model.
2023-05-29 10:47:29.008: [iter 67 : loss : 0.3024 = 0.0516 + 0.2463 + 0.0046, time: 6.427109]
2023-05-29 10:47:29.163: epoch 67:	0.02628487  	0.19462584  	0.10712864  
2023-05-29 10:47:35.779: [iter 68 : loss : 0.3017 = 0.0509 + 0.2460 + 0.0047, time: 6.615257]
2023-05-29 10:47:35.932: epoch 68:	0.02644717  	0.19577003  	0.10764769  
2023-05-29 10:47:35.932: Find a better model.
2023-05-29 10:47:42.393: [iter 69 : loss : 0.2999 = 0.0493 + 0.2459 + 0.0047, time: 6.459000]
2023-05-29 10:47:42.538: epoch 69:	0.02650362  	0.19595338  	0.10772637  
2023-05-29 10:47:42.538: Find a better model.
2023-05-29 10:47:49.026: [iter 70 : loss : 0.2984 = 0.0480 + 0.2456 + 0.0048, time: 6.485995]
2023-05-29 10:47:49.178: epoch 70:	0.02664475  	0.19702859  	0.10820810  
2023-05-29 10:47:49.178: Find a better model.
2023-05-29 10:47:55.588: [iter 71 : loss : 0.2972 = 0.0469 + 0.2454 + 0.0048, time: 6.408994]
2023-05-29 10:47:55.730: epoch 71:	0.02656713  	0.19665308  	0.10810143  
2023-05-29 10:48:02.190: [iter 72 : loss : 0.2963 = 0.0462 + 0.2452 + 0.0049, time: 6.458172]
2023-05-29 10:48:02.345: epoch 72:	0.02656007  	0.19652425  	0.10810161  
2023-05-29 10:48:08.796: [iter 73 : loss : 0.2949 = 0.0450 + 0.2450 + 0.0049, time: 6.449445]
2023-05-29 10:48:08.952: epoch 73:	0.02660241  	0.19657025  	0.10818605  
2023-05-29 10:48:15.390: [iter 74 : loss : 0.2938 = 0.0440 + 0.2448 + 0.0050, time: 6.436004]
2023-05-29 10:48:15.549: epoch 74:	0.02668002  	0.19708768  	0.10849189  
2023-05-29 10:48:15.549: Find a better model.
2023-05-29 10:48:21.980: [iter 75 : loss : 0.2931 = 0.0434 + 0.2446 + 0.0050, time: 6.430029]
2023-05-29 10:48:22.133: epoch 75:	0.02665886  	0.19705616  	0.10869642  
2023-05-29 10:48:28.596: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.462347]
2023-05-29 10:48:28.750: epoch 76:	0.02672237  	0.19759066  	0.10885058  
2023-05-29 10:48:28.750: Find a better model.
2023-05-29 10:48:35.182: [iter 77 : loss : 0.2910 = 0.0416 + 0.2442 + 0.0051, time: 6.431003]
2023-05-29 10:48:35.337: epoch 77:	0.02660241  	0.19694234  	0.10861786  
2023-05-29 10:48:41.788: [iter 78 : loss : 0.2905 = 0.0411 + 0.2442 + 0.0052, time: 6.450059]
2023-05-29 10:48:41.943: epoch 78:	0.02660946  	0.19709215  	0.10860539  
2023-05-29 10:48:48.372: [iter 79 : loss : 0.2889 = 0.0398 + 0.2439 + 0.0052, time: 6.428004]
2023-05-29 10:48:48.531: epoch 79:	0.02658829  	0.19694187  	0.10879070  
2023-05-29 10:48:54.976: [iter 80 : loss : 0.2882 = 0.0391 + 0.2438 + 0.0053, time: 6.444003]
2023-05-29 10:48:55.128: epoch 80:	0.02657419  	0.19640031  	0.10893568  
2023-05-29 10:49:01.577: [iter 81 : loss : 0.2877 = 0.0387 + 0.2436 + 0.0053, time: 6.448031]
2023-05-29 10:49:01.727: epoch 81:	0.02663063  	0.19645067  	0.10885140  
2023-05-29 10:49:08.165: [iter 82 : loss : 0.2866 = 0.0377 + 0.2435 + 0.0054, time: 6.436018]
2023-05-29 10:49:08.317: epoch 82:	0.02665180  	0.19645311  	0.10897100  
2023-05-29 10:49:14.767: [iter 83 : loss : 0.2856 = 0.0368 + 0.2434 + 0.0054, time: 6.448036]
2023-05-29 10:49:14.921: epoch 83:	0.02663768  	0.19620799  	0.10897882  
2023-05-29 10:49:21.364: [iter 84 : loss : 0.2855 = 0.0368 + 0.2432 + 0.0055, time: 6.442042]
2023-05-29 10:49:21.522: epoch 84:	0.02666592  	0.19664326  	0.10921748  
2023-05-29 10:49:27.934: [iter 85 : loss : 0.2847 = 0.0361 + 0.2431 + 0.0055, time: 6.411013]
2023-05-29 10:49:28.089: epoch 85:	0.02669414  	0.19661751  	0.10919429  
2023-05-29 10:49:34.558: [iter 86 : loss : 0.2839 = 0.0355 + 0.2429 + 0.0056, time: 6.467023]
2023-05-29 10:49:34.712: epoch 86:	0.02673648  	0.19685894  	0.10923503  
2023-05-29 10:49:41.157: [iter 87 : loss : 0.2824 = 0.0339 + 0.2428 + 0.0056, time: 6.443352]
2023-05-29 10:49:41.312: epoch 87:	0.02677176  	0.19690131  	0.10928166  
2023-05-29 10:49:47.749: [iter 88 : loss : 0.2817 = 0.0334 + 0.2426 + 0.0057, time: 6.436042]
2023-05-29 10:49:47.905: epoch 88:	0.02679293  	0.19745335  	0.10944445  
2023-05-29 10:49:54.371: [iter 89 : loss : 0.2810 = 0.0328 + 0.2425 + 0.0057, time: 6.464010]
2023-05-29 10:49:54.530: epoch 89:	0.02687055  	0.19797975  	0.10950413  
2023-05-29 10:49:54.530: Find a better model.
2023-05-29 10:50:00.917: [iter 90 : loss : 0.2813 = 0.0331 + 0.2424 + 0.0058, time: 6.386537]
2023-05-29 10:50:01.060: epoch 90:	0.02679293  	0.19731720  	0.10949855  
2023-05-29 10:50:07.661: [iter 91 : loss : 0.2805 = 0.0324 + 0.2422 + 0.0058, time: 6.599073]
2023-05-29 10:50:07.802: epoch 91:	0.02679999  	0.19708601  	0.10938798  
2023-05-29 10:50:14.160: [iter 92 : loss : 0.2794 = 0.0314 + 0.2422 + 0.0059, time: 6.356507]
2023-05-29 10:50:14.312: epoch 92:	0.02684233  	0.19765759  	0.10956241  
2023-05-29 10:50:20.735: [iter 93 : loss : 0.2797 = 0.0317 + 0.2421 + 0.0059, time: 6.422011]
2023-05-29 10:50:20.888: epoch 93:	0.02686350  	0.19753578  	0.10948608  
2023-05-29 10:50:27.337: [iter 94 : loss : 0.2782 = 0.0303 + 0.2420 + 0.0059, time: 6.448008]
2023-05-29 10:50:27.494: epoch 94:	0.02689878  	0.19771846  	0.10953841  
2023-05-29 10:50:33.923: [iter 95 : loss : 0.2774 = 0.0295 + 0.2419 + 0.0060, time: 6.427043]
2023-05-29 10:50:34.066: epoch 95:	0.02688466  	0.19732180  	0.10958642  
2023-05-29 10:50:40.531: [iter 96 : loss : 0.2774 = 0.0296 + 0.2417 + 0.0060, time: 6.463079]
2023-05-29 10:50:40.685: epoch 96:	0.02691289  	0.19755235  	0.10967118  
2023-05-29 10:50:47.123: [iter 97 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.437030]
2023-05-29 10:50:47.277: epoch 97:	0.02694111  	0.19779363  	0.10953162  
2023-05-29 10:50:53.732: [iter 98 : loss : 0.2762 = 0.0285 + 0.2416 + 0.0061, time: 6.453015]
2023-05-29 10:50:53.886: epoch 98:	0.02700462  	0.19833949  	0.10983928  
2023-05-29 10:50:53.886: Find a better model.
2023-05-29 10:51:00.335: [iter 99 : loss : 0.2755 = 0.0279 + 0.2414 + 0.0062, time: 6.448157]
2023-05-29 10:51:00.483: epoch 99:	0.02701168  	0.19829635  	0.10989334  
2023-05-29 10:51:06.918: [iter 100 : loss : 0.2752 = 0.0277 + 0.2413 + 0.0062, time: 6.432080]
2023-05-29 10:51:07.074: epoch 100:	0.02700462  	0.19829977  	0.10998259  
2023-05-29 10:51:13.523: [iter 101 : loss : 0.2746 = 0.0272 + 0.2412 + 0.0063, time: 6.448527]
2023-05-29 10:51:13.676: epoch 101:	0.02691288  	0.19764145  	0.10985564  
2023-05-29 10:51:20.121: [iter 102 : loss : 0.2740 = 0.0266 + 0.2412 + 0.0063, time: 6.443003]
2023-05-29 10:51:20.274: epoch 102:	0.02693405  	0.19770339  	0.10990576  
2023-05-29 10:51:26.708: [iter 103 : loss : 0.2738 = 0.0264 + 0.2410 + 0.0063, time: 6.432997]
2023-05-29 10:51:26.861: epoch 103:	0.02688466  	0.19739008  	0.11002707  
2023-05-29 10:51:33.330: [iter 104 : loss : 0.2739 = 0.0265 + 0.2410 + 0.0064, time: 6.467994]
2023-05-29 10:51:33.487: epoch 104:	0.02695522  	0.19784543  	0.11002113  
2023-05-29 10:51:39.913: [iter 105 : loss : 0.2734 = 0.0261 + 0.2409 + 0.0064, time: 6.425063]
2023-05-29 10:51:40.065: epoch 105:	0.02689171  	0.19759777  	0.10998744  
2023-05-29 10:51:46.510: [iter 106 : loss : 0.2729 = 0.0256 + 0.2408 + 0.0065, time: 6.444046]
2023-05-29 10:51:46.664: epoch 106:	0.02691994  	0.19774595  	0.11002041  
2023-05-29 10:51:53.108: [iter 107 : loss : 0.2723 = 0.0250 + 0.2408 + 0.0065, time: 6.443015]
2023-05-29 10:51:53.262: epoch 107:	0.02696933  	0.19810590  	0.11016320  
2023-05-29 10:51:59.689: [iter 108 : loss : 0.2719 = 0.0246 + 0.2407 + 0.0065, time: 6.426045]
2023-05-29 10:51:59.843: epoch 108:	0.02697639  	0.19847538  	0.11027089  
2023-05-29 10:51:59.843: Find a better model.
2023-05-29 10:52:06.309: [iter 109 : loss : 0.2710 = 0.0239 + 0.2406 + 0.0066, time: 6.465030]
2023-05-29 10:52:06.452: epoch 109:	0.02699050  	0.19852363  	0.11031708  
2023-05-29 10:52:06.452: Find a better model.
2023-05-29 10:52:12.874: [iter 110 : loss : 0.2708 = 0.0236 + 0.2406 + 0.0066, time: 6.421004]
2023-05-29 10:52:13.027: epoch 110:	0.02695522  	0.19829623  	0.11023346  
2023-05-29 10:52:19.500: [iter 111 : loss : 0.2704 = 0.0234 + 0.2404 + 0.0066, time: 6.471993]
2023-05-29 10:52:19.654: epoch 111:	0.02694111  	0.19824255  	0.11024582  
2023-05-29 10:52:26.300: [iter 112 : loss : 0.2701 = 0.0231 + 0.2403 + 0.0067, time: 6.643449]
2023-05-29 10:52:26.455: epoch 112:	0.02690583  	0.19783708  	0.11014584  
2023-05-29 10:52:32.900: [iter 113 : loss : 0.2701 = 0.0232 + 0.2402 + 0.0067, time: 6.444004]
2023-05-29 10:52:33.056: epoch 113:	0.02687055  	0.19748604  	0.10993706  
2023-05-29 10:52:39.700: [iter 114 : loss : 0.2694 = 0.0225 + 0.2401 + 0.0068, time: 6.642386]
2023-05-29 10:52:39.853: epoch 114:	0.02689877  	0.19760254  	0.11001158  
2023-05-29 10:52:46.471: [iter 115 : loss : 0.2692 = 0.0223 + 0.2401 + 0.0068, time: 6.616002]
2023-05-29 10:52:46.613: epoch 115:	0.02694111  	0.19801976  	0.11012223  
2023-05-29 10:52:53.292: [iter 116 : loss : 0.2686 = 0.0218 + 0.2400 + 0.0068, time: 6.678101]
2023-05-29 10:52:53.446: epoch 116:	0.02689877  	0.19744496  	0.10997940  
2023-05-29 10:53:00.101: [iter 117 : loss : 0.2686 = 0.0217 + 0.2400 + 0.0069, time: 6.654042]
2023-05-29 10:53:00.244: epoch 117:	0.02679998  	0.19664337  	0.10975356  
2023-05-29 10:53:06.685: [iter 118 : loss : 0.2682 = 0.0214 + 0.2399 + 0.0069, time: 6.439005]
2023-05-29 10:53:06.842: epoch 118:	0.02673647  	0.19623412  	0.10972169  
2023-05-29 10:53:13.461: [iter 119 : loss : 0.2677 = 0.0209 + 0.2399 + 0.0069, time: 6.616030]
2023-05-29 10:53:13.606: epoch 119:	0.02679292  	0.19636247  	0.10980969  
2023-05-29 10:53:20.098: [iter 120 : loss : 0.2678 = 0.0211 + 0.2398 + 0.0070, time: 6.490045]
2023-05-29 10:53:20.250: epoch 120:	0.02679292  	0.19607294  	0.10970521  
2023-05-29 10:53:26.675: [iter 121 : loss : 0.2676 = 0.0209 + 0.2397 + 0.0070, time: 6.424103]
2023-05-29 10:53:26.819: epoch 121:	0.02679292  	0.19594775  	0.10961810  
2023-05-29 10:53:33.472: [iter 122 : loss : 0.2672 = 0.0205 + 0.2396 + 0.0070, time: 6.651095]
2023-05-29 10:53:33.625: epoch 122:	0.02677175  	0.19586377  	0.10967153  
2023-05-29 10:53:40.247: [iter 123 : loss : 0.2670 = 0.0203 + 0.2396 + 0.0071, time: 6.618994]
2023-05-29 10:53:40.389: epoch 123:	0.02678587  	0.19594216  	0.10971393  
2023-05-29 10:53:47.056: [iter 124 : loss : 0.2660 = 0.0194 + 0.2395 + 0.0071, time: 6.665726]
2023-05-29 10:53:47.210: epoch 124:	0.02673647  	0.19554049  	0.10966277  
2023-05-29 10:53:53.667: [iter 125 : loss : 0.2659 = 0.0193 + 0.2395 + 0.0072, time: 6.456190]
2023-05-29 10:53:53.821: epoch 125:	0.02679292  	0.19595478  	0.10973856  
2023-05-29 10:54:00.447: [iter 126 : loss : 0.2661 = 0.0194 + 0.2394 + 0.0072, time: 6.624023]
2023-05-29 10:54:00.589: epoch 126:	0.02678587  	0.19582774  	0.10974334  
2023-05-29 10:54:07.243: [iter 127 : loss : 0.2653 = 0.0186 + 0.2394 + 0.0072, time: 6.653017]
2023-05-29 10:54:07.397: epoch 127:	0.02677881  	0.19617428  	0.10975894  
2023-05-29 10:54:13.894: [iter 128 : loss : 0.2658 = 0.0192 + 0.2393 + 0.0073, time: 6.495020]
2023-05-29 10:54:14.050: epoch 128:	0.02682114  	0.19619705  	0.10969151  
2023-05-29 10:54:20.660: [iter 129 : loss : 0.2652 = 0.0186 + 0.2393 + 0.0073, time: 6.609070]
2023-05-29 10:54:20.815: epoch 129:	0.02678587  	0.19584170  	0.10948177  
2023-05-29 10:54:27.446: [iter 130 : loss : 0.2653 = 0.0188 + 0.2392 + 0.0073, time: 6.627406]
2023-05-29 10:54:27.600: epoch 130:	0.02675764  	0.19557256  	0.10939007  
2023-05-29 10:54:34.254: [iter 131 : loss : 0.2646 = 0.0181 + 0.2392 + 0.0074, time: 6.653492]
2023-05-29 10:54:34.409: epoch 131:	0.02668707  	0.19477746  	0.10942054  
2023-05-29 10:54:41.016: [iter 132 : loss : 0.2646 = 0.0181 + 0.2391 + 0.0074, time: 6.606021]
2023-05-29 10:54:41.173: epoch 132:	0.02662357  	0.19430307  	0.10919792  
2023-05-29 10:54:47.830: [iter 133 : loss : 0.2639 = 0.0174 + 0.2391 + 0.0074, time: 6.655136]
2023-05-29 10:54:47.986: epoch 133:	0.02663767  	0.19446863  	0.10926393  
2023-05-29 10:54:54.457: [iter 134 : loss : 0.2643 = 0.0178 + 0.2390 + 0.0074, time: 6.470111]
2023-05-29 10:54:54.614: epoch 134:	0.02660239  	0.19397271  	0.10916216  
2023-05-29 10:54:54.614: Early stopping is trigger at epoch: 134
2023-05-29 10:54:54.614: best_result@epoch 109:

2023-05-29 10:54:54.614: 		0.0270      	0.1985      	0.1103      
2023-05-29 10:56:06.773: my pid: 13780
2023-05-29 10:56:06.773: model: model.general_recommender.SGL
2023-05-29 10:56:06.773: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 10:56:06.773: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 10:56:10.406: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 10:56:17.613: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.205095]
2023-05-29 10:56:17.768: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-29 10:56:17.769: Find a better model.
2023-05-29 10:56:25.207: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.437057]
2023-05-29 10:56:25.391: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-29 10:56:25.392: Find a better model.
2023-05-29 10:56:32.580: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.187194]
2023-05-29 10:56:32.767: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-29 10:56:32.767: Find a better model.
2023-05-29 10:56:39.991: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.222628]
2023-05-29 10:56:40.157: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-29 10:56:40.157: Find a better model.
2023-05-29 10:56:46.991: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 6.833008]
2023-05-29 10:56:47.150: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-29 10:56:47.150: Find a better model.
2023-05-29 10:56:53.971: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.819107]
2023-05-29 10:56:54.130: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-29 10:56:54.130: Find a better model.
2023-05-29 10:57:00.752: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.621024]
2023-05-29 10:57:00.898: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-29 10:57:00.898: Find a better model.
2023-05-29 10:57:07.381: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.482016]
2023-05-29 10:57:07.525: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-29 10:57:07.525: Find a better model.
2023-05-29 10:57:13.948: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.422029]
2023-05-29 10:57:14.103: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-29 10:57:20.372: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.267027]
2023-05-29 10:57:20.517: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-29 10:57:26.947: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.429005]
2023-05-29 10:57:27.104: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-29 10:57:33.563: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.458009]
2023-05-29 10:57:33.720: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-29 10:57:39.980: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.258994]
2023-05-29 10:57:40.135: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-29 10:57:40.135: Find a better model.
2023-05-29 10:57:46.533: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.397003]
2023-05-29 10:57:46.678: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-29 10:57:46.678: Find a better model.
2023-05-29 10:57:52.953: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.274085]
2023-05-29 10:57:53.107: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-29 10:57:53.107: Find a better model.
2023-05-29 10:57:59.374: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.266176]
2023-05-29 10:57:59.529: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-29 10:57:59.529: Find a better model.
2023-05-29 10:58:05.763: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.232009]
2023-05-29 10:58:05.917: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-29 10:58:05.917: Find a better model.
2023-05-29 10:58:12.344: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.425024]
2023-05-29 10:58:12.490: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-29 10:58:12.490: Find a better model.
2023-05-29 10:58:18.935: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.443014]
2023-05-29 10:58:19.088: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-29 10:58:19.088: Find a better model.
2023-05-29 10:58:25.543: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.453022]
2023-05-29 10:58:25.700: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-29 10:58:25.700: Find a better model.
2023-05-29 10:58:32.140: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.438429]
2023-05-29 10:58:32.294: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-29 10:58:32.295: Find a better model.
2023-05-29 10:58:38.738: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.441007]
2023-05-29 10:58:38.891: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-29 10:58:38.891: Find a better model.
2023-05-29 10:58:45.328: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.436014]
2023-05-29 10:58:45.471: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-29 10:58:45.471: Find a better model.
2023-05-29 10:58:51.745: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.273042]
2023-05-29 10:58:51.898: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-29 10:58:51.898: Find a better model.
2023-05-29 10:58:58.318: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.418772]
2023-05-29 10:58:58.472: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-29 10:58:58.472: Find a better model.
2023-05-29 10:59:04.754: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.280994]
2023-05-29 10:59:04.908: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-29 10:59:04.908: Find a better model.
2023-05-29 10:59:11.136: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.226994]
2023-05-29 10:59:11.292: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-29 10:59:11.292: Find a better model.
2023-05-29 10:59:17.536: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.243010]
2023-05-29 10:59:17.693: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-29 10:59:17.693: Find a better model.
2023-05-29 10:59:23.949: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.253994]
2023-05-29 10:59:24.103: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-29 10:59:24.104: Find a better model.
2023-05-29 10:59:30.322: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.216994]
2023-05-29 10:59:30.477: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-29 10:59:30.478: Find a better model.
2023-05-29 10:59:36.904: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.425254]
2023-05-29 10:59:37.059: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-29 10:59:37.059: Find a better model.
2023-05-29 10:59:43.511: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.450948]
2023-05-29 10:59:43.668: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-29 10:59:43.668: Find a better model.
2023-05-29 10:59:50.097: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.427385]
2023-05-29 10:59:50.252: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-29 10:59:50.252: Find a better model.
2023-05-29 10:59:56.533: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.279999]
2023-05-29 10:59:56.688: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-29 10:59:56.688: Find a better model.
2023-05-29 11:00:03.090: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.400994]
2023-05-29 11:00:03.233: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-29 11:00:03.234: Find a better model.
2023-05-29 11:00:09.721: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.486003]
2023-05-29 11:00:09.875: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-29 11:00:09.876: Find a better model.
2023-05-29 11:00:16.322: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.445006]
2023-05-29 11:00:16.465: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-29 11:00:16.465: Find a better model.
2023-05-29 11:00:22.900: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.433019]
2023-05-29 11:00:23.054: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-29 11:00:23.055: Find a better model.
2023-05-29 11:00:29.499: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.443030]
2023-05-29 11:00:29.654: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-29 11:00:29.655: Find a better model.
2023-05-29 11:00:36.097: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.440937]
2023-05-29 11:00:36.253: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-29 11:00:36.253: Find a better model.
2023-05-29 11:00:42.713: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.458993]
2023-05-29 11:00:42.882: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-29 11:00:42.882: Find a better model.
2023-05-29 11:00:49.306: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.422260]
2023-05-29 11:00:49.448: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-29 11:00:49.448: Find a better model.
2023-05-29 11:00:55.886: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.435386]
2023-05-29 11:00:56.042: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-29 11:01:02.478: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.434920]
2023-05-29 11:01:02.635: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-29 11:01:02.636: Find a better model.
2023-05-29 11:01:09.080: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.443014]
2023-05-29 11:01:09.235: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-29 11:01:09.235: Find a better model.
2023-05-29 11:01:15.689: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.451994]
2023-05-29 11:01:15.844: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-29 11:01:15.845: Find a better model.
2023-05-29 11:01:22.286: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.439994]
2023-05-29 11:01:22.442: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-29 11:01:22.442: Find a better model.
2023-05-29 11:01:28.863: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.419004]
2023-05-29 11:01:29.018: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-29 11:01:29.018: Find a better model.
2023-05-29 11:01:35.481: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.461336]
2023-05-29 11:01:35.640: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-29 11:01:35.640: Find a better model.
2023-05-29 11:01:42.075: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.433994]
2023-05-29 11:01:42.229: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-29 11:01:48.669: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0034, time: 6.439042]
2023-05-29 11:01:48.812: epoch 51:	0.02385745  	0.17556633  	0.09347075  
2023-05-29 11:01:48.813: Find a better model.
2023-05-29 11:01:55.283: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.469004]
2023-05-29 11:01:55.437: epoch 52:	0.02396329  	0.17615600  	0.09392820  
2023-05-29 11:01:55.438: Find a better model.
2023-05-29 11:02:01.861: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.422297]
2023-05-29 11:02:02.016: epoch 53:	0.02406913  	0.17702526  	0.09434863  
2023-05-29 11:02:02.016: Find a better model.
2023-05-29 11:02:08.469: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.451162]
2023-05-29 11:02:08.630: epoch 54:	0.02419615  	0.17792241  	0.09494144  
2023-05-29 11:02:08.630: Find a better model.
2023-05-29 11:02:15.075: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.443993]
2023-05-29 11:02:15.230: epoch 55:	0.02423849  	0.17839193  	0.09532860  
2023-05-29 11:02:15.230: Find a better model.
2023-05-29 11:02:21.672: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.439507]
2023-05-29 11:02:21.826: epoch 56:	0.02433728  	0.17909700  	0.09573369  
2023-05-29 11:02:21.826: Find a better model.
2023-05-29 11:02:28.467: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.639994]
2023-05-29 11:02:28.626: epoch 57:	0.02446430  	0.18026286  	0.09629583  
2023-05-29 11:02:28.626: Find a better model.
2023-05-29 11:02:35.059: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.429994]
2023-05-29 11:02:35.213: epoch 58:	0.02450663  	0.18062960  	0.09664251  
2023-05-29 11:02:35.213: Find a better model.
2023-05-29 11:02:41.843: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.629171]
2023-05-29 11:02:41.997: epoch 59:	0.02455603  	0.18130884  	0.09686511  
2023-05-29 11:02:41.998: Find a better model.
2023-05-29 11:02:48.463: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.462994]
2023-05-29 11:02:48.621: epoch 60:	0.02457720  	0.18123862  	0.09715549  
2023-05-29 11:02:55.059: [iter 61 : loss : 0.1636 = 0.0705 + 0.0892 + 0.0038, time: 6.436994]
2023-05-29 11:02:55.213: epoch 61:	0.02474656  	0.18253747  	0.09781680  
2023-05-29 11:02:55.213: Find a better model.
2023-05-29 11:03:01.652: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.438040]
2023-05-29 11:03:01.806: epoch 62:	0.02473244  	0.18249248  	0.09802019  
2023-05-29 11:03:08.452: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.644014]
2023-05-29 11:03:08.611: epoch 63:	0.02485240  	0.18354045  	0.09855148  
2023-05-29 11:03:08.611: Find a better model.
2023-05-29 11:03:15.044: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.431275]
2023-05-29 11:03:15.198: epoch 64:	0.02490885  	0.18378471  	0.09903330  
2023-05-29 11:03:15.199: Find a better model.
2023-05-29 11:03:21.637: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.436215]
2023-05-29 11:03:21.791: epoch 65:	0.02485945  	0.18354057  	0.09913395  
2023-05-29 11:03:28.255: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.462066]
2023-05-29 11:03:28.410: epoch 66:	0.02493708  	0.18397158  	0.09932361  
2023-05-29 11:03:28.410: Find a better model.
2023-05-29 11:03:34.837: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.426003]
2023-05-29 11:03:34.992: epoch 67:	0.02504998  	0.18468159  	0.09978308  
2023-05-29 11:03:34.992: Find a better model.
2023-05-29 11:03:41.442: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.448004]
2023-05-29 11:03:41.600: epoch 68:	0.02510642  	0.18502969  	0.10012835  
2023-05-29 11:03:41.600: Find a better model.
2023-05-29 11:03:48.026: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.425004]
2023-05-29 11:03:48.181: epoch 69:	0.02512054  	0.18508086  	0.10032206  
2023-05-29 11:03:48.181: Find a better model.
2023-05-29 11:03:54.674: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.492319]
2023-05-29 11:03:54.830: epoch 70:	0.02521933  	0.18603894  	0.10070904  
2023-05-29 11:03:54.830: Find a better model.
2023-05-29 11:04:01.425: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.594047]
2023-05-29 11:04:01.586: epoch 71:	0.02525461  	0.18614230  	0.10090048  
2023-05-29 11:04:01.586: Find a better model.
2023-05-29 11:04:08.036: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.448978]
2023-05-29 11:04:08.193: epoch 72:	0.02532518  	0.18680170  	0.10119528  
2023-05-29 11:04:08.193: Find a better model.
2023-05-29 11:04:14.643: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.448071]
2023-05-29 11:04:14.799: epoch 73:	0.02535341  	0.18726511  	0.10137676  
2023-05-29 11:04:14.799: Find a better model.
2023-05-29 11:04:21.420: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.620220]
2023-05-29 11:04:21.563: epoch 74:	0.02542397  	0.18757991  	0.10174557  
2023-05-29 11:04:21.563: Find a better model.
2023-05-29 11:04:28.031: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.467010]
2023-05-29 11:04:28.187: epoch 75:	0.02547337  	0.18816072  	0.10190730  
2023-05-29 11:04:28.188: Find a better model.
2023-05-29 11:04:34.823: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.633012]
2023-05-29 11:04:34.978: epoch 76:	0.02557922  	0.18915337  	0.10234687  
2023-05-29 11:04:34.978: Find a better model.
2023-05-29 11:04:41.419: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.440007]
2023-05-29 11:04:41.563: epoch 77:	0.02549453  	0.18842891  	0.10214259  
2023-05-29 11:04:48.025: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.459931]
2023-05-29 11:04:48.181: epoch 78:	0.02557921  	0.18915769  	0.10253035  
2023-05-29 11:04:48.181: Find a better model.
2023-05-29 11:04:54.611: [iter 79 : loss : 0.1425 = 0.0511 + 0.0869 + 0.0046, time: 6.428647]
2023-05-29 11:04:54.767: epoch 79:	0.02564978  	0.18960856  	0.10280474  
2023-05-29 11:04:54.767: Find a better model.
2023-05-29 11:05:01.195: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.426049]
2023-05-29 11:05:01.350: epoch 80:	0.02565683  	0.18977816  	0.10304097  
2023-05-29 11:05:01.350: Find a better model.
2023-05-29 11:05:07.627: [iter 81 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0046, time: 6.275334]
2023-05-29 11:05:07.780: epoch 81:	0.02568506  	0.18989682  	0.10328542  
2023-05-29 11:05:07.780: Find a better model.
2023-05-29 11:05:14.008: [iter 82 : loss : 0.1402 = 0.0490 + 0.0866 + 0.0047, time: 6.226974]
2023-05-29 11:05:14.151: epoch 82:	0.02567800  	0.18979020  	0.10337701  
2023-05-29 11:05:20.597: [iter 83 : loss : 0.1395 = 0.0483 + 0.0865 + 0.0047, time: 6.444059]
2023-05-29 11:05:20.754: epoch 83:	0.02574857  	0.19041438  	0.10361630  
2023-05-29 11:05:20.754: Find a better model.
2023-05-29 11:05:27.006: [iter 84 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 6.251032]
2023-05-29 11:05:27.148: epoch 84:	0.02564272  	0.18948308  	0.10349984  
2023-05-29 11:05:33.397: [iter 85 : loss : 0.1384 = 0.0473 + 0.0863 + 0.0048, time: 6.248197]
2023-05-29 11:05:33.542: epoch 85:	0.02574151  	0.19035104  	0.10382067  
2023-05-29 11:05:39.810: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.266008]
2023-05-29 11:05:39.963: epoch 86:	0.02583325  	0.19120090  	0.10410055  
2023-05-29 11:05:39.963: Find a better model.
2023-05-29 11:05:46.389: [iter 87 : loss : 0.1355 = 0.0445 + 0.0861 + 0.0049, time: 6.424436]
2023-05-29 11:05:46.533: epoch 87:	0.02592498  	0.19165075  	0.10435608  
2023-05-29 11:05:46.533: Find a better model.
2023-05-29 11:05:52.806: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.272106]
2023-05-29 11:05:52.961: epoch 88:	0.02598143  	0.19216737  	0.10469663  
2023-05-29 11:05:52.961: Find a better model.
2023-05-29 11:05:59.398: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.434664]
2023-05-29 11:05:59.553: epoch 89:	0.02593909  	0.19168027  	0.10474261  
2023-05-29 11:06:06.004: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.449174]
2023-05-29 11:06:06.161: epoch 90:	0.02598143  	0.19210102  	0.10495852  
2023-05-29 11:06:12.603: [iter 91 : loss : 0.1337 = 0.0429 + 0.0857 + 0.0050, time: 6.441046]
2023-05-29 11:06:12.757: epoch 91:	0.02607316  	0.19301951  	0.10521194  
2023-05-29 11:06:12.757: Find a better model.
2023-05-29 11:06:19.178: [iter 92 : loss : 0.1328 = 0.0421 + 0.0857 + 0.0051, time: 6.420430]
2023-05-29 11:06:19.330: epoch 92:	0.02606611  	0.19320604  	0.10531200  
2023-05-29 11:06:19.330: Find a better model.
2023-05-29 11:06:25.787: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.455071]
2023-05-29 11:06:25.941: epoch 93:	0.02607316  	0.19364491  	0.10542238  
2023-05-29 11:06:25.941: Find a better model.
2023-05-29 11:06:32.401: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.459009]
2023-05-29 11:06:32.555: epoch 94:	0.02604493  	0.19334863  	0.10543600  
2023-05-29 11:06:38.968: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.411010]
2023-05-29 11:06:39.125: epoch 95:	0.02602377  	0.19293091  	0.10547489  
2023-05-29 11:06:45.378: [iter 96 : loss : 0.1305 = 0.0400 + 0.0854 + 0.0052, time: 6.252008]
2023-05-29 11:06:45.521: epoch 96:	0.02607316  	0.19358504  	0.10575362  
2023-05-29 11:06:51.949: [iter 97 : loss : 0.1289 = 0.0384 + 0.0853 + 0.0052, time: 6.426382]
2023-05-29 11:06:52.091: epoch 97:	0.02608727  	0.19345793  	0.10576922  
2023-05-29 11:06:58.384: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.290009]
2023-05-29 11:06:58.538: epoch 98:	0.02606610  	0.19350217  	0.10580727  
2023-05-29 11:07:04.781: [iter 99 : loss : 0.1285 = 0.0380 + 0.0851 + 0.0053, time: 6.242091]
2023-05-29 11:07:04.937: epoch 99:	0.02612255  	0.19398789  	0.10604306  
2023-05-29 11:07:04.937: Find a better model.
2023-05-29 11:07:11.354: [iter 100 : loss : 0.1280 = 0.0376 + 0.0851 + 0.0053, time: 6.416017]
2023-05-29 11:07:11.498: epoch 100:	0.02615078  	0.19422464  	0.10611188  
2023-05-29 11:07:11.498: Find a better model.
2023-05-29 11:07:17.766: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.267004]
2023-05-29 11:07:17.911: epoch 101:	0.02622134  	0.19465888  	0.10637175  
2023-05-29 11:07:17.911: Find a better model.
2023-05-29 11:07:24.336: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.424310]
2023-05-29 11:07:24.492: epoch 102:	0.02623546  	0.19469464  	0.10644804  
2023-05-29 11:07:24.492: Find a better model.
2023-05-29 11:07:30.761: [iter 103 : loss : 0.1264 = 0.0361 + 0.0849 + 0.0055, time: 6.267004]
2023-05-29 11:07:30.913: epoch 103:	0.02622135  	0.19479854  	0.10662238  
2023-05-29 11:07:30.913: Find a better model.
2023-05-29 11:07:37.354: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.440015]
2023-05-29 11:07:37.506: epoch 104:	0.02623546  	0.19487023  	0.10676966  
2023-05-29 11:07:37.506: Find a better model.
2023-05-29 11:07:43.762: [iter 105 : loss : 0.1262 = 0.0359 + 0.0847 + 0.0055, time: 6.253001]
2023-05-29 11:07:43.915: epoch 105:	0.02619312  	0.19447325  	0.10677120  
2023-05-29 11:07:50.350: [iter 106 : loss : 0.1256 = 0.0354 + 0.0847 + 0.0056, time: 6.434006]
2023-05-29 11:07:50.505: epoch 106:	0.02616490  	0.19423872  	0.10656431  
2023-05-29 11:07:56.774: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.268385]
2023-05-29 11:07:56.926: epoch 107:	0.02622135  	0.19466639  	0.10668222  
2023-05-29 11:08:03.153: [iter 108 : loss : 0.1245 = 0.0343 + 0.0846 + 0.0056, time: 6.225005]
2023-05-29 11:08:03.307: epoch 108:	0.02624957  	0.19508272  	0.10680859  
2023-05-29 11:08:03.307: Find a better model.
2023-05-29 11:08:09.554: [iter 109 : loss : 0.1231 = 0.0329 + 0.0845 + 0.0057, time: 6.244994]
2023-05-29 11:08:09.710: epoch 109:	0.02626369  	0.19530113  	0.10692968  
2023-05-29 11:08:09.710: Find a better model.
2023-05-29 11:08:15.948: [iter 110 : loss : 0.1226 = 0.0324 + 0.0845 + 0.0057, time: 6.235488]
2023-05-29 11:08:16.101: epoch 110:	0.02632720  	0.19582899  	0.10706321  
2023-05-29 11:08:16.102: Find a better model.
2023-05-29 11:08:22.543: [iter 111 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0057, time: 6.440034]
2023-05-29 11:08:22.701: epoch 111:	0.02634837  	0.19601567  	0.10724574  
2023-05-29 11:08:22.701: Find a better model.
2023-05-29 11:08:29.138: [iter 112 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0058, time: 6.435465]
2023-05-29 11:08:29.292: epoch 112:	0.02635542  	0.19584881  	0.10718046  
2023-05-29 11:08:35.738: [iter 113 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 6.445017]
2023-05-29 11:08:35.893: epoch 113:	0.02632720  	0.19564304  	0.10713208  
2023-05-29 11:08:42.347: [iter 114 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0058, time: 6.452004]
2023-05-29 11:08:42.504: epoch 114:	0.02636248  	0.19556339  	0.10719226  
2023-05-29 11:08:48.929: [iter 115 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 6.423059]
2023-05-29 11:08:49.073: epoch 115:	0.02637660  	0.19602795  	0.10714391  
2023-05-29 11:08:49.073: Find a better model.
2023-05-29 11:08:55.536: [iter 116 : loss : 0.1203 = 0.0304 + 0.0841 + 0.0059, time: 6.462284]
2023-05-29 11:08:55.680: epoch 116:	0.02639071  	0.19610101  	0.10713025  
2023-05-29 11:08:55.680: Find a better model.
2023-05-29 11:09:02.136: [iter 117 : loss : 0.1202 = 0.0302 + 0.0840 + 0.0059, time: 6.454866]
2023-05-29 11:09:02.290: epoch 117:	0.02646833  	0.19672781  	0.10738301  
2023-05-29 11:09:02.290: Find a better model.
2023-05-29 11:09:08.742: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.451027]
2023-05-29 11:09:08.897: epoch 118:	0.02653184  	0.19709201  	0.10759106  
2023-05-29 11:09:08.897: Find a better model.
2023-05-29 11:09:15.345: [iter 119 : loss : 0.1191 = 0.0292 + 0.0839 + 0.0060, time: 6.446155]
2023-05-29 11:09:15.500: epoch 119:	0.02656712  	0.19699970  	0.10768977  
2023-05-29 11:09:21.919: [iter 120 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 6.418043]
2023-05-29 11:09:22.073: epoch 120:	0.02646127  	0.19590941  	0.10737159  
2023-05-29 11:09:28.531: [iter 121 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 6.457129]
2023-05-29 11:09:28.691: epoch 121:	0.02645421  	0.19603920  	0.10750698  
2023-05-29 11:09:35.139: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.447046]
2023-05-29 11:09:35.292: epoch 122:	0.02644716  	0.19606395  	0.10759328  
2023-05-29 11:09:41.719: [iter 123 : loss : 0.1184 = 0.0285 + 0.0837 + 0.0061, time: 6.425020]
2023-05-29 11:09:41.874: epoch 123:	0.02641188  	0.19575951  	0.10748030  
2023-05-29 11:09:48.313: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.438002]
2023-05-29 11:09:48.469: epoch 124:	0.02646833  	0.19610192  	0.10753966  
2023-05-29 11:09:54.903: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.433021]
2023-05-29 11:09:55.057: epoch 125:	0.02651773  	0.19686589  	0.10772527  
2023-05-29 11:10:01.531: [iter 126 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0062, time: 6.473024]
2023-05-29 11:10:01.689: epoch 126:	0.02650362  	0.19636890  	0.10771660  
2023-05-29 11:10:08.132: [iter 127 : loss : 0.1162 = 0.0264 + 0.0835 + 0.0062, time: 6.440994]
2023-05-29 11:10:08.285: epoch 127:	0.02643305  	0.19600880  	0.10764297  
2023-05-29 11:10:14.721: [iter 128 : loss : 0.1171 = 0.0274 + 0.0835 + 0.0063, time: 6.435030]
2023-05-29 11:10:14.874: epoch 128:	0.02650361  	0.19580962  	0.10752877  
2023-05-29 11:10:21.297: [iter 129 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 6.421020]
2023-05-29 11:10:21.441: epoch 129:	0.02650361  	0.19617674  	0.10771418  
2023-05-29 11:10:27.902: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.460012]
2023-05-29 11:10:28.057: epoch 130:	0.02646127  	0.19573405  	0.10771380  
2023-05-29 11:10:34.499: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 6.440481]
2023-05-29 11:10:34.659: epoch 131:	0.02647538  	0.19601202  	0.10773487  
2023-05-29 11:10:41.097: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.436002]
2023-05-29 11:10:41.254: epoch 132:	0.02642599  	0.19572522  	0.10773572  
2023-05-29 11:10:47.714: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.459054]
2023-05-29 11:10:47.869: epoch 133:	0.02636953  	0.19522797  	0.10770104  
2023-05-29 11:10:54.308: [iter 134 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 6.438050]
2023-05-29 11:10:54.463: epoch 134:	0.02635542  	0.19488984  	0.10760802  
2023-05-29 11:11:00.876: [iter 135 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0065, time: 6.412017]
2023-05-29 11:11:01.020: epoch 135:	0.02641187  	0.19544327  	0.10776975  
2023-05-29 11:11:07.292: [iter 136 : loss : 0.1145 = 0.0249 + 0.0832 + 0.0065, time: 6.271019]
2023-05-29 11:11:07.436: epoch 136:	0.02642599  	0.19562320  	0.10778321  
2023-05-29 11:11:13.892: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.455031]
2023-05-29 11:11:14.049: epoch 137:	0.02644010  	0.19574188  	0.10781500  
2023-05-29 11:11:20.472: [iter 138 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.422001]
2023-05-29 11:11:20.636: epoch 138:	0.02644715  	0.19596457  	0.10791906  
2023-05-29 11:11:27.084: [iter 139 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 6.446590]
2023-05-29 11:11:27.241: epoch 139:	0.02644715  	0.19580023  	0.10789448  
2023-05-29 11:11:33.681: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.439484]
2023-05-29 11:11:33.826: epoch 140:	0.02644010  	0.19568200  	0.10790733  
2023-05-29 11:11:40.300: [iter 141 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 6.473111]
2023-05-29 11:11:40.457: epoch 141:	0.02643304  	0.19575962  	0.10789756  
2023-05-29 11:11:46.876: [iter 142 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0067, time: 6.417110]
2023-05-29 11:11:47.032: epoch 142:	0.02639776  	0.19582146  	0.10797978  
2023-05-29 11:11:53.455: [iter 143 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 6.422018]
2023-05-29 11:11:53.614: epoch 143:	0.02639070  	0.19575901  	0.10819841  
2023-05-29 11:11:53.614: Early stopping is trigger at epoch: 143
2023-05-29 11:11:53.614: best_result@epoch 118:

2023-05-29 11:11:53.614: 		0.0265      	0.1971      	0.1076      
2023-05-29 11:13:38.607: my pid: 936
2023-05-29 11:13:38.607: model: model.general_recommender.SGL
2023-05-29 11:13:38.607: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 11:13:38.607: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 11:13:42.254: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 11:13:49.647: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.393075]
2023-05-29 11:13:49.803: epoch 1:	0.00226503  	0.01572687  	0.00760122  
2023-05-29 11:13:49.803: Find a better model.
2023-05-29 11:13:57.050: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.246462]
2023-05-29 11:13:57.258: epoch 2:	0.00454415  	0.03270170  	0.01585085  
2023-05-29 11:13:57.258: Find a better model.
2023-05-29 11:14:04.612: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.352423]
2023-05-29 11:14:04.797: epoch 3:	0.00754298  	0.05344307  	0.02547374  
2023-05-29 11:14:04.797: Find a better model.
2023-05-29 11:14:12.017: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.219027]
2023-05-29 11:14:12.187: epoch 4:	0.01098645  	0.07754456  	0.03734705  
2023-05-29 11:14:12.187: Find a better model.
2023-05-29 11:14:19.210: [iter 5 : loss : 0.7686 = 0.6892 + 0.0794 + 0.0000, time: 7.022113]
2023-05-29 11:14:19.359: epoch 5:	0.01452173  	0.10428132  	0.05020696  
2023-05-29 11:14:19.359: Find a better model.
2023-05-29 11:14:26.218: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.858421]
2023-05-29 11:14:26.376: epoch 6:	0.01706909  	0.12248143  	0.06102670  
2023-05-29 11:14:26.376: Find a better model.
2023-05-29 11:14:33.018: [iter 7 : loss : 0.7519 = 0.6705 + 0.0813 + 0.0001, time: 6.641010]
2023-05-29 11:14:33.175: epoch 7:	0.01856506  	0.13559972  	0.06763458  
2023-05-29 11:14:33.176: Find a better model.
2023-05-29 11:14:39.822: [iter 8 : loss : 0.7244 = 0.6398 + 0.0844 + 0.0001, time: 6.644003]
2023-05-29 11:14:39.981: epoch 8:	0.01879087  	0.13828135  	0.06887886  
2023-05-29 11:14:39.981: Find a better model.
2023-05-29 11:14:46.412: [iter 9 : loss : 0.6721 = 0.5825 + 0.0894 + 0.0002, time: 6.430024]
2023-05-29 11:14:46.566: epoch 9:	0.01858622  	0.13719133  	0.06838094  
2023-05-29 11:14:52.995: [iter 10 : loss : 0.6005 = 0.5056 + 0.0945 + 0.0003, time: 6.427999]
2023-05-29 11:14:53.152: epoch 10:	0.01860034  	0.13758810  	0.06819742  
2023-05-29 11:14:59.418: [iter 11 : loss : 0.5288 = 0.4299 + 0.0985 + 0.0005, time: 6.265002]
2023-05-29 11:14:59.574: epoch 11:	0.01855095  	0.13752784  	0.06846900  
2023-05-29 11:15:05.985: [iter 12 : loss : 0.4712 = 0.3699 + 0.1007 + 0.0006, time: 6.410162]
2023-05-29 11:15:06.127: epoch 12:	0.01853684  	0.13781577  	0.06882338  
2023-05-29 11:15:12.412: [iter 13 : loss : 0.4300 = 0.3273 + 0.1018 + 0.0008, time: 6.284014]
2023-05-29 11:15:12.555: epoch 13:	0.01868503  	0.13857643  	0.06953112  
2023-05-29 11:15:12.555: Find a better model.
2023-05-29 11:15:18.980: [iter 14 : loss : 0.3981 = 0.2948 + 0.1024 + 0.0009, time: 6.424014]
2023-05-29 11:15:19.122: epoch 14:	0.01891789  	0.14009659  	0.07059973  
2023-05-29 11:15:19.122: Find a better model.
2023-05-29 11:15:25.406: [iter 15 : loss : 0.3756 = 0.2721 + 0.1025 + 0.0010, time: 6.283115]
2023-05-29 11:15:25.552: epoch 15:	0.01913664  	0.14176439  	0.07140072  
2023-05-29 11:15:25.552: Find a better model.
2023-05-29 11:15:31.977: [iter 16 : loss : 0.3560 = 0.2525 + 0.1023 + 0.0012, time: 6.423009]
2023-05-29 11:15:32.131: epoch 16:	0.01936245  	0.14312100  	0.07239519  
2023-05-29 11:15:32.132: Find a better model.
2023-05-29 11:15:38.607: [iter 17 : loss : 0.3413 = 0.2380 + 0.1020 + 0.0013, time: 6.473000]
2023-05-29 11:15:38.748: epoch 17:	0.01946125  	0.14387205  	0.07281718  
2023-05-29 11:15:38.748: Find a better model.
2023-05-29 11:15:45.008: [iter 18 : loss : 0.3273 = 0.2241 + 0.1018 + 0.0014, time: 6.258039]
2023-05-29 11:15:45.162: epoch 18:	0.01963766  	0.14506000  	0.07355534  
2023-05-29 11:15:45.162: Find a better model.
2023-05-29 11:15:51.586: [iter 19 : loss : 0.3141 = 0.2113 + 0.1014 + 0.0015, time: 6.422994]
2023-05-29 11:15:51.740: epoch 19:	0.01979996  	0.14604256  	0.07434349  
2023-05-29 11:15:51.740: Find a better model.
2023-05-29 11:15:57.995: [iter 20 : loss : 0.3051 = 0.2026 + 0.1010 + 0.0015, time: 6.253003]
2023-05-29 11:15:58.141: epoch 20:	0.02013162  	0.14855796  	0.07522670  
2023-05-29 11:15:58.141: Find a better model.
2023-05-29 11:16:04.387: [iter 21 : loss : 0.2960 = 0.1939 + 0.1006 + 0.0016, time: 6.245086]
2023-05-29 11:16:04.543: epoch 21:	0.02027981  	0.14953384  	0.07610034  
2023-05-29 11:16:04.543: Find a better model.
2023-05-29 11:16:10.977: [iter 22 : loss : 0.2882 = 0.1863 + 0.1001 + 0.0017, time: 6.431013]
2023-05-29 11:16:11.131: epoch 22:	0.02037155  	0.15028700  	0.07660060  
2023-05-29 11:16:11.131: Find a better model.
2023-05-29 11:16:17.578: [iter 23 : loss : 0.2802 = 0.1786 + 0.0998 + 0.0018, time: 6.446371]
2023-05-29 11:16:17.733: epoch 23:	0.02066791  	0.15210135  	0.07757701  
2023-05-29 11:16:17.733: Find a better model.
2023-05-29 11:16:24.171: [iter 24 : loss : 0.2740 = 0.1729 + 0.0993 + 0.0018, time: 6.435031]
2023-05-29 11:16:24.315: epoch 24:	0.02081610  	0.15320855  	0.07825325  
2023-05-29 11:16:24.315: Find a better model.
2023-05-29 11:16:30.767: [iter 25 : loss : 0.2674 = 0.1665 + 0.0989 + 0.0019, time: 6.450132]
2023-05-29 11:16:30.928: epoch 25:	0.02099957  	0.15485251  	0.07900450  
2023-05-29 11:16:30.928: Find a better model.
2023-05-29 11:16:37.370: [iter 26 : loss : 0.2640 = 0.1636 + 0.0985 + 0.0020, time: 6.441001]
2023-05-29 11:16:37.527: epoch 26:	0.02116892  	0.15594651  	0.07967677  
2023-05-29 11:16:37.527: Find a better model.
2023-05-29 11:16:43.954: [iter 27 : loss : 0.2564 = 0.1563 + 0.0980 + 0.0021, time: 6.425131]
2023-05-29 11:16:44.111: epoch 27:	0.02131006  	0.15636247  	0.08016745  
2023-05-29 11:16:44.111: Find a better model.
2023-05-29 11:16:50.556: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.444007]
2023-05-29 11:16:50.711: epoch 28:	0.02155704  	0.15855406  	0.08120185  
2023-05-29 11:16:50.711: Find a better model.
2023-05-29 11:16:57.168: [iter 29 : loss : 0.2475 = 0.1481 + 0.0973 + 0.0022, time: 6.455994]
2023-05-29 11:16:57.322: epoch 29:	0.02178285  	0.16028748  	0.08201563  
2023-05-29 11:16:57.323: Find a better model.
2023-05-29 11:17:03.770: [iter 30 : loss : 0.2409 = 0.1418 + 0.0969 + 0.0022, time: 6.446047]
2023-05-29 11:17:03.932: epoch 30:	0.02200160  	0.16168471  	0.08273653  
2023-05-29 11:17:03.932: Find a better model.
2023-05-29 11:17:10.368: [iter 31 : loss : 0.2376 = 0.1388 + 0.0965 + 0.0023, time: 6.435015]
2023-05-29 11:17:10.526: epoch 31:	0.02208628  	0.16282843  	0.08343898  
2023-05-29 11:17:10.526: Find a better model.
2023-05-29 11:17:16.981: [iter 32 : loss : 0.2321 = 0.1336 + 0.0962 + 0.0024, time: 6.454081]
2023-05-29 11:17:17.136: epoch 32:	0.02229091  	0.16410680  	0.08419208  
2023-05-29 11:17:17.136: Find a better model.
2023-05-29 11:17:23.582: [iter 33 : loss : 0.2297 = 0.1314 + 0.0958 + 0.0024, time: 6.444007]
2023-05-29 11:17:23.735: epoch 33:	0.02237558  	0.16519101  	0.08473688  
2023-05-29 11:17:23.735: Find a better model.
2023-05-29 11:17:30.357: [iter 34 : loss : 0.2255 = 0.1276 + 0.0955 + 0.0025, time: 6.620003]
2023-05-29 11:17:30.513: epoch 34:	0.02245321  	0.16589856  	0.08522991  
2023-05-29 11:17:30.513: Find a better model.
2023-05-29 11:17:36.980: [iter 35 : loss : 0.2221 = 0.1244 + 0.0952 + 0.0025, time: 6.466525]
2023-05-29 11:17:37.135: epoch 35:	0.02255905  	0.16636525  	0.08580417  
2023-05-29 11:17:37.135: Find a better model.
2023-05-29 11:17:43.760: [iter 36 : loss : 0.2188 = 0.1214 + 0.0949 + 0.0026, time: 6.623657]
2023-05-29 11:17:43.919: epoch 36:	0.02260139  	0.16671252  	0.08641285  
2023-05-29 11:17:43.919: Find a better model.
2023-05-29 11:17:50.348: [iter 37 : loss : 0.2149 = 0.1178 + 0.0945 + 0.0026, time: 6.426016]
2023-05-29 11:17:50.502: epoch 37:	0.02269312  	0.16723008  	0.08699051  
2023-05-29 11:17:50.502: Find a better model.
2023-05-29 11:17:57.131: [iter 38 : loss : 0.2137 = 0.1167 + 0.0942 + 0.0027, time: 6.627086]
2023-05-29 11:17:57.286: epoch 38:	0.02274957  	0.16768724  	0.08746624  
2023-05-29 11:17:57.286: Find a better model.
2023-05-29 11:18:03.758: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.470032]
2023-05-29 11:18:03.914: epoch 39:	0.02291187  	0.16861948  	0.08818927  
2023-05-29 11:18:03.914: Find a better model.
2023-05-29 11:18:10.348: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.433076]
2023-05-29 11:18:10.502: epoch 40:	0.02297537  	0.16949230  	0.08860158  
2023-05-29 11:18:10.503: Find a better model.
2023-05-29 11:18:17.134: [iter 41 : loss : 0.2043 = 0.1081 + 0.0934 + 0.0029, time: 6.629987]
2023-05-29 11:18:17.293: epoch 41:	0.02304595  	0.17016615  	0.08909705  
2023-05-29 11:18:17.293: Find a better model.
2023-05-29 11:18:23.948: [iter 42 : loss : 0.2021 = 0.1061 + 0.0931 + 0.0029, time: 6.653465]
2023-05-29 11:18:24.102: epoch 42:	0.02317296  	0.17134044  	0.08978567  
2023-05-29 11:18:24.103: Find a better model.
2023-05-29 11:18:30.741: [iter 43 : loss : 0.1983 = 0.1025 + 0.0929 + 0.0030, time: 6.637039]
2023-05-29 11:18:30.895: epoch 43:	0.02320119  	0.17132421  	0.09009159  
2023-05-29 11:18:37.357: [iter 44 : loss : 0.1948 = 0.0993 + 0.0926 + 0.0030, time: 6.461055]
2023-05-29 11:18:37.512: epoch 44:	0.02323647  	0.17145844  	0.09045307  
2023-05-29 11:18:37.512: Find a better model.
2023-05-29 11:18:44.116: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.602014]
2023-05-29 11:18:44.270: epoch 45:	0.02339171  	0.17246050  	0.09109712  
2023-05-29 11:18:44.270: Find a better model.
2023-05-29 11:18:50.738: [iter 46 : loss : 0.1903 = 0.0951 + 0.0921 + 0.0031, time: 6.467006]
2023-05-29 11:18:50.894: epoch 46:	0.02353990  	0.17357495  	0.09184428  
2023-05-29 11:18:50.894: Find a better model.
2023-05-29 11:18:57.327: [iter 47 : loss : 0.1897 = 0.0947 + 0.0918 + 0.0032, time: 6.431963]
2023-05-29 11:18:57.484: epoch 47:	0.02365986  	0.17440261  	0.09232471  
2023-05-29 11:18:57.484: Find a better model.
2023-05-29 11:19:03.938: [iter 48 : loss : 0.1859 = 0.0910 + 0.0916 + 0.0032, time: 6.453011]
2023-05-29 11:19:04.094: epoch 48:	0.02375159  	0.17475082  	0.09285174  
2023-05-29 11:19:04.094: Find a better model.
2023-05-29 11:19:10.733: [iter 49 : loss : 0.1827 = 0.0880 + 0.0914 + 0.0033, time: 6.637261]
2023-05-29 11:19:10.890: epoch 49:	0.02383627  	0.17515925  	0.09294965  
2023-05-29 11:19:10.890: Find a better model.
2023-05-29 11:19:17.331: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.439999]
2023-05-29 11:19:17.485: epoch 50:	0.02382216  	0.17514339  	0.09322391  
2023-05-29 11:19:24.127: [iter 51 : loss : 0.1789 = 0.0845 + 0.0910 + 0.0034, time: 6.639993]
2023-05-29 11:19:24.284: epoch 51:	0.02385745  	0.17556633  	0.09347075  
2023-05-29 11:19:24.284: Find a better model.
2023-05-29 11:19:30.898: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.612993]
2023-05-29 11:19:31.043: epoch 52:	0.02396329  	0.17615600  	0.09392820  
2023-05-29 11:19:31.044: Find a better model.
2023-05-29 11:19:37.714: [iter 53 : loss : 0.1769 = 0.0828 + 0.0906 + 0.0034, time: 6.668030]
2023-05-29 11:19:37.869: epoch 53:	0.02406913  	0.17702526  	0.09434863  
2023-05-29 11:19:37.870: Find a better model.
2023-05-29 11:19:44.304: [iter 54 : loss : 0.1750 = 0.0811 + 0.0904 + 0.0035, time: 6.432994]
2023-05-29 11:19:44.446: epoch 54:	0.02419615  	0.17792241  	0.09494144  
2023-05-29 11:19:44.446: Find a better model.
2023-05-29 11:19:50.906: [iter 55 : loss : 0.1730 = 0.0793 + 0.0902 + 0.0035, time: 6.459994]
2023-05-29 11:19:51.050: epoch 55:	0.02423849  	0.17839193  	0.09532860  
2023-05-29 11:19:51.050: Find a better model.
2023-05-29 11:19:57.700: [iter 56 : loss : 0.1711 = 0.0775 + 0.0900 + 0.0036, time: 6.648018]
2023-05-29 11:19:57.856: epoch 56:	0.02433728  	0.17909700  	0.09573369  
2023-05-29 11:19:57.856: Find a better model.
2023-05-29 11:20:04.309: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.452022]
2023-05-29 11:20:04.466: epoch 57:	0.02446430  	0.18026286  	0.09629583  
2023-05-29 11:20:04.467: Find a better model.
2023-05-29 11:20:11.088: [iter 58 : loss : 0.1675 = 0.0741 + 0.0897 + 0.0037, time: 6.620030]
2023-05-29 11:20:11.243: epoch 58:	0.02450663  	0.18062960  	0.09664251  
2023-05-29 11:20:11.243: Find a better model.
2023-05-29 11:20:17.875: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.631004]
2023-05-29 11:20:18.029: epoch 59:	0.02455603  	0.18130884  	0.09686511  
2023-05-29 11:20:18.029: Find a better model.
2023-05-29 11:20:24.712: [iter 60 : loss : 0.1649 = 0.0718 + 0.0894 + 0.0038, time: 6.682101]
2023-05-29 11:20:24.869: epoch 60:	0.02457720  	0.18123862  	0.09715549  
2023-05-29 11:20:31.481: [iter 61 : loss : 0.1636 = 0.0705 + 0.0892 + 0.0038, time: 6.611004]
2023-05-29 11:20:31.625: epoch 61:	0.02474656  	0.18253747  	0.09781680  
2023-05-29 11:20:31.625: Find a better model.
2023-05-29 11:20:38.272: [iter 62 : loss : 0.1622 = 0.0693 + 0.0891 + 0.0039, time: 6.645117]
2023-05-29 11:20:38.427: epoch 62:	0.02473244  	0.18249248  	0.09802019  
2023-05-29 11:20:45.086: [iter 63 : loss : 0.1608 = 0.0680 + 0.0889 + 0.0039, time: 6.657079]
2023-05-29 11:20:45.242: epoch 63:	0.02485240  	0.18354045  	0.09855148  
2023-05-29 11:20:45.242: Find a better model.
2023-05-29 11:20:51.880: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.637032]
2023-05-29 11:20:52.040: epoch 64:	0.02490885  	0.18378471  	0.09903330  
2023-05-29 11:20:52.041: Find a better model.
2023-05-29 11:20:58.700: [iter 65 : loss : 0.1585 = 0.0659 + 0.0886 + 0.0040, time: 6.658026]
2023-05-29 11:20:58.853: epoch 65:	0.02485945  	0.18354057  	0.09913395  
2023-05-29 11:21:05.279: [iter 66 : loss : 0.1568 = 0.0644 + 0.0884 + 0.0040, time: 6.424189]
2023-05-29 11:21:05.433: epoch 66:	0.02493708  	0.18397158  	0.09932361  
2023-05-29 11:21:05.433: Find a better model.
2023-05-29 11:21:12.063: [iter 67 : loss : 0.1556 = 0.0632 + 0.0883 + 0.0041, time: 6.629092]
2023-05-29 11:21:12.221: epoch 67:	0.02504998  	0.18468159  	0.09978308  
2023-05-29 11:21:12.222: Find a better model.
2023-05-29 11:21:18.863: [iter 68 : loss : 0.1552 = 0.0629 + 0.0881 + 0.0041, time: 6.639994]
2023-05-29 11:21:19.020: epoch 68:	0.02510642  	0.18502969  	0.10012835  
2023-05-29 11:21:19.020: Find a better model.
2023-05-29 11:21:25.649: [iter 69 : loss : 0.1533 = 0.0611 + 0.0880 + 0.0042, time: 6.628130]
2023-05-29 11:21:25.804: epoch 69:	0.02512054  	0.18508086  	0.10032206  
2023-05-29 11:21:25.805: Find a better model.
2023-05-29 11:21:32.264: [iter 70 : loss : 0.1518 = 0.0597 + 0.0879 + 0.0042, time: 6.458318]
2023-05-29 11:21:32.415: epoch 70:	0.02521933  	0.18603894  	0.10070904  
2023-05-29 11:21:32.415: Find a better model.
2023-05-29 11:21:38.875: [iter 71 : loss : 0.1502 = 0.0582 + 0.0878 + 0.0042, time: 6.459006]
2023-05-29 11:21:39.034: epoch 71:	0.02525461  	0.18614230  	0.10090048  
2023-05-29 11:21:39.034: Find a better model.
2023-05-29 11:21:45.667: [iter 72 : loss : 0.1498 = 0.0579 + 0.0877 + 0.0043, time: 6.630631]
2023-05-29 11:21:45.820: epoch 72:	0.02532518  	0.18680170  	0.10119528  
2023-05-29 11:21:45.820: Find a better model.
2023-05-29 11:21:52.258: [iter 73 : loss : 0.1486 = 0.0568 + 0.0875 + 0.0043, time: 6.436003]
2023-05-29 11:21:52.402: epoch 73:	0.02535341  	0.18726511  	0.10137676  
2023-05-29 11:21:52.402: Find a better model.
2023-05-29 11:21:58.865: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.461004]
2023-05-29 11:21:59.021: epoch 74:	0.02542397  	0.18757991  	0.10174557  
2023-05-29 11:21:59.021: Find a better model.
2023-05-29 11:22:05.656: [iter 75 : loss : 0.1469 = 0.0551 + 0.0873 + 0.0044, time: 6.634026]
2023-05-29 11:22:05.814: epoch 75:	0.02547337  	0.18816072  	0.10190730  
2023-05-29 11:22:05.814: Find a better model.
2023-05-29 11:22:12.268: [iter 76 : loss : 0.1456 = 0.0540 + 0.0872 + 0.0044, time: 6.453550]
2023-05-29 11:22:12.425: epoch 76:	0.02557922  	0.18915337  	0.10234687  
2023-05-29 11:22:12.425: Find a better model.
2023-05-29 11:22:18.857: [iter 77 : loss : 0.1449 = 0.0533 + 0.0871 + 0.0045, time: 6.430994]
2023-05-29 11:22:19.012: epoch 77:	0.02549453  	0.18842891  	0.10214259  
2023-05-29 11:22:25.630: [iter 78 : loss : 0.1441 = 0.0526 + 0.0870 + 0.0045, time: 6.617094]
2023-05-29 11:22:25.784: epoch 78:	0.02557921  	0.18915769  	0.10253035  
2023-05-29 11:22:25.784: Find a better model.
2023-05-29 11:22:32.249: [iter 79 : loss : 0.1425 = 0.0511 + 0.0869 + 0.0046, time: 6.463971]
2023-05-29 11:22:32.404: epoch 79:	0.02564978  	0.18960856  	0.10280474  
2023-05-29 11:22:32.404: Find a better model.
2023-05-29 11:22:38.844: [iter 80 : loss : 0.1418 = 0.0504 + 0.0868 + 0.0046, time: 6.438153]
2023-05-29 11:22:38.991: epoch 80:	0.02565683  	0.18977816  	0.10304097  
2023-05-29 11:22:38.991: Find a better model.
2023-05-29 11:22:45.434: [iter 81 : loss : 0.1416 = 0.0503 + 0.0867 + 0.0046, time: 6.442012]
2023-05-29 11:22:45.592: epoch 81:	0.02568506  	0.18989682  	0.10328542  
2023-05-29 11:22:45.592: Find a better model.
2023-05-29 11:22:52.048: [iter 82 : loss : 0.1402 = 0.0490 + 0.0866 + 0.0047, time: 6.454025]
2023-05-29 11:22:52.203: epoch 82:	0.02567800  	0.18979020  	0.10337701  
2023-05-29 11:22:58.648: [iter 83 : loss : 0.1395 = 0.0483 + 0.0865 + 0.0047, time: 6.444003]
2023-05-29 11:22:58.793: epoch 83:	0.02574857  	0.19041438  	0.10361630  
2023-05-29 11:22:58.793: Find a better model.
2023-05-29 11:23:05.260: [iter 84 : loss : 0.1393 = 0.0482 + 0.0864 + 0.0048, time: 6.466017]
2023-05-29 11:23:05.413: epoch 84:	0.02564272  	0.18948308  	0.10349984  
2023-05-29 11:23:11.838: [iter 85 : loss : 0.1384 = 0.0473 + 0.0863 + 0.0048, time: 6.423003]
2023-05-29 11:23:11.994: epoch 85:	0.02574151  	0.19035104  	0.10382067  
2023-05-29 11:23:18.447: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.451007]
2023-05-29 11:23:18.603: epoch 86:	0.02583325  	0.19120090  	0.10410055  
2023-05-29 11:23:18.603: Find a better model.
2023-05-29 11:23:25.048: [iter 87 : loss : 0.1355 = 0.0445 + 0.0861 + 0.0049, time: 6.444288]
2023-05-29 11:23:25.202: epoch 87:	0.02592498  	0.19165075  	0.10435608  
2023-05-29 11:23:25.202: Find a better model.
2023-05-29 11:23:31.812: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.609034]
2023-05-29 11:23:31.958: epoch 88:	0.02598143  	0.19216737  	0.10469663  
2023-05-29 11:23:31.958: Find a better model.
2023-05-29 11:23:38.418: [iter 89 : loss : 0.1346 = 0.0438 + 0.0859 + 0.0049, time: 6.458003]
2023-05-29 11:23:38.575: epoch 89:	0.02593909  	0.19168027  	0.10474261  
2023-05-29 11:23:45.217: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.640071]
2023-05-29 11:23:45.371: epoch 90:	0.02598143  	0.19210102  	0.10495852  
2023-05-29 11:23:52.011: [iter 91 : loss : 0.1337 = 0.0429 + 0.0857 + 0.0050, time: 6.639009]
2023-05-29 11:23:52.165: epoch 91:	0.02607316  	0.19301951  	0.10521194  
2023-05-29 11:23:52.165: Find a better model.
2023-05-29 11:23:58.627: [iter 92 : loss : 0.1328 = 0.0421 + 0.0857 + 0.0051, time: 6.460005]
2023-05-29 11:23:58.781: epoch 92:	0.02606611  	0.19320604  	0.10531200  
2023-05-29 11:23:58.781: Find a better model.
2023-05-29 11:24:05.231: [iter 93 : loss : 0.1331 = 0.0424 + 0.0856 + 0.0051, time: 6.449003]
2023-05-29 11:24:05.385: epoch 93:	0.02607316  	0.19364491  	0.10542238  
2023-05-29 11:24:05.385: Find a better model.
2023-05-29 11:24:11.997: [iter 94 : loss : 0.1312 = 0.0405 + 0.0855 + 0.0051, time: 6.611086]
2023-05-29 11:24:12.154: epoch 94:	0.02604493  	0.19334863  	0.10543600  
2023-05-29 11:24:18.624: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.469004]
2023-05-29 11:24:18.779: epoch 95:	0.02602377  	0.19293091  	0.10547489  
2023-05-29 11:24:25.215: [iter 96 : loss : 0.1305 = 0.0400 + 0.0854 + 0.0052, time: 6.434609]
2023-05-29 11:24:25.360: epoch 96:	0.02607316  	0.19358504  	0.10575362  
2023-05-29 11:24:31.811: [iter 97 : loss : 0.1289 = 0.0384 + 0.0853 + 0.0052, time: 6.450014]
2023-05-29 11:24:31.967: epoch 97:	0.02608727  	0.19345793  	0.10576922  
2023-05-29 11:24:38.424: [iter 98 : loss : 0.1297 = 0.0392 + 0.0852 + 0.0053, time: 6.455004]
2023-05-29 11:24:38.578: epoch 98:	0.02606610  	0.19350217  	0.10580727  
2023-05-29 11:24:45.020: [iter 99 : loss : 0.1285 = 0.0380 + 0.0851 + 0.0053, time: 6.439994]
2023-05-29 11:24:45.172: epoch 99:	0.02612255  	0.19398789  	0.10604306  
2023-05-29 11:24:45.172: Find a better model.
2023-05-29 11:24:51.603: [iter 100 : loss : 0.1280 = 0.0376 + 0.0851 + 0.0053, time: 6.430050]
2023-05-29 11:24:51.759: epoch 100:	0.02615078  	0.19422464  	0.10611188  
2023-05-29 11:24:51.759: Find a better model.
2023-05-29 11:24:58.199: [iter 101 : loss : 0.1275 = 0.0372 + 0.0850 + 0.0054, time: 6.439453]
2023-05-29 11:24:58.352: epoch 101:	0.02622134  	0.19465888  	0.10637175  
2023-05-29 11:24:58.353: Find a better model.
2023-05-29 11:25:04.796: [iter 102 : loss : 0.1268 = 0.0365 + 0.0849 + 0.0054, time: 6.441020]
2023-05-29 11:25:04.954: epoch 102:	0.02623546  	0.19469464  	0.10644804  
2023-05-29 11:25:04.954: Find a better model.
2023-05-29 11:25:11.389: [iter 103 : loss : 0.1264 = 0.0361 + 0.0849 + 0.0055, time: 6.434026]
2023-05-29 11:25:11.542: epoch 103:	0.02622135  	0.19479854  	0.10662238  
2023-05-29 11:25:11.542: Find a better model.
2023-05-29 11:25:17.986: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.442441]
2023-05-29 11:25:18.139: epoch 104:	0.02623546  	0.19487023  	0.10676966  
2023-05-29 11:25:18.139: Find a better model.
2023-05-29 11:25:24.781: [iter 105 : loss : 0.1262 = 0.0359 + 0.0847 + 0.0055, time: 6.640519]
2023-05-29 11:25:24.939: epoch 105:	0.02619312  	0.19447325  	0.10677120  
2023-05-29 11:25:31.381: [iter 106 : loss : 0.1256 = 0.0354 + 0.0847 + 0.0056, time: 6.441004]
2023-05-29 11:25:31.537: epoch 106:	0.02616490  	0.19423872  	0.10656431  
2023-05-29 11:25:37.999: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.459168]
2023-05-29 11:25:38.154: epoch 107:	0.02622135  	0.19466639  	0.10668222  
2023-05-29 11:25:44.587: [iter 108 : loss : 0.1245 = 0.0343 + 0.0846 + 0.0056, time: 6.432013]
2023-05-29 11:25:44.745: epoch 108:	0.02624957  	0.19508272  	0.10680859  
2023-05-29 11:25:44.745: Find a better model.
2023-05-29 11:25:51.184: [iter 109 : loss : 0.1231 = 0.0329 + 0.0845 + 0.0057, time: 6.438036]
2023-05-29 11:25:51.340: epoch 109:	0.02626369  	0.19530113  	0.10692968  
2023-05-29 11:25:51.340: Find a better model.
2023-05-29 11:25:57.776: [iter 110 : loss : 0.1226 = 0.0324 + 0.0845 + 0.0057, time: 6.435096]
2023-05-29 11:25:57.924: epoch 110:	0.02632720  	0.19582899  	0.10706321  
2023-05-29 11:25:57.925: Find a better model.
2023-05-29 11:26:04.578: [iter 111 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0057, time: 6.652186]
2023-05-29 11:26:04.731: epoch 111:	0.02634837  	0.19601567  	0.10724574  
2023-05-29 11:26:04.731: Find a better model.
2023-05-29 11:26:11.359: [iter 112 : loss : 0.1224 = 0.0324 + 0.0843 + 0.0058, time: 6.627003]
2023-05-29 11:26:11.515: epoch 112:	0.02635542  	0.19584881  	0.10718046  
2023-05-29 11:26:18.171: [iter 113 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 6.655014]
2023-05-29 11:26:18.326: epoch 113:	0.02632720  	0.19564304  	0.10713208  
2023-05-29 11:26:24.972: [iter 114 : loss : 0.1214 = 0.0315 + 0.0841 + 0.0058, time: 6.644064]
2023-05-29 11:26:25.127: epoch 114:	0.02636248  	0.19556339  	0.10719226  
2023-05-29 11:26:31.793: [iter 115 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 6.664155]
2023-05-29 11:26:31.952: epoch 115:	0.02637660  	0.19602795  	0.10714391  
2023-05-29 11:26:31.952: Find a better model.
2023-05-29 11:26:38.588: [iter 116 : loss : 0.1203 = 0.0304 + 0.0841 + 0.0059, time: 6.635352]
2023-05-29 11:26:38.744: epoch 116:	0.02639071  	0.19610101  	0.10713025  
2023-05-29 11:26:38.744: Find a better model.
2023-05-29 11:26:45.379: [iter 117 : loss : 0.1202 = 0.0302 + 0.0840 + 0.0059, time: 6.634001]
2023-05-29 11:26:45.536: epoch 117:	0.02646833  	0.19672781  	0.10738301  
2023-05-29 11:26:45.536: Find a better model.
2023-05-29 11:26:52.162: [iter 118 : loss : 0.1202 = 0.0303 + 0.0839 + 0.0060, time: 6.625573]
2023-05-29 11:26:52.318: epoch 118:	0.02653184  	0.19709201  	0.10759106  
2023-05-29 11:26:52.318: Find a better model.
2023-05-29 11:26:58.958: [iter 119 : loss : 0.1191 = 0.0292 + 0.0839 + 0.0060, time: 6.638125]
2023-05-29 11:26:59.115: epoch 119:	0.02656712  	0.19699970  	0.10768977  
2023-05-29 11:27:05.780: [iter 120 : loss : 0.1194 = 0.0296 + 0.0838 + 0.0060, time: 6.664056]
2023-05-29 11:27:05.937: epoch 120:	0.02646127  	0.19590941  	0.10737159  
2023-05-29 11:27:12.579: [iter 121 : loss : 0.1195 = 0.0296 + 0.0838 + 0.0061, time: 6.641000]
2023-05-29 11:27:12.733: epoch 121:	0.02645421  	0.19603920  	0.10750698  
2023-05-29 11:27:19.359: [iter 122 : loss : 0.1187 = 0.0289 + 0.0838 + 0.0061, time: 6.625036]
2023-05-29 11:27:19.513: epoch 122:	0.02644716  	0.19606395  	0.10759328  
2023-05-29 11:27:26.133: [iter 123 : loss : 0.1184 = 0.0285 + 0.0837 + 0.0061, time: 6.618015]
2023-05-29 11:27:26.288: epoch 123:	0.02641188  	0.19575951  	0.10748030  
2023-05-29 11:27:32.954: [iter 124 : loss : 0.1175 = 0.0277 + 0.0837 + 0.0061, time: 6.665003]
2023-05-29 11:27:33.107: epoch 124:	0.02646833  	0.19610192  	0.10753966  
2023-05-29 11:27:39.744: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.635042]
2023-05-29 11:27:39.901: epoch 125:	0.02651773  	0.19686589  	0.10772527  
2023-05-29 11:27:46.357: [iter 126 : loss : 0.1170 = 0.0273 + 0.0835 + 0.0062, time: 6.455015]
2023-05-29 11:27:46.514: epoch 126:	0.02650362  	0.19636890  	0.10771660  
2023-05-29 11:27:52.958: [iter 127 : loss : 0.1162 = 0.0264 + 0.0835 + 0.0062, time: 6.442994]
2023-05-29 11:27:53.114: epoch 127:	0.02643305  	0.19600880  	0.10764297  
2023-05-29 11:27:59.739: [iter 128 : loss : 0.1171 = 0.0274 + 0.0835 + 0.0063, time: 6.624022]
2023-05-29 11:27:59.895: epoch 128:	0.02650361  	0.19580962  	0.10752877  
2023-05-29 11:28:06.520: [iter 129 : loss : 0.1163 = 0.0266 + 0.0834 + 0.0063, time: 6.623133]
2023-05-29 11:28:06.678: epoch 129:	0.02650361  	0.19617674  	0.10771418  
2023-05-29 11:28:13.136: [iter 130 : loss : 0.1164 = 0.0267 + 0.0834 + 0.0063, time: 6.457874]
2023-05-29 11:28:13.294: epoch 130:	0.02646127  	0.19573405  	0.10771380  
2023-05-29 11:28:19.729: [iter 131 : loss : 0.1155 = 0.0258 + 0.0833 + 0.0064, time: 6.434013]
2023-05-29 11:28:19.886: epoch 131:	0.02647538  	0.19601202  	0.10773487  
2023-05-29 11:28:26.333: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.446018]
2023-05-29 11:28:26.488: epoch 132:	0.02642599  	0.19572522  	0.10773572  
2023-05-29 11:28:33.117: [iter 133 : loss : 0.1144 = 0.0247 + 0.0833 + 0.0064, time: 6.628025]
2023-05-29 11:28:33.271: epoch 133:	0.02636953  	0.19522797  	0.10770104  
2023-05-29 11:28:39.732: [iter 134 : loss : 0.1152 = 0.0256 + 0.0832 + 0.0064, time: 6.459003]
2023-05-29 11:28:39.887: epoch 134:	0.02635542  	0.19488984  	0.10760802  
2023-05-29 11:28:46.330: [iter 135 : loss : 0.1149 = 0.0253 + 0.0832 + 0.0065, time: 6.441047]
2023-05-29 11:28:46.488: epoch 135:	0.02641187  	0.19544327  	0.10776975  
2023-05-29 11:28:53.115: [iter 136 : loss : 0.1145 = 0.0249 + 0.0832 + 0.0065, time: 6.626009]
2023-05-29 11:28:53.273: epoch 136:	0.02642599  	0.19562320  	0.10778321  
2023-05-29 11:28:59.733: [iter 137 : loss : 0.1141 = 0.0245 + 0.0831 + 0.0065, time: 6.458994]
2023-05-29 11:28:59.888: epoch 137:	0.02644010  	0.19574188  	0.10781500  
2023-05-29 11:29:06.326: [iter 138 : loss : 0.1139 = 0.0242 + 0.0831 + 0.0066, time: 6.437007]
2023-05-29 11:29:06.481: epoch 138:	0.02644715  	0.19596457  	0.10791906  
2023-05-29 11:29:12.905: [iter 139 : loss : 0.1137 = 0.0241 + 0.0830 + 0.0066, time: 6.423022]
2023-05-29 11:29:13.049: epoch 139:	0.02644715  	0.19580023  	0.10789448  
2023-05-29 11:29:19.516: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.464000]
2023-05-29 11:29:19.674: epoch 140:	0.02644010  	0.19568200  	0.10790733  
2023-05-29 11:29:26.117: [iter 141 : loss : 0.1135 = 0.0239 + 0.0830 + 0.0066, time: 6.442023]
2023-05-29 11:29:26.273: epoch 141:	0.02643304  	0.19575962  	0.10789756  
2023-05-29 11:29:32.713: [iter 142 : loss : 0.1126 = 0.0230 + 0.0829 + 0.0067, time: 6.439003]
2023-05-29 11:29:32.870: epoch 142:	0.02639776  	0.19582146  	0.10797978  
2023-05-29 11:29:39.489: [iter 143 : loss : 0.1128 = 0.0233 + 0.0829 + 0.0067, time: 6.617486]
2023-05-29 11:29:39.633: epoch 143:	0.02639070  	0.19575901  	0.10819841  
2023-05-29 11:29:39.633: Early stopping is trigger at epoch: 143
2023-05-29 11:29:39.633: best_result@epoch 118:

2023-05-29 11:29:39.633: 		0.0265      	0.1971      	0.1076      
2023-05-29 11:30:14.039: my pid: 1304
2023-05-29 11:30:14.039: model: model.general_recommender.SGL
2023-05-29 11:30:14.039: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 11:30:14.039: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 11:30:17.667: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 11:30:25.153: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.485993]
2023-05-29 11:30:25.307: epoch 1:	0.00216625  	0.01497536  	0.00764244  
2023-05-29 11:30:25.307: Find a better model.
2023-05-29 11:30:32.727: [iter 2 : loss : 0.7706 = 0.6929 + 0.0777 + 0.0000, time: 7.419011]
2023-05-29 11:30:32.919: epoch 2:	0.00394438  	0.02714157  	0.01355890  
2023-05-29 11:30:32.919: Find a better model.
2023-05-29 11:30:40.315: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.395000]
2023-05-29 11:30:40.491: epoch 3:	0.00671742  	0.04654722  	0.02366749  
2023-05-29 11:30:40.491: Find a better model.
2023-05-29 11:30:47.739: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.246154]
2023-05-29 11:30:47.895: epoch 4:	0.00967396  	0.06787906  	0.03394979  
2023-05-29 11:30:47.895: Find a better model.
2023-05-29 11:30:55.120: [iter 5 : loss : 0.7685 = 0.6906 + 0.0778 + 0.0000, time: 7.224402]
2023-05-29 11:30:55.276: epoch 5:	0.01265885  	0.08938721  	0.04379842  
2023-05-29 11:30:55.276: Find a better model.
2023-05-29 11:31:02.480: [iter 6 : loss : 0.7655 = 0.6874 + 0.0781 + 0.0000, time: 7.203098]
2023-05-29 11:31:02.634: epoch 6:	0.01543907  	0.11075804  	0.05446367  
2023-05-29 11:31:02.634: Find a better model.
2023-05-29 11:31:09.672: [iter 7 : loss : 0.7576 = 0.6787 + 0.0789 + 0.0000, time: 7.036021]
2023-05-29 11:31:09.825: epoch 7:	0.01788764  	0.12975959  	0.06405847  
2023-05-29 11:31:09.825: Find a better model.
2023-05-29 11:31:16.697: [iter 8 : loss : 0.7388 = 0.6578 + 0.0809 + 0.0001, time: 6.870122]
2023-05-29 11:31:16.852: epoch 8:	0.01873441  	0.13699752  	0.06902540  
2023-05-29 11:31:16.852: Find a better model.
2023-05-29 11:31:23.666: [iter 9 : loss : 0.6989 = 0.6139 + 0.0848 + 0.0002, time: 6.813247]
2023-05-29 11:31:23.820: epoch 9:	0.01879792  	0.13885236  	0.06976726  
2023-05-29 11:31:23.820: Find a better model.
2023-05-29 11:31:30.476: [iter 10 : loss : 0.6345 = 0.5442 + 0.0900 + 0.0003, time: 6.655027]
2023-05-29 11:31:30.629: epoch 10:	0.01888260  	0.13985242  	0.06963884  
2023-05-29 11:31:30.630: Find a better model.
2023-05-29 11:31:37.302: [iter 11 : loss : 0.5590 = 0.4638 + 0.0948 + 0.0004, time: 6.671011]
2023-05-29 11:31:37.455: epoch 11:	0.01871325  	0.13860905  	0.06942577  
2023-05-29 11:31:44.067: [iter 12 : loss : 0.4925 = 0.3940 + 0.0979 + 0.0006, time: 6.611049]
2023-05-29 11:31:44.219: epoch 12:	0.01852272  	0.13726650  	0.06928337  
2023-05-29 11:31:50.877: [iter 13 : loss : 0.4439 = 0.3436 + 0.0996 + 0.0007, time: 6.657022]
2023-05-29 11:31:51.032: epoch 13:	0.01857212  	0.13756423  	0.06985772  
2023-05-29 11:31:57.674: [iter 14 : loss : 0.4072 = 0.3058 + 0.1005 + 0.0009, time: 6.641014]
2023-05-29 11:31:57.828: epoch 14:	0.01878382  	0.13956578  	0.07076950  
2023-05-29 11:32:04.465: [iter 15 : loss : 0.3812 = 0.2795 + 0.1008 + 0.0010, time: 6.636115]
2023-05-29 11:32:04.618: epoch 15:	0.01891789  	0.14010404  	0.07146242  
2023-05-29 11:32:04.618: Find a better model.
2023-05-29 11:32:11.272: [iter 16 : loss : 0.3596 = 0.2577 + 0.1008 + 0.0011, time: 6.652207]
2023-05-29 11:32:11.424: epoch 16:	0.01919310  	0.14209834  	0.07224111  
2023-05-29 11:32:11.424: Find a better model.
2023-05-29 11:32:18.092: [iter 17 : loss : 0.3436 = 0.2418 + 0.1006 + 0.0012, time: 6.666512]
2023-05-29 11:32:18.243: epoch 17:	0.01939774  	0.14316788  	0.07318529  
2023-05-29 11:32:18.243: Find a better model.
2023-05-29 11:32:24.872: [iter 18 : loss : 0.3286 = 0.2268 + 0.1004 + 0.0013, time: 6.627032]
2023-05-29 11:32:25.027: epoch 18:	0.01965882  	0.14523189  	0.07400754  
2023-05-29 11:32:25.028: Find a better model.
2023-05-29 11:32:31.679: [iter 19 : loss : 0.3146 = 0.2131 + 0.1000 + 0.0014, time: 6.650048]
2023-05-29 11:32:31.832: epoch 19:	0.01989875  	0.14659438  	0.07485601  
2023-05-29 11:32:31.832: Find a better model.
2023-05-29 11:32:38.479: [iter 20 : loss : 0.3051 = 0.2039 + 0.0996 + 0.0015, time: 6.646025]
2023-05-29 11:32:38.634: epoch 20:	0.02015279  	0.14849868  	0.07577936  
2023-05-29 11:32:38.634: Find a better model.
2023-05-29 11:32:45.281: [iter 21 : loss : 0.2954 = 0.1946 + 0.0993 + 0.0016, time: 6.646573]
2023-05-29 11:32:45.434: epoch 21:	0.02032920  	0.14976291  	0.07656690  
2023-05-29 11:32:45.434: Find a better model.
2023-05-29 11:32:52.066: [iter 22 : loss : 0.2873 = 0.1868 + 0.0989 + 0.0017, time: 6.631015]
2023-05-29 11:32:52.208: epoch 22:	0.02051266  	0.15155566  	0.07746946  
2023-05-29 11:32:52.208: Find a better model.
2023-05-29 11:32:59.063: [iter 23 : loss : 0.2793 = 0.1790 + 0.0985 + 0.0018, time: 6.854020]
2023-05-29 11:32:59.216: epoch 23:	0.02067497  	0.15280922  	0.07839331  
2023-05-29 11:32:59.216: Find a better model.
2023-05-29 11:33:06.037: [iter 24 : loss : 0.2728 = 0.1729 + 0.0980 + 0.0018, time: 6.820004]
2023-05-29 11:33:06.189: epoch 24:	0.02087960  	0.15387651  	0.07897241  
2023-05-29 11:33:06.189: Find a better model.
2023-05-29 11:33:12.857: [iter 25 : loss : 0.2661 = 0.1665 + 0.0976 + 0.0019, time: 6.667000]
2023-05-29 11:33:13.014: epoch 25:	0.02102073  	0.15470774  	0.07946541  
2023-05-29 11:33:13.014: Find a better model.
2023-05-29 11:33:19.654: [iter 26 : loss : 0.2624 = 0.1633 + 0.0972 + 0.0020, time: 6.638048]
2023-05-29 11:33:19.807: epoch 26:	0.02112659  	0.15535788  	0.07995071  
2023-05-29 11:33:19.807: Find a better model.
2023-05-29 11:33:26.460: [iter 27 : loss : 0.2548 = 0.1559 + 0.0968 + 0.0021, time: 6.652068]
2023-05-29 11:33:26.610: epoch 27:	0.02129594  	0.15674502  	0.08069664  
2023-05-29 11:33:26.611: Find a better model.
2023-05-29 11:33:33.240: [iter 28 : loss : 0.2499 = 0.1514 + 0.0964 + 0.0021, time: 6.628013]
2023-05-29 11:33:33.390: epoch 28:	0.02143002  	0.15756500  	0.08144733  
2023-05-29 11:33:33.391: Find a better model.
2023-05-29 11:33:39.872: [iter 29 : loss : 0.2456 = 0.1474 + 0.0960 + 0.0022, time: 6.480003]
2023-05-29 11:33:40.030: epoch 29:	0.02162054  	0.15895677  	0.08225098  
2023-05-29 11:33:40.030: Find a better model.
2023-05-29 11:33:46.640: [iter 30 : loss : 0.2390 = 0.1411 + 0.0956 + 0.0022, time: 6.609023]
2023-05-29 11:33:46.792: epoch 30:	0.02184634  	0.16083184  	0.08313150  
2023-05-29 11:33:46.792: Find a better model.
2023-05-29 11:33:53.431: [iter 31 : loss : 0.2355 = 0.1380 + 0.0952 + 0.0023, time: 6.638290]
2023-05-29 11:33:53.583: epoch 31:	0.02198747  	0.16185437  	0.08384563  
2023-05-29 11:33:53.583: Find a better model.
2023-05-29 11:34:00.234: [iter 32 : loss : 0.2300 = 0.1327 + 0.0949 + 0.0024, time: 6.650328]
2023-05-29 11:34:00.375: epoch 32:	0.02214271  	0.16267397  	0.08440990  
2023-05-29 11:34:00.375: Find a better model.
2023-05-29 11:34:07.040: [iter 33 : loss : 0.2272 = 0.1302 + 0.0945 + 0.0024, time: 6.664003]
2023-05-29 11:34:07.193: epoch 33:	0.02221327  	0.16328903  	0.08470640  
2023-05-29 11:34:07.193: Find a better model.
2023-05-29 11:34:13.843: [iter 34 : loss : 0.2234 = 0.1268 + 0.0942 + 0.0025, time: 6.649003]
2023-05-29 11:34:13.998: epoch 34:	0.02237557  	0.16443875  	0.08538613  
2023-05-29 11:34:13.998: Find a better model.
2023-05-29 11:34:20.663: [iter 35 : loss : 0.2200 = 0.1236 + 0.0939 + 0.0025, time: 6.663268]
2023-05-29 11:34:20.804: epoch 35:	0.02248847  	0.16539912  	0.08601477  
2023-05-29 11:34:20.804: Find a better model.
2023-05-29 11:34:27.430: [iter 36 : loss : 0.2166 = 0.1204 + 0.0936 + 0.0026, time: 6.624942]
2023-05-29 11:34:27.570: epoch 36:	0.02270723  	0.16716278  	0.08693756  
2023-05-29 11:34:27.570: Find a better model.
2023-05-29 11:34:34.221: [iter 37 : loss : 0.2126 = 0.1167 + 0.0932 + 0.0027, time: 6.650993]
2023-05-29 11:34:34.368: epoch 37:	0.02288364  	0.16815960  	0.08760352  
2023-05-29 11:34:34.368: Find a better model.
2023-05-29 11:34:41.197: [iter 38 : loss : 0.2111 = 0.1154 + 0.0930 + 0.0027, time: 6.827034]
2023-05-29 11:34:41.342: epoch 38:	0.02296126  	0.16911186  	0.08815136  
2023-05-29 11:34:41.342: Find a better model.
2023-05-29 11:34:48.022: [iter 39 : loss : 0.2067 = 0.1112 + 0.0927 + 0.0028, time: 6.679008]
2023-05-29 11:34:48.168: epoch 39:	0.02294715  	0.16911449  	0.08876958  
2023-05-29 11:34:48.168: Find a better model.
2023-05-29 11:34:55.007: [iter 40 : loss : 0.2035 = 0.1084 + 0.0923 + 0.0028, time: 6.838006]
2023-05-29 11:34:55.155: epoch 40:	0.02297538  	0.16947632  	0.08907121  
2023-05-29 11:34:55.155: Find a better model.
2023-05-29 11:35:02.037: [iter 41 : loss : 0.2019 = 0.1070 + 0.0921 + 0.0029, time: 6.880073]
2023-05-29 11:35:02.186: epoch 41:	0.02314474  	0.17047954  	0.08967278  
2023-05-29 11:35:02.186: Find a better model.
2023-05-29 11:35:09.001: [iter 42 : loss : 0.1998 = 0.1051 + 0.0918 + 0.0029, time: 6.814529]
2023-05-29 11:35:09.149: epoch 42:	0.02327175  	0.17125009  	0.09019362  
2023-05-29 11:35:09.149: Find a better model.
2023-05-29 11:35:15.809: [iter 43 : loss : 0.1957 = 0.1012 + 0.0915 + 0.0030, time: 6.657994]
2023-05-29 11:35:15.955: epoch 43:	0.02338466  	0.17248400  	0.09090815  
2023-05-29 11:35:15.955: Find a better model.
2023-05-29 11:35:22.617: [iter 44 : loss : 0.1924 = 0.0981 + 0.0912 + 0.0030, time: 6.660968]
2023-05-29 11:35:22.765: epoch 44:	0.02351873  	0.17322424  	0.09142201  
2023-05-29 11:35:22.765: Find a better model.
2023-05-29 11:35:29.576: [iter 45 : loss : 0.1901 = 0.0960 + 0.0910 + 0.0031, time: 6.809998]
2023-05-29 11:35:29.721: epoch 45:	0.02365986  	0.17424634  	0.09224367  
2023-05-29 11:35:29.721: Find a better model.
2023-05-29 11:35:36.422: [iter 46 : loss : 0.1880 = 0.0941 + 0.0908 + 0.0031, time: 6.700010]
2023-05-29 11:35:36.569: epoch 46:	0.02369515  	0.17449503  	0.09244721  
2023-05-29 11:35:36.569: Find a better model.
2023-05-29 11:35:43.400: [iter 47 : loss : 0.1871 = 0.0933 + 0.0905 + 0.0032, time: 6.830348]
2023-05-29 11:35:43.546: epoch 47:	0.02386451  	0.17573193  	0.09284776  
2023-05-29 11:35:43.546: Find a better model.
2023-05-29 11:35:50.199: [iter 48 : loss : 0.1833 = 0.0898 + 0.0903 + 0.0032, time: 6.651004]
2023-05-29 11:35:50.343: epoch 48:	0.02392095  	0.17622703  	0.09325764  
2023-05-29 11:35:50.343: Find a better model.
2023-05-29 11:35:57.170: [iter 49 : loss : 0.1803 = 0.0869 + 0.0901 + 0.0033, time: 6.825994]
2023-05-29 11:35:57.318: epoch 49:	0.02406914  	0.17730820  	0.09392841  
2023-05-29 11:35:57.319: Find a better model.
2023-05-29 11:36:03.991: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 6.669997]
2023-05-29 11:36:04.137: epoch 50:	0.02406208  	0.17759329  	0.09424033  
2023-05-29 11:36:04.137: Find a better model.
2023-05-29 11:36:10.800: [iter 51 : loss : 0.1764 = 0.0833 + 0.0897 + 0.0034, time: 6.660994]
2023-05-29 11:36:10.948: epoch 51:	0.02416793  	0.17844321  	0.09467940  
2023-05-29 11:36:10.948: Find a better model.
2023-05-29 11:36:17.770: [iter 52 : loss : 0.1765 = 0.0836 + 0.0895 + 0.0034, time: 6.821005]
2023-05-29 11:36:17.916: epoch 52:	0.02422437  	0.17842750  	0.09497578  
2023-05-29 11:36:24.597: [iter 53 : loss : 0.1742 = 0.0815 + 0.0893 + 0.0035, time: 6.679995]
2023-05-29 11:36:24.744: epoch 53:	0.02433728  	0.17941333  	0.09565471  
2023-05-29 11:36:24.744: Find a better model.
2023-05-29 11:36:31.379: [iter 54 : loss : 0.1724 = 0.0798 + 0.0891 + 0.0035, time: 6.633211]
2023-05-29 11:36:31.523: epoch 54:	0.02434433  	0.17965502  	0.09601045  
2023-05-29 11:36:31.523: Find a better model.
2023-05-29 11:36:38.185: [iter 55 : loss : 0.1703 = 0.0779 + 0.0889 + 0.0036, time: 6.661023]
2023-05-29 11:36:38.332: epoch 55:	0.02432316  	0.17928515  	0.09599151  
2023-05-29 11:36:44.977: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.644039]
2023-05-29 11:36:45.123: epoch 56:	0.02438667  	0.17958453  	0.09643993  
2023-05-29 11:36:51.786: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 6.661000]
2023-05-29 11:36:51.933: epoch 57:	0.02448546  	0.18022777  	0.09681772  
2023-05-29 11:36:51.933: Find a better model.
2023-05-29 11:36:58.777: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 6.843006]
2023-05-29 11:36:58.923: epoch 58:	0.02447134  	0.17994051  	0.09698641  
2023-05-29 11:37:05.602: [iter 59 : loss : 0.1640 = 0.0721 + 0.0882 + 0.0038, time: 6.678585]
2023-05-29 11:37:05.748: epoch 59:	0.02459130  	0.18102334  	0.09751311  
2023-05-29 11:37:05.748: Find a better model.
2023-05-29 11:37:12.559: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 6.810007]
2023-05-29 11:37:12.706: epoch 60:	0.02473243  	0.18233371  	0.09813038  
2023-05-29 11:37:12.706: Find a better model.
2023-05-29 11:37:19.566: [iter 61 : loss : 0.1612 = 0.0694 + 0.0879 + 0.0038, time: 6.858993]
2023-05-29 11:37:19.712: epoch 61:	0.02476772  	0.18282568  	0.09840386  
2023-05-29 11:37:19.712: Find a better model.
2023-05-29 11:37:26.549: [iter 62 : loss : 0.1597 = 0.0681 + 0.0877 + 0.0039, time: 6.835995]
2023-05-29 11:37:26.696: epoch 62:	0.02479594  	0.18302089  	0.09864884  
2023-05-29 11:37:26.696: Find a better model.
2023-05-29 11:37:33.374: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 6.676003]
2023-05-29 11:37:33.523: epoch 63:	0.02488062  	0.18378438  	0.09916424  
2023-05-29 11:37:33.523: Find a better model.
2023-05-29 11:37:40.348: [iter 64 : loss : 0.1574 = 0.0660 + 0.0874 + 0.0040, time: 6.824007]
2023-05-29 11:37:40.495: epoch 64:	0.02494413  	0.18437508  	0.09951241  
2023-05-29 11:37:40.495: Find a better model.
2023-05-29 11:37:47.355: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 6.858997]
2023-05-29 11:37:47.501: epoch 65:	0.02497941  	0.18466699  	0.09980574  
2023-05-29 11:37:47.501: Find a better model.
2023-05-29 11:37:54.352: [iter 66 : loss : 0.1546 = 0.0634 + 0.0871 + 0.0041, time: 6.848998]
2023-05-29 11:37:54.498: epoch 66:	0.02506409  	0.18534249  	0.10031982  
2023-05-29 11:37:54.498: Find a better model.
2023-05-29 11:38:01.339: [iter 67 : loss : 0.1530 = 0.0620 + 0.0869 + 0.0041, time: 6.840011]
2023-05-29 11:38:01.486: epoch 67:	0.02502175  	0.18512684  	0.10033373  
2023-05-29 11:38:08.341: [iter 68 : loss : 0.1528 = 0.0618 + 0.0868 + 0.0042, time: 6.853993]
2023-05-29 11:38:08.489: epoch 68:	0.02517699  	0.18632852  	0.10074176  
2023-05-29 11:38:08.489: Find a better model.
2023-05-29 11:38:15.329: [iter 69 : loss : 0.1509 = 0.0601 + 0.0867 + 0.0042, time: 6.839006]
2023-05-29 11:38:15.476: epoch 69:	0.02514876  	0.18617438  	0.10094364  
2023-05-29 11:38:22.152: [iter 70 : loss : 0.1495 = 0.0587 + 0.0866 + 0.0042, time: 6.674014]
2023-05-29 11:38:22.298: epoch 70:	0.02522638  	0.18657640  	0.10142211  
2023-05-29 11:38:22.299: Find a better model.
2023-05-29 11:38:29.138: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.838001]
2023-05-29 11:38:29.284: epoch 71:	0.02530401  	0.18723078  	0.10194766  
2023-05-29 11:38:29.284: Find a better model.
2023-05-29 11:38:36.111: [iter 72 : loss : 0.1477 = 0.0571 + 0.0863 + 0.0043, time: 6.824993]
2023-05-29 11:38:36.258: epoch 72:	0.02538163  	0.18807197  	0.10218677  
2023-05-29 11:38:36.259: Find a better model.
2023-05-29 11:38:43.132: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 6.871995]
2023-05-29 11:38:43.278: epoch 73:	0.02545925  	0.18872808  	0.10249167  
2023-05-29 11:38:43.278: Find a better model.
2023-05-29 11:38:50.117: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.837110]
2023-05-29 11:38:50.265: epoch 74:	0.02547336  	0.18867107  	0.10270183  
2023-05-29 11:38:57.132: [iter 75 : loss : 0.1444 = 0.0540 + 0.0860 + 0.0044, time: 6.866029]
2023-05-29 11:38:57.279: epoch 75:	0.02556510  	0.18946289  	0.10315620  
2023-05-29 11:38:57.279: Find a better model.
2023-05-29 11:39:04.118: [iter 76 : loss : 0.1434 = 0.0531 + 0.0858 + 0.0045, time: 6.837016]
2023-05-29 11:39:04.266: epoch 76:	0.02557921  	0.18948366  	0.10323747  
2023-05-29 11:39:04.266: Find a better model.
2023-05-29 11:39:11.131: [iter 77 : loss : 0.1426 = 0.0523 + 0.0857 + 0.0045, time: 6.863003]
2023-05-29 11:39:11.279: epoch 77:	0.02567094  	0.19007935  	0.10351834  
2023-05-29 11:39:11.279: Find a better model.
2023-05-29 11:39:18.106: [iter 78 : loss : 0.1416 = 0.0515 + 0.0856 + 0.0046, time: 6.824993]
2023-05-29 11:39:18.254: epoch 78:	0.02574150  	0.19066168  	0.10372009  
2023-05-29 11:39:18.254: Find a better model.
2023-05-29 11:39:25.103: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 6.847998]
2023-05-29 11:39:25.250: epoch 79:	0.02572739  	0.19031818  	0.10357767  
2023-05-29 11:39:31.921: [iter 80 : loss : 0.1398 = 0.0498 + 0.0854 + 0.0047, time: 6.670007]
2023-05-29 11:39:32.068: epoch 80:	0.02576267  	0.19068532  	0.10380763  
2023-05-29 11:39:32.068: Find a better model.
2023-05-29 11:39:38.719: [iter 81 : loss : 0.1394 = 0.0494 + 0.0853 + 0.0047, time: 6.649999]
2023-05-29 11:39:38.863: epoch 81:	0.02581912  	0.19134311  	0.10397296  
2023-05-29 11:39:38.863: Find a better model.
2023-05-29 11:39:45.529: [iter 82 : loss : 0.1381 = 0.0482 + 0.0852 + 0.0047, time: 6.663191]
2023-05-29 11:39:45.675: epoch 82:	0.02590380  	0.19196683  	0.10444871  
2023-05-29 11:39:45.675: Find a better model.
2023-05-29 11:39:52.346: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 6.668994]
2023-05-29 11:39:52.493: epoch 83:	0.02589674  	0.19199549  	0.10462420  
2023-05-29 11:39:52.493: Find a better model.
2023-05-29 11:39:59.117: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 6.621993]
2023-05-29 11:39:59.262: epoch 84:	0.02598847  	0.19262144  	0.10496923  
2023-05-29 11:39:59.262: Find a better model.
2023-05-29 11:40:06.097: [iter 85 : loss : 0.1363 = 0.0465 + 0.0849 + 0.0048, time: 6.832998]
2023-05-29 11:40:06.243: epoch 85:	0.02589674  	0.19191842  	0.10492845  
2023-05-29 11:40:12.910: [iter 86 : loss : 0.1359 = 0.0463 + 0.0848 + 0.0049, time: 6.666003]
2023-05-29 11:40:13.057: epoch 86:	0.02596731  	0.19267619  	0.10519524  
2023-05-29 11:40:13.057: Find a better model.
2023-05-29 11:40:19.704: [iter 87 : loss : 0.1334 = 0.0437 + 0.0847 + 0.0049, time: 6.645994]
2023-05-29 11:40:19.850: epoch 87:	0.02600259  	0.19296810  	0.10554296  
2023-05-29 11:40:19.850: Find a better model.
2023-05-29 11:40:26.508: [iter 88 : loss : 0.1327 = 0.0431 + 0.0846 + 0.0050, time: 6.657001]
2023-05-29 11:40:26.653: epoch 88:	0.02606610  	0.19332168  	0.10571963  
2023-05-29 11:40:26.653: Find a better model.
2023-05-29 11:40:33.343: [iter 89 : loss : 0.1325 = 0.0430 + 0.0845 + 0.0050, time: 6.688007]
2023-05-29 11:40:33.491: epoch 89:	0.02603082  	0.19324417  	0.10568256  
2023-05-29 11:40:40.275: [iter 90 : loss : 0.1330 = 0.0435 + 0.0844 + 0.0050, time: 6.781995]
2023-05-29 11:40:40.422: epoch 90:	0.02607316  	0.19354725  	0.10576592  
2023-05-29 11:40:40.422: Find a better model.
2023-05-29 11:40:47.097: [iter 91 : loss : 0.1317 = 0.0422 + 0.0843 + 0.0051, time: 6.674033]
2023-05-29 11:40:47.245: epoch 91:	0.02612960  	0.19385689  	0.10596313  
2023-05-29 11:40:47.245: Find a better model.
2023-05-29 11:40:53.897: [iter 92 : loss : 0.1306 = 0.0413 + 0.0843 + 0.0051, time: 6.651124]
2023-05-29 11:40:54.041: epoch 92:	0.02617195  	0.19424167  	0.10611590  
2023-05-29 11:40:54.041: Find a better model.
2023-05-29 11:41:00.699: [iter 93 : loss : 0.1313 = 0.0420 + 0.0842 + 0.0052, time: 6.656003]
2023-05-29 11:41:00.846: epoch 93:	0.02623546  	0.19499393  	0.10628727  
2023-05-29 11:41:00.846: Find a better model.
2023-05-29 11:41:07.682: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 6.835001]
2023-05-29 11:41:07.828: epoch 94:	0.02618607  	0.19498123  	0.10625774  
2023-05-29 11:41:14.513: [iter 95 : loss : 0.1284 = 0.0391 + 0.0841 + 0.0052, time: 6.683998]
2023-05-29 11:41:14.660: epoch 95:	0.02616489  	0.19487981  	0.10619650  
2023-05-29 11:41:21.279: [iter 96 : loss : 0.1285 = 0.0393 + 0.0840 + 0.0053, time: 6.618001]
2023-05-29 11:41:21.425: epoch 96:	0.02619311  	0.19471452  	0.10647081  
2023-05-29 11:41:28.084: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 6.655993]
2023-05-29 11:41:28.230: epoch 97:	0.02620723  	0.19499263  	0.10654882  
2023-05-29 11:41:34.886: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 6.654993]
2023-05-29 11:41:35.032: epoch 98:	0.02632719  	0.19583116  	0.10707002  
2023-05-29 11:41:35.033: Find a better model.
2023-05-29 11:41:41.870: [iter 99 : loss : 0.1266 = 0.0374 + 0.0838 + 0.0054, time: 6.836000]
2023-05-29 11:41:42.016: epoch 99:	0.02634130  	0.19620173  	0.10694032  
2023-05-29 11:41:42.016: Find a better model.
2023-05-29 11:41:48.678: [iter 100 : loss : 0.1261 = 0.0370 + 0.0837 + 0.0054, time: 6.661003]
2023-05-29 11:41:48.824: epoch 100:	0.02635542  	0.19621514  	0.10690347  
2023-05-29 11:41:48.824: Find a better model.
2023-05-29 11:41:55.503: [iter 101 : loss : 0.1256 = 0.0365 + 0.0836 + 0.0054, time: 6.677016]
2023-05-29 11:41:55.649: epoch 101:	0.02632013  	0.19547941  	0.10677489  
2023-05-29 11:42:02.265: [iter 102 : loss : 0.1247 = 0.0356 + 0.0836 + 0.0055, time: 6.615001]
2023-05-29 11:42:02.411: epoch 102:	0.02644715  	0.19631743  	0.10713492  
2023-05-29 11:42:02.411: Find a better model.
2023-05-29 11:42:09.056: [iter 103 : loss : 0.1244 = 0.0354 + 0.0835 + 0.0055, time: 6.643018]
2023-05-29 11:42:09.204: epoch 103:	0.02649655  	0.19629750  	0.10718405  
2023-05-29 11:42:15.865: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 6.659098]
2023-05-29 11:42:16.012: epoch 104:	0.02639070  	0.19517985  	0.10690341  
2023-05-29 11:42:22.659: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.646002]
2023-05-29 11:42:22.807: epoch 105:	0.02644009  	0.19569534  	0.10721971  
2023-05-29 11:42:29.450: [iter 106 : loss : 0.1236 = 0.0347 + 0.0833 + 0.0056, time: 6.642010]
2023-05-29 11:42:29.597: epoch 106:	0.02655300  	0.19644500  	0.10756146  
2023-05-29 11:42:29.597: Find a better model.
2023-05-29 11:42:36.274: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0057, time: 6.674993]
2023-05-29 11:42:36.421: epoch 107:	0.02658828  	0.19660066  	0.10754263  
2023-05-29 11:42:36.422: Find a better model.
2023-05-29 11:42:43.057: [iter 108 : loss : 0.1225 = 0.0336 + 0.0832 + 0.0057, time: 6.633994]
2023-05-29 11:42:43.204: epoch 108:	0.02657416  	0.19656892  	0.10760897  
2023-05-29 11:42:49.849: [iter 109 : loss : 0.1213 = 0.0324 + 0.0831 + 0.0057, time: 6.642993]
2023-05-29 11:42:49.997: epoch 109:	0.02655300  	0.19610904  	0.10753655  
2023-05-29 11:42:56.643: [iter 110 : loss : 0.1206 = 0.0318 + 0.0831 + 0.0058, time: 6.644993]
2023-05-29 11:42:56.789: epoch 110:	0.02649654  	0.19590265  	0.10753446  
2023-05-29 11:43:03.651: [iter 111 : loss : 0.1206 = 0.0319 + 0.0829 + 0.0058, time: 6.861028]
2023-05-29 11:43:03.797: epoch 111:	0.02653182  	0.19643600  	0.10768051  
2023-05-29 11:43:10.663: [iter 112 : loss : 0.1205 = 0.0318 + 0.0829 + 0.0058, time: 6.863951]
2023-05-29 11:43:10.810: epoch 112:	0.02660944  	0.19709578  	0.10787323  
2023-05-29 11:43:10.810: Find a better model.
2023-05-29 11:43:17.673: [iter 113 : loss : 0.1205 = 0.0318 + 0.0828 + 0.0059, time: 6.862008]
2023-05-29 11:43:17.821: epoch 113:	0.02663062  	0.19723035  	0.10811451  
2023-05-29 11:43:17.821: Find a better model.
2023-05-29 11:43:24.628: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 6.805993]
2023-05-29 11:43:24.776: epoch 114:	0.02659534  	0.19688956  	0.10807677  
2023-05-29 11:43:31.628: [iter 115 : loss : 0.1191 = 0.0305 + 0.0827 + 0.0059, time: 6.849994]
2023-05-29 11:43:31.774: epoch 115:	0.02656712  	0.19675317  	0.10791369  
2023-05-29 11:43:38.622: [iter 116 : loss : 0.1183 = 0.0296 + 0.0827 + 0.0060, time: 6.845995]
2023-05-29 11:43:38.768: epoch 116:	0.02659534  	0.19699022  	0.10797733  
2023-05-29 11:43:45.627: [iter 117 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 6.858002]
2023-05-29 11:43:45.774: epoch 117:	0.02667296  	0.19764839  	0.10815831  
2023-05-29 11:43:45.775: Find a better model.
2023-05-29 11:43:52.641: [iter 118 : loss : 0.1182 = 0.0297 + 0.0826 + 0.0060, time: 6.865001]
2023-05-29 11:43:52.788: epoch 118:	0.02668002  	0.19742535  	0.10814526  
2023-05-29 11:43:59.652: [iter 119 : loss : 0.1173 = 0.0288 + 0.0825 + 0.0061, time: 6.861007]
2023-05-29 11:43:59.799: epoch 119:	0.02668707  	0.19727953  	0.10816471  
2023-05-29 11:44:06.621: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 6.820003]
2023-05-29 11:44:06.768: epoch 120:	0.02670824  	0.19743823  	0.10835786  
2023-05-29 11:44:13.632: [iter 121 : loss : 0.1174 = 0.0289 + 0.0824 + 0.0061, time: 6.861998]
2023-05-29 11:44:13.778: epoch 121:	0.02667296  	0.19716318  	0.10823260  
2023-05-29 11:44:20.619: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.840005]
2023-05-29 11:44:20.767: epoch 122:	0.02669413  	0.19708802  	0.10833393  
2023-05-29 11:44:27.631: [iter 123 : loss : 0.1164 = 0.0279 + 0.0823 + 0.0062, time: 6.863011]
2023-05-29 11:44:27.780: epoch 123:	0.02669413  	0.19707081  	0.10846683  
2023-05-29 11:44:34.617: [iter 124 : loss : 0.1157 = 0.0272 + 0.0823 + 0.0062, time: 6.834219]
2023-05-29 11:44:34.763: epoch 124:	0.02672235  	0.19695902  	0.10861655  
2023-05-29 11:44:41.652: [iter 125 : loss : 0.1148 = 0.0264 + 0.0822 + 0.0062, time: 6.886996]
2023-05-29 11:44:41.800: epoch 125:	0.02675764  	0.19733100  	0.10874858  
2023-05-29 11:44:48.615: [iter 126 : loss : 0.1153 = 0.0269 + 0.0822 + 0.0063, time: 6.814312]
2023-05-29 11:44:48.766: epoch 126:	0.02676470  	0.19781137  	0.10894937  
2023-05-29 11:44:48.766: Find a better model.
2023-05-29 11:44:55.608: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.840000]
2023-05-29 11:44:55.756: epoch 127:	0.02674352  	0.19739142  	0.10888495  
2023-05-29 11:45:02.614: [iter 128 : loss : 0.1154 = 0.0270 + 0.0821 + 0.0063, time: 6.857398]
2023-05-29 11:45:02.761: epoch 128:	0.02672941  	0.19726086  	0.10889233  
2023-05-29 11:45:09.617: [iter 129 : loss : 0.1144 = 0.0260 + 0.0821 + 0.0064, time: 6.854995]
2023-05-29 11:45:09.766: epoch 129:	0.02672236  	0.19725096  	0.10890797  
2023-05-29 11:45:16.774: [iter 130 : loss : 0.1146 = 0.0262 + 0.0820 + 0.0064, time: 7.006993]
2023-05-29 11:45:16.921: epoch 130:	0.02682820  	0.19825509  	0.10915592  
2023-05-29 11:45:16.922: Find a better model.
2023-05-29 11:45:23.812: [iter 131 : loss : 0.1136 = 0.0252 + 0.0820 + 0.0064, time: 6.889130]
2023-05-29 11:45:23.959: epoch 131:	0.02684936  	0.19806901  	0.10914039  
2023-05-29 11:45:30.794: [iter 132 : loss : 0.1139 = 0.0255 + 0.0819 + 0.0065, time: 6.832047]
2023-05-29 11:45:30.942: epoch 132:	0.02686348  	0.19819106  	0.10921164  
2023-05-29 11:45:37.792: [iter 133 : loss : 0.1126 = 0.0242 + 0.0819 + 0.0065, time: 6.849509]
2023-05-29 11:45:37.941: epoch 133:	0.02689170  	0.19830032  	0.10924426  
2023-05-29 11:45:37.941: Find a better model.
2023-05-29 11:45:44.804: [iter 134 : loss : 0.1133 = 0.0250 + 0.0818 + 0.0065, time: 6.862006]
2023-05-29 11:45:44.951: epoch 134:	0.02682113  	0.19781464  	0.10921235  
2023-05-29 11:45:51.789: [iter 135 : loss : 0.1132 = 0.0248 + 0.0818 + 0.0065, time: 6.836006]
2023-05-29 11:45:51.937: epoch 135:	0.02678585  	0.19736966  	0.10911421  
2023-05-29 11:45:58.788: [iter 136 : loss : 0.1127 = 0.0243 + 0.0818 + 0.0066, time: 6.848995]
2023-05-29 11:45:58.935: epoch 136:	0.02679996  	0.19734290  	0.10906399  
2023-05-29 11:46:05.812: [iter 137 : loss : 0.1124 = 0.0241 + 0.0817 + 0.0066, time: 6.874990]
2023-05-29 11:46:05.958: epoch 137:	0.02685642  	0.19769895  	0.10912172  
2023-05-29 11:46:12.779: [iter 138 : loss : 0.1121 = 0.0238 + 0.0817 + 0.0066, time: 6.818001]
2023-05-29 11:46:12.926: epoch 138:	0.02687054  	0.19758753  	0.10920090  
2023-05-29 11:46:19.791: [iter 139 : loss : 0.1118 = 0.0236 + 0.0816 + 0.0067, time: 6.863015]
2023-05-29 11:46:19.939: epoch 139:	0.02688465  	0.19799574  	0.10925062  
2023-05-29 11:46:26.767: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.827000]
2023-05-29 11:46:26.912: epoch 140:	0.02685642  	0.19793808  	0.10932781  
2023-05-29 11:46:33.767: [iter 141 : loss : 0.1118 = 0.0235 + 0.0816 + 0.0067, time: 6.854006]
2023-05-29 11:46:33.914: epoch 141:	0.02694815  	0.19863354  	0.10959081  
2023-05-29 11:46:33.914: Find a better model.
2023-05-29 11:46:40.758: [iter 142 : loss : 0.1109 = 0.0226 + 0.0815 + 0.0067, time: 6.843001]
2023-05-29 11:46:40.905: epoch 142:	0.02687054  	0.19848707  	0.10971107  
2023-05-29 11:46:47.774: [iter 143 : loss : 0.1110 = 0.0227 + 0.0815 + 0.0068, time: 6.867007]
2023-05-29 11:46:47.921: epoch 143:	0.02690582  	0.19866528  	0.10970854  
2023-05-29 11:46:47.921: Find a better model.
2023-05-29 11:46:54.768: [iter 144 : loss : 0.1104 = 0.0221 + 0.0815 + 0.0068, time: 6.845996]
2023-05-29 11:46:54.916: epoch 144:	0.02689875  	0.19867362  	0.10969602  
2023-05-29 11:46:54.916: Find a better model.
2023-05-29 11:47:01.753: [iter 145 : loss : 0.1103 = 0.0221 + 0.0814 + 0.0068, time: 6.836010]
2023-05-29 11:47:01.902: epoch 145:	0.02684936  	0.19817276  	0.10943372  
2023-05-29 11:47:08.752: [iter 146 : loss : 0.1108 = 0.0225 + 0.0814 + 0.0068, time: 6.847996]
2023-05-29 11:47:08.902: epoch 146:	0.02691992  	0.19867261  	0.10963587  
2023-05-29 11:47:15.762: [iter 147 : loss : 0.1105 = 0.0223 + 0.0814 + 0.0069, time: 6.858995]
2023-05-29 11:47:15.910: epoch 147:	0.02696226  	0.19909973  	0.10971519  
2023-05-29 11:47:15.910: Find a better model.
2023-05-29 11:47:22.751: [iter 148 : loss : 0.1093 = 0.0211 + 0.0813 + 0.0069, time: 6.839010]
2023-05-29 11:47:22.899: epoch 148:	0.02690581  	0.19865215  	0.10960031  
2023-05-29 11:47:29.763: [iter 149 : loss : 0.1097 = 0.0215 + 0.0813 + 0.0069, time: 6.862005]
2023-05-29 11:47:29.911: epoch 149:	0.02692698  	0.19888064  	0.10959250  
2023-05-29 11:47:36.747: [iter 150 : loss : 0.1089 = 0.0207 + 0.0813 + 0.0070, time: 6.834996]
2023-05-29 11:47:36.895: epoch 150:	0.02693404  	0.19861965  	0.10962643  
2023-05-29 11:47:43.762: [iter 151 : loss : 0.1092 = 0.0210 + 0.0812 + 0.0070, time: 6.865999]
2023-05-29 11:47:43.910: epoch 151:	0.02689876  	0.19830564  	0.10968216  
2023-05-29 11:47:50.745: [iter 152 : loss : 0.1085 = 0.0203 + 0.0812 + 0.0070, time: 6.833996]
2023-05-29 11:47:50.891: epoch 152:	0.02689170  	0.19842142  	0.10967440  
2023-05-29 11:47:57.733: [iter 153 : loss : 0.1078 = 0.0196 + 0.0812 + 0.0070, time: 6.839014]
2023-05-29 11:47:57.880: epoch 153:	0.02688464  	0.19832328  	0.10956512  
2023-05-29 11:48:04.737: [iter 154 : loss : 0.1082 = 0.0200 + 0.0811 + 0.0071, time: 6.855008]
2023-05-29 11:48:04.883: epoch 154:	0.02689170  	0.19839817  	0.10970148  
2023-05-29 11:48:11.572: [iter 155 : loss : 0.1091 = 0.0209 + 0.0811 + 0.0071, time: 6.687997]
2023-05-29 11:48:11.719: epoch 155:	0.02688465  	0.19860019  	0.10964636  
2023-05-29 11:48:18.535: [iter 156 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.813998]
2023-05-29 11:48:18.682: epoch 156:	0.02687054  	0.19812550  	0.10946902  
2023-05-29 11:48:25.535: [iter 157 : loss : 0.1080 = 0.0198 + 0.0811 + 0.0071, time: 6.851996]
2023-05-29 11:48:25.683: epoch 157:	0.02688465  	0.19811887  	0.10952926  
2023-05-29 11:48:32.545: [iter 158 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.860002]
2023-05-29 11:48:32.693: epoch 158:	0.02689876  	0.19814405  	0.10945520  
2023-05-29 11:48:39.522: [iter 159 : loss : 0.1077 = 0.0196 + 0.0810 + 0.0072, time: 6.827994]
2023-05-29 11:48:39.671: epoch 159:	0.02686348  	0.19792651  	0.10935546  
2023-05-29 11:48:46.518: [iter 160 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.845004]
2023-05-29 11:48:46.666: epoch 160:	0.02684936  	0.19751921  	0.10933740  
2023-05-29 11:48:53.523: [iter 161 : loss : 0.1069 = 0.0188 + 0.0809 + 0.0072, time: 6.856028]
2023-05-29 11:48:53.671: epoch 161:	0.02672940  	0.19687945  	0.10912196  
2023-05-29 11:49:00.528: [iter 162 : loss : 0.1062 = 0.0181 + 0.0809 + 0.0073, time: 6.856006]
2023-05-29 11:49:00.674: epoch 162:	0.02677880  	0.19701849  	0.10928661  
2023-05-29 11:49:07.518: [iter 163 : loss : 0.1067 = 0.0185 + 0.0809 + 0.0073, time: 6.841993]
2023-05-29 11:49:07.665: epoch 163:	0.02675058  	0.19678606  	0.10902821  
2023-05-29 11:49:14.515: [iter 164 : loss : 0.1067 = 0.0186 + 0.0809 + 0.0073, time: 6.847993]
2023-05-29 11:49:14.663: epoch 164:	0.02677879  	0.19686887  	0.10909409  
2023-05-29 11:49:21.516: [iter 165 : loss : 0.1063 = 0.0181 + 0.0808 + 0.0073, time: 6.852014]
2023-05-29 11:49:21.664: epoch 165:	0.02675056  	0.19683234  	0.10910444  
2023-05-29 11:49:28.521: [iter 166 : loss : 0.1061 = 0.0179 + 0.0808 + 0.0074, time: 6.854992]
2023-05-29 11:49:28.668: epoch 166:	0.02677174  	0.19705389  	0.10907000  
2023-05-29 11:49:35.528: [iter 167 : loss : 0.1065 = 0.0183 + 0.0808 + 0.0074, time: 6.859003]
2023-05-29 11:49:35.676: epoch 167:	0.02670117  	0.19616421  	0.10910287  
2023-05-29 11:49:42.503: [iter 168 : loss : 0.1059 = 0.0178 + 0.0808 + 0.0074, time: 6.826008]
2023-05-29 11:49:42.651: epoch 168:	0.02677880  	0.19682944  	0.10898040  
2023-05-29 11:49:49.507: [iter 169 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0074, time: 6.854996]
2023-05-29 11:49:49.653: epoch 169:	0.02676468  	0.19658510  	0.10897693  
2023-05-29 11:49:56.522: [iter 170 : loss : 0.1058 = 0.0176 + 0.0807 + 0.0075, time: 6.868000]
2023-05-29 11:49:56.669: epoch 170:	0.02670823  	0.19617310  	0.10876803  
2023-05-29 11:50:03.499: [iter 171 : loss : 0.1061 = 0.0179 + 0.0807 + 0.0075, time: 6.828993]
2023-05-29 11:50:03.644: epoch 171:	0.02675763  	0.19640163  	0.10898570  
2023-05-29 11:50:10.516: [iter 172 : loss : 0.1051 = 0.0169 + 0.0807 + 0.0075, time: 6.870003]
2023-05-29 11:50:10.664: epoch 172:	0.02668706  	0.19587341  	0.10887594  
2023-05-29 11:50:10.664: Early stopping is trigger at epoch: 172
2023-05-29 11:50:10.664: best_result@epoch 147:

2023-05-29 11:50:10.664: 		0.0270      	0.1991      	0.1097      
2023-05-29 14:35:41.358: my pid: 9944
2023-05-29 14:35:41.358: model: model.general_recommender.SGL
2023-05-29 14:35:41.358: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 14:35:41.358: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 14:35:45.003: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 14:35:52.548: [iter 1 : loss : 0.8491 = 0.6930 + 0.1561 + 0.0000, time: 7.545066]
2023-05-29 14:35:52.694: epoch 1:	0.00168643  	0.01153659  	0.00600129  
2023-05-29 14:35:52.694: Find a better model.
2023-05-29 14:36:00.312: [iter 2 : loss : 0.8483 = 0.6929 + 0.1554 + 0.0000, time: 7.616420]
2023-05-29 14:36:00.502: epoch 2:	0.00245555  	0.01642394  	0.00869469  
2023-05-29 14:36:00.502: Find a better model.
2023-05-29 14:36:08.195: [iter 3 : loss : 0.8481 = 0.6928 + 0.1553 + 0.0000, time: 7.692027]
2023-05-29 14:36:08.380: epoch 3:	0.00388793  	0.02625542  	0.01365823  
2023-05-29 14:36:08.380: Find a better model.
2023-05-29 14:36:15.746: [iter 4 : loss : 0.8479 = 0.6926 + 0.1553 + 0.0000, time: 7.365505]
2023-05-29 14:36:15.910: epoch 4:	0.00526387  	0.03586870  	0.01901259  
2023-05-29 14:36:15.910: Find a better model.
2023-05-29 14:36:23.136: [iter 5 : loss : 0.8476 = 0.6923 + 0.1552 + 0.0000, time: 7.224780]
2023-05-29 14:36:23.282: epoch 5:	0.00660452  	0.04506494  	0.02329369  
2023-05-29 14:36:23.282: Find a better model.
2023-05-29 14:36:30.519: [iter 6 : loss : 0.8473 = 0.6920 + 0.1553 + 0.0000, time: 7.236026]
2023-05-29 14:36:30.669: epoch 6:	0.00784639  	0.05406579  	0.02829268  
2023-05-29 14:36:30.669: Find a better model.
2023-05-29 14:36:37.916: [iter 7 : loss : 0.8466 = 0.6913 + 0.1553 + 0.0000, time: 7.246205]
2023-05-29 14:36:38.061: epoch 7:	0.00978686  	0.06919886  	0.03445496  
2023-05-29 14:36:38.061: Find a better model.
2023-05-29 14:36:45.289: [iter 8 : loss : 0.8458 = 0.6903 + 0.1554 + 0.0000, time: 7.226031]
2023-05-29 14:36:45.450: epoch 8:	0.01147336  	0.08150188  	0.04026670  
2023-05-29 14:36:45.450: Find a better model.
2023-05-29 14:36:52.705: [iter 9 : loss : 0.8441 = 0.6885 + 0.1556 + 0.0000, time: 7.253479]
2023-05-29 14:36:52.860: epoch 9:	0.01300461  	0.09332583  	0.04589792  
2023-05-29 14:36:52.860: Find a better model.
2023-05-29 14:36:59.905: [iter 10 : loss : 0.8409 = 0.6850 + 0.1559 + 0.0000, time: 7.044067]
2023-05-29 14:37:00.072: epoch 10:	0.01501568  	0.10798456  	0.05303740  
2023-05-29 14:37:00.072: Find a better model.
2023-05-29 14:37:07.119: [iter 11 : loss : 0.8347 = 0.6782 + 0.1565 + 0.0000, time: 7.046335]
2023-05-29 14:37:07.277: epoch 11:	0.01663865  	0.12011642  	0.05946904  
2023-05-29 14:37:07.277: Find a better model.
2023-05-29 14:37:14.288: [iter 12 : loss : 0.8227 = 0.6651 + 0.1576 + 0.0001, time: 7.009754]
2023-05-29 14:37:14.431: epoch 12:	0.01817694  	0.13186122  	0.06525528  
2023-05-29 14:37:14.431: Find a better model.
2023-05-29 14:37:21.305: [iter 13 : loss : 0.8017 = 0.6418 + 0.1597 + 0.0001, time: 6.870620]
2023-05-29 14:37:21.460: epoch 13:	0.01900256  	0.13839892  	0.06931407  
2023-05-29 14:37:21.460: Find a better model.
2023-05-29 14:37:28.300: [iter 14 : loss : 0.7663 = 0.6028 + 0.1634 + 0.0002, time: 6.838359]
2023-05-29 14:37:28.460: epoch 14:	0.01939067  	0.14162411  	0.07233877  
2023-05-29 14:37:28.460: Find a better model.
2023-05-29 14:37:35.283: [iter 15 : loss : 0.7164 = 0.5477 + 0.1683 + 0.0003, time: 6.821649]
2023-05-29 14:37:35.426: epoch 15:	0.01971528  	0.14560489  	0.07363057  
2023-05-29 14:37:35.426: Find a better model.
2023-05-29 14:37:42.289: [iter 16 : loss : 0.6562 = 0.4820 + 0.1737 + 0.0004, time: 6.861992]
2023-05-29 14:37:42.447: epoch 16:	0.01984229  	0.14663187  	0.07402168  
2023-05-29 14:37:42.447: Find a better model.
2023-05-29 14:37:49.317: [iter 17 : loss : 0.5968 = 0.4178 + 0.1784 + 0.0006, time: 6.869071]
2023-05-29 14:37:49.480: epoch 17:	0.01999049  	0.14750627  	0.07503948  
2023-05-29 14:37:49.480: Find a better model.
2023-05-29 14:37:56.267: [iter 18 : loss : 0.5454 = 0.3629 + 0.1818 + 0.0008, time: 6.786033]
2023-05-29 14:37:56.425: epoch 18:	0.02001165  	0.14747889  	0.07524960  
2023-05-29 14:38:03.279: [iter 19 : loss : 0.5031 = 0.3183 + 0.1838 + 0.0009, time: 6.852255]
2023-05-29 14:38:03.424: epoch 19:	0.02021629  	0.14914633  	0.07650916  
2023-05-29 14:38:03.425: Find a better model.
2023-05-29 14:38:10.258: [iter 20 : loss : 0.4717 = 0.2858 + 0.1848 + 0.0011, time: 6.832006]
2023-05-29 14:38:10.417: epoch 20:	0.02040681  	0.15059616  	0.07757657  
2023-05-29 14:38:10.417: Find a better model.
2023-05-29 14:38:17.252: [iter 21 : loss : 0.4456 = 0.2592 + 0.1853 + 0.0012, time: 6.834023]
2023-05-29 14:38:17.399: epoch 21:	0.02075259  	0.15318012  	0.07894836  
2023-05-29 14:38:17.399: Find a better model.
2023-05-29 14:38:24.076: [iter 22 : loss : 0.4250 = 0.2384 + 0.1853 + 0.0013, time: 6.676002]
2023-05-29 14:38:24.233: epoch 22:	0.02100662  	0.15509218  	0.07992326  
2023-05-29 14:38:24.233: Find a better model.
2023-05-29 14:38:31.079: [iter 23 : loss : 0.4074 = 0.2208 + 0.1851 + 0.0015, time: 6.845008]
2023-05-29 14:38:31.237: epoch 23:	0.02112658  	0.15606631  	0.08066137  
2023-05-29 14:38:31.237: Find a better model.
2023-05-29 14:38:38.066: [iter 24 : loss : 0.3932 = 0.2071 + 0.1846 + 0.0016, time: 6.826325]
2023-05-29 14:38:38.224: epoch 24:	0.02134533  	0.15777522  	0.08171339  
2023-05-29 14:38:38.224: Find a better model.
2023-05-29 14:38:45.063: [iter 25 : loss : 0.3801 = 0.1944 + 0.1841 + 0.0017, time: 6.837994]
2023-05-29 14:38:45.216: epoch 25:	0.02153586  	0.15894502  	0.08237842  
2023-05-29 14:38:45.216: Find a better model.
2023-05-29 14:38:52.068: [iter 26 : loss : 0.3706 = 0.1854 + 0.1834 + 0.0018, time: 6.849945]
2023-05-29 14:38:52.227: epoch 26:	0.02174755  	0.16013072  	0.08317948  
2023-05-29 14:38:52.228: Find a better model.
2023-05-29 14:38:59.054: [iter 27 : loss : 0.3592 = 0.1745 + 0.1827 + 0.0019, time: 6.824301]
2023-05-29 14:38:59.212: epoch 27:	0.02195925  	0.16204569  	0.08403410  
2023-05-29 14:38:59.212: Find a better model.
2023-05-29 14:39:06.056: [iter 28 : loss : 0.3504 = 0.1664 + 0.1820 + 0.0020, time: 6.843809]
2023-05-29 14:39:06.202: epoch 28:	0.02228384  	0.16439249  	0.08519165  
2023-05-29 14:39:06.202: Find a better model.
2023-05-29 14:39:13.064: [iter 29 : loss : 0.3428 = 0.1593 + 0.1814 + 0.0021, time: 6.861007]
2023-05-29 14:39:13.223: epoch 29:	0.02251671  	0.16614240  	0.08623806  
2023-05-29 14:39:13.223: Find a better model.
2023-05-29 14:39:20.052: [iter 30 : loss : 0.3335 = 0.1506 + 0.1807 + 0.0022, time: 6.826994]
2023-05-29 14:39:20.212: epoch 30:	0.02254494  	0.16642661  	0.08667824  
2023-05-29 14:39:20.212: Find a better model.
2023-05-29 14:39:27.057: [iter 31 : loss : 0.3273 = 0.1451 + 0.1800 + 0.0022, time: 6.844009]
2023-05-29 14:39:27.215: epoch 31:	0.02270724  	0.16788168  	0.08763610  
2023-05-29 14:39:27.216: Find a better model.
2023-05-29 14:39:34.234: [iter 32 : loss : 0.3200 = 0.1383 + 0.1794 + 0.0023, time: 7.017015]
2023-05-29 14:39:34.392: epoch 32:	0.02286954  	0.16927105  	0.08850102  
2023-05-29 14:39:34.392: Find a better model.
2023-05-29 14:39:41.226: [iter 33 : loss : 0.3149 = 0.1339 + 0.1787 + 0.0024, time: 6.833020]
2023-05-29 14:39:41.369: epoch 33:	0.02315885  	0.17130612  	0.08969644  
2023-05-29 14:39:41.369: Find a better model.
2023-05-29 14:39:48.243: [iter 34 : loss : 0.3095 = 0.1289 + 0.1781 + 0.0025, time: 6.873010]
2023-05-29 14:39:48.399: epoch 34:	0.02334937  	0.17261636  	0.09084994  
2023-05-29 14:39:48.400: Find a better model.
2023-05-29 14:39:55.277: [iter 35 : loss : 0.3045 = 0.1245 + 0.1775 + 0.0026, time: 6.875032]
2023-05-29 14:39:55.436: epoch 35:	0.02351167  	0.17407127  	0.09159385  
2023-05-29 14:39:55.436: Find a better model.
2023-05-29 14:40:02.445: [iter 36 : loss : 0.2998 = 0.1202 + 0.1769 + 0.0026, time: 7.007382]
2023-05-29 14:40:02.603: epoch 36:	0.02364575  	0.17502779  	0.09221248  
2023-05-29 14:40:02.603: Find a better model.
2023-05-29 14:40:09.634: [iter 37 : loss : 0.2945 = 0.1154 + 0.1763 + 0.0027, time: 7.030004]
2023-05-29 14:40:09.779: epoch 37:	0.02375865  	0.17559561  	0.09287143  
2023-05-29 14:40:09.780: Find a better model.
2023-05-29 14:40:16.809: [iter 38 : loss : 0.2916 = 0.1130 + 0.1759 + 0.0028, time: 7.028080]
2023-05-29 14:40:16.968: epoch 38:	0.02391389  	0.17677116  	0.09367339  
2023-05-29 14:40:16.968: Find a better model.
2023-05-29 14:40:23.833: [iter 39 : loss : 0.2863 = 0.1081 + 0.1753 + 0.0029, time: 6.864359]
2023-05-29 14:40:23.990: epoch 39:	0.02401268  	0.17748760  	0.09450243  
2023-05-29 14:40:23.990: Find a better model.
2023-05-29 14:40:31.011: [iter 40 : loss : 0.2824 = 0.1047 + 0.1748 + 0.0029, time: 7.018669]
2023-05-29 14:40:31.170: epoch 40:	0.02420321  	0.17879184  	0.09518597  
2023-05-29 14:40:31.170: Find a better model.
2023-05-29 14:40:38.063: [iter 41 : loss : 0.2798 = 0.1025 + 0.1743 + 0.0030, time: 6.892034]
2023-05-29 14:40:38.222: epoch 41:	0.02427377  	0.17938696  	0.09542485  
2023-05-29 14:40:38.222: Find a better model.
2023-05-29 14:40:45.023: [iter 42 : loss : 0.2765 = 0.0996 + 0.1738 + 0.0031, time: 6.800007]
2023-05-29 14:40:45.181: epoch 42:	0.02448547  	0.18088803  	0.09620275  
2023-05-29 14:40:45.182: Find a better model.
2023-05-29 14:40:52.205: [iter 43 : loss : 0.2721 = 0.0957 + 0.1733 + 0.0031, time: 7.022004]
2023-05-29 14:40:52.362: epoch 43:	0.02458426  	0.18123569  	0.09662788  
2023-05-29 14:40:52.362: Find a better model.
2023-05-29 14:40:59.406: [iter 44 : loss : 0.2684 = 0.0923 + 0.1729 + 0.0032, time: 7.042998]
2023-05-29 14:40:59.564: epoch 44:	0.02469010  	0.18209192  	0.09722359  
2023-05-29 14:40:59.564: Find a better model.
2023-05-29 14:41:06.433: [iter 45 : loss : 0.2652 = 0.0895 + 0.1725 + 0.0033, time: 6.868024]
2023-05-29 14:41:06.590: epoch 45:	0.02475361  	0.18295440  	0.09793669  
2023-05-29 14:41:06.590: Find a better model.
2023-05-29 14:41:13.593: [iter 46 : loss : 0.2628 = 0.0874 + 0.1721 + 0.0033, time: 7.001006]
2023-05-29 14:41:13.749: epoch 46:	0.02477478  	0.18323861  	0.09829447  
2023-05-29 14:41:13.750: Find a better model.
2023-05-29 14:41:20.636: [iter 47 : loss : 0.2611 = 0.0860 + 0.1717 + 0.0034, time: 6.885047]
2023-05-29 14:41:20.792: epoch 47:	0.02485239  	0.18356743  	0.09854799  
2023-05-29 14:41:20.792: Find a better model.
2023-05-29 14:41:27.617: [iter 48 : loss : 0.2572 = 0.0825 + 0.1713 + 0.0034, time: 6.823220]
2023-05-29 14:41:27.760: epoch 48:	0.02489473  	0.18406335  	0.09885184  
2023-05-29 14:41:27.760: Find a better model.
2023-05-29 14:41:34.595: [iter 49 : loss : 0.2540 = 0.0796 + 0.1710 + 0.0035, time: 6.833046]
2023-05-29 14:41:34.751: epoch 49:	0.02502881  	0.18536220  	0.09948385  
2023-05-29 14:41:34.751: Find a better model.
2023-05-29 14:41:41.617: [iter 50 : loss : 0.2526 = 0.0784 + 0.1706 + 0.0036, time: 6.865015]
2023-05-29 14:41:41.773: epoch 50:	0.02504292  	0.18568631  	0.09998199  
2023-05-29 14:41:41.773: Find a better model.
2023-05-29 14:41:48.611: [iter 51 : loss : 0.2494 = 0.0754 + 0.1703 + 0.0036, time: 6.836955]
2023-05-29 14:41:48.754: epoch 51:	0.02509937  	0.18594709  	0.10029037  
2023-05-29 14:41:48.754: Find a better model.
2023-05-29 14:41:55.614: [iter 52 : loss : 0.2488 = 0.0752 + 0.1700 + 0.0037, time: 6.859056]
2023-05-29 14:41:55.758: epoch 52:	0.02515582  	0.18637078  	0.10077165  
2023-05-29 14:41:55.758: Find a better model.
2023-05-29 14:42:02.627: [iter 53 : loss : 0.2463 = 0.0730 + 0.1696 + 0.0037, time: 6.866996]
2023-05-29 14:42:02.783: epoch 53:	0.02538163  	0.18856218  	0.10160968  
2023-05-29 14:42:02.783: Find a better model.
2023-05-29 14:42:09.609: [iter 54 : loss : 0.2443 = 0.0711 + 0.1693 + 0.0038, time: 6.824047]
2023-05-29 14:42:09.765: epoch 54:	0.02543102  	0.18870616  	0.10205443  
2023-05-29 14:42:09.765: Find a better model.
2023-05-29 14:42:16.612: [iter 55 : loss : 0.2422 = 0.0693 + 0.1690 + 0.0039, time: 6.844049]
2023-05-29 14:42:16.769: epoch 55:	0.02546631  	0.18887022  	0.10227064  
2023-05-29 14:42:16.769: Find a better model.
2023-05-29 14:42:23.598: [iter 56 : loss : 0.2402 = 0.0675 + 0.1687 + 0.0039, time: 6.828345]
2023-05-29 14:42:23.753: epoch 56:	0.02555098  	0.18948583  	0.10277537  
2023-05-29 14:42:23.753: Find a better model.
2023-05-29 14:42:30.580: [iter 57 : loss : 0.2385 = 0.0660 + 0.1685 + 0.0040, time: 6.826073]
2023-05-29 14:42:30.735: epoch 57:	0.02552276  	0.18963236  	0.10296629  
2023-05-29 14:42:30.735: Find a better model.
2023-05-29 14:42:37.590: [iter 58 : loss : 0.2364 = 0.0641 + 0.1682 + 0.0040, time: 6.854003]
2023-05-29 14:42:37.746: epoch 58:	0.02552982  	0.18983151  	0.10319003  
2023-05-29 14:42:37.747: Find a better model.
2023-05-29 14:42:44.606: [iter 59 : loss : 0.2351 = 0.0631 + 0.1679 + 0.0041, time: 6.858392]
2023-05-29 14:42:44.762: epoch 59:	0.02559333  	0.19048384  	0.10346719  
2023-05-29 14:42:44.763: Find a better model.
2023-05-29 14:42:51.600: [iter 60 : loss : 0.2336 = 0.0617 + 0.1677 + 0.0041, time: 6.834997]
2023-05-29 14:42:51.757: epoch 60:	0.02568506  	0.19114482  	0.10390606  
2023-05-29 14:42:51.758: Find a better model.
2023-05-29 14:42:58.587: [iter 61 : loss : 0.2320 = 0.0604 + 0.1675 + 0.0042, time: 6.828002]
2023-05-29 14:42:58.746: epoch 61:	0.02573446  	0.19146246  	0.10412119  
2023-05-29 14:42:58.746: Find a better model.
2023-05-29 14:43:05.593: [iter 62 : loss : 0.2304 = 0.0589 + 0.1672 + 0.0043, time: 6.845245]
2023-05-29 14:43:05.751: epoch 62:	0.02582619  	0.19194566  	0.10431074  
2023-05-29 14:43:05.751: Find a better model.
2023-05-29 14:43:12.587: [iter 63 : loss : 0.2290 = 0.0577 + 0.1670 + 0.0043, time: 6.835003]
2023-05-29 14:43:12.743: epoch 63:	0.02583325  	0.19173793  	0.10436251  
2023-05-29 14:43:19.578: [iter 64 : loss : 0.2280 = 0.0569 + 0.1668 + 0.0044, time: 6.834079]
2023-05-29 14:43:19.733: epoch 64:	0.02590381  	0.19197838  	0.10456209  
2023-05-29 14:43:19.733: Find a better model.
2023-05-29 14:43:26.581: [iter 65 : loss : 0.2267 = 0.0558 + 0.1665 + 0.0044, time: 6.847064]
2023-05-29 14:43:26.737: epoch 65:	0.02596026  	0.19241008  	0.10498924  
2023-05-29 14:43:26.737: Find a better model.
2023-05-29 14:43:33.558: [iter 66 : loss : 0.2251 = 0.0543 + 0.1663 + 0.0045, time: 6.820027]
2023-05-29 14:43:33.703: epoch 66:	0.02596026  	0.19229591  	0.10493387  
2023-05-29 14:43:40.548: [iter 67 : loss : 0.2235 = 0.0529 + 0.1661 + 0.0045, time: 6.844020]
2023-05-29 14:43:40.695: epoch 67:	0.02596732  	0.19266114  	0.10519618  
2023-05-29 14:43:40.695: Find a better model.
2023-05-29 14:43:47.555: [iter 68 : loss : 0.2229 = 0.0525 + 0.1659 + 0.0046, time: 6.859007]
2023-05-29 14:43:47.711: epoch 68:	0.02602377  	0.19287102  	0.10540703  
2023-05-29 14:43:47.711: Find a better model.
2023-05-29 14:43:54.567: [iter 69 : loss : 0.2213 = 0.0509 + 0.1657 + 0.0046, time: 6.855328]
2023-05-29 14:43:54.711: epoch 69:	0.02604494  	0.19291857  	0.10563383  
2023-05-29 14:43:54.711: Find a better model.
2023-05-29 14:44:01.548: [iter 70 : loss : 0.2200 = 0.0498 + 0.1656 + 0.0047, time: 6.836081]
2023-05-29 14:44:01.706: epoch 70:	0.02606611  	0.19321938  	0.10588345  
2023-05-29 14:44:01.706: Find a better model.
2023-05-29 14:44:08.571: [iter 71 : loss : 0.2184 = 0.0483 + 0.1654 + 0.0047, time: 6.864011]
2023-05-29 14:44:08.714: epoch 71:	0.02610140  	0.19362448  	0.10608815  
2023-05-29 14:44:08.714: Find a better model.
2023-05-29 14:44:15.562: [iter 72 : loss : 0.2179 = 0.0479 + 0.1652 + 0.0048, time: 6.846025]
2023-05-29 14:44:15.719: epoch 72:	0.02623546  	0.19452257  	0.10658046  
2023-05-29 14:44:15.719: Find a better model.
2023-05-29 14:44:22.540: [iter 73 : loss : 0.2167 = 0.0468 + 0.1650 + 0.0048, time: 6.820007]
2023-05-29 14:44:22.684: epoch 73:	0.02621430  	0.19454862  	0.10662888  
2023-05-29 14:44:22.684: Find a better model.
2023-05-29 14:44:29.541: [iter 74 : loss : 0.2153 = 0.0455 + 0.1649 + 0.0049, time: 6.853499]
2023-05-29 14:44:29.697: epoch 74:	0.02620018  	0.19456461  	0.10673302  
2023-05-29 14:44:29.697: Find a better model.
2023-05-29 14:44:36.517: [iter 75 : loss : 0.2148 = 0.0452 + 0.1647 + 0.0049, time: 6.819018]
2023-05-29 14:44:36.673: epoch 75:	0.02620724  	0.19428657  	0.10667471  
2023-05-29 14:44:43.518: [iter 76 : loss : 0.2138 = 0.0443 + 0.1645 + 0.0050, time: 6.842993]
2023-05-29 14:44:43.661: epoch 76:	0.02619313  	0.19428055  	0.10697447  
2023-05-29 14:44:50.372: [iter 77 : loss : 0.2129 = 0.0435 + 0.1644 + 0.0050, time: 6.710340]
2023-05-29 14:44:50.533: epoch 77:	0.02627074  	0.19486594  	0.10722049  
2023-05-29 14:44:50.533: Find a better model.
2023-05-29 14:44:57.338: [iter 78 : loss : 0.2122 = 0.0429 + 0.1642 + 0.0050, time: 6.803007]
2023-05-29 14:44:57.503: epoch 78:	0.02617195  	0.19433123  	0.10716973  
2023-05-29 14:45:04.322: [iter 79 : loss : 0.2109 = 0.0416 + 0.1641 + 0.0051, time: 6.818310]
2023-05-29 14:45:04.468: epoch 79:	0.02619312  	0.19433206  	0.10730578  
2023-05-29 14:45:11.129: [iter 80 : loss : 0.2103 = 0.0412 + 0.1640 + 0.0051, time: 6.658020]
2023-05-29 14:45:11.285: epoch 80:	0.02622840  	0.19439033  	0.10750268  
2023-05-29 14:45:17.946: [iter 81 : loss : 0.2096 = 0.0406 + 0.1638 + 0.0052, time: 6.660007]
2023-05-29 14:45:18.102: epoch 81:	0.02624957  	0.19469659  	0.10774166  
2023-05-29 14:45:24.743: [iter 82 : loss : 0.2086 = 0.0397 + 0.1637 + 0.0052, time: 6.639124]
2023-05-29 14:45:24.898: epoch 82:	0.02622135  	0.19428746  	0.10755888  
2023-05-29 14:45:31.551: [iter 83 : loss : 0.2078 = 0.0389 + 0.1636 + 0.0053, time: 6.651022]
2023-05-29 14:45:31.708: epoch 83:	0.02629191  	0.19474144  	0.10784110  
2023-05-29 14:45:38.342: [iter 84 : loss : 0.2077 = 0.0389 + 0.1635 + 0.0053, time: 6.633028]
2023-05-29 14:45:38.502: epoch 84:	0.02632719  	0.19479941  	0.10798127  
2023-05-29 14:45:45.132: [iter 85 : loss : 0.2069 = 0.0382 + 0.1633 + 0.0054, time: 6.629839]
2023-05-29 14:45:45.289: epoch 85:	0.02639776  	0.19546002  	0.10802346  
2023-05-29 14:45:45.289: Find a better model.
2023-05-29 14:45:51.924: [iter 86 : loss : 0.2063 = 0.0377 + 0.1631 + 0.0054, time: 6.632994]
2023-05-29 14:45:52.079: epoch 86:	0.02641892  	0.19555208  	0.10812376  
2023-05-29 14:45:52.079: Find a better model.
2023-05-29 14:45:58.720: [iter 87 : loss : 0.2043 = 0.0358 + 0.1631 + 0.0054, time: 6.640015]
2023-05-29 14:45:58.876: epoch 87:	0.02645420  	0.19568540  	0.10833161  
2023-05-29 14:45:58.876: Find a better model.
2023-05-29 14:46:05.711: [iter 88 : loss : 0.2037 = 0.0353 + 0.1630 + 0.0055, time: 6.834012]
2023-05-29 14:46:05.865: epoch 88:	0.02644009  	0.19571538  	0.10831813  
2023-05-29 14:46:05.866: Find a better model.
2023-05-29 14:46:12.728: [iter 89 : loss : 0.2033 = 0.0349 + 0.1629 + 0.0055, time: 6.861035]
2023-05-29 14:46:12.882: epoch 89:	0.02641186  	0.19564185  	0.10828143  
2023-05-29 14:46:19.507: [iter 90 : loss : 0.2036 = 0.0353 + 0.1627 + 0.0056, time: 6.622105]
2023-05-29 14:46:19.650: epoch 90:	0.02652477  	0.19624180  	0.10847772  
2023-05-29 14:46:19.650: Find a better model.
2023-05-29 14:46:26.493: [iter 91 : loss : 0.2027 = 0.0345 + 0.1626 + 0.0056, time: 6.841020]
2023-05-29 14:46:26.648: epoch 91:	0.02652477  	0.19612947  	0.10851834  
2023-05-29 14:46:33.482: [iter 92 : loss : 0.2015 = 0.0333 + 0.1625 + 0.0057, time: 6.833263]
2023-05-29 14:46:33.638: epoch 92:	0.02656711  	0.19654971  	0.10873464  
2023-05-29 14:46:33.639: Find a better model.
2023-05-29 14:46:40.501: [iter 93 : loss : 0.2021 = 0.0340 + 0.1624 + 0.0057, time: 6.860216]
2023-05-29 14:46:40.643: epoch 93:	0.02659533  	0.19678789  	0.10880528  
2023-05-29 14:46:40.643: Find a better model.
2023-05-29 14:46:47.490: [iter 94 : loss : 0.2005 = 0.0324 + 0.1624 + 0.0057, time: 6.845649]
2023-05-29 14:46:47.644: epoch 94:	0.02663767  	0.19717266  	0.10893147  
2023-05-29 14:46:47.644: Find a better model.
2023-05-29 14:46:54.342: [iter 95 : loss : 0.1997 = 0.0316 + 0.1622 + 0.0058, time: 6.697004]
2023-05-29 14:46:54.503: epoch 95:	0.02655299  	0.19660722  	0.10879372  
2023-05-29 14:47:01.267: [iter 96 : loss : 0.1998 = 0.0318 + 0.1621 + 0.0058, time: 6.762097]
2023-05-29 14:47:01.410: epoch 96:	0.02663767  	0.19728622  	0.10913821  
2023-05-29 14:47:01.410: Find a better model.
2023-05-29 14:47:08.280: [iter 97 : loss : 0.1983 = 0.0304 + 0.1620 + 0.0059, time: 6.868464]
2023-05-29 14:47:08.436: epoch 97:	0.02674352  	0.19811757  	0.10940159  
2023-05-29 14:47:08.436: Find a better model.
2023-05-29 14:47:15.283: [iter 98 : loss : 0.1987 = 0.0309 + 0.1620 + 0.0059, time: 6.846000]
2023-05-29 14:47:15.438: epoch 98:	0.02664473  	0.19756450  	0.10919015  
2023-05-29 14:47:22.114: [iter 99 : loss : 0.1979 = 0.0301 + 0.1619 + 0.0059, time: 6.675000]
2023-05-29 14:47:22.270: epoch 99:	0.02670824  	0.19765835  	0.10921570  
2023-05-29 14:47:29.088: [iter 100 : loss : 0.1976 = 0.0298 + 0.1618 + 0.0060, time: 6.815005]
2023-05-29 14:47:29.244: epoch 100:	0.02665178  	0.19723770  	0.10915210  
2023-05-29 14:47:36.083: [iter 101 : loss : 0.1970 = 0.0293 + 0.1617 + 0.0060, time: 6.837023]
2023-05-29 14:47:36.238: epoch 101:	0.02670118  	0.19729279  	0.10928741  
2023-05-29 14:47:42.892: [iter 102 : loss : 0.1964 = 0.0287 + 0.1616 + 0.0061, time: 6.652029]
2023-05-29 14:47:43.049: epoch 102:	0.02666590  	0.19683348  	0.10913949  
2023-05-29 14:47:49.874: [iter 103 : loss : 0.1960 = 0.0284 + 0.1615 + 0.0061, time: 6.821217]
2023-05-29 14:47:50.030: epoch 103:	0.02666590  	0.19705121  	0.10914675  
2023-05-29 14:47:56.690: [iter 104 : loss : 0.1963 = 0.0287 + 0.1615 + 0.0061, time: 6.659028]
2023-05-29 14:47:56.844: epoch 104:	0.02670824  	0.19745716  	0.10948139  
2023-05-29 14:48:03.652: [iter 105 : loss : 0.1958 = 0.0282 + 0.1614 + 0.0062, time: 6.805003]
2023-05-29 14:48:03.808: epoch 105:	0.02669413  	0.19743663  	0.10922381  
2023-05-29 14:48:10.469: [iter 106 : loss : 0.1952 = 0.0276 + 0.1613 + 0.0062, time: 6.659020]
2023-05-29 14:48:10.623: epoch 106:	0.02667296  	0.19719459  	0.10934294  
2023-05-29 14:48:17.281: [iter 107 : loss : 0.1946 = 0.0271 + 0.1612 + 0.0063, time: 6.656016]
2023-05-29 14:48:17.426: epoch 107:	0.02666590  	0.19695075  	0.10951275  
2023-05-29 14:48:24.063: [iter 108 : loss : 0.1942 = 0.0267 + 0.1612 + 0.0063, time: 6.636016]
2023-05-29 14:48:24.218: epoch 108:	0.02663062  	0.19653864  	0.10932679  
2023-05-29 14:48:30.852: [iter 109 : loss : 0.1932 = 0.0258 + 0.1611 + 0.0063, time: 6.632023]
2023-05-29 14:48:30.996: epoch 109:	0.02662356  	0.19627200  	0.10920431  
2023-05-29 14:48:37.676: [iter 110 : loss : 0.1928 = 0.0254 + 0.1610 + 0.0064, time: 6.678009]
2023-05-29 14:48:37.832: epoch 110:	0.02666590  	0.19664733  	0.10928968  
2023-05-29 14:48:44.654: [iter 111 : loss : 0.1927 = 0.0254 + 0.1609 + 0.0064, time: 6.821006]
2023-05-29 14:48:44.808: epoch 111:	0.02670118  	0.19683176  	0.10949196  
2023-05-29 14:48:51.680: [iter 112 : loss : 0.1924 = 0.0251 + 0.1608 + 0.0064, time: 6.871457]
2023-05-29 14:48:51.834: epoch 112:	0.02656711  	0.19600941  	0.10915165  
2023-05-29 14:48:58.686: [iter 113 : loss : 0.1926 = 0.0253 + 0.1608 + 0.0065, time: 6.850996]
2023-05-29 14:48:58.841: epoch 113:	0.02659533  	0.19595082  	0.10914697  
2023-05-29 14:49:05.669: [iter 114 : loss : 0.1917 = 0.0245 + 0.1607 + 0.0065, time: 6.827041]
2023-05-29 14:49:05.826: epoch 114:	0.02663062  	0.19585133  	0.10932477  
2023-05-29 14:49:12.671: [iter 115 : loss : 0.1913 = 0.0242 + 0.1606 + 0.0066, time: 6.844063]
2023-05-29 14:49:12.828: epoch 115:	0.02664473  	0.19564620  	0.10915845  
2023-05-29 14:49:19.657: [iter 116 : loss : 0.1906 = 0.0234 + 0.1606 + 0.0066, time: 6.827035]
2023-05-29 14:49:19.814: epoch 116:	0.02661650  	0.19546866  	0.10919403  
2023-05-29 14:49:26.652: [iter 117 : loss : 0.1907 = 0.0236 + 0.1605 + 0.0066, time: 6.836985]
2023-05-29 14:49:26.809: epoch 117:	0.02665884  	0.19605441  	0.10938891  
2023-05-29 14:49:33.644: [iter 118 : loss : 0.1904 = 0.0233 + 0.1604 + 0.0067, time: 6.833011]
2023-05-29 14:49:33.799: epoch 118:	0.02663061  	0.19584900  	0.10929117  
2023-05-29 14:49:40.684: [iter 119 : loss : 0.1899 = 0.0228 + 0.1604 + 0.0067, time: 6.883120]
2023-05-29 14:49:40.840: epoch 119:	0.02665179  	0.19579372  	0.10931580  
2023-05-29 14:49:47.642: [iter 120 : loss : 0.1900 = 0.0229 + 0.1603 + 0.0067, time: 6.801031]
2023-05-29 14:49:47.789: epoch 120:	0.02672235  	0.19631603  	0.10946955  
2023-05-29 14:49:54.634: [iter 121 : loss : 0.1898 = 0.0228 + 0.1602 + 0.0068, time: 6.843377]
2023-05-29 14:49:54.779: epoch 121:	0.02663767  	0.19580075  	0.10934649  
2023-05-29 14:50:01.648: [iter 122 : loss : 0.1892 = 0.0222 + 0.1602 + 0.0068, time: 6.868040]
2023-05-29 14:50:01.804: epoch 122:	0.02655299  	0.19518426  	0.10917116  
2023-05-29 14:50:01.804: Early stopping is trigger at epoch: 122
2023-05-29 14:50:01.804: best_result@epoch 97:

2023-05-29 14:50:01.804: 		0.0267      	0.1981      	0.1094      
2023-05-29 15:01:52.173: my pid: 1972
2023-05-29 15:01:52.173: model: model.general_recommender.SGL
2023-05-29 15:01:52.173: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 15:01:52.173: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 15:01:55.970: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 15:02:03.412: [iter 1 : loss : 0.9272 = 0.6930 + 0.2342 + 0.0000, time: 7.442358]
2023-05-29 15:02:03.567: epoch 1:	0.00162292  	0.01110590  	0.00567180  
2023-05-29 15:02:03.568: Find a better model.
2023-05-29 15:02:11.008: [iter 2 : loss : 0.9260 = 0.6929 + 0.2331 + 0.0000, time: 7.438009]
2023-05-29 15:02:11.211: epoch 2:	0.00211685  	0.01424832  	0.00766403  
2023-05-29 15:02:11.211: Find a better model.
2023-05-29 15:02:18.603: [iter 3 : loss : 0.9258 = 0.6929 + 0.2329 + 0.0000, time: 7.391198]
2023-05-29 15:02:18.783: epoch 3:	0.00323172  	0.02142003  	0.01132064  
2023-05-29 15:02:18.784: Find a better model.
2023-05-29 15:02:26.047: [iter 4 : loss : 0.9256 = 0.6927 + 0.2328 + 0.0000, time: 7.261042]
2023-05-29 15:02:26.208: epoch 4:	0.00421251  	0.02850758  	0.01542765  
2023-05-29 15:02:26.208: Find a better model.
2023-05-29 15:02:33.391: [iter 5 : loss : 0.9254 = 0.6926 + 0.2328 + 0.0000, time: 7.182023]
2023-05-29 15:02:33.553: epoch 5:	0.00491107  	0.03282116  	0.01776243  
2023-05-29 15:02:33.553: Find a better model.
2023-05-29 15:02:40.567: [iter 6 : loss : 0.9252 = 0.6924 + 0.2328 + 0.0000, time: 7.013041]
2023-05-29 15:02:40.723: epoch 6:	0.00568723  	0.03840594  	0.02064844  
2023-05-29 15:02:40.723: Find a better model.
2023-05-29 15:02:47.766: [iter 7 : loss : 0.9249 = 0.6921 + 0.2328 + 0.0000, time: 7.041798]
2023-05-29 15:02:47.921: epoch 7:	0.00680915  	0.04649426  	0.02426017  
2023-05-29 15:02:47.921: Find a better model.
2023-05-29 15:02:54.791: [iter 8 : loss : 0.9246 = 0.6918 + 0.2328 + 0.0000, time: 6.869014]
2023-05-29 15:02:54.945: epoch 8:	0.00795223  	0.05453566  	0.02811937  
2023-05-29 15:02:54.946: Find a better model.
2023-05-29 15:03:01.776: [iter 9 : loss : 0.9242 = 0.6913 + 0.2329 + 0.0000, time: 6.829029]
2023-05-29 15:03:01.932: epoch 9:	0.00911649  	0.06307746  	0.03247634  
2023-05-29 15:03:01.932: Find a better model.
2023-05-29 15:03:08.747: [iter 10 : loss : 0.9235 = 0.6905 + 0.2330 + 0.0000, time: 6.813318]
2023-05-29 15:03:08.901: epoch 10:	0.01020319  	0.07233232  	0.03646993  
2023-05-29 15:03:08.901: Find a better model.
2023-05-29 15:03:15.599: [iter 11 : loss : 0.9225 = 0.6895 + 0.2331 + 0.0000, time: 6.694997]
2023-05-29 15:03:15.756: epoch 11:	0.01152276  	0.08195840  	0.04081580  
2023-05-29 15:03:15.756: Find a better model.
2023-05-29 15:03:22.373: [iter 12 : loss : 0.9210 = 0.6878 + 0.2332 + 0.0000, time: 6.616036]
2023-05-29 15:03:22.527: epoch 12:	0.01257417  	0.08981858  	0.04442878  
2023-05-29 15:03:22.527: Find a better model.
2023-05-29 15:03:29.162: [iter 13 : loss : 0.9186 = 0.6852 + 0.2334 + 0.0000, time: 6.634006]
2023-05-29 15:03:29.315: epoch 13:	0.01409130  	0.10192300  	0.04953949  
2023-05-29 15:03:29.315: Find a better model.
2023-05-29 15:03:35.973: [iter 14 : loss : 0.9145 = 0.6807 + 0.2338 + 0.0000, time: 6.656999]
2023-05-29 15:03:36.128: epoch 14:	0.01533322  	0.11125549  	0.05421437  
2023-05-29 15:03:36.128: Find a better model.
2023-05-29 15:03:42.747: [iter 15 : loss : 0.9076 = 0.6732 + 0.2344 + 0.0001, time: 6.618063]
2023-05-29 15:03:42.891: epoch 15:	0.01655398  	0.11901085  	0.05921198  
2023-05-29 15:03:42.891: Find a better model.
2023-05-29 15:03:49.558: [iter 16 : loss : 0.8961 = 0.6606 + 0.2355 + 0.0001, time: 6.665113]
2023-05-29 15:03:49.709: epoch 16:	0.01786646  	0.12870090  	0.06465746  
2023-05-29 15:03:49.709: Find a better model.
2023-05-29 15:03:56.368: [iter 17 : loss : 0.8779 = 0.6405 + 0.2372 + 0.0001, time: 6.658676]
2023-05-29 15:03:56.524: epoch 17:	0.01887554  	0.13732396  	0.06980795  
2023-05-29 15:03:56.525: Find a better model.
2023-05-29 15:04:03.141: [iter 18 : loss : 0.8507 = 0.6105 + 0.2400 + 0.0002, time: 6.614045]
2023-05-29 15:04:03.295: epoch 18:	0.01963765  	0.14287443  	0.07302228  
2023-05-29 15:04:03.295: Find a better model.
2023-05-29 15:04:09.938: [iter 19 : loss : 0.8118 = 0.5676 + 0.2439 + 0.0003, time: 6.642003]
2023-05-29 15:04:10.092: epoch 19:	0.02014572  	0.14781277  	0.07546022  
2023-05-29 15:04:10.092: Find a better model.
2023-05-29 15:04:16.746: [iter 20 : loss : 0.7645 = 0.5155 + 0.2486 + 0.0004, time: 6.653263]
2023-05-29 15:04:16.902: epoch 20:	0.02032919  	0.15011024  	0.07634184  
2023-05-29 15:04:16.902: Find a better model.
2023-05-29 15:04:23.545: [iter 21 : loss : 0.7119 = 0.4578 + 0.2536 + 0.0005, time: 6.641084]
2023-05-29 15:04:23.699: epoch 21:	0.02057617  	0.15177135  	0.07729062  
2023-05-29 15:04:23.699: Find a better model.
2023-05-29 15:04:30.319: [iter 22 : loss : 0.6613 = 0.4028 + 0.2579 + 0.0007, time: 6.617762]
2023-05-29 15:04:30.473: epoch 22:	0.02097133  	0.15420575  	0.07881943  
2023-05-29 15:04:30.473: Find a better model.
2023-05-29 15:04:37.139: [iter 23 : loss : 0.6164 = 0.3544 + 0.2611 + 0.0009, time: 6.665041]
2023-05-29 15:04:37.294: epoch 23:	0.02116892  	0.15615278  	0.07986797  
2023-05-29 15:04:37.294: Find a better model.
2023-05-29 15:04:43.916: [iter 24 : loss : 0.5797 = 0.3156 + 0.2631 + 0.0010, time: 6.621021]
2023-05-29 15:04:44.070: epoch 24:	0.02134533  	0.15716004  	0.08093031  
2023-05-29 15:04:44.070: Find a better model.
2023-05-29 15:04:50.719: [iter 25 : loss : 0.5486 = 0.2832 + 0.2643 + 0.0012, time: 6.646028]
2023-05-29 15:04:50.875: epoch 25:	0.02154291  	0.15858315  	0.08202314  
2023-05-29 15:04:50.875: Find a better model.
2023-05-29 15:04:57.530: [iter 26 : loss : 0.5244 = 0.2583 + 0.2648 + 0.0013, time: 6.654519]
2023-05-29 15:04:57.670: epoch 26:	0.02169110  	0.15958805  	0.08300720  
2023-05-29 15:04:57.670: Find a better model.
2023-05-29 15:05:04.292: [iter 27 : loss : 0.5023 = 0.2360 + 0.2648 + 0.0014, time: 6.618525]
2023-05-29 15:05:04.447: epoch 27:	0.02191691  	0.16138315  	0.08403795  
2023-05-29 15:05:04.447: Find a better model.
2023-05-29 15:05:11.118: [iter 28 : loss : 0.4844 = 0.2184 + 0.2645 + 0.0016, time: 6.669262]
2023-05-29 15:05:11.273: epoch 28:	0.02222739  	0.16335493  	0.08515670  
2023-05-29 15:05:11.273: Find a better model.
2023-05-29 15:05:17.943: [iter 29 : loss : 0.4697 = 0.2039 + 0.2641 + 0.0017, time: 6.669012]
2023-05-29 15:05:18.096: epoch 29:	0.02248142  	0.16569829  	0.08617771  
2023-05-29 15:05:18.097: Find a better model.
2023-05-29 15:05:24.705: [iter 30 : loss : 0.4546 = 0.1893 + 0.2635 + 0.0018, time: 6.607014]
2023-05-29 15:05:24.864: epoch 30:	0.02271429  	0.16772975  	0.08717061  
2023-05-29 15:05:24.864: Find a better model.
2023-05-29 15:05:31.506: [iter 31 : loss : 0.4431 = 0.1784 + 0.2627 + 0.0019, time: 6.641015]
2023-05-29 15:05:31.661: epoch 31:	0.02286953  	0.16916804  	0.08806286  
2023-05-29 15:05:31.661: Find a better model.
2023-05-29 15:05:38.308: [iter 32 : loss : 0.4318 = 0.1678 + 0.2620 + 0.0020, time: 6.646083]
2023-05-29 15:05:38.463: epoch 32:	0.02308123  	0.17090912  	0.08930314  
2023-05-29 15:05:38.463: Find a better model.
2023-05-29 15:05:45.112: [iter 33 : loss : 0.4230 = 0.1597 + 0.2611 + 0.0021, time: 6.647305]
2023-05-29 15:05:45.265: epoch 33:	0.02324353  	0.17236055  	0.09024686  
2023-05-29 15:05:45.265: Find a better model.
2023-05-29 15:05:51.906: [iter 34 : loss : 0.4144 = 0.1518 + 0.2604 + 0.0022, time: 6.639432]
2023-05-29 15:05:52.060: epoch 34:	0.02348345  	0.17350131  	0.09137917  
2023-05-29 15:05:52.060: Find a better model.
2023-05-29 15:05:58.738: [iter 35 : loss : 0.4066 = 0.1447 + 0.2596 + 0.0023, time: 6.677027]
2023-05-29 15:05:58.895: epoch 35:	0.02362458  	0.17466035  	0.09229093  
2023-05-29 15:05:58.895: Find a better model.
2023-05-29 15:06:05.506: [iter 36 : loss : 0.3994 = 0.1381 + 0.2589 + 0.0024, time: 6.609478]
2023-05-29 15:06:05.648: epoch 36:	0.02385039  	0.17583629  	0.09322010  
2023-05-29 15:06:05.648: Find a better model.
2023-05-29 15:06:12.290: [iter 37 : loss : 0.3920 = 0.1315 + 0.2581 + 0.0025, time: 6.641006]
2023-05-29 15:06:12.446: epoch 37:	0.02400563  	0.17680018  	0.09410716  
2023-05-29 15:06:12.446: Find a better model.
2023-05-29 15:06:19.108: [iter 38 : loss : 0.3872 = 0.1272 + 0.2574 + 0.0026, time: 6.661048]
2023-05-29 15:06:19.266: epoch 38:	0.02423849  	0.17866039  	0.09523052  
2023-05-29 15:06:19.266: Find a better model.
2023-05-29 15:06:25.900: [iter 39 : loss : 0.3803 = 0.1209 + 0.2567 + 0.0027, time: 6.632010]
2023-05-29 15:06:26.052: epoch 39:	0.02433023  	0.17989641  	0.09591469  
2023-05-29 15:06:26.052: Find a better model.
2023-05-29 15:06:32.694: [iter 40 : loss : 0.3748 = 0.1162 + 0.2559 + 0.0028, time: 6.641026]
2023-05-29 15:06:32.850: epoch 40:	0.02450664  	0.18114035  	0.09655712  
2023-05-29 15:06:32.850: Find a better model.
2023-05-29 15:06:39.510: [iter 41 : loss : 0.3707 = 0.1126 + 0.2553 + 0.0028, time: 6.659034]
2023-05-29 15:06:39.669: epoch 41:	0.02460543  	0.18169528  	0.09708688  
2023-05-29 15:06:39.669: Find a better model.
2023-05-29 15:06:46.297: [iter 42 : loss : 0.3660 = 0.1085 + 0.2546 + 0.0029, time: 6.627002]
2023-05-29 15:06:46.453: epoch 42:	0.02471833  	0.18271428  	0.09770637  
2023-05-29 15:06:46.453: Find a better model.
2023-05-29 15:06:53.270: [iter 43 : loss : 0.3607 = 0.1038 + 0.2539 + 0.0030, time: 6.815993]
2023-05-29 15:06:53.424: epoch 43:	0.02477478  	0.18294187  	0.09820323  
2023-05-29 15:06:53.424: Find a better model.
2023-05-29 15:07:00.270: [iter 44 : loss : 0.3561 = 0.0997 + 0.2533 + 0.0031, time: 6.845352]
2023-05-29 15:07:00.413: epoch 44:	0.02494414  	0.18435137  	0.09900064  
2023-05-29 15:07:00.413: Find a better model.
2023-05-29 15:07:07.073: [iter 45 : loss : 0.3519 = 0.0959 + 0.2528 + 0.0032, time: 6.657998]
2023-05-29 15:07:07.217: epoch 45:	0.02504999  	0.18539955  	0.09975312  
2023-05-29 15:07:07.217: Find a better model.
2023-05-29 15:07:13.873: [iter 46 : loss : 0.3487 = 0.0932 + 0.2523 + 0.0032, time: 6.655242]
2023-05-29 15:07:14.016: epoch 46:	0.02509232  	0.18525012  	0.10010998  
2023-05-29 15:07:20.711: [iter 47 : loss : 0.3461 = 0.0910 + 0.2517 + 0.0033, time: 6.693365]
2023-05-29 15:07:20.866: epoch 47:	0.02511349  	0.18578072  	0.10045953  
2023-05-29 15:07:20.866: Find a better model.
2023-05-29 15:07:27.659: [iter 48 : loss : 0.3416 = 0.0870 + 0.2512 + 0.0034, time: 6.791993]
2023-05-29 15:07:27.818: epoch 48:	0.02515583  	0.18606639  	0.10090893  
2023-05-29 15:07:27.818: Find a better model.
2023-05-29 15:07:34.489: [iter 49 : loss : 0.3379 = 0.0836 + 0.2508 + 0.0034, time: 6.670032]
2023-05-29 15:07:34.642: epoch 49:	0.02524051  	0.18678227  	0.10129099  
2023-05-29 15:07:34.643: Find a better model.
2023-05-29 15:07:41.266: [iter 50 : loss : 0.3357 = 0.0818 + 0.2504 + 0.0035, time: 6.622270]
2023-05-29 15:07:41.423: epoch 50:	0.02538869  	0.18832202  	0.10213993  
2023-05-29 15:07:41.423: Find a better model.
2023-05-29 15:07:48.065: [iter 51 : loss : 0.3320 = 0.0785 + 0.2500 + 0.0036, time: 6.641569]
2023-05-29 15:07:48.220: epoch 51:	0.02549453  	0.18931790  	0.10253960  
2023-05-29 15:07:48.220: Find a better model.
2023-05-29 15:07:54.868: [iter 52 : loss : 0.3308 = 0.0776 + 0.2495 + 0.0037, time: 6.646025]
2023-05-29 15:07:55.021: epoch 52:	0.02557215  	0.19011758  	0.10293969  
2023-05-29 15:07:55.021: Find a better model.
2023-05-29 15:08:01.681: [iter 53 : loss : 0.3279 = 0.0751 + 0.2491 + 0.0037, time: 6.659017]
2023-05-29 15:08:01.837: epoch 53:	0.02564977  	0.19045466  	0.10334654  
2023-05-29 15:08:01.837: Find a better model.
2023-05-29 15:08:08.640: [iter 54 : loss : 0.3253 = 0.0729 + 0.2486 + 0.0038, time: 6.802020]
2023-05-29 15:08:08.797: epoch 54:	0.02571328  	0.19095892  	0.10373610  
2023-05-29 15:08:08.797: Find a better model.
2023-05-29 15:08:15.446: [iter 55 : loss : 0.3229 = 0.0708 + 0.2483 + 0.0039, time: 6.647999]
2023-05-29 15:08:15.599: epoch 55:	0.02567800  	0.19051649  	0.10391605  
2023-05-29 15:08:22.224: [iter 56 : loss : 0.3205 = 0.0687 + 0.2479 + 0.0039, time: 6.623010]
2023-05-29 15:08:22.379: epoch 56:	0.02576268  	0.19122705  	0.10421289  
2023-05-29 15:08:22.379: Find a better model.
2023-05-29 15:08:29.045: [iter 57 : loss : 0.3186 = 0.0670 + 0.2476 + 0.0040, time: 6.663447]
2023-05-29 15:08:29.198: epoch 57:	0.02584031  	0.19182326  	0.10461421  
2023-05-29 15:08:29.198: Find a better model.
2023-05-29 15:08:35.844: [iter 58 : loss : 0.3161 = 0.0648 + 0.2473 + 0.0041, time: 6.645950]
2023-05-29 15:08:35.999: epoch 58:	0.02589676  	0.19247323  	0.10479951  
2023-05-29 15:08:35.999: Find a better model.
2023-05-29 15:08:42.644: [iter 59 : loss : 0.3145 = 0.0636 + 0.2468 + 0.0041, time: 6.644007]
2023-05-29 15:08:42.790: epoch 59:	0.02600967  	0.19339386  	0.10533305  
2023-05-29 15:08:42.790: Find a better model.
2023-05-29 15:08:49.407: [iter 60 : loss : 0.3129 = 0.0621 + 0.2466 + 0.0042, time: 6.616031]
2023-05-29 15:08:49.550: epoch 60:	0.02607317  	0.19400783  	0.10583905  
2023-05-29 15:08:49.550: Find a better model.
2023-05-29 15:08:56.058: [iter 61 : loss : 0.3110 = 0.0605 + 0.2463 + 0.0042, time: 6.506008]
2023-05-29 15:08:56.214: epoch 61:	0.02602378  	0.19301157  	0.10585565  
2023-05-29 15:09:02.851: [iter 62 : loss : 0.3091 = 0.0588 + 0.2460 + 0.0043, time: 6.636011]
2023-05-29 15:09:03.005: epoch 62:	0.02606611  	0.19307330  	0.10607112  
2023-05-29 15:09:09.644: [iter 63 : loss : 0.3075 = 0.0574 + 0.2457 + 0.0044, time: 6.638118]
2023-05-29 15:09:09.801: epoch 63:	0.02610845  	0.19352147  	0.10646124  
2023-05-29 15:09:16.443: [iter 64 : loss : 0.3063 = 0.0564 + 0.2454 + 0.0044, time: 6.640002]
2023-05-29 15:09:16.597: epoch 64:	0.02603789  	0.19298294  	0.10649487  
2023-05-29 15:09:23.229: [iter 65 : loss : 0.3048 = 0.0552 + 0.2451 + 0.0045, time: 6.629020]
2023-05-29 15:09:23.381: epoch 65:	0.02603083  	0.19265036  	0.10651939  
2023-05-29 15:09:30.018: [iter 66 : loss : 0.3031 = 0.0537 + 0.2449 + 0.0045, time: 6.630247]
2023-05-29 15:09:30.173: epoch 66:	0.02605199  	0.19272234  	0.10662463  
2023-05-29 15:09:36.812: [iter 67 : loss : 0.3012 = 0.0520 + 0.2446 + 0.0046, time: 6.638005]
2023-05-29 15:09:36.969: epoch 67:	0.02600966  	0.19243875  	0.10673333  
2023-05-29 15:09:43.631: [iter 68 : loss : 0.3005 = 0.0515 + 0.2444 + 0.0046, time: 6.661013]
2023-05-29 15:09:43.790: epoch 68:	0.02602377  	0.19229464  	0.10687178  
2023-05-29 15:09:50.421: [iter 69 : loss : 0.2988 = 0.0499 + 0.2442 + 0.0047, time: 6.630002]
2023-05-29 15:09:50.575: epoch 69:	0.02603787  	0.19228381  	0.10692523  
2023-05-29 15:09:57.216: [iter 70 : loss : 0.2974 = 0.0487 + 0.2440 + 0.0048, time: 6.640012]
2023-05-29 15:09:57.370: epoch 70:	0.02605905  	0.19269486  	0.10722835  
2023-05-29 15:10:04.028: [iter 71 : loss : 0.2958 = 0.0472 + 0.2438 + 0.0048, time: 6.656013]
2023-05-29 15:10:04.172: epoch 71:	0.02610139  	0.19318134  	0.10738466  
2023-05-29 15:10:10.627: [iter 72 : loss : 0.2951 = 0.0467 + 0.2436 + 0.0049, time: 6.451997]
2023-05-29 15:10:10.788: epoch 72:	0.02617195  	0.19355936  	0.10777366  
2023-05-29 15:10:17.407: [iter 73 : loss : 0.2937 = 0.0454 + 0.2434 + 0.0049, time: 6.618012]
2023-05-29 15:10:17.560: epoch 73:	0.02628486  	0.19403563  	0.10800689  
2023-05-29 15:10:17.560: Find a better model.
2023-05-29 15:10:24.030: [iter 74 : loss : 0.2924 = 0.0442 + 0.2432 + 0.0050, time: 6.469077]
2023-05-29 15:10:24.184: epoch 74:	0.02627780  	0.19433197  	0.10821395  
2023-05-29 15:10:24.184: Find a better model.
2023-05-29 15:10:30.803: [iter 75 : loss : 0.2917 = 0.0438 + 0.2430 + 0.0050, time: 6.617961]
2023-05-29 15:10:30.956: epoch 75:	0.02628485  	0.19455984  	0.10841886  
2023-05-29 15:10:30.956: Find a better model.
2023-05-29 15:10:37.601: [iter 76 : loss : 0.2906 = 0.0428 + 0.2427 + 0.0051, time: 6.642961]
2023-05-29 15:10:37.758: epoch 76:	0.02630602  	0.19472733  	0.10852052  
2023-05-29 15:10:37.759: Find a better model.
2023-05-29 15:10:44.426: [iter 77 : loss : 0.2896 = 0.0419 + 0.2426 + 0.0051, time: 6.665137]
2023-05-29 15:10:44.581: epoch 77:	0.02623546  	0.19394304  	0.10835622  
2023-05-29 15:10:51.202: [iter 78 : loss : 0.2889 = 0.0414 + 0.2424 + 0.0052, time: 6.620452]
2023-05-29 15:10:51.355: epoch 78:	0.02624957  	0.19411281  	0.10847546  
2023-05-29 15:10:57.991: [iter 79 : loss : 0.2875 = 0.0400 + 0.2423 + 0.0052, time: 6.634015]
2023-05-29 15:10:58.145: epoch 79:	0.02634836  	0.19480097  	0.10878910  
2023-05-29 15:10:58.145: Find a better model.
2023-05-29 15:11:04.787: [iter 80 : loss : 0.2869 = 0.0395 + 0.2421 + 0.0053, time: 6.640961]
2023-05-29 15:11:04.931: epoch 80:	0.02635541  	0.19504341  	0.10880307  
2023-05-29 15:11:04.931: Find a better model.
2023-05-29 15:11:11.586: [iter 81 : loss : 0.2861 = 0.0388 + 0.2419 + 0.0053, time: 6.653994]
2023-05-29 15:11:11.742: epoch 81:	0.02634836  	0.19529317  	0.10881306  
2023-05-29 15:11:11.742: Find a better model.
2023-05-29 15:11:18.381: [iter 82 : loss : 0.2851 = 0.0379 + 0.2418 + 0.0054, time: 6.638007]
2023-05-29 15:11:18.535: epoch 82:	0.02622840  	0.19429816  	0.10860477  
2023-05-29 15:11:25.217: [iter 83 : loss : 0.2842 = 0.0371 + 0.2416 + 0.0054, time: 6.681073]
2023-05-29 15:11:25.361: epoch 83:	0.02628485  	0.19444348  	0.10847671  
2023-05-29 15:11:31.996: [iter 84 : loss : 0.2839 = 0.0370 + 0.2415 + 0.0055, time: 6.632016]
2023-05-29 15:11:32.152: epoch 84:	0.02634131  	0.19451199  	0.10866702  
2023-05-29 15:11:38.803: [iter 85 : loss : 0.2832 = 0.0363 + 0.2414 + 0.0055, time: 6.650294]
2023-05-29 15:11:38.960: epoch 85:	0.02638365  	0.19471632  	0.10872485  
2023-05-29 15:11:45.600: [iter 86 : loss : 0.2824 = 0.0358 + 0.2411 + 0.0056, time: 6.639054]
2023-05-29 15:11:45.760: epoch 86:	0.02634836  	0.19413978  	0.10871779  
2023-05-29 15:11:52.370: [iter 87 : loss : 0.2807 = 0.0340 + 0.2411 + 0.0056, time: 6.608378]
2023-05-29 15:11:52.524: epoch 87:	0.02636247  	0.19435780  	0.10889114  
2023-05-29 15:11:59.168: [iter 88 : loss : 0.2800 = 0.0334 + 0.2409 + 0.0057, time: 6.642006]
2023-05-29 15:11:59.323: epoch 88:	0.02629896  	0.19375382  	0.10868729  
2023-05-29 15:12:05.804: [iter 89 : loss : 0.2795 = 0.0330 + 0.2408 + 0.0057, time: 6.480507]
2023-05-29 15:12:05.958: epoch 89:	0.02639069  	0.19445854  	0.10898159  
2023-05-29 15:12:12.582: [iter 90 : loss : 0.2797 = 0.0332 + 0.2407 + 0.0058, time: 6.623164]
2023-05-29 15:12:12.742: epoch 90:	0.02641892  	0.19480194  	0.10910592  
2023-05-29 15:12:19.381: [iter 91 : loss : 0.2790 = 0.0326 + 0.2405 + 0.0058, time: 6.637998]
2023-05-29 15:12:19.537: epoch 91:	0.02644715  	0.19491719  	0.10916794  
2023-05-29 15:12:26.179: [iter 92 : loss : 0.2777 = 0.0314 + 0.2404 + 0.0059, time: 6.640020]
2023-05-29 15:12:26.333: epoch 92:	0.02637658  	0.19412315  	0.10885935  
2023-05-29 15:12:32.970: [iter 93 : loss : 0.2781 = 0.0319 + 0.2403 + 0.0059, time: 6.635346]
2023-05-29 15:12:33.125: epoch 93:	0.02632719  	0.19365326  	0.10878552  
2023-05-29 15:12:39.781: [iter 94 : loss : 0.2767 = 0.0305 + 0.2402 + 0.0059, time: 6.654365]
2023-05-29 15:12:39.938: epoch 94:	0.02639070  	0.19409287  	0.10903209  
2023-05-29 15:12:46.585: [iter 95 : loss : 0.2758 = 0.0297 + 0.2401 + 0.0060, time: 6.646012]
2023-05-29 15:12:46.742: epoch 95:	0.02634130  	0.19365834  	0.10894885  
2023-05-29 15:12:53.170: [iter 96 : loss : 0.2758 = 0.0298 + 0.2400 + 0.0060, time: 6.427003]
2023-05-29 15:12:53.326: epoch 96:	0.02644714  	0.19409345  	0.10911965  
2023-05-29 15:12:59.976: [iter 97 : loss : 0.2745 = 0.0285 + 0.2399 + 0.0061, time: 6.648993]
2023-05-29 15:13:00.130: epoch 97:	0.02643303  	0.19408877  	0.10910046  
2023-05-29 15:13:06.756: [iter 98 : loss : 0.2748 = 0.0288 + 0.2398 + 0.0061, time: 6.625316]
2023-05-29 15:13:06.913: epoch 98:	0.02642598  	0.19407865  	0.10911474  
2023-05-29 15:13:13.570: [iter 99 : loss : 0.2739 = 0.0281 + 0.2397 + 0.0062, time: 6.655521]
2023-05-29 15:13:13.727: epoch 99:	0.02646126  	0.19443791  	0.10917168  
2023-05-29 15:13:20.335: [iter 100 : loss : 0.2737 = 0.0279 + 0.2396 + 0.0062, time: 6.607010]
2023-05-29 15:13:20.491: epoch 100:	0.02649654  	0.19476220  	0.10930376  
2023-05-29 15:13:26.974: [iter 101 : loss : 0.2730 = 0.0273 + 0.2395 + 0.0063, time: 6.481021]
2023-05-29 15:13:27.127: epoch 101:	0.02639069  	0.19395670  	0.10911606  
2023-05-29 15:13:33.757: [iter 102 : loss : 0.2725 = 0.0268 + 0.2394 + 0.0063, time: 6.627433]
2023-05-29 15:13:33.916: epoch 102:	0.02641186  	0.19395795  	0.10907406  
2023-05-29 15:13:40.556: [iter 103 : loss : 0.2721 = 0.0264 + 0.2393 + 0.0063, time: 6.638982]
2023-05-29 15:13:40.715: epoch 103:	0.02634130  	0.19344914  	0.10886619  
2023-05-29 15:13:47.325: [iter 104 : loss : 0.2723 = 0.0266 + 0.2392 + 0.0064, time: 6.609487]
2023-05-29 15:13:47.481: epoch 104:	0.02632013  	0.19320130  	0.10890994  
2023-05-29 15:13:54.117: [iter 105 : loss : 0.2718 = 0.0262 + 0.2391 + 0.0064, time: 6.634012]
2023-05-29 15:13:54.273: epoch 105:	0.02631308  	0.19304216  	0.10878952  
2023-05-29 15:14:00.751: [iter 106 : loss : 0.2711 = 0.0256 + 0.2390 + 0.0065, time: 6.477131]
2023-05-29 15:14:00.905: epoch 106:	0.02632719  	0.19319396  	0.10874822  
2023-05-29 15:14:00.905: Early stopping is trigger at epoch: 106
2023-05-29 15:14:00.905: best_result@epoch 81:

2023-05-29 15:14:00.905: 		0.0263      	0.1953      	0.1088      
2023-05-29 15:16:23.356: my pid: 11956
2023-05-29 15:16:23.356: model: model.general_recommender.SGL
2023-05-29 15:16:23.356: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 15:16:23.356: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 15:16:26.980: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 15:16:34.318: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.338359]
2023-05-29 15:16:34.476: epoch 1:	0.00210274  	0.01440558  	0.00737595  
2023-05-29 15:16:34.476: Find a better model.
2023-05-29 15:16:41.897: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.420066]
2023-05-29 15:16:42.103: epoch 2:	0.00429719  	0.03066518  	0.01452341  
2023-05-29 15:16:42.103: Find a better model.
2023-05-29 15:16:49.480: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.375041]
2023-05-29 15:16:49.668: epoch 3:	0.00704905  	0.05048228  	0.02513229  
2023-05-29 15:16:49.668: Find a better model.
2023-05-29 15:16:56.667: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 6.997352]
2023-05-29 15:16:56.831: epoch 4:	0.01053484  	0.07480690  	0.03655858  
2023-05-29 15:16:56.831: Find a better model.
2023-05-29 15:17:03.888: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.055945]
2023-05-29 15:17:04.050: epoch 5:	0.01372437  	0.09867904  	0.04786229  
2023-05-29 15:17:04.051: Find a better model.
2023-05-29 15:17:10.856: [iter 6 : loss : 0.7645 = 0.6855 + 0.0790 + 0.0000, time: 6.803185]
2023-05-29 15:17:11.000: epoch 6:	0.01662454  	0.11961981  	0.05961014  
2023-05-29 15:17:11.000: Find a better model.
2023-05-29 15:17:17.655: [iter 7 : loss : 0.7540 = 0.6739 + 0.0800 + 0.0000, time: 6.654175]
2023-05-29 15:17:17.810: epoch 7:	0.01829690  	0.13358620  	0.06766710  
2023-05-29 15:17:17.810: Find a better model.
2023-05-29 15:17:24.462: [iter 8 : loss : 0.7297 = 0.6469 + 0.0827 + 0.0001, time: 6.651010]
2023-05-29 15:17:24.618: epoch 8:	0.01910134  	0.14064939  	0.07046395  
2023-05-29 15:17:24.618: Find a better model.
2023-05-29 15:17:31.244: [iter 9 : loss : 0.6813 = 0.5937 + 0.0874 + 0.0002, time: 6.625013]
2023-05-29 15:17:31.399: epoch 9:	0.01876264  	0.13835619  	0.06956491  
2023-05-29 15:17:38.025: [iter 10 : loss : 0.6108 = 0.5178 + 0.0928 + 0.0003, time: 6.624340]
2023-05-29 15:17:38.181: epoch 10:	0.01858623  	0.13751401  	0.06876146  
2023-05-29 15:17:44.857: [iter 11 : loss : 0.5370 = 0.4393 + 0.0973 + 0.0005, time: 6.669016]
2023-05-29 15:17:45.014: epoch 11:	0.01850156  	0.13684438  	0.06863049  
2023-05-29 15:17:51.646: [iter 12 : loss : 0.4763 = 0.3759 + 0.0999 + 0.0006, time: 6.631081]
2023-05-29 15:17:51.789: epoch 12:	0.01856506  	0.13734837  	0.06896063  
2023-05-29 15:17:58.439: [iter 13 : loss : 0.4329 = 0.3309 + 0.1013 + 0.0008, time: 6.649024]
2023-05-29 15:17:58.595: epoch 13:	0.01872031  	0.13893443  	0.06979192  
2023-05-29 15:18:05.257: [iter 14 : loss : 0.3998 = 0.2970 + 0.1019 + 0.0009, time: 6.661015]
2023-05-29 15:18:05.414: epoch 14:	0.01886849  	0.14048503  	0.07074974  
2023-05-29 15:18:12.045: [iter 15 : loss : 0.3764 = 0.2733 + 0.1020 + 0.0010, time: 6.629765]
2023-05-29 15:18:12.198: epoch 15:	0.01916486  	0.14260003  	0.07187110  
2023-05-29 15:18:12.198: Find a better model.
2023-05-29 15:18:18.847: [iter 16 : loss : 0.3562 = 0.2531 + 0.1019 + 0.0012, time: 6.648012]
2023-05-29 15:18:19.003: epoch 16:	0.01930600  	0.14320666  	0.07258938  
2023-05-29 15:18:19.003: Find a better model.
2023-05-29 15:18:25.806: [iter 17 : loss : 0.3413 = 0.2384 + 0.1017 + 0.0013, time: 6.802115]
2023-05-29 15:18:25.950: epoch 17:	0.01961649  	0.14523831  	0.07362153  
2023-05-29 15:18:25.950: Find a better model.
2023-05-29 15:18:32.658: [iter 18 : loss : 0.3269 = 0.2242 + 0.1014 + 0.0014, time: 6.706009]
2023-05-29 15:18:32.817: epoch 18:	0.01972234  	0.14580332  	0.07439545  
2023-05-29 15:18:32.817: Find a better model.
2023-05-29 15:18:39.417: [iter 19 : loss : 0.3135 = 0.2111 + 0.1010 + 0.0014, time: 6.599014]
2023-05-29 15:18:39.562: epoch 19:	0.01989169  	0.14656706  	0.07504763  
2023-05-29 15:18:39.562: Find a better model.
2023-05-29 15:18:46.248: [iter 20 : loss : 0.3044 = 0.2023 + 0.1006 + 0.0015, time: 6.685072]
2023-05-29 15:18:46.405: epoch 20:	0.02013867  	0.14881457  	0.07588630  
2023-05-29 15:18:46.405: Find a better model.
2023-05-29 15:18:53.206: [iter 21 : loss : 0.2952 = 0.1934 + 0.1002 + 0.0016, time: 6.798978]
2023-05-29 15:18:53.362: epoch 21:	0.02032214  	0.14994220  	0.07648180  
2023-05-29 15:18:53.363: Find a better model.
2023-05-29 15:19:00.029: [iter 22 : loss : 0.2873 = 0.1859 + 0.0997 + 0.0017, time: 6.664490]
2023-05-29 15:19:00.178: epoch 22:	0.02049150  	0.15144709  	0.07726181  
2023-05-29 15:19:00.178: Find a better model.
2023-05-29 15:19:06.814: [iter 23 : loss : 0.2793 = 0.1782 + 0.0993 + 0.0018, time: 6.633065]
2023-05-29 15:19:06.955: epoch 23:	0.02078082  	0.15329358  	0.07838293  
2023-05-29 15:19:06.955: Find a better model.
2023-05-29 15:19:13.610: [iter 24 : loss : 0.2729 = 0.1722 + 0.0988 + 0.0018, time: 6.653004]
2023-05-29 15:19:13.766: epoch 24:	0.02092900  	0.15409468  	0.07874555  
2023-05-29 15:19:13.766: Find a better model.
2023-05-29 15:19:20.395: [iter 25 : loss : 0.2663 = 0.1660 + 0.0984 + 0.0019, time: 6.628183]
2023-05-29 15:19:20.541: epoch 25:	0.02102780  	0.15455736  	0.07904619  
2023-05-29 15:19:20.541: Find a better model.
2023-05-29 15:19:27.218: [iter 26 : loss : 0.2630 = 0.1630 + 0.0980 + 0.0020, time: 6.675165]
2023-05-29 15:19:27.371: epoch 26:	0.02119715  	0.15603210  	0.07990877  
2023-05-29 15:19:27.371: Find a better model.
2023-05-29 15:19:34.019: [iter 27 : loss : 0.2553 = 0.1557 + 0.0975 + 0.0021, time: 6.646182]
2023-05-29 15:19:34.174: epoch 27:	0.02135946  	0.15736029  	0.08072589  
2023-05-29 15:19:34.174: Find a better model.
2023-05-29 15:19:40.794: [iter 28 : loss : 0.2504 = 0.1512 + 0.0971 + 0.0021, time: 6.618006]
2023-05-29 15:19:40.939: epoch 28:	0.02161349  	0.15898058  	0.08171630  
2023-05-29 15:19:40.939: Find a better model.
2023-05-29 15:19:47.609: [iter 29 : loss : 0.2463 = 0.1474 + 0.0967 + 0.0022, time: 6.669004]
2023-05-29 15:19:47.762: epoch 29:	0.02177578  	0.15956260  	0.08233958  
2023-05-29 15:19:47.762: Find a better model.
2023-05-29 15:19:54.410: [iter 30 : loss : 0.2397 = 0.1411 + 0.0964 + 0.0022, time: 6.646961]
2023-05-29 15:19:54.565: epoch 30:	0.02189575  	0.16077378  	0.08321399  
2023-05-29 15:19:54.565: Find a better model.
2023-05-29 15:20:01.217: [iter 31 : loss : 0.2365 = 0.1382 + 0.0960 + 0.0023, time: 6.651043]
2023-05-29 15:20:01.372: epoch 31:	0.02200159  	0.16145942  	0.08386496  
2023-05-29 15:20:01.372: Find a better model.
2023-05-29 15:20:07.982: [iter 32 : loss : 0.2309 = 0.1329 + 0.0956 + 0.0024, time: 6.609148]
2023-05-29 15:20:08.138: epoch 32:	0.02219917  	0.16356759  	0.08476924  
2023-05-29 15:20:08.138: Find a better model.
2023-05-29 15:20:14.780: [iter 33 : loss : 0.2282 = 0.1305 + 0.0952 + 0.0024, time: 6.641222]
2023-05-29 15:20:14.921: epoch 33:	0.02241793  	0.16535458  	0.08560543  
2023-05-29 15:20:14.921: Find a better model.
2023-05-29 15:20:21.573: [iter 34 : loss : 0.2242 = 0.1268 + 0.0949 + 0.0025, time: 6.649056]
2023-05-29 15:20:21.728: epoch 34:	0.02250966  	0.16605714  	0.08625448  
2023-05-29 15:20:21.728: Find a better model.
2023-05-29 15:20:28.371: [iter 35 : loss : 0.2209 = 0.1237 + 0.0946 + 0.0025, time: 6.641706]
2023-05-29 15:20:28.526: epoch 35:	0.02258022  	0.16665928  	0.08661240  
2023-05-29 15:20:28.526: Find a better model.
2023-05-29 15:20:35.193: [iter 36 : loss : 0.2176 = 0.1208 + 0.0943 + 0.0026, time: 6.666023]
2023-05-29 15:20:35.347: epoch 36:	0.02272135  	0.16758485  	0.08743635  
2023-05-29 15:20:35.347: Find a better model.
2023-05-29 15:20:41.988: [iter 37 : loss : 0.2137 = 0.1172 + 0.0939 + 0.0026, time: 6.640028]
2023-05-29 15:20:42.144: epoch 37:	0.02287660  	0.16877571  	0.08822113  
2023-05-29 15:20:42.145: Find a better model.
2023-05-29 15:20:48.773: [iter 38 : loss : 0.2122 = 0.1159 + 0.0937 + 0.0027, time: 6.627006]
2023-05-29 15:20:48.917: epoch 38:	0.02299656  	0.17003684  	0.08890180  
2023-05-29 15:20:48.917: Find a better model.
2023-05-29 15:20:55.372: [iter 39 : loss : 0.2077 = 0.1116 + 0.0933 + 0.0028, time: 6.454025]
2023-05-29 15:20:55.515: epoch 39:	0.02306007  	0.17125002  	0.08939903  
2023-05-29 15:20:55.515: Find a better model.
2023-05-29 15:21:02.150: [iter 40 : loss : 0.2045 = 0.1087 + 0.0930 + 0.0028, time: 6.633414]
2023-05-29 15:21:02.292: epoch 40:	0.02310946  	0.17102811  	0.08970530  
2023-05-29 15:21:08.771: [iter 41 : loss : 0.2031 = 0.1074 + 0.0928 + 0.0029, time: 6.476441]
2023-05-29 15:21:08.913: epoch 41:	0.02325765  	0.17172721  	0.09020405  
2023-05-29 15:21:08.913: Find a better model.
2023-05-29 15:21:15.383: [iter 42 : loss : 0.2011 = 0.1057 + 0.0925 + 0.0029, time: 6.467004]
2023-05-29 15:21:15.536: epoch 42:	0.02334233  	0.17214090  	0.09070205  
2023-05-29 15:21:15.536: Find a better model.
2023-05-29 15:21:22.170: [iter 43 : loss : 0.1969 = 0.1018 + 0.0922 + 0.0030, time: 6.633240]
2023-05-29 15:21:22.322: epoch 43:	0.02338467  	0.17226015  	0.09109305  
2023-05-29 15:21:22.322: Find a better model.
2023-05-29 15:21:28.973: [iter 44 : loss : 0.1935 = 0.0986 + 0.0919 + 0.0030, time: 6.649431]
2023-05-29 15:21:29.128: epoch 44:	0.02347640  	0.17302367  	0.09168367  
2023-05-29 15:21:29.128: Find a better model.
2023-05-29 15:21:35.756: [iter 45 : loss : 0.1913 = 0.0965 + 0.0917 + 0.0031, time: 6.626425]
2023-05-29 15:21:35.908: epoch 45:	0.02358225  	0.17404471  	0.09224348  
2023-05-29 15:21:35.909: Find a better model.
2023-05-29 15:21:42.547: [iter 46 : loss : 0.1889 = 0.0944 + 0.0914 + 0.0031, time: 6.636193]
2023-05-29 15:21:42.699: epoch 46:	0.02365987  	0.17442900  	0.09256386  
2023-05-29 15:21:42.699: Find a better model.
2023-05-29 15:21:49.354: [iter 47 : loss : 0.1884 = 0.0940 + 0.0912 + 0.0032, time: 6.654029]
2023-05-29 15:21:49.509: epoch 47:	0.02375866  	0.17536610  	0.09299775  
2023-05-29 15:21:49.510: Find a better model.
2023-05-29 15:21:56.155: [iter 48 : loss : 0.1845 = 0.0904 + 0.0910 + 0.0032, time: 6.643162]
2023-05-29 15:21:56.309: epoch 48:	0.02381511  	0.17576489  	0.09307435  
2023-05-29 15:21:56.309: Find a better model.
2023-05-29 15:22:02.950: [iter 49 : loss : 0.1813 = 0.0873 + 0.0907 + 0.0033, time: 6.640196]
2023-05-29 15:22:03.106: epoch 49:	0.02389979  	0.17682168  	0.09378588  
2023-05-29 15:22:03.106: Find a better model.
2023-05-29 15:22:09.759: [iter 50 : loss : 0.1805 = 0.0867 + 0.0905 + 0.0033, time: 6.652015]
2023-05-29 15:22:09.901: epoch 50:	0.02401269  	0.17754416  	0.09413382  
2023-05-29 15:22:09.901: Find a better model.
2023-05-29 15:22:16.551: [iter 51 : loss : 0.1775 = 0.0838 + 0.0904 + 0.0034, time: 6.649027]
2023-05-29 15:22:16.705: epoch 51:	0.02396329  	0.17711863  	0.09430172  
2023-05-29 15:22:23.347: [iter 52 : loss : 0.1777 = 0.0841 + 0.0901 + 0.0034, time: 6.641014]
2023-05-29 15:22:23.501: epoch 52:	0.02409736  	0.17817886  	0.09497526  
2023-05-29 15:22:23.501: Find a better model.
2023-05-29 15:22:30.137: [iter 53 : loss : 0.1755 = 0.0821 + 0.0899 + 0.0035, time: 6.635054]
2023-05-29 15:22:30.289: epoch 53:	0.02418204  	0.17897773  	0.09546136  
2023-05-29 15:22:30.289: Find a better model.
2023-05-29 15:22:36.945: [iter 54 : loss : 0.1736 = 0.0803 + 0.0897 + 0.0035, time: 6.654557]
2023-05-29 15:22:37.103: epoch 54:	0.02423849  	0.17985725  	0.09600236  
2023-05-29 15:22:37.103: Find a better model.
2023-05-29 15:22:43.750: [iter 55 : loss : 0.1716 = 0.0785 + 0.0895 + 0.0036, time: 6.646134]
2023-05-29 15:22:43.904: epoch 55:	0.02431611  	0.18025142  	0.09620326  
2023-05-29 15:22:43.904: Find a better model.
2023-05-29 15:22:50.544: [iter 56 : loss : 0.1698 = 0.0769 + 0.0893 + 0.0036, time: 6.638994]
2023-05-29 15:22:50.701: epoch 56:	0.02439373  	0.18107788  	0.09654815  
2023-05-29 15:22:50.701: Find a better model.
2023-05-29 15:22:57.347: [iter 57 : loss : 0.1680 = 0.0752 + 0.0892 + 0.0036, time: 6.644169]
2023-05-29 15:22:57.500: epoch 57:	0.02449252  	0.18181925  	0.09692415  
2023-05-29 15:22:57.500: Find a better model.
2023-05-29 15:23:04.133: [iter 58 : loss : 0.1664 = 0.0736 + 0.0890 + 0.0037, time: 6.632467]
2023-05-29 15:23:04.287: epoch 58:	0.02454897  	0.18249737  	0.09735210  
2023-05-29 15:23:04.287: Find a better model.
2023-05-29 15:23:10.948: [iter 59 : loss : 0.1652 = 0.0727 + 0.0888 + 0.0037, time: 6.660292]
2023-05-29 15:23:11.104: epoch 59:	0.02460542  	0.18264203  	0.09744757  
2023-05-29 15:23:11.104: Find a better model.
2023-05-29 15:23:17.894: [iter 60 : loss : 0.1637 = 0.0712 + 0.0887 + 0.0038, time: 6.788994]
2023-05-29 15:23:18.042: epoch 60:	0.02464777  	0.18306720  	0.09791163  
2023-05-29 15:23:18.042: Find a better model.
2023-05-29 15:23:24.713: [iter 61 : loss : 0.1623 = 0.0700 + 0.0885 + 0.0038, time: 6.670024]
2023-05-29 15:23:24.855: epoch 61:	0.02473950  	0.18366961  	0.09829699  
2023-05-29 15:23:24.855: Find a better model.
2023-05-29 15:23:31.340: [iter 62 : loss : 0.1609 = 0.0687 + 0.0883 + 0.0039, time: 6.483041]
2023-05-29 15:23:31.496: epoch 62:	0.02481712  	0.18403390  	0.09872781  
2023-05-29 15:23:31.496: Find a better model.
2023-05-29 15:23:38.133: [iter 63 : loss : 0.1594 = 0.0674 + 0.0881 + 0.0039, time: 6.636022]
2023-05-29 15:23:38.276: epoch 63:	0.02483123  	0.18393737  	0.09888187  
2023-05-29 15:23:44.910: [iter 64 : loss : 0.1584 = 0.0665 + 0.0880 + 0.0040, time: 6.633027]
2023-05-29 15:23:45.057: epoch 64:	0.02492296  	0.18455824  	0.09926249  
2023-05-29 15:23:45.058: Find a better model.
2023-05-29 15:23:51.527: [iter 65 : loss : 0.1572 = 0.0653 + 0.0878 + 0.0040, time: 6.468013]
2023-05-29 15:23:51.681: epoch 65:	0.02495825  	0.18472642  	0.09986895  
2023-05-29 15:23:51.681: Find a better model.
2023-05-29 15:23:58.306: [iter 66 : loss : 0.1556 = 0.0639 + 0.0877 + 0.0040, time: 6.623019]
2023-05-29 15:23:58.462: epoch 66:	0.02509937  	0.18572891  	0.10039324  
2023-05-29 15:23:58.463: Find a better model.
2023-05-29 15:24:05.096: [iter 67 : loss : 0.1543 = 0.0627 + 0.0875 + 0.0041, time: 6.632087]
2023-05-29 15:24:05.240: epoch 67:	0.02513465  	0.18589552  	0.10074226  
2023-05-29 15:24:05.240: Find a better model.
2023-05-29 15:24:11.919: [iter 68 : loss : 0.1539 = 0.0624 + 0.0874 + 0.0041, time: 6.678003]
2023-05-29 15:24:12.077: epoch 68:	0.02526167  	0.18662974  	0.10099774  
2023-05-29 15:24:12.077: Find a better model.
2023-05-29 15:24:18.713: [iter 69 : loss : 0.1520 = 0.0605 + 0.0873 + 0.0042, time: 6.635008]
2023-05-29 15:24:18.857: epoch 69:	0.02526167  	0.18680635  	0.10111563  
2023-05-29 15:24:18.857: Find a better model.
2023-05-29 15:24:25.338: [iter 70 : loss : 0.1504 = 0.0590 + 0.0872 + 0.0042, time: 6.478005]
2023-05-29 15:24:25.494: epoch 70:	0.02540985  	0.18757123  	0.10163230  
2023-05-29 15:24:25.494: Find a better model.
2023-05-29 15:24:32.096: [iter 71 : loss : 0.1490 = 0.0577 + 0.0870 + 0.0043, time: 6.601057]
2023-05-29 15:24:32.243: epoch 71:	0.02541691  	0.18756346  	0.10181540  
2023-05-29 15:24:38.883: [iter 72 : loss : 0.1487 = 0.0575 + 0.0869 + 0.0043, time: 6.639241]
2023-05-29 15:24:39.042: epoch 72:	0.02540985  	0.18762529  	0.10194986  
2023-05-29 15:24:39.042: Find a better model.
2023-05-29 15:24:45.514: [iter 73 : loss : 0.1474 = 0.0563 + 0.0868 + 0.0043, time: 6.470994]
2023-05-29 15:24:45.668: epoch 73:	0.02548748  	0.18826227  	0.10238817  
2023-05-29 15:24:45.668: Find a better model.
2023-05-29 15:24:52.284: [iter 74 : loss : 0.1460 = 0.0549 + 0.0867 + 0.0044, time: 6.613962]
2023-05-29 15:24:52.426: epoch 74:	0.02547336  	0.18789966  	0.10243747  
2023-05-29 15:24:58.907: [iter 75 : loss : 0.1455 = 0.0546 + 0.0866 + 0.0044, time: 6.480003]
2023-05-29 15:24:59.066: epoch 75:	0.02545219  	0.18783140  	0.10251483  
2023-05-29 15:25:05.688: [iter 76 : loss : 0.1445 = 0.0536 + 0.0864 + 0.0045, time: 6.620038]
2023-05-29 15:25:05.843: epoch 76:	0.02555098  	0.18823062  	0.10293715  
2023-05-29 15:25:12.297: [iter 77 : loss : 0.1437 = 0.0529 + 0.0863 + 0.0045, time: 6.452116]
2023-05-29 15:25:12.451: epoch 77:	0.02563566  	0.18899223  	0.10316374  
2023-05-29 15:25:12.451: Find a better model.
2023-05-29 15:25:19.081: [iter 78 : loss : 0.1428 = 0.0521 + 0.0862 + 0.0045, time: 6.629190]
2023-05-29 15:25:19.238: epoch 78:	0.02569917  	0.18948203  	0.10332931  
2023-05-29 15:25:19.239: Find a better model.
2023-05-29 15:25:25.862: [iter 79 : loss : 0.1414 = 0.0507 + 0.0861 + 0.0046, time: 6.622021]
2023-05-29 15:25:26.015: epoch 79:	0.02569211  	0.18951879  	0.10348457  
2023-05-29 15:25:26.015: Find a better model.
2023-05-29 15:25:32.493: [iter 80 : loss : 0.1407 = 0.0501 + 0.0860 + 0.0046, time: 6.477308]
2023-05-29 15:25:32.645: epoch 80:	0.02577678  	0.19016117  	0.10369831  
2023-05-29 15:25:32.645: Find a better model.
2023-05-29 15:25:39.282: [iter 81 : loss : 0.1406 = 0.0500 + 0.0859 + 0.0047, time: 6.635014]
2023-05-29 15:25:39.437: epoch 81:	0.02578385  	0.19018176  	0.10379211  
2023-05-29 15:25:39.438: Find a better model.
2023-05-29 15:25:46.065: [iter 82 : loss : 0.1392 = 0.0487 + 0.0858 + 0.0047, time: 6.625879]
2023-05-29 15:25:46.219: epoch 82:	0.02592498  	0.19131398  	0.10443475  
2023-05-29 15:25:46.219: Find a better model.
2023-05-29 15:25:52.899: [iter 83 : loss : 0.1383 = 0.0479 + 0.0857 + 0.0047, time: 6.678997]
2023-05-29 15:25:53.055: epoch 83:	0.02592498  	0.19129474  	0.10439229  
2023-05-29 15:25:59.670: [iter 84 : loss : 0.1382 = 0.0478 + 0.0856 + 0.0048, time: 6.613016]
2023-05-29 15:25:59.820: epoch 84:	0.02588970  	0.19105905  	0.10436158  
2023-05-29 15:26:06.472: [iter 85 : loss : 0.1372 = 0.0469 + 0.0855 + 0.0048, time: 6.651039]
2023-05-29 15:26:06.627: epoch 85:	0.02589676  	0.19127822  	0.10472431  
2023-05-29 15:26:13.256: [iter 86 : loss : 0.1369 = 0.0467 + 0.0854 + 0.0049, time: 6.628008]
2023-05-29 15:26:13.414: epoch 86:	0.02598144  	0.19171311  	0.10483202  
2023-05-29 15:26:13.414: Find a better model.
2023-05-29 15:26:20.062: [iter 87 : loss : 0.1344 = 0.0442 + 0.0853 + 0.0049, time: 6.647031]
2023-05-29 15:26:20.216: epoch 87:	0.02608022  	0.19230136  	0.10510676  
2023-05-29 15:26:20.216: Find a better model.
2023-05-29 15:26:26.846: [iter 88 : loss : 0.1338 = 0.0436 + 0.0852 + 0.0049, time: 6.629004]
2023-05-29 15:26:27.003: epoch 88:	0.02612257  	0.19260269  	0.10516122  
2023-05-29 15:26:27.004: Find a better model.
2023-05-29 15:26:33.655: [iter 89 : loss : 0.1336 = 0.0435 + 0.0851 + 0.0050, time: 6.650055]
2023-05-29 15:26:33.812: epoch 89:	0.02608729  	0.19225830  	0.10501633  
2023-05-29 15:26:40.262: [iter 90 : loss : 0.1342 = 0.0441 + 0.0851 + 0.0050, time: 6.448007]
2023-05-29 15:26:40.417: epoch 90:	0.02622841  	0.19299175  	0.10547516  
2023-05-29 15:26:40.417: Find a better model.
2023-05-29 15:26:47.044: [iter 91 : loss : 0.1328 = 0.0428 + 0.0849 + 0.0050, time: 6.626014]
2023-05-29 15:26:47.187: epoch 91:	0.02624958  	0.19325443  	0.10565675  
2023-05-29 15:26:47.187: Find a better model.
2023-05-29 15:26:53.852: [iter 92 : loss : 0.1315 = 0.0416 + 0.0849 + 0.0051, time: 6.663997]
2023-05-29 15:26:54.006: epoch 92:	0.02628487  	0.19354039  	0.10579532  
2023-05-29 15:26:54.006: Find a better model.
2023-05-29 15:27:00.667: [iter 93 : loss : 0.1322 = 0.0423 + 0.0848 + 0.0051, time: 6.659999]
2023-05-29 15:27:00.824: epoch 93:	0.02632014  	0.19379757  	0.10602950  
2023-05-29 15:27:00.824: Find a better model.
2023-05-29 15:27:07.447: [iter 94 : loss : 0.1301 = 0.0403 + 0.0847 + 0.0052, time: 6.622038]
2023-05-29 15:27:07.601: epoch 94:	0.02637660  	0.19439307  	0.10621788  
2023-05-29 15:27:07.601: Find a better model.
2023-05-29 15:27:14.255: [iter 95 : loss : 0.1293 = 0.0395 + 0.0847 + 0.0052, time: 6.653029]
2023-05-29 15:27:14.408: epoch 95:	0.02634132  	0.19385983  	0.10619597  
2023-05-29 15:27:21.060: [iter 96 : loss : 0.1294 = 0.0396 + 0.0846 + 0.0052, time: 6.650717]
2023-05-29 15:27:21.214: epoch 96:	0.02634837  	0.19416520  	0.10639746  
2023-05-29 15:27:27.843: [iter 97 : loss : 0.1279 = 0.0381 + 0.0845 + 0.0053, time: 6.628017]
2023-05-29 15:27:27.998: epoch 97:	0.02641188  	0.19460602  	0.10654476  
2023-05-29 15:27:27.998: Find a better model.
2023-05-29 15:27:34.629: [iter 98 : loss : 0.1285 = 0.0387 + 0.0844 + 0.0053, time: 6.630464]
2023-05-29 15:27:34.783: epoch 98:	0.02648950  	0.19544178  	0.10689670  
2023-05-29 15:27:34.783: Find a better model.
2023-05-29 15:27:41.428: [iter 99 : loss : 0.1275 = 0.0378 + 0.0844 + 0.0053, time: 6.643730]
2023-05-29 15:27:41.585: epoch 99:	0.02660240  	0.19622807  	0.10719150  
2023-05-29 15:27:41.585: Find a better model.
2023-05-29 15:27:48.240: [iter 100 : loss : 0.1270 = 0.0374 + 0.0843 + 0.0054, time: 6.653062]
2023-05-29 15:27:48.384: epoch 100:	0.02659534  	0.19634928  	0.10704225  
2023-05-29 15:27:48.384: Find a better model.
2023-05-29 15:27:55.037: [iter 101 : loss : 0.1266 = 0.0370 + 0.0842 + 0.0054, time: 6.652014]
2023-05-29 15:27:55.191: epoch 101:	0.02659534  	0.19626006  	0.10712380  
2023-05-29 15:28:01.849: [iter 102 : loss : 0.1256 = 0.0360 + 0.0841 + 0.0054, time: 6.655994]
2023-05-29 15:28:02.003: epoch 102:	0.02672942  	0.19731919  	0.10752213  
2023-05-29 15:28:02.003: Find a better model.
2023-05-29 15:28:08.634: [iter 103 : loss : 0.1255 = 0.0360 + 0.0841 + 0.0055, time: 6.629010]
2023-05-29 15:28:08.787: epoch 103:	0.02673648  	0.19726895  	0.10753379  
2023-05-29 15:28:15.443: [iter 104 : loss : 0.1258 = 0.0362 + 0.0840 + 0.0055, time: 6.654070]
2023-05-29 15:28:15.597: epoch 104:	0.02680704  	0.19798554  	0.10791365  
2023-05-29 15:28:15.597: Find a better model.
2023-05-29 15:28:22.238: [iter 105 : loss : 0.1251 = 0.0357 + 0.0839 + 0.0055, time: 6.639035]
2023-05-29 15:28:22.392: epoch 105:	0.02675764  	0.19758646  	0.10784768  
2023-05-29 15:28:29.207: [iter 106 : loss : 0.1246 = 0.0351 + 0.0839 + 0.0056, time: 6.813612]
2023-05-29 15:28:29.361: epoch 106:	0.02671531  	0.19697869  	0.10761713  
2023-05-29 15:28:36.021: [iter 107 : loss : 0.1236 = 0.0342 + 0.0838 + 0.0056, time: 6.658008]
2023-05-29 15:28:36.177: epoch 107:	0.02677175  	0.19746859  	0.10774097  
2023-05-29 15:28:42.829: [iter 108 : loss : 0.1234 = 0.0340 + 0.0838 + 0.0056, time: 6.651006]
2023-05-29 15:28:42.982: epoch 108:	0.02682820  	0.19781311  	0.10798325  
2023-05-29 15:28:49.632: [iter 109 : loss : 0.1222 = 0.0329 + 0.0837 + 0.0057, time: 6.648994]
2023-05-29 15:28:49.787: epoch 109:	0.02680703  	0.19785786  	0.10787627  
2023-05-29 15:28:56.421: [iter 110 : loss : 0.1216 = 0.0322 + 0.0837 + 0.0057, time: 6.633004]
2023-05-29 15:28:56.575: epoch 110:	0.02679292  	0.19763240  	0.10780358  
2023-05-29 15:29:03.206: [iter 111 : loss : 0.1216 = 0.0322 + 0.0836 + 0.0058, time: 6.630488]
2023-05-29 15:29:03.361: epoch 111:	0.02683526  	0.19800611  	0.10797031  
2023-05-29 15:29:03.361: Find a better model.
2023-05-29 15:29:10.031: [iter 112 : loss : 0.1214 = 0.0321 + 0.0835 + 0.0058, time: 6.669123]
2023-05-29 15:29:10.187: epoch 112:	0.02689171  	0.19850136  	0.10814700  
2023-05-29 15:29:10.187: Find a better model.
2023-05-29 15:29:16.812: [iter 113 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 6.624002]
2023-05-29 15:29:16.964: epoch 113:	0.02696227  	0.19912402  	0.10831583  
2023-05-29 15:29:16.964: Find a better model.
2023-05-29 15:29:23.608: [iter 114 : loss : 0.1205 = 0.0312 + 0.0834 + 0.0058, time: 6.642049]
2023-05-29 15:29:23.763: epoch 114:	0.02699050  	0.19928259  	0.10849472  
2023-05-29 15:29:23.763: Find a better model.
2023-05-29 15:29:30.404: [iter 115 : loss : 0.1202 = 0.0309 + 0.0833 + 0.0059, time: 6.639060]
2023-05-29 15:29:30.559: epoch 115:	0.02698344  	0.19878985  	0.10843786  
2023-05-29 15:29:37.192: [iter 116 : loss : 0.1193 = 0.0301 + 0.0833 + 0.0059, time: 6.632018]
2023-05-29 15:29:37.346: epoch 116:	0.02694109  	0.19867218  	0.10839144  
2023-05-29 15:29:43.999: [iter 117 : loss : 0.1193 = 0.0301 + 0.0833 + 0.0060, time: 6.652007]
2023-05-29 15:29:44.152: epoch 117:	0.02689876  	0.19816273  	0.10824535  
2023-05-29 15:29:50.790: [iter 118 : loss : 0.1191 = 0.0300 + 0.0832 + 0.0060, time: 6.637013]
2023-05-29 15:29:50.945: epoch 118:	0.02701166  	0.19904245  	0.10852972  
2023-05-29 15:29:57.415: [iter 119 : loss : 0.1181 = 0.0290 + 0.0831 + 0.0060, time: 6.468508]
2023-05-29 15:29:57.571: epoch 119:	0.02691287  	0.19832534  	0.10845687  
2023-05-29 15:30:04.209: [iter 120 : loss : 0.1186 = 0.0294 + 0.0831 + 0.0060, time: 6.637512]
2023-05-29 15:30:04.365: epoch 120:	0.02696227  	0.19834143  	0.10862617  
2023-05-29 15:30:10.996: [iter 121 : loss : 0.1185 = 0.0293 + 0.0830 + 0.0061, time: 6.630204]
2023-05-29 15:30:11.149: epoch 121:	0.02694814  	0.19826961  	0.10873204  
2023-05-29 15:30:17.801: [iter 122 : loss : 0.1177 = 0.0286 + 0.0830 + 0.0061, time: 6.651035]
2023-05-29 15:30:17.957: epoch 122:	0.02701871  	0.19897923  	0.10888854  
2023-05-29 15:30:24.400: [iter 123 : loss : 0.1176 = 0.0285 + 0.0829 + 0.0061, time: 6.442023]
2023-05-29 15:30:24.555: epoch 123:	0.02699754  	0.19882375  	0.10871448  
2023-05-29 15:30:31.183: [iter 124 : loss : 0.1164 = 0.0274 + 0.0829 + 0.0062, time: 6.626063]
2023-05-29 15:30:31.337: epoch 124:	0.02703283  	0.19905739  	0.10866745  
2023-05-29 15:30:37.978: [iter 125 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 6.638142]
2023-05-29 15:30:38.136: epoch 125:	0.02711044  	0.19959921  	0.10894509  
2023-05-29 15:30:38.136: Find a better model.
2023-05-29 15:30:44.784: [iter 126 : loss : 0.1161 = 0.0271 + 0.0828 + 0.0062, time: 6.646993]
2023-05-29 15:30:44.939: epoch 126:	0.02702577  	0.19927193  	0.10869739  
2023-05-29 15:30:51.567: [iter 127 : loss : 0.1152 = 0.0262 + 0.0828 + 0.0063, time: 6.627543]
2023-05-29 15:30:51.723: epoch 127:	0.02700460  	0.19917302  	0.10890824  
2023-05-29 15:30:58.377: [iter 128 : loss : 0.1163 = 0.0273 + 0.0827 + 0.0063, time: 6.653077]
2023-05-29 15:30:58.534: epoch 128:	0.02708222  	0.19968748  	0.10908210  
2023-05-29 15:30:58.534: Find a better model.
2023-05-29 15:31:05.184: [iter 129 : loss : 0.1153 = 0.0263 + 0.0827 + 0.0063, time: 6.648999]
2023-05-29 15:31:05.341: epoch 129:	0.02713162  	0.20014234  	0.10924158  
2023-05-29 15:31:05.341: Find a better model.
2023-05-29 15:31:11.969: [iter 130 : loss : 0.1154 = 0.0265 + 0.0826 + 0.0063, time: 6.626446]
2023-05-29 15:31:12.126: epoch 130:	0.02715279  	0.20040327  	0.10947416  
2023-05-29 15:31:12.126: Find a better model.
2023-05-29 15:31:18.755: [iter 131 : loss : 0.1145 = 0.0255 + 0.0826 + 0.0064, time: 6.627140]
2023-05-29 15:31:18.910: epoch 131:	0.02713163  	0.20027116  	0.10949889  
2023-05-29 15:31:25.550: [iter 132 : loss : 0.1148 = 0.0259 + 0.0825 + 0.0064, time: 6.637501]
2023-05-29 15:31:25.703: epoch 132:	0.02715279  	0.20049703  	0.10955517  
2023-05-29 15:31:25.703: Find a better model.
2023-05-29 15:31:32.353: [iter 133 : loss : 0.1134 = 0.0245 + 0.0825 + 0.0064, time: 6.649016]
2023-05-29 15:31:32.507: epoch 133:	0.02714573  	0.20060767  	0.10966173  
2023-05-29 15:31:32.507: Find a better model.
2023-05-29 15:31:38.957: [iter 134 : loss : 0.1143 = 0.0254 + 0.0824 + 0.0065, time: 6.448728]
2023-05-29 15:31:39.102: epoch 134:	0.02713162  	0.20029368  	0.10969546  
2023-05-29 15:31:45.758: [iter 135 : loss : 0.1139 = 0.0250 + 0.0824 + 0.0065, time: 6.654942]
2023-05-29 15:31:45.915: epoch 135:	0.02706105  	0.19970500  	0.10943808  
2023-05-29 15:31:52.535: [iter 136 : loss : 0.1137 = 0.0248 + 0.0824 + 0.0065, time: 6.618968]
2023-05-29 15:31:52.692: epoch 136:	0.02702577  	0.19978163  	0.10933129  
2023-05-29 15:31:59.346: [iter 137 : loss : 0.1133 = 0.0244 + 0.0823 + 0.0066, time: 6.653012]
2023-05-29 15:31:59.499: epoch 137:	0.02711750  	0.20028248  	0.10958382  
2023-05-29 15:32:06.152: [iter 138 : loss : 0.1130 = 0.0241 + 0.0823 + 0.0066, time: 6.651007]
2023-05-29 15:32:06.306: epoch 138:	0.02701872  	0.19951841  	0.10919426  
2023-05-29 15:32:12.940: [iter 139 : loss : 0.1126 = 0.0238 + 0.0823 + 0.0066, time: 6.631751]
2023-05-29 15:32:13.100: epoch 139:	0.02700460  	0.19911863  	0.10918485  
2023-05-29 15:32:19.538: [iter 140 : loss : 0.1122 = 0.0233 + 0.0822 + 0.0066, time: 6.437001]
2023-05-29 15:32:19.681: epoch 140:	0.02701872  	0.19900216  	0.10910781  
2023-05-29 15:32:26.167: [iter 141 : loss : 0.1128 = 0.0239 + 0.0822 + 0.0067, time: 6.484023]
2023-05-29 15:32:26.324: epoch 141:	0.02703988  	0.19927534  	0.10943471  
2023-05-29 15:32:32.921: [iter 142 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.596008]
2023-05-29 15:32:33.069: epoch 142:	0.02712456  	0.19997281  	0.10967022  
2023-05-29 15:32:39.539: [iter 143 : loss : 0.1119 = 0.0230 + 0.0821 + 0.0067, time: 6.468170]
2023-05-29 15:32:39.694: epoch 143:	0.02713162  	0.20011081  	0.10983335  
2023-05-29 15:32:46.317: [iter 144 : loss : 0.1114 = 0.0225 + 0.0821 + 0.0068, time: 6.621417]
2023-05-29 15:32:46.472: epoch 144:	0.02705400  	0.19967462  	0.10964646  
2023-05-29 15:32:52.924: [iter 145 : loss : 0.1114 = 0.0226 + 0.0820 + 0.0068, time: 6.451770]
2023-05-29 15:32:53.081: epoch 145:	0.02711751  	0.19993113  	0.10979816  
2023-05-29 15:32:59.714: [iter 146 : loss : 0.1116 = 0.0227 + 0.0820 + 0.0068, time: 6.632007]
2023-05-29 15:32:59.868: epoch 146:	0.02706106  	0.19944778  	0.10958800  
2023-05-29 15:33:06.319: [iter 147 : loss : 0.1113 = 0.0224 + 0.0820 + 0.0068, time: 6.449424]
2023-05-29 15:33:06.461: epoch 147:	0.02704695  	0.19951330  	0.10970555  
2023-05-29 15:33:12.955: [iter 148 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 6.492007]
2023-05-29 15:33:13.112: epoch 148:	0.02713868  	0.19992046  	0.10982645  
2023-05-29 15:33:19.519: [iter 149 : loss : 0.1106 = 0.0218 + 0.0819 + 0.0069, time: 6.405042]
2023-05-29 15:33:19.661: epoch 149:	0.02713162  	0.19966954  	0.10976075  
2023-05-29 15:33:26.140: [iter 150 : loss : 0.1100 = 0.0211 + 0.0819 + 0.0069, time: 6.477004]
2023-05-29 15:33:26.292: epoch 150:	0.02715985  	0.19985652  	0.11006520  
2023-05-29 15:33:32.907: [iter 151 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 6.614058]
2023-05-29 15:33:33.053: epoch 151:	0.02716691  	0.19971186  	0.10999361  
2023-05-29 15:33:39.521: [iter 152 : loss : 0.1094 = 0.0207 + 0.0818 + 0.0070, time: 6.466004]
2023-05-29 15:33:39.677: epoch 152:	0.02712457  	0.19962360  	0.11009317  
2023-05-29 15:33:46.314: [iter 153 : loss : 0.1086 = 0.0198 + 0.0818 + 0.0070, time: 6.636068]
2023-05-29 15:33:46.468: epoch 153:	0.02711046  	0.19952373  	0.10993390  
2023-05-29 15:33:53.093: [iter 154 : loss : 0.1092 = 0.0204 + 0.0818 + 0.0070, time: 6.624109]
2023-05-29 15:33:53.238: epoch 154:	0.02721630  	0.20046939  	0.11018348  
2023-05-29 15:33:59.715: [iter 155 : loss : 0.1099 = 0.0211 + 0.0817 + 0.0070, time: 6.476068]
2023-05-29 15:33:59.870: epoch 155:	0.02713868  	0.19987808  	0.10993437  
2023-05-29 15:34:06.493: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.622031]
2023-05-29 15:34:06.646: epoch 156:	0.02710340  	0.19950077  	0.10978712  
2023-05-29 15:34:13.278: [iter 157 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.630022]
2023-05-29 15:34:13.420: epoch 157:	0.02710340  	0.19959122  	0.10979386  
2023-05-29 15:34:20.079: [iter 158 : loss : 0.1082 = 0.0194 + 0.0816 + 0.0071, time: 6.657003]
2023-05-29 15:34:20.233: epoch 158:	0.02710340  	0.19970319  	0.10975437  
2023-05-29 15:34:20.233: Early stopping is trigger at epoch: 158
2023-05-29 15:34:20.233: best_result@epoch 133:

2023-05-29 15:34:20.233: 		0.0271      	0.2006      	0.1097      
2023-05-29 15:37:16.050: my pid: 16120
2023-05-29 15:37:16.050: model: model.general_recommender.SGL
2023-05-29 15:37:16.050: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 15:37:16.050: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.02
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 15:37:19.805: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 15:37:27.276: [iter 1 : loss : 0.8500 = 0.6930 + 0.1570 + 0.0000, time: 7.471402]
2023-05-29 15:37:27.435: epoch 1:	0.00169348  	0.01180019  	0.00596375  
2023-05-29 15:37:27.435: Find a better model.
2023-05-29 15:37:34.854: [iter 2 : loss : 0.8492 = 0.6929 + 0.1564 + 0.0000, time: 7.417750]
2023-05-29 15:37:35.054: epoch 2:	0.00269546  	0.01893742  	0.00922774  
2023-05-29 15:37:35.054: Find a better model.
2023-05-29 15:37:42.482: [iter 3 : loss : 0.8490 = 0.6927 + 0.1563 + 0.0000, time: 7.427053]
2023-05-29 15:37:42.674: epoch 3:	0.00421957  	0.02969064  	0.01543269  
2023-05-29 15:37:42.675: Find a better model.
2023-05-29 15:37:49.842: [iter 4 : loss : 0.8488 = 0.6925 + 0.1563 + 0.0000, time: 7.166010]
2023-05-29 15:37:49.991: epoch 4:	0.00577896  	0.04062739  	0.02059782  
2023-05-29 15:37:49.992: Find a better model.
2023-05-29 15:37:57.237: [iter 5 : loss : 0.8485 = 0.6921 + 0.1563 + 0.0000, time: 7.243211]
2023-05-29 15:37:57.400: epoch 5:	0.00720429  	0.05107100  	0.02583100  
2023-05-29 15:37:57.400: Find a better model.
2023-05-29 15:38:04.426: [iter 6 : loss : 0.8481 = 0.6916 + 0.1565 + 0.0000, time: 7.024445]
2023-05-29 15:38:04.581: epoch 6:	0.00890480  	0.06274708  	0.03147082  
2023-05-29 15:38:04.581: Find a better model.
2023-05-29 15:38:11.442: [iter 7 : loss : 0.8472 = 0.6906 + 0.1565 + 0.0000, time: 6.860076]
2023-05-29 15:38:11.603: epoch 7:	0.01063363  	0.07578441  	0.03763976  
2023-05-29 15:38:11.603: Find a better model.
2023-05-29 15:38:18.439: [iter 8 : loss : 0.8460 = 0.6892 + 0.1567 + 0.0000, time: 6.832031]
2023-05-29 15:38:18.594: epoch 8:	0.01250359  	0.08952019  	0.04392689  
2023-05-29 15:38:18.594: Find a better model.
2023-05-29 15:38:25.235: [iter 9 : loss : 0.8435 = 0.6864 + 0.1570 + 0.0000, time: 6.640007]
2023-05-29 15:38:25.387: epoch 9:	0.01466991  	0.10619799  	0.05173459  
2023-05-29 15:38:25.387: Find a better model.
2023-05-29 15:38:31.988: [iter 10 : loss : 0.8387 = 0.6812 + 0.1575 + 0.0000, time: 6.600018]
2023-05-29 15:38:32.132: epoch 10:	0.01651164  	0.12007037  	0.05876475  
2023-05-29 15:38:32.133: Find a better model.
2023-05-29 15:38:38.833: [iter 11 : loss : 0.8296 = 0.6711 + 0.1584 + 0.0001, time: 6.699038]
2023-05-29 15:38:38.987: epoch 11:	0.01802877  	0.13144334  	0.06564341  
2023-05-29 15:38:38.987: Find a better model.
2023-05-29 15:38:45.610: [iter 12 : loss : 0.8124 = 0.6520 + 0.1603 + 0.0001, time: 6.622068]
2023-05-29 15:38:45.755: epoch 12:	0.01903078  	0.13895506  	0.07024195  
2023-05-29 15:38:45.755: Find a better model.
2023-05-29 15:38:52.592: [iter 13 : loss : 0.7835 = 0.6200 + 0.1634 + 0.0002, time: 6.835031]
2023-05-29 15:38:52.748: epoch 13:	0.01938361  	0.14249241  	0.07208327  
2023-05-29 15:38:52.748: Find a better model.
2023-05-29 15:38:59.584: [iter 14 : loss : 0.7387 = 0.5702 + 0.1682 + 0.0003, time: 6.835004]
2023-05-29 15:38:59.728: epoch 14:	0.01970821  	0.14510790  	0.07364085  
2023-05-29 15:38:59.728: Find a better model.
2023-05-29 15:39:06.596: [iter 15 : loss : 0.6817 = 0.5074 + 0.1739 + 0.0004, time: 6.866003]
2023-05-29 15:39:06.751: epoch 15:	0.01960943  	0.14493297  	0.07365122  
2023-05-29 15:39:13.589: [iter 16 : loss : 0.6207 = 0.4411 + 0.1791 + 0.0005, time: 6.837023]
2023-05-29 15:39:13.744: epoch 16:	0.01981408  	0.14652576  	0.07433674  
2023-05-29 15:39:13.744: Find a better model.
2023-05-29 15:39:20.399: [iter 17 : loss : 0.5667 = 0.3831 + 0.1829 + 0.0007, time: 6.652975]
2023-05-29 15:39:20.541: epoch 17:	0.02005401  	0.14820686  	0.07523672  
2023-05-29 15:39:20.541: Find a better model.
2023-05-29 15:39:27.223: [iter 18 : loss : 0.5220 = 0.3356 + 0.1855 + 0.0009, time: 6.680216]
2023-05-29 15:39:27.379: epoch 18:	0.02020925  	0.14939292  	0.07605369  
2023-05-29 15:39:27.379: Find a better model.
2023-05-29 15:39:34.004: [iter 19 : loss : 0.4857 = 0.2979 + 0.1869 + 0.0010, time: 6.624445]
2023-05-29 15:39:34.160: epoch 19:	0.02034332  	0.14991602  	0.07696246  
2023-05-29 15:39:34.160: Find a better model.
2023-05-29 15:39:40.806: [iter 20 : loss : 0.4591 = 0.2705 + 0.1874 + 0.0011, time: 6.644210]
2023-05-29 15:39:40.963: epoch 20:	0.02052679  	0.15152287  	0.07795229  
2023-05-29 15:39:40.963: Find a better model.
2023-05-29 15:39:47.775: [iter 21 : loss : 0.4361 = 0.2473 + 0.1875 + 0.0013, time: 6.809277]
2023-05-29 15:39:47.943: epoch 21:	0.02085138  	0.15435696  	0.07928159  
2023-05-29 15:39:47.943: Find a better model.
2023-05-29 15:39:54.810: [iter 22 : loss : 0.4178 = 0.2291 + 0.1873 + 0.0014, time: 6.866155]
2023-05-29 15:39:54.964: epoch 22:	0.02105602  	0.15548703  	0.08004349  
2023-05-29 15:39:54.964: Find a better model.
2023-05-29 15:40:01.796: [iter 23 : loss : 0.4018 = 0.2134 + 0.1869 + 0.0015, time: 6.831030]
2023-05-29 15:40:01.950: epoch 23:	0.02126772  	0.15707196  	0.08104414  
2023-05-29 15:40:01.950: Find a better model.
2023-05-29 15:40:08.800: [iter 24 : loss : 0.3887 = 0.2009 + 0.1862 + 0.0016, time: 6.849236]
2023-05-29 15:40:08.957: epoch 24:	0.02150765  	0.15898342  	0.08213108  
2023-05-29 15:40:08.957: Find a better model.
2023-05-29 15:40:15.962: [iter 25 : loss : 0.3767 = 0.1894 + 0.1856 + 0.0017, time: 7.003993]
2023-05-29 15:40:16.116: epoch 25:	0.02172640  	0.16061702  	0.08291051  
2023-05-29 15:40:16.117: Find a better model.
2023-05-29 15:40:23.182: [iter 26 : loss : 0.3680 = 0.1812 + 0.1849 + 0.0018, time: 7.062687]
2023-05-29 15:40:23.338: epoch 26:	0.02199455  	0.16220607  	0.08386304  
2023-05-29 15:40:23.338: Find a better model.
2023-05-29 15:40:30.378: [iter 27 : loss : 0.3570 = 0.1709 + 0.1842 + 0.0019, time: 7.039082]
2023-05-29 15:40:30.531: epoch 27:	0.02217801  	0.16336031  	0.08494635  
2023-05-29 15:40:30.531: Find a better model.
2023-05-29 15:40:37.400: [iter 28 : loss : 0.3484 = 0.1630 + 0.1834 + 0.0020, time: 6.866946]
2023-05-29 15:40:37.553: epoch 28:	0.02235443  	0.16486344  	0.08591253  
2023-05-29 15:40:37.553: Find a better model.
2023-05-29 15:40:44.563: [iter 29 : loss : 0.3412 = 0.1564 + 0.1827 + 0.0021, time: 7.009749]
2023-05-29 15:40:44.719: epoch 29:	0.02260845  	0.16676483  	0.08706603  
2023-05-29 15:40:44.719: Find a better model.
2023-05-29 15:40:51.553: [iter 30 : loss : 0.3325 = 0.1483 + 0.1821 + 0.0022, time: 6.833019]
2023-05-29 15:40:51.697: epoch 30:	0.02277076  	0.16797768  	0.08778417  
2023-05-29 15:40:51.697: Find a better model.
2023-05-29 15:40:58.571: [iter 31 : loss : 0.3267 = 0.1431 + 0.1813 + 0.0023, time: 6.871521]
2023-05-29 15:40:58.715: epoch 31:	0.02289071  	0.16875339  	0.08826484  
2023-05-29 15:40:58.715: Find a better model.
2023-05-29 15:41:05.565: [iter 32 : loss : 0.3194 = 0.1364 + 0.1807 + 0.0024, time: 6.849058]
2023-05-29 15:41:05.723: epoch 32:	0.02304595  	0.17023422  	0.08941763  
2023-05-29 15:41:05.724: Find a better model.
2023-05-29 15:41:12.573: [iter 33 : loss : 0.3146 = 0.1322 + 0.1800 + 0.0024, time: 6.848032]
2023-05-29 15:41:12.733: epoch 33:	0.02318708  	0.17115240  	0.09008783  
2023-05-29 15:41:12.733: Find a better model.
2023-05-29 15:41:19.767: [iter 34 : loss : 0.3091 = 0.1273 + 0.1793 + 0.0025, time: 7.033072]
2023-05-29 15:41:19.922: epoch 34:	0.02344112  	0.17331387  	0.09113306  
2023-05-29 15:41:19.922: Find a better model.
2023-05-29 15:41:26.770: [iter 35 : loss : 0.3042 = 0.1228 + 0.1788 + 0.0026, time: 6.846996]
2023-05-29 15:41:26.928: epoch 35:	0.02358225  	0.17435135  	0.09181719  
2023-05-29 15:41:26.928: Find a better model.
2023-05-29 15:41:33.959: [iter 36 : loss : 0.2998 = 0.1190 + 0.1782 + 0.0027, time: 7.029993]
2023-05-29 15:41:34.114: epoch 36:	0.02365987  	0.17500675  	0.09260416  
2023-05-29 15:41:34.114: Find a better model.
2023-05-29 15:41:40.985: [iter 37 : loss : 0.2946 = 0.1143 + 0.1776 + 0.0027, time: 6.870051]
2023-05-29 15:41:41.139: epoch 37:	0.02381511  	0.17603429  	0.09316890  
2023-05-29 15:41:41.139: Find a better model.
2023-05-29 15:41:47.951: [iter 38 : loss : 0.2919 = 0.1121 + 0.1771 + 0.0028, time: 6.811038]
2023-05-29 15:41:48.108: epoch 38:	0.02390685  	0.17718674  	0.09390258  
2023-05-29 15:41:48.108: Find a better model.
2023-05-29 15:41:55.123: [iter 39 : loss : 0.2866 = 0.1073 + 0.1765 + 0.0029, time: 7.014012]
2023-05-29 15:41:55.277: epoch 39:	0.02401975  	0.17836550  	0.09455251  
2023-05-29 15:41:55.277: Find a better model.
2023-05-29 15:42:02.153: [iter 40 : loss : 0.2827 = 0.1038 + 0.1759 + 0.0029, time: 6.874678]
2023-05-29 15:42:02.308: epoch 40:	0.02418205  	0.17922048  	0.09523577  
2023-05-29 15:42:02.309: Find a better model.
2023-05-29 15:42:09.154: [iter 41 : loss : 0.2803 = 0.1017 + 0.1755 + 0.0030, time: 6.844000]
2023-05-29 15:42:09.311: epoch 41:	0.02433023  	0.18044674  	0.09606521  
2023-05-29 15:42:09.311: Find a better model.
2023-05-29 15:42:16.159: [iter 42 : loss : 0.2770 = 0.0990 + 0.1750 + 0.0031, time: 6.847064]
2023-05-29 15:42:16.315: epoch 42:	0.02437963  	0.18049587  	0.09642588  
2023-05-29 15:42:16.315: Find a better model.
2023-05-29 15:42:23.327: [iter 43 : loss : 0.2727 = 0.0951 + 0.1745 + 0.0031, time: 7.010993]
2023-05-29 15:42:23.483: epoch 43:	0.02452076  	0.18122613  	0.09696189  
2023-05-29 15:42:23.483: Find a better model.
2023-05-29 15:42:30.362: [iter 44 : loss : 0.2690 = 0.0918 + 0.1740 + 0.0032, time: 6.878110]
2023-05-29 15:42:30.506: epoch 44:	0.02461955  	0.18197651  	0.09746040  
2023-05-29 15:42:30.506: Find a better model.
2023-05-29 15:42:37.329: [iter 45 : loss : 0.2659 = 0.0889 + 0.1737 + 0.0033, time: 6.822504]
2023-05-29 15:42:37.472: epoch 45:	0.02467600  	0.18240629  	0.09801965  
2023-05-29 15:42:37.472: Find a better model.
2023-05-29 15:42:44.331: [iter 46 : loss : 0.2633 = 0.0867 + 0.1732 + 0.0033, time: 6.857088]
2023-05-29 15:42:44.488: epoch 46:	0.02471128  	0.18255371  	0.09842201  
2023-05-29 15:42:44.488: Find a better model.
2023-05-29 15:42:51.344: [iter 47 : loss : 0.2620 = 0.0858 + 0.1728 + 0.0034, time: 6.855431]
2023-05-29 15:42:51.499: epoch 47:	0.02478185  	0.18316859  	0.09901565  
2023-05-29 15:42:51.499: Find a better model.
2023-05-29 15:42:58.328: [iter 48 : loss : 0.2581 = 0.0821 + 0.1725 + 0.0035, time: 6.828016]
2023-05-29 15:42:58.469: epoch 48:	0.02496532  	0.18453048  	0.09967957  
2023-05-29 15:42:58.469: Find a better model.
2023-05-29 15:43:05.331: [iter 49 : loss : 0.2548 = 0.0791 + 0.1721 + 0.0035, time: 6.861022]
2023-05-29 15:43:05.472: epoch 49:	0.02490886  	0.18401909  	0.09974629  
2023-05-29 15:43:12.326: [iter 50 : loss : 0.2533 = 0.0779 + 0.1718 + 0.0036, time: 6.851198]
2023-05-29 15:43:12.481: epoch 50:	0.02501471  	0.18490055  	0.10032362  
2023-05-29 15:43:12.481: Find a better model.
2023-05-29 15:43:19.140: [iter 51 : loss : 0.2504 = 0.0752 + 0.1715 + 0.0036, time: 6.657279]
2023-05-29 15:43:19.293: epoch 51:	0.02500060  	0.18463136  	0.10055008  
2023-05-29 15:43:26.122: [iter 52 : loss : 0.2498 = 0.0749 + 0.1711 + 0.0037, time: 6.827267]
2023-05-29 15:43:26.276: epoch 52:	0.02519817  	0.18603536  	0.10135107  
2023-05-29 15:43:26.276: Find a better model.
2023-05-29 15:43:33.122: [iter 53 : loss : 0.2474 = 0.0728 + 0.1708 + 0.0038, time: 6.845000]
2023-05-29 15:43:33.273: epoch 53:	0.02529697  	0.18693897  	0.10183869  
2023-05-29 15:43:33.273: Find a better model.
2023-05-29 15:43:40.111: [iter 54 : loss : 0.2452 = 0.0709 + 0.1705 + 0.0038, time: 6.836019]
2023-05-29 15:43:40.266: epoch 54:	0.02533225  	0.18711096  	0.10215478  
2023-05-29 15:43:40.266: Find a better model.
2023-05-29 15:43:47.130: [iter 55 : loss : 0.2432 = 0.0692 + 0.1702 + 0.0039, time: 6.863000]
2023-05-29 15:43:47.285: epoch 55:	0.02539575  	0.18724434  	0.10235091  
2023-05-29 15:43:47.285: Find a better model.
2023-05-29 15:43:54.108: [iter 56 : loss : 0.2411 = 0.0673 + 0.1699 + 0.0039, time: 6.822112]
2023-05-29 15:43:54.262: epoch 56:	0.02548042  	0.18811578  	0.10286630  
2023-05-29 15:43:54.262: Find a better model.
2023-05-29 15:44:01.137: [iter 57 : loss : 0.2392 = 0.0655 + 0.1697 + 0.0040, time: 6.874053]
2023-05-29 15:44:01.291: epoch 57:	0.02553688  	0.18847035  	0.10299022  
2023-05-29 15:44:01.291: Find a better model.
2023-05-29 15:44:08.105: [iter 58 : loss : 0.2374 = 0.0640 + 0.1694 + 0.0040, time: 6.812431]
2023-05-29 15:44:08.258: epoch 58:	0.02556511  	0.18891922  	0.10320856  
2023-05-29 15:44:08.258: Find a better model.
2023-05-29 15:44:15.098: [iter 59 : loss : 0.2362 = 0.0631 + 0.1691 + 0.0041, time: 6.839026]
2023-05-29 15:44:15.251: epoch 59:	0.02563567  	0.18943772  	0.10361993  
2023-05-29 15:44:15.252: Find a better model.
2023-05-29 15:44:22.106: [iter 60 : loss : 0.2345 = 0.0615 + 0.1689 + 0.0041, time: 6.852000]
2023-05-29 15:44:22.266: epoch 60:	0.02567801  	0.19005641  	0.10401639  
2023-05-29 15:44:22.266: Find a better model.
2023-05-29 15:44:29.090: [iter 61 : loss : 0.2331 = 0.0603 + 0.1686 + 0.0042, time: 6.823569]
2023-05-29 15:44:29.247: epoch 61:	0.02574858  	0.19030274  	0.10440698  
2023-05-29 15:44:29.247: Find a better model.
2023-05-29 15:44:35.914: [iter 62 : loss : 0.2315 = 0.0589 + 0.1684 + 0.0042, time: 6.665691]
2023-05-29 15:44:36.070: epoch 62:	0.02593205  	0.19175377  	0.10493515  
2023-05-29 15:44:36.070: Find a better model.
2023-05-29 15:44:42.890: [iter 63 : loss : 0.2301 = 0.0577 + 0.1681 + 0.0043, time: 6.818045]
2023-05-29 15:44:43.044: epoch 63:	0.02590382  	0.19161153  	0.10497221  
2023-05-29 15:44:49.883: [iter 64 : loss : 0.2289 = 0.0566 + 0.1679 + 0.0043, time: 6.838127]
2023-05-29 15:44:50.038: epoch 64:	0.02594616  	0.19206344  	0.10527232  
2023-05-29 15:44:50.038: Find a better model.
2023-05-29 15:44:56.898: [iter 65 : loss : 0.2277 = 0.0556 + 0.1677 + 0.0044, time: 6.859022]
2023-05-29 15:44:57.057: epoch 65:	0.02599555  	0.19256262  	0.10554513  
2023-05-29 15:44:57.057: Find a better model.
2023-05-29 15:45:03.870: [iter 66 : loss : 0.2260 = 0.0541 + 0.1675 + 0.0045, time: 6.812140]
2023-05-29 15:45:04.017: epoch 66:	0.02607317  	0.19304700  	0.10584699  
2023-05-29 15:45:04.017: Find a better model.
2023-05-29 15:45:10.701: [iter 67 : loss : 0.2247 = 0.0530 + 0.1673 + 0.0045, time: 6.683053]
2023-05-29 15:45:10.856: epoch 67:	0.02606612  	0.19277158  	0.10587458  
2023-05-29 15:45:17.684: [iter 68 : loss : 0.2241 = 0.0525 + 0.1671 + 0.0046, time: 6.827004]
2023-05-29 15:45:17.837: epoch 68:	0.02625664  	0.19397980  	0.10645330  
2023-05-29 15:45:17.838: Find a better model.
2023-05-29 15:45:24.678: [iter 69 : loss : 0.2224 = 0.0509 + 0.1669 + 0.0046, time: 6.839110]
2023-05-29 15:45:24.834: epoch 69:	0.02624958  	0.19395807  	0.10655904  
2023-05-29 15:45:31.516: [iter 70 : loss : 0.2209 = 0.0495 + 0.1667 + 0.0047, time: 6.680169]
2023-05-29 15:45:31.673: epoch 70:	0.02633426  	0.19482012  	0.10694754  
2023-05-29 15:45:31.674: Find a better model.
2023-05-29 15:45:38.462: [iter 71 : loss : 0.2197 = 0.0484 + 0.1666 + 0.0047, time: 6.786457]
2023-05-29 15:45:38.604: epoch 71:	0.02635543  	0.19505201  	0.10701054  
2023-05-29 15:45:38.604: Find a better model.
2023-05-29 15:45:45.470: [iter 72 : loss : 0.2191 = 0.0479 + 0.1664 + 0.0048, time: 6.865382]
2023-05-29 15:45:45.628: epoch 72:	0.02634837  	0.19496059  	0.10693213  
2023-05-29 15:45:52.445: [iter 73 : loss : 0.2178 = 0.0468 + 0.1662 + 0.0048, time: 6.816048]
2023-05-29 15:45:52.588: epoch 73:	0.02643305  	0.19543476  	0.10712131  
2023-05-29 15:45:52.589: Find a better model.
2023-05-29 15:45:59.293: [iter 74 : loss : 0.2167 = 0.0458 + 0.1661 + 0.0048, time: 6.701455]
2023-05-29 15:45:59.450: epoch 74:	0.02653890  	0.19635135  	0.10753900  
2023-05-29 15:45:59.450: Find a better model.
2023-05-29 15:46:06.246: [iter 75 : loss : 0.2160 = 0.0452 + 0.1659 + 0.0049, time: 6.795036]
2023-05-29 15:46:06.403: epoch 75:	0.02658124  	0.19655739  	0.10762448  
2023-05-29 15:46:06.403: Find a better model.
2023-05-29 15:46:13.088: [iter 76 : loss : 0.2151 = 0.0444 + 0.1657 + 0.0049, time: 6.684004]
2023-05-29 15:46:13.245: epoch 76:	0.02660947  	0.19689006  	0.10779990  
2023-05-29 15:46:13.245: Find a better model.
2023-05-29 15:46:20.035: [iter 77 : loss : 0.2141 = 0.0436 + 0.1655 + 0.0050, time: 6.789025]
2023-05-29 15:46:20.191: epoch 77:	0.02663769  	0.19702235  	0.10783324  
2023-05-29 15:46:20.192: Find a better model.
2023-05-29 15:46:26.856: [iter 78 : loss : 0.2135 = 0.0431 + 0.1654 + 0.0050, time: 6.663040]
2023-05-29 15:46:26.999: epoch 78:	0.02668003  	0.19727039  	0.10803974  
2023-05-29 15:46:26.999: Find a better model.
2023-05-29 15:46:33.838: [iter 79 : loss : 0.2121 = 0.0417 + 0.1653 + 0.0051, time: 6.836120]
2023-05-29 15:46:33.994: epoch 79:	0.02668709  	0.19709900  	0.10803249  
2023-05-29 15:46:40.651: [iter 80 : loss : 0.2114 = 0.0411 + 0.1651 + 0.0051, time: 6.655335]
2023-05-29 15:46:40.795: epoch 80:	0.02663769  	0.19665813  	0.10799343  
2023-05-29 15:46:47.645: [iter 81 : loss : 0.2111 = 0.0409 + 0.1650 + 0.0052, time: 6.848999]
2023-05-29 15:46:47.800: epoch 81:	0.02659535  	0.19627471  	0.10788172  
2023-05-29 15:46:54.629: [iter 82 : loss : 0.2099 = 0.0398 + 0.1649 + 0.0052, time: 6.828018]
2023-05-29 15:46:54.786: epoch 82:	0.02657419  	0.19607131  	0.10781401  
2023-05-29 15:47:01.659: [iter 83 : loss : 0.2091 = 0.0390 + 0.1648 + 0.0053, time: 6.872194]
2023-05-29 15:47:01.804: epoch 83:	0.02655301  	0.19570601  	0.10783961  
2023-05-29 15:47:08.655: [iter 84 : loss : 0.2089 = 0.0389 + 0.1646 + 0.0053, time: 6.850022]
2023-05-29 15:47:08.813: epoch 84:	0.02671531  	0.19687109  	0.10826623  
2023-05-29 15:47:15.617: [iter 85 : loss : 0.2081 = 0.0383 + 0.1645 + 0.0053, time: 6.802430]
2023-05-29 15:47:15.772: epoch 85:	0.02666592  	0.19643976  	0.10825687  
2023-05-29 15:47:22.617: [iter 86 : loss : 0.2075 = 0.0378 + 0.1643 + 0.0054, time: 6.844173]
2023-05-29 15:47:22.776: epoch 86:	0.02670827  	0.19679356  	0.10842138  
2023-05-29 15:47:29.608: [iter 87 : loss : 0.2057 = 0.0360 + 0.1643 + 0.0054, time: 6.831023]
2023-05-29 15:47:29.764: epoch 87:	0.02682822  	0.19762407  	0.10871793  
2023-05-29 15:47:29.764: Find a better model.
2023-05-29 15:47:36.426: [iter 88 : loss : 0.2051 = 0.0355 + 0.1641 + 0.0055, time: 6.661011]
2023-05-29 15:47:36.582: epoch 88:	0.02675765  	0.19733845  	0.10855755  
2023-05-29 15:47:43.254: [iter 89 : loss : 0.2045 = 0.0350 + 0.1640 + 0.0055, time: 6.671251]
2023-05-29 15:47:43.409: epoch 89:	0.02671531  	0.19704358  	0.10849975  
2023-05-29 15:47:50.043: [iter 90 : loss : 0.2049 = 0.0354 + 0.1639 + 0.0056, time: 6.633037]
2023-05-29 15:47:50.199: epoch 90:	0.02682116  	0.19759727  	0.10865641  
2023-05-29 15:47:56.820: [iter 91 : loss : 0.2040 = 0.0346 + 0.1638 + 0.0056, time: 6.619025]
2023-05-29 15:47:56.962: epoch 91:	0.02689878  	0.19793151  	0.10892147  
2023-05-29 15:47:56.963: Find a better model.
2023-05-29 15:48:03.625: [iter 92 : loss : 0.2028 = 0.0335 + 0.1637 + 0.0056, time: 6.660994]
2023-05-29 15:48:03.781: epoch 92:	0.02691995  	0.19874735  	0.10894240  
2023-05-29 15:48:03.781: Find a better model.
2023-05-29 15:48:10.609: [iter 93 : loss : 0.2033 = 0.0341 + 0.1636 + 0.0057, time: 6.826993]
2023-05-29 15:48:10.764: epoch 93:	0.02686350  	0.19806084  	0.10880428  
2023-05-29 15:48:17.614: [iter 94 : loss : 0.2017 = 0.0324 + 0.1635 + 0.0057, time: 6.849333]
2023-05-29 15:48:17.769: epoch 94:	0.02690584  	0.19849205  	0.10896502  
2023-05-29 15:48:24.606: [iter 95 : loss : 0.2009 = 0.0317 + 0.1634 + 0.0058, time: 6.836465]
2023-05-29 15:48:24.749: epoch 95:	0.02694112  	0.19852421  	0.10901280  
2023-05-29 15:48:31.441: [iter 96 : loss : 0.2010 = 0.0318 + 0.1633 + 0.0058, time: 6.690382]
2023-05-29 15:48:31.585: epoch 96:	0.02693406  	0.19840595  	0.10902490  
2023-05-29 15:48:38.208: [iter 97 : loss : 0.1997 = 0.0307 + 0.1632 + 0.0058, time: 6.622530]
2023-05-29 15:48:38.361: epoch 97:	0.02696228  	0.19890946  	0.10936341  
2023-05-29 15:48:38.361: Find a better model.
2023-05-29 15:48:45.189: [iter 98 : loss : 0.1999 = 0.0309 + 0.1631 + 0.0059, time: 6.826999]
2023-05-29 15:48:45.333: epoch 98:	0.02699052  	0.19904149  	0.10944228  
2023-05-29 15:48:45.333: Find a better model.
2023-05-29 15:48:52.006: [iter 99 : loss : 0.1991 = 0.0302 + 0.1630 + 0.0059, time: 6.672010]
2023-05-29 15:48:52.163: epoch 99:	0.02706108  	0.19954512  	0.10949227  
2023-05-29 15:48:52.163: Find a better model.
2023-05-29 15:48:58.982: [iter 100 : loss : 0.1988 = 0.0299 + 0.1629 + 0.0060, time: 6.817147]
2023-05-29 15:48:59.137: epoch 100:	0.02706813  	0.19942681  	0.10964870  
2023-05-29 15:49:05.987: [iter 101 : loss : 0.1983 = 0.0294 + 0.1629 + 0.0060, time: 6.848047]
2023-05-29 15:49:06.143: epoch 101:	0.02710341  	0.19958155  	0.10983575  
2023-05-29 15:49:06.143: Find a better model.
2023-05-29 15:49:12.992: [iter 102 : loss : 0.1976 = 0.0287 + 0.1628 + 0.0060, time: 6.848361]
2023-05-29 15:49:13.148: epoch 102:	0.02710341  	0.19934680  	0.10967335  
2023-05-29 15:49:19.801: [iter 103 : loss : 0.1974 = 0.0286 + 0.1627 + 0.0061, time: 6.651993]
2023-05-29 15:49:19.957: epoch 103:	0.02714575  	0.19961293  	0.10990372  
2023-05-29 15:49:19.958: Find a better model.
2023-05-29 15:49:26.771: [iter 104 : loss : 0.1976 = 0.0288 + 0.1626 + 0.0061, time: 6.811993]
2023-05-29 15:49:26.929: epoch 104:	0.02713164  	0.19963200  	0.10998818  
2023-05-29 15:49:26.929: Find a better model.
2023-05-29 15:49:33.768: [iter 105 : loss : 0.1971 = 0.0284 + 0.1625 + 0.0062, time: 6.837994]
2023-05-29 15:49:33.922: epoch 105:	0.02707519  	0.19979945  	0.10993692  
2023-05-29 15:49:33.922: Find a better model.
2023-05-29 15:49:40.584: [iter 106 : loss : 0.1965 = 0.0278 + 0.1625 + 0.0062, time: 6.660959]
2023-05-29 15:49:40.730: epoch 106:	0.02706107  	0.19968465  	0.10986719  
2023-05-29 15:49:47.571: [iter 107 : loss : 0.1958 = 0.0272 + 0.1624 + 0.0062, time: 6.839715]
2023-05-29 15:49:47.717: epoch 107:	0.02703990  	0.19972621  	0.10998560  
2023-05-29 15:49:54.571: [iter 108 : loss : 0.1955 = 0.0269 + 0.1624 + 0.0063, time: 6.851999]
2023-05-29 15:49:54.729: epoch 108:	0.02702579  	0.19956402  	0.10998055  
2023-05-29 15:50:01.408: [iter 109 : loss : 0.1946 = 0.0260 + 0.1622 + 0.0063, time: 6.678427]
2023-05-29 15:50:01.564: epoch 109:	0.02701874  	0.19961156  	0.10990693  
2023-05-29 15:50:08.186: [iter 110 : loss : 0.1942 = 0.0256 + 0.1622 + 0.0063, time: 6.620020]
2023-05-29 15:50:08.342: epoch 110:	0.02702579  	0.19980015  	0.11006062  
2023-05-29 15:50:08.343: Find a better model.
2023-05-29 15:50:14.980: [iter 111 : loss : 0.1939 = 0.0254 + 0.1621 + 0.0064, time: 6.636105]
2023-05-29 15:50:15.127: epoch 111:	0.02703990  	0.19975291  	0.11005849  
2023-05-29 15:50:21.945: [iter 112 : loss : 0.1937 = 0.0253 + 0.1621 + 0.0064, time: 6.816024]
2023-05-29 15:50:22.102: epoch 112:	0.02708224  	0.19974598  	0.11006186  
2023-05-29 15:50:28.763: [iter 113 : loss : 0.1937 = 0.0253 + 0.1620 + 0.0065, time: 6.660014]
2023-05-29 15:50:28.917: epoch 113:	0.02703285  	0.19947946  	0.10986765  
2023-05-29 15:50:35.575: [iter 114 : loss : 0.1929 = 0.0246 + 0.1619 + 0.0065, time: 6.657053]
2023-05-29 15:50:35.733: epoch 114:	0.02713164  	0.19997895  	0.11003830  
2023-05-29 15:50:35.733: Find a better model.
2023-05-29 15:50:42.366: [iter 115 : loss : 0.1928 = 0.0244 + 0.1618 + 0.0065, time: 6.632179]
2023-05-29 15:50:42.521: epoch 115:	0.02713164  	0.19992244  	0.10991973  
2023-05-29 15:50:49.145: [iter 116 : loss : 0.1921 = 0.0238 + 0.1618 + 0.0066, time: 6.623056]
2023-05-29 15:50:49.300: epoch 116:	0.02707518  	0.19940208  	0.11007034  
2023-05-29 15:50:55.953: [iter 117 : loss : 0.1921 = 0.0238 + 0.1617 + 0.0066, time: 6.651628]
2023-05-29 15:50:56.109: epoch 117:	0.02703990  	0.19940813  	0.10995658  
2023-05-29 15:51:02.749: [iter 118 : loss : 0.1918 = 0.0235 + 0.1617 + 0.0066, time: 6.639038]
2023-05-29 15:51:02.904: epoch 118:	0.02700461  	0.19856367  	0.10978563  
2023-05-29 15:51:09.559: [iter 119 : loss : 0.1911 = 0.0228 + 0.1616 + 0.0067, time: 6.652497]
2023-05-29 15:51:09.717: epoch 119:	0.02706813  	0.19914699  	0.10992221  
2023-05-29 15:51:16.358: [iter 120 : loss : 0.1914 = 0.0231 + 0.1615 + 0.0067, time: 6.640003]
2023-05-29 15:51:16.515: epoch 120:	0.02703284  	0.19853741  	0.10991810  
2023-05-29 15:51:23.147: [iter 121 : loss : 0.1912 = 0.0230 + 0.1615 + 0.0067, time: 6.630008]
2023-05-29 15:51:23.290: epoch 121:	0.02703284  	0.19873330  	0.10989382  
2023-05-29 15:51:29.968: [iter 122 : loss : 0.1907 = 0.0225 + 0.1614 + 0.0068, time: 6.677042]
2023-05-29 15:51:30.125: epoch 122:	0.02697639  	0.19821082  	0.10987193  
2023-05-29 15:51:36.741: [iter 123 : loss : 0.1905 = 0.0224 + 0.1614 + 0.0068, time: 6.614046]
2023-05-29 15:51:36.886: epoch 123:	0.02701167  	0.19837561  	0.10995036  
2023-05-29 15:51:43.546: [iter 124 : loss : 0.1895 = 0.0213 + 0.1613 + 0.0068, time: 6.659014]
2023-05-29 15:51:43.693: epoch 124:	0.02698344  	0.19829170  	0.10989242  
2023-05-29 15:51:50.345: [iter 125 : loss : 0.1893 = 0.0212 + 0.1613 + 0.0069, time: 6.651212]
2023-05-29 15:51:50.503: epoch 125:	0.02698345  	0.19821481  	0.10994803  
2023-05-29 15:51:57.142: [iter 126 : loss : 0.1894 = 0.0213 + 0.1612 + 0.0069, time: 6.637051]
2023-05-29 15:51:57.296: epoch 126:	0.02690583  	0.19793765  	0.10990743  
2023-05-29 15:52:03.927: [iter 127 : loss : 0.1886 = 0.0205 + 0.1612 + 0.0069, time: 6.630386]
2023-05-29 15:52:04.087: epoch 127:	0.02693405  	0.19792265  	0.10990720  
2023-05-29 15:52:10.770: [iter 128 : loss : 0.1894 = 0.0213 + 0.1611 + 0.0070, time: 6.680104]
2023-05-29 15:52:10.926: epoch 128:	0.02699050  	0.19824275  	0.11006775  
2023-05-29 15:52:17.535: [iter 129 : loss : 0.1886 = 0.0206 + 0.1611 + 0.0070, time: 6.607103]
2023-05-29 15:52:17.697: epoch 129:	0.02691993  	0.19773202  	0.10974286  
2023-05-29 15:52:24.583: [iter 130 : loss : 0.1887 = 0.0207 + 0.1610 + 0.0070, time: 6.884186]
2023-05-29 15:52:24.734: epoch 130:	0.02689171  	0.19749257  	0.10977971  
2023-05-29 15:52:31.565: [iter 131 : loss : 0.1880 = 0.0200 + 0.1610 + 0.0070, time: 6.828993]
2023-05-29 15:52:31.713: epoch 131:	0.02688465  	0.19726464  	0.10979859  
2023-05-29 15:52:38.566: [iter 132 : loss : 0.1881 = 0.0201 + 0.1609 + 0.0071, time: 6.851545]
2023-05-29 15:52:38.720: epoch 132:	0.02696227  	0.19800752  	0.11001349  
2023-05-29 15:52:45.520: [iter 133 : loss : 0.1872 = 0.0191 + 0.1609 + 0.0071, time: 6.798170]
2023-05-29 15:52:45.666: epoch 133:	0.02694110  	0.19787396  	0.10995921  
2023-05-29 15:52:52.321: [iter 134 : loss : 0.1877 = 0.0197 + 0.1608 + 0.0071, time: 6.654074]
2023-05-29 15:52:52.466: epoch 134:	0.02689876  	0.19722332  	0.10980698  
2023-05-29 15:52:59.145: [iter 135 : loss : 0.1875 = 0.0196 + 0.1608 + 0.0072, time: 6.677994]
2023-05-29 15:52:59.301: epoch 135:	0.02691287  	0.19736493  	0.10990307  
2023-05-29 15:53:05.921: [iter 136 : loss : 0.1875 = 0.0195 + 0.1607 + 0.0072, time: 6.618993]
2023-05-29 15:53:06.064: epoch 136:	0.02694815  	0.19817235  	0.11007455  
2023-05-29 15:53:12.724: [iter 137 : loss : 0.1869 = 0.0190 + 0.1607 + 0.0072, time: 6.658048]
2023-05-29 15:53:12.879: epoch 137:	0.02687759  	0.19732314  	0.10977142  
2023-05-29 15:53:19.696: [iter 138 : loss : 0.1867 = 0.0188 + 0.1607 + 0.0073, time: 6.816010]
2023-05-29 15:53:19.857: epoch 138:	0.02695521  	0.19772509  	0.10992245  
2023-05-29 15:53:26.515: [iter 139 : loss : 0.1864 = 0.0185 + 0.1606 + 0.0073, time: 6.657021]
2023-05-29 15:53:26.675: epoch 139:	0.02691287  	0.19728920  	0.10984058  
2023-05-29 15:53:26.675: Early stopping is trigger at epoch: 139
2023-05-29 15:53:26.675: best_result@epoch 114:

2023-05-29 15:53:26.675: 		0.0271      	0.2000      	0.1100      
2023-05-29 16:05:49.446: my pid: 5340
2023-05-29 16:05:49.446: model: model.general_recommender.SGL
2023-05-29 16:05:49.446: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-05-29 16:05:49.446: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.03
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-29 16:05:53.069: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-29 16:06:00.521: [iter 1 : loss : 0.9285 = 0.6930 + 0.2355 + 0.0000, time: 7.452019]
2023-05-29 16:06:00.664: epoch 1:	0.00158058  	0.01081848  	0.00550972  
2023-05-29 16:06:00.665: Find a better model.
2023-05-29 16:06:08.062: [iter 2 : loss : 0.9274 = 0.6929 + 0.2345 + 0.0000, time: 7.395019]
2023-05-29 16:06:08.272: epoch 2:	0.00231443  	0.01607933  	0.00807435  
2023-05-29 16:06:08.272: Find a better model.
2023-05-29 16:06:15.712: [iter 3 : loss : 0.9272 = 0.6928 + 0.2344 + 0.0000, time: 7.438139]
2023-05-29 16:06:15.898: epoch 3:	0.00353513  	0.02500900  	0.01283249  
2023-05-29 16:06:15.898: Find a better model.
2023-05-29 16:06:23.041: [iter 4 : loss : 0.9270 = 0.6926 + 0.2344 + 0.0000, time: 7.142335]
2023-05-29 16:06:23.188: epoch 4:	0.00455826  	0.03170757  	0.01628073  
2023-05-29 16:06:23.188: Find a better model.
2023-05-29 16:06:30.078: [iter 5 : loss : 0.9268 = 0.6924 + 0.2344 + 0.0000, time: 6.889022]
2023-05-29 16:06:30.236: epoch 5:	0.00565901  	0.03928354  	0.01998714  
2023-05-29 16:06:30.237: Find a better model.
2023-05-29 16:06:37.049: [iter 6 : loss : 0.9266 = 0.6921 + 0.2345 + 0.0000, time: 6.810433]
2023-05-29 16:06:37.202: epoch 6:	0.00679503  	0.04820803  	0.02425356  
2023-05-29 16:06:37.202: Find a better model.
2023-05-29 16:06:44.027: [iter 7 : loss : 0.9262 = 0.6917 + 0.2344 + 0.0000, time: 6.824097]
2023-05-29 16:06:44.180: epoch 7:	0.00775466  	0.05502911  	0.02826805  
2023-05-29 16:06:44.180: Find a better model.
2023-05-29 16:06:50.833: [iter 8 : loss : 0.9258 = 0.6913 + 0.2346 + 0.0000, time: 6.652014]
2023-05-29 16:06:50.987: epoch 8:	0.00879191  	0.06239370  	0.03193789  
2023-05-29 16:06:50.987: Find a better model.
2023-05-29 16:06:57.624: [iter 9 : loss : 0.9252 = 0.6905 + 0.2347 + 0.0000, time: 6.636003]
2023-05-29 16:06:57.779: epoch 9:	0.01011851  	0.07202771  	0.03687577  
2023-05-29 16:06:57.780: Find a better model.
2023-05-29 16:07:04.417: [iter 10 : loss : 0.9243 = 0.6894 + 0.2349 + 0.0000, time: 6.636080]
2023-05-29 16:07:04.572: epoch 10:	0.01162154  	0.08355664  	0.04163356  
2023-05-29 16:07:04.572: Find a better model.
2023-05-29 16:07:11.239: [iter 11 : loss : 0.9228 = 0.6877 + 0.2350 + 0.0000, time: 6.665382]
2023-05-29 16:07:11.396: epoch 11:	0.01310340  	0.09449971  	0.04661254  
2023-05-29 16:07:11.396: Find a better model.
2023-05-29 16:07:18.023: [iter 12 : loss : 0.9204 = 0.6850 + 0.2353 + 0.0000, time: 6.625518]
2023-05-29 16:07:18.166: epoch 12:	0.01420420  	0.10270526  	0.05036783  
2023-05-29 16:07:18.166: Find a better model.
2023-05-29 16:07:24.821: [iter 13 : loss : 0.9164 = 0.6807 + 0.2357 + 0.0000, time: 6.654003]
2023-05-29 16:07:24.975: epoch 13:	0.01569310  	0.11440547  	0.05581946  
2023-05-29 16:07:24.975: Find a better model.
2023-05-29 16:07:31.634: [iter 14 : loss : 0.9097 = 0.6733 + 0.2364 + 0.0001, time: 6.658013]
2023-05-29 16:07:31.786: epoch 14:	0.01704087  	0.12463184  	0.06090038  
2023-05-29 16:07:31.786: Find a better model.
2023-05-29 16:07:38.437: [iter 15 : loss : 0.8988 = 0.6613 + 0.2375 + 0.0001, time: 6.649179]
2023-05-29 16:07:38.589: epoch 15:	0.01814166  	0.13306303  	0.06629407  
2023-05-29 16:07:38.590: Find a better model.
2023-05-29 16:07:45.235: [iter 16 : loss : 0.8812 = 0.6418 + 0.2393 + 0.0001, time: 6.644003]
2023-05-29 16:07:45.388: epoch 16:	0.01914368  	0.13998468  	0.07099237  
2023-05-29 16:07:45.388: Find a better model.
2023-05-29 16:07:52.218: [iter 17 : loss : 0.8546 = 0.6123 + 0.2421 + 0.0002, time: 6.828028]
2023-05-29 16:07:52.370: epoch 17:	0.01981407  	0.14497109  	0.07368261  
2023-05-29 16:07:52.371: Find a better model.
2023-05-29 16:07:59.040: [iter 18 : loss : 0.8177 = 0.5713 + 0.2461 + 0.0003, time: 6.668005]
2023-05-29 16:07:59.185: epoch 18:	0.02026568  	0.14905082  	0.07593886  
2023-05-29 16:07:59.185: Find a better model.
2023-05-29 16:08:05.992: [iter 19 : loss : 0.7701 = 0.5186 + 0.2511 + 0.0004, time: 6.806024]
2023-05-29 16:08:06.145: epoch 19:	0.02048444  	0.15088381  	0.07727360  
2023-05-29 16:08:06.145: Find a better model.
2023-05-29 16:08:12.820: [iter 20 : loss : 0.7190 = 0.4624 + 0.2561 + 0.0005, time: 6.674017]
2023-05-29 16:08:12.975: epoch 20:	0.02047033  	0.15102813  	0.07757349  
2023-05-29 16:08:12.975: Find a better model.
2023-05-29 16:08:19.602: [iter 21 : loss : 0.6682 = 0.4069 + 0.2606 + 0.0007, time: 6.626004]
2023-05-29 16:08:19.745: epoch 21:	0.02062557  	0.15199053  	0.07865055  
2023-05-29 16:08:19.745: Find a better model.
2023-05-29 16:08:26.596: [iter 22 : loss : 0.6236 = 0.3590 + 0.2638 + 0.0008, time: 6.849742]
2023-05-29 16:08:26.748: epoch 22:	0.02090078  	0.15404204  	0.07969928  
2023-05-29 16:08:26.748: Find a better model.
2023-05-29 16:08:33.424: [iter 23 : loss : 0.5860 = 0.3189 + 0.2661 + 0.0010, time: 6.675520]
2023-05-29 16:08:33.579: epoch 23:	0.02115481  	0.15603474  	0.08090917  
2023-05-29 16:08:33.579: Find a better model.
2023-05-29 16:08:40.393: [iter 24 : loss : 0.5556 = 0.2873 + 0.2671 + 0.0011, time: 6.812599]
2023-05-29 16:08:40.548: epoch 24:	0.02133828  	0.15722768  	0.08169047  
2023-05-29 16:08:40.548: Find a better model.
2023-05-29 16:08:47.380: [iter 25 : loss : 0.5298 = 0.2609 + 0.2677 + 0.0013, time: 6.831005]
2023-05-29 16:08:47.534: epoch 25:	0.02165583  	0.15998158  	0.08300146  
2023-05-29 16:08:47.534: Find a better model.
2023-05-29 16:08:54.374: [iter 26 : loss : 0.5095 = 0.2405 + 0.2676 + 0.0014, time: 6.838995]
2023-05-29 16:08:54.528: epoch 26:	0.02186047  	0.16120498  	0.08394521  
2023-05-29 16:08:54.528: Find a better model.
2023-05-29 16:09:01.204: [iter 27 : loss : 0.4902 = 0.2214 + 0.2673 + 0.0015, time: 6.675116]
2023-05-29 16:09:01.361: epoch 27:	0.02213568  	0.16359426  	0.08499733  
2023-05-29 16:09:01.361: Find a better model.
2023-05-29 16:09:08.171: [iter 28 : loss : 0.4745 = 0.2061 + 0.2667 + 0.0017, time: 6.808007]
2023-05-29 16:09:08.318: epoch 28:	0.02238971  	0.16556883  	0.08622522  
2023-05-29 16:09:08.318: Find a better model.
2023-05-29 16:09:14.998: [iter 29 : loss : 0.4614 = 0.1936 + 0.2661 + 0.0018, time: 6.679181]
2023-05-29 16:09:15.152: epoch 29:	0.02267902  	0.16768986  	0.08740284  
2023-05-29 16:09:15.153: Find a better model.
2023-05-29 16:09:21.962: [iter 30 : loss : 0.4479 = 0.1807 + 0.2654 + 0.0019, time: 6.808043]
2023-05-29 16:09:22.117: epoch 30:	0.02294010  	0.16965374  	0.08858088  
2023-05-29 16:09:22.117: Find a better model.
2023-05-29 16:09:28.992: [iter 31 : loss : 0.4377 = 0.1711 + 0.2645 + 0.0020, time: 6.874490]
2023-05-29 16:09:29.145: epoch 31:	0.02315180  	0.17128077  	0.08949901  
2023-05-29 16:09:29.145: Find a better model.
2023-05-29 16:09:35.949: [iter 32 : loss : 0.4271 = 0.1613 + 0.2637 + 0.0021, time: 6.796858]
2023-05-29 16:09:36.102: epoch 32:	0.02340584  	0.17348689  	0.09071592  
2023-05-29 16:09:36.102: Find a better model.
2023-05-29 16:09:42.948: [iter 33 : loss : 0.4190 = 0.1540 + 0.2628 + 0.0022, time: 6.845004]
2023-05-29 16:09:43.101: epoch 33:	0.02350462  	0.17442836  	0.09147421  
2023-05-29 16:09:43.101: Find a better model.
2023-05-29 16:09:49.779: [iter 34 : loss : 0.4109 = 0.1466 + 0.2620 + 0.0023, time: 6.677025]
2023-05-29 16:09:49.936: epoch 34:	0.02371632  	0.17601439  	0.09255218  
2023-05-29 16:09:49.936: Find a better model.
2023-05-29 16:09:56.583: [iter 35 : loss : 0.4034 = 0.1399 + 0.2612 + 0.0024, time: 6.646006]
2023-05-29 16:09:56.737: epoch 35:	0.02381511  	0.17626145  	0.09332548  
2023-05-29 16:09:56.737: Find a better model.
2023-05-29 16:10:03.545: [iter 36 : loss : 0.3970 = 0.1341 + 0.2604 + 0.0025, time: 6.807008]
2023-05-29 16:10:03.698: epoch 36:	0.02404091  	0.17813815  	0.09437858  
2023-05-29 16:10:03.698: Find a better model.
2023-05-29 16:10:10.543: [iter 37 : loss : 0.3899 = 0.1277 + 0.2596 + 0.0026, time: 6.843242]
2023-05-29 16:10:10.697: epoch 37:	0.02412559  	0.17917418  	0.09507145  
2023-05-29 16:10:10.697: Find a better model.
2023-05-29 16:10:17.378: [iter 38 : loss : 0.3855 = 0.1239 + 0.2590 + 0.0026, time: 6.680966]
2023-05-29 16:10:17.533: epoch 38:	0.02433728  	0.18088908  	0.09634510  
2023-05-29 16:10:17.533: Find a better model.
2023-05-29 16:10:24.327: [iter 39 : loss : 0.3787 = 0.1178 + 0.2582 + 0.0027, time: 6.792272]
2023-05-29 16:10:24.470: epoch 39:	0.02449252  	0.18169694  	0.09694327  
2023-05-29 16:10:24.470: Find a better model.
2023-05-29 16:10:31.167: [iter 40 : loss : 0.3734 = 0.1132 + 0.2574 + 0.0028, time: 6.696003]
2023-05-29 16:10:31.325: epoch 40:	0.02457721  	0.18203694  	0.09761711  
2023-05-29 16:10:31.325: Find a better model.
2023-05-29 16:10:38.169: [iter 41 : loss : 0.3698 = 0.1100 + 0.2569 + 0.0029, time: 6.842278]
2023-05-29 16:10:38.328: epoch 41:	0.02468306  	0.18265218  	0.09806329  
2023-05-29 16:10:38.328: Find a better model.
2023-05-29 16:10:45.123: [iter 42 : loss : 0.3652 = 0.1060 + 0.2561 + 0.0030, time: 6.794035]
2023-05-29 16:10:45.270: epoch 42:	0.02484536  	0.18349950  	0.09874345  
2023-05-29 16:10:45.270: Find a better model.
2023-05-29 16:10:52.140: [iter 43 : loss : 0.3602 = 0.1016 + 0.2555 + 0.0030, time: 6.869054]
2023-05-29 16:10:52.297: epoch 43:	0.02495120  	0.18458354  	0.09934972  
2023-05-29 16:10:52.297: Find a better model.
2023-05-29 16:10:58.966: [iter 44 : loss : 0.3556 = 0.0976 + 0.2549 + 0.0031, time: 6.668468]
2023-05-29 16:10:59.108: epoch 44:	0.02508527  	0.18569507  	0.10002819  
2023-05-29 16:10:59.109: Find a better model.
2023-05-29 16:11:05.749: [iter 45 : loss : 0.3516 = 0.0939 + 0.2544 + 0.0032, time: 6.638433]
2023-05-29 16:11:05.902: epoch 45:	0.02518407  	0.18677600  	0.10069001  
2023-05-29 16:11:05.902: Find a better model.
2023-05-29 16:11:12.560: [iter 46 : loss : 0.3483 = 0.0912 + 0.2538 + 0.0033, time: 6.655028]
2023-05-29 16:11:12.712: epoch 46:	0.02520523  	0.18699311  	0.10112856  
2023-05-29 16:11:12.712: Find a better model.
2023-05-29 16:11:19.540: [iter 47 : loss : 0.3462 = 0.0895 + 0.2533 + 0.0033, time: 6.827013]
2023-05-29 16:11:19.695: epoch 47:	0.02528286  	0.18748501  	0.10152585  
2023-05-29 16:11:19.695: Find a better model.
2023-05-29 16:11:26.547: [iter 48 : loss : 0.3418 = 0.0855 + 0.2528 + 0.0034, time: 6.851513]
2023-05-29 16:11:26.699: epoch 48:	0.02538165  	0.18832760  	0.10197400  
2023-05-29 16:11:26.699: Find a better model.
2023-05-29 16:11:33.344: [iter 49 : loss : 0.3380 = 0.0821 + 0.2524 + 0.0035, time: 6.644044]
2023-05-29 16:11:33.497: epoch 49:	0.02549455  	0.18918620  	0.10250088  
2023-05-29 16:11:33.497: Find a better model.
2023-05-29 16:11:40.312: [iter 50 : loss : 0.3359 = 0.0804 + 0.2520 + 0.0036, time: 6.814003]
2023-05-29 16:11:40.466: epoch 50:	0.02553689  	0.18939090  	0.10291192  
2023-05-29 16:11:40.466: Find a better model.
2023-05-29 16:11:47.145: [iter 51 : loss : 0.3325 = 0.0773 + 0.2516 + 0.0036, time: 6.677269]
2023-05-29 16:11:47.303: epoch 51:	0.02567096  	0.18990320  	0.10345937  
2023-05-29 16:11:47.303: Find a better model.
2023-05-29 16:11:54.119: [iter 52 : loss : 0.3313 = 0.0765 + 0.2511 + 0.0037, time: 6.815008]
2023-05-29 16:11:54.276: epoch 52:	0.02581209  	0.19104780  	0.10406985  
2023-05-29 16:11:54.277: Find a better model.
2023-05-29 16:12:00.934: [iter 53 : loss : 0.3284 = 0.0740 + 0.2507 + 0.0038, time: 6.655963]
2023-05-29 16:12:01.077: epoch 53:	0.02585442  	0.19111411  	0.10425646  
2023-05-29 16:12:01.077: Find a better model.
2023-05-29 16:12:07.713: [iter 54 : loss : 0.3259 = 0.0718 + 0.2503 + 0.0038, time: 6.633014]
2023-05-29 16:12:07.866: epoch 54:	0.02593205  	0.19196789  	0.10465426  
2023-05-29 16:12:07.866: Find a better model.
2023-05-29 16:12:14.538: [iter 55 : loss : 0.3238 = 0.0699 + 0.2500 + 0.0039, time: 6.671464]
2023-05-29 16:12:14.691: epoch 55:	0.02591793  	0.19180652  	0.10485595  
2023-05-29 16:12:21.334: [iter 56 : loss : 0.3211 = 0.0676 + 0.2495 + 0.0039, time: 6.641036]
2023-05-29 16:12:21.489: epoch 56:	0.02602378  	0.19264625  	0.10548526  
2023-05-29 16:12:21.489: Find a better model.
2023-05-29 16:12:28.326: [iter 57 : loss : 0.3190 = 0.0657 + 0.2492 + 0.0040, time: 6.836145]
2023-05-29 16:12:28.481: epoch 57:	0.02598144  	0.19243266  	0.10527906  
2023-05-29 16:12:35.125: [iter 58 : loss : 0.3169 = 0.0639 + 0.2489 + 0.0041, time: 6.643042]
2023-05-29 16:12:35.283: epoch 58:	0.02600967  	0.19292808  	0.10557017  
2023-05-29 16:12:35.283: Find a better model.
2023-05-29 16:12:41.929: [iter 59 : loss : 0.3154 = 0.0628 + 0.2485 + 0.0041, time: 6.644295]
2023-05-29 16:12:42.082: epoch 59:	0.02616490  	0.19369200  	0.10584053  
2023-05-29 16:12:42.083: Find a better model.
2023-05-29 16:12:48.718: [iter 60 : loss : 0.3136 = 0.0611 + 0.2483 + 0.0042, time: 6.634000]
2023-05-29 16:12:48.861: epoch 60:	0.02615785  	0.19361435  	0.10609178  
2023-05-29 16:12:55.523: [iter 61 : loss : 0.3119 = 0.0597 + 0.2480 + 0.0043, time: 6.660998]
2023-05-29 16:12:55.675: epoch 61:	0.02624959  	0.19432184  	0.10649586  
2023-05-29 16:12:55.675: Find a better model.
2023-05-29 16:13:02.515: [iter 62 : loss : 0.3102 = 0.0582 + 0.2476 + 0.0043, time: 6.838441]
2023-05-29 16:13:02.669: epoch 62:	0.02624253  	0.19444370  	0.10669725  
2023-05-29 16:13:02.669: Find a better model.
2023-05-29 16:13:09.340: [iter 63 : loss : 0.3085 = 0.0568 + 0.2473 + 0.0044, time: 6.670173]
2023-05-29 16:13:09.493: epoch 63:	0.02624959  	0.19447371  	0.10685644  
2023-05-29 16:13:09.493: Find a better model.
2023-05-29 16:13:16.290: [iter 64 : loss : 0.3071 = 0.0556 + 0.2470 + 0.0044, time: 6.794510]
2023-05-29 16:13:16.443: epoch 64:	0.02627781  	0.19453143  	0.10689343  
2023-05-29 16:13:16.443: Find a better model.
2023-05-29 16:13:23.128: [iter 65 : loss : 0.3058 = 0.0545 + 0.2468 + 0.0045, time: 6.684031]
2023-05-29 16:13:23.279: epoch 65:	0.02636954  	0.19510010  	0.10727960  
2023-05-29 16:13:23.279: Find a better model.
2023-05-29 16:13:30.083: [iter 66 : loss : 0.3040 = 0.0529 + 0.2465 + 0.0045, time: 6.802609]
2023-05-29 16:13:30.228: epoch 66:	0.02641894  	0.19568619  	0.10755415  
2023-05-29 16:13:30.228: Find a better model.
2023-05-29 16:13:36.895: [iter 67 : loss : 0.3025 = 0.0516 + 0.2463 + 0.0046, time: 6.665090]
2023-05-29 16:13:37.037: epoch 67:	0.02650362  	0.19608134  	0.10770885  
2023-05-29 16:13:37.037: Find a better model.
2023-05-29 16:13:43.691: [iter 68 : loss : 0.3017 = 0.0510 + 0.2461 + 0.0047, time: 6.652056]
2023-05-29 16:13:43.846: epoch 68:	0.02653185  	0.19618101  	0.10790087  
2023-05-29 16:13:43.846: Find a better model.
2023-05-29 16:13:50.500: [iter 69 : loss : 0.2999 = 0.0494 + 0.2459 + 0.0047, time: 6.652483]
2023-05-29 16:13:50.652: epoch 69:	0.02657418  	0.19664820  	0.10809547  
2023-05-29 16:13:50.652: Find a better model.
2023-05-29 16:13:57.320: [iter 70 : loss : 0.2984 = 0.0480 + 0.2457 + 0.0048, time: 6.667003]
2023-05-29 16:13:57.474: epoch 70:	0.02668708  	0.19738717  	0.10841736  
2023-05-29 16:13:57.475: Find a better model.
2023-05-29 16:14:04.092: [iter 71 : loss : 0.2972 = 0.0469 + 0.2455 + 0.0048, time: 6.616010]
2023-05-29 16:14:04.248: epoch 71:	0.02668002  	0.19750465  	0.10850456  
2023-05-29 16:14:04.248: Find a better model.
2023-05-29 16:14:10.870: [iter 72 : loss : 0.2963 = 0.0462 + 0.2453 + 0.0049, time: 6.620645]
2023-05-29 16:14:11.017: epoch 72:	0.02674354  	0.19805762  	0.10872795  
2023-05-29 16:14:11.017: Find a better model.
2023-05-29 16:14:17.667: [iter 73 : loss : 0.2950 = 0.0450 + 0.2450 + 0.0049, time: 6.649021]
2023-05-29 16:14:17.821: epoch 73:	0.02670826  	0.19749977  	0.10861640  
2023-05-29 16:14:24.485: [iter 74 : loss : 0.2939 = 0.0440 + 0.2448 + 0.0050, time: 6.663141]
2023-05-29 16:14:24.639: epoch 74:	0.02667297  	0.19731848  	0.10866768  
2023-05-29 16:14:31.296: [iter 75 : loss : 0.2931 = 0.0434 + 0.2446 + 0.0050, time: 6.656095]
2023-05-29 16:14:31.452: epoch 75:	0.02675765  	0.19805133  	0.10900944  
2023-05-29 16:14:38.090: [iter 76 : loss : 0.2921 = 0.0426 + 0.2444 + 0.0051, time: 6.637004]
2023-05-29 16:14:38.233: epoch 76:	0.02674353  	0.19819173  	0.10930536  
2023-05-29 16:14:38.233: Find a better model.
2023-05-29 16:14:44.862: [iter 77 : loss : 0.2910 = 0.0417 + 0.2442 + 0.0051, time: 6.628386]
2023-05-29 16:14:45.016: epoch 77:	0.02668002  	0.19750766  	0.10908931  
2023-05-29 16:14:51.677: [iter 78 : loss : 0.2905 = 0.0412 + 0.2441 + 0.0052, time: 6.659001]
2023-05-29 16:14:51.830: epoch 78:	0.02665180  	0.19711451  	0.10908506  
2023-05-29 16:14:58.474: [iter 79 : loss : 0.2890 = 0.0398 + 0.2439 + 0.0052, time: 6.643013]
2023-05-29 16:14:58.631: epoch 79:	0.02666592  	0.19708551  	0.10917061  
2023-05-29 16:15:05.268: [iter 80 : loss : 0.2882 = 0.0392 + 0.2438 + 0.0053, time: 6.635009]
2023-05-29 16:15:05.422: epoch 80:	0.02666591  	0.19707939  	0.10906538  
2023-05-29 16:15:12.256: [iter 81 : loss : 0.2878 = 0.0388 + 0.2436 + 0.0053, time: 6.833008]
2023-05-29 16:15:12.413: epoch 81:	0.02673648  	0.19744983  	0.10919114  
2023-05-29 16:15:19.247: [iter 82 : loss : 0.2867 = 0.0378 + 0.2435 + 0.0054, time: 6.833000]
2023-05-29 16:15:19.392: epoch 82:	0.02674354  	0.19752255  	0.10943425  
2023-05-29 16:15:26.286: [iter 83 : loss : 0.2856 = 0.0369 + 0.2433 + 0.0054, time: 6.893013]
2023-05-29 16:15:26.434: epoch 83:	0.02673648  	0.19756661  	0.10954851  
2023-05-29 16:15:33.065: [iter 84 : loss : 0.2855 = 0.0368 + 0.2432 + 0.0055, time: 6.630022]
2023-05-29 16:15:33.216: epoch 84:	0.02676470  	0.19753790  	0.10957377  
2023-05-29 16:15:39.858: [iter 85 : loss : 0.2847 = 0.0361 + 0.2431 + 0.0055, time: 6.641119]
2023-05-29 16:15:40.002: epoch 85:	0.02679293  	0.19801562  	0.10977969  
2023-05-29 16:15:46.660: [iter 86 : loss : 0.2840 = 0.0356 + 0.2428 + 0.0056, time: 6.656010]
2023-05-29 16:15:46.813: epoch 86:	0.02687055  	0.19828503  	0.10982276  
2023-05-29 16:15:46.813: Find a better model.
2023-05-29 16:15:53.648: [iter 87 : loss : 0.2824 = 0.0340 + 0.2428 + 0.0056, time: 6.832222]
2023-05-29 16:15:53.793: epoch 87:	0.02682821  	0.19783510  	0.10979462  
2023-05-29 16:16:00.660: [iter 88 : loss : 0.2817 = 0.0334 + 0.2427 + 0.0057, time: 6.865993]
2023-05-29 16:16:00.815: epoch 88:	0.02690583  	0.19847913  	0.10988984  
2023-05-29 16:16:00.815: Find a better model.
2023-05-29 16:16:07.646: [iter 89 : loss : 0.2811 = 0.0328 + 0.2425 + 0.0057, time: 6.830122]
2023-05-29 16:16:07.800: epoch 89:	0.02694112  	0.19870241  	0.10993464  
2023-05-29 16:16:07.800: Find a better model.
2023-05-29 16:16:14.448: [iter 90 : loss : 0.2813 = 0.0331 + 0.2424 + 0.0058, time: 6.647059]
2023-05-29 16:16:14.602: epoch 90:	0.02688466  	0.19809294  	0.10980815  
2023-05-29 16:16:21.438: [iter 91 : loss : 0.2805 = 0.0325 + 0.2422 + 0.0058, time: 6.834018]
2023-05-29 16:16:21.592: epoch 91:	0.02692700  	0.19850302  	0.10997116  
2023-05-29 16:16:28.234: [iter 92 : loss : 0.2795 = 0.0314 + 0.2422 + 0.0059, time: 6.641078]
2023-05-29 16:16:28.379: epoch 92:	0.02693406  	0.19851612  	0.10981359  
2023-05-29 16:16:35.031: [iter 93 : loss : 0.2797 = 0.0318 + 0.2420 + 0.0059, time: 6.650002]
2023-05-29 16:16:35.184: epoch 93:	0.02697639  	0.19874281  	0.11010329  
2023-05-29 16:16:35.184: Find a better model.
2023-05-29 16:16:41.843: [iter 94 : loss : 0.2782 = 0.0303 + 0.2420 + 0.0059, time: 6.657012]
2023-05-29 16:16:41.995: epoch 94:	0.02699051  	0.19879273  	0.11007200  
2023-05-29 16:16:41.995: Find a better model.
2023-05-29 16:16:48.833: [iter 95 : loss : 0.2774 = 0.0296 + 0.2418 + 0.0060, time: 6.836998]
2023-05-29 16:16:48.987: epoch 95:	0.02696228  	0.19845822  	0.10995626  
2023-05-29 16:16:55.653: [iter 96 : loss : 0.2774 = 0.0297 + 0.2417 + 0.0060, time: 6.665173]
2023-05-29 16:16:55.807: epoch 96:	0.02694817  	0.19844738  	0.10992739  
2023-05-29 16:17:02.625: [iter 97 : loss : 0.2762 = 0.0286 + 0.2416 + 0.0061, time: 6.817059]
2023-05-29 16:17:02.780: epoch 97:	0.02687054  	0.19759832  	0.10969490  
2023-05-29 16:17:09.603: [iter 98 : loss : 0.2762 = 0.0286 + 0.2415 + 0.0061, time: 6.821097]
2023-05-29 16:17:09.757: epoch 98:	0.02696228  	0.19837107  	0.11004528  
2023-05-29 16:17:16.440: [iter 99 : loss : 0.2756 = 0.0280 + 0.2414 + 0.0062, time: 6.680998]
2023-05-29 16:17:16.595: epoch 99:	0.02699050  	0.19837163  	0.11006416  
2023-05-29 16:17:23.217: [iter 100 : loss : 0.2753 = 0.0278 + 0.2413 + 0.0062, time: 6.621030]
2023-05-29 16:17:23.362: epoch 100:	0.02702578  	0.19895948  	0.11025689  
2023-05-29 16:17:23.362: Find a better model.
2023-05-29 16:17:30.037: [iter 101 : loss : 0.2747 = 0.0272 + 0.2412 + 0.0062, time: 6.674008]
2023-05-29 16:17:30.191: epoch 101:	0.02704695  	0.19895606  	0.11030168  
2023-05-29 16:17:37.010: [iter 102 : loss : 0.2741 = 0.0266 + 0.2411 + 0.0063, time: 6.816004]
2023-05-29 16:17:37.165: epoch 102:	0.02700462  	0.19818227  	0.11010659  
2023-05-29 16:17:43.808: [iter 103 : loss : 0.2738 = 0.0265 + 0.2410 + 0.0063, time: 6.640015]
2023-05-29 16:17:43.951: epoch 103:	0.02706107  	0.19853978  	0.11029978  
2023-05-29 16:17:50.608: [iter 104 : loss : 0.2740 = 0.0266 + 0.2410 + 0.0064, time: 6.655242]
2023-05-29 16:17:50.764: epoch 104:	0.02698345  	0.19820064  	0.11022539  
2023-05-29 16:17:57.398: [iter 105 : loss : 0.2735 = 0.0262 + 0.2409 + 0.0064, time: 6.633000]
2023-05-29 16:17:57.553: epoch 105:	0.02702578  	0.19857726  	0.11044903  
2023-05-29 16:18:04.197: [iter 106 : loss : 0.2729 = 0.0257 + 0.2408 + 0.0064, time: 6.643022]
2023-05-29 16:18:04.355: epoch 106:	0.02699756  	0.19824512  	0.11028415  
2023-05-29 16:18:11.039: [iter 107 : loss : 0.2723 = 0.0251 + 0.2407 + 0.0065, time: 6.682434]
2023-05-29 16:18:11.187: epoch 107:	0.02702578  	0.19847606  	0.11036380  
2023-05-29 16:18:17.804: [iter 108 : loss : 0.2719 = 0.0247 + 0.2407 + 0.0065, time: 6.616227]
2023-05-29 16:18:17.961: epoch 108:	0.02700461  	0.19841097  	0.11042657  
2023-05-29 16:18:24.607: [iter 109 : loss : 0.2710 = 0.0239 + 0.2405 + 0.0066, time: 6.644997]
2023-05-29 16:18:24.762: epoch 109:	0.02703284  	0.19852780  	0.11050960  
2023-05-29 16:18:31.381: [iter 110 : loss : 0.2708 = 0.0237 + 0.2405 + 0.0066, time: 6.617998]
2023-05-29 16:18:31.534: epoch 110:	0.02695522  	0.19778223  	0.11036327  
2023-05-29 16:18:38.188: [iter 111 : loss : 0.2705 = 0.0234 + 0.2404 + 0.0066, time: 6.653379]
2023-05-29 16:18:38.335: epoch 111:	0.02689171  	0.19745779  	0.11030006  
2023-05-29 16:18:44.799: [iter 112 : loss : 0.2702 = 0.0232 + 0.2404 + 0.0067, time: 6.461924]
2023-05-29 16:18:44.952: epoch 112:	0.02680703  	0.19686554  	0.11012585  
2023-05-29 16:18:51.573: [iter 113 : loss : 0.2702 = 0.0232 + 0.2403 + 0.0067, time: 6.619008]
2023-05-29 16:18:51.727: epoch 113:	0.02682114  	0.19689509  	0.10998169  
2023-05-29 16:18:58.375: [iter 114 : loss : 0.2695 = 0.0225 + 0.2402 + 0.0067, time: 6.647272]
2023-05-29 16:18:58.530: epoch 114:	0.02680703  	0.19684558  	0.11005548  
2023-05-29 16:19:05.186: [iter 115 : loss : 0.2693 = 0.0224 + 0.2401 + 0.0068, time: 6.653917]
2023-05-29 16:19:05.342: epoch 115:	0.02679997  	0.19653575  	0.10993420  
2023-05-29 16:19:11.984: [iter 116 : loss : 0.2687 = 0.0218 + 0.2401 + 0.0068, time: 6.640018]
2023-05-29 16:19:12.137: epoch 116:	0.02686348  	0.19713339  	0.10991661  
2023-05-29 16:19:18.591: [iter 117 : loss : 0.2687 = 0.0218 + 0.2400 + 0.0069, time: 6.452056]
2023-05-29 16:19:18.737: epoch 117:	0.02684937  	0.19668896  	0.10995261  
2023-05-29 16:19:25.361: [iter 118 : loss : 0.2683 = 0.0215 + 0.2399 + 0.0069, time: 6.623387]
2023-05-29 16:19:25.504: epoch 118:	0.02678586  	0.19627330  	0.10981510  
2023-05-29 16:19:31.999: [iter 119 : loss : 0.2678 = 0.0209 + 0.2399 + 0.0069, time: 6.494009]
2023-05-29 16:19:32.151: epoch 119:	0.02677881  	0.19624074  	0.10972390  
2023-05-29 16:19:38.774: [iter 120 : loss : 0.2679 = 0.0211 + 0.2398 + 0.0070, time: 6.621450]
2023-05-29 16:19:38.917: epoch 120:	0.02682115  	0.19646971  	0.10974093  
2023-05-29 16:19:45.560: [iter 121 : loss : 0.2677 = 0.0210 + 0.2397 + 0.0070, time: 6.642762]
2023-05-29 16:19:45.712: epoch 121:	0.02678587  	0.19608958  	0.10978325  
2023-05-29 16:19:52.390: [iter 122 : loss : 0.2673 = 0.0206 + 0.2397 + 0.0070, time: 6.675999]
2023-05-29 16:19:52.544: epoch 122:	0.02673647  	0.19597849  	0.10972284  
2023-05-29 16:19:59.171: [iter 123 : loss : 0.2671 = 0.0204 + 0.2396 + 0.0071, time: 6.626001]
2023-05-29 16:19:59.327: epoch 123:	0.02676469  	0.19601701  	0.10991453  
2023-05-29 16:20:05.965: [iter 124 : loss : 0.2661 = 0.0194 + 0.2396 + 0.0071, time: 6.636010]
2023-05-29 16:20:06.120: epoch 124:	0.02670824  	0.19555354  	0.10974826  
2023-05-29 16:20:12.772: [iter 125 : loss : 0.2660 = 0.0193 + 0.2395 + 0.0071, time: 6.651011]
2023-05-29 16:20:12.926: epoch 125:	0.02670824  	0.19536418  	0.10978231  
2023-05-29 16:20:12.926: Early stopping is trigger at epoch: 125
2023-05-29 16:20:12.926: best_result@epoch 100:

2023-05-29 16:20:12.926: 		0.0270      	0.1990      	0.1103      
2023-06-05 21:18:35.137: my pid: 892
2023-06-05 21:18:35.138: model: model.general_recommender.SGL
2023-06-05 21:18:35.138: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-06-05 21:18:35.138: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-05 21:18:38.548: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-05 21:18:46.429: [iter 1 : loss : 0.7707 = 0.6930 + 0.0777 + 0.0000, time: 7.881053]
2023-06-05 21:18:46.588: epoch 1:	0.00182049  	0.01247851  	0.00641295  
2023-06-05 21:18:46.588: Find a better model.
2023-06-05 21:18:54.647: [iter 2 : loss : 0.7702 = 0.6929 + 0.0773 + 0.0000, time: 8.058139]
2023-06-05 21:18:54.849: epoch 2:	0.00340812  	0.02291176  	0.01205127  
2023-06-05 21:18:54.849: Find a better model.
2023-06-05 21:19:02.580: [iter 3 : loss : 0.7699 = 0.6927 + 0.0773 + 0.0000, time: 7.729041]
2023-06-05 21:19:02.759: epoch 3:	0.00572252  	0.03909776  	0.01962253  
2023-06-05 21:19:02.759: Find a better model.
2023-06-05 21:19:10.391: [iter 4 : loss : 0.7695 = 0.6922 + 0.0773 + 0.0000, time: 7.629528]
2023-06-05 21:19:10.553: epoch 4:	0.00826976  	0.05776171  	0.02886414  
2023-06-05 21:19:10.553: Find a better model.
2023-06-05 21:19:18.012: [iter 5 : loss : 0.7685 = 0.6912 + 0.0773 + 0.0000, time: 7.457411]
2023-06-05 21:19:18.174: epoch 5:	0.01116287  	0.07925095  	0.03801398  
2023-06-05 21:19:18.174: Find a better model.
2023-06-05 21:19:25.573: [iter 6 : loss : 0.7663 = 0.6887 + 0.0776 + 0.0000, time: 7.398014]
2023-06-05 21:19:25.728: epoch 6:	0.01402778  	0.10035503  	0.04873716  
2023-06-05 21:19:25.728: Find a better model.
2023-06-05 21:19:32.977: [iter 7 : loss : 0.7604 = 0.6822 + 0.0781 + 0.0000, time: 7.247993]
2023-06-05 21:19:33.137: epoch 7:	0.01656808  	0.11991202  	0.05953827  
2023-06-05 21:19:33.137: Find a better model.
2023-06-05 21:19:40.354: [iter 8 : loss : 0.7460 = 0.6664 + 0.0795 + 0.0001, time: 7.214095]
2023-06-05 21:19:40.508: epoch 8:	0.01822634  	0.13399720  	0.06703661  
2023-06-05 21:19:40.508: Find a better model.
2023-06-05 21:19:47.566: [iter 9 : loss : 0.7140 = 0.6312 + 0.0827 + 0.0001, time: 7.056003]
2023-06-05 21:19:47.723: epoch 9:	0.01882615  	0.13857825  	0.06937189  
2023-06-05 21:19:47.723: Find a better model.
2023-06-05 21:19:54.777: [iter 10 : loss : 0.6577 = 0.5698 + 0.0876 + 0.0002, time: 7.053009]
2023-06-05 21:19:54.931: epoch 10:	0.01880497  	0.13887355  	0.06943322  
2023-06-05 21:19:54.931: Find a better model.
2023-06-05 21:20:01.965: [iter 11 : loss : 0.5835 = 0.4903 + 0.0927 + 0.0004, time: 7.031029]
2023-06-05 21:20:02.122: epoch 11:	0.01871325  	0.13834164  	0.06918861  
2023-06-05 21:20:09.157: [iter 12 : loss : 0.5120 = 0.4151 + 0.0964 + 0.0005, time: 7.033275]
2023-06-05 21:20:09.308: epoch 12:	0.01859329  	0.13762099  	0.06928687  
2023-06-05 21:20:16.389: [iter 13 : loss : 0.4580 = 0.3588 + 0.0986 + 0.0007, time: 7.079012]
2023-06-05 21:20:16.543: epoch 13:	0.01862152  	0.13798004  	0.06981543  
2023-06-05 21:20:23.571: [iter 14 : loss : 0.4170 = 0.3164 + 0.0997 + 0.0008, time: 7.026012]
2023-06-05 21:20:23.722: epoch 14:	0.01879793  	0.13965908  	0.07090380  
2023-06-05 21:20:23.722: Find a better model.
2023-06-05 21:20:30.764: [iter 15 : loss : 0.3883 = 0.2871 + 0.1002 + 0.0010, time: 7.041014]
2023-06-05 21:20:30.936: epoch 15:	0.01903785  	0.14129075  	0.07181130  
2023-06-05 21:20:30.936: Find a better model.
2023-06-05 21:20:37.938: [iter 16 : loss : 0.3647 = 0.2633 + 0.1003 + 0.0011, time: 7.001015]
2023-06-05 21:20:38.095: epoch 16:	0.01927777  	0.14274189  	0.07270191  
2023-06-05 21:20:38.096: Find a better model.
2023-06-05 21:20:45.151: [iter 17 : loss : 0.3474 = 0.2460 + 0.1002 + 0.0012, time: 7.051843]
2023-06-05 21:20:45.326: epoch 17:	0.01946830  	0.14400752  	0.07337730  
2023-06-05 21:20:45.326: Find a better model.
2023-06-05 21:20:52.385: [iter 18 : loss : 0.3316 = 0.2303 + 0.1000 + 0.0013, time: 7.057821]
2023-06-05 21:20:52.556: epoch 18:	0.01966589  	0.14492343  	0.07378655  
2023-06-05 21:20:52.556: Find a better model.
2023-06-05 21:20:59.554: [iter 19 : loss : 0.3170 = 0.2159 + 0.0997 + 0.0014, time: 6.996032]
2023-06-05 21:20:59.708: epoch 19:	0.01979996  	0.14591213  	0.07443274  
2023-06-05 21:20:59.708: Find a better model.
2023-06-05 21:21:06.726: [iter 20 : loss : 0.3070 = 0.2062 + 0.0993 + 0.0015, time: 7.016995]
2023-06-05 21:21:06.881: epoch 20:	0.02007517  	0.14773399  	0.07527462  
2023-06-05 21:21:06.881: Find a better model.
2023-06-05 21:21:13.948: [iter 21 : loss : 0.2970 = 0.1965 + 0.0989 + 0.0016, time: 7.064940]
2023-06-05 21:21:14.128: epoch 21:	0.02024452  	0.14905559  	0.07602164  
2023-06-05 21:21:14.128: Find a better model.
2023-06-05 21:21:21.321: [iter 22 : loss : 0.2888 = 0.1885 + 0.0986 + 0.0017, time: 7.191402]
2023-06-05 21:21:21.476: epoch 22:	0.02039977  	0.15020433  	0.07675193  
2023-06-05 21:21:21.476: Find a better model.
2023-06-05 21:21:28.708: [iter 23 : loss : 0.2804 = 0.1804 + 0.0982 + 0.0018, time: 7.229400]
2023-06-05 21:21:28.862: epoch 23:	0.02053384  	0.15121645  	0.07762539  
2023-06-05 21:21:28.862: Find a better model.
2023-06-05 21:21:35.939: [iter 24 : loss : 0.2737 = 0.1742 + 0.0977 + 0.0018, time: 7.076053]
2023-06-05 21:21:36.097: epoch 24:	0.02066792  	0.15216972  	0.07842357  
2023-06-05 21:21:36.097: Find a better model.
2023-06-05 21:21:43.320: [iter 25 : loss : 0.2668 = 0.1676 + 0.0973 + 0.0019, time: 7.220334]
2023-06-05 21:21:43.475: epoch 25:	0.02092195  	0.15356258  	0.07906280  
2023-06-05 21:21:43.475: Find a better model.
2023-06-05 21:21:50.573: [iter 26 : loss : 0.2631 = 0.1642 + 0.0969 + 0.0020, time: 7.096036]
2023-06-05 21:21:50.727: epoch 26:	0.02121832  	0.15581352  	0.08014733  
2023-06-05 21:21:50.727: Find a better model.
2023-06-05 21:21:57.925: [iter 27 : loss : 0.2553 = 0.1568 + 0.0965 + 0.0020, time: 7.196994]
2023-06-05 21:21:58.076: epoch 27:	0.02138063  	0.15693627  	0.08094244  
2023-06-05 21:21:58.076: Find a better model.
2023-06-05 21:22:05.158: [iter 28 : loss : 0.2505 = 0.1523 + 0.0961 + 0.0021, time: 7.080527]
2023-06-05 21:22:05.313: epoch 28:	0.02152881  	0.15810443  	0.08165993  
2023-06-05 21:22:05.313: Find a better model.
2023-06-05 21:22:12.328: [iter 29 : loss : 0.2460 = 0.1482 + 0.0957 + 0.0022, time: 7.014023]
2023-06-05 21:22:12.485: epoch 29:	0.02172639  	0.15987940  	0.08257011  
2023-06-05 21:22:12.485: Find a better model.
2023-06-05 21:22:19.534: [iter 30 : loss : 0.2395 = 0.1419 + 0.0953 + 0.0022, time: 7.047019]
2023-06-05 21:22:19.686: epoch 30:	0.02175462  	0.15979137  	0.08281510  
2023-06-05 21:22:26.741: [iter 31 : loss : 0.2358 = 0.1386 + 0.0949 + 0.0023, time: 7.054023]
2023-06-05 21:22:26.895: epoch 31:	0.02195925  	0.16179331  	0.08361772  
2023-06-05 21:22:26.895: Find a better model.
2023-06-05 21:22:33.914: [iter 32 : loss : 0.2302 = 0.1333 + 0.0946 + 0.0024, time: 7.018014]
2023-06-05 21:22:34.082: epoch 32:	0.02210037  	0.16277587  	0.08426581  
2023-06-05 21:22:34.082: Find a better model.
2023-06-05 21:22:41.296: [iter 33 : loss : 0.2275 = 0.1309 + 0.0942 + 0.0024, time: 7.212012]
2023-06-05 21:22:41.453: epoch 33:	0.02219917  	0.16290483  	0.08485293  
2023-06-05 21:22:41.453: Find a better model.
2023-06-05 21:22:48.508: [iter 34 : loss : 0.2236 = 0.1272 + 0.0939 + 0.0025, time: 7.053529]
2023-06-05 21:22:48.664: epoch 34:	0.02238263  	0.16414498  	0.08558935  
2023-06-05 21:22:48.664: Find a better model.
2023-06-05 21:22:55.898: [iter 35 : loss : 0.2202 = 0.1241 + 0.0936 + 0.0025, time: 7.233016]
2023-06-05 21:22:56.052: epoch 35:	0.02261550  	0.16602466  	0.08661664  
2023-06-05 21:22:56.052: Find a better model.
2023-06-05 21:23:03.287: [iter 36 : loss : 0.2167 = 0.1209 + 0.0933 + 0.0026, time: 7.233014]
2023-06-05 21:23:03.457: epoch 36:	0.02279191  	0.16721652  	0.08722485  
2023-06-05 21:23:03.457: Find a better model.
2023-06-05 21:23:10.683: [iter 37 : loss : 0.2128 = 0.1172 + 0.0929 + 0.0027, time: 7.225002]
2023-06-05 21:23:10.839: epoch 37:	0.02299654  	0.16870312  	0.08791480  
2023-06-05 21:23:10.839: Find a better model.
2023-06-05 21:23:18.095: [iter 38 : loss : 0.2112 = 0.1158 + 0.0926 + 0.0027, time: 7.254281]
2023-06-05 21:23:18.248: epoch 38:	0.02307417  	0.16902891  	0.08839076  
2023-06-05 21:23:18.248: Find a better model.
2023-06-05 21:23:25.315: [iter 39 : loss : 0.2068 = 0.1117 + 0.0923 + 0.0028, time: 7.066021]
2023-06-05 21:23:25.471: epoch 39:	0.02323647  	0.17060193  	0.08930998  
2023-06-05 21:23:25.471: Find a better model.
2023-06-05 21:23:32.708: [iter 40 : loss : 0.2036 = 0.1087 + 0.0920 + 0.0028, time: 7.236024]
2023-06-05 21:23:32.864: epoch 40:	0.02320119  	0.17064951  	0.08967443  
2023-06-05 21:23:32.864: Find a better model.
2023-06-05 21:23:41.331: [iter 41 : loss : 0.2020 = 0.1073 + 0.0918 + 0.0029, time: 8.464417]
2023-06-05 21:23:41.480: epoch 41:	0.02330704  	0.17172450  	0.09028203  
2023-06-05 21:23:41.480: Find a better model.
2023-06-05 21:23:48.487: [iter 42 : loss : 0.1998 = 0.1053 + 0.0915 + 0.0029, time: 7.006035]
2023-06-05 21:23:48.642: epoch 42:	0.02344111  	0.17251645  	0.09075402  
2023-06-05 21:23:48.642: Find a better model.
2023-06-05 21:23:55.698: [iter 43 : loss : 0.1957 = 0.1015 + 0.0912 + 0.0030, time: 7.052999]
2023-06-05 21:23:55.867: epoch 43:	0.02344111  	0.17263615  	0.09096446  
2023-06-05 21:23:55.867: Find a better model.
2023-06-05 21:24:02.919: [iter 44 : loss : 0.1923 = 0.0983 + 0.0909 + 0.0030, time: 7.051269]
2023-06-05 21:24:03.084: epoch 44:	0.02346228  	0.17275804  	0.09123723  
2023-06-05 21:24:03.084: Find a better model.
2023-06-05 21:24:10.271: [iter 45 : loss : 0.1902 = 0.0964 + 0.0907 + 0.0031, time: 7.186246]
2023-06-05 21:24:10.423: epoch 45:	0.02361047  	0.17384170  	0.09201190  
2023-06-05 21:24:10.423: Find a better model.
2023-06-05 21:24:17.486: [iter 46 : loss : 0.1879 = 0.0943 + 0.0904 + 0.0031, time: 7.061142]
2023-06-05 21:24:17.640: epoch 46:	0.02368810  	0.17460252  	0.09264982  
2023-06-05 21:24:17.640: Find a better model.
2023-06-05 21:24:24.688: [iter 47 : loss : 0.1870 = 0.0936 + 0.0902 + 0.0032, time: 7.046026]
2023-06-05 21:24:24.841: epoch 47:	0.02371632  	0.17484610  	0.09293859  
2023-06-05 21:24:24.841: Find a better model.
2023-06-05 21:24:32.051: [iter 48 : loss : 0.1832 = 0.0900 + 0.0900 + 0.0032, time: 7.208014]
2023-06-05 21:24:32.204: epoch 48:	0.02376572  	0.17547078  	0.09325372  
2023-06-05 21:24:32.204: Find a better model.
2023-06-05 21:24:39.270: [iter 49 : loss : 0.1801 = 0.0870 + 0.0898 + 0.0033, time: 7.064011]
2023-06-05 21:24:39.423: epoch 49:	0.02389978  	0.17658278  	0.09397858  
2023-06-05 21:24:39.423: Find a better model.
2023-06-05 21:24:46.478: [iter 50 : loss : 0.1793 = 0.0864 + 0.0896 + 0.0033, time: 7.054085]
2023-06-05 21:24:46.634: epoch 50:	0.02393507  	0.17642903  	0.09424134  
2023-06-05 21:24:54.049: [iter 51 : loss : 0.1763 = 0.0836 + 0.0894 + 0.0034, time: 7.414015]
2023-06-05 21:24:54.204: epoch 51:	0.02400562  	0.17661202  	0.09445719  
2023-06-05 21:24:54.204: Find a better model.
2023-06-05 21:25:01.483: [iter 52 : loss : 0.1763 = 0.0837 + 0.0892 + 0.0034, time: 7.278372]
2023-06-05 21:25:01.650: epoch 52:	0.02413264  	0.17751485  	0.09498487  
2023-06-05 21:25:01.650: Find a better model.
2023-06-05 21:25:08.882: [iter 53 : loss : 0.1742 = 0.0818 + 0.0890 + 0.0035, time: 7.230003]
2023-06-05 21:25:09.037: epoch 53:	0.02431611  	0.17926165  	0.09579246  
2023-06-05 21:25:09.037: Find a better model.
2023-06-05 21:25:16.274: [iter 54 : loss : 0.1722 = 0.0799 + 0.0887 + 0.0035, time: 7.234036]
2023-06-05 21:25:16.427: epoch 54:	0.02440079  	0.17984538  	0.09628913  
2023-06-05 21:25:16.427: Find a better model.
2023-06-05 21:25:23.647: [iter 55 : loss : 0.1702 = 0.0781 + 0.0886 + 0.0036, time: 7.218282]
2023-06-05 21:25:23.818: epoch 55:	0.02453486  	0.18062998  	0.09668039  
2023-06-05 21:25:23.818: Find a better model.
2023-06-05 21:25:31.051: [iter 56 : loss : 0.1686 = 0.0766 + 0.0884 + 0.0036, time: 7.232014]
2023-06-05 21:25:31.211: epoch 56:	0.02453486  	0.18069020  	0.09680892  
2023-06-05 21:25:31.212: Find a better model.
2023-06-05 21:25:38.460: [iter 57 : loss : 0.1668 = 0.0749 + 0.0882 + 0.0037, time: 7.247013]
2023-06-05 21:25:38.613: epoch 57:	0.02453486  	0.18093002  	0.09707007  
2023-06-05 21:25:38.613: Find a better model.
2023-06-05 21:25:45.645: [iter 58 : loss : 0.1648 = 0.0731 + 0.0880 + 0.0037, time: 7.030455]
2023-06-05 21:25:45.798: epoch 58:	0.02461953  	0.18123129  	0.09751399  
2023-06-05 21:25:45.798: Find a better model.
2023-06-05 21:25:53.033: [iter 59 : loss : 0.1638 = 0.0722 + 0.0878 + 0.0038, time: 7.232893]
2023-06-05 21:25:53.191: epoch 59:	0.02473243  	0.18202271  	0.09783001  
2023-06-05 21:25:53.191: Find a better model.
2023-06-05 21:26:00.444: [iter 60 : loss : 0.1623 = 0.0708 + 0.0877 + 0.0038, time: 7.251048]
2023-06-05 21:26:00.599: epoch 60:	0.02482416  	0.18311521  	0.09833410  
2023-06-05 21:26:00.599: Find a better model.
2023-06-05 21:26:08.022: [iter 61 : loss : 0.1612 = 0.0698 + 0.0875 + 0.0039, time: 7.422258]
2023-06-05 21:26:08.179: epoch 61:	0.02482416  	0.18274796  	0.09849198  
2023-06-05 21:26:15.430: [iter 62 : loss : 0.1594 = 0.0682 + 0.0874 + 0.0039, time: 7.250007]
2023-06-05 21:26:15.586: epoch 62:	0.02488767  	0.18342757  	0.09888700  
2023-06-05 21:26:15.586: Find a better model.
2023-06-05 21:26:23.019: [iter 63 : loss : 0.1582 = 0.0670 + 0.0872 + 0.0039, time: 7.431993]
2023-06-05 21:26:23.174: epoch 63:	0.02492295  	0.18339181  	0.09923358  
2023-06-05 21:26:30.621: [iter 64 : loss : 0.1571 = 0.0661 + 0.0870 + 0.0040, time: 7.445001]
2023-06-05 21:26:30.779: epoch 64:	0.02509230  	0.18474191  	0.09972481  
2023-06-05 21:26:30.779: Find a better model.
2023-06-05 21:26:38.057: [iter 65 : loss : 0.1560 = 0.0652 + 0.0869 + 0.0040, time: 7.275993]
2023-06-05 21:26:38.210: epoch 65:	0.02512759  	0.18482873  	0.10006040  
2023-06-05 21:26:38.210: Find a better model.
2023-06-05 21:26:45.446: [iter 66 : loss : 0.1543 = 0.0636 + 0.0867 + 0.0041, time: 7.235003]
2023-06-05 21:26:45.598: epoch 66:	0.02518404  	0.18523534  	0.10050575  
2023-06-05 21:26:45.598: Find a better model.
2023-06-05 21:26:52.848: [iter 67 : loss : 0.1528 = 0.0621 + 0.0866 + 0.0041, time: 7.248013]
2023-06-05 21:26:53.002: epoch 67:	0.02528988  	0.18581329  	0.10079002  
2023-06-05 21:26:53.002: Find a better model.
2023-06-05 21:27:00.420: [iter 68 : loss : 0.1526 = 0.0620 + 0.0864 + 0.0042, time: 7.417002]
2023-06-05 21:27:00.573: epoch 68:	0.02535339  	0.18638711  	0.10115582  
2023-06-05 21:27:00.573: Find a better model.
2023-06-05 21:27:08.007: [iter 69 : loss : 0.1506 = 0.0601 + 0.0863 + 0.0042, time: 7.432000]
2023-06-05 21:27:08.163: epoch 69:	0.02538162  	0.18692106  	0.10144361  
2023-06-05 21:27:08.163: Find a better model.
2023-06-05 21:27:15.424: [iter 70 : loss : 0.1491 = 0.0587 + 0.0862 + 0.0042, time: 7.259043]
2023-06-05 21:27:15.576: epoch 70:	0.02543102  	0.18737283  	0.10162526  
2023-06-05 21:27:15.576: Find a better model.
2023-06-05 21:27:22.824: [iter 71 : loss : 0.1476 = 0.0573 + 0.0861 + 0.0043, time: 7.246566]
2023-06-05 21:27:22.995: epoch 71:	0.02550159  	0.18787891  	0.10189347  
2023-06-05 21:27:22.995: Find a better model.
2023-06-05 21:27:30.208: [iter 72 : loss : 0.1476 = 0.0573 + 0.0860 + 0.0043, time: 7.211089]
2023-06-05 21:27:30.363: epoch 72:	0.02548042  	0.18773951  	0.10199112  
2023-06-05 21:27:37.601: [iter 73 : loss : 0.1461 = 0.0559 + 0.0858 + 0.0044, time: 7.236060]
2023-06-05 21:27:37.767: epoch 73:	0.02546630  	0.18785541  	0.10213057  
2023-06-05 21:27:45.185: [iter 74 : loss : 0.1446 = 0.0545 + 0.0857 + 0.0044, time: 7.417044]
2023-06-05 21:27:45.335: epoch 74:	0.02550864  	0.18798728  	0.10223542  
2023-06-05 21:27:45.335: Find a better model.
2023-06-05 21:27:52.580: [iter 75 : loss : 0.1442 = 0.0542 + 0.0856 + 0.0045, time: 7.243015]
2023-06-05 21:27:52.737: epoch 75:	0.02559332  	0.18900709  	0.10286360  
2023-06-05 21:27:52.737: Find a better model.
2023-06-05 21:28:00.005: [iter 76 : loss : 0.1432 = 0.0533 + 0.0855 + 0.0045, time: 7.267018]
2023-06-05 21:28:00.169: epoch 76:	0.02563566  	0.18883832  	0.10300989  
2023-06-05 21:28:07.396: [iter 77 : loss : 0.1422 = 0.0524 + 0.0853 + 0.0045, time: 7.224014]
2023-06-05 21:28:07.549: epoch 77:	0.02566389  	0.18911251  	0.10335736  
2023-06-05 21:28:07.549: Find a better model.
2023-06-05 21:28:14.812: [iter 78 : loss : 0.1413 = 0.0515 + 0.0852 + 0.0046, time: 7.262015]
2023-06-05 21:28:14.967: epoch 78:	0.02577679  	0.19013983  	0.10361417  
2023-06-05 21:28:14.967: Find a better model.
2023-06-05 21:28:22.209: [iter 79 : loss : 0.1402 = 0.0505 + 0.0851 + 0.0046, time: 7.240032]
2023-06-05 21:28:22.363: epoch 79:	0.02581208  	0.19037795  	0.10382093  
2023-06-05 21:28:22.363: Find a better model.
2023-06-05 21:28:29.596: [iter 80 : loss : 0.1395 = 0.0498 + 0.0850 + 0.0047, time: 7.232031]
2023-06-05 21:28:29.750: epoch 80:	0.02584736  	0.19035077  	0.10392210  
2023-06-05 21:28:36.980: [iter 81 : loss : 0.1392 = 0.0495 + 0.0849 + 0.0047, time: 7.229416]
2023-06-05 21:28:37.134: epoch 81:	0.02589675  	0.19085892  	0.10425874  
2023-06-05 21:28:37.135: Find a better model.
2023-06-05 21:28:44.372: [iter 82 : loss : 0.1379 = 0.0484 + 0.0848 + 0.0047, time: 7.236033]
2023-06-05 21:28:44.528: epoch 82:	0.02591792  	0.19104262  	0.10436379  
2023-06-05 21:28:44.529: Find a better model.
2023-06-05 21:28:51.780: [iter 83 : loss : 0.1370 = 0.0475 + 0.0847 + 0.0048, time: 7.250010]
2023-06-05 21:28:51.934: epoch 83:	0.02605905  	0.19209462  	0.10498278  
2023-06-05 21:28:51.934: Find a better model.
2023-06-05 21:28:59.157: [iter 84 : loss : 0.1369 = 0.0475 + 0.0846 + 0.0048, time: 7.222013]
2023-06-05 21:28:59.312: epoch 84:	0.02607316  	0.19210017  	0.10500698  
2023-06-05 21:28:59.312: Find a better model.
2023-06-05 21:29:06.568: [iter 85 : loss : 0.1359 = 0.0466 + 0.0845 + 0.0049, time: 7.254054]
2023-06-05 21:29:06.720: epoch 85:	0.02608727  	0.19252647  	0.10530012  
2023-06-05 21:29:06.720: Find a better model.
2023-06-05 21:29:13.959: [iter 86 : loss : 0.1357 = 0.0464 + 0.0844 + 0.0049, time: 7.237006]
2023-06-05 21:29:14.114: epoch 86:	0.02610138  	0.19247648  	0.10547797  
2023-06-05 21:29:21.367: [iter 87 : loss : 0.1331 = 0.0438 + 0.0843 + 0.0049, time: 7.252054]
2023-06-05 21:29:21.522: epoch 87:	0.02618606  	0.19300111  	0.10584541  
2023-06-05 21:29:21.522: Find a better model.
2023-06-05 21:29:28.780: [iter 88 : loss : 0.1324 = 0.0432 + 0.0842 + 0.0050, time: 7.257027]
2023-06-05 21:29:28.937: epoch 88:	0.02614372  	0.19293088  	0.10585997  
2023-06-05 21:29:36.162: [iter 89 : loss : 0.1322 = 0.0431 + 0.0842 + 0.0050, time: 7.224010]
2023-06-05 21:29:36.317: epoch 89:	0.02615784  	0.19274564  	0.10582916  
2023-06-05 21:29:43.562: [iter 90 : loss : 0.1328 = 0.0437 + 0.0841 + 0.0050, time: 7.242041]
2023-06-05 21:29:43.716: epoch 90:	0.02608021  	0.19210723  	0.10583767  
2023-06-05 21:29:50.984: [iter 91 : loss : 0.1315 = 0.0425 + 0.0840 + 0.0051, time: 7.266021]
2023-06-05 21:29:51.140: epoch 91:	0.02610844  	0.19252141  	0.10592780  
2023-06-05 21:29:58.366: [iter 92 : loss : 0.1306 = 0.0416 + 0.0839 + 0.0051, time: 7.223017]
2023-06-05 21:29:58.520: epoch 92:	0.02604493  	0.19215968  	0.10581880  
2023-06-05 21:30:05.771: [iter 93 : loss : 0.1311 = 0.0421 + 0.0838 + 0.0052, time: 7.249042]
2023-06-05 21:30:05.927: epoch 93:	0.02610139  	0.19268785  	0.10603800  
2023-06-05 21:30:13.149: [iter 94 : loss : 0.1288 = 0.0399 + 0.0837 + 0.0052, time: 7.219993]
2023-06-05 21:30:13.303: epoch 94:	0.02619312  	0.19320560  	0.10623912  
2023-06-05 21:30:13.303: Find a better model.
2023-06-05 21:30:20.559: [iter 95 : loss : 0.1281 = 0.0392 + 0.0837 + 0.0052, time: 7.255041]
2023-06-05 21:30:20.715: epoch 95:	0.02620723  	0.19296007  	0.10628855  
2023-06-05 21:30:27.973: [iter 96 : loss : 0.1283 = 0.0394 + 0.0836 + 0.0053, time: 7.257016]
2023-06-05 21:30:28.128: epoch 96:	0.02618606  	0.19302996  	0.10631625  
2023-06-05 21:30:35.356: [iter 97 : loss : 0.1265 = 0.0377 + 0.0835 + 0.0053, time: 7.227056]
2023-06-05 21:30:35.510: epoch 97:	0.02627780  	0.19362088  	0.10656470  
2023-06-05 21:30:35.510: Find a better model.
2023-06-05 21:30:42.734: [iter 98 : loss : 0.1273 = 0.0385 + 0.0834 + 0.0053, time: 7.222006]
2023-06-05 21:30:42.889: epoch 98:	0.02632014  	0.19402649  	0.10683572  
2023-06-05 21:30:42.889: Find a better model.
2023-06-05 21:30:50.133: [iter 99 : loss : 0.1263 = 0.0376 + 0.0834 + 0.0054, time: 7.243156]
2023-06-05 21:30:50.288: epoch 99:	0.02634130  	0.19425054  	0.10711735  
2023-06-05 21:30:50.288: Find a better model.
2023-06-05 21:30:57.533: [iter 100 : loss : 0.1258 = 0.0371 + 0.0833 + 0.0054, time: 7.244003]
2023-06-05 21:30:57.690: epoch 100:	0.02642598  	0.19484577  	0.10717084  
2023-06-05 21:30:57.690: Find a better model.
2023-06-05 21:31:04.928: [iter 101 : loss : 0.1253 = 0.0366 + 0.0832 + 0.0054, time: 7.237050]
2023-06-05 21:31:05.086: epoch 101:	0.02643304  	0.19477093  	0.10716098  
2023-06-05 21:31:12.332: [iter 102 : loss : 0.1244 = 0.0358 + 0.0832 + 0.0055, time: 7.245006]
2023-06-05 21:31:12.487: epoch 102:	0.02644715  	0.19510464  	0.10726599  
2023-06-05 21:31:12.487: Find a better model.
2023-06-05 21:31:19.724: [iter 103 : loss : 0.1241 = 0.0355 + 0.0831 + 0.0055, time: 7.236034]
2023-06-05 21:31:19.880: epoch 103:	0.02649654  	0.19542319  	0.10744940  
2023-06-05 21:31:19.880: Find a better model.
2023-06-05 21:31:27.143: [iter 104 : loss : 0.1245 = 0.0360 + 0.0830 + 0.0056, time: 7.262000]
2023-06-05 21:31:27.299: epoch 104:	0.02651771  	0.19546229  	0.10780243  
2023-06-05 21:31:27.299: Find a better model.
2023-06-05 21:31:34.546: [iter 105 : loss : 0.1238 = 0.0353 + 0.0829 + 0.0056, time: 7.246025]
2023-06-05 21:31:34.701: epoch 105:	0.02648949  	0.19524220  	0.10771026  
2023-06-05 21:31:41.931: [iter 106 : loss : 0.1234 = 0.0349 + 0.0829 + 0.0056, time: 7.229006]
2023-06-05 21:31:42.086: epoch 106:	0.02645421  	0.19497995  	0.10766440  
2023-06-05 21:31:49.329: [iter 107 : loss : 0.1225 = 0.0340 + 0.0828 + 0.0057, time: 7.241024]
2023-06-05 21:31:49.483: epoch 107:	0.02641187  	0.19470626  	0.10766832  
2023-06-05 21:31:56.720: [iter 108 : loss : 0.1222 = 0.0337 + 0.0828 + 0.0057, time: 7.235045]
2023-06-05 21:31:56.877: epoch 108:	0.02649655  	0.19536076  	0.10781406  
2023-06-05 21:32:04.140: [iter 109 : loss : 0.1210 = 0.0326 + 0.0827 + 0.0057, time: 7.261044]
2023-06-05 21:32:04.299: epoch 109:	0.02657417  	0.19573461  	0.10803743  
2023-06-05 21:32:04.299: Find a better model.
2023-06-05 21:32:11.500: [iter 110 : loss : 0.1203 = 0.0319 + 0.0827 + 0.0058, time: 7.200027]
2023-06-05 21:32:11.658: epoch 110:	0.02651066  	0.19529979  	0.10771813  
2023-06-05 21:32:18.903: [iter 111 : loss : 0.1203 = 0.0319 + 0.0826 + 0.0058, time: 7.242012]
2023-06-05 21:32:19.059: epoch 111:	0.02655300  	0.19555132  	0.10794111  
2023-06-05 21:32:26.309: [iter 112 : loss : 0.1202 = 0.0318 + 0.0825 + 0.0058, time: 7.249033]
2023-06-05 21:32:26.465: epoch 112:	0.02656711  	0.19553477  	0.10802677  
2023-06-05 21:32:33.709: [iter 113 : loss : 0.1202 = 0.0318 + 0.0825 + 0.0059, time: 7.243011]
2023-06-05 21:32:33.864: epoch 113:	0.02658123  	0.19581334  	0.10822228  
2023-06-05 21:32:33.864: Find a better model.
2023-06-05 21:32:41.087: [iter 114 : loss : 0.1193 = 0.0310 + 0.0824 + 0.0059, time: 7.222062]
2023-06-05 21:32:41.245: epoch 114:	0.02651772  	0.19525519  	0.10800596  
2023-06-05 21:32:48.478: [iter 115 : loss : 0.1188 = 0.0305 + 0.0823 + 0.0059, time: 7.231026]
2023-06-05 21:32:48.633: epoch 115:	0.02657417  	0.19534537  	0.10805854  
2023-06-05 21:32:55.887: [iter 116 : loss : 0.1180 = 0.0297 + 0.0823 + 0.0060, time: 7.253013]
2023-06-05 21:32:56.042: epoch 116:	0.02657417  	0.19532664  	0.10815475  
2023-06-05 21:33:03.132: [iter 117 : loss : 0.1180 = 0.0297 + 0.0823 + 0.0060, time: 7.087066]
2023-06-05 21:33:03.288: epoch 117:	0.02656711  	0.19557683  	0.10831545  
2023-06-05 21:33:10.505: [iter 118 : loss : 0.1179 = 0.0297 + 0.0822 + 0.0060, time: 7.215034]
2023-06-05 21:33:10.659: epoch 118:	0.02653889  	0.19521314  	0.10833370  
2023-06-05 21:33:17.912: [iter 119 : loss : 0.1171 = 0.0289 + 0.0821 + 0.0061, time: 7.252038]
2023-06-05 21:33:18.068: epoch 119:	0.02648244  	0.19500847  	0.10823502  
2023-06-05 21:33:25.262: [iter 120 : loss : 0.1173 = 0.0291 + 0.0821 + 0.0061, time: 7.192004]
2023-06-05 21:33:25.419: epoch 120:	0.02650361  	0.19521220  	0.10833301  
2023-06-05 21:33:32.678: [iter 121 : loss : 0.1171 = 0.0289 + 0.0820 + 0.0061, time: 7.258052]
2023-06-05 21:33:32.835: epoch 121:	0.02649656  	0.19524445  	0.10834497  
2023-06-05 21:33:40.086: [iter 122 : loss : 0.1164 = 0.0282 + 0.0820 + 0.0062, time: 7.250012]
2023-06-05 21:33:40.244: epoch 122:	0.02655301  	0.19556656  	0.10859129  
2023-06-05 21:33:47.471: [iter 123 : loss : 0.1162 = 0.0281 + 0.0820 + 0.0062, time: 7.225025]
2023-06-05 21:33:47.628: epoch 123:	0.02652478  	0.19514892  	0.10863188  
2023-06-05 21:33:54.874: [iter 124 : loss : 0.1154 = 0.0272 + 0.0819 + 0.0062, time: 7.245037]
2023-06-05 21:33:55.028: epoch 124:	0.02655301  	0.19552587  	0.10862479  
2023-06-05 21:34:02.269: [iter 125 : loss : 0.1146 = 0.0265 + 0.0819 + 0.0062, time: 7.240026]
2023-06-05 21:34:02.427: epoch 125:	0.02660240  	0.19567177  	0.10875382  
2023-06-05 21:34:09.666: [iter 126 : loss : 0.1151 = 0.0270 + 0.0818 + 0.0063, time: 7.238039]
2023-06-05 21:34:09.823: epoch 126:	0.02657419  	0.19583584  	0.10867063  
2023-06-05 21:34:09.823: Find a better model.
2023-06-05 21:34:17.063: [iter 127 : loss : 0.1140 = 0.0259 + 0.0818 + 0.0063, time: 7.239040]
2023-06-05 21:34:17.219: epoch 127:	0.02646128  	0.19503090  	0.10851024  
2023-06-05 21:34:24.466: [iter 128 : loss : 0.1151 = 0.0271 + 0.0817 + 0.0063, time: 7.244061]
2023-06-05 21:34:24.620: epoch 128:	0.02651067  	0.19516861  	0.10866448  
2023-06-05 21:34:31.854: [iter 129 : loss : 0.1142 = 0.0262 + 0.0817 + 0.0064, time: 7.232004]
2023-06-05 21:34:32.009: epoch 129:	0.02650362  	0.19508192  	0.10879198  
2023-06-05 21:34:39.292: [iter 130 : loss : 0.1143 = 0.0263 + 0.0816 + 0.0064, time: 7.282025]
2023-06-05 21:34:39.447: epoch 130:	0.02650361  	0.19503017  	0.10867107  
2023-06-05 21:34:46.686: [iter 131 : loss : 0.1133 = 0.0253 + 0.0816 + 0.0064, time: 7.238001]
2023-06-05 21:34:46.840: epoch 131:	0.02656712  	0.19544488  	0.10885611  
2023-06-05 21:34:54.075: [iter 132 : loss : 0.1136 = 0.0256 + 0.0815 + 0.0065, time: 7.232032]
2023-06-05 21:34:54.228: epoch 132:	0.02664474  	0.19571304  	0.10890607  
2023-06-05 21:35:01.629: [iter 133 : loss : 0.1124 = 0.0245 + 0.0815 + 0.0065, time: 7.400031]
2023-06-05 21:35:01.782: epoch 133:	0.02662357  	0.19575155  	0.10892266  
2023-06-05 21:35:09.045: [iter 134 : loss : 0.1130 = 0.0251 + 0.0815 + 0.0065, time: 7.262018]
2023-06-05 21:35:09.200: epoch 134:	0.02663768  	0.19570948  	0.10890461  
2023-06-05 21:35:16.473: [iter 135 : loss : 0.1128 = 0.0248 + 0.0814 + 0.0065, time: 7.272026]
2023-06-05 21:35:16.629: epoch 135:	0.02663062  	0.19589843  	0.10900864  
2023-06-05 21:35:16.629: Find a better model.
2023-06-05 21:35:23.845: [iter 136 : loss : 0.1124 = 0.0245 + 0.0814 + 0.0066, time: 7.215016]
2023-06-05 21:35:24.001: epoch 136:	0.02674353  	0.19658984  	0.10912656  
2023-06-05 21:35:24.001: Find a better model.
2023-06-05 21:35:31.235: [iter 137 : loss : 0.1121 = 0.0241 + 0.0813 + 0.0066, time: 7.232028]
2023-06-05 21:35:31.389: epoch 137:	0.02676470  	0.19675992  	0.10931396  
2023-06-05 21:35:31.390: Find a better model.
2023-06-05 21:35:38.632: [iter 138 : loss : 0.1117 = 0.0238 + 0.0813 + 0.0066, time: 7.241007]
2023-06-05 21:35:38.789: epoch 138:	0.02663768  	0.19589010  	0.10908991  
2023-06-05 21:35:46.029: [iter 139 : loss : 0.1115 = 0.0236 + 0.0813 + 0.0067, time: 7.239313]
2023-06-05 21:35:46.183: epoch 139:	0.02660945  	0.19561020  	0.10919696  
2023-06-05 21:35:53.415: [iter 140 : loss : 0.1108 = 0.0229 + 0.0812 + 0.0067, time: 7.231038]
2023-06-05 21:35:53.571: epoch 140:	0.02658123  	0.19530895  	0.10918372  
2023-06-05 21:36:00.819: [iter 141 : loss : 0.1116 = 0.0237 + 0.0812 + 0.0067, time: 7.246035]
2023-06-05 21:36:00.973: epoch 141:	0.02661651  	0.19580656  	0.10929669  
2023-06-05 21:36:08.224: [iter 142 : loss : 0.1107 = 0.0228 + 0.0812 + 0.0067, time: 7.249038]
2023-06-05 21:36:08.380: epoch 142:	0.02660240  	0.19546837  	0.10910799  
2023-06-05 21:36:15.633: [iter 143 : loss : 0.1107 = 0.0228 + 0.0811 + 0.0068, time: 7.251012]
2023-06-05 21:36:15.786: epoch 143:	0.02656712  	0.19545124  	0.10909875  
2023-06-05 21:36:23.039: [iter 144 : loss : 0.1101 = 0.0222 + 0.0811 + 0.0068, time: 7.250034]
2023-06-05 21:36:23.194: epoch 144:	0.02660946  	0.19551890  	0.10914355  
2023-06-05 21:36:30.444: [iter 145 : loss : 0.1099 = 0.0221 + 0.0810 + 0.0068, time: 7.248016]
2023-06-05 21:36:30.599: epoch 145:	0.02661651  	0.19590737  	0.10924742  
2023-06-05 21:36:37.800: [iter 146 : loss : 0.1104 = 0.0225 + 0.0810 + 0.0068, time: 7.200016]
2023-06-05 21:36:37.956: epoch 146:	0.02661651  	0.19580798  	0.10939502  
2023-06-05 21:36:45.227: [iter 147 : loss : 0.1102 = 0.0223 + 0.0810 + 0.0069, time: 7.269029]
2023-06-05 21:36:45.386: epoch 147:	0.02659534  	0.19579464  	0.10919456  
2023-06-05 21:36:54.487: [iter 148 : loss : 0.1089 = 0.0211 + 0.0809 + 0.0069, time: 9.100159]
2023-06-05 21:36:54.646: epoch 148:	0.02657418  	0.19572277  	0.10928302  
2023-06-05 21:37:01.817: [iter 149 : loss : 0.1094 = 0.0216 + 0.0809 + 0.0069, time: 7.170176]
2023-06-05 21:37:01.967: epoch 149:	0.02654595  	0.19541678  	0.10934078  
2023-06-05 21:37:09.235: [iter 150 : loss : 0.1088 = 0.0210 + 0.0809 + 0.0070, time: 7.267020]
2023-06-05 21:37:09.392: epoch 150:	0.02663063  	0.19593211  	0.10950454  
2023-06-05 21:37:17.234: [iter 151 : loss : 0.1089 = 0.0211 + 0.0809 + 0.0070, time: 7.841225]
2023-06-05 21:37:17.386: epoch 151:	0.02670119  	0.19636919  	0.10951190  
2023-06-05 21:37:24.619: [iter 152 : loss : 0.1083 = 0.0205 + 0.0808 + 0.0070, time: 7.231484]
2023-06-05 21:37:24.793: epoch 152:	0.02670119  	0.19663826  	0.10957637  
2023-06-05 21:37:32.005: [iter 153 : loss : 0.1075 = 0.0196 + 0.0808 + 0.0070, time: 7.211052]
2023-06-05 21:37:32.163: epoch 153:	0.02671531  	0.19670968  	0.10976176  
2023-06-05 21:37:39.413: [iter 154 : loss : 0.1078 = 0.0200 + 0.0808 + 0.0071, time: 7.248045]
2023-06-05 21:37:39.584: epoch 154:	0.02664475  	0.19612326  	0.10962304  
2023-06-05 21:37:46.635: [iter 155 : loss : 0.1087 = 0.0209 + 0.0807 + 0.0071, time: 7.050086]
2023-06-05 21:37:46.797: epoch 155:	0.02667297  	0.19632182  	0.10967787  
2023-06-05 21:37:53.798: [iter 156 : loss : 0.1079 = 0.0201 + 0.0807 + 0.0071, time: 7.000040]
2023-06-05 21:37:53.949: epoch 156:	0.02660240  	0.19584787  	0.10948467  
2023-06-05 21:38:28.690: my pid: 1144
2023-06-05 21:38:28.690: model: model.general_recommender.SGL
2023-06-05 21:38:28.691: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-06-05 21:38:28.691: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-05 21:38:31.995: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-05 21:38:39.876: [iter 1 : loss : 0.7711 = 0.6930 + 0.0781 + 0.0000, time: 7.880659]
2023-06-05 21:38:40.035: epoch 1:	0.00218742  	0.01488089  	0.00755444  
2023-06-05 21:38:40.035: Find a better model.
2023-06-05 21:38:48.000: [iter 2 : loss : 0.7706 = 0.6928 + 0.0777 + 0.0000, time: 7.964359]
2023-06-05 21:38:48.215: epoch 2:	0.00395850  	0.02735926  	0.01409806  
2023-06-05 21:38:48.215: Find a better model.
2023-06-05 21:38:55.995: [iter 3 : loss : 0.7703 = 0.6926 + 0.0777 + 0.0000, time: 7.777334]
2023-06-05 21:38:56.171: epoch 3:	0.00680210  	0.04786813  	0.02394184  
2023-06-05 21:38:56.171: Find a better model.
2023-06-05 21:39:03.601: [iter 4 : loss : 0.7697 = 0.6920 + 0.0777 + 0.0000, time: 7.429008]
2023-06-05 21:39:03.758: epoch 4:	0.00970924  	0.06834342  	0.03415706  
2023-06-05 21:39:03.759: Find a better model.
2023-06-05 21:39:11.231: [iter 5 : loss : 0.7685 = 0.6906 + 0.0779 + 0.0000, time: 7.470737]
2023-06-05 21:39:11.397: epoch 5:	0.01268001  	0.09021717  	0.04433249  
2023-06-05 21:39:11.397: Find a better model.
2023-06-05 21:39:18.792: [iter 6 : loss : 0.7655 = 0.6873 + 0.0782 + 0.0000, time: 7.393701]
2023-06-05 21:39:18.962: epoch 6:	0.01550258  	0.11156718  	0.05531818  
2023-06-05 21:39:18.962: Find a better model.
2023-06-05 21:39:26.356: [iter 7 : loss : 0.7576 = 0.6786 + 0.0789 + 0.0000, time: 7.390485]
2023-06-05 21:39:26.507: epoch 7:	0.01773239  	0.12820822  	0.06381691  
2023-06-05 21:39:26.507: Find a better model.
2023-06-05 21:39:33.791: [iter 8 : loss : 0.7387 = 0.6577 + 0.0809 + 0.0001, time: 7.281018]
2023-06-05 21:39:33.946: epoch 8:	0.01876264  	0.13728260  	0.06914058  
2023-06-05 21:39:33.946: Find a better model.
2023-06-05 21:39:40.973: [iter 9 : loss : 0.6987 = 0.6137 + 0.0848 + 0.0002, time: 7.026263]
2023-06-05 21:39:41.134: epoch 9:	0.01876264  	0.13873155  	0.06996586  
2023-06-05 21:39:41.134: Find a better model.
2023-06-05 21:39:48.149: [iter 10 : loss : 0.6343 = 0.5440 + 0.0900 + 0.0003, time: 7.012994]
2023-06-05 21:39:48.317: epoch 10:	0.01879087  	0.13958888  	0.06976914  
2023-06-05 21:39:48.317: Find a better model.
2023-06-05 21:39:55.367: [iter 11 : loss : 0.5588 = 0.4636 + 0.0947 + 0.0004, time: 7.048066]
2023-06-05 21:39:55.520: epoch 11:	0.01864975  	0.13805191  	0.06925280  
2023-06-05 21:40:02.361: [iter 12 : loss : 0.4924 = 0.3939 + 0.0978 + 0.0006, time: 6.839483]
2023-06-05 21:40:02.524: epoch 12:	0.01856507  	0.13753049  	0.06934516  
2023-06-05 21:40:09.527: [iter 13 : loss : 0.4438 = 0.3435 + 0.0996 + 0.0007, time: 7.001004]
2023-06-05 21:40:09.681: epoch 13:	0.01869209  	0.13833410  	0.06980453  
2023-06-05 21:40:16.542: [iter 14 : loss : 0.4070 = 0.3058 + 0.1004 + 0.0009, time: 6.859015]
2023-06-05 21:40:16.698: epoch 14:	0.01880499  	0.13951227  	0.07093462  
2023-06-05 21:40:23.543: [iter 15 : loss : 0.3812 = 0.2795 + 0.1007 + 0.0010, time: 6.844048]
2023-06-05 21:40:23.695: epoch 15:	0.01896023  	0.14064296  	0.07152325  
2023-06-05 21:40:23.695: Find a better model.
2023-06-05 21:40:30.749: [iter 16 : loss : 0.3595 = 0.2577 + 0.1007 + 0.0011, time: 7.053055]
2023-06-05 21:40:30.901: epoch 16:	0.01925660  	0.14262988  	0.07251948  
2023-06-05 21:40:30.901: Find a better model.
2023-06-05 21:40:37.740: [iter 17 : loss : 0.3435 = 0.2417 + 0.1006 + 0.0012, time: 6.837615]
2023-06-05 21:40:37.893: epoch 17:	0.01951770  	0.14441097  	0.07368688  
2023-06-05 21:40:37.893: Find a better model.
2023-06-05 21:40:44.700: [iter 18 : loss : 0.3284 = 0.2268 + 0.1003 + 0.0013, time: 6.805380]
2023-06-05 21:40:44.852: epoch 18:	0.01979996  	0.14619948  	0.07446142  
2023-06-05 21:40:44.852: Find a better model.
2023-06-05 21:40:51.578: [iter 19 : loss : 0.3145 = 0.2131 + 0.1000 + 0.0014, time: 6.725142]
2023-06-05 21:40:51.728: epoch 19:	0.01991992  	0.14674084  	0.07499498  
2023-06-05 21:40:51.728: Find a better model.
2023-06-05 21:40:58.514: [iter 20 : loss : 0.3050 = 0.2039 + 0.0996 + 0.0015, time: 6.782433]
2023-06-05 21:40:58.667: epoch 20:	0.02022335  	0.14893183  	0.07594781  
2023-06-05 21:40:58.667: Find a better model.
2023-06-05 21:41:05.486: [iter 21 : loss : 0.2954 = 0.1945 + 0.0992 + 0.0016, time: 6.818178]
2023-06-05 21:41:05.638: epoch 21:	0.02048445  	0.15104119  	0.07704224  
2023-06-05 21:41:05.638: Find a better model.
2023-06-05 21:41:12.318: [iter 22 : loss : 0.2873 = 0.1868 + 0.0988 + 0.0017, time: 6.677259]
2023-06-05 21:41:12.469: epoch 22:	0.02052678  	0.15107854  	0.07750925  
2023-06-05 21:41:12.469: Find a better model.
2023-06-05 21:41:19.330: [iter 23 : loss : 0.2791 = 0.1789 + 0.0984 + 0.0018, time: 6.859147]
2023-06-05 21:41:19.495: epoch 23:	0.02063263  	0.15197212  	0.07831296  
2023-06-05 21:41:19.495: Find a better model.
2023-06-05 21:41:26.076: [iter 24 : loss : 0.2725 = 0.1728 + 0.0979 + 0.0018, time: 6.577965]
2023-06-05 21:41:26.291: epoch 24:	0.02091489  	0.15427686  	0.07934262  
2023-06-05 21:41:26.291: Find a better model.
2023-06-05 21:41:33.101: [iter 25 : loss : 0.2658 = 0.1664 + 0.0975 + 0.0019, time: 6.807846]
2023-06-05 21:41:33.252: epoch 25:	0.02111953  	0.15570854  	0.07986085  
2023-06-05 21:41:33.253: Find a better model.
2023-06-05 21:41:40.047: [iter 26 : loss : 0.2623 = 0.1632 + 0.0971 + 0.0020, time: 6.793002]
2023-06-05 21:41:40.213: epoch 26:	0.02126772  	0.15659946  	0.08046993  
2023-06-05 21:41:40.214: Find a better model.
2023-06-05 21:41:46.858: [iter 27 : loss : 0.2547 = 0.1559 + 0.0967 + 0.0021, time: 6.642613]
2023-06-05 21:41:47.012: epoch 27:	0.02150059  	0.15828989  	0.08130661  
2023-06-05 21:41:47.012: Find a better model.
2023-06-05 21:41:53.656: [iter 28 : loss : 0.2498 = 0.1513 + 0.0963 + 0.0021, time: 6.642067]
2023-06-05 21:41:53.810: epoch 28:	0.02154293  	0.15844570  	0.08185481  
2023-06-05 21:41:53.810: Find a better model.
2023-06-05 21:42:00.478: [iter 29 : loss : 0.2455 = 0.1473 + 0.0959 + 0.0022, time: 6.667123]
2023-06-05 21:42:00.623: epoch 29:	0.02174050  	0.15998103  	0.08258281  
2023-06-05 21:42:00.623: Find a better model.
2023-06-05 21:42:07.270: [iter 30 : loss : 0.2388 = 0.1410 + 0.0956 + 0.0022, time: 6.646048]
2023-06-05 21:42:07.427: epoch 30:	0.02186046  	0.16099659  	0.08315682  
2023-06-05 21:42:07.427: Find a better model.
2023-06-05 21:42:14.045: [iter 31 : loss : 0.2354 = 0.1379 + 0.0952 + 0.0023, time: 6.616994]
2023-06-05 21:42:14.202: epoch 31:	0.02200159  	0.16230665  	0.08406002  
2023-06-05 21:42:14.202: Find a better model.
2023-06-05 21:42:20.845: [iter 32 : loss : 0.2298 = 0.1326 + 0.0949 + 0.0024, time: 6.642075]
2023-06-05 21:42:21.002: epoch 32:	0.02219917  	0.16348831  	0.08478422  
2023-06-05 21:42:21.002: Find a better model.
2023-06-05 21:42:27.655: [iter 33 : loss : 0.2270 = 0.1302 + 0.0945 + 0.0024, time: 6.652018]
2023-06-05 21:42:27.810: epoch 33:	0.02238264  	0.16481707  	0.08545400  
2023-06-05 21:42:27.810: Find a better model.
2023-06-05 21:42:34.462: [iter 34 : loss : 0.2232 = 0.1266 + 0.0941 + 0.0025, time: 6.649931]
2023-06-05 21:42:34.616: epoch 34:	0.02244614  	0.16493091  	0.08599292  
2023-06-05 21:42:34.616: Find a better model.
2023-06-05 21:42:41.257: [iter 35 : loss : 0.2199 = 0.1236 + 0.0938 + 0.0025, time: 6.639677]
2023-06-05 21:42:41.413: epoch 35:	0.02255904  	0.16565798  	0.08654740  
2023-06-05 21:42:41.413: Find a better model.
2023-06-05 21:42:48.227: [iter 36 : loss : 0.2164 = 0.1203 + 0.0935 + 0.0026, time: 6.812095]
2023-06-05 21:42:48.383: epoch 36:	0.02273546  	0.16711043  	0.08717378  
2023-06-05 21:42:48.383: Find a better model.
2023-06-05 21:42:55.225: [iter 37 : loss : 0.2125 = 0.1166 + 0.0932 + 0.0027, time: 6.841046]
2023-06-05 21:42:55.369: epoch 37:	0.02282719  	0.16778265  	0.08785906  
2023-06-05 21:42:55.369: Find a better model.
2023-06-05 21:43:02.218: [iter 38 : loss : 0.2109 = 0.1153 + 0.0929 + 0.0027, time: 6.848027]
2023-06-05 21:43:02.374: epoch 38:	0.02305300  	0.16957818  	0.08885599  
2023-06-05 21:43:02.375: Find a better model.
2023-06-05 21:43:09.245: [iter 39 : loss : 0.2065 = 0.1112 + 0.0926 + 0.0028, time: 6.869281]
2023-06-05 21:43:09.402: epoch 39:	0.02318002  	0.17044824  	0.08952654  
2023-06-05 21:43:09.402: Find a better model.
2023-06-05 21:43:16.218: [iter 40 : loss : 0.2034 = 0.1083 + 0.0923 + 0.0028, time: 6.814157]
2023-06-05 21:43:16.374: epoch 40:	0.02322236  	0.17064893  	0.08981863  
2023-06-05 21:43:16.375: Find a better model.
2023-06-05 21:43:23.243: [iter 41 : loss : 0.2018 = 0.1069 + 0.0921 + 0.0029, time: 6.867491]
2023-06-05 21:43:23.398: epoch 41:	0.02337761  	0.17191613  	0.09055949  
2023-06-05 21:43:23.398: Find a better model.
2023-06-05 21:43:30.230: [iter 42 : loss : 0.1997 = 0.1050 + 0.0918 + 0.0029, time: 6.831012]
2023-06-05 21:43:30.372: epoch 42:	0.02347640  	0.17269470  	0.09107928  
2023-06-05 21:43:30.373: Find a better model.
2023-06-05 21:43:37.228: [iter 43 : loss : 0.1956 = 0.1012 + 0.0915 + 0.0030, time: 6.853993]
2023-06-05 21:43:37.384: epoch 43:	0.02358224  	0.17356738  	0.09152656  
2023-06-05 21:43:37.384: Find a better model.
2023-06-05 21:43:44.229: [iter 44 : loss : 0.1923 = 0.0981 + 0.0912 + 0.0030, time: 6.844043]
2023-06-05 21:43:44.384: epoch 44:	0.02361047  	0.17362782  	0.09166179  
2023-06-05 21:43:44.384: Find a better model.
2023-06-05 21:43:51.226: [iter 45 : loss : 0.1900 = 0.0959 + 0.0910 + 0.0031, time: 6.841006]
2023-06-05 21:43:51.384: epoch 45:	0.02383627  	0.17516258  	0.09241475  
2023-06-05 21:43:51.384: Find a better model.
2023-06-05 21:43:58.205: [iter 46 : loss : 0.1878 = 0.0940 + 0.0907 + 0.0031, time: 6.820131]
2023-06-05 21:43:58.360: epoch 46:	0.02384333  	0.17511262  	0.09289749  
2023-06-05 21:44:05.051: [iter 47 : loss : 0.1870 = 0.0933 + 0.0905 + 0.0032, time: 6.688994]
2023-06-05 21:44:05.197: epoch 47:	0.02392095  	0.17546724  	0.09315798  
2023-06-05 21:44:05.197: Find a better model.
2023-06-05 21:44:12.000: [iter 48 : loss : 0.1832 = 0.0897 + 0.0903 + 0.0032, time: 6.801914]
2023-06-05 21:44:12.158: epoch 48:	0.02408325  	0.17695673  	0.09385813  
2023-06-05 21:44:12.159: Find a better model.
2023-06-05 21:44:19.005: [iter 49 : loss : 0.1802 = 0.0868 + 0.0901 + 0.0033, time: 6.844994]
2023-06-05 21:44:19.164: epoch 49:	0.02410442  	0.17708440  	0.09425959  
2023-06-05 21:44:19.164: Find a better model.
2023-06-05 21:44:25.822: [iter 50 : loss : 0.1794 = 0.0862 + 0.0899 + 0.0033, time: 6.656993]
2023-06-05 21:44:25.978: epoch 50:	0.02426671  	0.17815678  	0.09496620  
2023-06-05 21:44:25.978: Find a better model.
2023-06-05 21:44:32.816: [iter 51 : loss : 0.1763 = 0.0833 + 0.0897 + 0.0034, time: 6.836351]
2023-06-05 21:44:32.973: epoch 51:	0.02438667  	0.17912374  	0.09539530  
2023-06-05 21:44:32.973: Find a better model.
2023-06-05 21:44:39.804: [iter 52 : loss : 0.1764 = 0.0835 + 0.0895 + 0.0034, time: 6.828994]
2023-06-05 21:44:39.961: epoch 52:	0.02435845  	0.17923558  	0.09565324  
2023-06-05 21:44:39.961: Find a better model.
2023-06-05 21:44:46.796: [iter 53 : loss : 0.1743 = 0.0815 + 0.0893 + 0.0035, time: 6.833993]
2023-06-05 21:44:46.953: epoch 53:	0.02447135  	0.18005098  	0.09628272  
2023-06-05 21:44:46.953: Find a better model.
2023-06-05 21:44:53.776: [iter 54 : loss : 0.1723 = 0.0797 + 0.0891 + 0.0035, time: 6.821950]
2023-06-05 21:44:53.932: epoch 54:	0.02447841  	0.18017909  	0.09646380  
2023-06-05 21:44:53.932: Find a better model.
2023-06-05 21:45:00.774: [iter 55 : loss : 0.1704 = 0.0779 + 0.0889 + 0.0036, time: 6.839993]
2023-06-05 21:45:00.928: epoch 55:	0.02456309  	0.18087253  	0.09680478  
2023-06-05 21:45:00.928: Find a better model.
2023-06-05 21:45:07.765: [iter 56 : loss : 0.1687 = 0.0764 + 0.0887 + 0.0036, time: 6.835481]
2023-06-05 21:45:07.920: epoch 56:	0.02465482  	0.18166302  	0.09736538  
2023-06-05 21:45:07.920: Find a better model.
2023-06-05 21:45:14.593: [iter 57 : loss : 0.1670 = 0.0748 + 0.0886 + 0.0037, time: 6.671993]
2023-06-05 21:45:14.748: epoch 57:	0.02476066  	0.18259275  	0.09772479  
2023-06-05 21:45:14.748: Find a better model.
2023-06-05 21:45:21.561: [iter 58 : loss : 0.1651 = 0.0730 + 0.0884 + 0.0037, time: 6.812326]
2023-06-05 21:45:21.717: epoch 58:	0.02476772  	0.18271141  	0.09796172  
2023-06-05 21:45:21.717: Find a better model.
2023-06-05 21:45:28.418: [iter 59 : loss : 0.1640 = 0.0720 + 0.0882 + 0.0038, time: 6.700256]
2023-06-05 21:45:28.573: epoch 59:	0.02476772  	0.18248044  	0.09818185  
2023-06-05 21:45:35.352: [iter 60 : loss : 0.1626 = 0.0708 + 0.0880 + 0.0038, time: 6.777994]
2023-06-05 21:45:35.510: epoch 60:	0.02484534  	0.18321483  	0.09871304  
2023-06-05 21:45:35.510: Find a better model.
2023-06-05 21:45:42.356: [iter 61 : loss : 0.1612 = 0.0695 + 0.0878 + 0.0039, time: 6.845026]
2023-06-05 21:45:42.499: epoch 61:	0.02501469  	0.18452002  	0.09944363  
2023-06-05 21:45:42.499: Find a better model.
2023-06-05 21:45:49.352: [iter 62 : loss : 0.1596 = 0.0680 + 0.0877 + 0.0039, time: 6.850250]
2023-06-05 21:45:49.499: epoch 62:	0.02499352  	0.18442157  	0.09928674  
2023-06-05 21:45:56.366: [iter 63 : loss : 0.1583 = 0.0668 + 0.0875 + 0.0039, time: 6.864086]
2023-06-05 21:45:56.514: epoch 63:	0.02500764  	0.18445410  	0.09959482  
2023-06-05 21:46:03.352: [iter 64 : loss : 0.1573 = 0.0659 + 0.0874 + 0.0040, time: 6.836453]
2023-06-05 21:46:03.501: epoch 64:	0.02502881  	0.18480191  	0.09970900  
2023-06-05 21:46:03.501: Find a better model.
2023-06-05 21:46:10.370: [iter 65 : loss : 0.1562 = 0.0649 + 0.0872 + 0.0040, time: 6.868003]
2023-06-05 21:46:10.520: epoch 65:	0.02513466  	0.18570313  	0.10011692  
2023-06-05 21:46:10.520: Find a better model.
2023-06-05 21:46:17.378: [iter 66 : loss : 0.1546 = 0.0635 + 0.0871 + 0.0041, time: 6.857004]
2023-06-05 21:46:17.527: epoch 66:	0.02520522  	0.18629365  	0.10051939  
2023-06-05 21:46:17.527: Find a better model.
2023-06-05 21:46:24.357: [iter 67 : loss : 0.1531 = 0.0620 + 0.0869 + 0.0041, time: 6.829003]
2023-06-05 21:46:24.506: epoch 67:	0.02524756  	0.18657148  	0.10092725  
2023-06-05 21:46:24.506: Find a better model.
2023-06-05 21:46:31.363: [iter 68 : loss : 0.1527 = 0.0618 + 0.0868 + 0.0042, time: 6.855016]
2023-06-05 21:46:31.511: epoch 68:	0.02531107  	0.18707627  	0.10118856  
2023-06-05 21:46:31.512: Find a better model.
2023-06-05 21:46:38.343: [iter 69 : loss : 0.1509 = 0.0600 + 0.0867 + 0.0042, time: 6.828997]
2023-06-05 21:46:38.491: epoch 69:	0.02533224  	0.18713546  	0.10145739  
2023-06-05 21:46:38.491: Find a better model.
2023-06-05 21:46:45.335: [iter 70 : loss : 0.1495 = 0.0588 + 0.0866 + 0.0042, time: 6.842993]
2023-06-05 21:46:45.481: epoch 70:	0.02538869  	0.18781719  	0.10186896  
2023-06-05 21:46:45.482: Find a better model.
2023-06-05 21:46:52.362: [iter 71 : loss : 0.1478 = 0.0571 + 0.0864 + 0.0043, time: 6.878012]
2023-06-05 21:46:52.511: epoch 71:	0.02553688  	0.18888400  	0.10243377  
2023-06-05 21:46:52.511: Find a better model.
2023-06-05 21:46:59.323: [iter 72 : loss : 0.1478 = 0.0571 + 0.0863 + 0.0043, time: 6.809534]
2023-06-05 21:46:59.473: epoch 72:	0.02552276  	0.18892699  	0.10251765  
2023-06-05 21:46:59.473: Find a better model.
2023-06-05 21:47:06.337: [iter 73 : loss : 0.1463 = 0.0558 + 0.0862 + 0.0044, time: 6.861981]
2023-06-05 21:47:06.487: epoch 73:	0.02555804  	0.18882461  	0.10267581  
2023-06-05 21:47:13.334: [iter 74 : loss : 0.1448 = 0.0543 + 0.0861 + 0.0044, time: 6.846172]
2023-06-05 21:47:13.482: epoch 74:	0.02555099  	0.18883535  	0.10287584  
2023-06-05 21:47:20.340: [iter 75 : loss : 0.1444 = 0.0540 + 0.0859 + 0.0044, time: 6.857117]
2023-06-05 21:47:20.487: epoch 75:	0.02562155  	0.18944436  	0.10309801  
2023-06-05 21:47:20.488: Find a better model.
2023-06-05 21:47:27.338: [iter 76 : loss : 0.1433 = 0.0530 + 0.0858 + 0.0045, time: 6.848995]
2023-06-05 21:47:27.488: epoch 76:	0.02569917  	0.18990421  	0.10334107  
2023-06-05 21:47:27.488: Find a better model.
2023-06-05 21:47:34.343: [iter 77 : loss : 0.1426 = 0.0524 + 0.0857 + 0.0045, time: 6.854110]
2023-06-05 21:47:34.493: epoch 77:	0.02578385  	0.19024749  	0.10351003  
2023-06-05 21:47:34.494: Find a better model.
2023-06-05 21:47:41.317: [iter 78 : loss : 0.1415 = 0.0514 + 0.0856 + 0.0046, time: 6.821994]
2023-06-05 21:47:41.466: epoch 78:	0.02576268  	0.19034988  	0.10362610  
2023-06-05 21:47:41.466: Find a better model.
2023-06-05 21:47:48.313: [iter 79 : loss : 0.1403 = 0.0502 + 0.0855 + 0.0046, time: 6.846200]
2023-06-05 21:47:48.462: epoch 79:	0.02585441  	0.19078508  	0.10394981  
2023-06-05 21:47:48.462: Find a better model.
2023-06-05 21:47:55.315: [iter 80 : loss : 0.1398 = 0.0497 + 0.0854 + 0.0047, time: 6.851994]
2023-06-05 21:47:55.463: epoch 80:	0.02581913  	0.19058968  	0.10406753  
2023-06-05 21:48:02.316: [iter 81 : loss : 0.1394 = 0.0494 + 0.0853 + 0.0047, time: 6.852005]
2023-06-05 21:48:02.465: epoch 81:	0.02585441  	0.19097061  	0.10426480  
2023-06-05 21:48:02.465: Find a better model.
2023-06-05 21:48:09.332: [iter 82 : loss : 0.1382 = 0.0483 + 0.0852 + 0.0047, time: 6.864278]
2023-06-05 21:48:09.480: epoch 82:	0.02593203  	0.19151479  	0.10449041  
2023-06-05 21:48:09.480: Find a better model.
2023-06-05 21:48:16.324: [iter 83 : loss : 0.1372 = 0.0473 + 0.0851 + 0.0048, time: 6.843181]
2023-06-05 21:48:16.473: epoch 83:	0.02587558  	0.19105680  	0.10460138  
2023-06-05 21:48:23.300: [iter 84 : loss : 0.1372 = 0.0474 + 0.0850 + 0.0048, time: 6.824996]
2023-06-05 21:48:23.448: epoch 84:	0.02587558  	0.19121103  	0.10468962  
2023-06-05 21:48:30.315: [iter 85 : loss : 0.1362 = 0.0464 + 0.0849 + 0.0048, time: 6.865999]
2023-06-05 21:48:30.464: epoch 85:	0.02600260  	0.19195592  	0.10497850  
2023-06-05 21:48:30.464: Find a better model.
2023-06-05 21:48:37.321: [iter 86 : loss : 0.1360 = 0.0463 + 0.0847 + 0.0049, time: 6.855993]
2023-06-05 21:48:37.470: epoch 86:	0.02605905  	0.19238085  	0.10514887  
2023-06-05 21:48:37.471: Find a better model.
2023-06-05 21:48:44.319: [iter 87 : loss : 0.1333 = 0.0437 + 0.0847 + 0.0049, time: 6.847367]
2023-06-05 21:48:44.466: epoch 87:	0.02605905  	0.19258668  	0.10537048  
2023-06-05 21:48:44.466: Find a better model.
2023-06-05 21:48:51.302: [iter 88 : loss : 0.1327 = 0.0432 + 0.0846 + 0.0050, time: 6.834001]
2023-06-05 21:48:51.451: epoch 88:	0.02616489  	0.19326322  	0.10568237  
2023-06-05 21:48:51.451: Find a better model.
2023-06-05 21:48:58.300: [iter 89 : loss : 0.1325 = 0.0429 + 0.0845 + 0.0050, time: 6.847001]
2023-06-05 21:48:58.450: epoch 89:	0.02619312  	0.19394220  	0.10587804  
2023-06-05 21:48:58.450: Find a better model.
2023-06-05 21:49:05.271: [iter 90 : loss : 0.1331 = 0.0436 + 0.0844 + 0.0050, time: 6.819138]
2023-06-05 21:49:05.421: epoch 90:	0.02620017  	0.19417109  	0.10587243  
2023-06-05 21:49:05.421: Find a better model.
2023-06-05 21:49:12.278: [iter 91 : loss : 0.1318 = 0.0424 + 0.0843 + 0.0051, time: 6.856003]
2023-06-05 21:49:12.428: epoch 91:	0.02623546  	0.19440855  	0.10607282  
2023-06-05 21:49:12.428: Find a better model.
2023-06-05 21:49:19.284: [iter 92 : loss : 0.1307 = 0.0413 + 0.0843 + 0.0051, time: 6.854986]
2023-06-05 21:49:19.432: epoch 92:	0.02616489  	0.19398080  	0.10590981  
2023-06-05 21:49:26.270: [iter 93 : loss : 0.1314 = 0.0421 + 0.0842 + 0.0052, time: 6.836993]
2023-06-05 21:49:26.421: epoch 93:	0.02615078  	0.19370733  	0.10590345  
2023-06-05 21:49:33.290: [iter 94 : loss : 0.1292 = 0.0399 + 0.0841 + 0.0052, time: 6.868004]
2023-06-05 21:49:33.439: epoch 94:	0.02617901  	0.19393934  	0.10614622  
2023-06-05 21:49:40.283: [iter 95 : loss : 0.1283 = 0.0391 + 0.0840 + 0.0052, time: 6.843003]
2023-06-05 21:49:40.433: epoch 95:	0.02621429  	0.19430152  	0.10632688  
2023-06-05 21:49:47.261: [iter 96 : loss : 0.1286 = 0.0393 + 0.0839 + 0.0053, time: 6.826993]
2023-06-05 21:49:47.410: epoch 96:	0.02620723  	0.19415043  	0.10635963  
2023-06-05 21:49:54.274: [iter 97 : loss : 0.1268 = 0.0377 + 0.0839 + 0.0053, time: 6.862006]
2023-06-05 21:49:54.425: epoch 97:	0.02625663  	0.19479156  	0.10674275  
2023-06-05 21:49:54.425: Find a better model.
2023-06-05 21:50:01.267: [iter 98 : loss : 0.1276 = 0.0384 + 0.0838 + 0.0053, time: 6.840003]
2023-06-05 21:50:01.417: epoch 98:	0.02632720  	0.19513172  	0.10698558  
2023-06-05 21:50:01.417: Find a better model.
2023-06-05 21:50:08.277: [iter 99 : loss : 0.1266 = 0.0374 + 0.0837 + 0.0054, time: 6.858012]
2023-06-05 21:50:08.427: epoch 99:	0.02636248  	0.19559175  	0.10705092  
2023-06-05 21:50:08.427: Find a better model.
2023-06-05 21:50:15.266: [iter 100 : loss : 0.1262 = 0.0371 + 0.0837 + 0.0054, time: 6.838008]
2023-06-05 21:50:15.415: epoch 100:	0.02634837  	0.19571647  	0.10714787  
2023-06-05 21:50:15.415: Find a better model.
2023-06-05 21:50:22.288: [iter 101 : loss : 0.1256 = 0.0366 + 0.0836 + 0.0054, time: 6.871003]
2023-06-05 21:50:22.436: epoch 101:	0.02643304  	0.19602373  	0.10733842  
2023-06-05 21:50:22.436: Find a better model.
2023-06-05 21:50:29.068: [iter 102 : loss : 0.1247 = 0.0357 + 0.0835 + 0.0055, time: 6.631005]
2023-06-05 21:50:29.217: epoch 102:	0.02640481  	0.19583003  	0.10731304  
2023-06-05 21:50:36.060: [iter 103 : loss : 0.1245 = 0.0355 + 0.0835 + 0.0055, time: 6.842005]
2023-06-05 21:50:36.209: epoch 103:	0.02646127  	0.19585131  	0.10743192  
2023-06-05 21:50:43.037: [iter 104 : loss : 0.1247 = 0.0358 + 0.0834 + 0.0056, time: 6.827070]
2023-06-05 21:50:43.185: epoch 104:	0.02649655  	0.19648601  	0.10780634  
2023-06-05 21:50:43.185: Find a better model.
2023-06-05 21:50:50.034: [iter 105 : loss : 0.1241 = 0.0352 + 0.0833 + 0.0056, time: 6.847994]
2023-06-05 21:50:50.183: epoch 105:	0.02651065  	0.19646570  	0.10783213  
2023-06-05 21:50:57.045: [iter 106 : loss : 0.1237 = 0.0348 + 0.0833 + 0.0056, time: 6.861065]
2023-06-05 21:50:57.193: epoch 106:	0.02652477  	0.19654107  	0.10793885  
2023-06-05 21:50:57.193: Find a better model.
2023-06-05 21:51:03.889: [iter 107 : loss : 0.1228 = 0.0339 + 0.0832 + 0.0056, time: 6.694009]
2023-06-05 21:51:04.037: epoch 107:	0.02652477  	0.19656916  	0.10809391  
2023-06-05 21:51:04.037: Find a better model.
2023-06-05 21:51:10.852: [iter 108 : loss : 0.1225 = 0.0337 + 0.0832 + 0.0057, time: 6.813016]
2023-06-05 21:51:11.000: epoch 108:	0.02655300  	0.19662607  	0.10814496  
2023-06-05 21:51:11.000: Find a better model.
2023-06-05 21:51:17.837: [iter 109 : loss : 0.1213 = 0.0325 + 0.0831 + 0.0057, time: 6.834993]
2023-06-05 21:51:17.986: epoch 109:	0.02662356  	0.19709098  	0.10834049  
2023-06-05 21:51:17.986: Find a better model.
2023-06-05 21:51:24.841: [iter 110 : loss : 0.1206 = 0.0318 + 0.0831 + 0.0058, time: 6.852937]
2023-06-05 21:51:24.988: epoch 110:	0.02653888  	0.19633307  	0.10817355  
2023-06-05 21:51:31.842: [iter 111 : loss : 0.1207 = 0.0319 + 0.0830 + 0.0058, time: 6.852013]
2023-06-05 21:51:31.991: epoch 111:	0.02653183  	0.19635455  	0.10815854  
2023-06-05 21:51:38.854: [iter 112 : loss : 0.1206 = 0.0318 + 0.0829 + 0.0058, time: 6.860857]
2023-06-05 21:51:39.001: epoch 112:	0.02655300  	0.19664952  	0.10839838  
2023-06-05 21:51:45.863: [iter 113 : loss : 0.1207 = 0.0319 + 0.0829 + 0.0059, time: 6.861059]
2023-06-05 21:51:46.012: epoch 113:	0.02655300  	0.19676660  	0.10864346  
2023-06-05 21:51:52.838: [iter 114 : loss : 0.1196 = 0.0309 + 0.0828 + 0.0059, time: 6.824003]
2023-06-05 21:51:52.987: epoch 114:	0.02660945  	0.19743967  	0.10889003  
2023-06-05 21:51:52.988: Find a better model.
2023-06-05 21:51:59.834: [iter 115 : loss : 0.1193 = 0.0306 + 0.0827 + 0.0059, time: 6.844605]
2023-06-05 21:51:59.982: epoch 115:	0.02653889  	0.19672480  	0.10868594  
2023-06-05 21:52:06.809: [iter 116 : loss : 0.1183 = 0.0297 + 0.0827 + 0.0060, time: 6.824951]
2023-06-05 21:52:06.958: epoch 116:	0.02655300  	0.19674248  	0.10869422  
2023-06-05 21:52:13.639: [iter 117 : loss : 0.1184 = 0.0298 + 0.0826 + 0.0060, time: 6.680071]
2023-06-05 21:52:13.787: epoch 117:	0.02662356  	0.19718707  	0.10886955  
2023-06-05 21:52:20.626: [iter 118 : loss : 0.1183 = 0.0297 + 0.0826 + 0.0060, time: 6.837000]
2023-06-05 21:52:20.774: epoch 118:	0.02660944  	0.19695303  	0.10873333  
2023-06-05 21:52:27.453: [iter 119 : loss : 0.1175 = 0.0289 + 0.0825 + 0.0061, time: 6.678015]
2023-06-05 21:52:27.602: epoch 119:	0.02660239  	0.19694844  	0.10887686  
2023-06-05 21:52:34.417: [iter 120 : loss : 0.1176 = 0.0290 + 0.0825 + 0.0061, time: 6.812997]
2023-06-05 21:52:34.565: epoch 120:	0.02663768  	0.19715489  	0.10899548  
2023-06-05 21:52:41.423: [iter 121 : loss : 0.1175 = 0.0289 + 0.0824 + 0.0061, time: 6.856397]
2023-06-05 21:52:41.572: epoch 121:	0.02664473  	0.19700816  	0.10891755  
2023-06-05 21:52:48.419: [iter 122 : loss : 0.1166 = 0.0281 + 0.0824 + 0.0061, time: 6.845005]
2023-06-05 21:52:48.568: epoch 122:	0.02666590  	0.19732337  	0.10925773  
2023-06-05 21:52:55.410: [iter 123 : loss : 0.1165 = 0.0280 + 0.0823 + 0.0062, time: 6.840994]
2023-06-05 21:52:55.559: epoch 123:	0.02673646  	0.19794762  	0.10952949  
2023-06-05 21:52:55.559: Find a better model.
2023-06-05 21:53:02.414: [iter 124 : loss : 0.1156 = 0.0271 + 0.0823 + 0.0062, time: 6.853015]
2023-06-05 21:53:02.562: epoch 124:	0.02673646  	0.19787292  	0.10945746  
2023-06-05 21:53:09.422: [iter 125 : loss : 0.1150 = 0.0265 + 0.0822 + 0.0062, time: 6.858997]
2023-06-05 21:53:09.571: epoch 125:	0.02676469  	0.19829239  	0.10967095  
2023-06-05 21:53:09.571: Find a better model.
2023-06-05 21:53:16.214: [iter 126 : loss : 0.1154 = 0.0270 + 0.0822 + 0.0063, time: 6.641004]
2023-06-05 21:53:16.362: epoch 126:	0.02671529  	0.19785371  	0.10938609  
2023-06-05 21:53:23.194: [iter 127 : loss : 0.1145 = 0.0260 + 0.0822 + 0.0063, time: 6.830984]
2023-06-05 21:53:23.344: epoch 127:	0.02665178  	0.19751480  	0.10952699  
2023-06-05 21:53:30.024: [iter 128 : loss : 0.1155 = 0.0271 + 0.0821 + 0.0063, time: 6.679140]
2023-06-05 21:53:30.173: epoch 128:	0.02665179  	0.19758409  	0.10961003  
2023-06-05 21:53:36.979: [iter 129 : loss : 0.1145 = 0.0261 + 0.0821 + 0.0064, time: 6.805000]
2023-06-05 21:53:37.128: epoch 129:	0.02668002  	0.19791810  	0.10962002  
2023-06-05 21:53:43.797: [iter 130 : loss : 0.1147 = 0.0263 + 0.0820 + 0.0064, time: 6.666063]
2023-06-05 21:53:43.945: epoch 130:	0.02670118  	0.19802247  	0.10967027  
2023-06-05 21:53:50.621: [iter 131 : loss : 0.1136 = 0.0252 + 0.0820 + 0.0064, time: 6.674994]
2023-06-05 21:53:50.770: epoch 131:	0.02672941  	0.19805230  	0.10970031  
2023-06-05 21:53:57.593: [iter 132 : loss : 0.1140 = 0.0256 + 0.0819 + 0.0064, time: 6.822000]
2023-06-05 21:53:57.755: epoch 132:	0.02672941  	0.19781540  	0.10963125  
2023-06-05 21:54:04.580: [iter 133 : loss : 0.1127 = 0.0244 + 0.0819 + 0.0065, time: 6.823026]
2023-06-05 21:54:04.731: epoch 133:	0.02677880  	0.19838911  	0.10991754  
2023-06-05 21:54:04.731: Find a better model.
2023-06-05 21:54:11.587: [iter 134 : loss : 0.1134 = 0.0251 + 0.0818 + 0.0065, time: 6.854993]
2023-06-05 21:54:11.737: epoch 134:	0.02670824  	0.19793999  	0.10992463  
2023-06-05 21:54:18.565: [iter 135 : loss : 0.1132 = 0.0249 + 0.0818 + 0.0065, time: 6.827005]
2023-06-05 21:54:18.713: epoch 135:	0.02673646  	0.19813506  	0.10994281  
2023-06-05 21:54:25.563: [iter 136 : loss : 0.1128 = 0.0245 + 0.0818 + 0.0066, time: 6.848038]
2023-06-05 21:54:25.712: epoch 136:	0.02674352  	0.19798589  	0.10981841  
2023-06-05 21:54:32.415: [iter 137 : loss : 0.1125 = 0.0241 + 0.0817 + 0.0066, time: 6.700997]
2023-06-05 21:54:32.563: epoch 137:	0.02675763  	0.19804768  	0.10980942  
2023-06-05 21:54:39.373: [iter 138 : loss : 0.1122 = 0.0238 + 0.0817 + 0.0066, time: 6.809150]
2023-06-05 21:54:39.522: epoch 138:	0.02678586  	0.19826998  	0.11005072  
2023-06-05 21:54:46.380: [iter 139 : loss : 0.1118 = 0.0235 + 0.0816 + 0.0067, time: 6.856057]
2023-06-05 21:54:46.529: epoch 139:	0.02675764  	0.19822429  	0.11006163  
2023-06-05 21:54:53.180: [iter 140 : loss : 0.1113 = 0.0230 + 0.0816 + 0.0067, time: 6.650006]
2023-06-05 21:54:53.327: epoch 140:	0.02665885  	0.19740264  	0.10979918  
2023-06-05 21:54:59.989: [iter 141 : loss : 0.1119 = 0.0236 + 0.0816 + 0.0067, time: 6.659276]
2023-06-05 21:55:00.142: epoch 141:	0.02663063  	0.19746505  	0.10990331  
2023-06-05 21:55:06.777: [iter 142 : loss : 0.1110 = 0.0227 + 0.0815 + 0.0067, time: 6.634004]
2023-06-05 21:55:06.926: epoch 142:	0.02668002  	0.19766094  	0.10992477  
2023-06-05 21:55:13.594: [iter 143 : loss : 0.1111 = 0.0228 + 0.0815 + 0.0068, time: 6.667023]
2023-06-05 21:55:13.743: epoch 143:	0.02669412  	0.19762211  	0.10979807  
2023-06-05 21:55:20.550: [iter 144 : loss : 0.1105 = 0.0222 + 0.0815 + 0.0068, time: 6.798221]
2023-06-05 21:55:20.699: epoch 144:	0.02668001  	0.19738208  	0.10980982  
2023-06-05 21:55:27.365: [iter 145 : loss : 0.1104 = 0.0221 + 0.0814 + 0.0068, time: 6.665004]
2023-06-05 21:55:27.513: epoch 145:	0.02668707  	0.19760959  	0.11005361  
2023-06-05 21:55:34.345: [iter 146 : loss : 0.1109 = 0.0226 + 0.0814 + 0.0068, time: 6.829129]
2023-06-05 21:55:34.495: epoch 146:	0.02668002  	0.19749391  	0.11003733  
2023-06-05 21:55:41.171: [iter 147 : loss : 0.1106 = 0.0223 + 0.0814 + 0.0069, time: 6.675011]
2023-06-05 21:55:41.320: epoch 147:	0.02663062  	0.19721019  	0.11000042  
2023-06-05 21:55:47.967: [iter 148 : loss : 0.1093 = 0.0211 + 0.0813 + 0.0069, time: 6.646004]
2023-06-05 21:55:48.118: epoch 148:	0.02664473  	0.19713549  	0.11002218  
2023-06-05 21:55:54.781: [iter 149 : loss : 0.1098 = 0.0215 + 0.0813 + 0.0069, time: 6.661007]
2023-06-05 21:55:54.928: epoch 149:	0.02654594  	0.19638918  	0.10979454  
2023-06-05 21:56:01.555: [iter 150 : loss : 0.1090 = 0.0208 + 0.0813 + 0.0070, time: 6.626172]
2023-06-05 21:56:01.702: epoch 150:	0.02664473  	0.19690688  	0.11013956  
2023-06-05 21:56:08.533: [iter 151 : loss : 0.1093 = 0.0211 + 0.0813 + 0.0070, time: 6.829010]
2023-06-05 21:56:08.681: epoch 151:	0.02663767  	0.19669572  	0.11004882  
2023-06-05 21:56:15.366: [iter 152 : loss : 0.1086 = 0.0204 + 0.0812 + 0.0070, time: 6.682997]
2023-06-05 21:56:15.515: epoch 152:	0.02667296  	0.19714855  	0.11017443  
2023-06-05 21:56:22.326: [iter 153 : loss : 0.1079 = 0.0197 + 0.0812 + 0.0070, time: 6.809994]
2023-06-05 21:56:22.476: epoch 153:	0.02672235  	0.19751938  	0.11025425  
2023-06-05 21:56:29.148: [iter 154 : loss : 0.1082 = 0.0200 + 0.0812 + 0.0071, time: 6.670002]
2023-06-05 21:56:29.295: epoch 154:	0.02675764  	0.19751510  	0.11056547  
2023-06-05 21:56:35.970: [iter 155 : loss : 0.1092 = 0.0210 + 0.0811 + 0.0071, time: 6.672994]
2023-06-05 21:56:36.121: epoch 155:	0.02671530  	0.19727102  	0.11049072  
2023-06-05 21:56:42.743: [iter 156 : loss : 0.1083 = 0.0201 + 0.0811 + 0.0071, time: 6.620022]
2023-06-05 21:56:42.891: epoch 156:	0.02677175  	0.19771554  	0.11038198  
2023-06-05 21:56:49.540: [iter 157 : loss : 0.1081 = 0.0199 + 0.0811 + 0.0071, time: 6.648003]
2023-06-05 21:56:49.688: epoch 157:	0.02679998  	0.19762820  	0.11033206  
2023-06-05 21:56:56.529: [iter 158 : loss : 0.1074 = 0.0192 + 0.0810 + 0.0072, time: 6.839061]
2023-06-05 21:56:56.678: epoch 158:	0.02682114  	0.19759335  	0.11022583  
2023-06-05 21:56:56.678: Early stopping is trigger at epoch: 158
2023-06-05 21:56:56.678: best_result@epoch 133:

2023-06-05 21:56:56.678: 		0.0268      	0.1984      	0.1099      
2023-06-06 09:23:08.255: my pid: 6660
2023-06-06 09:23:08.255: model: model.general_recommender.SGL
2023-06-06 09:23:08.255: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-06-06 09:23:08.255: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-06 09:23:11.594: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-06 09:23:19.592: [iter 1 : loss : 0.7715 = 0.6930 + 0.0785 + 0.0000, time: 7.998505]
2023-06-06 09:23:19.756: epoch 1:	0.00220859  	0.01498763  	0.00750853  
2023-06-06 09:23:19.756: Find a better model.
2023-06-06 09:23:27.510: [iter 2 : loss : 0.7710 = 0.6928 + 0.0782 + 0.0000, time: 7.752695]
2023-06-06 09:23:27.719: epoch 2:	0.00410667  	0.02892982  	0.01416585  
2023-06-06 09:23:27.719: Find a better model.
2023-06-06 09:23:35.342: [iter 3 : loss : 0.7707 = 0.6924 + 0.0782 + 0.0000, time: 7.621950]
2023-06-06 09:23:35.525: epoch 3:	0.00715490  	0.05049675  	0.02492975  
2023-06-06 09:23:35.525: Find a better model.
2023-06-06 09:23:42.930: [iter 4 : loss : 0.7700 = 0.6917 + 0.0783 + 0.0000, time: 7.404027]
2023-06-06 09:23:43.087: epoch 4:	0.01043605  	0.07291649  	0.03605649  
2023-06-06 09:23:43.087: Find a better model.
2023-06-06 09:23:50.444: [iter 5 : loss : 0.7684 = 0.6899 + 0.0785 + 0.0000, time: 7.355476]
2023-06-06 09:23:50.609: epoch 5:	0.01323747  	0.09496174  	0.04658305  
2023-06-06 09:23:50.609: Find a better model.
2023-06-06 09:23:57.436: [iter 6 : loss : 0.7645 = 0.6854 + 0.0790 + 0.0000, time: 6.826045]
2023-06-06 09:23:57.598: epoch 6:	0.01668099  	0.12051311  	0.05920552  
2023-06-06 09:23:57.598: Find a better model.
2023-06-06 09:24:04.269: [iter 7 : loss : 0.7540 = 0.6738 + 0.0801 + 0.0000, time: 6.669552]
2023-06-06 09:24:04.432: epoch 7:	0.01843803  	0.13426773  	0.06704067  
2023-06-06 09:24:04.432: Find a better model.
2023-06-06 09:24:11.341: [iter 8 : loss : 0.7295 = 0.6467 + 0.0828 + 0.0001, time: 6.906888]
2023-06-06 09:24:11.489: epoch 8:	0.01890377  	0.13876523  	0.06978312  
2023-06-06 09:24:11.490: Find a better model.
2023-06-06 09:24:18.474: [iter 9 : loss : 0.6810 = 0.5933 + 0.0874 + 0.0002, time: 6.983090]
2023-06-06 09:24:18.642: epoch 9:	0.01849449  	0.13663806  	0.06874169  
2023-06-06 09:24:25.328: [iter 10 : loss : 0.6105 = 0.5174 + 0.0928 + 0.0003, time: 6.685055]
2023-06-06 09:24:25.478: epoch 10:	0.01853684  	0.13685367  	0.06852735  
2023-06-06 09:24:32.527: [iter 11 : loss : 0.5365 = 0.4390 + 0.0970 + 0.0005, time: 7.048017]
2023-06-06 09:24:32.700: epoch 11:	0.01845217  	0.13629697  	0.06828228  
2023-06-06 09:24:39.443: [iter 12 : loss : 0.4760 = 0.3758 + 0.0995 + 0.0006, time: 6.742102]
2023-06-06 09:24:39.602: epoch 12:	0.01846628  	0.13642029  	0.06872068  
2023-06-06 09:24:46.595: [iter 13 : loss : 0.4326 = 0.3310 + 0.1009 + 0.0008, time: 6.990539]
2023-06-06 09:24:46.757: epoch 13:	0.01854390  	0.13727862  	0.06935147  
2023-06-06 09:24:53.588: [iter 14 : loss : 0.3994 = 0.2970 + 0.1015 + 0.0009, time: 6.828040]
2023-06-06 09:24:53.752: epoch 14:	0.01879793  	0.13961299  	0.07077211  
2023-06-06 09:24:53.753: Find a better model.
2023-06-06 09:25:02.222: [iter 15 : loss : 0.3761 = 0.2734 + 0.1016 + 0.0010, time: 8.465952]
2023-06-06 09:25:02.536: epoch 15:	0.01896023  	0.14085835  	0.07159097  
2023-06-06 09:25:02.536: Find a better model.
2023-06-06 09:25:10.059: [iter 16 : loss : 0.3559 = 0.2532 + 0.1015 + 0.0012, time: 7.521082]
2023-06-06 09:25:10.239: epoch 16:	0.01914370  	0.14200313  	0.07224663  
2023-06-06 09:25:10.239: Find a better model.
2023-06-06 09:25:18.805: [iter 17 : loss : 0.3410 = 0.2384 + 0.1013 + 0.0013, time: 8.558073]
2023-06-06 09:25:19.093: epoch 17:	0.01949653  	0.14421123  	0.07348430  
2023-06-06 09:25:19.093: Find a better model.
2023-06-06 09:25:27.153: [iter 18 : loss : 0.3266 = 0.2242 + 0.1010 + 0.0014, time: 8.058055]
2023-06-06 09:25:27.369: epoch 18:	0.01958826  	0.14446405  	0.07406116  
2023-06-06 09:25:27.369: Find a better model.
2023-06-06 09:25:36.090: [iter 19 : loss : 0.3132 = 0.2110 + 0.1007 + 0.0014, time: 8.717051]
2023-06-06 09:25:36.392: epoch 19:	0.01971528  	0.14553764  	0.07476111  
2023-06-06 09:25:36.392: Find a better model.
2023-06-06 09:25:44.522: [iter 20 : loss : 0.3042 = 0.2024 + 0.1002 + 0.0015, time: 8.129043]
2023-06-06 09:25:44.709: epoch 20:	0.01995521  	0.14726886  	0.07542714  
2023-06-06 09:25:44.709: Find a better model.
2023-06-06 09:25:53.357: [iter 21 : loss : 0.2949 = 0.1935 + 0.0999 + 0.0016, time: 8.647023]
2023-06-06 09:25:53.692: epoch 21:	0.02023746  	0.14912321  	0.07630318  
2023-06-06 09:25:53.692: Find a better model.
2023-06-06 09:26:01.851: [iter 22 : loss : 0.2870 = 0.1859 + 0.0994 + 0.0017, time: 8.157036]
2023-06-06 09:26:02.037: epoch 22:	0.02038566  	0.15037067  	0.07702947  
2023-06-06 09:26:02.038: Find a better model.
2023-06-06 09:26:10.688: [iter 23 : loss : 0.2791 = 0.1783 + 0.0990 + 0.0018, time: 8.647014]
2023-06-06 09:26:11.022: epoch 23:	0.02056912  	0.15161905  	0.07763815  
2023-06-06 09:26:11.023: Find a better model.
2023-06-06 09:26:19.147: [iter 24 : loss : 0.2727 = 0.1722 + 0.0986 + 0.0018, time: 8.123052]
2023-06-06 09:26:19.358: epoch 24:	0.02078081  	0.15304460  	0.07858250  
2023-06-06 09:26:19.358: Find a better model.
2023-06-06 09:26:27.900: [iter 25 : loss : 0.2661 = 0.1661 + 0.0982 + 0.0019, time: 8.540036]
2023-06-06 09:26:28.226: epoch 25:	0.02094311  	0.15413880  	0.07895625  
2023-06-06 09:26:28.226: Find a better model.
2023-06-06 09:26:36.387: [iter 26 : loss : 0.2627 = 0.1630 + 0.0978 + 0.0020, time: 8.159048]
2023-06-06 09:26:36.558: epoch 26:	0.02116892  	0.15543643  	0.07981659  
2023-06-06 09:26:36.558: Find a better model.
2023-06-06 09:26:45.136: [iter 27 : loss : 0.2551 = 0.1558 + 0.0973 + 0.0021, time: 8.577024]
2023-06-06 09:26:45.466: epoch 27:	0.02121126  	0.15584648  	0.08041868  
2023-06-06 09:26:45.466: Find a better model.
2023-06-06 09:26:53.488: [iter 28 : loss : 0.2503 = 0.1513 + 0.0969 + 0.0021, time: 8.021028]
2023-06-06 09:26:53.660: epoch 28:	0.02139473  	0.15718409  	0.08128716  
2023-06-06 09:26:53.660: Find a better model.
2023-06-06 09:27:02.326: [iter 29 : loss : 0.2462 = 0.1475 + 0.0965 + 0.0022, time: 8.664034]
2023-06-06 09:27:02.640: epoch 29:	0.02164171  	0.15847467  	0.08211847  
2023-06-06 09:27:02.640: Find a better model.
2023-06-06 09:27:10.629: [iter 30 : loss : 0.2396 = 0.1412 + 0.0962 + 0.0022, time: 7.987030]
2023-06-06 09:27:10.811: epoch 30:	0.02182518  	0.16006330  	0.08273166  
2023-06-06 09:27:10.811: Find a better model.
2023-06-06 09:27:19.524: [iter 31 : loss : 0.2362 = 0.1381 + 0.0958 + 0.0023, time: 8.702021]
2023-06-06 09:27:19.846: epoch 31:	0.02193809  	0.16101184  	0.08345711  
2023-06-06 09:27:19.846: Find a better model.
2023-06-06 09:27:27.838: [iter 32 : loss : 0.2308 = 0.1330 + 0.0955 + 0.0024, time: 7.990030]
2023-06-06 09:27:28.025: epoch 32:	0.02210744  	0.16225271  	0.08406720  
2023-06-06 09:27:28.025: Find a better model.
2023-06-06 09:27:36.572: [iter 33 : loss : 0.2281 = 0.1306 + 0.0951 + 0.0024, time: 8.545019]
2023-06-06 09:27:36.883: epoch 33:	0.02219917  	0.16337349  	0.08472048  
2023-06-06 09:27:36.883: Find a better model.
2023-06-06 09:27:45.233: [iter 34 : loss : 0.2241 = 0.1269 + 0.0947 + 0.0025, time: 8.349029]
2023-06-06 09:27:45.420: epoch 34:	0.02231207  	0.16380700  	0.08539790  
2023-06-06 09:27:45.421: Find a better model.
2023-06-06 09:27:54.025: [iter 35 : loss : 0.2208 = 0.1238 + 0.0944 + 0.0025, time: 8.601011]
2023-06-06 09:27:54.309: epoch 35:	0.02247437  	0.16526940  	0.08623502  
2023-06-06 09:27:54.309: Find a better model.
2023-06-06 09:28:02.688: [iter 36 : loss : 0.2176 = 0.1209 + 0.0941 + 0.0026, time: 8.377028]
2023-06-06 09:28:02.873: epoch 36:	0.02252376  	0.16590522  	0.08674090  
2023-06-06 09:28:02.873: Find a better model.
2023-06-06 09:28:11.444: [iter 37 : loss : 0.2136 = 0.1172 + 0.0938 + 0.0026, time: 8.567007]
2023-06-06 09:28:11.763: epoch 37:	0.02265784  	0.16730258  	0.08737612  
2023-06-06 09:28:11.763: Find a better model.
2023-06-06 09:28:20.159: [iter 38 : loss : 0.2121 = 0.1159 + 0.0935 + 0.0027, time: 8.394039]
2023-06-06 09:28:20.355: epoch 38:	0.02275663  	0.16802934  	0.08802508  
2023-06-06 09:28:20.355: Find a better model.
2023-06-06 09:28:28.840: [iter 39 : loss : 0.2076 = 0.1117 + 0.0932 + 0.0028, time: 8.479006]
2023-06-06 09:28:29.165: epoch 39:	0.02286248  	0.16833481  	0.08840825  
2023-06-06 09:28:29.165: Find a better model.
2023-06-06 09:28:37.598: [iter 40 : loss : 0.2045 = 0.1088 + 0.0929 + 0.0028, time: 8.431034]
2023-06-06 09:28:37.782: epoch 40:	0.02308123  	0.16980256  	0.08903708  
2023-06-06 09:28:37.783: Find a better model.
2023-06-06 09:28:46.294: [iter 41 : loss : 0.2030 = 0.1074 + 0.0927 + 0.0029, time: 8.508006]
2023-06-06 09:28:46.608: epoch 41:	0.02312357  	0.17044450  	0.08951116  
2023-06-06 09:28:46.608: Find a better model.
2023-06-06 09:28:55.117: [iter 42 : loss : 0.2009 = 0.1057 + 0.0924 + 0.0029, time: 8.505037]
2023-06-06 09:28:55.293: epoch 42:	0.02319414  	0.17100537  	0.08994471  
2023-06-06 09:28:55.293: Find a better model.
2023-06-06 09:29:03.862: [iter 43 : loss : 0.1969 = 0.1018 + 0.0921 + 0.0030, time: 8.565044]
2023-06-06 09:29:04.181: epoch 43:	0.02330704  	0.17155522  	0.09051308  
2023-06-06 09:29:04.181: Find a better model.
2023-06-06 09:29:12.600: [iter 44 : loss : 0.1934 = 0.0986 + 0.0918 + 0.0030, time: 8.418015]
2023-06-06 09:29:12.790: epoch 44:	0.02339172  	0.17211649  	0.09088958  
2023-06-06 09:29:12.791: Find a better model.
2023-06-06 09:29:21.392: [iter 45 : loss : 0.1911 = 0.0965 + 0.0916 + 0.0031, time: 8.597022]
2023-06-06 09:29:21.682: epoch 45:	0.02351874  	0.17286807  	0.09159698  
2023-06-06 09:29:21.682: Find a better model.
2023-06-06 09:29:30.118: [iter 46 : loss : 0.1889 = 0.0944 + 0.0913 + 0.0031, time: 8.434022]
2023-06-06 09:29:30.309: epoch 46:	0.02359636  	0.17359281  	0.09202679  
2023-06-06 09:29:30.310: Find a better model.
2023-06-06 09:29:38.859: [iter 47 : loss : 0.1883 = 0.0940 + 0.0911 + 0.0032, time: 8.546037]
2023-06-06 09:29:39.155: epoch 47:	0.02365987  	0.17391455  	0.09237783  
2023-06-06 09:29:39.155: Find a better model.
2023-06-06 09:29:47.558: [iter 48 : loss : 0.1845 = 0.0904 + 0.0909 + 0.0032, time: 8.402228]
2023-06-06 09:29:47.749: epoch 48:	0.02384334  	0.17518350  	0.09307203  
2023-06-06 09:29:47.749: Find a better model.
2023-06-06 09:29:56.399: [iter 49 : loss : 0.1813 = 0.0873 + 0.0907 + 0.0033, time: 8.647022]
2023-06-06 09:29:56.674: epoch 49:	0.02392096  	0.17571820  	0.09341720  
2023-06-06 09:29:56.674: Find a better model.
2023-06-06 09:30:05.041: [iter 50 : loss : 0.1804 = 0.0866 + 0.0905 + 0.0033, time: 8.366024]
2023-06-06 09:30:05.229: epoch 50:	0.02393507  	0.17593735  	0.09380727  
2023-06-06 09:30:05.229: Find a better model.
2023-06-06 09:30:14.055: [iter 51 : loss : 0.1776 = 0.0839 + 0.0903 + 0.0034, time: 8.821024]
2023-06-06 09:30:14.335: epoch 51:	0.02408324  	0.17702380  	0.09426763  
2023-06-06 09:30:14.335: Find a better model.
2023-06-06 09:30:22.644: [iter 52 : loss : 0.1776 = 0.0841 + 0.0901 + 0.0034, time: 8.306021]
2023-06-06 09:30:22.828: epoch 52:	0.02418909  	0.17753211  	0.09471813  
2023-06-06 09:30:22.828: Find a better model.
2023-06-06 09:30:31.683: [iter 53 : loss : 0.1754 = 0.0821 + 0.0899 + 0.0035, time: 8.852049]
2023-06-06 09:30:31.964: epoch 53:	0.02423143  	0.17787145  	0.09498526  
2023-06-06 09:30:31.964: Find a better model.
2023-06-06 09:30:40.214: [iter 54 : loss : 0.1735 = 0.0803 + 0.0897 + 0.0035, time: 8.248003]
2023-06-06 09:30:40.399: epoch 54:	0.02445018  	0.17968924  	0.09596508  
2023-06-06 09:30:40.399: Find a better model.
2023-06-06 09:30:49.242: [iter 55 : loss : 0.1716 = 0.0785 + 0.0895 + 0.0036, time: 8.839019]
2023-06-06 09:30:49.514: epoch 55:	0.02449958  	0.18006366  	0.09622481  
2023-06-06 09:30:49.515: Find a better model.
2023-06-06 09:30:57.802: [iter 56 : loss : 0.1697 = 0.0769 + 0.0893 + 0.0036, time: 8.286000]
2023-06-06 09:30:57.987: epoch 56:	0.02461954  	0.18067938  	0.09667598  
2023-06-06 09:30:57.987: Find a better model.
2023-06-06 09:31:06.920: [iter 57 : loss : 0.1679 = 0.0751 + 0.0892 + 0.0036, time: 8.924051]
2023-06-06 09:31:07.198: epoch 57:	0.02459837  	0.18065795  	0.09685545  
2023-06-06 09:31:15.367: [iter 58 : loss : 0.1663 = 0.0736 + 0.0890 + 0.0037, time: 8.167007]
2023-06-06 09:31:15.553: epoch 58:	0.02460542  	0.18061377  	0.09707228  
2023-06-06 09:31:24.417: [iter 59 : loss : 0.1650 = 0.0725 + 0.0888 + 0.0037, time: 8.862015]
2023-06-06 09:31:24.723: epoch 59:	0.02467598  	0.18108550  	0.09751908  
2023-06-06 09:31:24.724: Find a better model.
2023-06-06 09:31:32.932: [iter 60 : loss : 0.1636 = 0.0712 + 0.0886 + 0.0038, time: 8.206022]
2023-06-06 09:31:33.111: epoch 60:	0.02474655  	0.18197237  	0.09792720  
2023-06-06 09:31:33.111: Find a better model.
2023-06-06 09:31:42.001: [iter 61 : loss : 0.1623 = 0.0700 + 0.0885 + 0.0038, time: 8.889013]
2023-06-06 09:31:42.307: epoch 61:	0.02476772  	0.18214151  	0.09812771  
2023-06-06 09:31:42.307: Find a better model.
2023-06-06 09:31:50.517: [iter 62 : loss : 0.1608 = 0.0686 + 0.0883 + 0.0039, time: 8.209006]
2023-06-06 09:31:50.701: epoch 62:	0.02485945  	0.18284178  	0.09836522  
2023-06-06 09:31:50.701: Find a better model.
2023-06-06 09:31:59.616: [iter 63 : loss : 0.1594 = 0.0674 + 0.0881 + 0.0039, time: 8.913006]
2023-06-06 09:31:59.891: epoch 63:	0.02486651  	0.18279068  	0.09869488  
2023-06-06 09:32:08.128: [iter 64 : loss : 0.1583 = 0.0663 + 0.0880 + 0.0040, time: 8.234042]
2023-06-06 09:32:08.315: epoch 64:	0.02494412  	0.18306048  	0.09912474  
2023-06-06 09:32:08.315: Find a better model.
2023-06-06 09:32:17.223: [iter 65 : loss : 0.1572 = 0.0654 + 0.0878 + 0.0040, time: 8.905089]
2023-06-06 09:32:17.511: epoch 65:	0.02508526  	0.18420130  	0.09969873  
2023-06-06 09:32:17.511: Find a better model.
2023-06-06 09:32:25.714: [iter 66 : loss : 0.1554 = 0.0637 + 0.0877 + 0.0040, time: 8.200007]
2023-06-06 09:32:25.901: epoch 66:	0.02509231  	0.18407677  	0.09983932  
2023-06-06 09:32:34.794: [iter 67 : loss : 0.1543 = 0.0627 + 0.0875 + 0.0041, time: 8.889006]
2023-06-06 09:32:35.077: epoch 67:	0.02520521  	0.18482682  	0.10020690  
2023-06-06 09:32:35.077: Find a better model.
2023-06-06 09:32:43.362: [iter 68 : loss : 0.1539 = 0.0623 + 0.0874 + 0.0041, time: 8.283020]
2023-06-06 09:32:43.548: epoch 68:	0.02528989  	0.18533657  	0.10063110  
2023-06-06 09:32:43.548: Find a better model.
2023-06-06 09:32:52.399: [iter 69 : loss : 0.1518 = 0.0604 + 0.0873 + 0.0042, time: 8.842007]
2023-06-06 09:32:52.703: epoch 69:	0.02519110  	0.18452866  	0.10058159  
2023-06-06 09:33:00.958: [iter 70 : loss : 0.1503 = 0.0590 + 0.0871 + 0.0042, time: 8.253031]
2023-06-06 09:33:01.147: epoch 70:	0.02521227  	0.18490681  	0.10067988  
2023-06-06 09:33:10.005: [iter 71 : loss : 0.1490 = 0.0577 + 0.0870 + 0.0043, time: 8.849023]
2023-06-06 09:33:10.319: epoch 71:	0.02521933  	0.18470283  	0.10088389  
2023-06-06 09:33:18.511: [iter 72 : loss : 0.1487 = 0.0575 + 0.0869 + 0.0043, time: 8.191014]
2023-06-06 09:33:18.697: epoch 72:	0.02528284  	0.18547334  	0.10118270  
2023-06-06 09:33:18.697: Find a better model.
2023-06-06 09:33:27.526: [iter 73 : loss : 0.1474 = 0.0563 + 0.0868 + 0.0043, time: 8.820007]
2023-06-06 09:33:27.839: epoch 73:	0.02537457  	0.18592113  	0.10138001  
2023-06-06 09:33:27.839: Find a better model.
2023-06-06 09:33:36.145: [iter 74 : loss : 0.1459 = 0.0548 + 0.0867 + 0.0044, time: 8.304410]
2023-06-06 09:33:36.326: epoch 74:	0.02543103  	0.18669169  	0.10177289  
2023-06-06 09:33:36.326: Find a better model.
2023-06-06 09:33:45.222: [iter 75 : loss : 0.1454 = 0.0544 + 0.0865 + 0.0044, time: 8.893001]
2023-06-06 09:33:45.489: epoch 75:	0.02544514  	0.18689002  	0.10177276  
2023-06-06 09:33:45.489: Find a better model.
2023-06-06 09:33:53.814: [iter 76 : loss : 0.1444 = 0.0535 + 0.0864 + 0.0045, time: 8.323030]
2023-06-06 09:33:54.001: epoch 76:	0.02549453  	0.18700245  	0.10209756  
2023-06-06 09:33:54.001: Find a better model.
2023-06-06 09:34:02.794: [iter 77 : loss : 0.1436 = 0.0528 + 0.0863 + 0.0045, time: 8.785019]
2023-06-06 09:34:03.070: epoch 77:	0.02558627  	0.18762943  	0.10251535  
2023-06-06 09:34:03.070: Find a better model.
2023-06-06 09:34:11.333: [iter 78 : loss : 0.1428 = 0.0521 + 0.0862 + 0.0045, time: 8.262005]
2023-06-06 09:34:11.519: epoch 78:	0.02562155  	0.18815456  	0.10269964  
2023-06-06 09:34:11.519: Find a better model.
2023-06-06 09:34:20.270: [iter 79 : loss : 0.1413 = 0.0506 + 0.0861 + 0.0046, time: 8.744005]
2023-06-06 09:34:20.552: epoch 79:	0.02560745  	0.18803665  	0.10285234  
2023-06-06 09:34:28.954: [iter 80 : loss : 0.1406 = 0.0500 + 0.0860 + 0.0046, time: 8.399016]
2023-06-06 09:34:29.143: epoch 80:	0.02557216  	0.18777101  	0.10284992  
2023-06-06 09:34:37.977: [iter 81 : loss : 0.1405 = 0.0500 + 0.0859 + 0.0047, time: 8.831007]
2023-06-06 09:34:38.292: epoch 81:	0.02567801  	0.18866643  	0.10322306  
2023-06-06 09:34:38.292: Find a better model.
2023-06-06 09:34:46.667: [iter 82 : loss : 0.1391 = 0.0487 + 0.0858 + 0.0047, time: 8.374000]
2023-06-06 09:34:46.855: epoch 82:	0.02576268  	0.18936519  	0.10360405  
2023-06-06 09:34:46.855: Find a better model.
2023-06-06 09:34:55.668: [iter 83 : loss : 0.1382 = 0.0478 + 0.0857 + 0.0047, time: 8.810022]
2023-06-06 09:34:55.933: epoch 83:	0.02579796  	0.18952328  	0.10369452  
2023-06-06 09:34:55.933: Find a better model.
2023-06-06 09:35:04.367: [iter 84 : loss : 0.1381 = 0.0477 + 0.0856 + 0.0048, time: 8.433032]
2023-06-06 09:35:04.557: epoch 84:	0.02581913  	0.18961459  	0.10382637  
2023-06-06 09:35:04.557: Find a better model.
2023-06-06 09:35:13.268: [iter 85 : loss : 0.1372 = 0.0469 + 0.0855 + 0.0048, time: 8.707020]
2023-06-06 09:35:13.573: epoch 85:	0.02587558  	0.18999329  	0.10410798  
2023-06-06 09:35:13.573: Find a better model.
2023-06-06 09:35:22.119: [iter 86 : loss : 0.1369 = 0.0467 + 0.0853 + 0.0049, time: 8.545007]
2023-06-06 09:35:22.310: epoch 86:	0.02586853  	0.18974626  	0.10405864  
2023-06-06 09:35:30.981: [iter 87 : loss : 0.1343 = 0.0441 + 0.0853 + 0.0049, time: 8.660007]
2023-06-06 09:35:31.296: epoch 87:	0.02588264  	0.18988946  	0.10413978  
2023-06-06 09:35:39.944: [iter 88 : loss : 0.1337 = 0.0435 + 0.0852 + 0.0049, time: 8.646004]
2023-06-06 09:35:40.132: epoch 88:	0.02594615  	0.19060029  	0.10431774  
2023-06-06 09:35:40.132: Find a better model.
2023-06-06 09:35:48.852: [iter 89 : loss : 0.1336 = 0.0435 + 0.0851 + 0.0050, time: 8.718024]
2023-06-06 09:35:49.168: epoch 89:	0.02600966  	0.19089890  	0.10442499  
2023-06-06 09:35:49.168: Find a better model.
2023-06-06 09:35:57.794: [iter 90 : loss : 0.1341 = 0.0440 + 0.0850 + 0.0050, time: 8.625000]
2023-06-06 09:35:57.981: epoch 90:	0.02596731  	0.19078347  	0.10446414  
2023-06-06 09:36:06.679: [iter 91 : loss : 0.1326 = 0.0426 + 0.0849 + 0.0050, time: 8.690048]
2023-06-06 09:36:06.992: epoch 91:	0.02605199  	0.19160910  	0.10467067  
2023-06-06 09:36:06.992: Find a better model.
2023-06-06 09:36:15.533: [iter 92 : loss : 0.1315 = 0.0416 + 0.0849 + 0.0051, time: 8.540116]
2023-06-06 09:36:15.720: epoch 92:	0.02600965  	0.19132239  	0.10467744  
2023-06-06 09:36:24.393: [iter 93 : loss : 0.1321 = 0.0422 + 0.0848 + 0.0051, time: 8.663016]
2023-06-06 09:36:24.713: epoch 93:	0.02608728  	0.19202918  	0.10504870  
2023-06-06 09:36:24.713: Find a better model.
2023-06-06 09:36:33.263: [iter 94 : loss : 0.1301 = 0.0402 + 0.0847 + 0.0052, time: 8.548007]
2023-06-06 09:36:33.451: epoch 94:	0.02608728  	0.19195236  	0.10500607  
2023-06-06 09:36:42.169: [iter 95 : loss : 0.1293 = 0.0395 + 0.0846 + 0.0052, time: 8.715016]
2023-06-06 09:36:42.457: epoch 95:	0.02613667  	0.19233951  	0.10532168  
2023-06-06 09:36:42.457: Find a better model.
2023-06-06 09:36:50.995: [iter 96 : loss : 0.1294 = 0.0396 + 0.0845 + 0.0052, time: 8.529006]
2023-06-06 09:36:51.186: epoch 96:	0.02615079  	0.19265550  	0.10550682  
2023-06-06 09:36:51.186: Find a better model.
2023-06-06 09:37:00.023: [iter 97 : loss : 0.1278 = 0.0380 + 0.0845 + 0.0053, time: 8.828995]
2023-06-06 09:37:00.292: epoch 97:	0.02624957  	0.19361667  	0.10599896  
2023-06-06 09:37:00.292: Find a better model.
2023-06-06 09:37:08.777: [iter 98 : loss : 0.1284 = 0.0387 + 0.0844 + 0.0053, time: 8.484024]
2023-06-06 09:37:08.969: epoch 98:	0.02633426  	0.19419304  	0.10616049  
2023-06-06 09:37:08.969: Find a better model.
2023-06-06 09:37:17.680: [iter 99 : loss : 0.1274 = 0.0377 + 0.0843 + 0.0053, time: 8.704000]
2023-06-06 09:37:17.995: epoch 99:	0.02636954  	0.19432460  	0.10643259  
2023-06-06 09:37:17.995: Find a better model.
2023-06-06 09:37:26.595: [iter 100 : loss : 0.1270 = 0.0374 + 0.0843 + 0.0054, time: 8.597024]
2023-06-06 09:37:26.785: epoch 100:	0.02640482  	0.19444555  	0.10640970  
2023-06-06 09:37:26.785: Find a better model.
2023-06-06 09:37:35.514: [iter 101 : loss : 0.1264 = 0.0368 + 0.0842 + 0.0054, time: 8.722009]
2023-06-06 09:37:35.830: epoch 101:	0.02639071  	0.19443771  	0.10653567  
2023-06-06 09:37:44.417: [iter 102 : loss : 0.1255 = 0.0359 + 0.0841 + 0.0054, time: 8.586039]
2023-06-06 09:37:45.238: epoch 102:	0.02644716  	0.19491774  	0.10681689  
2023-06-06 09:37:45.238: Find a better model.
2023-06-06 09:37:55.386: [iter 103 : loss : 0.1254 = 0.0358 + 0.0840 + 0.0055, time: 10.138005]
2023-06-06 09:37:55.714: epoch 103:	0.02651067  	0.19553997  	0.10696319  
2023-06-06 09:37:55.715: Find a better model.
2023-06-06 09:38:04.494: [iter 104 : loss : 0.1256 = 0.0361 + 0.0840 + 0.0055, time: 8.775031]
2023-06-06 09:38:04.828: epoch 104:	0.02657417  	0.19618182  	0.10711142  
2023-06-06 09:38:04.828: Find a better model.
2023-06-06 09:38:13.506: [iter 105 : loss : 0.1251 = 0.0356 + 0.0839 + 0.0056, time: 8.675016]
2023-06-06 09:38:13.826: epoch 105:	0.02653889  	0.19593470  	0.10713522  
2023-06-06 09:38:22.554: [iter 106 : loss : 0.1245 = 0.0351 + 0.0839 + 0.0056, time: 8.726035]
2023-06-06 09:38:22.759: epoch 106:	0.02660945  	0.19641314  	0.10701062  
2023-06-06 09:38:22.759: Find a better model.
2023-06-06 09:38:31.393: [iter 107 : loss : 0.1235 = 0.0341 + 0.0838 + 0.0056, time: 8.630061]
2023-06-06 09:38:31.707: epoch 107:	0.02666590  	0.19658592  	0.10716487  
2023-06-06 09:38:31.707: Find a better model.
2023-06-06 09:38:40.282: [iter 108 : loss : 0.1235 = 0.0340 + 0.0838 + 0.0056, time: 8.573017]
2023-06-06 09:38:40.461: epoch 108:	0.02659534  	0.19613871  	0.10711934  
2023-06-06 09:38:49.128: [iter 109 : loss : 0.1222 = 0.0328 + 0.0837 + 0.0057, time: 8.660023]
2023-06-06 09:38:49.435: epoch 109:	0.02662357  	0.19635929  	0.10718822  
2023-06-06 09:38:57.894: [iter 110 : loss : 0.1215 = 0.0321 + 0.0836 + 0.0057, time: 8.458017]
2023-06-06 09:38:58.081: epoch 110:	0.02660945  	0.19609161  	0.10722357  
2023-06-06 09:39:06.679: [iter 111 : loss : 0.1216 = 0.0322 + 0.0836 + 0.0058, time: 8.586028]
2023-06-06 09:39:07.005: epoch 111:	0.02660239  	0.19589640  	0.10732201  
2023-06-06 09:39:15.590: [iter 112 : loss : 0.1213 = 0.0320 + 0.0835 + 0.0058, time: 8.584015]
2023-06-06 09:39:15.776: epoch 112:	0.02670824  	0.19677950  	0.10750952  
2023-06-06 09:39:15.776: Find a better model.
2023-06-06 09:39:24.598: [iter 113 : loss : 0.1212 = 0.0319 + 0.0835 + 0.0058, time: 8.816167]
2023-06-06 09:39:24.955: epoch 113:	0.02668707  	0.19700472  	0.10760789  
2023-06-06 09:39:24.956: Find a better model.
2023-06-06 09:39:34.297: [iter 114 : loss : 0.1203 = 0.0311 + 0.0834 + 0.0059, time: 9.338953]
2023-06-06 09:39:34.476: epoch 114:	0.02663062  	0.19642386  	0.10750742  
2023-06-06 09:39:43.123: [iter 115 : loss : 0.1200 = 0.0308 + 0.0833 + 0.0059, time: 8.644002]
2023-06-06 09:39:43.437: epoch 115:	0.02655300  	0.19559112  	0.10730997  
2023-06-06 09:39:51.945: [iter 116 : loss : 0.1193 = 0.0301 + 0.0833 + 0.0059, time: 8.506006]
2023-06-06 09:39:52.131: epoch 116:	0.02651065  	0.19505168  	0.10737180  
2023-06-06 09:40:00.710: [iter 117 : loss : 0.1193 = 0.0301 + 0.0832 + 0.0060, time: 8.574023]
2023-06-06 09:40:01.041: epoch 117:	0.02653183  	0.19542953  	0.10747056  
2023-06-06 09:40:09.616: [iter 118 : loss : 0.1191 = 0.0300 + 0.0832 + 0.0060, time: 8.571007]
2023-06-06 09:40:09.842: epoch 118:	0.02660945  	0.19628891  	0.10771815  
2023-06-06 09:40:18.501: [iter 119 : loss : 0.1181 = 0.0289 + 0.0831 + 0.0060, time: 8.656027]
2023-06-06 09:40:18.831: epoch 119:	0.02665179  	0.19662175  	0.10781930  
2023-06-06 09:40:27.448: [iter 120 : loss : 0.1186 = 0.0294 + 0.0831 + 0.0060, time: 8.615008]
2023-06-06 09:40:27.634: epoch 120:	0.02661651  	0.19608399  	0.10763850  
2023-06-06 09:40:36.285: [iter 121 : loss : 0.1183 = 0.0292 + 0.0830 + 0.0061, time: 8.647017]
2023-06-06 09:40:36.627: epoch 121:	0.02665178  	0.19644327  	0.10783176  
2023-06-06 09:40:45.190: [iter 122 : loss : 0.1176 = 0.0285 + 0.0830 + 0.0061, time: 8.562020]
2023-06-06 09:40:45.383: epoch 122:	0.02654594  	0.19571006  	0.10759625  
2023-06-06 09:40:54.260: [iter 123 : loss : 0.1175 = 0.0284 + 0.0829 + 0.0061, time: 8.874106]
2023-06-06 09:40:54.590: epoch 123:	0.02657416  	0.19606180  	0.10771766  
2023-06-06 09:41:03.113: [iter 124 : loss : 0.1163 = 0.0273 + 0.0829 + 0.0062, time: 8.522072]
2023-06-06 09:41:03.308: epoch 124:	0.02662356  	0.19616468  	0.10793409  
2023-06-06 09:41:12.028: [iter 125 : loss : 0.1159 = 0.0269 + 0.0828 + 0.0062, time: 8.714007]
2023-06-06 09:41:12.350: epoch 125:	0.02670118  	0.19680406  	0.10795332  
2023-06-06 09:41:20.814: [iter 126 : loss : 0.1160 = 0.0270 + 0.0828 + 0.0062, time: 8.461331]
2023-06-06 09:41:21.000: epoch 126:	0.02670118  	0.19705546  	0.10797159  
2023-06-06 09:41:21.000: Find a better model.
2023-06-06 09:41:27.692: [iter 127 : loss : 0.1151 = 0.0261 + 0.0828 + 0.0063, time: 6.691011]
2023-06-06 09:41:27.854: epoch 127:	0.02670824  	0.19700651  	0.10801638  
2023-06-06 09:41:34.513: [iter 128 : loss : 0.1163 = 0.0273 + 0.0827 + 0.0063, time: 6.658051]
2023-06-06 09:41:34.675: epoch 128:	0.02675763  	0.19722740  	0.10819752  
2023-06-06 09:41:34.676: Find a better model.
2023-06-06 09:41:41.257: [iter 129 : loss : 0.1153 = 0.0263 + 0.0827 + 0.0063, time: 6.580045]
2023-06-06 09:41:41.408: epoch 129:	0.02678585  	0.19740728  	0.10834749  
2023-06-06 09:41:41.408: Find a better model.
2023-06-06 09:41:48.052: [iter 130 : loss : 0.1154 = 0.0264 + 0.0826 + 0.0064, time: 6.643003]
2023-06-06 09:41:48.202: epoch 130:	0.02678586  	0.19742283  	0.10827924  
2023-06-06 09:41:48.202: Find a better model.
2023-06-06 09:41:54.852: [iter 131 : loss : 0.1143 = 0.0254 + 0.0826 + 0.0064, time: 6.649026]
2023-06-06 09:41:55.015: epoch 131:	0.02679292  	0.19733140  	0.10810590  
2023-06-06 09:42:01.675: [iter 132 : loss : 0.1147 = 0.0258 + 0.0825 + 0.0064, time: 6.657996]
2023-06-06 09:42:01.836: epoch 132:	0.02680703  	0.19701460  	0.10811941  
2023-06-06 09:42:08.651: [iter 133 : loss : 0.1134 = 0.0245 + 0.0825 + 0.0064, time: 6.814531]
2023-06-06 09:42:08.815: epoch 133:	0.02687054  	0.19764160  	0.10845358  
2023-06-06 09:42:08.815: Find a better model.
2023-06-06 09:42:15.464: [iter 134 : loss : 0.1142 = 0.0253 + 0.0824 + 0.0065, time: 6.648090]
2023-06-06 09:42:15.626: epoch 134:	0.02687760  	0.19762331  	0.10858183  
2023-06-06 09:42:22.325: [iter 135 : loss : 0.1138 = 0.0249 + 0.0824 + 0.0065, time: 6.698130]
2023-06-06 09:42:22.485: epoch 135:	0.02685642  	0.19712126  	0.10855051  
2023-06-06 09:42:29.237: [iter 136 : loss : 0.1135 = 0.0246 + 0.0824 + 0.0065, time: 6.750282]
2023-06-06 09:42:29.395: epoch 136:	0.02693405  	0.19756486  	0.10865846  
2023-06-06 09:42:36.042: [iter 137 : loss : 0.1133 = 0.0244 + 0.0823 + 0.0066, time: 6.644994]
2023-06-06 09:42:36.191: epoch 137:	0.02691288  	0.19772652  	0.10853868  
2023-06-06 09:42:36.191: Find a better model.
2023-06-06 09:42:42.842: [iter 138 : loss : 0.1129 = 0.0240 + 0.0823 + 0.0066, time: 6.648994]
2023-06-06 09:42:43.004: epoch 138:	0.02696933  	0.19836920  	0.10871794  
2023-06-06 09:42:43.005: Find a better model.
2023-06-06 09:42:49.648: [iter 139 : loss : 0.1126 = 0.0238 + 0.0822 + 0.0066, time: 6.641994]
2023-06-06 09:42:49.808: epoch 139:	0.02697638  	0.19815502  	0.10870037  
2023-06-06 09:42:56.441: [iter 140 : loss : 0.1120 = 0.0231 + 0.0822 + 0.0066, time: 6.632161]
2023-06-06 09:42:56.590: epoch 140:	0.02687760  	0.19748235  	0.10850275  
2023-06-06 09:43:03.262: [iter 141 : loss : 0.1128 = 0.0239 + 0.0822 + 0.0067, time: 6.662999]
2023-06-06 09:43:03.419: epoch 141:	0.02675764  	0.19653660  	0.10822663  
2023-06-06 09:43:10.025: [iter 142 : loss : 0.1117 = 0.0229 + 0.0821 + 0.0067, time: 6.604425]
2023-06-06 09:43:10.174: epoch 142:	0.02679998  	0.19679338  	0.10829293  
2023-06-06 09:43:16.825: [iter 143 : loss : 0.1118 = 0.0230 + 0.0821 + 0.0067, time: 6.650017]
2023-06-06 09:43:16.989: epoch 143:	0.02675058  	0.19630842  	0.10825710  
2023-06-06 09:43:23.645: [iter 144 : loss : 0.1113 = 0.0225 + 0.0821 + 0.0068, time: 6.654746]
2023-06-06 09:43:23.806: epoch 144:	0.02684231  	0.19700493  	0.10859331  
2023-06-06 09:43:30.433: [iter 145 : loss : 0.1113 = 0.0225 + 0.0820 + 0.0068, time: 6.626315]
2023-06-06 09:43:30.596: epoch 145:	0.02684937  	0.19705756  	0.10872065  
2023-06-06 09:43:37.252: [iter 146 : loss : 0.1115 = 0.0227 + 0.0820 + 0.0068, time: 6.654252]
2023-06-06 09:43:37.413: epoch 146:	0.02687053  	0.19685288  	0.10866768  
2023-06-06 09:43:44.019: [iter 147 : loss : 0.1113 = 0.0225 + 0.0820 + 0.0068, time: 6.604051]
2023-06-06 09:43:44.169: epoch 147:	0.02688465  	0.19722989  	0.10872626  
2023-06-06 09:43:50.654: [iter 148 : loss : 0.1102 = 0.0214 + 0.0819 + 0.0069, time: 6.483004]
2023-06-06 09:43:50.817: epoch 148:	0.02691287  	0.19728053  	0.10875115  
2023-06-06 09:43:57.408: [iter 149 : loss : 0.1107 = 0.0219 + 0.0819 + 0.0069, time: 6.588999]
2023-06-06 09:43:57.557: epoch 149:	0.02684936  	0.19668059  	0.10867233  
2023-06-06 09:44:04.209: [iter 150 : loss : 0.1099 = 0.0211 + 0.0819 + 0.0069, time: 6.651233]
2023-06-06 09:44:04.363: epoch 150:	0.02685642  	0.19673614  	0.10864142  
2023-06-06 09:44:11.001: [iter 151 : loss : 0.1101 = 0.0213 + 0.0819 + 0.0069, time: 6.636053]
2023-06-06 09:44:11.162: epoch 151:	0.02683525  	0.19684984  	0.10884575  
2023-06-06 09:44:17.820: [iter 152 : loss : 0.1094 = 0.0206 + 0.0818 + 0.0070, time: 6.657012]
2023-06-06 09:44:17.986: epoch 152:	0.02683525  	0.19670022  	0.10877828  
2023-06-06 09:44:24.618: [iter 153 : loss : 0.1086 = 0.0199 + 0.0818 + 0.0070, time: 6.630987]
2023-06-06 09:44:24.765: epoch 153:	0.02689876  	0.19732295  	0.10907340  
2023-06-06 09:44:31.422: [iter 154 : loss : 0.1092 = 0.0204 + 0.0817 + 0.0070, time: 6.655994]
2023-06-06 09:44:31.585: epoch 154:	0.02687053  	0.19705568  	0.10904079  
2023-06-06 09:44:38.210: [iter 155 : loss : 0.1098 = 0.0210 + 0.0817 + 0.0070, time: 6.623998]
2023-06-06 09:44:38.364: epoch 155:	0.02681408  	0.19642788  	0.10887159  
2023-06-06 09:44:45.002: [iter 156 : loss : 0.1091 = 0.0203 + 0.0817 + 0.0071, time: 6.637018]
2023-06-06 09:44:45.165: epoch 156:	0.02684231  	0.19661225  	0.10886301  
2023-06-06 09:44:51.784: [iter 157 : loss : 0.1090 = 0.0203 + 0.0817 + 0.0071, time: 6.618001]
2023-06-06 09:44:51.935: epoch 157:	0.02681408  	0.19659747  	0.10898715  
2023-06-06 09:44:58.588: [iter 158 : loss : 0.1082 = 0.0195 + 0.0816 + 0.0071, time: 6.652335]
2023-06-06 09:44:58.734: epoch 158:	0.02679292  	0.19656183  	0.10873518  
2023-06-06 09:45:05.400: [iter 159 : loss : 0.1085 = 0.0198 + 0.0816 + 0.0071, time: 6.665001]
2023-06-06 09:45:05.555: epoch 159:	0.02689876  	0.19712184  	0.10909830  
2023-06-06 09:45:12.188: [iter 160 : loss : 0.1081 = 0.0194 + 0.0816 + 0.0072, time: 6.631412]
2023-06-06 09:45:12.340: epoch 160:	0.02684936  	0.19670121  	0.10897207  
2023-06-06 09:45:19.016: [iter 161 : loss : 0.1076 = 0.0189 + 0.0816 + 0.0072, time: 6.673471]
2023-06-06 09:45:19.169: epoch 161:	0.02687053  	0.19687437  	0.10886928  
2023-06-06 09:45:25.788: [iter 162 : loss : 0.1071 = 0.0183 + 0.0815 + 0.0072, time: 6.617021]
2023-06-06 09:45:25.941: epoch 162:	0.02687053  	0.19669245  	0.10894642  
2023-06-06 09:45:32.586: [iter 163 : loss : 0.1075 = 0.0188 + 0.0815 + 0.0072, time: 6.644105]
2023-06-06 09:45:32.739: epoch 163:	0.02685642  	0.19682650  	0.10895765  
2023-06-06 09:45:32.739: Early stopping is trigger at epoch: 163
2023-06-06 09:45:32.739: best_result@epoch 138:

2023-06-06 09:45:32.739: 		0.0270      	0.1984      	0.1087      
2023-06-06 09:50:15.337: my pid: 4420
2023-06-06 09:50:15.337: model: model.general_recommender.SGL
2023-06-06 09:50:15.337: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-06-06 09:50:15.337: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-06 09:50:18.547: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-06 09:50:25.887: [iter 1 : loss : 0.7720 = 0.6930 + 0.0790 + 0.0000, time: 7.340321]
2023-06-06 09:50:26.037: epoch 1:	0.00221564  	0.01526994  	0.00757922  
2023-06-06 09:50:26.037: Find a better model.
2023-06-06 09:50:33.690: [iter 2 : loss : 0.7716 = 0.6927 + 0.0788 + 0.0000, time: 7.651614]
2023-06-06 09:50:33.904: epoch 2:	0.00436069  	0.03050231  	0.01531526  
2023-06-06 09:50:33.904: Find a better model.
2023-06-06 09:50:41.273: [iter 3 : loss : 0.7712 = 0.6923 + 0.0789 + 0.0000, time: 7.368205]
2023-06-06 09:50:41.445: epoch 3:	0.00749359  	0.05374757  	0.02604349  
2023-06-06 09:50:41.445: Find a better model.
2023-06-06 09:50:48.660: [iter 4 : loss : 0.7705 = 0.6914 + 0.0791 + 0.0000, time: 7.212439]
2023-06-06 09:50:48.827: epoch 4:	0.01102174  	0.07858300  	0.03788975  
2023-06-06 09:50:48.827: Find a better model.
2023-06-06 09:50:55.838: [iter 5 : loss : 0.7686 = 0.6893 + 0.0794 + 0.0000, time: 7.010379]
2023-06-06 09:50:55.985: epoch 5:	0.01452174  	0.10421766  	0.05040441  
2023-06-06 09:50:55.985: Find a better model.
2023-06-06 09:51:02.857: [iter 6 : loss : 0.7640 = 0.6840 + 0.0800 + 0.0000, time: 6.871005]
2023-06-06 09:51:03.002: epoch 6:	0.01706910  	0.12278593  	0.06132984  
2023-06-06 09:51:03.002: Find a better model.
2023-06-06 09:51:09.658: [iter 7 : loss : 0.7521 = 0.6707 + 0.0813 + 0.0001, time: 6.655010]
2023-06-06 09:51:09.821: epoch 7:	0.01851566  	0.13480489  	0.06790141  
2023-06-06 09:51:09.821: Find a better model.
2023-06-06 09:51:16.472: [iter 8 : loss : 0.7249 = 0.6404 + 0.0844 + 0.0001, time: 6.649327]
2023-06-06 09:51:16.629: epoch 8:	0.01879087  	0.13847187  	0.06921651  
2023-06-06 09:51:16.629: Find a better model.
2023-06-06 09:51:23.230: [iter 9 : loss : 0.6732 = 0.5837 + 0.0893 + 0.0002, time: 6.597465]
2023-06-06 09:51:23.380: epoch 9:	0.01864268  	0.13826260  	0.06853525  
2023-06-06 09:51:29.840: [iter 10 : loss : 0.6019 = 0.5071 + 0.0945 + 0.0003, time: 6.458001]
2023-06-06 09:51:29.986: epoch 10:	0.01859329  	0.13785908  	0.06830364  
2023-06-06 09:51:36.412: [iter 11 : loss : 0.5302 = 0.4313 + 0.0984 + 0.0005, time: 6.424254]
2023-06-06 09:51:36.559: epoch 11:	0.01843804  	0.13700619  	0.06804857  
2023-06-06 09:51:43.030: [iter 12 : loss : 0.4723 = 0.3711 + 0.1006 + 0.0006, time: 6.470088]
2023-06-06 09:51:43.188: epoch 12:	0.01853684  	0.13742857  	0.06874239  
2023-06-06 09:51:49.645: [iter 13 : loss : 0.4308 = 0.3282 + 0.1018 + 0.0008, time: 6.453393]
2023-06-06 09:51:49.805: epoch 13:	0.01860034  	0.13787290  	0.06930932  
2023-06-06 09:51:56.420: [iter 14 : loss : 0.3987 = 0.2955 + 0.1023 + 0.0009, time: 6.613336]
2023-06-06 09:51:56.578: epoch 14:	0.01885438  	0.13985136  	0.07051347  
2023-06-06 09:51:56.578: Find a better model.
2023-06-06 09:52:03.027: [iter 15 : loss : 0.3761 = 0.2727 + 0.1024 + 0.0010, time: 6.447998]
2023-06-06 09:52:03.173: epoch 15:	0.01916486  	0.14193055  	0.07164008  
2023-06-06 09:52:03.173: Find a better model.
2023-06-06 09:52:09.629: [iter 16 : loss : 0.3564 = 0.2529 + 0.1023 + 0.0012, time: 6.453017]
2023-06-06 09:52:09.776: epoch 16:	0.01938362  	0.14311571  	0.07233466  
2023-06-06 09:52:09.776: Find a better model.
2023-06-06 09:52:16.224: [iter 17 : loss : 0.3416 = 0.2384 + 0.1020 + 0.0013, time: 6.446323]
2023-06-06 09:52:16.372: epoch 17:	0.01959532  	0.14491956  	0.07326522  
2023-06-06 09:52:16.372: Find a better model.
2023-06-06 09:52:22.850: [iter 18 : loss : 0.3275 = 0.2244 + 0.1017 + 0.0014, time: 6.476015]
2023-06-06 09:52:23.008: epoch 18:	0.01984230  	0.14688779  	0.07436250  
2023-06-06 09:52:23.008: Find a better model.
2023-06-06 09:52:29.635: [iter 19 : loss : 0.3144 = 0.2115 + 0.1014 + 0.0015, time: 6.624995]
2023-06-06 09:52:29.796: epoch 19:	0.02002577  	0.14796695  	0.07504325  
2023-06-06 09:52:29.796: Find a better model.
2023-06-06 09:52:36.426: [iter 20 : loss : 0.3053 = 0.2028 + 0.1010 + 0.0015, time: 6.629019]
2023-06-06 09:52:36.587: epoch 20:	0.02021629  	0.14900865  	0.07567476  
2023-06-06 09:52:36.587: Find a better model.
2023-06-06 09:52:43.229: [iter 21 : loss : 0.2961 = 0.1940 + 0.1005 + 0.0016, time: 6.640459]
2023-06-06 09:52:43.388: epoch 21:	0.02037860  	0.15047877  	0.07659443  
2023-06-06 09:52:43.388: Find a better model.
2023-06-06 09:52:49.831: [iter 22 : loss : 0.2882 = 0.1864 + 0.1001 + 0.0017, time: 6.442011]
2023-06-06 09:52:49.990: epoch 22:	0.02048444  	0.15099365  	0.07719886  
2023-06-06 09:52:49.990: Find a better model.
2023-06-06 09:52:56.591: [iter 23 : loss : 0.2802 = 0.1787 + 0.0997 + 0.0018, time: 6.600653]
2023-06-06 09:52:56.736: epoch 23:	0.02070319  	0.15238787  	0.07802155  
2023-06-06 09:52:56.737: Find a better model.
2023-06-06 09:53:03.230: [iter 24 : loss : 0.2740 = 0.1730 + 0.0992 + 0.0018, time: 6.491463]
2023-06-06 09:53:03.392: epoch 24:	0.02083021  	0.15338162  	0.07854630  
2023-06-06 09:53:03.392: Find a better model.
2023-06-06 09:53:09.816: [iter 25 : loss : 0.2674 = 0.1666 + 0.0989 + 0.0019, time: 6.422011]
2023-06-06 09:53:09.961: epoch 25:	0.02102073  	0.15496889  	0.07904340  
2023-06-06 09:53:09.961: Find a better model.
2023-06-06 09:53:16.405: [iter 26 : loss : 0.2641 = 0.1637 + 0.0984 + 0.0020, time: 6.442027]
2023-06-06 09:53:16.550: epoch 26:	0.02125360  	0.15681820  	0.07996786  
2023-06-06 09:53:16.550: Find a better model.
2023-06-06 09:53:23.007: [iter 27 : loss : 0.2565 = 0.1564 + 0.0980 + 0.0021, time: 6.455024]
2023-06-06 09:53:23.167: epoch 27:	0.02143707  	0.15781142  	0.08074690  
2023-06-06 09:53:23.167: Find a better model.
2023-06-06 09:53:29.616: [iter 28 : loss : 0.2517 = 0.1520 + 0.0976 + 0.0021, time: 6.447371]
2023-06-06 09:53:29.775: epoch 28:	0.02157821  	0.15890542  	0.08152188  
2023-06-06 09:53:29.775: Find a better model.
2023-06-06 09:53:36.200: [iter 29 : loss : 0.2475 = 0.1482 + 0.0972 + 0.0022, time: 6.422113]
2023-06-06 09:53:36.364: epoch 29:	0.02181107  	0.16065875  	0.08225199  
2023-06-06 09:53:36.364: Find a better model.
2023-06-06 09:53:42.799: [iter 30 : loss : 0.2409 = 0.1418 + 0.0968 + 0.0022, time: 6.434104]
2023-06-06 09:53:42.957: epoch 30:	0.02190985  	0.16103753  	0.08282952  
2023-06-06 09:53:42.957: Find a better model.
2023-06-06 09:53:49.409: [iter 31 : loss : 0.2377 = 0.1389 + 0.0965 + 0.0023, time: 6.449006]
2023-06-06 09:53:49.568: epoch 31:	0.02208627  	0.16241807  	0.08364556  
2023-06-06 09:53:49.568: Find a better model.
2023-06-06 09:53:55.993: [iter 32 : loss : 0.2321 = 0.1336 + 0.0961 + 0.0024, time: 6.423222]
2023-06-06 09:53:56.137: epoch 32:	0.02223445  	0.16349787  	0.08447644  
2023-06-06 09:53:56.137: Find a better model.
2023-06-06 09:54:02.619: [iter 33 : loss : 0.2297 = 0.1315 + 0.0957 + 0.0024, time: 6.480025]
2023-06-06 09:54:02.782: epoch 33:	0.02234736  	0.16429953  	0.08506086  
2023-06-06 09:54:02.782: Find a better model.
2023-06-06 09:54:09.376: [iter 34 : loss : 0.2254 = 0.1275 + 0.0954 + 0.0025, time: 6.591311]
2023-06-06 09:54:09.535: epoch 34:	0.02246731  	0.16484624  	0.08558924  
2023-06-06 09:54:09.535: Find a better model.
2023-06-06 09:54:16.194: [iter 35 : loss : 0.2221 = 0.1244 + 0.0951 + 0.0025, time: 6.657974]
2023-06-06 09:54:16.340: epoch 35:	0.02262255  	0.16617613  	0.08633794  
2023-06-06 09:54:16.341: Find a better model.
2023-06-06 09:54:22.776: [iter 36 : loss : 0.2187 = 0.1213 + 0.0948 + 0.0026, time: 6.433994]
2023-06-06 09:54:22.926: epoch 36:	0.02274957  	0.16747332  	0.08696788  
2023-06-06 09:54:22.926: Find a better model.
2023-06-06 09:54:29.569: [iter 37 : loss : 0.2149 = 0.1177 + 0.0945 + 0.0026, time: 6.640481]
2023-06-06 09:54:29.719: epoch 37:	0.02275663  	0.16782232  	0.08742718  
2023-06-06 09:54:29.719: Find a better model.
2023-06-06 09:54:36.374: [iter 38 : loss : 0.2136 = 0.1167 + 0.0942 + 0.0027, time: 6.653212]
2023-06-06 09:54:36.528: epoch 38:	0.02296126  	0.16912845  	0.08818092  
2023-06-06 09:54:36.528: Find a better model.
2023-06-06 09:54:43.176: [iter 39 : loss : 0.2090 = 0.1124 + 0.0939 + 0.0028, time: 6.645994]
2023-06-06 09:54:43.324: epoch 39:	0.02304595  	0.16981047  	0.08875472  
2023-06-06 09:54:43.324: Find a better model.
2023-06-06 09:54:49.976: [iter 40 : loss : 0.2057 = 0.1093 + 0.0936 + 0.0028, time: 6.649969]
2023-06-06 09:54:50.125: epoch 40:	0.02311651  	0.17051481  	0.08923428  
2023-06-06 09:54:50.125: Find a better model.
2023-06-06 09:54:56.756: [iter 41 : loss : 0.2044 = 0.1081 + 0.0934 + 0.0029, time: 6.628964]
2023-06-06 09:54:56.905: epoch 41:	0.02316591  	0.17079745  	0.08944334  
2023-06-06 09:54:56.905: Find a better model.
2023-06-06 09:55:03.574: [iter 42 : loss : 0.2022 = 0.1062 + 0.0931 + 0.0029, time: 6.668372]
2023-06-06 09:55:03.723: epoch 42:	0.02330704  	0.17164809  	0.08999967  
2023-06-06 09:55:03.724: Find a better model.
2023-06-06 09:55:10.353: [iter 43 : loss : 0.1983 = 0.1025 + 0.0928 + 0.0030, time: 6.627474]
2023-06-06 09:55:10.501: epoch 43:	0.02341289  	0.17235419  	0.09056564  
2023-06-06 09:55:10.502: Find a better model.
2023-06-06 09:55:16.963: [iter 44 : loss : 0.1948 = 0.0993 + 0.0925 + 0.0030, time: 6.459998]
2023-06-06 09:55:17.114: epoch 44:	0.02351873  	0.17335144  	0.09112495  
2023-06-06 09:55:17.115: Find a better model.
2023-06-06 09:55:23.759: [iter 45 : loss : 0.1926 = 0.0972 + 0.0923 + 0.0031, time: 6.642004]
2023-06-06 09:55:23.908: epoch 45:	0.02359636  	0.17345563  	0.09152825  
2023-06-06 09:55:23.908: Find a better model.
2023-06-06 09:55:30.531: [iter 46 : loss : 0.1902 = 0.0950 + 0.0921 + 0.0031, time: 6.620994]
2023-06-06 09:55:30.681: epoch 46:	0.02371631  	0.17420608  	0.09203725  
2023-06-06 09:55:30.681: Find a better model.
2023-06-06 09:55:37.349: [iter 47 : loss : 0.1896 = 0.0946 + 0.0918 + 0.0032, time: 6.666814]
2023-06-06 09:55:37.502: epoch 47:	0.02382922  	0.17528175  	0.09256405  
2023-06-06 09:55:37.502: Find a better model.
2023-06-06 09:55:44.137: [iter 48 : loss : 0.1857 = 0.0909 + 0.0916 + 0.0032, time: 6.632994]
2023-06-06 09:55:44.286: epoch 48:	0.02398446  	0.17649707  	0.09303872  
2023-06-06 09:55:44.286: Find a better model.
2023-06-06 09:55:50.951: [iter 49 : loss : 0.1827 = 0.0881 + 0.0914 + 0.0033, time: 6.664222]
2023-06-06 09:55:51.102: epoch 49:	0.02402680  	0.17659324  	0.09335025  
2023-06-06 09:55:51.102: Find a better model.
2023-06-06 09:55:57.738: [iter 50 : loss : 0.1819 = 0.0874 + 0.0912 + 0.0033, time: 6.634955]
2023-06-06 09:55:57.887: epoch 50:	0.02406914  	0.17699200  	0.09369277  
2023-06-06 09:55:57.887: Find a better model.
2023-06-06 09:56:04.722: [iter 51 : loss : 0.1789 = 0.0845 + 0.0911 + 0.0034, time: 6.834524]
2023-06-06 09:56:04.874: epoch 51:	0.02407619  	0.17727074  	0.09399707  
2023-06-06 09:56:04.874: Find a better model.
2023-06-06 09:56:11.732: [iter 52 : loss : 0.1788 = 0.0846 + 0.0908 + 0.0034, time: 6.856096]
2023-06-06 09:56:11.881: epoch 52:	0.02418909  	0.17840303  	0.09462878  
2023-06-06 09:56:11.881: Find a better model.
2023-06-06 09:56:18.731: [iter 53 : loss : 0.1767 = 0.0826 + 0.0906 + 0.0034, time: 6.848149]
2023-06-06 09:56:18.884: epoch 53:	0.02420320  	0.17839460  	0.09475725  
2023-06-06 09:56:25.916: [iter 54 : loss : 0.1749 = 0.0810 + 0.0904 + 0.0035, time: 7.029993]
2023-06-06 09:56:26.064: epoch 54:	0.02442195  	0.17991744  	0.09550700  
2023-06-06 09:56:26.064: Find a better model.
2023-06-06 09:56:32.921: [iter 55 : loss : 0.1730 = 0.0792 + 0.0903 + 0.0035, time: 6.854997]
2023-06-06 09:56:33.073: epoch 55:	0.02442195  	0.17992432  	0.09571549  
2023-06-06 09:56:33.074: Find a better model.
2023-06-06 09:56:39.923: [iter 56 : loss : 0.1710 = 0.0774 + 0.0900 + 0.0036, time: 6.848286]
2023-06-06 09:56:40.073: epoch 56:	0.02442901  	0.17985316  	0.09599603  
2023-06-06 09:56:46.922: [iter 57 : loss : 0.1693 = 0.0758 + 0.0899 + 0.0036, time: 6.847983]
2023-06-06 09:56:47.072: epoch 57:	0.02456308  	0.18120821  	0.09649271  
2023-06-06 09:56:47.073: Find a better model.
2023-06-06 09:56:53.927: [iter 58 : loss : 0.1676 = 0.0742 + 0.0897 + 0.0037, time: 6.851996]
2023-06-06 09:56:54.076: epoch 58:	0.02457014  	0.18128709  	0.09662072  
2023-06-06 09:56:54.076: Find a better model.
2023-06-06 09:57:00.923: [iter 59 : loss : 0.1664 = 0.0732 + 0.0895 + 0.0037, time: 6.844485]
2023-06-06 09:57:01.073: epoch 59:	0.02461248  	0.18205209  	0.09728011  
2023-06-06 09:57:01.073: Find a better model.
2023-06-06 09:57:07.922: [iter 60 : loss : 0.1648 = 0.0717 + 0.0894 + 0.0038, time: 6.847926]
2023-06-06 09:57:08.075: epoch 60:	0.02475361  	0.18319893  	0.09789711  
2023-06-06 09:57:08.075: Find a better model.
2023-06-06 09:57:14.914: [iter 61 : loss : 0.1636 = 0.0706 + 0.0892 + 0.0038, time: 6.837994]
2023-06-06 09:57:15.062: epoch 61:	0.02478183  	0.18308745  	0.09804786  
2023-06-06 09:57:21.922: [iter 62 : loss : 0.1621 = 0.0692 + 0.0891 + 0.0039, time: 6.859006]
2023-06-06 09:57:22.070: epoch 62:	0.02483123  	0.18358587  	0.09832785  
2023-06-06 09:57:22.070: Find a better model.
2023-06-06 09:57:28.902: [iter 63 : loss : 0.1608 = 0.0681 + 0.0889 + 0.0039, time: 6.828994]
2023-06-06 09:57:29.055: epoch 63:	0.02482417  	0.18355748  	0.09849668  
2023-06-06 09:57:35.905: [iter 64 : loss : 0.1596 = 0.0670 + 0.0887 + 0.0039, time: 6.849000]
2023-06-06 09:57:36.055: epoch 64:	0.02496530  	0.18413626  	0.09884368  
2023-06-06 09:57:36.055: Find a better model.
2023-06-06 09:57:42.908: [iter 65 : loss : 0.1584 = 0.0659 + 0.0886 + 0.0040, time: 6.851990]
2023-06-06 09:57:43.058: epoch 65:	0.02495119  	0.18440151  	0.09910413  
2023-06-06 09:57:43.058: Find a better model.
2023-06-06 09:57:49.896: [iter 66 : loss : 0.1569 = 0.0645 + 0.0884 + 0.0040, time: 6.836357]
2023-06-06 09:57:50.048: epoch 66:	0.02499353  	0.18488985  	0.09925508  
2023-06-06 09:57:50.048: Find a better model.
2023-06-06 09:57:56.882: [iter 67 : loss : 0.1555 = 0.0631 + 0.0883 + 0.0041, time: 6.832489]
2023-06-06 09:57:57.031: epoch 67:	0.02495119  	0.18474708  	0.09959850  
2023-06-06 09:58:03.885: [iter 68 : loss : 0.1552 = 0.0630 + 0.0881 + 0.0041, time: 6.852994]
2023-06-06 09:58:04.034: epoch 68:	0.02502175  	0.18514173  	0.09973151  
2023-06-06 09:58:04.034: Find a better model.
2023-06-06 09:58:10.899: [iter 69 : loss : 0.1532 = 0.0610 + 0.0880 + 0.0042, time: 6.863398]
2023-06-06 09:58:11.047: epoch 69:	0.02507820  	0.18578076  	0.10025297  
2023-06-06 09:58:11.048: Find a better model.
2023-06-06 09:58:17.890: [iter 70 : loss : 0.1517 = 0.0597 + 0.0879 + 0.0042, time: 6.841001]
2023-06-06 09:58:18.044: epoch 70:	0.02509937  	0.18592757  	0.10043650  
2023-06-06 09:58:18.045: Find a better model.
2023-06-06 09:58:24.889: [iter 71 : loss : 0.1503 = 0.0583 + 0.0878 + 0.0042, time: 6.842993]
2023-06-06 09:58:25.042: epoch 71:	0.02515582  	0.18630514  	0.10094692  
2023-06-06 09:58:25.043: Find a better model.
2023-06-06 09:58:31.882: [iter 72 : loss : 0.1499 = 0.0579 + 0.0877 + 0.0043, time: 6.837999]
2023-06-06 09:58:32.035: epoch 72:	0.02516288  	0.18615346  	0.10113543  
2023-06-06 09:58:38.899: [iter 73 : loss : 0.1486 = 0.0567 + 0.0875 + 0.0043, time: 6.861994]
2023-06-06 09:58:39.048: epoch 73:	0.02520522  	0.18686770  	0.10150691  
2023-06-06 09:58:39.049: Find a better model.
2023-06-06 09:58:45.875: [iter 74 : loss : 0.1471 = 0.0553 + 0.0874 + 0.0044, time: 6.825322]
2023-06-06 09:58:46.026: epoch 74:	0.02528990  	0.18730323  	0.10187788  
2023-06-06 09:58:46.026: Find a better model.
2023-06-06 09:58:52.887: [iter 75 : loss : 0.1467 = 0.0550 + 0.0873 + 0.0044, time: 6.858993]
2023-06-06 09:58:53.036: epoch 75:	0.02538869  	0.18803971  	0.10217515  
2023-06-06 09:58:53.036: Find a better model.
2023-06-06 09:58:59.886: [iter 76 : loss : 0.1458 = 0.0542 + 0.0872 + 0.0044, time: 6.848418]
2023-06-06 09:59:00.038: epoch 76:	0.02545925  	0.18801932  	0.10237280  
2023-06-06 09:59:06.875: [iter 77 : loss : 0.1448 = 0.0533 + 0.0870 + 0.0045, time: 6.833993]
2023-06-06 09:59:07.024: epoch 77:	0.02543102  	0.18812892  	0.10273890  
2023-06-06 09:59:07.024: Find a better model.
2023-06-06 09:59:13.879: [iter 78 : loss : 0.1440 = 0.0525 + 0.0870 + 0.0045, time: 6.854418]
2023-06-06 09:59:14.032: epoch 78:	0.02547336  	0.18813562  	0.10302718  
2023-06-06 09:59:14.032: Find a better model.
2023-06-06 09:59:20.853: [iter 79 : loss : 0.1425 = 0.0511 + 0.0868 + 0.0046, time: 6.820011]
2023-06-06 09:59:21.004: epoch 79:	0.02550864  	0.18835542  	0.10321226  
2023-06-06 09:59:21.004: Find a better model.
2023-06-06 09:59:27.873: [iter 80 : loss : 0.1419 = 0.0505 + 0.0868 + 0.0046, time: 6.866993]
2023-06-06 09:59:28.025: epoch 80:	0.02557920  	0.18872437  	0.10344315  
2023-06-06 09:59:28.025: Find a better model.
2023-06-06 09:59:34.869: [iter 81 : loss : 0.1416 = 0.0503 + 0.0866 + 0.0046, time: 6.843129]
2023-06-06 09:59:35.019: epoch 81:	0.02558626  	0.18871631  	0.10348858  
2023-06-06 09:59:41.868: [iter 82 : loss : 0.1404 = 0.0491 + 0.0865 + 0.0047, time: 6.846998]
2023-06-06 09:59:42.017: epoch 82:	0.02562860  	0.18909372  	0.10361836  
2023-06-06 09:59:42.017: Find a better model.
2023-06-06 09:59:48.851: [iter 83 : loss : 0.1395 = 0.0484 + 0.0865 + 0.0047, time: 6.831993]
2023-06-06 09:59:49.001: epoch 83:	0.02568506  	0.18968439  	0.10389277  
2023-06-06 09:59:49.001: Find a better model.
2023-06-06 09:59:55.667: [iter 84 : loss : 0.1394 = 0.0483 + 0.0864 + 0.0048, time: 6.663353]
2023-06-06 09:59:55.819: epoch 84:	0.02572740  	0.19040962  	0.10415584  
2023-06-06 09:59:55.819: Find a better model.
2023-06-06 10:00:02.647: [iter 85 : loss : 0.1384 = 0.0474 + 0.0862 + 0.0048, time: 6.825996]
2023-06-06 10:00:02.796: epoch 85:	0.02577679  	0.19073468  	0.10440326  
2023-06-06 10:00:02.796: Find a better model.
2023-06-06 10:00:09.462: [iter 86 : loss : 0.1382 = 0.0472 + 0.0861 + 0.0048, time: 6.663564]
2023-06-06 10:00:09.614: epoch 86:	0.02576974  	0.19081999  	0.10456161  
2023-06-06 10:00:09.614: Find a better model.
2023-06-06 10:00:16.443: [iter 87 : loss : 0.1355 = 0.0446 + 0.0861 + 0.0049, time: 6.828439]
2023-06-06 10:00:16.594: epoch 87:	0.02582619  	0.19083522  	0.10472548  
2023-06-06 10:00:16.594: Find a better model.
2023-06-06 10:00:23.258: [iter 88 : loss : 0.1349 = 0.0440 + 0.0860 + 0.0049, time: 6.662994]
2023-06-06 10:00:23.408: epoch 88:	0.02588264  	0.19164205  	0.10497732  
2023-06-06 10:00:23.408: Find a better model.
2023-06-06 10:00:30.252: [iter 89 : loss : 0.1347 = 0.0438 + 0.0859 + 0.0050, time: 6.841996]
2023-06-06 10:00:30.403: epoch 89:	0.02589676  	0.19221483  	0.10522485  
2023-06-06 10:00:30.403: Find a better model.
2023-06-06 10:00:37.057: [iter 90 : loss : 0.1352 = 0.0444 + 0.0858 + 0.0050, time: 6.652994]
2023-06-06 10:00:37.207: epoch 90:	0.02603788  	0.19304915  	0.10558078  
2023-06-06 10:00:37.207: Find a better model.
2023-06-06 10:00:44.028: [iter 91 : loss : 0.1338 = 0.0430 + 0.0857 + 0.0050, time: 6.819988]
2023-06-06 10:00:44.178: epoch 91:	0.02610140  	0.19350262  	0.10585506  
2023-06-06 10:00:44.178: Find a better model.
2023-06-06 10:00:50.845: [iter 92 : loss : 0.1329 = 0.0422 + 0.0856 + 0.0051, time: 6.664271]
2023-06-06 10:00:50.994: epoch 92:	0.02611550  	0.19376577  	0.10605239  
2023-06-06 10:00:50.994: Find a better model.
2023-06-06 10:00:57.646: [iter 93 : loss : 0.1333 = 0.0426 + 0.0856 + 0.0051, time: 6.650371]
2023-06-06 10:00:57.796: epoch 93:	0.02622135  	0.19422141  	0.10631616  
2023-06-06 10:00:57.796: Find a better model.
2023-06-06 10:01:04.628: [iter 94 : loss : 0.1312 = 0.0406 + 0.0855 + 0.0051, time: 6.830994]
2023-06-06 10:01:04.779: epoch 94:	0.02616490  	0.19389999  	0.10626461  
2023-06-06 10:01:11.617: [iter 95 : loss : 0.1305 = 0.0399 + 0.0854 + 0.0052, time: 6.836276]
2023-06-06 10:01:11.770: epoch 95:	0.02617196  	0.19384593  	0.10635287  
2023-06-06 10:01:18.618: [iter 96 : loss : 0.1306 = 0.0401 + 0.0853 + 0.0052, time: 6.846002]
2023-06-06 10:01:18.768: epoch 96:	0.02618607  	0.19423231  	0.10656641  
2023-06-06 10:01:18.768: Find a better model.
2023-06-06 10:01:25.617: [iter 97 : loss : 0.1289 = 0.0385 + 0.0852 + 0.0052, time: 6.847999]
2023-06-06 10:01:25.767: epoch 97:	0.02623546  	0.19415531  	0.10658611  
2023-06-06 10:01:32.620: [iter 98 : loss : 0.1297 = 0.0393 + 0.0852 + 0.0053, time: 6.852471]
2023-06-06 10:01:32.773: epoch 98:	0.02628485  	0.19460770  	0.10680469  
2023-06-06 10:01:32.773: Find a better model.
2023-06-06 10:01:39.626: [iter 99 : loss : 0.1285 = 0.0381 + 0.0851 + 0.0053, time: 6.851075]
2023-06-06 10:01:39.776: epoch 99:	0.02629191  	0.19458948  	0.10684904  
2023-06-06 10:01:46.431: [iter 100 : loss : 0.1281 = 0.0377 + 0.0850 + 0.0053, time: 6.652020]
2023-06-06 10:01:46.584: epoch 100:	0.02633425  	0.19487640  	0.10687791  
2023-06-06 10:01:46.584: Find a better model.
2023-06-06 10:01:53.407: [iter 101 : loss : 0.1276 = 0.0372 + 0.0850 + 0.0054, time: 6.822213]
2023-06-06 10:01:53.557: epoch 101:	0.02629897  	0.19444153  	0.10700904  
2023-06-06 10:02:00.229: [iter 102 : loss : 0.1269 = 0.0366 + 0.0849 + 0.0054, time: 6.669994]
2023-06-06 10:02:00.378: epoch 102:	0.02624252  	0.19413990  	0.10693665  
2023-06-06 10:02:07.022: [iter 103 : loss : 0.1264 = 0.0362 + 0.0848 + 0.0055, time: 6.643089]
2023-06-06 10:02:07.171: epoch 103:	0.02628486  	0.19445942  	0.10698203  
2023-06-06 10:02:13.996: [iter 104 : loss : 0.1268 = 0.0366 + 0.0848 + 0.0055, time: 6.824588]
2023-06-06 10:02:14.146: epoch 104:	0.02628485  	0.19439234  	0.10708482  
2023-06-06 10:02:20.819: [iter 105 : loss : 0.1263 = 0.0361 + 0.0847 + 0.0055, time: 6.671993]
2023-06-06 10:02:20.967: epoch 105:	0.02632014  	0.19424595  	0.10709848  
2023-06-06 10:02:27.811: [iter 106 : loss : 0.1257 = 0.0355 + 0.0846 + 0.0056, time: 6.841865]
2023-06-06 10:02:27.959: epoch 106:	0.02634131  	0.19460581  	0.10725316  
2023-06-06 10:02:34.790: [iter 107 : loss : 0.1247 = 0.0345 + 0.0846 + 0.0056, time: 6.830090]
2023-06-06 10:02:34.942: epoch 107:	0.02631308  	0.19468749  	0.10732023  
2023-06-06 10:02:41.603: [iter 108 : loss : 0.1244 = 0.0342 + 0.0846 + 0.0056, time: 6.660116]
2023-06-06 10:02:41.752: epoch 108:	0.02636248  	0.19512229  	0.10756313  
2023-06-06 10:02:41.752: Find a better model.
2023-06-06 10:02:48.588: [iter 109 : loss : 0.1231 = 0.0330 + 0.0844 + 0.0057, time: 6.834993]
2023-06-06 10:02:48.738: epoch 109:	0.02644715  	0.19548686  	0.10762065  
2023-06-06 10:02:48.738: Find a better model.
2023-06-06 10:02:55.579: [iter 110 : loss : 0.1226 = 0.0325 + 0.0844 + 0.0057, time: 6.839994]
2023-06-06 10:02:55.732: epoch 110:	0.02640481  	0.19543056  	0.10773135  
2023-06-06 10:03:02.578: [iter 111 : loss : 0.1226 = 0.0325 + 0.0844 + 0.0057, time: 6.844265]
2023-06-06 10:03:02.727: epoch 111:	0.02643304  	0.19527736  	0.10785769  
2023-06-06 10:03:09.397: [iter 112 : loss : 0.1225 = 0.0324 + 0.0843 + 0.0058, time: 6.667994]
2023-06-06 10:03:09.549: epoch 112:	0.02643304  	0.19557704  	0.10787278  
2023-06-06 10:03:09.549: Find a better model.
2023-06-06 10:03:16.387: [iter 113 : loss : 0.1222 = 0.0322 + 0.0842 + 0.0058, time: 6.834994]
2023-06-06 10:03:16.536: epoch 113:	0.02640481  	0.19547151  	0.10778335  
2023-06-06 10:03:23.193: [iter 114 : loss : 0.1214 = 0.0315 + 0.0842 + 0.0058, time: 6.654994]
2023-06-06 10:03:23.342: epoch 114:	0.02643304  	0.19535226  	0.10789232  
2023-06-06 10:03:30.168: [iter 115 : loss : 0.1210 = 0.0310 + 0.0841 + 0.0059, time: 6.823996]
2023-06-06 10:03:30.318: epoch 115:	0.02640481  	0.19514024  	0.10783454  
2023-06-06 10:03:36.989: [iter 116 : loss : 0.1205 = 0.0305 + 0.0841 + 0.0059, time: 6.668994]
2023-06-06 10:03:37.141: epoch 116:	0.02646832  	0.19537501  	0.10779621  
2023-06-06 10:03:43.786: [iter 117 : loss : 0.1203 = 0.0303 + 0.0840 + 0.0059, time: 6.644067]
2023-06-06 10:03:43.935: epoch 117:	0.02644009  	0.19523980  	0.10790718  
2023-06-06 10:03:50.784: [iter 118 : loss : 0.1203 = 0.0304 + 0.0839 + 0.0060, time: 6.846993]
2023-06-06 10:03:50.934: epoch 118:	0.02642598  	0.19501615  	0.10789249  
2023-06-06 10:03:57.768: [iter 119 : loss : 0.1193 = 0.0294 + 0.0839 + 0.0060, time: 6.832201]
2023-06-06 10:03:57.919: epoch 119:	0.02644715  	0.19509552  	0.10781523  
2023-06-06 10:04:04.777: [iter 120 : loss : 0.1197 = 0.0298 + 0.0839 + 0.0060, time: 6.855993]
2023-06-06 10:04:04.931: epoch 120:	0.02644715  	0.19513160  	0.10795898  
2023-06-06 10:04:11.755: [iter 121 : loss : 0.1195 = 0.0297 + 0.0838 + 0.0061, time: 6.822994]
2023-06-06 10:04:11.905: epoch 121:	0.02638364  	0.19464722  	0.10787518  
2023-06-06 10:04:18.777: [iter 122 : loss : 0.1187 = 0.0288 + 0.0838 + 0.0061, time: 6.869993]
2023-06-06 10:04:18.929: epoch 122:	0.02641187  	0.19467150  	0.10809111  
2023-06-06 10:04:25.757: [iter 123 : loss : 0.1185 = 0.0287 + 0.0837 + 0.0061, time: 6.826999]
2023-06-06 10:04:25.908: epoch 123:	0.02636954  	0.19437075  	0.10800350  
2023-06-06 10:04:32.761: [iter 124 : loss : 0.1176 = 0.0278 + 0.0837 + 0.0061, time: 6.851008]
2023-06-06 10:04:32.914: epoch 124:	0.02651066  	0.19522497  	0.10822682  
2023-06-06 10:04:39.757: [iter 125 : loss : 0.1170 = 0.0272 + 0.0836 + 0.0062, time: 6.842005]
2023-06-06 10:04:39.909: epoch 125:	0.02645422  	0.19504020  	0.10812648  
2023-06-06 10:04:46.561: [iter 126 : loss : 0.1172 = 0.0274 + 0.0836 + 0.0062, time: 6.651228]
2023-06-06 10:04:46.711: epoch 126:	0.02643305  	0.19501287  	0.10801040  
2023-06-06 10:04:53.362: [iter 127 : loss : 0.1163 = 0.0265 + 0.0836 + 0.0062, time: 6.649607]
2023-06-06 10:04:53.514: epoch 127:	0.02639071  	0.19470212  	0.10807114  
2023-06-06 10:05:00.335: [iter 128 : loss : 0.1172 = 0.0274 + 0.0835 + 0.0063, time: 6.819977]
2023-06-06 10:05:00.485: epoch 128:	0.02643304  	0.19508962  	0.10841669  
2023-06-06 10:05:07.339: [iter 129 : loss : 0.1164 = 0.0267 + 0.0835 + 0.0063, time: 6.852994]
2023-06-06 10:05:07.488: epoch 129:	0.02637659  	0.19447470  	0.10818005  
2023-06-06 10:05:14.341: [iter 130 : loss : 0.1165 = 0.0268 + 0.0834 + 0.0063, time: 6.852403]
2023-06-06 10:05:14.490: epoch 130:	0.02637659  	0.19451231  	0.10827767  
2023-06-06 10:05:21.152: [iter 131 : loss : 0.1156 = 0.0259 + 0.0833 + 0.0064, time: 6.659994]
2023-06-06 10:05:21.303: epoch 131:	0.02640482  	0.19512093  	0.10849880  
2023-06-06 10:05:27.950: [iter 132 : loss : 0.1157 = 0.0260 + 0.0833 + 0.0064, time: 6.644663]
2023-06-06 10:05:28.099: epoch 132:	0.02641894  	0.19465557  	0.10853484  
2023-06-06 10:05:34.748: [iter 133 : loss : 0.1146 = 0.0248 + 0.0833 + 0.0064, time: 6.646909]
2023-06-06 10:05:34.897: epoch 133:	0.02641893  	0.19484265  	0.10853390  
2023-06-06 10:05:41.549: [iter 134 : loss : 0.1153 = 0.0256 + 0.0832 + 0.0064, time: 6.650994]
2023-06-06 10:05:41.700: epoch 134:	0.02643304  	0.19494243  	0.10868309  
2023-06-06 10:05:48.533: [iter 135 : loss : 0.1149 = 0.0252 + 0.0832 + 0.0065, time: 6.832172]
2023-06-06 10:05:48.683: epoch 135:	0.02644010  	0.19512554  	0.10866865  
2023-06-06 10:05:55.519: [iter 136 : loss : 0.1146 = 0.0249 + 0.0832 + 0.0065, time: 6.835145]
2023-06-06 10:05:55.671: epoch 136:	0.02655300  	0.19594257  	0.10905518  
2023-06-06 10:05:55.671: Find a better model.
2023-06-06 10:06:02.518: [iter 137 : loss : 0.1142 = 0.0245 + 0.0831 + 0.0065, time: 6.846013]
2023-06-06 10:06:02.671: epoch 137:	0.02658123  	0.19597295  	0.10909291  
2023-06-06 10:06:02.671: Find a better model.
2023-06-06 10:06:09.347: [iter 138 : loss : 0.1140 = 0.0244 + 0.0831 + 0.0066, time: 6.674200]
2023-06-06 10:06:09.499: epoch 138:	0.02646127  	0.19486962  	0.10883191  
2023-06-06 10:06:16.326: [iter 139 : loss : 0.1138 = 0.0242 + 0.0831 + 0.0066, time: 6.825285]
2023-06-06 10:06:16.476: epoch 139:	0.02649655  	0.19535010  	0.10898248  
2023-06-06 10:06:23.317: [iter 140 : loss : 0.1131 = 0.0235 + 0.0830 + 0.0066, time: 6.840622]
2023-06-06 10:06:23.467: epoch 140:	0.02654595  	0.19557394  	0.10908324  
2023-06-06 10:06:30.132: [iter 141 : loss : 0.1137 = 0.0240 + 0.0830 + 0.0066, time: 6.663994]
2023-06-06 10:06:30.284: epoch 141:	0.02645421  	0.19457315  	0.10904884  
2023-06-06 10:06:37.100: [iter 142 : loss : 0.1128 = 0.0232 + 0.0829 + 0.0067, time: 6.815006]
2023-06-06 10:06:37.251: epoch 142:	0.02645422  	0.19464742  	0.10894401  
2023-06-06 10:06:43.931: [iter 143 : loss : 0.1130 = 0.0234 + 0.0829 + 0.0067, time: 6.677994]
2023-06-06 10:06:44.081: epoch 143:	0.02653184  	0.19534540  	0.10921688  
2023-06-06 10:06:50.911: [iter 144 : loss : 0.1123 = 0.0227 + 0.0829 + 0.0067, time: 6.828166]
2023-06-06 10:06:51.064: epoch 144:	0.02664474  	0.19604093  	0.10948798  
2023-06-06 10:06:51.064: Find a better model.
2023-06-06 10:06:57.920: [iter 145 : loss : 0.1123 = 0.0228 + 0.0828 + 0.0068, time: 6.855054]
2023-06-06 10:06:58.075: epoch 145:	0.02653889  	0.19527213  	0.10951074  
2023-06-06 10:07:04.719: [iter 146 : loss : 0.1126 = 0.0230 + 0.0828 + 0.0068, time: 6.641994]
2023-06-06 10:07:04.869: epoch 146:	0.02653184  	0.19549190  	0.10958686  
2023-06-06 10:07:11.697: [iter 147 : loss : 0.1123 = 0.0227 + 0.0828 + 0.0068, time: 6.826000]
2023-06-06 10:07:11.848: epoch 147:	0.02646833  	0.19511512  	0.10936715  
2023-06-06 10:07:18.512: [iter 148 : loss : 0.1112 = 0.0217 + 0.0827 + 0.0068, time: 6.662994]
2023-06-06 10:07:18.664: epoch 148:	0.02648244  	0.19541186  	0.10942571  
2023-06-06 10:07:25.308: [iter 149 : loss : 0.1115 = 0.0219 + 0.0827 + 0.0069, time: 6.642034]
2023-06-06 10:07:25.458: epoch 149:	0.02651067  	0.19541413  	0.10956547  
2023-06-06 10:07:32.116: [iter 150 : loss : 0.1109 = 0.0213 + 0.0827 + 0.0069, time: 6.656993]
2023-06-06 10:07:32.269: epoch 150:	0.02644010  	0.19490127  	0.10934756  
2023-06-06 10:07:38.911: [iter 151 : loss : 0.1111 = 0.0216 + 0.0827 + 0.0069, time: 6.640466]
2023-06-06 10:07:39.060: epoch 151:	0.02646833  	0.19529665  	0.10922676  
2023-06-06 10:07:45.711: [iter 152 : loss : 0.1104 = 0.0209 + 0.0826 + 0.0069, time: 6.649999]
2023-06-06 10:07:45.859: epoch 152:	0.02644010  	0.19496037  	0.10913455  
2023-06-06 10:07:52.504: [iter 153 : loss : 0.1094 = 0.0199 + 0.0826 + 0.0070, time: 6.642993]
2023-06-06 10:07:52.656: epoch 153:	0.02643305  	0.19473162  	0.10908727  
2023-06-06 10:07:59.297: [iter 154 : loss : 0.1102 = 0.0207 + 0.0825 + 0.0070, time: 6.638556]
2023-06-06 10:07:59.447: epoch 154:	0.02644010  	0.19498499  	0.10920262  
2023-06-06 10:08:06.095: [iter 155 : loss : 0.1107 = 0.0212 + 0.0825 + 0.0070, time: 6.646993]
2023-06-06 10:08:06.246: epoch 155:	0.02641188  	0.19454587  	0.10900734  
2023-06-06 10:08:13.081: [iter 156 : loss : 0.1100 = 0.0204 + 0.0825 + 0.0070, time: 6.834292]
2023-06-06 10:08:13.230: epoch 156:	0.02648950  	0.19509207  	0.10917536  
2023-06-06 10:08:19.903: [iter 157 : loss : 0.1100 = 0.0205 + 0.0825 + 0.0071, time: 6.671994]
2023-06-06 10:08:20.052: epoch 157:	0.02639071  	0.19441330  	0.10894931  
2023-06-06 10:08:26.883: [iter 158 : loss : 0.1092 = 0.0197 + 0.0824 + 0.0071, time: 6.830289]
2023-06-06 10:08:27.035: epoch 158:	0.02639776  	0.19436510  	0.10887163  
2023-06-06 10:08:35.736: [iter 159 : loss : 0.1094 = 0.0199 + 0.0824 + 0.0071, time: 8.700304]
2023-06-06 10:08:35.886: epoch 159:	0.02644010  	0.19473529  	0.10903082  
2023-06-06 10:08:42.623: [iter 160 : loss : 0.1092 = 0.0197 + 0.0824 + 0.0071, time: 6.734458]
2023-06-06 10:08:42.775: epoch 160:	0.02645421  	0.19454344  	0.10901455  
2023-06-06 10:08:49.748: [iter 161 : loss : 0.1086 = 0.0191 + 0.0824 + 0.0072, time: 6.970858]
2023-06-06 10:08:49.897: epoch 161:	0.02644716  	0.19448362  	0.10904393  
2023-06-06 10:08:56.657: [iter 162 : loss : 0.1081 = 0.0186 + 0.0823 + 0.0072, time: 6.758074]
2023-06-06 10:08:56.802: epoch 162:	0.02639776  	0.19371651  	0.10880099  
2023-06-06 10:09:03.292: [iter 163 : loss : 0.1086 = 0.0190 + 0.0823 + 0.0072, time: 6.489005]
2023-06-06 10:09:03.454: epoch 163:	0.02640482  	0.19378206  	0.10882869  
2023-06-06 10:09:10.061: [iter 164 : loss : 0.1085 = 0.0190 + 0.0823 + 0.0072, time: 6.605013]
2023-06-06 10:09:10.209: epoch 164:	0.02646833  	0.19487761  	0.10906655  
2023-06-06 10:09:16.686: [iter 165 : loss : 0.1081 = 0.0187 + 0.0822 + 0.0073, time: 6.475983]
2023-06-06 10:09:16.832: epoch 165:	0.02641188  	0.19456100  	0.10901857  
2023-06-06 10:09:23.283: [iter 166 : loss : 0.1081 = 0.0186 + 0.0822 + 0.0073, time: 6.450004]
2023-06-06 10:09:23.445: epoch 166:	0.02647539  	0.19491816  	0.10909983  
2023-06-06 10:09:30.070: [iter 167 : loss : 0.1083 = 0.0188 + 0.0822 + 0.0073, time: 6.623259]
2023-06-06 10:09:30.231: epoch 167:	0.02651772  	0.19558404  	0.10931792  
2023-06-06 10:09:36.853: [iter 168 : loss : 0.1078 = 0.0183 + 0.0822 + 0.0073, time: 6.620542]
2023-06-06 10:09:37.014: epoch 168:	0.02641894  	0.19482653  	0.10904621  
2023-06-06 10:09:43.490: [iter 169 : loss : 0.1080 = 0.0185 + 0.0822 + 0.0074, time: 6.474029]
2023-06-06 10:09:43.648: epoch 169:	0.02648950  	0.19528426  	0.10929254  
2023-06-06 10:09:43.648: Early stopping is trigger at epoch: 169
2023-06-06 10:09:43.648: best_result@epoch 144:

2023-06-06 10:09:43.648: 		0.0266      	0.1960      	0.1095      
2023-06-06 10:16:02.054: my pid: 7052
2023-06-06 10:16:02.055: model: model.general_recommender.SGL
2023-06-06 10:16:02.055: Dataset statistics:
Name: Amazon_Video_Games_polluted
The number of users: 7253
The number of items: 4338
The number of ratings: 128569
Average actions of users: 17.73
Average actions of items: 29.64
The sparsity of the dataset: 99.591371%

The number of training: 108094
The number of validation: 0
The number of testing: 20475
2023-06-06 10:16:02.055: NeuRec:[NeuRec]:
recommender=SGL
dataset=Amazon_Video_Games_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.01
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-06 10:16:05.370: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-06 10:16:12.624: [iter 1 : loss : 0.7726 = 0.6930 + 0.0797 + 0.0000, time: 7.253253]
2023-06-06 10:16:12.775: epoch 1:	0.00205335  	0.01440828  	0.00727433  
2023-06-06 10:16:12.775: Find a better model.
2023-06-06 10:16:20.154: [iter 2 : loss : 0.7723 = 0.6927 + 0.0796 + 0.0000, time: 7.376807]
2023-06-06 10:16:20.344: epoch 2:	0.00481934  	0.03375034  	0.01711842  
2023-06-06 10:16:20.344: Find a better model.
2023-06-06 10:16:27.558: [iter 3 : loss : 0.7720 = 0.6923 + 0.0798 + 0.0000, time: 7.213053]
2023-06-06 10:16:27.733: epoch 3:	0.00804396  	0.05689500  	0.02832178  
2023-06-06 10:16:27.733: Find a better model.
2023-06-06 10:16:34.746: [iter 4 : loss : 0.7714 = 0.6914 + 0.0800 + 0.0000, time: 7.011997]
2023-06-06 10:16:34.916: epoch 4:	0.01143101  	0.08167341  	0.03933702  
2023-06-06 10:16:34.916: Find a better model.
2023-06-06 10:16:41.753: [iter 5 : loss : 0.7698 = 0.6895 + 0.0803 + 0.0000, time: 6.835004]
2023-06-06 10:16:41.902: epoch 5:	0.01505802  	0.10762647  	0.05224091  
2023-06-06 10:16:41.902: Find a better model.
2023-06-06 10:16:48.555: [iter 6 : loss : 0.7660 = 0.6851 + 0.0809 + 0.0000, time: 6.651367]
2023-06-06 10:16:48.712: epoch 6:	0.01743604  	0.12586397  	0.06257792  
2023-06-06 10:16:48.712: Find a better model.
2023-06-06 10:16:55.310: [iter 7 : loss : 0.7562 = 0.6740 + 0.0822 + 0.0000, time: 6.595994]
2023-06-06 10:16:55.470: epoch 7:	0.01886849  	0.13790064  	0.06807020  
2023-06-06 10:16:55.470: Find a better model.
2023-06-06 10:17:01.961: [iter 8 : loss : 0.7334 = 0.6484 + 0.0849 + 0.0001, time: 6.490122]
2023-06-06 10:17:02.122: epoch 8:	0.01886144  	0.13864276  	0.06938722  
2023-06-06 10:17:02.122: Find a better model.
2023-06-06 10:17:08.529: [iter 9 : loss : 0.6876 = 0.5979 + 0.0896 + 0.0002, time: 6.406025]
2023-06-06 10:17:08.675: epoch 9:	0.01850862  	0.13693553  	0.06851951  
2023-06-06 10:17:15.108: [iter 10 : loss : 0.6194 = 0.5243 + 0.0948 + 0.0003, time: 6.432025]
2023-06-06 10:17:15.265: epoch 10:	0.01844510  	0.13641110  	0.06755064  
2023-06-06 10:17:21.539: [iter 11 : loss : 0.5464 = 0.4469 + 0.0991 + 0.0005, time: 6.273004]
2023-06-06 10:17:21.695: epoch 11:	0.01831809  	0.13559180  	0.06729791  
2023-06-06 10:17:28.130: [iter 12 : loss : 0.4855 = 0.3834 + 0.1015 + 0.0006, time: 6.434004]
2023-06-06 10:17:28.286: epoch 12:	0.01829692  	0.13486096  	0.06758112  
2023-06-06 10:17:34.691: [iter 13 : loss : 0.4414 = 0.3378 + 0.1029 + 0.0008, time: 6.404014]
2023-06-06 10:17:34.836: epoch 13:	0.01844511  	0.13653137  	0.06830732  
2023-06-06 10:17:41.338: [iter 14 : loss : 0.4075 = 0.3032 + 0.1034 + 0.0009, time: 6.501043]
2023-06-06 10:17:41.496: epoch 14:	0.01866386  	0.13772780  	0.06906221  
2023-06-06 10:17:47.882: [iter 15 : loss : 0.3835 = 0.2789 + 0.1035 + 0.0010, time: 6.385429]
2023-06-06 10:17:48.037: epoch 15:	0.01874148  	0.13887681  	0.06994254  
2023-06-06 10:17:48.037: Find a better model.
2023-06-06 10:17:54.491: [iter 16 : loss : 0.3630 = 0.2585 + 0.1034 + 0.0011, time: 6.453012]
2023-06-06 10:17:54.644: epoch 16:	0.01897434  	0.14036019  	0.07079761  
2023-06-06 10:17:54.644: Find a better model.
2023-06-06 10:18:01.084: [iter 17 : loss : 0.3477 = 0.2433 + 0.1031 + 0.0012, time: 6.439022]
2023-06-06 10:18:01.229: epoch 17:	0.01934128  	0.14257132  	0.07198877  
2023-06-06 10:18:01.229: Find a better model.
2023-06-06 10:18:07.530: [iter 18 : loss : 0.3331 = 0.2289 + 0.1029 + 0.0013, time: 6.299298]
2023-06-06 10:18:07.689: epoch 18:	0.01953886  	0.14405619  	0.07304974  
2023-06-06 10:18:07.689: Find a better model.
2023-06-06 10:18:14.106: [iter 19 : loss : 0.3195 = 0.2156 + 0.1025 + 0.0014, time: 6.416004]
2023-06-06 10:18:14.253: epoch 19:	0.01967999  	0.14495210  	0.07362238  
2023-06-06 10:18:14.253: Find a better model.
2023-06-06 10:18:20.714: [iter 20 : loss : 0.3102 = 0.2066 + 0.1021 + 0.0015, time: 6.459062]
2023-06-06 10:18:20.874: epoch 20:	0.01987053  	0.14683141  	0.07464163  
2023-06-06 10:18:20.875: Find a better model.
2023-06-06 10:18:27.331: [iter 21 : loss : 0.3008 = 0.1976 + 0.1016 + 0.0016, time: 6.454014]
2023-06-06 10:18:27.492: epoch 21:	0.02010339  	0.14835642  	0.07540581  
2023-06-06 10:18:27.492: Find a better model.
2023-06-06 10:18:34.097: [iter 22 : loss : 0.2926 = 0.1897 + 0.1012 + 0.0017, time: 6.603959]
2023-06-06 10:18:34.254: epoch 22:	0.02027980  	0.14985250  	0.07622267  
2023-06-06 10:18:34.254: Find a better model.
2023-06-06 10:18:40.686: [iter 23 : loss : 0.2845 = 0.1819 + 0.1008 + 0.0017, time: 6.431029]
2023-06-06 10:18:40.847: epoch 23:	0.02044210  	0.15095140  	0.07684309  
2023-06-06 10:18:40.848: Find a better model.
2023-06-06 10:18:47.501: [iter 24 : loss : 0.2781 = 0.1760 + 0.1003 + 0.0018, time: 6.652285]
2023-06-06 10:18:47.660: epoch 24:	0.02056912  	0.15185730  	0.07756615  
2023-06-06 10:18:47.660: Find a better model.
2023-06-06 10:18:54.104: [iter 25 : loss : 0.2716 = 0.1697 + 0.0999 + 0.0019, time: 6.443004]
2023-06-06 10:18:54.248: epoch 25:	0.02083021  	0.15339693  	0.07835028  
2023-06-06 10:18:54.248: Find a better model.
2023-06-06 10:19:00.698: [iter 26 : loss : 0.2680 = 0.1665 + 0.0995 + 0.0020, time: 6.448035]
2023-06-06 10:19:00.841: epoch 26:	0.02102779  	0.15471697  	0.07900903  
2023-06-06 10:19:00.841: Find a better model.
2023-06-06 10:19:07.294: [iter 27 : loss : 0.2603 = 0.1591 + 0.0991 + 0.0020, time: 6.452035]
2023-06-06 10:19:07.452: epoch 27:	0.02120421  	0.15593931  	0.07984456  
2023-06-06 10:19:07.452: Find a better model.
2023-06-06 10:19:13.889: [iter 28 : loss : 0.2553 = 0.1546 + 0.0986 + 0.0021, time: 6.436026]
2023-06-06 10:19:14.046: epoch 28:	0.02147236  	0.15796451  	0.08091897  
2023-06-06 10:19:14.046: Find a better model.
2023-06-06 10:19:20.480: [iter 29 : loss : 0.2512 = 0.1508 + 0.0983 + 0.0021, time: 6.431475]
2023-06-06 10:19:20.639: epoch 29:	0.02169817  	0.15952259  	0.08175687  
2023-06-06 10:19:20.639: Find a better model.
2023-06-06 10:19:26.903: [iter 30 : loss : 0.2444 = 0.1443 + 0.0979 + 0.0022, time: 6.263004]
2023-06-06 10:19:27.061: epoch 30:	0.02184635  	0.16074844  	0.08251982  
2023-06-06 10:19:27.061: Find a better model.
2023-06-06 10:19:33.468: [iter 31 : loss : 0.2410 = 0.1413 + 0.0975 + 0.0023, time: 6.406040]
2023-06-06 10:19:33.625: epoch 31:	0.02192397  	0.16150279  	0.08310472  
2023-06-06 10:19:33.625: Find a better model.
2023-06-06 10:19:40.046: [iter 32 : loss : 0.2354 = 0.1359 + 0.0972 + 0.0023, time: 6.420017]
2023-06-06 10:19:40.200: epoch 32:	0.02207216  	0.16269398  	0.08378901  
2023-06-06 10:19:40.200: Find a better model.
2023-06-06 10:19:46.647: [iter 33 : loss : 0.2330 = 0.1338 + 0.0968 + 0.0024, time: 6.445003]
2023-06-06 10:19:46.792: epoch 33:	0.02218506  	0.16367936  	0.08438802  
2023-06-06 10:19:46.792: Find a better model.
2023-06-06 10:19:53.249: [iter 34 : loss : 0.2286 = 0.1297 + 0.0965 + 0.0024, time: 6.455202]
2023-06-06 10:19:53.394: epoch 34:	0.02229796  	0.16443159  	0.08506659  
2023-06-06 10:19:53.394: Find a better model.
2023-06-06 10:19:59.681: [iter 35 : loss : 0.2252 = 0.1265 + 0.0962 + 0.0025, time: 6.286005]
2023-06-06 10:19:59.838: epoch 35:	0.02238264  	0.16519199  	0.08561821  
2023-06-06 10:19:59.838: Find a better model.
2023-06-06 10:20:06.278: [iter 36 : loss : 0.2220 = 0.1236 + 0.0958 + 0.0025, time: 6.439006]
2023-06-06 10:20:06.435: epoch 36:	0.02254494  	0.16581750  	0.08621838  
2023-06-06 10:20:06.435: Find a better model.
2023-06-06 10:20:12.666: [iter 37 : loss : 0.2179 = 0.1198 + 0.0955 + 0.0026, time: 6.230120]
2023-06-06 10:20:12.812: epoch 37:	0.02266490  	0.16681600  	0.08682578  
2023-06-06 10:20:12.812: Find a better model.
2023-06-06 10:20:19.243: [iter 38 : loss : 0.2165 = 0.1186 + 0.0952 + 0.0027, time: 6.430012]
2023-06-06 10:20:19.388: epoch 38:	0.02281309  	0.16788666  	0.08755873  
2023-06-06 10:20:19.388: Find a better model.
2023-06-06 10:20:25.632: [iter 39 : loss : 0.2119 = 0.1143 + 0.0949 + 0.0027, time: 6.242002]
2023-06-06 10:20:25.783: epoch 39:	0.02306006  	0.16995166  	0.08856205  
2023-06-06 10:20:25.783: Find a better model.
2023-06-06 10:20:32.207: [iter 40 : loss : 0.2086 = 0.1112 + 0.0946 + 0.0028, time: 6.423006]
2023-06-06 10:20:32.354: epoch 40:	0.02306712  	0.17037053  	0.08870891  
2023-06-06 10:20:32.354: Find a better model.
2023-06-06 10:20:38.828: [iter 41 : loss : 0.2071 = 0.1099 + 0.0944 + 0.0028, time: 6.471085]
2023-06-06 10:20:38.978: epoch 41:	0.02310946  	0.17096785  	0.08931135  
2023-06-06 10:20:38.979: Find a better model.
2023-06-06 10:20:45.254: [iter 42 : loss : 0.2049 = 0.1079 + 0.0941 + 0.0029, time: 6.274028]
2023-06-06 10:20:45.402: epoch 42:	0.02328588  	0.17240730  	0.09006448  
2023-06-06 10:20:45.403: Find a better model.
2023-06-06 10:20:51.650: [iter 43 : loss : 0.2010 = 0.1043 + 0.0938 + 0.0029, time: 6.245996]
2023-06-06 10:20:51.799: epoch 43:	0.02334233  	0.17317443  	0.09067352  
2023-06-06 10:20:51.799: Find a better model.
2023-06-06 10:20:58.053: [iter 44 : loss : 0.1975 = 0.1009 + 0.0936 + 0.0030, time: 6.253110]
2023-06-06 10:20:58.205: epoch 44:	0.02340584  	0.17347328  	0.09113271  
2023-06-06 10:20:58.205: Find a better model.
2023-06-06 10:21:04.452: [iter 45 : loss : 0.1953 = 0.0989 + 0.0933 + 0.0030, time: 6.245971]
2023-06-06 10:21:04.599: epoch 45:	0.02344817  	0.17374961  	0.09139249  
2023-06-06 10:21:04.599: Find a better model.
2023-06-06 10:21:10.856: [iter 46 : loss : 0.1930 = 0.0969 + 0.0930 + 0.0031, time: 6.255003]
2023-06-06 10:21:11.007: epoch 46:	0.02349051  	0.17403980  	0.09153727  
2023-06-06 10:21:11.008: Find a better model.
2023-06-06 10:21:17.218: [iter 47 : loss : 0.1922 = 0.0963 + 0.0928 + 0.0031, time: 6.209017]
2023-06-06 10:21:17.366: epoch 47:	0.02361047  	0.17468241  	0.09195849  
2023-06-06 10:21:17.366: Find a better model.
2023-06-06 10:21:23.638: [iter 48 : loss : 0.1884 = 0.0926 + 0.0926 + 0.0032, time: 6.269994]
2023-06-06 10:21:23.788: epoch 48:	0.02368809  	0.17538013  	0.09234922  
2023-06-06 10:21:23.788: Find a better model.
2023-06-06 10:21:30.043: [iter 49 : loss : 0.1852 = 0.0896 + 0.0924 + 0.0032, time: 6.253004]
2023-06-06 10:21:30.191: epoch 49:	0.02382217  	0.17622790  	0.09285719  
2023-06-06 10:21:30.191: Find a better model.
2023-06-06 10:21:36.444: [iter 50 : loss : 0.1847 = 0.0892 + 0.0922 + 0.0033, time: 6.251060]
2023-06-06 10:21:36.596: epoch 50:	0.02385039  	0.17645630  	0.09306756  
2023-06-06 10:21:36.596: Find a better model.
2023-06-06 10:21:43.039: [iter 51 : loss : 0.1816 = 0.0862 + 0.0921 + 0.0033, time: 6.442584]
2023-06-06 10:21:43.188: epoch 51:	0.02397740  	0.17722023  	0.09354310  
2023-06-06 10:21:43.188: Find a better model.
2023-06-06 10:21:49.631: [iter 52 : loss : 0.1812 = 0.0860 + 0.0919 + 0.0034, time: 6.442132]
2023-06-06 10:21:49.779: epoch 52:	0.02414676  	0.17844801  	0.09409427  
2023-06-06 10:21:49.779: Find a better model.
2023-06-06 10:21:56.225: [iter 53 : loss : 0.1794 = 0.0844 + 0.0916 + 0.0034, time: 6.445004]
2023-06-06 10:21:56.376: epoch 53:	0.02421732  	0.17908078  	0.09457029  
2023-06-06 10:21:56.376: Find a better model.
2023-06-06 10:22:02.823: [iter 54 : loss : 0.1774 = 0.0825 + 0.0915 + 0.0035, time: 6.446006]
2023-06-06 10:22:02.972: epoch 54:	0.02433022  	0.17962031  	0.09499779  
2023-06-06 10:22:02.972: Find a better model.
2023-06-06 10:22:09.403: [iter 55 : loss : 0.1754 = 0.0807 + 0.0913 + 0.0035, time: 6.430072]
2023-06-06 10:22:09.552: epoch 55:	0.02437961  	0.18011054  	0.09527788  
2023-06-06 10:22:09.553: Find a better model.
2023-06-06 10:22:16.028: [iter 56 : loss : 0.1735 = 0.0789 + 0.0910 + 0.0035, time: 6.473055]
2023-06-06 10:22:16.179: epoch 56:	0.02447841  	0.18075912  	0.09572424  
2023-06-06 10:22:16.179: Find a better model.
2023-06-06 10:22:22.623: [iter 57 : loss : 0.1718 = 0.0773 + 0.0909 + 0.0036, time: 6.441993]
2023-06-06 10:22:22.770: epoch 57:	0.02453486  	0.18112008  	0.09587211  
2023-06-06 10:22:22.771: Find a better model.
2023-06-06 10:22:29.233: [iter 58 : loss : 0.1696 = 0.0753 + 0.0907 + 0.0036, time: 6.461021]
2023-06-06 10:22:29.382: epoch 58:	0.02467599  	0.18209842  	0.09643570  
2023-06-06 10:22:29.382: Find a better model.
2023-06-06 10:22:35.829: [iter 59 : loss : 0.1688 = 0.0746 + 0.0905 + 0.0037, time: 6.445993]
2023-06-06 10:22:35.977: epoch 59:	0.02473244  	0.18237540  	0.09685394  
2023-06-06 10:22:35.977: Find a better model.
2023-06-06 10:22:42.419: [iter 60 : loss : 0.1672 = 0.0731 + 0.0904 + 0.0037, time: 6.441028]
2023-06-06 10:22:42.568: epoch 60:	0.02479594  	0.18268202  	0.09717082  
2023-06-06 10:22:42.568: Find a better model.
2023-06-06 10:22:49.000: [iter 61 : loss : 0.1658 = 0.0719 + 0.0902 + 0.0038, time: 6.429995]
2023-06-06 10:22:49.149: epoch 61:	0.02487356  	0.18328519  	0.09753386  
2023-06-06 10:22:49.150: Find a better model.
2023-06-06 10:22:55.598: [iter 62 : loss : 0.1643 = 0.0704 + 0.0901 + 0.0038, time: 6.447006]
2023-06-06 10:22:55.745: epoch 62:	0.02492295  	0.18385558  	0.09776603  
2023-06-06 10:22:55.745: Find a better model.
2023-06-06 10:23:02.182: [iter 63 : loss : 0.1630 = 0.0693 + 0.0899 + 0.0039, time: 6.436003]
2023-06-06 10:23:02.332: epoch 63:	0.02504292  	0.18473972  	0.09828636  
2023-06-06 10:23:02.332: Find a better model.
2023-06-06 10:23:08.801: [iter 64 : loss : 0.1619 = 0.0683 + 0.0897 + 0.0039, time: 6.467014]
2023-06-06 10:23:08.949: epoch 64:	0.02507820  	0.18477355  	0.09866545  
2023-06-06 10:23:08.949: Find a better model.
2023-06-06 10:23:15.384: [iter 65 : loss : 0.1605 = 0.0670 + 0.0896 + 0.0039, time: 6.434005]
2023-06-06 10:23:15.533: epoch 65:	0.02509231  	0.18497583  	0.09902789  
2023-06-06 10:23:15.533: Find a better model.
2023-06-06 10:23:21.997: [iter 66 : loss : 0.1590 = 0.0656 + 0.0894 + 0.0040, time: 6.463013]
2023-06-06 10:23:22.145: epoch 66:	0.02510642  	0.18496498  	0.09922085  
2023-06-06 10:23:28.590: [iter 67 : loss : 0.1575 = 0.0642 + 0.0893 + 0.0040, time: 6.442997]
2023-06-06 10:23:28.737: epoch 67:	0.02516993  	0.18553849  	0.09959541  
2023-06-06 10:23:28.737: Find a better model.
2023-06-06 10:23:35.194: [iter 68 : loss : 0.1575 = 0.0643 + 0.0891 + 0.0041, time: 6.454996]
2023-06-06 10:23:35.341: epoch 68:	0.02520522  	0.18599483  	0.09993853  
2023-06-06 10:23:35.341: Find a better model.
2023-06-06 10:23:41.786: [iter 69 : loss : 0.1554 = 0.0623 + 0.0890 + 0.0041, time: 6.443030]
2023-06-06 10:23:41.934: epoch 69:	0.02523344  	0.18616201  	0.10007714  
2023-06-06 10:23:41.934: Find a better model.
2023-06-06 10:23:48.379: [iter 70 : loss : 0.1535 = 0.0605 + 0.0889 + 0.0041, time: 6.442560]
2023-06-06 10:23:48.527: epoch 70:	0.02524756  	0.18628947  	0.10030659  
2023-06-06 10:23:48.527: Find a better model.
2023-06-06 10:23:54.972: [iter 71 : loss : 0.1523 = 0.0594 + 0.0888 + 0.0042, time: 6.444021]
2023-06-06 10:23:55.121: epoch 71:	0.02538869  	0.18700701  	0.10063650  
2023-06-06 10:23:55.121: Find a better model.
2023-06-06 10:24:01.582: [iter 72 : loss : 0.1520 = 0.0591 + 0.0887 + 0.0042, time: 6.460767]
2023-06-06 10:24:01.731: epoch 72:	0.02546631  	0.18803424  	0.10110144  
2023-06-06 10:24:01.731: Find a better model.
2023-06-06 10:24:08.176: [iter 73 : loss : 0.1506 = 0.0578 + 0.0885 + 0.0043, time: 6.442993]
2023-06-06 10:24:08.327: epoch 73:	0.02562861  	0.18908843  	0.10153451  
2023-06-06 10:24:08.327: Find a better model.
2023-06-06 10:24:14.787: [iter 74 : loss : 0.1493 = 0.0565 + 0.0884 + 0.0043, time: 6.458994]
2023-06-06 10:24:14.937: epoch 74:	0.02564272  	0.18914445  	0.10198894  
2023-06-06 10:24:14.937: Find a better model.
2023-06-06 10:24:21.365: [iter 75 : loss : 0.1488 = 0.0562 + 0.0883 + 0.0044, time: 6.427004]
2023-06-06 10:24:21.517: epoch 75:	0.02565683  	0.18891746  	0.10214438  
2023-06-06 10:24:27.966: [iter 76 : loss : 0.1477 = 0.0552 + 0.0882 + 0.0044, time: 6.448021]
2023-06-06 10:24:28.114: epoch 76:	0.02572739  	0.18939707  	0.10246222  
2023-06-06 10:24:28.114: Find a better model.
2023-06-06 10:24:34.564: [iter 77 : loss : 0.1466 = 0.0541 + 0.0880 + 0.0044, time: 6.448460]
2023-06-06 10:24:34.715: epoch 77:	0.02577679  	0.18957350  	0.10252390  
2023-06-06 10:24:34.715: Find a better model.
2023-06-06 10:24:41.169: [iter 78 : loss : 0.1460 = 0.0535 + 0.0880 + 0.0045, time: 6.453007]
2023-06-06 10:24:41.317: epoch 78:	0.02576268  	0.18959057  	0.10277356  
2023-06-06 10:24:41.317: Find a better model.
2023-06-06 10:24:47.737: [iter 79 : loss : 0.1446 = 0.0522 + 0.0879 + 0.0045, time: 6.418373]
2023-06-06 10:24:47.886: epoch 79:	0.02584030  	0.19022807  	0.10316918  
2023-06-06 10:24:47.886: Find a better model.
2023-06-06 10:24:54.348: [iter 80 : loss : 0.1437 = 0.0513 + 0.0878 + 0.0046, time: 6.460994]
2023-06-06 10:24:54.497: epoch 80:	0.02584736  	0.19009589  	0.10316857  
2023-06-06 10:25:00.959: [iter 81 : loss : 0.1439 = 0.0516 + 0.0877 + 0.0046, time: 6.461000]
2023-06-06 10:25:01.105: epoch 81:	0.02593909  	0.19090746  	0.10346191  
2023-06-06 10:25:01.106: Find a better model.
2023-06-06 10:25:07.555: [iter 82 : loss : 0.1423 = 0.0501 + 0.0876 + 0.0046, time: 6.447018]
2023-06-06 10:25:07.703: epoch 82:	0.02597437  	0.19121386  	0.10367843  
2023-06-06 10:25:07.703: Find a better model.
2023-06-06 10:25:14.157: [iter 83 : loss : 0.1414 = 0.0492 + 0.0875 + 0.0047, time: 6.451994]
2023-06-06 10:25:14.305: epoch 83:	0.02600260  	0.19137755  	0.10387468  
2023-06-06 10:25:14.305: Find a better model.
2023-06-06 10:25:20.745: [iter 84 : loss : 0.1413 = 0.0492 + 0.0874 + 0.0047, time: 6.439131]
2023-06-06 10:25:20.909: epoch 84:	0.02608727  	0.19218911  	0.10426304  
2023-06-06 10:25:20.909: Find a better model.
2023-06-06 10:25:27.345: [iter 85 : loss : 0.1403 = 0.0483 + 0.0873 + 0.0047, time: 6.435082]
2023-06-06 10:25:27.495: epoch 85:	0.02612255  	0.19240673  	0.10432437  
2023-06-06 10:25:27.495: Find a better model.
2023-06-06 10:25:33.943: [iter 86 : loss : 0.1401 = 0.0482 + 0.0872 + 0.0048, time: 6.446036]
2023-06-06 10:25:34.094: epoch 86:	0.02613667  	0.19300206  	0.10472936  
2023-06-06 10:25:34.094: Find a better model.
2023-06-06 10:25:40.518: [iter 87 : loss : 0.1375 = 0.0456 + 0.0871 + 0.0048, time: 6.422125]
2023-06-06 10:25:40.667: epoch 87:	0.02611550  	0.19294766  	0.10465438  
2023-06-06 10:25:47.138: [iter 88 : loss : 0.1367 = 0.0448 + 0.0870 + 0.0049, time: 6.469999]
2023-06-06 10:25:47.289: epoch 88:	0.02611550  	0.19305333  	0.10466604  
2023-06-06 10:25:47.290: Find a better model.
2023-06-06 10:25:53.736: [iter 89 : loss : 0.1364 = 0.0446 + 0.0869 + 0.0049, time: 6.445005]
2023-06-06 10:25:53.885: epoch 89:	0.02622135  	0.19378459  	0.10503525  
2023-06-06 10:25:53.885: Find a better model.
2023-06-06 10:26:00.349: [iter 90 : loss : 0.1369 = 0.0452 + 0.0868 + 0.0049, time: 6.463025]
2023-06-06 10:26:00.495: epoch 90:	0.02624251  	0.19405074  	0.10529271  
2023-06-06 10:26:00.495: Find a better model.
2023-06-06 10:26:06.940: [iter 91 : loss : 0.1358 = 0.0441 + 0.0867 + 0.0050, time: 6.444022]
2023-06-06 10:26:07.087: epoch 91:	0.02628485  	0.19421951  	0.10534237  
2023-06-06 10:26:07.087: Find a better model.
2023-06-06 10:26:13.556: [iter 92 : loss : 0.1348 = 0.0431 + 0.0866 + 0.0050, time: 6.468261]
2023-06-06 10:26:13.704: epoch 92:	0.02634836  	0.19446589  	0.10563917  
2023-06-06 10:26:13.704: Find a better model.
2023-06-06 10:26:20.143: [iter 93 : loss : 0.1350 = 0.0433 + 0.0866 + 0.0050, time: 6.437994]
2023-06-06 10:26:20.292: epoch 93:	0.02641892  	0.19471753  	0.10591182  
2023-06-06 10:26:20.292: Find a better model.
2023-06-06 10:26:26.738: [iter 94 : loss : 0.1329 = 0.0414 + 0.0865 + 0.0051, time: 6.444015]
2023-06-06 10:26:26.888: epoch 94:	0.02641892  	0.19484280  	0.10609719  
2023-06-06 10:26:26.888: Find a better model.
2023-06-06 10:26:33.324: [iter 95 : loss : 0.1324 = 0.0409 + 0.0864 + 0.0051, time: 6.433993]
2023-06-06 10:26:33.475: epoch 95:	0.02644715  	0.19506192  	0.10634603  
2023-06-06 10:26:33.475: Find a better model.
2023-06-06 10:26:39.921: [iter 96 : loss : 0.1324 = 0.0409 + 0.0864 + 0.0052, time: 6.445011]
2023-06-06 10:26:40.070: epoch 96:	0.02649654  	0.19513462  	0.10649846  
2023-06-06 10:26:40.070: Find a better model.
2023-06-06 10:26:46.539: [iter 97 : loss : 0.1307 = 0.0393 + 0.0863 + 0.0052, time: 6.468034]
2023-06-06 10:26:46.688: epoch 97:	0.02655300  	0.19547494  	0.10649014  
2023-06-06 10:26:46.688: Find a better model.
2023-06-06 10:26:53.138: [iter 98 : loss : 0.1315 = 0.0401 + 0.0862 + 0.0052, time: 6.448932]
2023-06-06 10:26:53.290: epoch 98:	0.02651066  	0.19512852  	0.10659456  
2023-06-06 10:26:59.725: [iter 99 : loss : 0.1303 = 0.0390 + 0.0861 + 0.0053, time: 6.434054]
2023-06-06 10:26:59.876: epoch 99:	0.02648949  	0.19510995  	0.10670023  
2023-06-06 10:27:06.320: [iter 100 : loss : 0.1298 = 0.0385 + 0.0861 + 0.0053, time: 6.443005]
2023-06-06 10:27:06.469: epoch 100:	0.02653889  	0.19549802  	0.10666664  
2023-06-06 10:27:06.469: Find a better model.
2023-06-06 10:27:12.928: [iter 101 : loss : 0.1294 = 0.0381 + 0.0860 + 0.0053, time: 6.457843]
2023-06-06 10:27:13.078: epoch 101:	0.02652477  	0.19538766  	0.10688934  
2023-06-06 10:27:19.529: [iter 102 : loss : 0.1283 = 0.0370 + 0.0859 + 0.0054, time: 6.450011]
2023-06-06 10:27:19.680: epoch 102:	0.02658828  	0.19586359  	0.10685953  
2023-06-06 10:27:19.680: Find a better model.
2023-06-06 10:27:26.093: [iter 103 : loss : 0.1279 = 0.0367 + 0.0858 + 0.0054, time: 6.410004]
2023-06-06 10:27:26.243: epoch 103:	0.02659534  	0.19597372  	0.10699116  
2023-06-06 10:27:26.243: Find a better model.
2023-06-06 10:27:32.707: [iter 104 : loss : 0.1286 = 0.0374 + 0.0858 + 0.0054, time: 6.462996]
2023-06-06 10:27:32.857: epoch 104:	0.02658828  	0.19579828  	0.10705871  
2023-06-06 10:27:39.317: [iter 105 : loss : 0.1281 = 0.0369 + 0.0857 + 0.0055, time: 6.459050]
2023-06-06 10:27:39.466: epoch 105:	0.02656711  	0.19565684  	0.10682214  
2023-06-06 10:27:45.912: [iter 106 : loss : 0.1273 = 0.0361 + 0.0857 + 0.0055, time: 6.444075]
2023-06-06 10:27:46.064: epoch 106:	0.02663767  	0.19635281  	0.10713382  
2023-06-06 10:27:46.064: Find a better model.
2023-06-06 10:27:52.694: [iter 107 : loss : 0.1265 = 0.0353 + 0.0856 + 0.0055, time: 6.627995]
2023-06-06 10:27:52.842: epoch 107:	0.02665178  	0.19629218  	0.10712753  
2023-06-06 10:27:59.297: [iter 108 : loss : 0.1263 = 0.0351 + 0.0856 + 0.0056, time: 6.452996]
2023-06-06 10:27:59.445: epoch 108:	0.02664473  	0.19660895  	0.10728618  
2023-06-06 10:27:59.445: Find a better model.
2023-06-06 10:28:05.912: [iter 109 : loss : 0.1249 = 0.0338 + 0.0855 + 0.0056, time: 6.465997]
2023-06-06 10:28:06.061: epoch 109:	0.02661650  	0.19630022  	0.10719802  
2023-06-06 10:28:12.519: [iter 110 : loss : 0.1243 = 0.0332 + 0.0855 + 0.0056, time: 6.456003]
2023-06-06 10:28:12.670: epoch 110:	0.02668707  	0.19667643  	0.10738179  
2023-06-06 10:28:12.670: Find a better model.
2023-06-06 10:28:19.257: [iter 111 : loss : 0.1244 = 0.0333 + 0.0854 + 0.0057, time: 6.586002]
2023-06-06 10:28:19.404: epoch 111:	0.02668707  	0.19667788  	0.10739192  
2023-06-06 10:28:19.404: Find a better model.
2023-06-06 10:28:25.912: [iter 112 : loss : 0.1240 = 0.0329 + 0.0853 + 0.0057, time: 6.505539]
2023-06-06 10:28:26.062: epoch 112:	0.02677175  	0.19716740  	0.10767574  
2023-06-06 10:28:26.062: Find a better model.
2023-06-06 10:28:32.492: [iter 113 : loss : 0.1239 = 0.0328 + 0.0853 + 0.0057, time: 6.428998]
2023-06-06 10:28:32.641: epoch 113:	0.02672235  	0.19653192  	0.10752867  
2023-06-06 10:28:39.102: [iter 114 : loss : 0.1231 = 0.0321 + 0.0852 + 0.0058, time: 6.460002]
2023-06-06 10:28:39.253: epoch 114:	0.02664473  	0.19602211  	0.10743049  
2023-06-06 10:28:45.690: [iter 115 : loss : 0.1227 = 0.0317 + 0.0852 + 0.0058, time: 6.435997]
2023-06-06 10:28:45.840: epoch 115:	0.02663061  	0.19600596  	0.10731082  
2023-06-06 10:28:52.286: [iter 116 : loss : 0.1218 = 0.0308 + 0.0851 + 0.0058, time: 6.445006]
2023-06-06 10:28:52.435: epoch 116:	0.02662355  	0.19578342  	0.10721797  
2023-06-06 10:28:58.882: [iter 117 : loss : 0.1219 = 0.0309 + 0.0850 + 0.0059, time: 6.445982]
2023-06-06 10:28:59.033: epoch 117:	0.02668001  	0.19618332  	0.10740567  
2023-06-06 10:29:05.479: [iter 118 : loss : 0.1216 = 0.0308 + 0.0850 + 0.0059, time: 6.445005]
2023-06-06 10:29:05.626: epoch 118:	0.02670823  	0.19679394  	0.10770503  
2023-06-06 10:29:12.234: [iter 119 : loss : 0.1207 = 0.0299 + 0.0849 + 0.0059, time: 6.605993]
2023-06-06 10:29:12.383: epoch 119:	0.02668001  	0.19660078  	0.10786542  
2023-06-06 10:29:18.872: [iter 120 : loss : 0.1210 = 0.0302 + 0.0849 + 0.0060, time: 6.487131]
2023-06-06 10:29:19.021: epoch 120:	0.02671529  	0.19706385  	0.10827362  
2023-06-06 10:29:25.477: [iter 121 : loss : 0.1210 = 0.0302 + 0.0849 + 0.0060, time: 6.454436]
2023-06-06 10:29:25.627: epoch 121:	0.02679996  	0.19756559  	0.10836550  
2023-06-06 10:29:25.627: Find a better model.
2023-06-06 10:29:32.073: [iter 122 : loss : 0.1201 = 0.0293 + 0.0848 + 0.0060, time: 6.445018]
2023-06-06 10:29:32.221: epoch 122:	0.02675762  	0.19684641  	0.10823946  
2023-06-06 10:29:38.681: [iter 123 : loss : 0.1200 = 0.0292 + 0.0848 + 0.0060, time: 6.458006]
2023-06-06 10:29:38.831: epoch 123:	0.02675057  	0.19696862  	0.10809296  
2023-06-06 10:29:45.440: [iter 124 : loss : 0.1191 = 0.0283 + 0.0847 + 0.0061, time: 6.607056]
2023-06-06 10:29:45.590: epoch 124:	0.02678585  	0.19733915  	0.10827442  
2023-06-06 10:29:52.067: [iter 125 : loss : 0.1186 = 0.0279 + 0.0847 + 0.0061, time: 6.476140]
2023-06-06 10:29:52.219: epoch 125:	0.02680702  	0.19734572  	0.10838521  
2023-06-06 10:29:58.854: [iter 126 : loss : 0.1186 = 0.0279 + 0.0846 + 0.0061, time: 6.633023]
2023-06-06 10:29:59.006: epoch 126:	0.02680702  	0.19767398  	0.10846341  
2023-06-06 10:29:59.006: Find a better model.
2023-06-06 10:30:05.443: [iter 127 : loss : 0.1180 = 0.0272 + 0.0846 + 0.0062, time: 6.436003]
2023-06-06 10:30:05.594: epoch 127:	0.02679996  	0.19743323  	0.10841655  
2023-06-06 10:30:12.069: [iter 128 : loss : 0.1187 = 0.0280 + 0.0845 + 0.0062, time: 6.473533]
2023-06-06 10:30:12.222: epoch 128:	0.02674351  	0.19686024  	0.10823624  
2023-06-06 10:30:18.653: [iter 129 : loss : 0.1181 = 0.0274 + 0.0845 + 0.0062, time: 6.430013]
2023-06-06 10:30:18.803: epoch 129:	0.02674351  	0.19657007  	0.10808300  
2023-06-06 10:30:25.255: [iter 130 : loss : 0.1179 = 0.0272 + 0.0844 + 0.0063, time: 6.450995]
2023-06-06 10:30:25.405: epoch 130:	0.02677174  	0.19680263  	0.10815756  
2023-06-06 10:30:31.864: [iter 131 : loss : 0.1172 = 0.0265 + 0.0844 + 0.0063, time: 6.457404]
2023-06-06 10:30:32.012: epoch 131:	0.02676468  	0.19653489  	0.10818743  
2023-06-06 10:30:38.469: [iter 132 : loss : 0.1175 = 0.0268 + 0.0844 + 0.0063, time: 6.455511]
2023-06-06 10:30:38.619: epoch 132:	0.02685641  	0.19729756  	0.10845954  
2023-06-06 10:30:45.052: [iter 133 : loss : 0.1161 = 0.0254 + 0.0843 + 0.0063, time: 6.430993]
2023-06-06 10:30:45.202: epoch 133:	0.02684936  	0.19731131  	0.10845639  
2023-06-06 10:30:51.639: [iter 134 : loss : 0.1169 = 0.0262 + 0.0843 + 0.0064, time: 6.435006]
2023-06-06 10:30:51.788: epoch 134:	0.02677879  	0.19655840  	0.10831342  
2023-06-06 10:30:58.228: [iter 135 : loss : 0.1165 = 0.0258 + 0.0842 + 0.0064, time: 6.438002]
2023-06-06 10:30:58.375: epoch 135:	0.02682819  	0.19737421  	0.10854446  
2023-06-06 10:31:04.855: [iter 136 : loss : 0.1160 = 0.0253 + 0.0842 + 0.0064, time: 6.479005]
2023-06-06 10:31:05.003: epoch 136:	0.02686347  	0.19725968  	0.10843780  
2023-06-06 10:31:11.454: [iter 137 : loss : 0.1157 = 0.0250 + 0.0841 + 0.0065, time: 6.449023]
2023-06-06 10:31:11.602: epoch 137:	0.02687052  	0.19740914  	0.10850967  
2023-06-06 10:31:18.038: [iter 138 : loss : 0.1155 = 0.0249 + 0.0841 + 0.0065, time: 6.434514]
2023-06-06 10:31:18.188: epoch 138:	0.02687758  	0.19737227  	0.10870665  
2023-06-06 10:31:24.631: [iter 139 : loss : 0.1153 = 0.0247 + 0.0841 + 0.0065, time: 6.442006]
2023-06-06 10:31:24.780: epoch 139:	0.02696226  	0.19818321  	0.10915985  
2023-06-06 10:31:24.780: Find a better model.
2023-06-06 10:31:31.238: [iter 140 : loss : 0.1147 = 0.0241 + 0.0841 + 0.0066, time: 6.456009]
2023-06-06 10:31:31.390: epoch 140:	0.02685641  	0.19749810  	0.10909098  
2023-06-06 10:31:37.842: [iter 141 : loss : 0.1153 = 0.0247 + 0.0840 + 0.0066, time: 6.451266]
2023-06-06 10:31:37.994: epoch 141:	0.02681407  	0.19722492  	0.10892408  
2023-06-06 10:31:44.445: [iter 142 : loss : 0.1143 = 0.0237 + 0.0840 + 0.0066, time: 6.449007]
2023-06-06 10:31:44.596: epoch 142:	0.02685641  	0.19739358  	0.10907181  
2023-06-06 10:31:51.173: [iter 143 : loss : 0.1143 = 0.0238 + 0.0839 + 0.0066, time: 6.575377]
2023-06-06 10:31:51.323: epoch 143:	0.02684230  	0.19737083  	0.10900856  
2023-06-06 10:31:57.807: [iter 144 : loss : 0.1137 = 0.0231 + 0.0839 + 0.0067, time: 6.482996]
2023-06-06 10:31:57.957: epoch 144:	0.02686347  	0.19691241  	0.10880987  
2023-06-06 10:32:04.415: [iter 145 : loss : 0.1135 = 0.0229 + 0.0839 + 0.0067, time: 6.457007]
2023-06-06 10:32:04.565: epoch 145:	0.02679996  	0.19669400  	0.10898352  
2023-06-06 10:32:11.025: [iter 146 : loss : 0.1139 = 0.0234 + 0.0839 + 0.0067, time: 6.457108]
2023-06-06 10:32:11.174: epoch 146:	0.02681407  	0.19661950  	0.10906313  
2023-06-06 10:32:17.609: [iter 147 : loss : 0.1137 = 0.0231 + 0.0838 + 0.0067, time: 6.432994]
2023-06-06 10:32:17.760: epoch 147:	0.02686347  	0.19674580  	0.10920436  
2023-06-06 10:32:24.202: [iter 148 : loss : 0.1125 = 0.0220 + 0.0837 + 0.0068, time: 6.439132]
2023-06-06 10:32:24.351: epoch 148:	0.02692697  	0.19757612  	0.10950876  
2023-06-06 10:32:30.800: [iter 149 : loss : 0.1130 = 0.0225 + 0.0838 + 0.0068, time: 6.448013]
2023-06-06 10:32:30.951: epoch 149:	0.02686347  	0.19703174  	0.10940363  
2023-06-06 10:32:37.407: [iter 150 : loss : 0.1124 = 0.0219 + 0.0837 + 0.0068, time: 6.454999]
2023-06-06 10:32:37.559: epoch 150:	0.02689875  	0.19742763  	0.10955840  
2023-06-06 10:32:43.976: [iter 151 : loss : 0.1125 = 0.0219 + 0.0837 + 0.0068, time: 6.416092]
2023-06-06 10:32:44.128: epoch 151:	0.02690580  	0.19751491  	0.10968365  
2023-06-06 10:32:50.623: [iter 152 : loss : 0.1119 = 0.0214 + 0.0836 + 0.0069, time: 6.493025]
2023-06-06 10:32:50.774: epoch 152:	0.02687052  	0.19706985  	0.10955868  
2023-06-06 10:32:57.215: [iter 153 : loss : 0.1108 = 0.0203 + 0.0836 + 0.0069, time: 6.439994]
2023-06-06 10:32:57.364: epoch 153:	0.02687052  	0.19714721  	0.10966267  
2023-06-06 10:33:03.807: [iter 154 : loss : 0.1116 = 0.0211 + 0.0836 + 0.0069, time: 6.442180]
2023-06-06 10:33:03.958: epoch 154:	0.02689875  	0.19719860  	0.10962211  
2023-06-06 10:33:10.388: [iter 155 : loss : 0.1121 = 0.0216 + 0.0835 + 0.0069, time: 6.427997]
2023-06-06 10:33:10.537: epoch 155:	0.02689169  	0.19712950  	0.10967525  
2023-06-06 10:33:16.991: [iter 156 : loss : 0.1115 = 0.0210 + 0.0836 + 0.0070, time: 6.452022]
2023-06-06 10:33:17.141: epoch 156:	0.02674350  	0.19613919  	0.10919867  
2023-06-06 10:33:23.591: [iter 157 : loss : 0.1115 = 0.0210 + 0.0835 + 0.0070, time: 6.448009]
2023-06-06 10:33:23.741: epoch 157:	0.02676467  	0.19600230  	0.10921126  
2023-06-06 10:33:30.179: [iter 158 : loss : 0.1106 = 0.0201 + 0.0835 + 0.0070, time: 6.435506]
2023-06-06 10:33:30.328: epoch 158:	0.02675056  	0.19564772  	0.10921004  
2023-06-06 10:33:36.773: [iter 159 : loss : 0.1108 = 0.0203 + 0.0834 + 0.0070, time: 6.444107]
2023-06-06 10:33:36.925: epoch 159:	0.02675762  	0.19566271  	0.10914350  
2023-06-06 10:33:43.380: [iter 160 : loss : 0.1106 = 0.0201 + 0.0834 + 0.0071, time: 6.453994]
2023-06-06 10:33:43.529: epoch 160:	0.02670822  	0.19548151  	0.10889030  
2023-06-06 10:33:49.977: [iter 161 : loss : 0.1101 = 0.0196 + 0.0834 + 0.0071, time: 6.447034]
2023-06-06 10:33:50.127: epoch 161:	0.02671528  	0.19531372  	0.10890958  
2023-06-06 10:33:56.575: [iter 162 : loss : 0.1095 = 0.0191 + 0.0833 + 0.0071, time: 6.446007]
2023-06-06 10:33:56.726: epoch 162:	0.02665883  	0.19481938  	0.10871559  
2023-06-06 10:34:03.176: [iter 163 : loss : 0.1099 = 0.0195 + 0.0833 + 0.0071, time: 6.449002]
2023-06-06 10:34:03.326: epoch 163:	0.02668706  	0.19524035  	0.10868923  
2023-06-06 10:34:09.786: [iter 164 : loss : 0.1098 = 0.0194 + 0.0833 + 0.0072, time: 6.459012]
2023-06-06 10:34:09.935: epoch 164:	0.02659532  	0.19438197  	0.10852306  
2023-06-06 10:34:09.935: Early stopping is trigger at epoch: 164
2023-06-06 10:34:09.936: best_result@epoch 139:

2023-06-06 10:34:09.936: 		0.0270      	0.1982      	0.1092      
