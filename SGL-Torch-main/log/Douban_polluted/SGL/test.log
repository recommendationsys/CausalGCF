2023-05-09 11:12:16.857: my pid: 1060
2023-05-09 11:12:16.857: model: model.general_recommender.SGL
2023-05-09 11:12:16.857: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 11:12:16.857: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 11:12:21.181: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 11:13:09.986: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 48.805576]
2023-05-09 11:13:10.407: epoch 1:	0.00273420  	0.00639168  	0.00521473  
2023-05-09 11:13:10.407: Find a better model.
2023-05-09 11:13:47.452: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 37.038531]
2023-05-09 11:13:47.855: epoch 2:	0.00208960  	0.00389808  	0.00335562  
2023-05-09 11:14:27.891: [iter 3 : loss : 1.6070 = 0.6930 + 0.9139 + 0.0000, time: 40.028788]
2023-05-09 11:14:28.589: epoch 3:	0.00406637  	0.00862525  	0.00712825  
2023-05-09 11:14:28.589: Find a better model.
2023-05-09 11:15:09.796: [iter 4 : loss : 1.6075 = 0.6930 + 0.9145 + 0.0000, time: 41.199284]
2023-05-09 11:15:10.473: epoch 4:	0.00271271  	0.00515350  	0.00464285  
2023-05-09 11:15:54.183: [iter 5 : loss : 1.6073 = 0.6929 + 0.9143 + 0.0000, time: 43.702937]
2023-05-09 11:15:54.883: epoch 5:	0.00547912  	0.01114391  	0.00975902  
2023-05-09 11:15:54.883: Find a better model.
2023-05-09 11:16:41.682: [iter 6 : loss : 1.6077 = 0.6929 + 0.9148 + 0.0000, time: 46.792016]
2023-05-09 11:16:42.402: epoch 6:	0.00344863  	0.00631967  	0.00544696  
2023-05-09 11:17:30.079: [iter 7 : loss : 1.6076 = 0.6928 + 0.9148 + 0.0000, time: 47.666668]
2023-05-09 11:17:30.682: epoch 7:	0.00706914  	0.01376254  	0.01205548  
2023-05-09 11:17:30.682: Find a better model.
2023-05-09 11:18:19.865: [iter 8 : loss : 1.6079 = 0.6928 + 0.9151 + 0.0000, time: 49.174608]
2023-05-09 11:18:20.342: epoch 8:	0.00487749  	0.00841710  	0.00783403  
2023-05-09 11:19:08.638: [iter 9 : loss : 1.6077 = 0.6926 + 0.9152 + 0.0000, time: 48.288618]
2023-05-09 11:19:09.108: epoch 9:	0.00898154  	0.01751146  	0.01538671  
2023-05-09 11:19:09.109: Find a better model.
2023-05-09 11:19:56.510: [iter 10 : loss : 1.6080 = 0.6925 + 0.9155 + 0.0000, time: 47.393526]
2023-05-09 11:19:56.931: epoch 10:	0.00689724  	0.01167310  	0.01107583  
2023-05-09 11:20:43.352: [iter 11 : loss : 1.6076 = 0.6922 + 0.9153 + 0.0000, time: 46.413331]
2023-05-09 11:20:43.806: epoch 11:	0.01219392  	0.02312554  	0.02171287  
2023-05-09 11:20:43.806: Find a better model.
2023-05-09 11:21:31.750: [iter 12 : loss : 1.6081 = 0.6921 + 0.9160 + 0.0000, time: 47.935920]
2023-05-09 11:21:32.299: epoch 12:	0.00945963  	0.01646703  	0.01622386  
2023-05-09 11:22:17.253: [iter 13 : loss : 1.6074 = 0.6915 + 0.9159 + 0.0000, time: 44.946067]
2023-05-09 11:22:18.175: epoch 13:	0.01628193  	0.03144797  	0.03008131  
2023-05-09 11:22:18.175: Find a better model.
2023-05-09 11:23:03.081: [iter 14 : loss : 1.6079 = 0.6912 + 0.9167 + 0.0000, time: 44.899426]
2023-05-09 11:23:03.712: epoch 14:	0.01420300  	0.02544429  	0.02574049  
2023-05-09 11:23:47.792: [iter 15 : loss : 1.6066 = 0.6901 + 0.9164 + 0.0000, time: 44.072732]
2023-05-09 11:23:48.669: epoch 15:	0.02429678  	0.04723466  	0.04604264  
2023-05-09 11:23:48.669: Find a better model.
2023-05-09 11:24:33.264: [iter 16 : loss : 1.6070 = 0.6891 + 0.9178 + 0.0001, time: 44.587036]
2023-05-09 11:24:34.049: epoch 16:	0.02562896  	0.04794053  	0.04851392  
2023-05-09 11:24:34.049: Find a better model.
2023-05-09 11:25:19.895: [iter 17 : loss : 1.6040 = 0.6865 + 0.9174 + 0.0001, time: 45.836417]
2023-05-09 11:25:20.405: epoch 17:	0.04034668  	0.07736930  	0.07750724  
2023-05-09 11:25:20.405: Find a better model.
2023-05-09 11:26:04.273: [iter 18 : loss : 1.6029 = 0.6826 + 0.9201 + 0.0001, time: 43.861346]
2023-05-09 11:26:04.684: epoch 18:	0.04645412  	0.08878540  	0.08955072  
2023-05-09 11:26:04.684: Find a better model.
2023-05-09 11:26:47.917: [iter 19 : loss : 1.5933 = 0.6733 + 0.9198 + 0.0002, time: 43.226670]
2023-05-09 11:26:48.444: epoch 19:	0.06296080  	0.11922095  	0.11958539  
2023-05-09 11:26:48.445: Find a better model.
2023-05-09 11:27:31.370: [iter 20 : loss : 1.5821 = 0.6559 + 0.9259 + 0.0003, time: 42.916631]
2023-05-09 11:27:31.816: epoch 20:	0.07135652  	0.13304251  	0.13440874  
2023-05-09 11:27:31.816: Find a better model.
2023-05-09 11:28:13.307: [iter 21 : loss : 1.5467 = 0.6194 + 0.9267 + 0.0005, time: 41.483239]
2023-05-09 11:28:13.736: epoch 21:	0.07970915  	0.14759058  	0.14866747  
2023-05-09 11:28:13.736: Find a better model.
2023-05-09 11:28:55.050: [iter 22 : loss : 1.5078 = 0.5684 + 0.9386 + 0.0009, time: 41.307558]
2023-05-09 11:28:55.468: epoch 22:	0.08236277  	0.15355138  	0.15441778  
2023-05-09 11:28:55.468: Find a better model.
2023-05-09 11:29:35.176: [iter 23 : loss : 1.4430 = 0.5024 + 0.9393 + 0.0013, time: 39.699853]
2023-05-09 11:29:35.628: epoch 23:	0.08453815  	0.15825915  	0.15861191  
2023-05-09 11:29:35.628: Find a better model.
2023-05-09 11:30:13.873: [iter 24 : loss : 1.3994 = 0.4447 + 0.9528 + 0.0018, time: 38.238813]
2023-05-09 11:30:14.319: epoch 24:	0.08524714  	0.16057436  	0.16051485  
2023-05-09 11:30:14.319: Find a better model.
2023-05-09 11:30:52.519: [iter 25 : loss : 1.3393 = 0.3898 + 0.9472 + 0.0023, time: 38.190366]
2023-05-09 11:30:53.398: epoch 25:	0.08644507  	0.16289189  	0.16223888  
2023-05-09 11:30:53.398: Find a better model.
2023-05-09 11:31:31.486: [iter 26 : loss : 1.3093 = 0.3475 + 0.9590 + 0.0028, time: 38.080273]
2023-05-09 11:31:31.916: epoch 26:	0.08678874  	0.16359434  	0.16298214  
2023-05-09 11:31:31.916: Find a better model.
2023-05-09 11:32:09.722: [iter 27 : loss : 1.2620 = 0.3096 + 0.9490 + 0.0033, time: 37.799517]
2023-05-09 11:32:10.409: epoch 27:	0.08740114  	0.16493383  	0.16393796  
2023-05-09 11:32:10.409: Find a better model.
2023-05-09 11:32:48.502: [iter 28 : loss : 1.2440 = 0.2808 + 0.9595 + 0.0038, time: 38.083533]
2023-05-09 11:32:48.902: epoch 28:	0.08763213  	0.16483761  	0.16388842  
2023-05-09 11:33:26.860: [iter 29 : loss : 1.2078 = 0.2553 + 0.9483 + 0.0042, time: 37.950437]
2023-05-09 11:33:27.551: epoch 29:	0.08792219  	0.16520107  	0.16420630  
2023-05-09 11:33:27.551: Find a better model.
2023-05-09 11:34:09.206: [iter 30 : loss : 1.1971 = 0.2349 + 0.9576 + 0.0046, time: 41.641671]
2023-05-09 11:34:09.896: epoch 30:	0.08768038  	0.16458353  	0.16343762  
2023-05-09 11:34:53.977: [iter 31 : loss : 1.1677 = 0.2163 + 0.9464 + 0.0051, time: 44.073854]
2023-05-09 11:34:54.684: epoch 31:	0.08808324  	0.16493593  	0.16361110  
2023-05-09 11:35:46.135: [iter 32 : loss : 1.1624 = 0.2018 + 0.9552 + 0.0054, time: 51.444368]
2023-05-09 11:35:46.833: epoch 32:	0.08762129  	0.16402921  	0.16263226  
2023-05-09 11:36:35.249: [iter 33 : loss : 1.1378 = 0.1875 + 0.9444 + 0.0058, time: 48.407856]
2023-05-09 11:36:35.954: epoch 33:	0.08791134  	0.16450927  	0.16294944  
2023-05-09 11:37:27.023: [iter 34 : loss : 1.1357 = 0.1768 + 0.9527 + 0.0062, time: 51.062997]
2023-05-09 11:37:27.536: epoch 34:	0.08711641  	0.16286652  	0.16175276  
2023-05-09 11:38:08.949: my pid: 11012
2023-05-09 11:38:08.949: model: model.general_recommender.SGL
2023-05-09 11:38:08.949: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 11:38:08.949: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 11:38:13.336: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 11:38:52.956: [iter 1 : loss : 1.6092 = 0.6931 + 0.9161 + 0.0000, time: 39.619258]
2023-05-09 11:38:53.421: epoch 1:	0.00285237  	0.00678490  	0.00556334  
2023-05-09 11:38:53.421: Find a better model.
2023-05-09 11:39:33.068: [iter 2 : loss : 1.6088 = 0.6931 + 0.9157 + 0.0000, time: 39.639929]
2023-05-09 11:39:33.525: epoch 2:	0.00194994  	0.00385866  	0.00338491  
2023-05-09 11:40:13.023: [iter 3 : loss : 1.6082 = 0.6930 + 0.9152 + 0.0000, time: 39.491000]
2023-05-09 11:40:13.480: epoch 3:	0.00391597  	0.00844868  	0.00714234  
2023-05-09 11:40:13.480: Find a better model.
2023-05-09 11:40:52.862: [iter 4 : loss : 1.6091 = 0.6930 + 0.9161 + 0.0000, time: 39.374457]
2023-05-09 11:40:53.333: epoch 4:	0.00227224  	0.00431229  	0.00384187  
2023-05-09 11:41:32.565: [iter 5 : loss : 1.6088 = 0.6929 + 0.9159 + 0.0000, time: 39.224976]
2023-05-09 11:41:33.000: epoch 5:	0.00519979  	0.01069443  	0.00935667  
2023-05-09 11:41:33.000: Find a better model.
2023-05-09 11:42:12.247: [iter 6 : loss : 1.6095 = 0.6929 + 0.9166 + 0.0000, time: 39.238788]
2023-05-09 11:42:12.657: epoch 6:	0.00318005  	0.00533059  	0.00517050  
2023-05-09 11:42:51.904: [iter 7 : loss : 1.6093 = 0.6928 + 0.9165 + 0.0000, time: 39.239837]
2023-05-09 11:42:52.385: epoch 7:	0.00607000  	0.01152423  	0.01008502  
2023-05-09 11:42:52.385: Find a better model.
2023-05-09 11:43:31.877: [iter 8 : loss : 1.6098 = 0.6927 + 0.9171 + 0.0000, time: 39.485138]
2023-05-09 11:43:32.350: epoch 8:	0.00422215  	0.00663604  	0.00659971  
2023-05-09 11:44:11.546: [iter 9 : loss : 1.6096 = 0.6925 + 0.9171 + 0.0000, time: 39.186449]
2023-05-09 11:44:11.976: epoch 9:	0.00769229  	0.01417877  	0.01313946  
2023-05-09 11:44:11.976: Find a better model.
2023-05-09 11:44:51.909: [iter 10 : loss : 1.6102 = 0.6924 + 0.9177 + 0.0000, time: 39.924922]
2023-05-09 11:44:52.483: epoch 10:	0.00602703  	0.00975599  	0.00989349  
2023-05-09 11:45:32.127: [iter 11 : loss : 1.6096 = 0.6921 + 0.9175 + 0.0000, time: 39.638479]
2023-05-09 11:45:32.665: epoch 11:	0.01106583  	0.02013676  	0.01930155  
2023-05-09 11:45:32.665: Find a better model.
2023-05-09 11:46:12.880: [iter 12 : loss : 1.6103 = 0.6919 + 0.9184 + 0.0000, time: 40.207504]
2023-05-09 11:46:13.464: epoch 12:	0.00907286  	0.01544445  	0.01558993  
2023-05-09 11:46:53.611: [iter 13 : loss : 1.6097 = 0.6913 + 0.9183 + 0.0000, time: 40.137692]
2023-05-09 11:46:54.075: epoch 13:	0.01548688  	0.02928179  	0.02731648  
2023-05-09 11:46:54.075: Find a better model.
2023-05-09 11:47:34.153: [iter 14 : loss : 1.6103 = 0.6909 + 0.9194 + 0.0000, time: 40.069949]
2023-05-09 11:47:34.750: epoch 14:	0.01437489  	0.02549392  	0.02559153  
2023-05-09 11:48:14.854: [iter 15 : loss : 1.6090 = 0.6898 + 0.9192 + 0.0001, time: 40.096325]
2023-05-09 11:48:15.477: epoch 15:	0.02450087  	0.04673213  	0.04508640  
2023-05-09 11:48:15.477: Find a better model.
2023-05-09 11:48:55.952: [iter 16 : loss : 1.6095 = 0.6886 + 0.9208 + 0.0001, time: 40.466715]
2023-05-09 11:48:56.481: epoch 16:	0.02623598  	0.04904263  	0.04966712  
2023-05-09 11:48:56.481: Find a better model.
2023-05-09 11:49:39.102: [iter 17 : loss : 1.6064 = 0.6857 + 0.9206 + 0.0001, time: 42.609912]
2023-05-09 11:49:39.653: epoch 17:	0.04077638  	0.07843830  	0.07710437  
2023-05-09 11:49:39.653: Find a better model.
2023-05-09 11:50:20.510: [iter 18 : loss : 1.6054 = 0.6815 + 0.9237 + 0.0001, time: 40.847862]
2023-05-09 11:50:20.953: epoch 18:	0.04799586  	0.09076557  	0.09141728  
2023-05-09 11:50:20.954: Find a better model.
2023-05-09 11:51:02.398: [iter 19 : loss : 1.5954 = 0.6715 + 0.9238 + 0.0002, time: 41.437449]
2023-05-09 11:51:02.826: epoch 19:	0.06335285  	0.11855908  	0.11922026  
2023-05-09 11:51:02.827: Find a better model.
2023-05-09 11:51:44.536: [iter 20 : loss : 1.5841 = 0.6536 + 0.9302 + 0.0003, time: 41.701594]
2023-05-09 11:51:44.975: epoch 20:	0.07196870  	0.13297641  	0.13470577  
2023-05-09 11:51:44.975: Find a better model.
2023-05-09 11:52:26.815: [iter 21 : loss : 1.5490 = 0.6169 + 0.9315 + 0.0005, time: 41.832721]
2023-05-09 11:52:27.267: epoch 21:	0.07871537  	0.14579818  	0.14782290  
2023-05-09 11:52:27.267: Find a better model.
2023-05-09 11:53:10.190: [iter 22 : loss : 1.5114 = 0.5670 + 0.9435 + 0.0009, time: 42.915390]
2023-05-09 11:53:10.586: epoch 22:	0.08147626  	0.15226090  	0.15404637  
2023-05-09 11:53:10.586: Find a better model.
2023-05-09 11:53:44.984: [iter 23 : loss : 1.4483 = 0.5024 + 0.9445 + 0.0013, time: 34.392011]
2023-05-09 11:53:45.395: epoch 23:	0.08366252  	0.15656361  	0.15808722  
2023-05-09 11:53:45.395: Find a better model.
2023-05-09 11:54:19.794: [iter 24 : loss : 1.4055 = 0.4454 + 0.9583 + 0.0018, time: 34.391894]
2023-05-09 11:54:20.223: epoch 24:	0.08458102  	0.15856007  	0.15983975  
2023-05-09 11:54:20.223: Find a better model.
2023-05-09 11:54:54.722: [iter 25 : loss : 1.3455 = 0.3906 + 0.9526 + 0.0023, time: 34.491720]
2023-05-09 11:54:55.117: epoch 25:	0.08558548  	0.16093160  	0.16167797  
2023-05-09 11:54:55.117: Find a better model.
2023-05-09 11:55:29.551: [iter 26 : loss : 1.3158 = 0.3484 + 0.9646 + 0.0028, time: 34.426453]
2023-05-09 11:55:29.949: epoch 26:	0.08601523  	0.16135290  	0.16188605  
2023-05-09 11:55:29.949: Find a better model.
2023-05-09 11:56:04.485: [iter 27 : loss : 1.2683 = 0.3105 + 0.9545 + 0.0033, time: 34.528461]
2023-05-09 11:56:04.882: epoch 27:	0.08651476  	0.16218877  	0.16248719  
2023-05-09 11:56:04.882: Find a better model.
2023-05-09 11:56:39.185: [iter 28 : loss : 1.2504 = 0.2814 + 0.9652 + 0.0038, time: 34.297261]
2023-05-09 11:56:39.582: epoch 28:	0.08668659  	0.16268730  	0.16257732  
2023-05-09 11:56:39.582: Find a better model.
2023-05-09 11:57:14.089: [iter 29 : loss : 1.2137 = 0.2558 + 0.9536 + 0.0042, time: 34.500578]
2023-05-09 11:57:14.493: epoch 29:	0.08701967  	0.16333856  	0.16301243  
2023-05-09 11:57:14.493: Find a better model.
2023-05-09 11:57:49.096: [iter 30 : loss : 1.2033 = 0.2354 + 0.9632 + 0.0046, time: 34.595570]
2023-05-09 11:57:49.498: epoch 30:	0.08698207  	0.16303825  	0.16263793  
2023-05-09 11:58:24.096: [iter 31 : loss : 1.1731 = 0.2164 + 0.9516 + 0.0051, time: 34.590250]
2023-05-09 11:58:24.496: epoch 31:	0.08727221  	0.16371368  	0.16278847  
2023-05-09 11:58:24.496: Find a better model.
2023-05-09 11:58:59.121: [iter 32 : loss : 1.1682 = 0.2021 + 0.9607 + 0.0054, time: 34.619270]
2023-05-09 11:58:59.527: epoch 32:	0.08699818  	0.16309579  	0.16197954  
2023-05-09 11:59:33.778: [iter 33 : loss : 1.1432 = 0.1878 + 0.9496 + 0.0058, time: 34.244616]
2023-05-09 11:59:34.207: epoch 33:	0.08736343  	0.16378303  	0.16240476  
2023-05-09 11:59:34.207: Find a better model.
2023-05-09 12:00:08.668: [iter 34 : loss : 1.1411 = 0.1769 + 0.9580 + 0.0062, time: 34.453701]
2023-05-09 12:00:09.064: epoch 34:	0.08670814  	0.16279186  	0.16127777  
2023-05-09 12:00:43.615: [iter 35 : loss : 1.1199 = 0.1658 + 0.9476 + 0.0065, time: 34.545381]
2023-05-09 12:00:44.017: epoch 35:	0.08708949  	0.16367443  	0.16197813  
2023-05-09 12:01:18.662: [iter 36 : loss : 1.1200 = 0.1573 + 0.9558 + 0.0068, time: 34.638071]
2023-05-09 12:01:19.062: epoch 36:	0.08679952  	0.16312769  	0.16130127  
2023-05-09 12:01:53.559: [iter 37 : loss : 1.1014 = 0.1486 + 0.9456 + 0.0072, time: 34.490040]
2023-05-09 12:01:53.958: epoch 37:	0.08696068  	0.16267796  	0.16125272  
2023-05-09 12:02:28.660: [iter 38 : loss : 1.1027 = 0.1417 + 0.9536 + 0.0075, time: 34.695263]
2023-05-09 12:02:29.055: epoch 38:	0.08639663  	0.16164224  	0.16034643  
2023-05-09 12:03:03.607: [iter 39 : loss : 1.0868 = 0.1350 + 0.9440 + 0.0078, time: 34.544402]
2023-05-09 12:03:04.000: epoch 39:	0.08639665  	0.16164863  	0.16024753  
2023-05-09 12:03:38.820: [iter 40 : loss : 1.0892 = 0.1296 + 0.9515 + 0.0081, time: 34.813528]
2023-05-09 12:03:39.244: epoch 40:	0.08606359  	0.16034564  	0.15926889  
2023-05-09 12:04:13.957: [iter 41 : loss : 1.0745 = 0.1237 + 0.9424 + 0.0083, time: 34.705907]
2023-05-09 12:04:14.373: epoch 41:	0.08616026  	0.16041546  	0.15935381  
2023-05-09 12:04:49.178: [iter 42 : loss : 1.0773 = 0.1188 + 0.9499 + 0.0086, time: 34.797172]
2023-05-09 12:04:49.575: epoch 42:	0.08561778  	0.15929329  	0.15825470  
2023-05-09 12:05:24.294: [iter 43 : loss : 1.0640 = 0.1140 + 0.9412 + 0.0089, time: 34.713835]
2023-05-09 12:05:24.692: epoch 43:	0.08579510  	0.15897520  	0.15832196  
2023-05-09 12:05:59.324: [iter 44 : loss : 1.0675 = 0.1100 + 0.9484 + 0.0091, time: 34.625126]
2023-05-09 12:05:59.719: epoch 44:	0.08523640  	0.15748203  	0.15706992  
2023-05-09 12:06:34.279: [iter 45 : loss : 1.0560 = 0.1064 + 0.9402 + 0.0094, time: 34.553274]
2023-05-09 12:06:34.680: epoch 45:	0.08534386  	0.15716694  	0.15700468  
2023-05-09 12:07:09.311: [iter 46 : loss : 1.0599 = 0.1029 + 0.9474 + 0.0096, time: 34.624528]
2023-05-09 12:07:09.713: epoch 46:	0.08493023  	0.15612759  	0.15600015  
2023-05-09 12:07:44.276: [iter 47 : loss : 1.0481 = 0.0992 + 0.9391 + 0.0098, time: 34.556370]
2023-05-09 12:07:44.678: epoch 47:	0.08488735  	0.15611558  	0.15602906  
2023-05-09 12:08:19.314: [iter 48 : loss : 1.0525 = 0.0965 + 0.9460 + 0.0101, time: 34.630249]
2023-05-09 12:08:19.715: epoch 48:	0.08425348  	0.15450272  	0.15469731  
2023-05-09 12:08:54.295: [iter 49 : loss : 1.0418 = 0.0933 + 0.9382 + 0.0103, time: 34.571773]
2023-05-09 12:08:54.701: epoch 49:	0.08424811  	0.15438533  	0.15473387  
2023-05-09 12:09:29.298: [iter 50 : loss : 1.0461 = 0.0907 + 0.9449 + 0.0105, time: 34.588721]
2023-05-09 12:09:29.697: epoch 50:	0.08381304  	0.15329114  	0.15354045  
2023-05-09 12:10:04.276: [iter 51 : loss : 1.0364 = 0.0882 + 0.9375 + 0.0107, time: 34.571296]
2023-05-09 12:10:04.670: epoch 51:	0.08388289  	0.15355203  	0.15372406  
2023-05-09 12:10:39.445: [iter 52 : loss : 1.0409 = 0.0858 + 0.9441 + 0.0109, time: 34.767728]
2023-05-09 12:10:39.846: epoch 52:	0.08334039  	0.15209761  	0.15249881  
2023-05-09 12:11:14.397: [iter 53 : loss : 1.0312 = 0.0834 + 0.9367 + 0.0111, time: 34.544377]
2023-05-09 12:11:14.795: epoch 53:	0.08350690  	0.15221085  	0.15263376  
2023-05-09 12:11:49.811: [iter 54 : loss : 1.0355 = 0.0811 + 0.9431 + 0.0113, time: 35.009022]
2023-05-09 12:11:50.244: epoch 54:	0.08295899  	0.15085992  	0.15150669  
2023-05-09 12:12:24.732: [iter 55 : loss : 1.0271 = 0.0795 + 0.9362 + 0.0115, time: 34.481197]
2023-05-09 12:12:25.124: epoch 55:	0.08306645  	0.15083928  	0.15159689  
2023-05-09 12:12:59.816: [iter 56 : loss : 1.0318 = 0.0776 + 0.9425 + 0.0117, time: 34.682949]
2023-05-09 12:13:00.244: epoch 56:	0.08264212  	0.14955451  	0.15081361  
2023-05-09 12:13:35.181: [iter 57 : loss : 1.0233 = 0.0757 + 0.9357 + 0.0119, time: 34.930253]
2023-05-09 12:13:35.581: epoch 57:	0.08266895  	0.14935869  	0.15053765  
2023-05-09 12:14:10.794: [iter 58 : loss : 1.0280 = 0.0742 + 0.9418 + 0.0120, time: 35.206165]
2023-05-09 12:14:11.224: epoch 58:	0.08233052  	0.14881155  	0.14974783  
2023-05-09 12:14:11.224: Early stopping is trigger at epoch: 58
2023-05-09 12:14:11.224: best_result@epoch 33:

2023-05-09 12:14:11.224: 		0.0874      	0.1638      	0.1624      
2023-05-09 14:34:31.356: my pid: 1988
2023-05-09 14:34:31.356: model: model.general_recommender.SGL
2023-05-09 14:34:31.356: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 14:34:31.356: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 14:34:35.403: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 14:35:13.284: [iter 1 : loss : 1.6083 = 0.6931 + 0.9151 + 0.0000, time: 37.880709]
2023-05-09 14:35:13.687: epoch 1:	0.00301353  	0.00705283  	0.00579627  
2023-05-09 14:35:13.687: Find a better model.
2023-05-09 14:35:50.324: [iter 2 : loss : 1.6067 = 0.6931 + 0.9136 + 0.0000, time: 36.630085]
2023-05-09 14:35:50.740: epoch 2:	0.00256231  	0.00483164  	0.00421920  
2023-05-09 14:36:27.305: [iter 3 : loss : 1.6061 = 0.6930 + 0.9131 + 0.0000, time: 36.556104]
2023-05-09 14:36:27.710: epoch 3:	0.00483989  	0.01032643  	0.00887188  
2023-05-09 14:36:27.710: Find a better model.
2023-05-09 14:37:04.367: [iter 4 : loss : 1.6064 = 0.6930 + 0.9134 + 0.0000, time: 36.650035]
2023-05-09 14:37:04.796: epoch 4:	0.00341640  	0.00592715  	0.00570279  
2023-05-09 14:37:41.734: [iter 5 : loss : 1.6062 = 0.6929 + 0.9132 + 0.0000, time: 36.929739]
2023-05-09 14:37:42.153: epoch 5:	0.00668237  	0.01313257  	0.01159223  
2023-05-09 14:37:42.153: Find a better model.
2023-05-09 14:38:19.112: [iter 6 : loss : 1.6064 = 0.6929 + 0.9135 + 0.0000, time: 36.953069]
2023-05-09 14:38:19.529: epoch 6:	0.00456056  	0.00782698  	0.00762125  
2023-05-09 14:38:56.724: [iter 7 : loss : 1.6063 = 0.6928 + 0.9135 + 0.0000, time: 37.188169]
2023-05-09 14:38:57.144: epoch 7:	0.00895468  	0.01662961  	0.01565001  
2023-05-09 14:38:57.144: Find a better model.
2023-05-09 14:39:44.577: [iter 8 : loss : 1.6065 = 0.6927 + 0.9137 + 0.0000, time: 47.417534]
2023-05-09 14:39:45.336: epoch 8:	0.00610223  	0.01023782  	0.00994090  
2023-05-09 14:40:32.390: [iter 9 : loss : 1.6063 = 0.6926 + 0.9137 + 0.0000, time: 47.040223]
2023-05-09 14:40:33.143: epoch 9:	0.01103898  	0.02033568  	0.01926967  
2023-05-09 14:40:33.143: Find a better model.
2023-05-09 14:41:20.453: [iter 10 : loss : 1.6064 = 0.6925 + 0.9139 + 0.0000, time: 47.296853]
2023-05-09 14:41:21.180: epoch 10:	0.00826707  	0.01431981  	0.01395911  
2023-05-09 14:42:08.882: [iter 11 : loss : 1.6059 = 0.6922 + 0.9138 + 0.0000, time: 47.694893]
2023-05-09 14:42:09.628: epoch 11:	0.01426211  	0.02755759  	0.02550356  
2023-05-09 14:42:09.628: Find a better model.
2023-05-09 14:42:58.519: [iter 12 : loss : 1.6063 = 0.6920 + 0.9143 + 0.0000, time: 48.879671]
2023-05-09 14:42:59.313: epoch 12:	0.01139352  	0.02101501  	0.02033420  
2023-05-09 14:43:51.230: [iter 13 : loss : 1.6056 = 0.6914 + 0.9141 + 0.0000, time: 51.896897]
2023-05-09 14:43:51.976: epoch 13:	0.01901087  	0.03675938  	0.03538823  
2023-05-09 14:43:51.976: Find a better model.
2023-05-09 14:44:41.993: [iter 14 : loss : 1.6059 = 0.6910 + 0.9149 + 0.0000, time: 50.005977]
2023-05-09 14:44:42.753: epoch 14:	0.01732944  	0.03128343  	0.03185970  
2023-05-09 14:45:32.856: [iter 15 : loss : 1.6044 = 0.6898 + 0.9145 + 0.0000, time: 50.095665]
2023-05-09 14:45:33.621: epoch 15:	0.02884121  	0.05713786  	0.05404866  
2023-05-09 14:45:33.621: Find a better model.
2023-05-09 14:46:23.767: [iter 16 : loss : 1.6045 = 0.6885 + 0.9159 + 0.0001, time: 50.138080]
2023-05-09 14:46:24.499: epoch 16:	0.02990475  	0.05709959  	0.05705165  
2023-05-09 14:47:15.287: [iter 17 : loss : 1.6007 = 0.6853 + 0.9153 + 0.0001, time: 50.778752]
2023-05-09 14:47:15.975: epoch 17:	0.04503069  	0.08853643  	0.08734521  
2023-05-09 14:47:15.975: Find a better model.
2023-05-09 14:48:05.895: [iter 18 : loss : 1.5986 = 0.6802 + 0.9183 + 0.0001, time: 49.903839]
2023-05-09 14:48:06.622: epoch 18:	0.05178807  	0.10040658  	0.10078530  
2023-05-09 14:48:06.622: Find a better model.
2023-05-09 14:48:56.838: [iter 19 : loss : 1.5856 = 0.6677 + 0.9177 + 0.0002, time: 50.208018]
2023-05-09 14:48:57.579: epoch 19:	0.06696239  	0.12793814  	0.12933153  
2023-05-09 14:48:57.579: Find a better model.
2023-05-09 14:49:47.917: [iter 20 : loss : 1.5693 = 0.6442 + 0.9248 + 0.0004, time: 50.327243]
2023-05-09 14:49:48.677: epoch 20:	0.07437508  	0.14114180  	0.14263082  
2023-05-09 14:49:48.678: Find a better model.
2023-05-09 14:50:38.505: [iter 21 : loss : 1.5250 = 0.5989 + 0.9254 + 0.0006, time: 49.819899]
2023-05-09 14:50:39.239: epoch 21:	0.08057401  	0.15143631  	0.15289481  
2023-05-09 14:50:39.239: Find a better model.
2023-05-09 14:51:29.476: [iter 22 : loss : 1.4815 = 0.5423 + 0.9382 + 0.0010, time: 50.230757]
2023-05-09 14:51:30.210: epoch 22:	0.08312537  	0.15671133  	0.15775780  
2023-05-09 14:51:30.210: Find a better model.
2023-05-09 14:52:22.348: [iter 23 : loss : 1.4149 = 0.4760 + 0.9373 + 0.0015, time: 52.123595]
2023-05-09 14:52:23.034: epoch 23:	0.08538141  	0.16033527  	0.16117552  
2023-05-09 14:52:23.034: Find a better model.
2023-05-09 14:53:13.481: [iter 24 : loss : 1.3737 = 0.4211 + 0.9506 + 0.0020, time: 50.438316]
2023-05-09 14:53:14.215: epoch 24:	0.08597224  	0.16196690  	0.16273597  
2023-05-09 14:53:14.215: Find a better model.
2023-05-09 14:54:03.575: [iter 25 : loss : 1.3162 = 0.3701 + 0.9436 + 0.0025, time: 49.345622]
2023-05-09 14:54:04.339: epoch 25:	0.08703578  	0.16393231  	0.16462572  
2023-05-09 14:54:04.339: Find a better model.
2023-05-09 14:54:54.111: [iter 26 : loss : 1.2890 = 0.3309 + 0.9551 + 0.0030, time: 49.763119]
2023-05-09 14:54:54.859: epoch 26:	0.08720751  	0.16516215  	0.16484796  
2023-05-09 14:54:54.859: Find a better model.
2023-05-09 14:55:44.712: [iter 27 : loss : 1.2444 = 0.2961 + 0.9448 + 0.0035, time: 49.842149]
2023-05-09 14:55:45.454: epoch 27:	0.08783602  	0.16597120  	0.16548824  
2023-05-09 14:55:45.455: Find a better model.
2023-05-09 14:56:35.827: [iter 28 : loss : 1.2285 = 0.2693 + 0.9552 + 0.0040, time: 50.358668]
2023-05-09 14:56:36.583: epoch 28:	0.08806159  	0.16634172  	0.16582578  
2023-05-09 14:56:36.583: Find a better model.
2023-05-09 14:57:27.590: [iter 29 : loss : 1.1942 = 0.2459 + 0.9439 + 0.0044, time: 50.999053]
2023-05-09 14:57:28.378: epoch 29:	0.08826566  	0.16685879  	0.16620496  
2023-05-09 14:57:28.378: Find a better model.
2023-05-09 14:58:18.841: [iter 30 : loss : 1.1848 = 0.2268 + 0.9531 + 0.0048, time: 50.447860]
2023-05-09 14:58:19.574: epoch 30:	0.08822277  	0.16641316  	0.16573839  
2023-05-09 14:59:10.065: [iter 31 : loss : 1.1565 = 0.2091 + 0.9421 + 0.0052, time: 50.478057]
2023-05-09 14:59:10.815: epoch 31:	0.08864173  	0.16740999  	0.16616862  
2023-05-09 14:59:10.815: Find a better model.
2023-05-09 15:00:01.107: [iter 32 : loss : 1.1520 = 0.1956 + 0.9507 + 0.0056, time: 50.283324]
2023-05-09 15:00:01.852: epoch 32:	0.08826043  	0.16606823  	0.16518055  
2023-05-09 15:00:51.993: [iter 33 : loss : 1.1284 = 0.1822 + 0.9402 + 0.0060, time: 50.126887]
2023-05-09 15:00:52.738: epoch 33:	0.08852366  	0.16639140  	0.16533485  
2023-05-09 15:01:42.968: [iter 34 : loss : 1.1269 = 0.1722 + 0.9484 + 0.0063, time: 50.223007]
2023-05-09 15:01:43.706: epoch 34:	0.08801874  	0.16541032  	0.16432659  
2023-05-09 15:02:34.080: [iter 35 : loss : 1.1068 = 0.1616 + 0.9385 + 0.0067, time: 50.362593]
2023-05-09 15:02:34.801: epoch 35:	0.08843776  	0.16627152  	0.16481060  
2023-05-09 15:03:24.769: [iter 36 : loss : 1.1067 = 0.1535 + 0.9463 + 0.0070, time: 49.961098]
2023-05-09 15:03:25.502: epoch 36:	0.08789518  	0.16516533  	0.16385637  
2023-05-09 15:04:15.771: [iter 37 : loss : 1.0892 = 0.1451 + 0.9367 + 0.0073, time: 50.260965]
2023-05-09 15:04:16.477: epoch 37:	0.08807786  	0.16525470  	0.16395919  
2023-05-09 15:05:07.026: [iter 38 : loss : 1.0901 = 0.1384 + 0.9441 + 0.0076, time: 50.539752]
2023-05-09 15:05:07.793: epoch 38:	0.08748697  	0.16420613  	0.16291264  
2023-05-09 15:05:58.412: [iter 39 : loss : 1.0753 = 0.1322 + 0.9352 + 0.0079, time: 50.613249]
2023-05-09 15:05:59.129: epoch 39:	0.08759981  	0.16405003  	0.16268925  
2023-05-09 15:06:49.660: [iter 40 : loss : 1.0772 = 0.1268 + 0.9423 + 0.0082, time: 50.522045]
2023-05-09 15:06:50.403: epoch 40:	0.08713243  	0.16298622  	0.16158779  
2023-05-09 15:07:41.462: [iter 41 : loss : 1.0636 = 0.1213 + 0.9338 + 0.0085, time: 51.049777]
2023-05-09 15:07:42.169: epoch 41:	0.08730434  	0.16289644  	0.16177434  
2023-05-09 15:08:24.868: [iter 42 : loss : 1.0662 = 0.1166 + 0.9408 + 0.0087, time: 42.691697]
2023-05-09 15:08:25.301: epoch 42:	0.08693900  	0.16166265  	0.16063146  
2023-05-09 15:09:03.436: [iter 43 : loss : 1.0535 = 0.1118 + 0.9327 + 0.0090, time: 38.129354]
2023-05-09 15:09:03.865: epoch 43:	0.08698743  	0.16146527  	0.16059273  
2023-05-09 15:09:43.485: [iter 44 : loss : 1.0565 = 0.1079 + 0.9394 + 0.0093, time: 39.613747]
2023-05-09 15:09:43.921: epoch 44:	0.08641797  	0.15990874  	0.15944505  
2023-05-09 15:10:23.447: [iter 45 : loss : 1.0460 = 0.1048 + 0.9317 + 0.0095, time: 39.517814]
2023-05-09 15:10:23.877: epoch 45:	0.08648247  	0.15966424  	0.15909699  
2023-05-09 15:11:03.568: [iter 46 : loss : 1.0490 = 0.1010 + 0.9383 + 0.0097, time: 39.684430]
2023-05-09 15:11:04.002: epoch 46:	0.08590230  	0.15835419  	0.15811007  
2023-05-09 15:11:44.145: [iter 47 : loss : 1.0385 = 0.0979 + 0.9307 + 0.0100, time: 40.134867]
2023-05-09 15:11:44.630: epoch 47:	0.08603125  	0.15827629  	0.15812260  
2023-05-09 15:12:26.276: [iter 48 : loss : 1.0418 = 0.0945 + 0.9371 + 0.0102, time: 41.637768]
2023-05-09 15:12:26.696: epoch 48:	0.08526321  	0.15650389  	0.15670459  
2023-05-09 15:13:09.125: [iter 49 : loss : 1.0321 = 0.0919 + 0.9298 + 0.0104, time: 42.422689]
2023-05-09 15:13:09.581: epoch 49:	0.08532233  	0.15644942  	0.15662034  
2023-05-09 15:13:53.346: [iter 50 : loss : 1.0356 = 0.0890 + 0.9360 + 0.0106, time: 43.757706]
2023-05-09 15:13:53.785: epoch 50:	0.08482273  	0.15508862  	0.15561739  
2023-05-09 15:14:38.846: [iter 51 : loss : 1.0269 = 0.0868 + 0.9292 + 0.0108, time: 45.053955]
2023-05-09 15:14:39.436: epoch 51:	0.08468845  	0.15478432  	0.15543631  
2023-05-09 15:15:25.358: [iter 52 : loss : 1.0311 = 0.0847 + 0.9354 + 0.0110, time: 45.912909]
2023-05-09 15:15:25.790: epoch 52:	0.08440910  	0.15399778  	0.15447038  
2023-05-09 15:16:12.099: [iter 53 : loss : 1.0221 = 0.0824 + 0.9285 + 0.0112, time: 46.300281]
2023-05-09 15:16:12.536: epoch 53:	0.08431780  	0.15355353  	0.15429884  
2023-05-09 15:17:00.482: [iter 54 : loss : 1.0259 = 0.0800 + 0.9345 + 0.0114, time: 47.938832]
2023-05-09 15:17:00.930: epoch 54:	0.08372692  	0.15218388  	0.15299115  
2023-05-09 15:17:49.823: [iter 55 : loss : 1.0179 = 0.0783 + 0.9280 + 0.0116, time: 48.885633]
2023-05-09 15:17:50.718: epoch 55:	0.08380207  	0.15213647  	0.15306067  
2023-05-09 15:18:40.225: [iter 56 : loss : 1.0222 = 0.0766 + 0.9338 + 0.0118, time: 49.500147]
2023-05-09 15:18:40.660: epoch 56:	0.08331867  	0.15116467  	0.15207300  
2023-05-09 15:18:40.660: Early stopping is trigger at epoch: 56
2023-05-09 15:18:40.660: best_result@epoch 31:

2023-05-09 15:18:40.660: 		0.0886      	0.1674      	0.1662      
2023-05-09 15:35:03.016: my pid: 5392
2023-05-09 15:35:03.016: model: model.general_recommender.SGL
2023-05-09 15:35:03.016: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 15:35:03.016: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 15:35:08.275: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 15:35:54.120: [iter 1 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 45.835021]
2023-05-09 15:35:54.893: epoch 1:	0.00316393  	0.00739141  	0.00599332  
2023-05-09 15:35:54.893: Find a better model.
2023-05-09 15:36:40.614: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 45.705769]
2023-05-09 15:36:41.379: epoch 2:	0.00297592  	0.00578074  	0.00514348  
2023-05-09 15:37:22.859: [iter 3 : loss : 1.6051 = 0.6930 + 0.9121 + 0.0000, time: 41.474080]
2023-05-09 15:37:23.273: epoch 3:	0.00562415  	0.01210201  	0.01040120  
2023-05-09 15:37:23.273: Find a better model.
2023-05-09 15:38:01.903: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 38.624585]
2023-05-09 15:38:02.366: epoch 4:	0.00391597  	0.00706186  	0.00674280  
2023-05-09 15:38:52.642: [iter 5 : loss : 1.6050 = 0.6929 + 0.9121 + 0.0000, time: 50.261717]
2023-05-09 15:38:53.398: epoch 5:	0.00847658  	0.01682030  	0.01507137  
2023-05-09 15:38:53.398: Find a better model.
2023-05-09 15:39:44.800: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 51.388382]
2023-05-09 15:39:45.533: epoch 6:	0.00579605  	0.01105067  	0.01045881  
2023-05-09 15:40:37.734: [iter 7 : loss : 1.6051 = 0.6928 + 0.9123 + 0.0000, time: 52.187964]
2023-05-09 15:40:38.538: epoch 7:	0.01077575  	0.02112691  	0.01937929  
2023-05-09 15:40:38.538: Find a better model.
2023-05-09 15:41:31.921: [iter 8 : loss : 1.6052 = 0.6928 + 0.9124 + 0.0000, time: 53.369527]
2023-05-09 15:41:32.647: epoch 8:	0.00756873  	0.01344812  	0.01305157  
2023-05-09 15:42:26.973: [iter 9 : loss : 1.6049 = 0.6926 + 0.9123 + 0.0000, time: 54.313711]
2023-05-09 15:42:27.545: epoch 9:	0.01357986  	0.02518886  	0.02356194  
2023-05-09 15:42:27.545: Find a better model.
2023-05-09 15:43:23.467: [iter 10 : loss : 1.6051 = 0.6925 + 0.9126 + 0.0000, time: 55.914701]
2023-05-09 15:43:23.951: epoch 10:	0.00969600  	0.01712159  	0.01677418  
2023-05-09 15:44:19.040: [iter 11 : loss : 1.6045 = 0.6922 + 0.9123 + 0.0000, time: 55.083910]
2023-05-09 15:44:19.606: epoch 11:	0.01662575  	0.03214090  	0.03004079  
2023-05-09 15:44:19.606: Find a better model.
2023-05-09 15:45:14.651: [iter 12 : loss : 1.6049 = 0.6920 + 0.9129 + 0.0000, time: 55.039293]
2023-05-09 15:45:15.151: epoch 12:	0.01280631  	0.02367006  	0.02293652  
2023-05-09 15:46:10.036: [iter 13 : loss : 1.6040 = 0.6915 + 0.9125 + 0.0000, time: 54.877931]
2023-05-09 15:46:10.575: epoch 13:	0.02155714  	0.04315223  	0.04035281  
2023-05-09 15:46:10.575: Find a better model.
2023-05-09 15:47:05.608: [iter 14 : loss : 1.6045 = 0.6910 + 0.9134 + 0.0000, time: 55.025066]
2023-05-09 15:47:06.100: epoch 14:	0.01812987  	0.03610299  	0.03478304  
2023-05-09 15:48:01.093: [iter 15 : loss : 1.6027 = 0.6899 + 0.9127 + 0.0000, time: 54.987290]
2023-05-09 15:48:01.620: epoch 15:	0.02998532  	0.06107019  	0.05844121  
2023-05-09 15:48:01.620: Find a better model.
2023-05-09 15:48:56.620: [iter 16 : loss : 1.6029 = 0.6886 + 0.9143 + 0.0001, time: 54.991759]
2023-05-09 15:48:57.109: epoch 16:	0.02991006  	0.06129559  	0.05936990  
2023-05-09 15:48:57.109: Find a better model.
2023-05-09 15:49:52.478: [iter 17 : loss : 1.5987 = 0.6854 + 0.9133 + 0.0001, time: 55.360365]
2023-05-09 15:49:52.962: epoch 17:	0.04403682  	0.08977586  	0.08707244  
2023-05-09 15:49:52.962: Find a better model.
2023-05-09 15:50:48.053: [iter 18 : loss : 1.5967 = 0.6800 + 0.9166 + 0.0001, time: 55.083731]
2023-05-09 15:50:48.574: epoch 18:	0.05075143  	0.10123504  	0.10031848  
2023-05-09 15:50:48.574: Find a better model.
2023-05-09 15:51:43.579: [iter 19 : loss : 1.5824 = 0.6667 + 0.9155 + 0.0002, time: 54.997143]
2023-05-09 15:51:44.060: epoch 19:	0.06534024  	0.12623504  	0.12613241  
2023-05-09 15:51:44.060: Find a better model.
2023-05-09 15:52:39.175: [iter 20 : loss : 1.5656 = 0.6419 + 0.9233 + 0.0004, time: 55.106464]
2023-05-09 15:52:39.681: epoch 20:	0.07316127  	0.13900125  	0.13982971  
2023-05-09 15:52:39.681: Find a better model.
2023-05-09 15:53:34.538: [iter 21 : loss : 1.5198 = 0.5960 + 0.9231 + 0.0007, time: 54.849560]
2023-05-09 15:53:35.034: epoch 21:	0.07953720  	0.14927238  	0.14982593  
2023-05-09 15:53:35.034: Find a better model.
2023-05-09 15:54:30.255: [iter 22 : loss : 1.4775 = 0.5401 + 0.9364 + 0.0011, time: 55.214340]
2023-05-09 15:54:30.754: epoch 22:	0.08213695  	0.15502290  	0.15522088  
2023-05-09 15:54:30.755: Find a better model.
2023-05-09 15:55:25.819: [iter 23 : loss : 1.4113 = 0.4756 + 0.9341 + 0.0016, time: 55.054940]
2023-05-09 15:55:26.376: epoch 23:	0.08408681  	0.15862577  	0.15842152  
2023-05-09 15:55:26.376: Find a better model.
2023-05-09 15:56:21.565: [iter 24 : loss : 1.3718 = 0.4220 + 0.9477 + 0.0021, time: 55.182532]
2023-05-09 15:56:22.091: epoch 24:	0.08520401  	0.16158101  	0.16092546  
2023-05-09 15:56:22.091: Find a better model.
2023-05-09 15:57:17.618: [iter 25 : loss : 1.3145 = 0.3720 + 0.9399 + 0.0026, time: 55.521679]
2023-05-09 15:57:18.096: epoch 25:	0.08622458  	0.16323091  	0.16215351  
2023-05-09 15:57:18.096: Find a better model.
2023-05-09 15:58:13.413: [iter 26 : loss : 1.2885 = 0.3337 + 0.9518 + 0.0031, time: 55.309999]
2023-05-09 15:58:13.884: epoch 26:	0.08668663  	0.16464141  	0.16330017  
2023-05-09 15:58:13.884: Find a better model.
2023-05-09 15:59:09.085: [iter 27 : loss : 1.2436 = 0.2989 + 0.9412 + 0.0036, time: 55.193552]
2023-05-09 15:59:09.603: epoch 27:	0.08721303  	0.16543171  	0.16394573  
2023-05-09 15:59:09.603: Find a better model.
2023-05-09 16:00:05.303: [iter 28 : loss : 1.2280 = 0.2721 + 0.9519 + 0.0040, time: 55.693717]
2023-05-09 16:00:05.772: epoch 28:	0.08723457  	0.16573061  	0.16411859  
2023-05-09 16:00:05.773: Find a better model.
2023-05-09 16:01:00.963: [iter 29 : loss : 1.1933 = 0.2484 + 0.9404 + 0.0044, time: 55.183227]
2023-05-09 16:01:01.501: epoch 29:	0.08777711  	0.16635486  	0.16455624  
2023-05-09 16:01:01.501: Find a better model.
2023-05-09 16:01:59.112: [iter 30 : loss : 1.1840 = 0.2291 + 0.9501 + 0.0049, time: 57.603919]
2023-05-09 16:01:59.633: epoch 30:	0.08766432  	0.16593480  	0.16421741  
2023-05-09 16:02:54.725: [iter 31 : loss : 1.1552 = 0.2112 + 0.9388 + 0.0053, time: 55.085739]
2023-05-09 16:02:55.220: epoch 31:	0.08815849  	0.16652332  	0.16454646  
2023-05-09 16:02:55.220: Find a better model.
2023-05-09 16:03:50.557: [iter 32 : loss : 1.1510 = 0.1976 + 0.9478 + 0.0056, time: 55.330877]
2023-05-09 16:03:51.053: epoch 32:	0.08777712  	0.16534428  	0.16371968  
2023-05-09 16:04:46.516: [iter 33 : loss : 1.1269 = 0.1839 + 0.9370 + 0.0060, time: 55.454569]
2023-05-09 16:04:47.002: epoch 33:	0.08799198  	0.16528893  	0.16367961  
2023-05-09 16:05:42.634: [iter 34 : loss : 1.1255 = 0.1737 + 0.9455 + 0.0064, time: 55.625497]
2023-05-09 16:05:43.112: epoch 34:	0.08726688  	0.16409807  	0.16259111  
2023-05-09 16:06:38.712: [iter 35 : loss : 1.1050 = 0.1629 + 0.9354 + 0.0067, time: 55.594864]
2023-05-09 16:06:39.196: epoch 35:	0.08732057  	0.16372383  	0.16229716  
2023-05-09 16:07:34.583: [iter 36 : loss : 1.1053 = 0.1549 + 0.9434 + 0.0070, time: 55.380074]
2023-05-09 16:07:35.070: epoch 36:	0.08694459  	0.16252075  	0.16142014  
2023-05-09 16:08:30.375: [iter 37 : loss : 1.0875 = 0.1465 + 0.9337 + 0.0073, time: 55.297444]
2023-05-09 16:08:30.853: epoch 37:	0.08709499  	0.16277772  	0.16152163  
2023-05-09 16:10:03.541: my pid: 9312
2023-05-09 16:10:03.541: model: model.general_recommender.SGL
2023-05-09 16:10:03.541: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 16:10:03.541: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 16:10:07.854: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 16:11:00.540: [iter 1 : loss : 1.6068 = 0.6931 + 0.9137 + 0.0000, time: 52.685590]
2023-05-09 16:11:00.962: epoch 1:	0.00358829  	0.00821681  	0.00678928  
2023-05-09 16:11:00.962: Find a better model.
2023-05-09 16:11:52.922: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 51.953714]
2023-05-09 16:11:53.386: epoch 2:	0.00407174  	0.00846781  	0.00762471  
2023-05-09 16:11:53.386: Find a better model.
2023-05-09 16:12:44.981: [iter 3 : loss : 1.6043 = 0.6930 + 0.9113 + 0.0000, time: 51.586212]
2023-05-09 16:12:45.433: epoch 3:	0.00706914  	0.01567437  	0.01359049  
2023-05-09 16:12:45.433: Find a better model.
2023-05-09 16:13:37.295: [iter 4 : loss : 1.6051 = 0.6930 + 0.9121 + 0.0000, time: 51.855053]
2023-05-09 16:13:37.719: epoch 4:	0.00567787  	0.01156903  	0.01042680  
2023-05-09 16:14:29.767: [iter 5 : loss : 1.6040 = 0.6929 + 0.9111 + 0.0000, time: 52.041072]
2023-05-09 16:14:30.198: epoch 5:	0.00991625  	0.02048692  	0.01837350  
2023-05-09 16:14:30.198: Find a better model.
2023-05-09 16:15:22.288: [iter 6 : loss : 1.6049 = 0.6929 + 0.9120 + 0.0000, time: 52.083754]
2023-05-09 16:15:22.717: epoch 6:	0.00742369  	0.01400409  	0.01345586  
2023-05-09 16:16:18.010: [iter 7 : loss : 1.6040 = 0.6928 + 0.9112 + 0.0000, time: 55.286303]
2023-05-09 16:16:18.497: epoch 7:	0.01246789  	0.02391982  	0.02227901  
2023-05-09 16:16:18.498: Find a better model.
2023-05-09 16:17:12.543: [iter 8 : loss : 1.6047 = 0.6927 + 0.9120 + 0.0000, time: 54.037285]
2023-05-09 16:17:13.001: epoch 8:	0.00912121  	0.01769290  	0.01662621  
2023-05-09 16:18:06.787: [iter 9 : loss : 1.6038 = 0.6925 + 0.9112 + 0.0000, time: 53.776660]
2023-05-09 16:18:07.214: epoch 9:	0.01508939  	0.02942494  	0.02761565  
2023-05-09 16:18:07.214: Find a better model.
2023-05-09 16:19:00.403: [iter 10 : loss : 1.6046 = 0.6924 + 0.9122 + 0.0000, time: 53.181421]
2023-05-09 16:19:00.836: epoch 10:	0.01118402  	0.02104755  	0.02037954  
2023-05-09 16:19:54.326: [iter 11 : loss : 1.6032 = 0.6921 + 0.9110 + 0.0000, time: 53.481546]
2023-05-09 16:19:54.752: epoch 11:	0.01875841  	0.03686730  	0.03426979  
2023-05-09 16:19:54.752: Find a better model.
2023-05-09 16:20:48.757: [iter 12 : loss : 1.6043 = 0.6919 + 0.9124 + 0.0000, time: 53.998581]
2023-05-09 16:20:49.189: epoch 12:	0.01502491  	0.02924177  	0.02778969  
2023-05-09 16:21:43.452: [iter 13 : loss : 1.6026 = 0.6914 + 0.9112 + 0.0000, time: 54.255912]
2023-05-09 16:21:43.880: epoch 13:	0.02347493  	0.04690177  	0.04339563  
2023-05-09 16:21:43.880: Find a better model.
2023-05-09 16:22:38.950: [iter 14 : loss : 1.6038 = 0.6909 + 0.9129 + 0.0000, time: 55.062088]
2023-05-09 16:22:39.439: epoch 14:	0.02063319  	0.04185713  	0.03939497  
2023-05-09 16:23:35.457: [iter 15 : loss : 1.6010 = 0.6897 + 0.9113 + 0.0000, time: 56.011228]
2023-05-09 16:23:35.909: epoch 15:	0.03172560  	0.06520168  	0.06135582  
2023-05-09 16:23:35.909: Find a better model.
2023-05-09 16:24:31.818: [iter 16 : loss : 1.6020 = 0.6881 + 0.9138 + 0.0001, time: 55.901945]
2023-05-09 16:24:32.376: epoch 16:	0.03225197  	0.06634994  	0.06316419  
2023-05-09 16:24:32.376: Find a better model.
2023-05-09 16:25:28.564: [iter 17 : loss : 1.5962 = 0.6844 + 0.9117 + 0.0001, time: 56.178726]
2023-05-09 16:25:29.039: epoch 17:	0.04537978  	0.09299581  	0.08921482  
2023-05-09 16:25:29.039: Find a better model.
2023-05-09 16:26:25.237: [iter 18 : loss : 1.5943 = 0.6777 + 0.9165 + 0.0001, time: 56.188270]
2023-05-09 16:26:25.741: epoch 18:	0.05276040  	0.10579234  	0.10359821  
2023-05-09 16:26:25.741: Find a better model.
2023-05-09 16:27:21.824: [iter 19 : loss : 1.5763 = 0.6621 + 0.9140 + 0.0002, time: 56.075936]
2023-05-09 16:27:22.342: epoch 19:	0.06541548  	0.12717113  	0.12624747  
2023-05-09 16:27:22.343: Find a better model.
2023-05-09 16:28:18.377: [iter 20 : loss : 1.5585 = 0.6341 + 0.9239 + 0.0004, time: 56.003728]
2023-05-09 16:28:18.843: epoch 20:	0.07263479  	0.13854235  	0.13910167  
2023-05-09 16:28:18.843: Find a better model.
2023-05-09 16:29:14.551: [iter 21 : loss : 1.5091 = 0.5868 + 0.9215 + 0.0008, time: 55.698749]
2023-05-09 16:29:15.036: epoch 21:	0.07808152  	0.14794964  	0.14809714  
2023-05-09 16:29:15.036: Find a better model.
2023-05-09 16:30:11.154: [iter 22 : loss : 1.4691 = 0.5316 + 0.9363 + 0.0012, time: 56.110487]
2023-05-09 16:30:11.661: epoch 22:	0.08123993  	0.15359767  	0.15379226  
2023-05-09 16:30:11.662: Find a better model.
2023-05-09 16:31:07.585: [iter 23 : loss : 1.4036 = 0.4703 + 0.9316 + 0.0017, time: 55.914245]
2023-05-09 16:31:08.053: epoch 23:	0.08361419  	0.15735959  	0.15733452  
2023-05-09 16:31:08.053: Find a better model.
2023-05-09 16:32:04.236: [iter 24 : loss : 1.3670 = 0.4186 + 0.9463 + 0.0022, time: 56.177120]
2023-05-09 16:32:04.722: epoch 24:	0.08511285  	0.16040701  	0.16012467  
2023-05-09 16:32:04.722: Find a better model.
2023-05-09 16:33:00.971: [iter 25 : loss : 1.3104 = 0.3706 + 0.9371 + 0.0027, time: 56.238776]
2023-05-09 16:33:01.506: epoch 25:	0.08631611  	0.16251810  	0.16182467  
2023-05-09 16:33:01.506: Find a better model.
2023-05-09 16:33:57.459: [iter 26 : loss : 1.2859 = 0.3328 + 0.9500 + 0.0032, time: 55.945636]
2023-05-09 16:33:57.941: epoch 26:	0.08673519  	0.16317557  	0.16254376  
2023-05-09 16:33:57.941: Find a better model.
2023-05-09 16:34:54.265: [iter 27 : loss : 1.2412 = 0.2991 + 0.9385 + 0.0036, time: 56.315842]
2023-05-09 16:34:54.752: epoch 27:	0.08735292  	0.16443180  	0.16337533  
2023-05-09 16:34:54.753: Find a better model.
2023-05-09 16:35:50.898: [iter 28 : loss : 1.2268 = 0.2725 + 0.9502 + 0.0041, time: 56.139125]
2023-05-09 16:35:51.451: epoch 28:	0.08725078  	0.16419306  	0.16345228  
2023-05-09 16:36:47.605: [iter 29 : loss : 1.1914 = 0.2489 + 0.9379 + 0.0045, time: 56.146407]
2023-05-09 16:36:48.076: epoch 29:	0.08763226  	0.16430750  	0.16384424  
2023-05-09 16:37:44.371: [iter 30 : loss : 1.1829 = 0.2296 + 0.9483 + 0.0049, time: 56.287728]
2023-05-09 16:37:44.850: epoch 30:	0.08736362  	0.16378079  	0.16348226  
2023-05-09 16:38:40.854: [iter 31 : loss : 1.1538 = 0.2120 + 0.9364 + 0.0053, time: 55.996734]
2023-05-09 16:38:41.401: epoch 31:	0.08773959  	0.16398774  	0.16361763  
2023-05-09 16:39:37.495: [iter 32 : loss : 1.1502 = 0.1983 + 0.9462 + 0.0057, time: 56.086390]
2023-05-09 16:39:37.989: epoch 32:	0.08734749  	0.16317189  	0.16301331  
2023-05-09 16:40:33.662: [iter 33 : loss : 1.1254 = 0.1846 + 0.9348 + 0.0061, time: 55.657665]
2023-05-09 16:40:34.171: epoch 33:	0.08765905  	0.16420427  	0.16347130  
2023-05-09 16:41:14.123: [iter 34 : loss : 1.1246 = 0.1742 + 0.9439 + 0.0064, time: 39.944033]
2023-05-09 16:41:14.536: epoch 34:	0.08708432  	0.16303363  	0.16219835  
2023-05-09 16:41:54.153: [iter 35 : loss : 1.1036 = 0.1636 + 0.9332 + 0.0068, time: 39.611579]
2023-05-09 16:41:54.566: epoch 35:	0.08744428  	0.16308758  	0.16238442  
2023-05-09 16:42:34.484: [iter 36 : loss : 1.1044 = 0.1553 + 0.9420 + 0.0071, time: 39.878061]
2023-05-09 16:42:34.884: epoch 36:	0.08689634  	0.16161439  	0.16128509  
2023-05-09 16:43:14.578: [iter 37 : loss : 1.0858 = 0.1468 + 0.9315 + 0.0074, time: 39.686273]
2023-05-09 16:43:14.970: epoch 37:	0.08703063  	0.16180925  	0.16154705  
2023-05-09 16:43:54.891: [iter 38 : loss : 1.0878 = 0.1400 + 0.9400 + 0.0077, time: 39.915803]
2023-05-09 16:43:55.318: epoch 38:	0.08655256  	0.16061606  	0.16033787  
2023-05-09 16:44:34.952: [iter 39 : loss : 1.0718 = 0.1338 + 0.9301 + 0.0080, time: 39.622637]
2023-05-09 16:44:35.385: epoch 39:	0.08660088  	0.16005106  	0.16012640  
2023-05-09 16:45:15.087: [iter 40 : loss : 1.0746 = 0.1281 + 0.9382 + 0.0083, time: 39.696054]
2023-05-09 16:45:15.504: epoch 40:	0.08592404  	0.15889430  	0.15899551  
2023-05-09 16:45:55.396: [iter 41 : loss : 1.0595 = 0.1222 + 0.9287 + 0.0086, time: 39.885520]
2023-05-09 16:45:55.792: epoch 41:	0.08605831  	0.15900198  	0.15897608  
2023-05-09 16:46:35.376: [iter 42 : loss : 1.0632 = 0.1176 + 0.9368 + 0.0088, time: 39.575772]
2023-05-09 16:46:35.770: epoch 42:	0.08540832  	0.15740217  	0.15753895  
2023-05-09 16:47:15.696: [iter 43 : loss : 1.0494 = 0.1126 + 0.9277 + 0.0091, time: 39.919913]
2023-05-09 16:47:16.096: epoch 43:	0.08555336  	0.15718444  	0.15756372  
2023-05-09 16:47:56.018: [iter 44 : loss : 1.0536 = 0.1087 + 0.9355 + 0.0094, time: 39.916391]
2023-05-09 16:47:56.443: epoch 44:	0.08493561  	0.15607195  	0.15643220  
2023-05-09 16:48:36.315: [iter 45 : loss : 1.0416 = 0.1054 + 0.9266 + 0.0096, time: 39.866597]
2023-05-09 16:48:36.714: epoch 45:	0.08521499  	0.15621012  	0.15636636  
2023-05-09 16:49:16.570: [iter 46 : loss : 1.0459 = 0.1016 + 0.9344 + 0.0098, time: 39.848991]
2023-05-09 16:49:16.965: epoch 46:	0.08448980  	0.15473545  	0.15517102  
2023-05-09 16:49:56.692: [iter 47 : loss : 1.0340 = 0.0982 + 0.9257 + 0.0101, time: 39.721366]
2023-05-09 16:49:57.085: epoch 47:	0.08481210  	0.15494131  	0.15537098  
2023-05-09 16:50:37.021: [iter 48 : loss : 1.0387 = 0.0951 + 0.9333 + 0.0103, time: 39.930428]
2023-05-09 16:50:37.449: epoch 48:	0.08410317  	0.15329224  	0.15397955  
2023-05-09 16:51:17.480: [iter 49 : loss : 1.0277 = 0.0923 + 0.9249 + 0.0105, time: 40.024042]
2023-05-09 16:51:17.878: epoch 49:	0.08425353  	0.15303761  	0.15413374  
2023-05-09 16:51:57.906: [iter 50 : loss : 1.0329 = 0.0899 + 0.9322 + 0.0107, time: 40.021095]
2023-05-09 16:51:58.332: epoch 50:	0.08356060  	0.15167564  	0.15276287  
2023-05-09 16:52:37.987: [iter 51 : loss : 1.0223 = 0.0871 + 0.9243 + 0.0109, time: 39.646624]
2023-05-09 16:52:38.412: epoch 51:	0.08356060  	0.15112540  	0.15262370  
2023-05-09 16:53:18.090: [iter 52 : loss : 1.0277 = 0.0849 + 0.9316 + 0.0111, time: 39.671691]
2023-05-09 16:53:18.503: epoch 52:	0.08300195  	0.14962973  	0.15135856  
2023-05-09 16:53:18.504: Early stopping is trigger at epoch: 52
2023-05-09 16:53:18.504: best_result@epoch 27:

2023-05-09 16:53:18.504: 		0.0874      	0.1644      	0.1634      
2023-05-09 17:09:11.648: my pid: 16332
2023-05-09 17:09:11.648: model: model.general_recommender.SGL
2023-05-09 17:09:11.648: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-09 17:09:11.649: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-09 17:09:16.791: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-09 17:09:52.698: [iter 1 : loss : 1.6101 = 0.6931 + 0.9170 + 0.0000, time: 35.905711]
2023-05-09 17:09:53.183: epoch 1:	0.00304576  	0.00706498  	0.00557860  
2023-05-09 17:09:53.183: Find a better model.
2023-05-09 17:10:28.261: [iter 2 : loss : 1.6104 = 0.6931 + 0.9173 + 0.0000, time: 35.070337]
2023-05-09 17:10:28.703: epoch 2:	0.00193382  	0.00368678  	0.00316649  
2023-05-09 17:11:02.784: [iter 3 : loss : 1.6102 = 0.6930 + 0.9172 + 0.0000, time: 34.072002]
2023-05-09 17:11:03.248: epoch 3:	0.00385151  	0.00811821  	0.00680367  
2023-05-09 17:11:03.248: Find a better model.
2023-05-09 17:11:38.826: [iter 4 : loss : 1.6113 = 0.6930 + 0.9183 + 0.0000, time: 35.571790]
2023-05-09 17:11:39.295: epoch 4:	0.00233670  	0.00418319  	0.00377008  
2023-05-09 17:12:20.631: [iter 5 : loss : 1.6112 = 0.6929 + 0.9183 + 0.0000, time: 41.330443]
2023-05-09 17:12:21.096: epoch 5:	0.00448536  	0.00872825  	0.00792883  
2023-05-09 17:12:21.096: Find a better model.
2023-05-09 17:13:06.844: [iter 6 : loss : 1.6120 = 0.6929 + 0.9192 + 0.0000, time: 45.740908]
2023-05-09 17:13:07.331: epoch 6:	0.00295981  	0.00449792  	0.00448190  
2023-05-09 17:13:53.655: [iter 7 : loss : 1.6121 = 0.6927 + 0.9193 + 0.0000, time: 46.314212]
2023-05-09 17:13:54.416: epoch 7:	0.00536631  	0.00956789  	0.00899821  
2023-05-09 17:13:54.416: Find a better model.
2023-05-09 17:14:37.252: [iter 8 : loss : 1.6127 = 0.6927 + 0.9200 + 0.0000, time: 42.828457]
2023-05-09 17:14:38.046: epoch 8:	0.00386762  	0.00569339  	0.00587948  
2023-05-09 17:15:16.825: [iter 9 : loss : 1.6127 = 0.6924 + 0.9202 + 0.0000, time: 38.771628]
2023-05-09 17:15:17.556: epoch 9:	0.00683278  	0.01229199  	0.01161023  
2023-05-09 17:15:17.556: Find a better model.
2023-05-09 17:15:56.083: [iter 10 : loss : 1.6133 = 0.6923 + 0.9209 + 0.0000, time: 38.510153]
2023-05-09 17:15:56.813: epoch 10:	0.00572622  	0.00970429  	0.00916828  
2023-05-09 17:16:31.701: [iter 11 : loss : 1.6129 = 0.6919 + 0.9210 + 0.0000, time: 34.881746]
2023-05-09 17:16:32.304: epoch 11:	0.01007741  	0.01948094  	0.01773447  
2023-05-09 17:16:32.304: Find a better model.
2023-05-09 17:17:07.215: [iter 12 : loss : 1.6138 = 0.6918 + 0.9220 + 0.0000, time: 34.903127]
2023-05-09 17:17:07.810: epoch 12:	0.00821873  	0.01390471  	0.01401382  
2023-05-09 17:17:42.122: [iter 13 : loss : 1.6132 = 0.6911 + 0.9221 + 0.0000, time: 34.305456]
2023-05-09 17:17:42.536: epoch 13:	0.01428894  	0.02673642  	0.02576211  
2023-05-09 17:17:42.536: Find a better model.
2023-05-09 17:18:23.198: [iter 14 : loss : 1.6141 = 0.6907 + 0.9233 + 0.0001, time: 40.654713]
2023-05-09 17:18:23.630: epoch 14:	0.01380008  	0.02385727  	0.02436841  
2023-05-09 17:19:08.911: [iter 15 : loss : 1.6128 = 0.6894 + 0.9233 + 0.0001, time: 45.273276]
2023-05-09 17:19:09.371: epoch 15:	0.02297526  	0.04315623  	0.04214933  
2023-05-09 17:19:09.371: Find a better model.
2023-05-09 17:19:55.741: [iter 16 : loss : 1.6136 = 0.6883 + 0.9252 + 0.0001, time: 46.360889]
2023-05-09 17:19:56.500: epoch 16:	0.02509174  	0.04567591  	0.04684234  
2023-05-09 17:19:56.501: Find a better model.
2023-05-09 17:20:39.845: [iter 17 : loss : 1.6108 = 0.6854 + 0.9254 + 0.0001, time: 43.330310]
2023-05-09 17:20:40.607: epoch 17:	0.03905759  	0.07289727  	0.07361351  
2023-05-09 17:20:40.607: Find a better model.
2023-05-09 17:21:19.952: [iter 18 : loss : 1.6102 = 0.6815 + 0.9285 + 0.0001, time: 39.336266]
2023-05-09 17:21:20.699: epoch 18:	0.04650253  	0.08597202  	0.08805356  
2023-05-09 17:21:20.699: Find a better model.
2023-05-09 17:21:55.681: [iter 19 : loss : 1.6017 = 0.6723 + 0.9291 + 0.0002, time: 34.976001]
2023-05-09 17:21:56.165: epoch 19:	0.06141920  	0.11335965  	0.11553364  
2023-05-09 17:21:56.165: Find a better model.
2023-05-09 17:22:30.802: [iter 20 : loss : 1.5929 = 0.6571 + 0.9355 + 0.0003, time: 34.629193]
2023-05-09 17:22:31.268: epoch 20:	0.06948172  	0.12758213  	0.13118298  
2023-05-09 17:22:31.268: Find a better model.
2023-05-09 17:23:05.691: [iter 21 : loss : 1.5629 = 0.6251 + 0.9373 + 0.0005, time: 34.414935]
2023-05-09 17:23:06.811: epoch 21:	0.07730264  	0.14173441  	0.14505379  
2023-05-09 17:23:06.811: Find a better model.
2023-05-09 17:23:41.316: [iter 22 : loss : 1.5303 = 0.5805 + 0.9490 + 0.0008, time: 34.496848]
2023-05-09 17:23:41.735: epoch 22:	0.08067596  	0.14951347  	0.15239403  
2023-05-09 17:23:41.736: Find a better model.
2023-05-09 17:24:22.725: [iter 23 : loss : 1.4712 = 0.5190 + 0.9510 + 0.0012, time: 40.982911]
2023-05-09 17:24:23.167: epoch 23:	0.08294269  	0.15389004  	0.15665241  
2023-05-09 17:24:23.168: Find a better model.
2023-05-09 17:25:09.292: [iter 24 : loss : 1.4291 = 0.4626 + 0.9648 + 0.0017, time: 46.117511]
2023-05-09 17:25:09.728: epoch 24:	0.08480126  	0.15832327  	0.16020033  
2023-05-09 17:25:09.728: Find a better model.
2023-05-09 17:25:57.230: [iter 25 : loss : 1.3689 = 0.4063 + 0.9604 + 0.0022, time: 47.487201]
2023-05-09 17:25:57.952: epoch 25:	0.08574134  	0.15998752  	0.16140217  
2023-05-09 17:25:57.952: Find a better model.
2023-05-09 17:26:40.791: [iter 26 : loss : 1.3374 = 0.3622 + 0.9725 + 0.0027, time: 42.826789]
2023-05-09 17:26:41.549: epoch 26:	0.08665447  	0.16221248  	0.16290092  
2023-05-09 17:26:41.550: Find a better model.
2023-05-09 17:27:20.148: [iter 27 : loss : 1.2882 = 0.3221 + 0.9629 + 0.0032, time: 38.589506]
2023-05-09 17:27:20.854: epoch 27:	0.08695529  	0.16298562  	0.16349924  
2023-05-09 17:27:20.854: Find a better model.
2023-05-09 17:27:56.060: [iter 28 : loss : 1.2685 = 0.2912 + 0.9736 + 0.0036, time: 35.200709]
2023-05-09 17:27:56.461: epoch 28:	0.08701442  	0.16302615  	0.16355182  
2023-05-09 17:27:56.461: Find a better model.
2023-05-09 17:28:31.792: [iter 29 : loss : 1.2307 = 0.2644 + 0.9622 + 0.0041, time: 35.322983]
2023-05-09 17:28:32.318: epoch 29:	0.08727226  	0.16376366  	0.16388065  
2023-05-09 17:28:32.319: Find a better model.
2023-05-09 17:29:06.799: [iter 30 : loss : 1.2191 = 0.2427 + 0.9718 + 0.0045, time: 34.472774]
2023-05-09 17:29:07.252: epoch 30:	0.08719168  	0.16400672  	0.16395997  
2023-05-09 17:29:07.252: Find a better model.
2023-05-09 17:29:43.940: [iter 31 : loss : 1.1880 = 0.2229 + 0.9602 + 0.0049, time: 36.679371]
2023-05-09 17:29:44.381: epoch 31:	0.08738507  	0.16435367  	0.16401853  
2023-05-09 17:29:44.381: Find a better model.
2023-05-09 17:30:27.047: [iter 32 : loss : 1.1821 = 0.2076 + 0.9693 + 0.0053, time: 42.656277]
2023-05-09 17:30:30.068: epoch 32:	0.08714338  	0.16395624  	0.16373932  
2023-05-09 17:31:17.074: [iter 33 : loss : 1.1562 = 0.1925 + 0.9580 + 0.0057, time: 46.998630]
2023-05-09 17:31:17.511: epoch 33:	0.08730448  	0.16380247  	0.16370127  
2023-05-09 17:32:02.997: [iter 34 : loss : 1.1539 = 0.1813 + 0.9666 + 0.0060, time: 45.478665]
2023-05-09 17:32:03.741: epoch 34:	0.08699300  	0.16343306  	0.16307096  
2023-05-09 17:32:46.423: [iter 35 : loss : 1.1318 = 0.1694 + 0.9560 + 0.0064, time: 42.673200]
2023-05-09 17:32:47.189: epoch 35:	0.08721861  	0.16365018  	0.16331896  
2023-05-09 17:33:24.978: [iter 36 : loss : 1.1317 = 0.1606 + 0.9644 + 0.0067, time: 37.780010]
2023-05-09 17:33:25.705: epoch 36:	0.08674053  	0.16253959  	0.16251653  
2023-05-09 17:34:00.731: [iter 37 : loss : 1.1125 = 0.1516 + 0.9539 + 0.0070, time: 35.018855]
2023-05-09 17:34:01.318: epoch 37:	0.08691779  	0.16286686  	0.16271682  
2023-05-09 17:34:36.015: [iter 38 : loss : 1.1135 = 0.1443 + 0.9619 + 0.0074, time: 34.689021]
2023-05-09 17:34:36.968: epoch 38:	0.08653101  	0.16164267  	0.16187119  
2023-05-09 17:35:11.526: [iter 39 : loss : 1.0975 = 0.1377 + 0.9522 + 0.0077, time: 34.523427]
2023-05-09 17:35:11.932: epoch 39:	0.08644508  	0.16110706  	0.16155513  
2023-05-09 17:35:54.585: [iter 40 : loss : 1.0998 = 0.1320 + 0.9598 + 0.0079, time: 42.646951]
2023-05-09 17:35:55.564: epoch 40:	0.08613349  	0.16032599  	0.16055021  
2023-05-09 17:36:43.236: [iter 41 : loss : 1.0847 = 0.1260 + 0.9505 + 0.0082, time: 47.664898]
2023-05-09 17:36:43.718: epoch 41:	0.08632690  	0.16055030  	0.16050370  
2023-05-09 17:37:28.223: [iter 42 : loss : 1.0875 = 0.1208 + 0.9582 + 0.0085, time: 44.497585]
2023-05-09 17:37:28.962: epoch 42:	0.08583271  	0.15942709  	0.15932699  
2023-05-09 17:38:08.088: [iter 43 : loss : 1.0738 = 0.1158 + 0.9492 + 0.0088, time: 39.110612]
2023-05-09 17:38:08.831: epoch 43:	0.08599394  	0.15932719  	0.15929951  
2023-05-09 17:38:44.491: [iter 44 : loss : 1.0776 = 0.1119 + 0.9567 + 0.0090, time: 35.653809]
2023-05-09 17:38:44.895: epoch 44:	0.08563935  	0.15865690  	0.15859193  
2023-05-09 17:39:20.338: [iter 45 : loss : 1.0658 = 0.1084 + 0.9481 + 0.0093, time: 35.435711]
2023-05-09 17:39:20.751: epoch 45:	0.08552121  	0.15829414  	0.15829888  
2023-05-09 17:39:55.126: [iter 46 : loss : 1.0694 = 0.1045 + 0.9554 + 0.0095, time: 34.369068]
2023-05-09 17:39:55.560: epoch 46:	0.08512905  	0.15731341  	0.15737964  
2023-05-09 17:40:36.467: [iter 47 : loss : 1.0576 = 0.1009 + 0.9470 + 0.0097, time: 40.898433]
2023-05-09 17:40:36.875: epoch 47:	0.08524720  	0.15703107  	0.15737739  
2023-05-09 17:41:24.347: [iter 48 : loss : 1.0614 = 0.0974 + 0.9540 + 0.0100, time: 47.464418]
2023-05-09 17:41:24.785: epoch 48:	0.08475306  	0.15529637  	0.15618598  
2023-05-09 17:42:09.292: [iter 49 : loss : 1.0506 = 0.0944 + 0.9460 + 0.0102, time: 44.498458]
2023-05-09 17:42:10.060: epoch 49:	0.08486044  	0.15549403  	0.15600811  
2023-05-09 17:42:49.088: [iter 50 : loss : 1.0553 = 0.0921 + 0.9528 + 0.0104, time: 39.018634]
2023-05-09 17:42:49.826: epoch 50:	0.08450595  	0.15469354  	0.15516850  
2023-05-09 17:43:25.594: [iter 51 : loss : 1.0452 = 0.0894 + 0.9452 + 0.0106, time: 35.761445]
2023-05-09 17:43:26.042: epoch 51:	0.08451136  	0.15455696  	0.15501033  
2023-05-09 17:44:01.977: [iter 52 : loss : 1.0502 = 0.0871 + 0.9522 + 0.0108, time: 35.928315]
2023-05-09 17:44:02.399: epoch 52:	0.08408159  	0.15384373  	0.15413210  
2023-05-09 17:44:37.295: [iter 53 : loss : 1.0401 = 0.0847 + 0.9444 + 0.0110, time: 34.889865]
2023-05-09 17:44:37.750: epoch 53:	0.08412456  	0.15324554  	0.15391651  
2023-05-09 17:45:18.216: [iter 54 : loss : 1.0445 = 0.0822 + 0.9511 + 0.0112, time: 40.457938]
2023-05-09 17:45:18.627: epoch 54:	0.08363570  	0.15247320  	0.15289968  
2023-05-09 17:46:05.339: [iter 55 : loss : 1.0358 = 0.0805 + 0.9439 + 0.0114, time: 46.705779]
2023-05-09 17:46:05.794: epoch 55:	0.08383990  	0.15288343  	0.15286358  
2023-05-09 17:46:51.346: [iter 56 : loss : 1.0408 = 0.0787 + 0.9505 + 0.0116, time: 45.542438]
2023-05-09 17:46:52.114: epoch 56:	0.08317377  	0.15105845  	0.15177797  
2023-05-09 17:46:52.114: Early stopping is trigger at epoch: 56
2023-05-09 17:46:52.114: best_result@epoch 31:

2023-05-09 17:46:52.115: 		0.0874      	0.1644      	0.1640      
2023-05-21 15:48:04.777: my pid: 9552
2023-05-21 15:48:04.777: model: model.general_recommender.SGL
2023-05-21 15:48:04.777: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 15:48:04.777: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 15:48:10.024: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 15:48:53.329: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 43.297509]
2023-05-21 15:48:54.055: epoch 1:	0.00296518  	0.00735567  	0.00575102  
2023-05-21 15:48:54.055: Find a better model.
2023-05-21 15:49:30.194: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 36.131223]
2023-05-21 15:49:30.600: epoch 2:	0.00394282  	0.00915322  	0.00758516  
2023-05-21 15:49:30.601: Find a better model.
2023-05-21 15:50:06.350: [iter 3 : loss : 1.6076 = 0.6930 + 0.9145 + 0.0000, time: 35.742109]
2023-05-21 15:50:06.783: epoch 3:	0.00465725  	0.00979082  	0.00850732  
2023-05-21 15:50:06.783: Find a better model.
2023-05-21 15:50:42.320: [iter 4 : loss : 1.6078 = 0.6930 + 0.9148 + 0.0000, time: 35.530909]
2023-05-21 15:50:42.774: epoch 4:	0.00484526  	0.01059586  	0.00875067  
2023-05-21 15:50:42.774: Find a better model.
2023-05-21 15:51:18.522: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 35.738681]
2023-05-21 15:51:18.977: epoch 5:	0.00561878  	0.01157434  	0.01024149  
2023-05-21 15:51:18.978: Find a better model.
2023-05-21 15:52:03.010: [iter 6 : loss : 1.6082 = 0.6928 + 0.9153 + 0.0000, time: 44.019522]
2023-05-21 15:52:03.653: epoch 6:	0.00639767  	0.01219901  	0.01102735  
2023-05-21 15:52:03.653: Find a better model.
2023-05-21 15:52:46.008: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 42.347950]
2023-05-21 15:52:46.640: epoch 7:	0.00711749  	0.01319541  	0.01213542  
2023-05-21 15:52:46.641: Find a better model.
2023-05-21 15:53:29.359: [iter 8 : loss : 1.6084 = 0.6926 + 0.9158 + 0.0000, time: 42.703967]
2023-05-21 15:53:29.985: epoch 8:	0.00789104  	0.01477515  	0.01373267  
2023-05-21 15:53:29.985: Find a better model.
2023-05-21 15:54:13.909: [iter 9 : loss : 1.6087 = 0.6924 + 0.9162 + 0.0000, time: 43.914953]
2023-05-21 15:54:14.550: epoch 9:	0.00973361  	0.01912601  	0.01729940  
2023-05-21 15:54:14.550: Find a better model.
2023-05-21 15:54:58.401: [iter 10 : loss : 1.6087 = 0.6922 + 0.9164 + 0.0000, time: 43.833482]
2023-05-21 15:54:59.058: epoch 10:	0.01112490  	0.02076957  	0.01930229  
2023-05-21 15:54:59.059: Find a better model.
2023-05-21 15:55:41.728: [iter 11 : loss : 1.6086 = 0.6919 + 0.9166 + 0.0000, time: 42.661765]
2023-05-21 15:55:42.372: epoch 11:	0.01337036  	0.02605434  	0.02441905  
2023-05-21 15:55:42.372: Find a better model.
2023-05-21 15:56:25.378: [iter 12 : loss : 1.6086 = 0.6915 + 0.9171 + 0.0000, time: 42.996987]
2023-05-21 15:56:26.025: epoch 12:	0.01587366  	0.03110991  	0.02961182  
2023-05-21 15:56:26.026: Find a better model.
2023-05-21 15:57:10.235: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 44.195348]
2023-05-21 15:57:10.916: epoch 13:	0.02033234  	0.04108478  	0.03917249  
2023-05-21 15:57:10.916: Find a better model.
2023-05-21 15:57:55.434: [iter 14 : loss : 1.6081 = 0.6898 + 0.9182 + 0.0000, time: 44.510139]
2023-05-21 15:57:56.072: epoch 14:	0.02634345  	0.05275756  	0.05064335  
2023-05-21 15:57:56.072: Find a better model.
2023-05-21 15:58:38.118: [iter 15 : loss : 1.6071 = 0.6880 + 0.9190 + 0.0001, time: 42.037198]
2023-05-21 15:58:38.771: epoch 15:	0.03443813  	0.06791695  	0.06646837  
2023-05-21 15:58:38.771: Find a better model.
2023-05-21 15:59:21.582: [iter 16 : loss : 1.6049 = 0.6846 + 0.9202 + 0.0001, time: 42.801656]
2023-05-21 15:59:22.211: epoch 16:	0.04544431  	0.08887696  	0.08750679  
2023-05-21 15:59:22.211: Find a better model.
2023-05-21 16:00:05.856: [iter 17 : loss : 1.5996 = 0.6775 + 0.9220 + 0.0001, time: 43.637655]
2023-05-21 16:00:06.491: epoch 17:	0.05752486  	0.10973946  	0.10976725  
2023-05-21 16:00:06.491: Find a better model.
2023-05-21 16:00:50.383: [iter 18 : loss : 1.5877 = 0.6625 + 0.9249 + 0.0002, time: 43.883061]
2023-05-21 16:00:51.043: epoch 18:	0.06893391  	0.12978040  	0.13005438  
2023-05-21 16:00:51.043: Find a better model.
2023-05-21 16:01:33.784: [iter 19 : loss : 1.5625 = 0.6327 + 0.9293 + 0.0004, time: 42.734440]
2023-05-21 16:01:34.442: epoch 19:	0.07609942  	0.14317587  	0.14359459  
2023-05-21 16:01:34.442: Find a better model.
2023-05-21 16:02:17.202: [iter 20 : loss : 1.5213 = 0.5851 + 0.9355 + 0.0007, time: 42.753191]
2023-05-21 16:02:17.850: epoch 20:	0.08019251  	0.15150554  	0.15108821  
2023-05-21 16:02:17.850: Find a better model.
2023-05-21 16:03:01.585: [iter 21 : loss : 1.4685 = 0.5248 + 0.9426 + 0.0012, time: 43.728330]
2023-05-21 16:03:02.223: epoch 21:	0.08253985  	0.15565880  	0.15524264  
2023-05-21 16:03:02.223: Find a better model.
2023-05-21 16:03:46.279: [iter 22 : loss : 1.4131 = 0.4630 + 0.9485 + 0.0016, time: 44.043332]
2023-05-21 16:03:46.921: epoch 22:	0.08435543  	0.15986858  	0.15836664  
2023-05-21 16:03:46.921: Find a better model.
2023-05-21 16:04:29.376: [iter 23 : loss : 1.3628 = 0.4080 + 0.9527 + 0.0021, time: 42.441896]
2023-05-21 16:04:30.024: epoch 23:	0.08541901  	0.16256855  	0.16063224  
2023-05-21 16:04:30.024: Find a better model.
2023-05-21 16:05:12.882: [iter 24 : loss : 1.3190 = 0.3615 + 0.9548 + 0.0026, time: 42.844309]
2023-05-21 16:05:13.491: epoch 24:	0.08603677  	0.16395372  	0.16190815  
2023-05-21 16:05:13.491: Find a better model.
2023-05-21 16:05:57.060: [iter 25 : loss : 1.2823 = 0.3236 + 0.9555 + 0.0031, time: 43.558331]
2023-05-21 16:05:57.741: epoch 25:	0.08682097  	0.16586167  	0.16315088  
2023-05-21 16:05:57.742: Find a better model.
2023-05-21 16:06:42.018: [iter 26 : loss : 1.2505 = 0.2914 + 0.9556 + 0.0036, time: 44.266272]
2023-05-21 16:06:42.641: epoch 26:	0.08707888  	0.16596864  	0.16332206  
2023-05-21 16:06:42.641: Find a better model.
2023-05-21 16:07:25.252: [iter 27 : loss : 1.2239 = 0.2649 + 0.9549 + 0.0040, time: 42.605483]
2023-05-21 16:07:25.907: epoch 27:	0.08769665  	0.16689785  	0.16399100  
2023-05-21 16:07:25.907: Find a better model.
2023-05-21 16:08:08.681: [iter 28 : loss : 1.2012 = 0.2425 + 0.9542 + 0.0045, time: 42.766130]
2023-05-21 16:08:09.294: epoch 28:	0.08785783  	0.16671835  	0.16410954  
2023-05-21 16:08:52.907: [iter 29 : loss : 1.1818 = 0.2239 + 0.9530 + 0.0049, time: 43.606011]
2023-05-21 16:08:53.560: epoch 29:	0.08790082  	0.16674034  	0.16399790  
2023-05-21 16:09:37.569: [iter 30 : loss : 1.1647 = 0.2076 + 0.9519 + 0.0053, time: 44.001647]
2023-05-21 16:09:38.189: epoch 30:	0.08789010  	0.16656084  	0.16383319  
2023-05-21 16:10:20.955: [iter 31 : loss : 1.1494 = 0.1930 + 0.9508 + 0.0056, time: 42.755828]
2023-05-21 16:10:21.594: epoch 31:	0.08783099  	0.16625524  	0.16359217  
2023-05-21 16:11:04.253: [iter 32 : loss : 1.1369 = 0.1813 + 0.9497 + 0.0060, time: 42.653512]
2023-05-21 16:11:04.888: epoch 32:	0.08780413  	0.16601820  	0.16342615  
2023-05-21 16:11:48.898: [iter 33 : loss : 1.1249 = 0.1699 + 0.9487 + 0.0063, time: 44.003651]
2023-05-21 16:11:49.546: epoch 33:	0.08771278  	0.16605210  	0.16303088  
2023-05-21 16:12:33.251: [iter 34 : loss : 1.1155 = 0.1611 + 0.9477 + 0.0067, time: 43.698175]
2023-05-21 16:12:33.912: epoch 34:	0.08758389  	0.16560477  	0.16263990  
2023-05-21 16:13:16.779: [iter 35 : loss : 1.1055 = 0.1517 + 0.9468 + 0.0070, time: 42.852043]
2023-05-21 16:13:17.420: epoch 35:	0.08750865  	0.16507018  	0.16233434  
2023-05-21 16:14:00.142: [iter 36 : loss : 1.0976 = 0.1445 + 0.9459 + 0.0073, time: 42.714120]
2023-05-21 16:14:00.797: epoch 36:	0.08722934  	0.16375348  	0.16147944  
2023-05-21 16:14:44.722: [iter 37 : loss : 1.0896 = 0.1371 + 0.9448 + 0.0076, time: 43.917949]
2023-05-21 16:14:45.371: epoch 37:	0.08685331  	0.16278888  	0.16088916  
2023-05-21 16:15:29.501: [iter 38 : loss : 1.0833 = 0.1313 + 0.9441 + 0.0079, time: 44.121331]
2023-05-21 16:15:30.134: epoch 38:	0.08662234  	0.16186853  	0.16026127  
2023-05-21 16:16:13.118: [iter 39 : loss : 1.0773 = 0.1259 + 0.9433 + 0.0082, time: 42.976442]
2023-05-21 16:16:13.783: epoch 39:	0.08649882  	0.16105616  	0.15980634  
2023-05-21 16:16:56.708: [iter 40 : loss : 1.0720 = 0.1210 + 0.9426 + 0.0084, time: 42.916659]
2023-05-21 16:16:57.337: epoch 40:	0.08638602  	0.16048458  	0.15932444  
2023-05-21 16:17:41.411: [iter 41 : loss : 1.0666 = 0.1160 + 0.9419 + 0.0087, time: 44.065090]
2023-05-21 16:17:42.050: epoch 41:	0.08632698  	0.16011809  	0.15891282  
2023-05-21 16:18:26.320: [iter 42 : loss : 1.0618 = 0.1116 + 0.9413 + 0.0090, time: 44.262574]
2023-05-21 16:18:26.985: epoch 42:	0.08613898  	0.15947475  	0.15824018  
2023-05-21 16:19:09.978: [iter 43 : loss : 1.0574 = 0.1075 + 0.9407 + 0.0092, time: 42.979917]
2023-05-21 16:19:10.595: epoch 43:	0.08594565  	0.15867943  	0.15759251  
2023-05-21 16:19:53.443: [iter 44 : loss : 1.0534 = 0.1038 + 0.9402 + 0.0094, time: 42.839858]
2023-05-21 16:19:54.090: epoch 44:	0.08585432  	0.15824623  	0.15721646  
2023-05-21 16:20:37.964: [iter 45 : loss : 1.0504 = 0.1010 + 0.9397 + 0.0097, time: 43.867852]
2023-05-21 16:20:38.574: epoch 45:	0.08549445  	0.15716460  	0.15658623  
2023-05-21 16:21:22.716: [iter 46 : loss : 1.0463 = 0.0973 + 0.9392 + 0.0099, time: 44.135316]
2023-05-21 16:21:23.354: epoch 46:	0.08529034  	0.15647757  	0.15606071  
2023-05-21 16:22:02.097: [iter 47 : loss : 1.0433 = 0.0946 + 0.9386 + 0.0101, time: 38.734947]
2023-05-21 16:22:02.519: epoch 47:	0.08506477  	0.15567815  	0.15542458  
2023-05-21 16:22:37.982: [iter 48 : loss : 1.0403 = 0.0918 + 0.9382 + 0.0103, time: 35.456475]
2023-05-21 16:22:38.401: epoch 48:	0.08479083  	0.15490086  	0.15485072  
2023-05-21 16:23:14.704: [iter 49 : loss : 1.0375 = 0.0891 + 0.9378 + 0.0106, time: 36.296931]
2023-05-21 16:23:15.101: epoch 49:	0.08452217  	0.15403883  	0.15414506  
2023-05-21 16:23:50.651: [iter 50 : loss : 1.0349 = 0.0868 + 0.9374 + 0.0108, time: 35.544121]
2023-05-21 16:23:51.058: epoch 50:	0.08437181  	0.15376589  	0.15364775  
2023-05-21 16:24:25.950: [iter 51 : loss : 1.0326 = 0.0845 + 0.9371 + 0.0109, time: 34.868622]
2023-05-21 16:24:26.349: epoch 51:	0.08420532  	0.15270720  	0.15304151  
2023-05-21 16:25:01.921: [iter 52 : loss : 1.0303 = 0.0824 + 0.9368 + 0.0111, time: 35.564922]
2023-05-21 16:25:02.334: epoch 52:	0.08407103  	0.15236665  	0.15237594  
2023-05-21 16:25:02.334: Early stopping is trigger at epoch: 52
2023-05-21 16:25:02.334: best_result@epoch 27:

2023-05-21 16:25:02.334: 		0.0877      	0.1669      	0.1640      
2023-05-21 16:32:17.899: my pid: 13756
2023-05-21 16:32:17.899: model: model.general_recommender.SGL
2023-05-21 16:32:17.899: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 16:32:17.899: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 16:32:23.723: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 16:33:10.822: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 47.092529]
2023-05-21 16:33:11.504: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-05-21 16:33:11.504: Find a better model.
2023-05-21 16:33:57.268: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 45.757251]
2023-05-21 16:33:57.919: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-05-21 16:33:57.919: Find a better model.
2023-05-21 16:34:43.634: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 45.709132]
2023-05-21 16:34:44.310: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-05-21 16:34:44.310: Find a better model.
2023-05-21 16:35:31.052: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 46.735138]
2023-05-21 16:35:31.722: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-05-21 16:35:31.722: Find a better model.
2023-05-21 16:36:18.769: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 47.039464]
2023-05-21 16:36:19.431: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-05-21 16:36:19.431: Find a better model.
2023-05-21 16:37:05.269: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 45.829587]
2023-05-21 16:37:05.921: epoch 6:	0.00772451  	0.01568698  	0.01374723  
2023-05-21 16:37:05.921: Find a better model.
2023-05-21 16:37:51.687: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 45.757821]
2023-05-21 16:37:52.373: epoch 7:	0.00857865  	0.01634379  	0.01484605  
2023-05-21 16:37:52.373: Find a better model.
2023-05-21 16:38:39.240: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 46.859035]
2023-05-21 16:38:39.877: epoch 8:	0.00980345  	0.01916631  	0.01706018  
2023-05-21 16:38:39.877: Find a better model.
2023-05-21 16:39:26.916: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 47.030882]
2023-05-21 16:39:27.611: epoch 9:	0.01139889  	0.02280196  	0.02033713  
2023-05-21 16:39:27.611: Find a better model.
2023-05-21 16:40:13.456: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 45.838912]
2023-05-21 16:40:14.102: epoch 10:	0.01327366  	0.02668142  	0.02470750  
2023-05-21 16:40:14.103: Find a better model.
2023-05-21 16:40:59.877: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 45.763949]
2023-05-21 16:41:00.540: epoch 11:	0.01542245  	0.03111634  	0.02916739  
2023-05-21 16:41:00.541: Find a better model.
2023-05-21 16:41:47.609: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 47.054084]
2023-05-21 16:41:48.293: epoch 12:	0.01837162  	0.03774254  	0.03553504  
2023-05-21 16:41:48.293: Find a better model.
2023-05-21 16:42:35.431: [iter 13 : loss : 1.6047 = 0.6911 + 0.9135 + 0.0000, time: 47.130338]
2023-05-21 16:42:36.087: epoch 13:	0.02247574  	0.04678126  	0.04394830  
2023-05-21 16:42:36.087: Find a better model.
2023-05-21 16:43:21.860: [iter 14 : loss : 1.6041 = 0.6901 + 0.9139 + 0.0000, time: 45.763739]
2023-05-21 16:43:22.530: epoch 14:	0.02782069  	0.05873166  	0.05544734  
2023-05-21 16:43:22.530: Find a better model.
2023-05-21 16:44:08.292: [iter 15 : loss : 1.6027 = 0.6884 + 0.9143 + 0.0001, time: 45.754602]
2023-05-21 16:44:08.927: epoch 15:	0.03541569  	0.07228198  	0.07093161  
2023-05-21 16:44:08.928: Find a better model.
2023-05-21 16:44:56.126: [iter 16 : loss : 1.6001 = 0.6849 + 0.9151 + 0.0001, time: 47.191790]
2023-05-21 16:44:56.783: epoch 16:	0.04557317  	0.09196179  	0.09038765  
2023-05-21 16:44:56.783: Find a better model.
2023-05-21 16:45:43.503: [iter 17 : loss : 1.5938 = 0.6774 + 0.9162 + 0.0001, time: 46.713616]
2023-05-21 16:45:43.938: epoch 17:	0.05755161  	0.11398961  	0.11317725  
2023-05-21 16:45:43.938: Find a better model.
2023-05-21 16:46:29.750: [iter 18 : loss : 1.5796 = 0.6609 + 0.9185 + 0.0002, time: 45.799931]
2023-05-21 16:46:30.408: epoch 18:	0.06847719  	0.13218176  	0.13287163  
2023-05-21 16:46:30.408: Find a better model.
2023-05-21 16:47:16.199: [iter 19 : loss : 1.5506 = 0.6281 + 0.9221 + 0.0004, time: 45.782375]
2023-05-21 16:47:16.862: epoch 19:	0.07634110  	0.14508772  	0.14614482  
2023-05-21 16:47:16.862: Find a better model.
2023-05-21 16:48:03.944: [iter 20 : loss : 1.5053 = 0.5770 + 0.9275 + 0.0008, time: 47.066319]
2023-05-21 16:48:04.609: epoch 20:	0.08077267  	0.15228282  	0.15366140  
2023-05-21 16:48:04.609: Find a better model.
2023-05-21 16:48:51.765: [iter 21 : loss : 1.4498 = 0.5150 + 0.9336 + 0.0012, time: 47.149526]
2023-05-21 16:48:52.376: epoch 21:	0.08284067  	0.15643990  	0.15736179  
2023-05-21 16:48:52.376: Find a better model.
2023-05-21 16:49:38.318: [iter 22 : loss : 1.3934 = 0.4529 + 0.9388 + 0.0017, time: 45.933706]
2023-05-21 16:49:38.963: epoch 22:	0.08440384  	0.15957822  	0.16007976  
2023-05-21 16:49:38.964: Find a better model.
2023-05-21 16:50:25.076: [iter 23 : loss : 1.3434 = 0.3986 + 0.9425 + 0.0022, time: 46.103257]
2023-05-21 16:50:25.751: epoch 23:	0.08541364  	0.16201310  	0.16203941  
2023-05-21 16:50:25.751: Find a better model.
2023-05-21 16:51:13.122: [iter 24 : loss : 1.3003 = 0.3528 + 0.9447 + 0.0027, time: 47.355453]
2023-05-21 16:51:13.790: epoch 24:	0.08623549  	0.16389117  	0.16352585  
2023-05-21 16:51:13.790: Find a better model.
2023-05-21 16:52:01.143: [iter 25 : loss : 1.2646 = 0.3159 + 0.9454 + 0.0032, time: 47.345671]
2023-05-21 16:52:01.714: epoch 25:	0.08679948  	0.16464932  	0.16406660  
2023-05-21 16:52:01.714: Find a better model.
2023-05-21 16:52:47.799: [iter 26 : loss : 1.2338 = 0.2847 + 0.9455 + 0.0036, time: 46.076452]
2023-05-21 16:52:48.471: epoch 26:	0.08722925  	0.16563146  	0.16449451  
2023-05-21 16:52:48.471: Find a better model.
2023-05-21 16:53:34.566: [iter 27 : loss : 1.2080 = 0.2588 + 0.9451 + 0.0041, time: 46.085963]
2023-05-21 16:53:35.262: epoch 27:	0.08759449  	0.16634370  	0.16492295  
2023-05-21 16:53:35.262: Find a better model.
2023-05-21 16:54:22.989: [iter 28 : loss : 1.1865 = 0.2375 + 0.9445 + 0.0045, time: 47.716326]
2023-05-21 16:54:23.676: epoch 28:	0.08772340  	0.16697216  	0.16485225  
2023-05-21 16:54:23.676: Find a better model.
2023-05-21 16:55:09.561: [iter 29 : loss : 1.1678 = 0.2195 + 0.9435 + 0.0049, time: 45.876391]
2023-05-21 16:55:10.243: epoch 29:	0.08742800  	0.16648513  	0.16440715  
2023-05-21 16:55:56.738: [iter 30 : loss : 1.1514 = 0.2036 + 0.9424 + 0.0053, time: 46.487733]
2023-05-21 16:55:57.415: epoch 30:	0.08746027  	0.16669156  	0.16444235  
2023-05-21 16:56:45.128: [iter 31 : loss : 1.1367 = 0.1895 + 0.9415 + 0.0057, time: 47.706576]
2023-05-21 16:56:45.797: epoch 31:	0.08766440  	0.16715895  	0.16458072  
2023-05-21 16:56:45.797: Find a better model.
2023-05-21 16:57:32.595: [iter 32 : loss : 1.1247 = 0.1782 + 0.9405 + 0.0060, time: 46.791370]
2023-05-21 16:57:33.030: epoch 32:	0.08771276  	0.16716813  	0.16431847  
2023-05-21 16:57:33.031: Find a better model.
2023-05-21 16:58:19.690: [iter 33 : loss : 1.1131 = 0.1672 + 0.9396 + 0.0064, time: 46.651612]
2023-05-21 16:58:20.349: epoch 33:	0.08759999  	0.16660284  	0.16376559  
2023-05-21 16:59:07.578: [iter 34 : loss : 1.1042 = 0.1589 + 0.9386 + 0.0067, time: 47.220129]
2023-05-21 16:59:08.264: epoch 34:	0.08721859  	0.16544624  	0.16302161  
2023-05-21 16:59:55.959: [iter 35 : loss : 1.0948 = 0.1498 + 0.9379 + 0.0070, time: 47.687199]
2023-05-21 16:59:56.619: epoch 35:	0.08712728  	0.16481820  	0.16258790  
2023-05-21 17:00:40.488: [iter 36 : loss : 1.0871 = 0.1427 + 0.9370 + 0.0073, time: 43.861850]
2023-05-21 17:00:40.889: epoch 36:	0.08697151  	0.16401964  	0.16190222  
2023-05-21 17:01:20.463: [iter 37 : loss : 1.0795 = 0.1357 + 0.9362 + 0.0076, time: 39.566785]
2023-05-21 17:01:20.910: epoch 37:	0.08670828  	0.16338989  	0.16128896  
2023-05-21 17:01:59.639: [iter 38 : loss : 1.0731 = 0.1298 + 0.9354 + 0.0079, time: 38.722592]
2023-05-21 17:02:00.057: epoch 38:	0.08657928  	0.16272368  	0.16074999  
2023-05-21 17:02:38.591: [iter 39 : loss : 1.0674 = 0.1245 + 0.9347 + 0.0082, time: 38.525134]
2023-05-21 17:02:38.994: epoch 39:	0.08650953  	0.16205645  	0.16017999  
2023-05-21 17:03:17.887: [iter 40 : loss : 1.0622 = 0.1197 + 0.9340 + 0.0085, time: 38.886335]
2023-05-21 17:03:18.319: epoch 40:	0.08606905  	0.16079494  	0.15930696  
2023-05-21 17:03:57.408: [iter 41 : loss : 1.0567 = 0.1146 + 0.9334 + 0.0087, time: 39.082476]
2023-05-21 17:03:57.815: epoch 41:	0.08596163  	0.15997843  	0.15873289  
2023-05-21 17:04:37.220: [iter 42 : loss : 1.0524 = 0.1106 + 0.9328 + 0.0090, time: 39.396762]
2023-05-21 17:04:37.647: epoch 42:	0.08577898  	0.15950023  	0.15808137  
2023-05-21 17:05:25.422: [iter 43 : loss : 1.0478 = 0.1063 + 0.9323 + 0.0092, time: 47.761380]
2023-05-21 17:05:26.056: epoch 43:	0.08574671  	0.15901783  	0.15768918  
2023-05-21 17:06:12.641: [iter 44 : loss : 1.0440 = 0.1028 + 0.9318 + 0.0095, time: 46.577457]
2023-05-21 17:06:13.275: epoch 44:	0.08553720  	0.15825820  	0.15699749  
2023-05-21 17:07:00.787: [iter 45 : loss : 1.0409 = 0.0999 + 0.9313 + 0.0097, time: 47.504447]
2023-05-21 17:07:01.434: epoch 45:	0.08552653  	0.15787205  	0.15646940  
2023-05-21 17:07:48.347: [iter 46 : loss : 1.0372 = 0.0964 + 0.9309 + 0.0099, time: 46.906250]
2023-05-21 17:07:48.969: epoch 46:	0.08517199  	0.15690883  	0.15582870  
2023-05-21 17:08:35.810: [iter 47 : loss : 1.0340 = 0.0935 + 0.9303 + 0.0102, time: 46.832412]
2023-05-21 17:08:36.455: epoch 47:	0.08481746  	0.15582493  	0.15508011  
2023-05-21 17:09:24.660: [iter 48 : loss : 1.0310 = 0.0907 + 0.9300 + 0.0104, time: 48.198091]
2023-05-21 17:09:25.092: epoch 48:	0.08466712  	0.15503345  	0.15468125  
2023-05-21 17:10:12.133: [iter 49 : loss : 1.0284 = 0.0882 + 0.9296 + 0.0106, time: 47.031262]
2023-05-21 17:10:12.774: epoch 49:	0.08456495  	0.15454720  	0.15420969  
2023-05-21 17:15:02.069: my pid: 3592
2023-05-21 17:15:02.069: model: model.general_recommender.SGL
2023-05-21 17:15:02.069: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 17:15:02.069: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 17:15:07.961: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 17:15:52.327: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 44.365541]
2023-05-21 17:15:52.972: epoch 1:	0.00337880  	0.00807749  	0.00656585  
2023-05-21 17:15:52.972: Find a better model.
2023-05-21 17:16:36.996: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 44.018370]
2023-05-21 17:16:37.641: epoch 2:	0.00420603  	0.00948111  	0.00820640  
2023-05-21 17:16:37.641: Find a better model.
2023-05-21 17:17:23.074: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 45.426497]
2023-05-21 17:17:23.720: epoch 3:	0.00493658  	0.01017637  	0.00911207  
2023-05-21 17:17:23.720: Find a better model.
2023-05-21 17:18:07.840: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 44.114258]
2023-05-21 17:18:08.485: epoch 4:	0.00538780  	0.01099415  	0.00942833  
2023-05-21 17:18:08.485: Find a better model.
2023-05-21 17:18:52.740: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 44.247451]
2023-05-21 17:18:53.364: epoch 5:	0.00636544  	0.01287323  	0.01113765  
2023-05-21 17:18:53.364: Find a better model.
2023-05-21 17:19:38.711: [iter 6 : loss : 1.6067 = 0.6929 + 0.9139 + 0.0000, time: 45.338694]
2023-05-21 17:19:39.350: epoch 6:	0.00684889  	0.01343150  	0.01244461  
2023-05-21 17:19:39.350: Find a better model.
2023-05-21 17:20:24.518: [iter 7 : loss : 1.6068 = 0.6928 + 0.9141 + 0.0000, time: 45.159788]
2023-05-21 17:20:25.147: epoch 7:	0.00780509  	0.01476091  	0.01331042  
2023-05-21 17:20:25.147: Find a better model.
2023-05-21 17:21:09.035: [iter 8 : loss : 1.6068 = 0.6927 + 0.9141 + 0.0000, time: 43.878716]
2023-05-21 17:21:09.684: epoch 8:	0.00943815  	0.01698818  	0.01583513  
2023-05-21 17:21:09.684: Find a better model.
2023-05-21 17:21:53.797: [iter 9 : loss : 1.6069 = 0.6925 + 0.9144 + 0.0000, time: 44.103309]
2023-05-21 17:21:54.452: epoch 9:	0.01121624  	0.02089916  	0.01911004  
2023-05-21 17:21:54.452: Find a better model.
2023-05-21 17:22:39.944: [iter 10 : loss : 1.6069 = 0.6923 + 0.9145 + 0.0000, time: 45.475220]
2023-05-21 17:22:40.610: epoch 10:	0.01245715  	0.02363614  	0.02191894  
2023-05-21 17:22:40.610: Find a better model.
2023-05-21 17:23:24.651: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 44.033500]
2023-05-21 17:23:25.296: epoch 11:	0.01471334  	0.02865947  	0.02756227  
2023-05-21 17:23:25.296: Find a better model.
2023-05-21 17:24:09.277: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 43.974502]
2023-05-21 17:24:09.900: epoch 12:	0.01783442  	0.03515960  	0.03334959  
2023-05-21 17:24:09.900: Find a better model.
2023-05-21 17:24:55.198: [iter 13 : loss : 1.6063 = 0.6909 + 0.9154 + 0.0000, time: 45.282820]
2023-05-21 17:24:55.849: epoch 13:	0.02180425  	0.04406047  	0.04224520  
2023-05-21 17:24:55.849: Find a better model.
2023-05-21 17:25:40.079: [iter 14 : loss : 1.6058 = 0.6899 + 0.9158 + 0.0000, time: 44.224262]
2023-05-21 17:25:40.691: epoch 14:	0.02780993  	0.05583351  	0.05436920  
2023-05-21 17:25:40.691: Find a better model.
2023-05-21 17:26:24.852: [iter 15 : loss : 1.6045 = 0.6880 + 0.9165 + 0.0001, time: 44.153577]
2023-05-21 17:26:25.483: epoch 15:	0.03626444  	0.07159533  	0.07095426  
2023-05-21 17:26:25.483: Find a better model.
2023-05-21 17:27:10.728: [iter 16 : loss : 1.6019 = 0.6843 + 0.9175 + 0.0001, time: 45.237587]
2023-05-21 17:27:11.344: epoch 16:	0.04700745  	0.09165454  	0.09044846  
2023-05-21 17:27:11.344: Find a better model.
2023-05-21 17:27:56.569: [iter 17 : loss : 1.5956 = 0.6765 + 0.9190 + 0.0001, time: 45.217395]
2023-05-21 17:27:57.160: epoch 17:	0.05883551  	0.11261404  	0.11300911  
2023-05-21 17:27:57.160: Find a better model.
2023-05-21 17:28:40.603: [iter 18 : loss : 1.5815 = 0.6596 + 0.9217 + 0.0003, time: 43.435140]
2023-05-21 17:28:41.232: epoch 18:	0.06971812  	0.13111809  	0.13292237  
2023-05-21 17:28:41.232: Find a better model.
2023-05-21 17:29:25.493: [iter 19 : loss : 1.5528 = 0.6265 + 0.9258 + 0.0005, time: 44.253615]
2023-05-21 17:29:26.131: epoch 19:	0.07663126  	0.14289980  	0.14530519  
2023-05-21 17:29:26.131: Find a better model.
2023-05-21 17:30:11.729: [iter 20 : loss : 1.5082 = 0.5758 + 0.9316 + 0.0008, time: 45.589133]
2023-05-21 17:30:12.368: epoch 20:	0.08061690  	0.15009645  	0.15222371  
2023-05-21 17:30:12.368: Find a better model.
2023-05-21 17:30:56.546: [iter 21 : loss : 1.4535 = 0.5142 + 0.9381 + 0.0012, time: 44.163536]
2023-05-21 17:30:57.164: epoch 21:	0.08310384  	0.15576603  	0.15632708  
2023-05-21 17:30:57.164: Find a better model.
2023-05-21 17:31:41.070: [iter 22 : loss : 1.3979 = 0.4527 + 0.9435 + 0.0017, time: 43.899144]
2023-05-21 17:31:41.732: epoch 22:	0.08437688  	0.15871572  	0.15865318  
2023-05-21 17:31:41.732: Find a better model.
2023-05-21 17:32:27.123: [iter 23 : loss : 1.3483 = 0.3988 + 0.9473 + 0.0022, time: 45.383058]
2023-05-21 17:32:27.754: epoch 23:	0.08573052  	0.16206206  	0.16121858  
2023-05-21 17:32:27.754: Find a better model.
2023-05-21 17:33:11.999: [iter 24 : loss : 1.3053 = 0.3532 + 0.9494 + 0.0027, time: 44.237376]
2023-05-21 17:33:12.612: epoch 24:	0.08670277  	0.16368064  	0.16271077  
2023-05-21 17:33:12.612: Find a better model.
2023-05-21 17:33:56.987: [iter 25 : loss : 1.2696 = 0.3164 + 0.9500 + 0.0032, time: 44.365791]
2023-05-21 17:33:57.630: epoch 25:	0.08698212  	0.16406426  	0.16303243  
2023-05-21 17:33:57.630: Find a better model.
2023-05-21 17:34:43.048: [iter 26 : loss : 1.2390 = 0.2853 + 0.9500 + 0.0037, time: 45.408198]
2023-05-21 17:34:43.691: epoch 26:	0.08727747  	0.16507630  	0.16332172  
2023-05-21 17:34:43.691: Find a better model.
2023-05-21 17:35:28.557: [iter 27 : loss : 1.2132 = 0.2596 + 0.9495 + 0.0041, time: 44.860209]
2023-05-21 17:35:28.988: epoch 27:	0.08756226  	0.16537684  	0.16376337  
2023-05-21 17:35:28.988: Find a better model.
2023-05-21 17:36:13.287: [iter 28 : loss : 1.1913 = 0.2380 + 0.9488 + 0.0045, time: 44.288210]
2023-05-21 17:36:13.920: epoch 28:	0.08780942  	0.16593042  	0.16389219  
2023-05-21 17:36:13.920: Find a better model.
2023-05-21 17:36:51.041: [iter 29 : loss : 1.1727 = 0.2201 + 0.9477 + 0.0049, time: 37.113785]
2023-05-21 17:36:51.473: epoch 29:	0.08786847  	0.16617244  	0.16401365  
2023-05-21 17:36:51.473: Find a better model.
2023-05-21 17:37:28.468: [iter 30 : loss : 1.1560 = 0.2041 + 0.9466 + 0.0053, time: 36.981045]
2023-05-21 17:37:28.863: epoch 30:	0.08788460  	0.16587938  	0.16391777  
2023-05-21 17:38:06.006: [iter 31 : loss : 1.1414 = 0.1901 + 0.9456 + 0.0057, time: 37.137829]
2023-05-21 17:38:06.402: epoch 31:	0.08812092  	0.16615698  	0.16407211  
2023-05-21 17:38:43.438: [iter 32 : loss : 1.1292 = 0.1786 + 0.9446 + 0.0060, time: 37.027757]
2023-05-21 17:38:43.844: epoch 32:	0.08798126  	0.16548653  	0.16360894  
2023-05-21 17:39:20.531: [iter 33 : loss : 1.1176 = 0.1677 + 0.9436 + 0.0064, time: 36.680370]
2023-05-21 17:39:20.928: epoch 33:	0.08770733  	0.16480510  	0.16285771  
2023-05-21 17:39:58.153: [iter 34 : loss : 1.1086 = 0.1592 + 0.9426 + 0.0067, time: 37.217406]
2023-05-21 17:39:58.601: epoch 34:	0.08765896  	0.16453229  	0.16268557  
2023-05-21 17:40:35.528: [iter 35 : loss : 1.0988 = 0.1499 + 0.9418 + 0.0070, time: 36.921369]
2023-05-21 17:40:35.925: epoch 35:	0.08746026  	0.16391152  	0.16214173  
2023-05-21 17:41:13.172: [iter 36 : loss : 1.0912 = 0.1430 + 0.9409 + 0.0073, time: 37.239203]
2023-05-21 17:41:13.571: epoch 36:	0.08725066  	0.16332953  	0.16156845  
2023-05-21 17:41:50.702: [iter 37 : loss : 1.0837 = 0.1360 + 0.9400 + 0.0076, time: 37.116310]
2023-05-21 17:41:51.095: epoch 37:	0.08681554  	0.16227488  	0.16084570  
2023-05-21 17:42:28.116: [iter 38 : loss : 1.0771 = 0.1300 + 0.9392 + 0.0079, time: 37.015124]
2023-05-21 17:42:28.506: epoch 38:	0.08656846  	0.16143148  	0.16014636  
2023-05-21 17:43:05.501: [iter 39 : loss : 1.0714 = 0.1248 + 0.9384 + 0.0082, time: 36.987312]
2023-05-21 17:43:05.914: epoch 39:	0.08630524  	0.16055766  	0.15945451  
2023-05-21 17:43:43.042: [iter 40 : loss : 1.0662 = 0.1199 + 0.9378 + 0.0085, time: 37.121589]
2023-05-21 17:43:43.440: epoch 40:	0.08597223  	0.15943444  	0.15856069  
2023-05-21 17:44:20.643: [iter 41 : loss : 1.0608 = 0.1150 + 0.9371 + 0.0087, time: 37.196087]
2023-05-21 17:44:21.036: epoch 41:	0.08582183  	0.15890309  	0.15802269  
2023-05-21 17:44:58.228: [iter 42 : loss : 1.0564 = 0.1109 + 0.9365 + 0.0090, time: 37.184864]
2023-05-21 17:44:58.620: epoch 42:	0.08568759  	0.15837033  	0.15760091  
2023-05-21 17:45:35.714: [iter 43 : loss : 1.0514 = 0.1062 + 0.9360 + 0.0092, time: 37.087049]
2023-05-21 17:45:36.109: epoch 43:	0.08547807  	0.15735303  	0.15699586  
2023-05-21 17:46:13.032: [iter 44 : loss : 1.0480 = 0.1031 + 0.9355 + 0.0095, time: 36.914058]
2023-05-21 17:46:13.427: epoch 44:	0.08527399  	0.15678103  	0.15675421  
2023-05-21 17:46:50.831: [iter 45 : loss : 1.0451 = 0.1004 + 0.9349 + 0.0097, time: 37.397622]
2023-05-21 17:46:51.249: epoch 45:	0.08498393  	0.15586689  	0.15594444  
2023-05-21 17:47:28.622: [iter 46 : loss : 1.0412 = 0.0968 + 0.9345 + 0.0099, time: 37.365455]
2023-05-21 17:47:29.024: epoch 46:	0.08469921  	0.15490969  	0.15533854  
2023-05-21 17:48:06.433: [iter 47 : loss : 1.0379 = 0.0939 + 0.9339 + 0.0102, time: 37.401807]
2023-05-21 17:48:06.860: epoch 47:	0.08457575  	0.15400696  	0.15468894  
2023-05-21 17:48:44.202: [iter 48 : loss : 1.0347 = 0.0908 + 0.9335 + 0.0104, time: 37.336293]
2023-05-21 17:48:44.619: epoch 48:	0.08428030  	0.15306905  	0.15391400  
2023-05-21 17:49:22.031: [iter 49 : loss : 1.0324 = 0.0886 + 0.9332 + 0.0106, time: 37.404688]
2023-05-21 17:49:22.422: epoch 49:	0.08401711  	0.15238956  	0.15328050  
2023-05-21 17:49:59.549: [iter 50 : loss : 1.0298 = 0.0863 + 0.9327 + 0.0108, time: 37.119610]
2023-05-21 17:49:59.962: epoch 50:	0.08383445  	0.15178366  	0.15282935  
2023-05-21 17:50:37.314: [iter 51 : loss : 1.0274 = 0.0840 + 0.9324 + 0.0110, time: 37.345205]
2023-05-21 17:50:37.707: epoch 51:	0.08371630  	0.15127835  	0.15218399  
2023-05-21 17:51:15.098: [iter 52 : loss : 1.0252 = 0.0819 + 0.9321 + 0.0112, time: 37.385332]
2023-05-21 17:51:15.490: epoch 52:	0.08352294  	0.15102567  	0.15168539  
2023-05-21 17:51:52.829: [iter 53 : loss : 1.0231 = 0.0801 + 0.9317 + 0.0114, time: 37.331897]
2023-05-21 17:51:53.225: epoch 53:	0.08330268  	0.15031630  	0.15098517  
2023-05-21 17:52:30.477: [iter 54 : loss : 1.0207 = 0.0777 + 0.9315 + 0.0115, time: 37.244460]
2023-05-21 17:52:30.913: epoch 54:	0.08305564  	0.14969230  	0.15063491  
2023-05-21 17:52:30.914: Early stopping is trigger at epoch: 54
2023-05-21 17:52:30.914: best_result@epoch 29:

2023-05-21 17:52:30.914: 		0.0879      	0.1662      	0.1640      
2023-05-21 18:11:01.890: my pid: 13360
2023-05-21 18:11:01.890: model: model.general_recommender.SGL
2023-05-21 18:11:01.890: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 18:11:01.890: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 18:11:06.776: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 18:11:46.049: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 39.272823]
2023-05-21 18:11:46.467: epoch 1:	0.00349160  	0.00821223  	0.00674875  
2023-05-21 18:11:46.467: Find a better model.
2023-05-21 18:12:25.591: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 39.116695]
2023-05-21 18:12:26.013: epoch 2:	0.00411472  	0.00870434  	0.00735326  
2023-05-21 18:12:26.013: Find a better model.
2023-05-21 18:13:04.974: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 38.954511]
2023-05-21 18:13:05.394: epoch 3:	0.00513533  	0.01078933  	0.00928117  
2023-05-21 18:13:05.395: Find a better model.
2023-05-21 18:13:44.676: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 39.274866]
2023-05-21 18:13:45.101: epoch 4:	0.00604314  	0.01171840  	0.01048327  
2023-05-21 18:13:45.101: Find a better model.
2023-05-21 18:14:24.572: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 39.463905]
2023-05-21 18:14:24.997: epoch 5:	0.00712823  	0.01388803  	0.01248124  
2023-05-21 18:14:24.997: Find a better model.
2023-05-21 18:15:04.117: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 39.114316]
2023-05-21 18:15:04.537: epoch 6:	0.00838526  	0.01581074  	0.01438362  
2023-05-21 18:15:04.537: Find a better model.
2023-05-21 18:15:43.700: [iter 7 : loss : 1.6045 = 0.6928 + 0.9118 + 0.0000, time: 39.156273]
2023-05-21 18:15:44.101: epoch 7:	0.00974434  	0.01849503  	0.01673545  
2023-05-21 18:15:44.101: Find a better model.
2023-05-21 18:16:23.494: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 39.386487]
2023-05-21 18:16:23.893: epoch 8:	0.01081872  	0.02081267  	0.01917062  
2023-05-21 18:16:23.893: Find a better model.
2023-05-21 18:17:02.907: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 39.007434]
2023-05-21 18:17:03.306: epoch 9:	0.01225839  	0.02384916  	0.02214896  
2023-05-21 18:17:03.307: Find a better model.
2023-05-21 18:17:42.461: [iter 10 : loss : 1.6041 = 0.6922 + 0.9119 + 0.0000, time: 39.147426]
2023-05-21 18:17:42.890: epoch 10:	0.01446623  	0.02762912  	0.02612099  
2023-05-21 18:17:42.890: Find a better model.
2023-05-21 18:18:22.034: [iter 11 : loss : 1.6037 = 0.6919 + 0.9118 + 0.0000, time: 39.137249]
2023-05-21 18:18:22.463: epoch 11:	0.01684063  	0.03299030  	0.03131263  
2023-05-21 18:18:22.464: Find a better model.
2023-05-21 18:19:01.636: [iter 12 : loss : 1.6034 = 0.6914 + 0.9120 + 0.0000, time: 39.166425]
2023-05-21 18:19:02.043: epoch 12:	0.02011749  	0.04012677  	0.03871176  
2023-05-21 18:19:02.043: Find a better model.
2023-05-21 18:19:41.232: [iter 13 : loss : 1.6028 = 0.6906 + 0.9122 + 0.0000, time: 39.183767]
2023-05-21 18:19:41.648: epoch 13:	0.02454392  	0.05044828  	0.04768474  
2023-05-21 18:19:41.648: Find a better model.
2023-05-21 18:20:20.825: [iter 14 : loss : 1.6017 = 0.6892 + 0.9125 + 0.0000, time: 39.169308]
2023-05-21 18:20:21.223: epoch 14:	0.03081251  	0.06410605  	0.06152410  
2023-05-21 18:20:21.223: Find a better model.
2023-05-21 18:21:00.567: [iter 15 : loss : 1.5995 = 0.6865 + 0.9129 + 0.0001, time: 39.338375]
2023-05-21 18:21:00.968: epoch 15:	0.03925627  	0.08156533  	0.07889908  
2023-05-21 18:21:00.968: Find a better model.
2023-05-21 18:21:40.188: [iter 16 : loss : 1.5947 = 0.6809 + 0.9137 + 0.0001, time: 39.213010]
2023-05-21 18:21:40.607: epoch 16:	0.04988117  	0.10059800  	0.09907958  
2023-05-21 18:21:40.607: Find a better model.
2023-05-21 18:22:19.556: [iter 17 : loss : 1.5837 = 0.6685 + 0.9150 + 0.0002, time: 38.942774]
2023-05-21 18:22:19.979: epoch 17:	0.06223021  	0.12163071  	0.12117431  
2023-05-21 18:22:19.979: Find a better model.
2023-05-21 18:22:59.209: [iter 18 : loss : 1.5604 = 0.6423 + 0.9178 + 0.0003, time: 39.224235]
2023-05-21 18:22:59.649: epoch 18:	0.07218361  	0.13793622  	0.13815576  
2023-05-21 18:22:59.649: Find a better model.
2023-05-21 18:23:38.994: [iter 19 : loss : 1.5195 = 0.5966 + 0.9223 + 0.0006, time: 39.338088]
2023-05-21 18:23:39.388: epoch 19:	0.07819429  	0.14819573  	0.14893936  
2023-05-21 18:23:39.388: Find a better model.
2023-05-21 18:24:18.549: [iter 20 : loss : 1.4658 = 0.5364 + 0.9284 + 0.0010, time: 39.155053]
2023-05-21 18:24:18.951: epoch 20:	0.08143867  	0.15340436  	0.15408923  
2023-05-21 18:24:18.951: Find a better model.
2023-05-21 18:24:58.190: [iter 21 : loss : 1.4086 = 0.4729 + 0.9343 + 0.0015, time: 39.231881]
2023-05-21 18:24:58.591: epoch 21:	0.08359271  	0.15744768  	0.15773760  
2023-05-21 18:24:58.591: Find a better model.
2023-05-21 18:25:37.678: [iter 22 : loss : 1.3555 = 0.4149 + 0.9386 + 0.0020, time: 39.075087]
2023-05-21 18:25:38.074: epoch 22:	0.08497849  	0.16026980  	0.15994368  
2023-05-21 18:25:38.074: Find a better model.
2023-05-21 18:26:17.283: [iter 23 : loss : 1.3106 = 0.3669 + 0.9413 + 0.0025, time: 39.201937]
2023-05-21 18:26:17.725: epoch 23:	0.08593989  	0.16167279  	0.16135204  
2023-05-21 18:26:17.725: Find a better model.
2023-05-21 18:26:56.925: [iter 24 : loss : 1.2725 = 0.3269 + 0.9426 + 0.0030, time: 39.193691]
2023-05-21 18:26:57.319: epoch 24:	0.08667594  	0.16347824  	0.16233547  
2023-05-21 18:26:57.319: Find a better model.
2023-05-21 18:27:36.457: [iter 25 : loss : 1.2412 = 0.2949 + 0.9428 + 0.0034, time: 39.130573]
2023-05-21 18:27:36.880: epoch 25:	0.08718091  	0.16448498  	0.16293757  
2023-05-21 18:27:36.881: Find a better model.
2023-05-21 18:28:16.188: [iter 26 : loss : 1.2139 = 0.2675 + 0.9425 + 0.0039, time: 39.301481]
2023-05-21 18:28:16.580: epoch 26:	0.08753002  	0.16484171  	0.16340445  
2023-05-21 18:28:16.580: Find a better model.
2023-05-21 18:28:55.796: [iter 27 : loss : 1.1909 = 0.2447 + 0.9419 + 0.0043, time: 39.208999]
2023-05-21 18:28:56.190: epoch 27:	0.08768043  	0.16538452  	0.16354743  
2023-05-21 18:28:56.190: Find a better model.
2023-05-21 18:29:35.652: [iter 28 : loss : 1.1713 = 0.2255 + 0.9411 + 0.0047, time: 39.455336]
2023-05-21 18:29:36.056: epoch 28:	0.08770184  	0.16518980  	0.16362105  
2023-05-21 18:30:15.207: [iter 29 : loss : 1.1548 = 0.2096 + 0.9401 + 0.0051, time: 39.144908]
2023-05-21 18:30:15.602: epoch 29:	0.08757836  	0.16518284  	0.16345333  
2023-05-21 18:30:55.200: [iter 30 : loss : 1.1399 = 0.1953 + 0.9391 + 0.0055, time: 39.589955]
2023-05-21 18:30:55.621: epoch 30:	0.08751386  	0.16502371  	0.16333756  
2023-05-21 18:31:34.774: [iter 31 : loss : 1.1264 = 0.1825 + 0.9381 + 0.0059, time: 39.146186]
2023-05-21 18:31:35.170: epoch 31:	0.08721303  	0.16444944  	0.16284704  
2023-05-21 18:32:14.129: [iter 32 : loss : 1.1153 = 0.1720 + 0.9371 + 0.0062, time: 38.953214]
2023-05-21 18:32:14.524: epoch 32:	0.08729364  	0.16435827  	0.16265941  
2023-05-21 18:32:53.748: [iter 33 : loss : 1.1047 = 0.1619 + 0.9362 + 0.0066, time: 39.215654]
2023-05-21 18:32:54.146: epoch 33:	0.08732051  	0.16412753  	0.16233809  
2023-05-21 18:33:33.585: [iter 34 : loss : 1.0962 = 0.1540 + 0.9353 + 0.0069, time: 39.432547]
2023-05-21 18:33:34.005: epoch 34:	0.08709496  	0.16367769  	0.16189425  
2023-05-21 18:34:13.287: [iter 35 : loss : 1.0874 = 0.1456 + 0.9346 + 0.0072, time: 39.275009]
2023-05-21 18:34:13.680: epoch 35:	0.08678881  	0.16302910  	0.16126357  
2023-05-21 18:34:53.154: [iter 36 : loss : 1.0801 = 0.1389 + 0.9337 + 0.0075, time: 39.467659]
2023-05-21 18:34:53.573: epoch 36:	0.08665987  	0.16242032  	0.16077998  
2023-05-21 18:35:32.669: [iter 37 : loss : 1.0729 = 0.1322 + 0.9329 + 0.0078, time: 39.089971]
2023-05-21 18:35:33.083: epoch 37:	0.08652015  	0.16197643  	0.16036129  
2023-05-21 18:36:12.495: [iter 38 : loss : 1.0671 = 0.1268 + 0.9322 + 0.0081, time: 39.405740]
2023-05-21 18:36:12.925: epoch 38:	0.08641812  	0.16158055  	0.16000596  
2023-05-21 18:36:52.270: [iter 39 : loss : 1.0617 = 0.1218 + 0.9315 + 0.0083, time: 39.337338]
2023-05-21 18:36:52.664: epoch 39:	0.08624622  	0.16079433  	0.15933473  
2023-05-21 18:37:32.633: [iter 40 : loss : 1.0566 = 0.1172 + 0.9309 + 0.0086, time: 39.962640]
2023-05-21 18:37:33.047: epoch 40:	0.08599383  	0.15984644  	0.15843110  
2023-05-21 18:38:50.529: my pid: 1964
2023-05-21 18:38:50.529: model: model.general_recommender.SGL
2023-05-21 18:38:50.529: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 18:38:50.529: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 18:38:55.509: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 18:39:36.023: [iter 1 : loss : 1.6068 = 0.6931 + 0.9136 + 0.0000, time: 40.512584]
2023-05-21 18:39:36.426: epoch 1:	0.00398042  	0.00875837  	0.00757808  
2023-05-21 18:39:36.426: Find a better model.
2023-05-21 18:40:16.908: [iter 2 : loss : 1.6045 = 0.6931 + 0.9114 + 0.0000, time: 40.474656]
2023-05-21 18:40:17.320: epoch 2:	0.00478080  	0.00989423  	0.00854846  
2023-05-21 18:40:17.320: Find a better model.
2023-05-21 18:40:57.833: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 40.506615]
2023-05-21 18:40:58.255: epoch 3:	0.00566175  	0.01142239  	0.01010403  
2023-05-21 18:40:58.255: Find a better model.
2023-05-21 18:41:38.851: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 40.589906]
2023-05-21 18:41:39.287: epoch 4:	0.00656956  	0.01223412  	0.01126100  
2023-05-21 18:41:39.287: Find a better model.
2023-05-21 18:42:19.801: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 40.505915]
2023-05-21 18:42:20.235: epoch 5:	0.00781047  	0.01443362  	0.01366854  
2023-05-21 18:42:20.235: Find a better model.
2023-05-21 18:43:00.627: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 40.384989]
2023-05-21 18:43:01.049: epoch 6:	0.00903526  	0.01660175  	0.01595149  
2023-05-21 18:43:01.049: Find a better model.
2023-05-21 18:43:41.539: [iter 7 : loss : 1.6035 = 0.6927 + 0.9108 + 0.0000, time: 40.483325]
2023-05-21 18:43:41.953: epoch 7:	0.01024931  	0.01879452  	0.01769141  
2023-05-21 18:43:41.953: Find a better model.
2023-05-21 18:44:22.594: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 40.633756]
2023-05-21 18:44:22.997: epoch 8:	0.01145798  	0.02116834  	0.01978062  
2023-05-21 18:44:22.998: Find a better model.
2023-05-21 18:45:03.913: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 40.907752]
2023-05-21 18:45:04.336: epoch 9:	0.01377864  	0.02622136  	0.02398405  
2023-05-21 18:45:04.336: Find a better model.
2023-05-21 18:45:45.411: [iter 10 : loss : 1.6029 = 0.6921 + 0.9107 + 0.0000, time: 41.068962]
2023-05-21 18:45:45.811: epoch 10:	0.01519683  	0.02964116  	0.02722461  
2023-05-21 18:45:45.811: Find a better model.
2023-05-21 18:46:26.726: [iter 11 : loss : 1.6024 = 0.6917 + 0.9106 + 0.0000, time: 40.908126]
2023-05-21 18:46:27.146: epoch 11:	0.01746376  	0.03546352  	0.03276338  
2023-05-21 18:46:27.146: Find a better model.
2023-05-21 18:47:08.214: [iter 12 : loss : 1.6019 = 0.6911 + 0.9108 + 0.0000, time: 41.053368]
2023-05-21 18:47:08.617: epoch 12:	0.02043442  	0.04189388  	0.03929387  
2023-05-21 18:47:08.617: Find a better model.
2023-05-21 18:47:49.893: [iter 13 : loss : 1.6011 = 0.6902 + 0.9109 + 0.0000, time: 41.269730]
2023-05-21 18:47:50.398: epoch 13:	0.02497904  	0.05210627  	0.04830518  
2023-05-21 18:47:50.399: Find a better model.
2023-05-21 18:48:38.637: [iter 14 : loss : 1.5995 = 0.6883 + 0.9111 + 0.0000, time: 48.231184]
2023-05-21 18:48:39.286: epoch 14:	0.03057078  	0.06559827  	0.06054273  
2023-05-21 18:48:39.286: Find a better model.
2023-05-21 18:49:27.447: [iter 15 : loss : 1.5963 = 0.6847 + 0.9115 + 0.0001, time: 48.153350]
2023-05-21 18:49:28.022: epoch 15:	0.03916496  	0.08405378  	0.07853647  
2023-05-21 18:49:28.022: Find a better model.
2023-05-21 18:50:15.501: [iter 16 : loss : 1.5894 = 0.6770 + 0.9123 + 0.0001, time: 47.470116]
2023-05-21 18:50:16.138: epoch 16:	0.04953205  	0.10311379  	0.09912878  
2023-05-21 18:50:16.138: Find a better model.
2023-05-21 18:51:04.337: [iter 17 : loss : 1.5742 = 0.6602 + 0.9138 + 0.0002, time: 48.181659]
2023-05-21 18:51:04.959: epoch 17:	0.06203132  	0.12364715  	0.12135680  
2023-05-21 18:51:04.959: Find a better model.
2023-05-21 18:51:53.197: [iter 18 : loss : 1.5448 = 0.6275 + 0.9169 + 0.0004, time: 48.229264]
2023-05-21 18:51:53.806: epoch 18:	0.07196865  	0.13941117  	0.13838565  
2023-05-21 18:51:53.807: Find a better model.
2023-05-21 18:52:42.082: [iter 19 : loss : 1.4990 = 0.5766 + 0.9216 + 0.0007, time: 48.267442]
2023-05-21 18:52:42.534: epoch 19:	0.07775372  	0.14854443  	0.14807352  
2023-05-21 18:52:42.534: Find a better model.
2023-05-21 18:53:30.945: [iter 20 : loss : 1.4441 = 0.5156 + 0.9274 + 0.0012, time: 48.404323]
2023-05-21 18:53:31.566: epoch 20:	0.08106790  	0.15390742  	0.15374638  
2023-05-21 18:53:31.566: Find a better model.
2023-05-21 18:54:19.470: [iter 21 : loss : 1.3889 = 0.4547 + 0.9326 + 0.0016, time: 47.887445]
2023-05-21 18:54:20.064: epoch 21:	0.08360323  	0.15808606  	0.15742163  
2023-05-21 18:54:20.064: Find a better model.
2023-05-21 18:55:08.330: [iter 22 : loss : 1.3391 = 0.4005 + 0.9364 + 0.0021, time: 48.253489]
2023-05-21 18:55:08.937: epoch 22:	0.08480097  	0.16029814  	0.15947098  
2023-05-21 18:55:08.937: Find a better model.
2023-05-21 18:55:57.133: [iter 23 : loss : 1.2970 = 0.3557 + 0.9387 + 0.0026, time: 48.188440]
2023-05-21 18:55:57.639: epoch 23:	0.08592375  	0.16223457  	0.16117822  
2023-05-21 18:55:57.639: Find a better model.
2023-05-21 18:56:45.887: [iter 24 : loss : 1.2613 = 0.3183 + 0.9399 + 0.0031, time: 48.232158]
2023-05-21 18:56:46.505: epoch 24:	0.08668655  	0.16401684  	0.16234246  
2023-05-21 18:56:46.505: Find a better model.
2023-05-21 18:57:34.903: [iter 25 : loss : 1.2319 = 0.2883 + 0.9400 + 0.0036, time: 48.388095]
2023-05-21 18:57:35.521: epoch 25:	0.08702509  	0.16411696  	0.16271743  
2023-05-21 18:57:35.521: Find a better model.
2023-05-21 18:58:23.988: [iter 26 : loss : 1.2061 = 0.2624 + 0.9397 + 0.0040, time: 48.452073]
2023-05-21 18:58:24.598: epoch 26:	0.08727214  	0.16470820  	0.16347517  
2023-05-21 18:58:24.598: Find a better model.
2023-05-21 18:59:12.701: [iter 27 : loss : 1.1843 = 0.2408 + 0.9391 + 0.0044, time: 48.097593]
2023-05-21 18:59:13.342: epoch 27:	0.08724524  	0.16461441  	0.16332895  
2023-05-21 19:00:01.937: [iter 28 : loss : 1.1657 = 0.2225 + 0.9384 + 0.0048, time: 48.583163]
2023-05-21 19:00:02.544: epoch 28:	0.08749241  	0.16475873  	0.16323227  
2023-05-21 19:00:02.544: Find a better model.
2023-05-21 19:00:50.923: [iter 29 : loss : 1.1500 = 0.2073 + 0.9374 + 0.0052, time: 48.370402]
2023-05-21 19:00:51.551: epoch 29:	0.08732586  	0.16439444  	0.16299786  
2023-05-21 19:01:39.759: [iter 30 : loss : 1.1355 = 0.1934 + 0.9365 + 0.0056, time: 48.201043]
2023-05-21 19:01:40.378: epoch 30:	0.08728834  	0.16410777  	0.16270742  
2023-05-21 19:02:28.592: [iter 31 : loss : 1.1223 = 0.1808 + 0.9356 + 0.0060, time: 48.207543]
2023-05-21 19:02:29.218: epoch 31:	0.08714870  	0.16396093  	0.16226748  
2023-05-21 19:03:17.738: [iter 32 : loss : 1.1118 = 0.1709 + 0.9346 + 0.0063, time: 48.510470]
2023-05-21 19:03:18.354: epoch 32:	0.08701981  	0.16304451  	0.16163906  
2023-05-21 19:04:07.174: [iter 33 : loss : 1.1013 = 0.1609 + 0.9337 + 0.0066, time: 48.812587]
2023-05-21 19:04:07.813: epoch 33:	0.08704131  	0.16300838  	0.16152962  
2023-05-21 19:04:56.693: [iter 34 : loss : 1.0932 = 0.1533 + 0.9329 + 0.0070, time: 48.872462]
2023-05-21 19:04:57.334: epoch 34:	0.08684792  	0.16288693  	0.16100456  
2023-05-21 19:05:38.846: [iter 35 : loss : 1.0846 = 0.1452 + 0.9322 + 0.0073, time: 41.502326]
2023-05-21 19:05:39.292: epoch 35:	0.08672974  	0.16216214  	0.16050982  
2023-05-21 19:07:28.269: my pid: 15012
2023-05-21 19:07:28.269: model: model.general_recommender.SGL
2023-05-21 19:07:28.269: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 19:07:28.269: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 19:07:33.592: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 19:08:18.263: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 44.665087]
2023-05-21 19:08:18.852: epoch 1:	0.00346474  	0.00759193  	0.00659054  
2023-05-21 19:08:18.852: Find a better model.
2023-05-21 19:09:04.061: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 45.196830]
2023-05-21 19:09:04.653: epoch 2:	0.00404488  	0.00949621  	0.00793493  
2023-05-21 19:09:04.653: Find a better model.
2023-05-21 19:09:49.513: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 44.850381]
2023-05-21 19:09:50.094: epoch 3:	0.00516756  	0.01102578  	0.00923869  
2023-05-21 19:09:50.094: Find a better model.
2023-05-21 19:10:35.022: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 44.913418]
2023-05-21 19:10:35.618: epoch 4:	0.00552209  	0.01085587  	0.00966270  
2023-05-21 19:11:20.839: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 45.205849]
2023-05-21 19:11:21.377: epoch 5:	0.00656419  	0.01279577  	0.01102954  
2023-05-21 19:11:21.377: Find a better model.
2023-05-21 19:12:05.879: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 44.486593]
2023-05-21 19:12:06.501: epoch 6:	0.00775675  	0.01544983  	0.01373369  
2023-05-21 19:12:06.501: Find a better model.
2023-05-21 19:12:51.560: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 45.049773]
2023-05-21 19:12:52.140: epoch 7:	0.00850344  	0.01644688  	0.01500680  
2023-05-21 19:12:52.140: Find a better model.
2023-05-21 19:13:37.245: [iter 8 : loss : 1.6054 = 0.6927 + 0.9128 + 0.0000, time: 45.082110]
2023-05-21 19:13:37.837: epoch 8:	0.00976584  	0.01928187  	0.01716662  
2023-05-21 19:13:37.838: Find a better model.
2023-05-21 19:14:22.924: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 45.079335]
2023-05-21 19:14:23.510: epoch 9:	0.01130220  	0.02337988  	0.02044731  
2023-05-21 19:14:23.510: Find a better model.
2023-05-21 19:15:08.665: [iter 10 : loss : 1.6054 = 0.6923 + 0.9130 + 0.0000, time: 45.147649]
2023-05-21 19:15:09.279: epoch 10:	0.01323606  	0.02677178  	0.02418940  
2023-05-21 19:15:09.280: Find a better model.
2023-05-21 19:15:54.777: [iter 11 : loss : 1.6051 = 0.6920 + 0.9131 + 0.0000, time: 45.486995]
2023-05-21 19:15:55.350: epoch 11:	0.01539559  	0.03127310  	0.02851266  
2023-05-21 19:15:55.350: Find a better model.
2023-05-21 19:16:39.951: [iter 12 : loss : 1.6050 = 0.6916 + 0.9133 + 0.0000, time: 44.593225]
2023-05-21 19:16:40.422: epoch 12:	0.01828566  	0.03730493  	0.03465550  
2023-05-21 19:16:40.422: Find a better model.
2023-05-21 19:17:25.177: [iter 13 : loss : 1.6046 = 0.6910 + 0.9136 + 0.0000, time: 44.741283]
2023-05-21 19:17:25.753: epoch 13:	0.02243813  	0.04682295  	0.04354852  
2023-05-21 19:17:25.753: Find a better model.
2023-05-21 19:18:10.753: [iter 14 : loss : 1.6040 = 0.6900 + 0.9140 + 0.0000, time: 44.983604]
2023-05-21 19:18:11.356: epoch 14:	0.02811611  	0.05903977  	0.05571724  
2023-05-21 19:18:11.356: Find a better model.
2023-05-21 19:18:56.473: [iter 15 : loss : 1.6025 = 0.6881 + 0.9144 + 0.0001, time: 45.102922]
2023-05-21 19:18:57.051: epoch 15:	0.03625901  	0.07504689  	0.07235404  
2023-05-21 19:18:57.051: Find a better model.
2023-05-21 19:19:41.840: [iter 16 : loss : 1.5996 = 0.6843 + 0.9152 + 0.0001, time: 44.777987]
2023-05-21 19:19:42.455: epoch 16:	0.04722225  	0.09467959  	0.09276501  
2023-05-21 19:19:42.455: Find a better model.
2023-05-21 19:20:27.256: [iter 17 : loss : 1.5927 = 0.6762 + 0.9164 + 0.0001, time: 44.788304]
2023-05-21 19:20:27.845: epoch 17:	0.05853472  	0.11534946  	0.11445736  
2023-05-21 19:20:27.845: Find a better model.
2023-05-21 19:21:07.178: [iter 18 : loss : 1.5772 = 0.6583 + 0.9187 + 0.0002, time: 39.326884]
2023-05-21 19:21:07.598: epoch 18:	0.07001883  	0.13460036  	0.13458757  
2023-05-21 19:21:07.598: Find a better model.
2023-05-21 19:21:45.428: [iter 19 : loss : 1.5461 = 0.6232 + 0.9225 + 0.0005, time: 37.820272]
2023-05-21 19:21:45.856: epoch 19:	0.07695334  	0.14609878  	0.14731084  
2023-05-21 19:21:45.857: Find a better model.
2023-05-21 19:22:23.791: [iter 20 : loss : 1.4986 = 0.5696 + 0.9282 + 0.0008, time: 37.928531]
2023-05-21 19:22:24.219: epoch 20:	0.08108944  	0.15377019  	0.15489012  
2023-05-21 19:22:24.219: Find a better model.
2023-05-21 19:23:02.497: [iter 21 : loss : 1.4419 = 0.5060 + 0.9346 + 0.0012, time: 38.265637]
2023-05-21 19:23:03.080: epoch 21:	0.08330795  	0.15816900  	0.15829144  
2023-05-21 19:23:03.080: Find a better model.
2023-05-21 19:23:47.755: [iter 22 : loss : 1.3856 = 0.4440 + 0.9399 + 0.0017, time: 44.669034]
2023-05-21 19:23:48.335: epoch 22:	0.08446285  	0.16020183  	0.16025338  
2023-05-21 19:23:48.336: Find a better model.
2023-05-21 19:24:33.541: [iter 23 : loss : 1.3364 = 0.3907 + 0.9434 + 0.0022, time: 45.193851]
2023-05-21 19:24:34.122: epoch 23:	0.08534922  	0.16250984  	0.16198391  
2023-05-21 19:24:34.122: Find a better model.
2023-05-21 19:25:18.965: [iter 24 : loss : 1.2944 = 0.3462 + 0.9454 + 0.0028, time: 44.831435]
2023-05-21 19:25:19.550: epoch 24:	0.08590794  	0.16386168  	0.16300134  
2023-05-21 19:25:19.550: Find a better model.
2023-05-21 19:26:04.530: [iter 25 : loss : 1.2596 = 0.3105 + 0.9459 + 0.0032, time: 44.967772]
2023-05-21 19:26:05.100: epoch 25:	0.08637521  	0.16463389  	0.16357110  
2023-05-21 19:26:05.100: Find a better model.
2023-05-21 19:26:50.244: [iter 26 : loss : 1.2297 = 0.2802 + 0.9457 + 0.0037, time: 45.137613]
2023-05-21 19:26:50.681: epoch 26:	0.08689085  	0.16518141  	0.16402803  
2023-05-21 19:26:50.681: Find a better model.
2023-05-21 19:27:35.645: [iter 27 : loss : 1.2047 = 0.2553 + 0.9452 + 0.0041, time: 44.954595]
2023-05-21 19:27:36.251: epoch 27:	0.08716474  	0.16582148  	0.16428052  
2023-05-21 19:27:36.251: Find a better model.
2023-05-21 19:28:21.326: [iter 28 : loss : 1.1835 = 0.2344 + 0.9445 + 0.0046, time: 45.062711]
2023-05-21 19:28:21.902: epoch 28:	0.08717013  	0.16559471  	0.16407152  
2023-05-21 19:29:06.696: [iter 29 : loss : 1.1654 = 0.2170 + 0.9434 + 0.0050, time: 44.787116]
2023-05-21 19:29:07.258: epoch 29:	0.08708963  	0.16546139  	0.16397585  
2023-05-21 19:29:52.567: [iter 30 : loss : 1.1492 = 0.2015 + 0.9424 + 0.0053, time: 45.301882]
2023-05-21 19:29:53.146: epoch 30:	0.08703046  	0.16530947  	0.16373484  
2023-05-21 19:30:38.385: [iter 31 : loss : 1.1348 = 0.1878 + 0.9414 + 0.0057, time: 45.229744]
2023-05-21 19:30:38.902: epoch 31:	0.08706816  	0.16502452  	0.16336372  
2023-05-21 19:31:24.229: [iter 32 : loss : 1.1231 = 0.1767 + 0.9403 + 0.0061, time: 45.319840]
2023-05-21 19:31:24.808: epoch 32:	0.08710576  	0.16483556  	0.16320953  
2023-05-21 19:32:10.053: [iter 33 : loss : 1.1118 = 0.1659 + 0.9395 + 0.0064, time: 45.231706]
2023-05-21 19:32:10.618: epoch 33:	0.08707353  	0.16431931  	0.16268140  
2023-05-21 19:32:55.662: [iter 34 : loss : 1.1029 = 0.1576 + 0.9385 + 0.0068, time: 45.027876]
2023-05-21 19:32:56.260: epoch 34:	0.08695541  	0.16420111  	0.16241238  
2023-05-21 19:33:41.701: [iter 35 : loss : 1.0937 = 0.1489 + 0.9378 + 0.0071, time: 45.432716]
2023-05-21 19:33:42.299: epoch 35:	0.08706285  	0.16386713  	0.16205117  
2023-05-21 19:34:27.385: [iter 36 : loss : 1.0861 = 0.1418 + 0.9368 + 0.0074, time: 45.077084]
2023-05-21 19:34:27.962: epoch 36:	0.08663846  	0.16322656  	0.16139477  
2023-05-21 19:35:13.366: [iter 37 : loss : 1.0787 = 0.1350 + 0.9360 + 0.0077, time: 45.389223]
2023-05-21 19:35:13.961: epoch 37:	0.08659548  	0.16255774  	0.16081421  
2023-05-21 19:35:58.854: [iter 38 : loss : 1.0722 = 0.1290 + 0.9352 + 0.0080, time: 44.886119]
2023-05-21 19:35:59.427: epoch 38:	0.08665457  	0.16234161  	0.16043298  
2023-05-21 19:36:45.001: [iter 39 : loss : 1.0665 = 0.1237 + 0.9345 + 0.0082, time: 45.566320]
2023-05-21 19:36:45.588: epoch 39:	0.08649871  	0.16168718  	0.15984024  
2023-05-21 19:37:31.700: [iter 40 : loss : 1.0616 = 0.1192 + 0.9339 + 0.0085, time: 46.104798]
2023-05-21 19:37:32.260: epoch 40:	0.08629993  	0.16079073  	0.15920271  
2023-05-21 19:38:18.374: [iter 41 : loss : 1.0560 = 0.1140 + 0.9332 + 0.0088, time: 46.097631]
2023-05-21 19:38:18.953: epoch 41:	0.08609589  	0.16016929  	0.15857647  
2023-05-21 19:39:36.610: my pid: 12848
2023-05-21 19:39:36.610: model: model.general_recommender.SGL
2023-05-21 19:39:36.610: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-21 19:39:36.610: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-21 19:39:42.293: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-21 19:40:25.085: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 42.782720]
2023-05-21 19:40:25.677: epoch 1:	0.00299741  	0.00738922  	0.00575289  
2023-05-21 19:40:25.677: Find a better model.
2023-05-21 19:41:07.456: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 41.773113]
2023-05-21 19:41:07.971: epoch 2:	0.00409860  	0.00935637  	0.00772496  
2023-05-21 19:41:07.971: Find a better model.
2023-05-21 19:41:43.469: [iter 3 : loss : 1.6076 = 0.6930 + 0.9146 + 0.0000, time: 35.491083]
2023-05-21 19:41:43.875: epoch 3:	0.00466800  	0.00979553  	0.00848747  
2023-05-21 19:41:43.875: Find a better model.
2023-05-21 19:42:18.822: [iter 4 : loss : 1.6078 = 0.6930 + 0.9149 + 0.0000, time: 34.941449]
2023-05-21 19:42:19.278: epoch 4:	0.00483989  	0.01042520  	0.00878581  
2023-05-21 19:42:19.278: Find a better model.
2023-05-21 19:42:54.401: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 35.116286]
2023-05-21 19:42:54.801: epoch 5:	0.00557043  	0.01193158  	0.01004153  
2023-05-21 19:42:54.801: Find a better model.
2023-05-21 19:43:30.030: [iter 6 : loss : 1.6082 = 0.6928 + 0.9154 + 0.0000, time: 35.223597]
2023-05-21 19:43:30.446: epoch 6:	0.00626338  	0.01217524  	0.01071642  
2023-05-21 19:43:30.446: Find a better model.
2023-05-21 19:44:05.557: [iter 7 : loss : 1.6085 = 0.6927 + 0.9157 + 0.0000, time: 35.101871]
2023-05-21 19:44:05.960: epoch 7:	0.00728401  	0.01418152  	0.01274701  
2023-05-21 19:44:05.960: Find a better model.
2023-05-21 19:44:41.154: [iter 8 : loss : 1.6085 = 0.6926 + 0.9158 + 0.0000, time: 35.186780]
2023-05-21 19:44:41.567: epoch 8:	0.00805757  	0.01563041  	0.01453470  
2023-05-21 19:44:41.567: Find a better model.
2023-05-21 19:45:16.707: [iter 9 : loss : 1.6087 = 0.6924 + 0.9163 + 0.0000, time: 35.133325]
2023-05-21 19:45:17.105: epoch 9:	0.00979807  	0.01908716  	0.01759563  
2023-05-21 19:45:17.105: Find a better model.
2023-05-21 19:45:52.358: [iter 10 : loss : 1.6087 = 0.6922 + 0.9165 + 0.0000, time: 35.246879]
2023-05-21 19:45:52.756: epoch 10:	0.01166748  	0.02217755  	0.02074117  
2023-05-21 19:45:52.756: Find a better model.
2023-05-21 19:46:27.927: [iter 11 : loss : 1.6086 = 0.6919 + 0.9167 + 0.0000, time: 35.163868]
2023-05-21 19:46:28.354: epoch 11:	0.01367118  	0.02701039  	0.02538692  
2023-05-21 19:46:28.354: Find a better model.
2023-05-21 19:47:03.451: [iter 12 : loss : 1.6086 = 0.6914 + 0.9171 + 0.0000, time: 35.090907]
2023-05-21 19:47:03.872: epoch 12:	0.01675466  	0.03266034  	0.03119988  
2023-05-21 19:47:03.873: Find a better model.
2023-05-21 19:47:39.087: [iter 13 : loss : 1.6085 = 0.6908 + 0.9177 + 0.0000, time: 35.206635]
2023-05-21 19:47:39.499: epoch 13:	0.02068689  	0.04158856  	0.03980047  
2023-05-21 19:47:39.499: Find a better model.
2023-05-21 19:48:14.729: [iter 14 : loss : 1.6080 = 0.6897 + 0.9183 + 0.0000, time: 35.222856]
2023-05-21 19:48:15.130: epoch 14:	0.02686451  	0.05353881  	0.05188674  
2023-05-21 19:48:15.130: Find a better model.
2023-05-21 19:48:50.278: [iter 15 : loss : 1.6069 = 0.6878 + 0.9191 + 0.0001, time: 35.142545]
2023-05-21 19:48:50.676: epoch 15:	0.03544254  	0.06971268  	0.06886489  
2023-05-21 19:48:50.676: Find a better model.
2023-05-21 19:49:25.840: [iter 16 : loss : 1.6046 = 0.6842 + 0.9204 + 0.0001, time: 35.157001]
2023-05-21 19:49:26.267: epoch 16:	0.04609960  	0.08878956  	0.08869868  
2023-05-21 19:49:26.268: Find a better model.
2023-05-21 19:50:01.524: [iter 17 : loss : 1.5990 = 0.6767 + 0.9222 + 0.0001, time: 35.249985]
2023-05-21 19:50:01.927: epoch 17:	0.05827677  	0.11123896  	0.11081914  
2023-05-21 19:50:01.927: Find a better model.
2023-05-21 19:50:37.276: [iter 18 : loss : 1.5863 = 0.6609 + 0.9252 + 0.0003, time: 35.342250]
2023-05-21 19:50:37.681: epoch 18:	0.06935822  	0.13075639  	0.13125518  
2023-05-21 19:50:37.681: Find a better model.
2023-05-21 19:51:12.989: [iter 19 : loss : 1.5600 = 0.6298 + 0.9298 + 0.0005, time: 35.302039]
2023-05-21 19:51:13.414: epoch 19:	0.07629297  	0.14330590  	0.14407004  
2023-05-21 19:51:13.414: Find a better model.
2023-05-21 19:51:48.659: [iter 20 : loss : 1.5179 = 0.5812 + 0.9360 + 0.0008, time: 35.238747]
2023-05-21 19:51:49.079: epoch 20:	0.08024097  	0.15071937  	0.15092884  
2023-05-21 19:51:49.079: Find a better model.
2023-05-21 19:52:24.223: [iter 21 : loss : 1.4649 = 0.5207 + 0.9430 + 0.0012, time: 35.136625]
2023-05-21 19:52:24.625: epoch 21:	0.08227137  	0.15489592  	0.15502350  
2023-05-21 19:52:24.625: Find a better model.
2023-05-21 19:52:59.934: [iter 22 : loss : 1.4098 = 0.4594 + 0.9487 + 0.0017, time: 35.302293]
2023-05-21 19:53:00.334: epoch 22:	0.08391501  	0.15824236  	0.15781561  
2023-05-21 19:53:00.334: Find a better model.
2023-05-21 19:53:35.494: [iter 23 : loss : 1.3600 = 0.4051 + 0.9527 + 0.0022, time: 35.152933]
2023-05-21 19:53:35.916: epoch 23:	0.08483881  	0.15998891  	0.15977868  
2023-05-21 19:53:35.916: Find a better model.
2023-05-21 19:54:11.193: [iter 24 : loss : 1.3166 = 0.3591 + 0.9548 + 0.0027, time: 35.269290]
2023-05-21 19:54:11.600: epoch 24:	0.08560686  	0.16202915  	0.16126117  
2023-05-21 19:54:11.600: Find a better model.
2023-05-21 19:54:46.776: [iter 25 : loss : 1.2803 = 0.3217 + 0.9555 + 0.0031, time: 35.170357]
2023-05-21 19:54:47.176: epoch 25:	0.08640721  	0.16404895  	0.16237041  
2023-05-21 19:54:47.176: Find a better model.
2023-05-21 19:55:22.540: [iter 26 : loss : 1.2490 = 0.2900 + 0.9555 + 0.0036, time: 35.357535]
2023-05-21 19:55:22.960: epoch 26:	0.08689068  	0.16482788  	0.16319166  
2023-05-21 19:55:22.961: Find a better model.
2023-05-21 19:55:58.273: [iter 27 : loss : 1.2226 = 0.2637 + 0.9548 + 0.0041, time: 35.306036]
2023-05-21 19:55:58.677: epoch 27:	0.08712703  	0.16526805  	0.16350287  
2023-05-21 19:55:58.677: Find a better model.
2023-05-21 19:56:33.787: [iter 28 : loss : 1.2002 = 0.2416 + 0.9541 + 0.0045, time: 35.104527]
2023-05-21 19:56:34.180: epoch 28:	0.08683703  	0.16506423  	0.16320074  
2023-05-21 19:57:09.497: [iter 29 : loss : 1.1808 = 0.2230 + 0.9529 + 0.0049, time: 35.310306]
2023-05-21 19:57:09.890: epoch 29:	0.08702504  	0.16556594  	0.16327901  
2023-05-21 19:57:09.890: Find a better model.
2023-05-21 19:57:45.238: [iter 30 : loss : 1.1638 = 0.2068 + 0.9517 + 0.0053, time: 35.342485]
2023-05-21 19:57:45.647: epoch 30:	0.08733663  	0.16594251  	0.16324197  
2023-05-21 19:57:45.648: Find a better model.
2023-05-21 19:58:21.076: [iter 31 : loss : 1.1487 = 0.1924 + 0.9507 + 0.0057, time: 35.421749]
2023-05-21 19:58:21.491: epoch 31:	0.08739026  	0.16608123  	0.16314000  
2023-05-21 19:58:21.491: Find a better model.
2023-05-21 19:58:57.015: [iter 32 : loss : 1.1363 = 0.1807 + 0.9496 + 0.0060, time: 35.517807]
2023-05-21 19:58:57.434: epoch 32:	0.08715398  	0.16516005  	0.16253285  
2023-05-21 19:59:33.014: [iter 33 : loss : 1.1245 = 0.1696 + 0.9486 + 0.0064, time: 35.573443]
2023-05-21 19:59:33.426: epoch 33:	0.08721309  	0.16530466  	0.16252518  
2023-05-21 20:00:08.827: [iter 34 : loss : 1.1150 = 0.1607 + 0.9476 + 0.0067, time: 35.389119]
2023-05-21 20:00:09.245: epoch 34:	0.08683176  	0.16439031  	0.16187996  
2023-05-21 20:00:44.797: [iter 35 : loss : 1.1052 = 0.1514 + 0.9468 + 0.0070, time: 35.545299]
2023-05-21 20:00:45.194: epoch 35:	0.08669746  	0.16365609  	0.16137433  
2023-05-21 20:01:20.826: [iter 36 : loss : 1.0973 = 0.1441 + 0.9458 + 0.0073, time: 35.625066]
2023-05-21 20:01:21.248: epoch 36:	0.08639675  	0.16326918  	0.16111036  
2023-05-21 20:01:56.647: [iter 37 : loss : 1.0893 = 0.1369 + 0.9448 + 0.0076, time: 35.391473]
2023-05-21 20:01:57.066: epoch 37:	0.08642894  	0.16291851  	0.16073854  
2023-05-21 20:02:32.629: [iter 38 : loss : 1.0828 = 0.1309 + 0.9440 + 0.0079, time: 35.556935]
2023-05-21 20:02:33.049: epoch 38:	0.08617114  	0.16221298  	0.15999444  
2023-05-21 20:03:08.407: [iter 39 : loss : 1.0771 = 0.1257 + 0.9432 + 0.0082, time: 35.350586]
2023-05-21 20:03:08.807: epoch 39:	0.08620873  	0.16197051  	0.15965417  
2023-05-21 20:03:44.353: [iter 40 : loss : 1.0717 = 0.1207 + 0.9425 + 0.0085, time: 35.538857]
2023-05-21 20:03:44.762: epoch 40:	0.08590791  	0.16110064  	0.15901235  
2023-05-21 20:04:20.178: [iter 41 : loss : 1.0666 = 0.1160 + 0.9418 + 0.0087, time: 35.410628]
2023-05-21 20:04:20.622: epoch 41:	0.08584338  	0.16054450  	0.15866005  
2023-05-21 20:04:56.151: [iter 42 : loss : 1.0617 = 0.1115 + 0.9412 + 0.0090, time: 35.521655]
2023-05-21 20:04:56.598: epoch 42:	0.08556946  	0.15965861  	0.15799651  
2023-05-21 20:05:32.359: [iter 43 : loss : 1.0571 = 0.1072 + 0.9407 + 0.0092, time: 35.752671]
2023-05-21 20:05:32.826: epoch 43:	0.08540292  	0.15886177  	0.15764320  
2023-05-21 20:06:07.931: [iter 44 : loss : 1.0533 = 0.1036 + 0.9402 + 0.0095, time: 35.096889]
2023-05-21 20:06:08.329: epoch 44:	0.08521496  	0.15802084  	0.15693939  
2023-05-21 20:06:43.877: [iter 45 : loss : 1.0502 = 0.1009 + 0.9396 + 0.0097, time: 35.540401]
2023-05-21 20:06:44.301: epoch 45:	0.08490346  	0.15736237  	0.15626788  
2023-05-21 20:07:19.941: [iter 46 : loss : 1.0463 = 0.0972 + 0.9392 + 0.0099, time: 35.633873]
2023-05-21 20:07:20.338: epoch 46:	0.08473156  	0.15688871  	0.15566923  
2023-05-21 20:07:56.062: [iter 47 : loss : 1.0433 = 0.0946 + 0.9386 + 0.0101, time: 35.717416]
2023-05-21 20:07:56.460: epoch 47:	0.08449519  	0.15587486  	0.15489773  
2023-05-21 20:08:32.298: [iter 48 : loss : 1.0402 = 0.0916 + 0.9382 + 0.0104, time: 35.832366]
2023-05-21 20:08:32.721: epoch 48:	0.08419980  	0.15522541  	0.15430601  
2023-05-21 20:09:08.651: [iter 49 : loss : 1.0374 = 0.0890 + 0.9378 + 0.0106, time: 35.923573]
2023-05-21 20:09:09.051: epoch 49:	0.08412453  	0.15487814  	0.15370102  
2023-05-21 20:09:44.858: [iter 50 : loss : 1.0348 = 0.0866 + 0.9374 + 0.0108, time: 35.799325]
2023-05-21 20:09:45.251: epoch 50:	0.08396338  	0.15402566  	0.15307397  
2023-05-21 20:10:21.270: [iter 51 : loss : 1.0325 = 0.0844 + 0.9371 + 0.0110, time: 36.012574]
2023-05-21 20:10:21.665: epoch 51:	0.08368404  	0.15330306  	0.15250495  
2023-05-21 20:10:57.631: [iter 52 : loss : 1.0303 = 0.0824 + 0.9368 + 0.0111, time: 35.959240]
2023-05-21 20:10:58.033: epoch 52:	0.08349068  	0.15267380  	0.15175992  
2023-05-21 20:11:33.963: [iter 53 : loss : 1.0279 = 0.0802 + 0.9364 + 0.0113, time: 35.923167]
2023-05-21 20:11:34.389: epoch 53:	0.08327043  	0.15166593  	0.15109271  
2023-05-21 20:12:10.226: [iter 54 : loss : 1.0256 = 0.0779 + 0.9361 + 0.0115, time: 35.830056]
2023-05-21 20:12:10.622: epoch 54:	0.08293200  	0.15107936  	0.15051208  
2023-05-21 20:12:46.557: [iter 55 : loss : 1.0239 = 0.0764 + 0.9358 + 0.0117, time: 35.928416]
2023-05-21 20:12:46.970: epoch 55:	0.08263656  	0.15019202  	0.14981857  
2023-05-21 20:13:22.521: [iter 56 : loss : 1.0222 = 0.0748 + 0.9356 + 0.0119, time: 35.543063]
2023-05-21 20:13:22.941: epoch 56:	0.08250766  	0.14951694  	0.14931759  
2023-05-21 20:13:22.941: Early stopping is trigger at epoch: 56
2023-05-21 20:13:22.941: best_result@epoch 31:

2023-05-21 20:13:22.941: 		0.0874      	0.1661      	0.1631      
2023-05-22 09:19:50.104: my pid: 11164
2023-05-22 09:19:50.104: model: model.general_recommender.SGL
2023-05-22 09:19:50.104: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-22 09:19:50.104: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-22 09:19:54.925: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-22 09:20:31.614: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 36.687877]
2023-05-22 09:20:32.012: epoch 1:	0.00334120  	0.00786280  	0.00649008  
2023-05-22 09:20:32.012: Find a better model.
2023-05-22 09:21:08.576: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 36.557873]
2023-05-22 09:21:08.998: epoch 2:	0.00408786  	0.00917887  	0.00794192  
2023-05-22 09:21:08.999: Find a better model.
2023-05-22 09:21:45.835: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 36.829732]
2023-05-22 09:21:46.232: epoch 3:	0.00501178  	0.01059719  	0.00915547  
2023-05-22 09:21:46.232: Find a better model.
2023-05-22 09:22:22.724: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 36.485834]
2023-05-22 09:22:23.123: epoch 4:	0.00530722  	0.01041653  	0.00926671  
2023-05-22 09:22:59.562: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 36.432092]
2023-05-22 09:22:59.989: epoch 5:	0.00644601  	0.01356702  	0.01114095  
2023-05-22 09:22:59.990: Find a better model.
2023-05-22 09:23:36.561: [iter 6 : loss : 1.6068 = 0.6929 + 0.9139 + 0.0000, time: 36.565368]
2023-05-22 09:23:36.966: epoch 6:	0.00707451  	0.01428248  	0.01281583  
2023-05-22 09:23:36.966: Find a better model.
2023-05-22 09:24:13.608: [iter 7 : loss : 1.6068 = 0.6928 + 0.9141 + 0.0000, time: 36.634786]
2023-05-22 09:24:14.038: epoch 7:	0.00821874  	0.01526398  	0.01421783  
2023-05-22 09:24:14.038: Find a better model.
2023-05-22 09:24:50.847: [iter 8 : loss : 1.6068 = 0.6926 + 0.9141 + 0.0000, time: 36.802804]
2023-05-22 09:24:51.271: epoch 8:	0.00947039  	0.01825008  	0.01656322  
2023-05-22 09:24:51.271: Find a better model.
2023-05-22 09:25:27.770: [iter 9 : loss : 1.6069 = 0.6925 + 0.9144 + 0.0000, time: 36.490991]
2023-05-22 09:25:28.170: epoch 9:	0.01135055  	0.02111777  	0.01930680  
2023-05-22 09:25:28.171: Find a better model.
2023-05-22 09:26:04.766: [iter 10 : loss : 1.6069 = 0.6923 + 0.9146 + 0.0000, time: 36.588890]
2023-05-22 09:26:05.188: epoch 10:	0.01266127  	0.02436149  	0.02207644  
2023-05-22 09:26:05.188: Find a better model.
2023-05-22 09:26:41.675: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 36.481066]
2023-05-22 09:26:42.074: epoch 11:	0.01535798  	0.03025255  	0.02806907  
2023-05-22 09:26:42.075: Find a better model.
2023-05-22 09:27:18.678: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 36.597746]
2023-05-22 09:27:19.078: epoch 12:	0.01844682  	0.03588342  	0.03370643  
2023-05-22 09:27:19.079: Find a better model.
2023-05-22 09:27:55.689: [iter 13 : loss : 1.6063 = 0.6909 + 0.9154 + 0.0000, time: 36.603559]
2023-05-22 09:27:56.108: epoch 13:	0.02211043  	0.04442263  	0.04252813  
2023-05-22 09:27:56.108: Find a better model.
2023-05-22 09:28:32.774: [iter 14 : loss : 1.6057 = 0.6898 + 0.9158 + 0.0000, time: 36.659962]
2023-05-22 09:28:33.176: epoch 14:	0.02840076  	0.05756029  	0.05596591  
2023-05-22 09:28:33.176: Find a better model.
2023-05-22 09:29:09.818: [iter 15 : loss : 1.6045 = 0.6879 + 0.9165 + 0.0001, time: 36.635991]
2023-05-22 09:29:10.213: epoch 15:	0.03693041  	0.07369842  	0.07212353  
2023-05-22 09:29:10.213: Find a better model.
2023-05-22 09:29:46.716: [iter 16 : loss : 1.6017 = 0.6841 + 0.9175 + 0.0001, time: 36.496747]
2023-05-22 09:29:47.139: epoch 16:	0.04766275  	0.09303214  	0.09225933  
2023-05-22 09:29:47.139: Find a better model.
2023-05-22 09:30:23.887: [iter 17 : loss : 1.5952 = 0.6761 + 0.9190 + 0.0001, time: 36.741793]
2023-05-22 09:30:24.308: epoch 17:	0.05888384  	0.11288106  	0.11363865  
2023-05-22 09:30:24.309: Find a better model.
2023-05-22 09:31:00.830: [iter 18 : loss : 1.5806 = 0.6586 + 0.9218 + 0.0003, time: 36.515212]
2023-05-22 09:31:01.221: epoch 18:	0.06946029  	0.13090701  	0.13224483  
2023-05-22 09:31:01.221: Find a better model.
2023-05-22 09:31:37.806: [iter 19 : loss : 1.5513 = 0.6248 + 0.9260 + 0.0005, time: 36.577863]
2023-05-22 09:31:38.200: epoch 19:	0.07656673  	0.14404297  	0.14582571  
2023-05-22 09:31:38.200: Find a better model.
2023-05-22 09:32:14.794: [iter 20 : loss : 1.5062 = 0.5736 + 0.9318 + 0.0008, time: 36.587110]
2023-05-22 09:32:15.187: epoch 20:	0.08031064  	0.15077154  	0.15246323  
2023-05-22 09:32:15.187: Find a better model.
2023-05-22 09:32:51.847: [iter 21 : loss : 1.4514 = 0.5120 + 0.9382 + 0.0012, time: 36.652272]
2023-05-22 09:32:52.267: epoch 21:	0.08298022  	0.15551414  	0.15658815  
2023-05-22 09:32:52.267: Find a better model.
2023-05-22 09:33:28.987: [iter 22 : loss : 1.3960 = 0.4507 + 0.9435 + 0.0017, time: 36.714153]
2023-05-22 09:33:29.379: epoch 22:	0.08415132  	0.15831879  	0.15872397  
2023-05-22 09:33:29.379: Find a better model.
2023-05-22 09:34:06.165: [iter 23 : loss : 1.3467 = 0.3973 + 0.9472 + 0.0022, time: 36.779901]
2023-05-22 09:34:06.581: epoch 23:	0.08525782  	0.16039127  	0.16057119  
2023-05-22 09:34:06.581: Find a better model.
2023-05-22 09:34:43.165: [iter 24 : loss : 1.3041 = 0.3521 + 0.9492 + 0.0027, time: 36.577800]
2023-05-22 09:34:43.561: epoch 24:	0.08605828  	0.16219157  	0.16198948  
2023-05-22 09:34:43.561: Find a better model.
2023-05-22 09:35:20.227: [iter 25 : loss : 1.2686 = 0.3156 + 0.9498 + 0.0032, time: 36.660458]
2023-05-22 09:35:20.619: epoch 25:	0.08677796  	0.16348539  	0.16300824  
2023-05-22 09:35:20.619: Find a better model.
2023-05-22 09:35:57.301: [iter 26 : loss : 1.2381 = 0.2846 + 0.9498 + 0.0037, time: 36.674937]
2023-05-22 09:35:57.695: epoch 26:	0.08705731  	0.16403252  	0.16333599  
2023-05-22 09:35:57.695: Find a better model.
2023-05-22 09:36:34.091: [iter 27 : loss : 1.2124 = 0.2590 + 0.9493 + 0.0041, time: 36.389512]
2023-05-22 09:36:34.486: epoch 27:	0.08719165  	0.16471346  	0.16355485  
2023-05-22 09:36:34.486: Find a better model.
2023-05-22 09:37:11.339: [iter 28 : loss : 1.1905 = 0.2374 + 0.9486 + 0.0045, time: 36.847784]
2023-05-22 09:37:11.762: epoch 28:	0.08742802  	0.16529767  	0.16386983  
2023-05-22 09:37:11.762: Find a better model.
2023-05-22 09:37:49.232: [iter 29 : loss : 1.1720 = 0.2196 + 0.9475 + 0.0049, time: 37.451379]
2023-05-22 09:37:49.647: epoch 29:	0.08748709  	0.16515754  	0.16379465  
2023-05-22 09:38:26.708: [iter 30 : loss : 1.1555 = 0.2037 + 0.9464 + 0.0053, time: 37.053763]
2023-05-22 09:38:27.119: epoch 30:	0.08745488  	0.16518328  	0.16368380  
2023-05-22 09:39:04.987: [iter 31 : loss : 1.1409 = 0.1897 + 0.9455 + 0.0057, time: 37.860765]
2023-05-22 09:39:05.381: epoch 31:	0.08742802  	0.16493639  	0.16343102  
2023-05-22 09:39:48.633: [iter 32 : loss : 1.1287 = 0.1782 + 0.9445 + 0.0061, time: 43.246392]
2023-05-22 09:39:49.216: epoch 32:	0.08725080  	0.16482811  	0.16283976  
2023-05-22 09:40:32.628: [iter 33 : loss : 1.1172 = 0.1673 + 0.9435 + 0.0064, time: 43.403730]
2023-05-22 09:40:33.220: epoch 33:	0.08713258  	0.16467927  	0.16245177  
2023-05-22 09:41:17.070: [iter 34 : loss : 1.1081 = 0.1589 + 0.9425 + 0.0067, time: 43.840183]
2023-05-22 09:41:17.648: epoch 34:	0.08714338  	0.16420974  	0.16196536  
2023-05-22 09:42:01.097: [iter 35 : loss : 1.0983 = 0.1496 + 0.9417 + 0.0071, time: 43.440969]
2023-05-22 09:42:01.698: epoch 35:	0.08697682  	0.16356289  	0.16149174  
2023-05-22 09:42:45.577: [iter 36 : loss : 1.0908 = 0.1427 + 0.9408 + 0.0074, time: 43.869921]
2023-05-22 09:42:46.176: epoch 36:	0.08671360  	0.16301601  	0.16095072  
2023-05-22 09:43:29.593: [iter 37 : loss : 1.0832 = 0.1357 + 0.9399 + 0.0077, time: 43.410776]
2023-05-22 09:43:30.212: epoch 37:	0.08666521  	0.16262779  	0.16068351  
2023-05-22 09:44:13.910: [iter 38 : loss : 1.0768 = 0.1297 + 0.9391 + 0.0079, time: 43.690327]
2023-05-22 09:44:14.491: epoch 38:	0.08660077  	0.16189121  	0.16014254  
2023-05-22 09:44:58.174: [iter 39 : loss : 1.0711 = 0.1245 + 0.9384 + 0.0082, time: 43.677305]
2023-05-22 09:44:58.721: epoch 39:	0.08642887  	0.16103011  	0.15963098  
2023-05-22 09:45:42.366: [iter 40 : loss : 1.0660 = 0.1198 + 0.9377 + 0.0085, time: 43.636161]
2023-05-22 09:45:42.949: epoch 40:	0.08602600  	0.16026643  	0.15878028  
2023-05-22 09:46:26.811: [iter 41 : loss : 1.0606 = 0.1148 + 0.9371 + 0.0087, time: 43.854322]
2023-05-22 09:46:27.277: epoch 41:	0.08590243  	0.15926921  	0.15818368  
2023-05-22 09:47:11.173: [iter 42 : loss : 1.0560 = 0.1106 + 0.9365 + 0.0090, time: 43.884398]
2023-05-22 09:47:11.761: epoch 42:	0.08558014  	0.15830238  	0.15738530  
2023-05-22 09:47:55.372: [iter 43 : loss : 1.0513 = 0.1061 + 0.9359 + 0.0092, time: 43.601370]
2023-05-22 09:47:55.957: epoch 43:	0.08532772  	0.15780234  	0.15693386  
2023-05-22 09:48:39.756: [iter 44 : loss : 1.0477 = 0.1028 + 0.9354 + 0.0095, time: 43.792227]
2023-05-22 09:48:40.318: epoch 44:	0.08517732  	0.15738791  	0.15645348  
2023-05-22 09:49:24.146: [iter 45 : loss : 1.0449 = 0.1003 + 0.9349 + 0.0097, time: 43.818684]
2023-05-22 09:49:24.720: epoch 45:	0.08500541  	0.15657960  	0.15584694  
2023-05-22 09:50:08.196: [iter 46 : loss : 1.0410 = 0.0966 + 0.9345 + 0.0099, time: 43.469731]
2023-05-22 09:50:08.773: epoch 46:	0.08480136  	0.15600547  	0.15540877  
2023-05-22 09:50:52.709: [iter 47 : loss : 1.0379 = 0.0938 + 0.9339 + 0.0102, time: 43.923970]
2023-05-22 09:50:53.291: epoch 47:	0.08432868  	0.15462469  	0.15443468  
2023-05-22 09:51:36.813: [iter 48 : loss : 1.0346 = 0.0907 + 0.9335 + 0.0104, time: 43.514818]
2023-05-22 09:51:37.390: epoch 48:	0.08432870  	0.15436271  	0.15408869  
2023-05-22 09:52:21.351: [iter 49 : loss : 1.0322 = 0.0884 + 0.9331 + 0.0106, time: 43.950837]
2023-05-22 09:52:21.939: epoch 49:	0.08398498  	0.15365297  	0.15333806  
2023-05-22 09:53:34.520: my pid: 4236
2023-05-22 09:53:34.520: model: model.general_recommender.SGL
2023-05-22 09:53:34.520: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-22 09:53:34.520: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-22 09:53:39.517: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-22 09:54:23.171: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 43.654094]
2023-05-22 09:54:23.809: epoch 1:	0.00358829  	0.00830876  	0.00670722  
2023-05-22 09:54:23.809: Find a better model.
2023-05-22 09:55:10.497: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 46.680916]
2023-05-22 09:55:11.124: epoch 2:	0.00417380  	0.00889647  	0.00746856  
2023-05-22 09:55:11.124: Find a better model.
2023-05-22 09:55:57.820: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 46.687884]
2023-05-22 09:55:58.444: epoch 3:	0.00552746  	0.01157317  	0.00982668  
2023-05-22 09:55:58.444: Find a better model.
2023-05-22 09:56:45.187: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 46.734593]
2023-05-22 09:56:45.831: epoch 4:	0.00615594  	0.01191790  	0.01082346  
2023-05-22 09:56:45.831: Find a better model.
2023-05-22 09:57:32.775: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 46.937317]
2023-05-22 09:57:33.411: epoch 5:	0.00741294  	0.01436540  	0.01297462  
2023-05-22 09:57:33.411: Find a better model.
2023-05-22 09:58:20.230: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 46.806821]
2023-05-22 09:58:20.843: epoch 6:	0.00893856  	0.01705313  	0.01519196  
2023-05-22 09:58:20.843: Find a better model.
2023-05-22 09:59:07.512: [iter 7 : loss : 1.6045 = 0.6928 + 0.9117 + 0.0000, time: 46.651438]
2023-05-22 09:59:08.168: epoch 7:	0.00976584  	0.01857428  	0.01721251  
2023-05-22 09:59:08.168: Find a better model.
2023-05-22 09:59:54.619: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 46.442942]
2023-05-22 09:59:55.265: epoch 8:	0.01088856  	0.02064012  	0.01905265  
2023-05-22 09:59:55.265: Find a better model.
2023-05-22 10:00:41.606: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 46.329217]
2023-05-22 10:00:42.243: epoch 9:	0.01211335  	0.02331987  	0.02203610  
2023-05-22 10:00:42.243: Find a better model.
2023-05-22 10:01:28.308: [iter 10 : loss : 1.6041 = 0.6922 + 0.9118 + 0.0000, time: 46.055140]
2023-05-22 10:01:28.952: epoch 10:	0.01406871  	0.02709178  	0.02555448  
2023-05-22 10:01:28.952: Find a better model.
2023-05-22 10:02:15.208: [iter 11 : loss : 1.6038 = 0.6919 + 0.9118 + 0.0000, time: 46.248667]
2023-05-22 10:02:15.796: epoch 11:	0.01656130  	0.03331491  	0.03118905  
2023-05-22 10:02:15.797: Find a better model.
2023-05-22 10:03:02.302: [iter 12 : loss : 1.6035 = 0.6914 + 0.9120 + 0.0000, time: 46.499065]
2023-05-22 10:03:02.747: epoch 12:	0.01986500  	0.04023784  	0.03854181  
2023-05-22 10:03:02.748: Find a better model.
2023-05-22 10:03:49.560: [iter 13 : loss : 1.6029 = 0.6907 + 0.9122 + 0.0000, time: 46.805412]
2023-05-22 10:03:50.067: epoch 13:	0.02359846  	0.04884685  	0.04653793  
2023-05-22 10:03:50.067: Find a better model.
2023-05-22 10:04:36.978: [iter 14 : loss : 1.6018 = 0.6893 + 0.9124 + 0.0000, time: 46.897938]
2023-05-22 10:04:37.574: epoch 14:	0.02997995  	0.06369454  	0.06013818  
2023-05-22 10:04:37.574: Find a better model.
2023-05-22 10:05:24.585: [iter 15 : loss : 1.5997 = 0.6868 + 0.9128 + 0.0001, time: 46.995578]
2023-05-22 10:05:25.222: epoch 15:	0.03791875  	0.07902350  	0.07642375  
2023-05-22 10:05:25.222: Find a better model.
2023-05-22 10:06:11.977: [iter 16 : loss : 1.5952 = 0.6816 + 0.9136 + 0.0001, time: 46.740073]
2023-05-22 10:06:12.608: epoch 16:	0.04868337  	0.09984147  	0.09743126  
2023-05-22 10:06:12.608: Find a better model.
2023-05-22 10:06:59.606: [iter 17 : loss : 1.5850 = 0.6700 + 0.9148 + 0.0002, time: 46.992113]
2023-05-22 10:07:00.256: epoch 17:	0.06108066  	0.12087873  	0.11963751  
2023-05-22 10:07:00.256: Find a better model.
2023-05-22 10:07:47.037: [iter 18 : loss : 1.5631 = 0.6454 + 0.9174 + 0.0003, time: 46.774551]
2023-05-22 10:07:47.665: epoch 18:	0.07177001  	0.13814206  	0.13806896  
2023-05-22 10:07:47.665: Find a better model.
2023-05-22 10:08:34.458: [iter 19 : loss : 1.5238 = 0.6016 + 0.9217 + 0.0006, time: 46.782110]
2023-05-22 10:08:35.103: epoch 19:	0.07818365  	0.14814048  	0.14873916  
2023-05-22 10:08:35.103: Find a better model.
2023-05-22 10:09:21.801: [iter 20 : loss : 1.4707 = 0.5420 + 0.9277 + 0.0010, time: 46.685818]
2023-05-22 10:09:22.410: epoch 20:	0.08193289  	0.15470773  	0.15489152  
2023-05-22 10:09:22.410: Find a better model.
2023-05-22 10:10:09.071: [iter 21 : loss : 1.4132 = 0.4780 + 0.9338 + 0.0014, time: 46.652441]
2023-05-22 10:10:09.700: epoch 21:	0.08385590  	0.15836343  	0.15826109  
2023-05-22 10:10:09.700: Find a better model.
2023-05-22 10:10:49.118: [iter 22 : loss : 1.3594 = 0.4192 + 0.9383 + 0.0019, time: 39.411425]
2023-05-22 10:10:49.539: epoch 22:	0.08521490  	0.16129582  	0.16040428  
2023-05-22 10:10:49.539: Find a better model.
2023-05-22 10:11:28.934: [iter 23 : loss : 1.3139 = 0.3703 + 0.9411 + 0.0024, time: 39.389006]
2023-05-22 10:11:29.353: epoch 23:	0.08618708  	0.16290909  	0.16211037  
2023-05-22 10:11:29.354: Find a better model.
2023-05-22 10:12:08.717: [iter 24 : loss : 1.2752 = 0.3297 + 0.9426 + 0.0029, time: 39.356464]
2023-05-22 10:12:09.128: epoch 24:	0.08691227  	0.16399811  	0.16315477  
2023-05-22 10:12:09.129: Find a better model.
2023-05-22 10:12:48.447: [iter 25 : loss : 1.2433 = 0.2972 + 0.9428 + 0.0034, time: 39.311315]
2023-05-22 10:12:48.862: epoch 25:	0.08740638  	0.16506325  	0.16379291  
2023-05-22 10:12:48.862: Find a better model.
2023-05-22 10:13:28.178: [iter 26 : loss : 1.2157 = 0.2693 + 0.9425 + 0.0039, time: 39.309380]
2023-05-22 10:13:28.580: epoch 26:	0.08766962  	0.16585995  	0.16460320  
2023-05-22 10:13:28.580: Find a better model.
2023-05-22 10:14:08.117: [iter 27 : loss : 1.1924 = 0.2462 + 0.9419 + 0.0043, time: 39.529158]
2023-05-22 10:14:08.517: epoch 27:	0.08771259  	0.16607268  	0.16450188  
2023-05-22 10:14:08.517: Find a better model.
2023-05-22 10:14:48.108: [iter 28 : loss : 1.1726 = 0.2268 + 0.9411 + 0.0047, time: 39.584419]
2023-05-22 10:14:48.516: epoch 28:	0.08778255  	0.16584963  	0.16435291  
2023-05-22 10:15:35.576: [iter 29 : loss : 1.1559 = 0.2107 + 0.9401 + 0.0051, time: 47.051335]
2023-05-22 10:15:36.170: epoch 29:	0.08786310  	0.16573098  	0.16452403  
2023-05-22 10:16:23.119: [iter 30 : loss : 1.1408 = 0.1962 + 0.9391 + 0.0055, time: 46.937025]
2023-05-22 10:16:23.707: epoch 30:	0.08775561  	0.16531833  	0.16416129  
2023-05-22 10:17:10.607: [iter 31 : loss : 1.1272 = 0.1832 + 0.9381 + 0.0058, time: 46.887340]
2023-05-22 10:17:11.211: epoch 31:	0.08761054  	0.16526857  	0.16379766  
2023-05-22 10:17:58.240: [iter 32 : loss : 1.1160 = 0.1727 + 0.9371 + 0.0062, time: 47.022165]
2023-05-22 10:17:58.838: epoch 32:	0.08744413  	0.16480395  	0.16342245  
2023-05-22 10:18:45.959: [iter 33 : loss : 1.1054 = 0.1626 + 0.9362 + 0.0065, time: 47.114037]
2023-05-22 10:18:46.409: epoch 33:	0.08772345  	0.16513979  	0.16342801  
2023-05-22 10:19:33.378: [iter 34 : loss : 1.0968 = 0.1547 + 0.9353 + 0.0068, time: 46.962340]
2023-05-22 10:19:34.009: epoch 34:	0.08755153  	0.16482875  	0.16283172  
2023-05-22 10:20:21.030: [iter 35 : loss : 1.0879 = 0.1462 + 0.9346 + 0.0072, time: 47.012906]
2023-05-22 10:20:21.607: epoch 35:	0.08734210  	0.16401349  	0.16213255  
2023-05-22 10:21:09.102: [iter 36 : loss : 1.0805 = 0.1393 + 0.9337 + 0.0075, time: 47.479944]
2023-05-22 10:21:09.700: epoch 36:	0.08709502  	0.16313350  	0.16155957  
2023-05-22 10:21:48.306: my pid: 13984
2023-05-22 10:21:48.306: model: model.general_recommender.SGL
2023-05-22 10:21:48.306: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-22 10:21:48.306: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-22 10:21:54.003: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-22 10:22:41.688: [iter 1 : loss : 1.6067 = 0.6931 + 0.9136 + 0.0000, time: 47.684070]
2023-05-22 10:22:42.308: epoch 1:	0.00401265  	0.00896359  	0.00771930  
2023-05-22 10:22:42.309: Find a better model.
2023-05-22 10:23:30.199: [iter 2 : loss : 1.6044 = 0.6931 + 0.9114 + 0.0000, time: 47.884368]
2023-05-22 10:23:30.815: epoch 2:	0.00460891  	0.00982602  	0.00849008  
2023-05-22 10:23:30.815: Find a better model.
2023-05-22 10:24:18.373: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 47.550917]
2023-05-22 10:24:18.835: epoch 3:	0.00556506  	0.01147948  	0.01006097  
2023-05-22 10:24:18.836: Find a better model.
2023-05-22 10:25:06.554: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 47.703825]
2023-05-22 10:25:07.181: epoch 4:	0.00660180  	0.01225515  	0.01134190  
2023-05-22 10:25:07.181: Find a better model.
2023-05-22 10:25:55.127: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 47.936516]
2023-05-22 10:25:55.714: epoch 5:	0.00798237  	0.01507628  	0.01376361  
2023-05-22 10:25:55.714: Find a better model.
2023-05-22 10:26:43.607: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 47.886114]
2023-05-22 10:26:44.225: epoch 6:	0.00920178  	0.01703170  	0.01610058  
2023-05-22 10:26:44.225: Find a better model.
2023-05-22 10:27:32.122: [iter 7 : loss : 1.6035 = 0.6927 + 0.9108 + 0.0000, time: 47.888588]
2023-05-22 10:27:32.731: epoch 7:	0.01032988  	0.01926965  	0.01802563  
2023-05-22 10:27:32.731: Find a better model.
2023-05-22 10:28:20.806: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 48.068644]
2023-05-22 10:28:21.285: epoch 8:	0.01138278  	0.02103770  	0.01990023  
2023-05-22 10:28:21.285: Find a better model.
2023-05-22 10:29:09.179: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 47.879541]
2023-05-22 10:29:09.781: epoch 9:	0.01336500  	0.02612833  	0.02418572  
2023-05-22 10:29:09.781: Find a better model.
2023-05-22 10:29:57.828: [iter 10 : loss : 1.6028 = 0.6921 + 0.9107 + 0.0000, time: 48.037371]
2023-05-22 10:29:58.428: epoch 10:	0.01512699  	0.02955298  	0.02747703  
2023-05-22 10:29:58.428: Find a better model.
2023-05-22 10:30:45.756: [iter 11 : loss : 1.6024 = 0.6917 + 0.9106 + 0.0000, time: 47.315937]
2023-05-22 10:30:46.352: epoch 11:	0.01748525  	0.03575983  	0.03316909  
2023-05-22 10:30:46.352: Find a better model.
2023-05-22 10:31:26.778: [iter 12 : loss : 1.6019 = 0.6911 + 0.9108 + 0.0000, time: 40.419781]
2023-05-22 10:31:27.189: epoch 12:	0.02078899  	0.04314394  	0.04034121  
2023-05-22 10:31:27.189: Find a better model.
2023-05-22 10:32:07.550: [iter 13 : loss : 1.6011 = 0.6901 + 0.9109 + 0.0000, time: 40.355035]
2023-05-22 10:32:07.950: epoch 13:	0.02465672  	0.05218611  	0.04871231  
2023-05-22 10:32:07.950: Find a better model.
2023-05-22 10:32:48.550: [iter 14 : loss : 1.5995 = 0.6883 + 0.9111 + 0.0000, time: 40.594333]
2023-05-22 10:32:48.949: epoch 14:	0.03060839  	0.06557579  	0.06087002  
2023-05-22 10:32:48.949: Find a better model.
2023-05-22 10:33:29.236: [iter 15 : loss : 1.5963 = 0.6847 + 0.9115 + 0.0001, time: 40.281385]
2023-05-22 10:33:29.637: epoch 15:	0.03938524  	0.08472098  	0.07897170  
2023-05-22 10:33:29.637: Find a better model.
2023-05-22 10:34:10.146: [iter 16 : loss : 1.5893 = 0.6769 + 0.9123 + 0.0001, time: 40.501719]
2023-05-22 10:34:10.570: epoch 16:	0.04981669  	0.10395326  	0.09956413  
2023-05-22 10:34:10.571: Find a better model.
2023-05-22 10:34:50.992: [iter 17 : loss : 1.5741 = 0.6600 + 0.9139 + 0.0002, time: 40.413497]
2023-05-22 10:34:51.393: epoch 17:	0.06190251  	0.12317971  	0.12155142  
2023-05-22 10:34:51.393: Find a better model.
2023-05-22 10:35:32.263: [iter 18 : loss : 1.5445 = 0.6271 + 0.9170 + 0.0004, time: 40.863030]
2023-05-22 10:35:32.669: epoch 18:	0.07193639  	0.13906887  	0.13861465  
2023-05-22 10:35:32.669: Find a better model.
2023-05-22 10:36:13.340: [iter 19 : loss : 1.4986 = 0.5761 + 0.9217 + 0.0007, time: 40.663987]
2023-05-22 10:36:13.743: epoch 19:	0.07762488  	0.14815797  	0.14789946  
2023-05-22 10:36:13.743: Find a better model.
2023-05-22 10:36:54.277: [iter 20 : loss : 1.4437 = 0.5151 + 0.9275 + 0.0012, time: 40.525259]
2023-05-22 10:36:54.700: epoch 20:	0.08080470  	0.15358296  	0.15359536  
2023-05-22 10:36:54.700: Find a better model.
2023-05-22 10:37:35.340: [iter 21 : loss : 1.3886 = 0.4543 + 0.9327 + 0.0016, time: 40.634568]
2023-05-22 10:37:35.761: epoch 21:	0.08311441  	0.15763202  	0.15723635  
2023-05-22 10:37:35.762: Find a better model.
2023-05-22 10:38:16.257: [iter 22 : loss : 1.3389 = 0.4003 + 0.9365 + 0.0021, time: 40.489287]
2023-05-22 10:38:16.683: epoch 22:	0.08439811  	0.15944883  	0.15928179  
2023-05-22 10:38:16.683: Find a better model.
2023-05-22 10:38:57.292: [iter 23 : loss : 1.2970 = 0.3556 + 0.9387 + 0.0026, time: 40.599104]
2023-05-22 10:38:57.688: epoch 23:	0.08554768  	0.16204663  	0.16098860  
2023-05-22 10:38:57.688: Find a better model.
2023-05-22 10:39:38.660: [iter 24 : loss : 1.2613 = 0.3184 + 0.9399 + 0.0031, time: 40.964047]
2023-05-22 10:39:39.059: epoch 24:	0.08643936  	0.16394003  	0.16244982  
2023-05-22 10:39:39.059: Find a better model.
2023-05-22 10:40:19.746: [iter 25 : loss : 1.2319 = 0.2883 + 0.9400 + 0.0036, time: 40.680372]
2023-05-22 10:40:20.139: epoch 25:	0.08697665  	0.16438113  	0.16301377  
2023-05-22 10:40:20.139: Find a better model.
2023-05-22 10:41:01.377: [iter 26 : loss : 1.2061 = 0.2624 + 0.9397 + 0.0040, time: 41.221787]
2023-05-22 10:41:01.775: epoch 26:	0.08712706  	0.16460006  	0.16330016  
2023-05-22 10:41:01.775: Find a better model.
2023-05-22 10:41:42.479: [iter 27 : loss : 1.1844 = 0.2408 + 0.9391 + 0.0044, time: 40.697194]
2023-05-22 10:41:42.892: epoch 27:	0.08732046  	0.16498323  	0.16330469  
2023-05-22 10:41:42.892: Find a better model.
2023-05-22 10:42:23.942: [iter 28 : loss : 1.1658 = 0.2225 + 0.9384 + 0.0048, time: 41.043176]
2023-05-22 10:42:24.355: epoch 28:	0.08726679  	0.16482629  	0.16324285  
2023-05-22 10:43:05.228: [iter 29 : loss : 1.1500 = 0.2073 + 0.9374 + 0.0052, time: 40.865730]
2023-05-22 10:43:05.624: epoch 29:	0.08707346  	0.16430491  	0.16293435  
2023-05-22 10:43:46.510: [iter 30 : loss : 1.1356 = 0.1935 + 0.9365 + 0.0056, time: 40.879265]
2023-05-22 10:43:46.907: epoch 30:	0.08710026  	0.16409837  	0.16259377  
2023-05-22 10:44:27.611: [iter 31 : loss : 1.1223 = 0.1808 + 0.9356 + 0.0060, time: 40.697751]
2023-05-22 10:44:28.036: epoch 31:	0.08698214  	0.16377886  	0.16215625  
2023-05-22 10:45:09.060: [iter 32 : loss : 1.1118 = 0.1708 + 0.9346 + 0.0063, time: 41.017304]
2023-05-22 10:45:09.469: epoch 32:	0.08695523  	0.16363640  	0.16191971  
2023-05-22 10:45:50.401: [iter 33 : loss : 1.1013 = 0.1609 + 0.9338 + 0.0066, time: 40.925218]
2023-05-22 10:45:50.825: epoch 33:	0.08690692  	0.16281003  	0.16145651  
2023-05-22 10:46:31.701: [iter 34 : loss : 1.0932 = 0.1533 + 0.9329 + 0.0070, time: 40.865022]
2023-05-22 10:46:32.095: epoch 34:	0.08692845  	0.16279219  	0.16116151  
2023-05-22 10:47:13.149: [iter 35 : loss : 1.0847 = 0.1452 + 0.9322 + 0.0073, time: 41.048032]
2023-05-22 10:47:13.566: epoch 35:	0.08672433  	0.16215341  	0.16056997  
2023-05-22 10:47:54.828: [iter 36 : loss : 1.0775 = 0.1385 + 0.9314 + 0.0076, time: 41.255938]
2023-05-22 10:47:55.248: epoch 36:	0.08643965  	0.16168377  	0.15986940  
2023-05-22 10:48:35.993: [iter 37 : loss : 1.0705 = 0.1320 + 0.9306 + 0.0079, time: 40.738217]
2023-05-22 10:48:36.420: epoch 37:	0.08629464  	0.16135931  	0.15958141  
2023-05-22 10:49:17.616: [iter 38 : loss : 1.0648 = 0.1268 + 0.9299 + 0.0081, time: 41.189167]
2023-05-22 10:49:18.017: epoch 38:	0.08620328  	0.16056086  	0.15904486  
2023-05-22 10:49:59.283: [iter 39 : loss : 1.0594 = 0.1218 + 0.9292 + 0.0084, time: 41.257699]
2023-05-22 10:49:59.689: epoch 39:	0.08584334  	0.15949711  	0.15829960  
2023-05-22 10:50:41.139: [iter 40 : loss : 1.0545 = 0.1172 + 0.9286 + 0.0087, time: 41.443662]
2023-05-22 10:50:41.550: epoch 40:	0.08548884  	0.15826935  	0.15748379  
2023-05-22 10:51:22.668: [iter 41 : loss : 1.0495 = 0.1125 + 0.9280 + 0.0089, time: 41.111457]
2023-05-22 10:51:23.067: epoch 41:	0.08531694  	0.15748867  	0.15687856  
2023-05-22 10:52:04.098: [iter 42 : loss : 1.0454 = 0.1088 + 0.9275 + 0.0092, time: 41.023741]
2023-05-22 10:52:04.536: epoch 42:	0.08526865  	0.15691285  	0.15640835  
2023-05-22 10:52:45.582: [iter 43 : loss : 1.0413 = 0.1048 + 0.9270 + 0.0094, time: 41.038096]
2023-05-22 10:52:45.981: epoch 43:	0.08486579  	0.15573230  	0.15566422  
2023-05-22 10:53:27.357: [iter 44 : loss : 1.0375 = 0.1013 + 0.9265 + 0.0097, time: 41.369959]
2023-05-22 10:53:27.767: epoch 44:	0.08472072  	0.15514950  	0.15504852  
2023-05-23 20:47:46.090: my pid: 8160
2023-05-23 20:47:46.090: model: model.general_recommender.SGL
2023-05-23 20:47:46.090: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-23 20:47:46.090: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-23 20:47:50.922: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-23 20:48:28.324: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 37.401074]
2023-05-23 20:48:28.728: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-05-23 20:48:28.729: Find a better model.
2023-05-23 20:49:05.748: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.013598]
2023-05-23 20:49:06.146: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-05-23 20:49:06.146: Find a better model.
2023-05-23 20:49:43.138: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 36.985412]
2023-05-23 20:49:43.549: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-05-23 20:49:43.549: Find a better model.
2023-05-23 20:50:20.306: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 36.750002]
2023-05-23 20:50:20.709: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-05-23 20:50:20.710: Find a better model.
2023-05-23 20:50:57.804: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.088228]
2023-05-23 20:50:58.204: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-05-23 20:50:58.204: Find a better model.
2023-05-23 20:51:35.347: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.136883]
2023-05-23 20:51:35.755: epoch 6:	0.00772451  	0.01568698  	0.01374723  
2023-05-23 20:51:35.755: Find a better model.
2023-05-23 20:52:13.122: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 37.359509]
2023-05-23 20:52:13.524: epoch 7:	0.00857865  	0.01634379  	0.01484605  
2023-05-23 20:52:13.524: Find a better model.
2023-05-23 20:52:50.636: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 37.106860]
2023-05-23 20:52:51.042: epoch 8:	0.00980345  	0.01916631  	0.01706018  
2023-05-23 20:52:51.042: Find a better model.
2023-05-23 20:53:28.448: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 37.398883]
2023-05-23 20:53:28.865: epoch 9:	0.01139889  	0.02280196  	0.02033713  
2023-05-23 20:53:28.865: Find a better model.
2023-05-23 20:54:06.091: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 37.220814]
2023-05-23 20:54:06.498: epoch 10:	0.01327366  	0.02668142  	0.02470750  
2023-05-23 20:54:06.498: Find a better model.
2023-05-23 20:54:44.171: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 37.666596]
2023-05-23 20:54:44.574: epoch 11:	0.01542245  	0.03111634  	0.02916739  
2023-05-23 20:54:44.574: Find a better model.
2023-05-23 20:55:21.400: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 36.819525]
2023-05-23 20:55:21.800: epoch 12:	0.01837162  	0.03774254  	0.03553504  
2023-05-23 20:55:21.800: Find a better model.
2023-05-23 20:55:58.814: [iter 13 : loss : 1.6047 = 0.6911 + 0.9135 + 0.0000, time: 37.007924]
2023-05-23 20:55:59.221: epoch 13:	0.02247574  	0.04678126  	0.04394830  
2023-05-23 20:55:59.221: Find a better model.
2023-05-23 20:56:36.343: [iter 14 : loss : 1.6041 = 0.6901 + 0.9139 + 0.0000, time: 37.114872]
2023-05-23 20:56:36.743: epoch 14:	0.02782069  	0.05873166  	0.05544734  
2023-05-23 20:56:36.743: Find a better model.
2023-05-23 20:57:13.730: [iter 15 : loss : 1.6027 = 0.6884 + 0.9143 + 0.0001, time: 36.978834]
2023-05-23 20:57:14.144: epoch 15:	0.03541569  	0.07228198  	0.07093161  
2023-05-23 20:57:14.145: Find a better model.
2023-05-23 20:57:51.943: [iter 16 : loss : 1.6000 = 0.6849 + 0.9150 + 0.0001, time: 37.792070]
2023-05-23 20:57:52.344: epoch 16:	0.04676036  	0.09366168  	0.09238080  
2023-05-23 20:57:52.344: Find a better model.
2023-05-23 20:58:29.917: [iter 17 : loss : 1.5935 = 0.6773 + 0.9161 + 0.0001, time: 37.566626]
2023-05-23 20:58:30.321: epoch 17:	0.05855069  	0.11563964  	0.11480868  
2023-05-23 20:58:30.321: Find a better model.
2023-05-23 20:59:08.186: [iter 18 : loss : 1.5791 = 0.6605 + 0.9183 + 0.0002, time: 37.858966]
2023-05-23 20:59:08.582: epoch 18:	0.06948166  	0.13351610  	0.13435432  
2023-05-23 20:59:08.582: Find a better model.
2023-05-23 20:59:46.756: [iter 19 : loss : 1.5497 = 0.6272 + 0.9220 + 0.0004, time: 38.167802]
2023-05-23 20:59:47.152: epoch 19:	0.07685133  	0.14568959  	0.14739549  
2023-05-23 20:59:47.152: Find a better model.
2023-05-23 21:00:25.043: [iter 20 : loss : 1.5038 = 0.5755 + 0.9276 + 0.0008, time: 37.884094]
2023-05-23 21:00:25.447: epoch 20:	0.08106273  	0.15259156  	0.15440956  
2023-05-23 21:00:25.447: Find a better model.
2023-05-23 21:01:03.420: [iter 21 : loss : 1.4477 = 0.5127 + 0.9338 + 0.0012, time: 37.966356]
2023-05-23 21:01:03.815: epoch 21:	0.08318444  	0.15727343  	0.15806970  
2023-05-23 21:01:03.815: Find a better model.
2023-05-23 21:01:41.670: [iter 22 : loss : 1.3911 = 0.4502 + 0.9392 + 0.0017, time: 37.848241]
2023-05-23 21:01:42.068: epoch 22:	0.08458110  	0.15996696  	0.16060397  
2023-05-23 21:01:42.068: Find a better model.
2023-05-23 21:02:20.009: [iter 23 : loss : 1.3410 = 0.3959 + 0.9429 + 0.0022, time: 37.934974]
2023-05-23 21:02:20.403: epoch 23:	0.08581655  	0.16247109  	0.16251287  
2023-05-23 21:02:20.403: Find a better model.
2023-05-23 21:02:58.423: [iter 24 : loss : 1.2980 = 0.3502 + 0.9450 + 0.0027, time: 38.012948]
2023-05-23 21:02:58.818: epoch 24:	0.08649337  	0.16442634  	0.16374367  
2023-05-23 21:02:58.818: Find a better model.
2023-05-23 21:03:36.855: [iter 25 : loss : 1.2624 = 0.3136 + 0.9456 + 0.0032, time: 38.030295]
2023-05-23 21:03:37.247: epoch 25:	0.08704661  	0.16541874  	0.16421244  
2023-05-23 21:03:37.247: Find a better model.
2023-05-23 21:04:15.230: [iter 26 : loss : 1.2319 = 0.2825 + 0.9456 + 0.0037, time: 37.975894]
2023-05-23 21:04:15.622: epoch 26:	0.08740115  	0.16604136  	0.16481176  
2023-05-23 21:04:15.622: Find a better model.
2023-05-23 21:04:53.454: [iter 27 : loss : 1.2062 = 0.2569 + 0.9451 + 0.0041, time: 37.819457]
2023-05-23 21:04:53.852: epoch 27:	0.08762669  	0.16688263  	0.16492711  
2023-05-23 21:04:53.852: Find a better model.
2023-05-23 21:05:31.918: [iter 28 : loss : 1.1847 = 0.2358 + 0.9444 + 0.0045, time: 38.058922]
2023-05-23 21:05:32.309: epoch 28:	0.08764822  	0.16707423  	0.16502355  
2023-05-23 21:05:32.310: Find a better model.
2023-05-23 21:06:10.377: [iter 29 : loss : 1.1662 = 0.2180 + 0.9433 + 0.0049, time: 38.060918]
2023-05-23 21:06:10.792: epoch 29:	0.08748712  	0.16666961  	0.16458365  
2023-05-23 21:06:48.943: [iter 30 : loss : 1.1498 = 0.2022 + 0.9422 + 0.0053, time: 38.145573]
2023-05-23 21:06:49.341: epoch 30:	0.08756236  	0.16684170  	0.16458559  
2023-05-23 21:07:27.490: [iter 31 : loss : 1.1353 = 0.1883 + 0.9413 + 0.0057, time: 38.141994]
2023-05-23 21:07:27.906: epoch 31:	0.08774500  	0.16726770  	0.16458616  
2023-05-23 21:07:27.906: Find a better model.
2023-05-23 21:08:05.846: [iter 32 : loss : 1.1234 = 0.1771 + 0.9402 + 0.0061, time: 37.933707]
2023-05-23 21:08:06.243: epoch 32:	0.08762150  	0.16679874  	0.16427374  
2023-05-23 21:08:44.335: [iter 33 : loss : 1.1118 = 0.1661 + 0.9393 + 0.0064, time: 38.085064]
2023-05-23 21:08:44.728: epoch 33:	0.08757314  	0.16600898  	0.16349596  
2023-05-23 21:09:22.968: [iter 34 : loss : 1.1030 = 0.1579 + 0.9383 + 0.0067, time: 38.232867]
2023-05-23 21:09:23.360: epoch 34:	0.08706280  	0.16474310  	0.16267519  
2023-05-23 21:10:01.777: [iter 35 : loss : 1.0936 = 0.1490 + 0.9375 + 0.0071, time: 38.411079]
2023-05-23 21:10:02.180: epoch 35:	0.08705749  	0.16449013  	0.16238284  
2023-05-23 21:10:40.603: [iter 36 : loss : 1.0860 = 0.1420 + 0.9367 + 0.0073, time: 38.415661]
2023-05-23 21:10:40.997: epoch 36:	0.08693929  	0.16360644  	0.16182175  
2023-05-23 21:11:19.254: [iter 37 : loss : 1.0784 = 0.1350 + 0.9358 + 0.0077, time: 38.250288]
2023-05-23 21:11:19.648: epoch 37:	0.08705207  	0.16356497  	0.16157605  
2023-05-23 21:11:58.021: [iter 38 : loss : 1.0721 = 0.1291 + 0.9350 + 0.0079, time: 38.365511]
2023-05-23 21:11:58.415: epoch 38:	0.08674587  	0.16247575  	0.16100143  
2023-05-23 21:12:36.674: [iter 39 : loss : 1.0664 = 0.1239 + 0.9344 + 0.0082, time: 38.250214]
2023-05-23 21:12:37.066: epoch 39:	0.08655789  	0.16186082  	0.16022845  
2023-05-23 21:13:15.282: [iter 40 : loss : 1.0613 = 0.1191 + 0.9337 + 0.0085, time: 38.208537]
2023-05-23 21:13:15.674: epoch 40:	0.08602608  	0.16057605  	0.15914477  
2023-05-23 21:13:53.864: [iter 41 : loss : 1.0558 = 0.1140 + 0.9330 + 0.0087, time: 38.184026]
2023-05-23 21:13:54.259: epoch 41:	0.08608516  	0.16031665  	0.15875244  
2023-05-23 21:14:32.711: [iter 42 : loss : 1.0516 = 0.1101 + 0.9324 + 0.0090, time: 38.444651]
2023-05-23 21:14:33.105: epoch 42:	0.08575749  	0.15925847  	0.15797424  
2023-05-23 21:15:11.151: [iter 43 : loss : 1.0470 = 0.1058 + 0.9319 + 0.0092, time: 38.038912]
2023-05-23 21:15:11.563: epoch 43:	0.08577894  	0.15921202  	0.15776969  
2023-05-23 21:15:49.744: [iter 44 : loss : 1.0432 = 0.1023 + 0.9314 + 0.0095, time: 38.167332]
2023-05-23 21:15:50.140: epoch 44:	0.08545665  	0.15818119  	0.15703753  
2023-05-23 21:16:28.525: [iter 45 : loss : 1.0401 = 0.0995 + 0.9309 + 0.0097, time: 38.379350]
2023-05-23 21:16:28.920: epoch 45:	0.08546744  	0.15755607  	0.15649900  
2023-05-23 21:17:07.472: [iter 46 : loss : 1.0364 = 0.0960 + 0.9305 + 0.0099, time: 38.544900]
2023-05-23 21:17:07.880: epoch 46:	0.08517735  	0.15684828  	0.15575612  
2023-05-23 21:17:45.979: [iter 47 : loss : 1.0333 = 0.0932 + 0.9300 + 0.0102, time: 38.093643]
2023-05-23 21:17:46.375: epoch 47:	0.08483897  	0.15577796  	0.15515001  
2023-05-23 21:18:24.516: [iter 48 : loss : 1.0303 = 0.0903 + 0.9296 + 0.0104, time: 38.134590]
2023-05-23 21:18:24.924: epoch 48:	0.08459184  	0.15493961  	0.15445580  
2023-05-23 21:19:03.454: [iter 49 : loss : 1.0277 = 0.0879 + 0.9292 + 0.0106, time: 38.523395]
2023-05-23 21:19:03.853: epoch 49:	0.08426958  	0.15370899  	0.15380250  
2023-05-23 21:19:42.030: [iter 50 : loss : 1.0254 = 0.0858 + 0.9288 + 0.0108, time: 38.170636]
2023-05-23 21:19:42.425: epoch 50:	0.08415139  	0.15344602  	0.15338914  
2023-05-23 21:20:20.851: [iter 51 : loss : 1.0232 = 0.0837 + 0.9286 + 0.0110, time: 38.419418]
2023-05-23 21:20:21.245: epoch 51:	0.08399566  	0.15302625  	0.15298109  
2023-05-23 21:20:59.810: [iter 52 : loss : 1.0208 = 0.0813 + 0.9283 + 0.0112, time: 38.558710]
2023-05-23 21:21:00.222: epoch 52:	0.08363571  	0.15218629  	0.15220608  
2023-05-23 21:21:38.233: [iter 53 : loss : 1.0185 = 0.0794 + 0.9278 + 0.0114, time: 38.003412]
2023-05-23 21:21:38.629: epoch 53:	0.08354437  	0.15204443  	0.15206686  
2023-05-23 21:22:16.881: [iter 54 : loss : 1.0161 = 0.0769 + 0.9276 + 0.0116, time: 38.246731]
2023-05-23 21:22:17.292: epoch 54:	0.08323281  	0.15136828  	0.15149276  
2023-05-23 21:22:55.615: [iter 55 : loss : 1.0149 = 0.0759 + 0.9273 + 0.0117, time: 38.315479]
2023-05-23 21:22:56.010: epoch 55:	0.08306087  	0.15041576  	0.15099113  
2023-05-23 21:23:34.470: [iter 56 : loss : 1.0128 = 0.0739 + 0.9271 + 0.0119, time: 38.454194]
2023-05-23 21:23:34.867: epoch 56:	0.08285140  	0.14989409  	0.15054712  
2023-05-23 21:23:34.867: Early stopping is trigger at epoch: 56
2023-05-23 21:23:34.867: best_result@epoch 31:

2023-05-23 21:23:34.867: 		0.0877      	0.1673      	0.1646      
2023-05-24 14:40:36.713: my pid: 14084
2023-05-24 14:40:36.713: model: model.general_recommender.SGL
2023-05-24 14:40:36.713: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 14:40:36.713: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 14:40:41.590: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 14:41:19.724: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 38.132722]
2023-05-24 14:41:20.151: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-05-24 14:41:20.151: Find a better model.
2023-05-24 14:41:58.053: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.896114]
2023-05-24 14:41:58.479: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-05-24 14:41:58.479: Find a better model.
2023-05-24 14:42:36.278: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 37.792125]
2023-05-24 14:42:36.734: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-05-24 14:42:36.734: Find a better model.
2023-05-24 14:43:14.651: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 37.911416]
2023-05-24 14:43:15.059: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-05-24 14:43:15.059: Find a better model.
2023-05-24 14:43:53.073: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 38.005923]
2023-05-24 14:43:53.497: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-05-24 14:43:53.497: Find a better model.
2023-05-24 14:44:31.446: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.942887]
2023-05-24 14:44:31.863: epoch 6:	0.00772451  	0.01568698  	0.01374723  
2023-05-24 14:44:31.863: Find a better model.
2023-05-24 14:45:09.997: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 38.127373]
2023-05-24 14:45:10.419: epoch 7:	0.00857865  	0.01634379  	0.01484605  
2023-05-24 14:45:10.419: Find a better model.
2023-05-24 14:45:48.396: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 37.970673]
2023-05-24 14:45:48.834: epoch 8:	0.00980345  	0.01916631  	0.01706018  
2023-05-24 14:45:48.835: Find a better model.
2023-05-24 14:46:26.851: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 38.009561]
2023-05-24 14:46:27.277: epoch 9:	0.01139889  	0.02280196  	0.02033713  
2023-05-24 14:46:27.277: Find a better model.
2023-05-24 14:47:05.188: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 37.903852]
2023-05-24 14:47:05.612: epoch 10:	0.01327366  	0.02668142  	0.02470750  
2023-05-24 14:47:05.613: Find a better model.
2023-05-24 14:47:44.344: [iter 11 : loss : 1.6052 = 0.6921 + 0.9131 + 0.0000, time: 38.724905]
2023-05-24 14:47:44.769: epoch 11:	0.01582534  	0.03182322  	0.02958031  
2023-05-24 14:47:44.769: Find a better model.
2023-05-24 14:48:23.562: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 38.786106]
2023-05-24 14:48:23.971: epoch 12:	0.01929559  	0.03931639  	0.03642214  
2023-05-24 14:48:23.971: Find a better model.
2023-05-24 14:49:02.813: [iter 13 : loss : 1.6046 = 0.6911 + 0.9135 + 0.0000, time: 38.836593]
2023-05-24 14:49:03.210: epoch 13:	0.02358774  	0.04787140  	0.04561435  
2023-05-24 14:49:03.210: Find a better model.
2023-05-24 14:49:42.107: [iter 14 : loss : 1.6040 = 0.6901 + 0.9139 + 0.0000, time: 38.890047]
2023-05-24 14:49:42.530: epoch 14:	0.02935687  	0.06059671  	0.05719132  
2023-05-24 14:49:42.530: Find a better model.
2023-05-24 14:50:21.234: [iter 15 : loss : 1.6026 = 0.6883 + 0.9143 + 0.0001, time: 38.697551]
2023-05-24 14:50:21.630: epoch 15:	0.03736554  	0.07617891  	0.07382537  
2023-05-24 14:50:21.630: Find a better model.
2023-05-24 14:51:00.390: [iter 16 : loss : 1.5998 = 0.6847 + 0.9150 + 0.0001, time: 38.754126]
2023-05-24 14:51:00.813: epoch 16:	0.04747470  	0.09555506  	0.09369494  
2023-05-24 14:51:00.813: Find a better model.
2023-05-24 14:51:39.757: [iter 17 : loss : 1.5932 = 0.6769 + 0.9162 + 0.0001, time: 38.937970]
2023-05-24 14:51:40.181: epoch 17:	0.05913622  	0.11708698  	0.11532641  
2023-05-24 14:51:40.182: Find a better model.
2023-05-24 14:52:19.098: [iter 18 : loss : 1.5784 = 0.6597 + 0.9184 + 0.0002, time: 38.911060]
2023-05-24 14:52:19.491: epoch 18:	0.07035188  	0.13532549  	0.13524866  
2023-05-24 14:52:19.491: Find a better model.
2023-05-24 14:52:58.321: [iter 19 : loss : 1.5483 = 0.6256 + 0.9222 + 0.0004, time: 38.824107]
2023-05-24 14:52:58.762: epoch 19:	0.07720600  	0.14589074  	0.14760943  
2023-05-24 14:52:58.762: Find a better model.
2023-05-24 14:53:37.443: [iter 20 : loss : 1.5018 = 0.5732 + 0.9278 + 0.0008, time: 38.674063]
2023-05-24 14:53:37.855: epoch 20:	0.08130982  	0.15302810  	0.15476142  
2023-05-24 14:53:37.856: Find a better model.
2023-05-24 14:54:16.932: [iter 21 : loss : 1.4455 = 0.5103 + 0.9340 + 0.0012, time: 39.069100]
2023-05-24 14:54:17.328: epoch 21:	0.08320590  	0.15684645  	0.15804432  
2023-05-24 14:54:17.329: Find a better model.
2023-05-24 14:54:56.237: [iter 22 : loss : 1.3890 = 0.4480 + 0.9393 + 0.0017, time: 38.901832]
2023-05-24 14:54:56.631: epoch 22:	0.08464019  	0.16029434  	0.16066864  
2023-05-24 14:54:56.631: Find a better model.
2023-05-24 14:55:35.425: [iter 23 : loss : 1.3392 = 0.3940 + 0.9430 + 0.0022, time: 38.788122]
2023-05-24 14:55:35.853: epoch 23:	0.08551575  	0.16208963  	0.16250920  
2023-05-24 14:55:35.853: Find a better model.
2023-05-24 14:56:14.822: [iter 24 : loss : 1.2965 = 0.3487 + 0.9450 + 0.0027, time: 38.963236]
2023-05-24 14:56:15.216: epoch 24:	0.08653631  	0.16462055  	0.16401327  
2023-05-24 14:56:15.216: Find a better model.
2023-05-24 14:56:54.234: [iter 25 : loss : 1.2612 = 0.3124 + 0.9456 + 0.0032, time: 39.011208]
2023-05-24 14:56:54.630: epoch 25:	0.08692300  	0.16537604  	0.16437854  
2023-05-24 14:56:54.630: Find a better model.
2023-05-24 14:57:33.437: [iter 26 : loss : 1.2308 = 0.2815 + 0.9456 + 0.0037, time: 38.800395]
2023-05-24 14:57:33.851: epoch 26:	0.08732055  	0.16625264  	0.16480823  
2023-05-24 14:57:33.851: Find a better model.
2023-05-24 14:58:12.838: [iter 27 : loss : 1.2053 = 0.2561 + 0.9451 + 0.0041, time: 38.981188]
2023-05-24 14:58:13.257: epoch 27:	0.08732055  	0.16601786  	0.16489501  
2023-05-24 14:58:52.285: [iter 28 : loss : 1.1840 = 0.2351 + 0.9444 + 0.0045, time: 39.020076]
2023-05-24 14:58:52.703: epoch 28:	0.08763207  	0.16666016  	0.16522217  
2023-05-24 14:58:52.703: Find a better model.
2023-05-24 14:59:31.566: [iter 29 : loss : 1.1656 = 0.2174 + 0.9433 + 0.0049, time: 38.848822]
2023-05-24 14:59:31.969: epoch 29:	0.08739039  	0.16600785  	0.16495818  
2023-05-24 15:00:10.986: [iter 30 : loss : 1.1493 = 0.2017 + 0.9422 + 0.0053, time: 39.010009]
2023-05-24 15:00:11.377: epoch 30:	0.08763222  	0.16609961  	0.16515462  
2023-05-24 15:00:50.141: [iter 31 : loss : 1.1347 = 0.1878 + 0.9412 + 0.0057, time: 38.757097]
2023-05-24 15:00:50.564: epoch 31:	0.08759468  	0.16591839  	0.16473071  
2023-05-24 15:01:29.665: [iter 32 : loss : 1.1229 = 0.1767 + 0.9402 + 0.0061, time: 39.094604]
2023-05-24 15:01:30.069: epoch 32:	0.08754638  	0.16572516  	0.16450362  
2023-05-24 15:02:09.110: [iter 33 : loss : 1.1115 = 0.1658 + 0.9393 + 0.0064, time: 39.031562]
2023-05-24 15:02:09.534: epoch 33:	0.08764843  	0.16554534  	0.16416284  
2023-05-24 15:02:48.564: [iter 34 : loss : 1.1027 = 0.1577 + 0.9383 + 0.0067, time: 39.023735]
2023-05-24 15:02:48.975: epoch 34:	0.08743351  	0.16532116  	0.16358849  
2023-05-24 15:03:27.996: [iter 35 : loss : 1.0933 = 0.1487 + 0.9375 + 0.0071, time: 39.014151]
2023-05-24 15:03:28.393: epoch 35:	0.08726167  	0.16468449  	0.16317481  
2023-05-24 15:04:07.936: [iter 36 : loss : 1.0858 = 0.1418 + 0.9366 + 0.0074, time: 39.537398]
2023-05-24 15:04:08.330: epoch 36:	0.08725092  	0.16440362  	0.16264988  
2023-05-24 15:04:47.859: [iter 37 : loss : 1.0782 = 0.1348 + 0.9357 + 0.0077, time: 39.522732]
2023-05-24 15:04:48.252: epoch 37:	0.08717564  	0.16380520  	0.16226014  
2023-05-24 15:05:27.457: [iter 38 : loss : 1.0718 = 0.1288 + 0.9350 + 0.0080, time: 39.198051]
2023-05-24 15:05:27.873: epoch 38:	0.08677279  	0.16246995  	0.16145675  
2023-05-24 15:06:06.989: [iter 39 : loss : 1.0663 = 0.1237 + 0.9343 + 0.0082, time: 39.110385]
2023-05-24 15:06:07.389: epoch 39:	0.08675128  	0.16174245  	0.16075025  
2023-05-24 15:06:46.839: [iter 40 : loss : 1.0611 = 0.1190 + 0.9337 + 0.0085, time: 39.443717]
2023-05-24 15:06:47.234: epoch 40:	0.08635373  	0.16080600  	0.15999547  
2023-05-24 15:07:26.372: [iter 41 : loss : 1.0556 = 0.1139 + 0.9330 + 0.0088, time: 39.132223]
2023-05-24 15:07:26.789: epoch 41:	0.08619259  	0.16032514  	0.15957128  
2023-05-24 15:08:05.912: [iter 42 : loss : 1.0514 = 0.1100 + 0.9324 + 0.0090, time: 39.115329]
2023-05-24 15:08:06.347: epoch 42:	0.08592402  	0.15947998  	0.15903369  
2023-05-24 15:08:45.692: [iter 43 : loss : 1.0468 = 0.1057 + 0.9319 + 0.0093, time: 39.336351]
2023-05-24 15:08:46.089: epoch 43:	0.08587568  	0.15902211  	0.15862627  
2023-05-24 15:09:25.559: [iter 44 : loss : 1.0431 = 0.1022 + 0.9314 + 0.0095, time: 39.463408]
2023-05-24 15:09:25.974: epoch 44:	0.08563396  	0.15828857  	0.15810150  
2023-05-24 15:10:05.296: [iter 45 : loss : 1.0401 = 0.0995 + 0.9309 + 0.0097, time: 39.315429]
2023-05-24 15:10:05.726: epoch 45:	0.08548357  	0.15765943  	0.15742116  
2023-05-24 15:10:45.035: [iter 46 : loss : 1.0363 = 0.0959 + 0.9305 + 0.0099, time: 39.302632]
2023-05-24 15:10:45.433: epoch 46:	0.08517732  	0.15716797  	0.15683830  
2023-05-24 15:11:24.706: [iter 47 : loss : 1.0332 = 0.0931 + 0.9300 + 0.0102, time: 39.267071]
2023-05-24 15:11:25.102: epoch 47:	0.08494106  	0.15601923  	0.15612055  
2023-05-24 15:12:04.513: [iter 48 : loss : 1.0302 = 0.0903 + 0.9296 + 0.0104, time: 39.403129]
2023-05-24 15:12:04.922: epoch 48:	0.08484972  	0.15563451  	0.15549073  
2023-05-24 15:12:44.375: [iter 49 : loss : 1.0276 = 0.0878 + 0.9292 + 0.0106, time: 39.446784]
2023-05-24 15:12:44.795: epoch 49:	0.08469394  	0.15525830  	0.15498243  
2023-05-24 15:13:23.988: [iter 50 : loss : 1.0254 = 0.0858 + 0.9288 + 0.0108, time: 39.187094]
2023-05-24 15:13:24.385: epoch 50:	0.08450591  	0.15458891  	0.15441613  
2023-05-24 15:14:03.798: [iter 51 : loss : 1.0231 = 0.0835 + 0.9285 + 0.0110, time: 39.406575]
2023-05-24 15:14:04.194: epoch 51:	0.08428029  	0.15390046  	0.15381584  
2023-05-24 15:14:43.465: [iter 52 : loss : 1.0207 = 0.0813 + 0.9282 + 0.0112, time: 39.263778]
2023-05-24 15:14:43.882: epoch 52:	0.08402781  	0.15314633  	0.15305933  
2023-05-24 15:15:23.192: [iter 53 : loss : 1.0184 = 0.0793 + 0.9278 + 0.0114, time: 39.303545]
2023-05-24 15:15:23.592: epoch 53:	0.08359265  	0.15225270  	0.15232758  
2023-05-24 15:15:23.592: Early stopping is trigger at epoch: 53
2023-05-24 15:15:23.592: best_result@epoch 28:

2023-05-24 15:15:23.592: 		0.0876      	0.1667      	0.1652      
2023-05-24 15:18:33.398: my pid: 5340
2023-05-24 15:18:33.398: model: model.general_recommender.SGL
2023-05-24 15:18:33.398: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 15:18:33.398: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 15:18:38.427: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 15:19:13.919: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 35.491493]
2023-05-24 15:19:14.334: epoch 1:	0.00296518  	0.00735567  	0.00575102  
2023-05-24 15:19:14.335: Find a better model.
2023-05-24 15:19:49.396: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 35.055096]
2023-05-24 15:19:49.797: epoch 2:	0.00394282  	0.00915322  	0.00758516  
2023-05-24 15:19:49.797: Find a better model.
2023-05-24 15:20:25.042: [iter 3 : loss : 1.6076 = 0.6930 + 0.9145 + 0.0000, time: 35.237799]
2023-05-24 15:20:25.459: epoch 3:	0.00465725  	0.00979082  	0.00850732  
2023-05-24 15:20:25.459: Find a better model.
2023-05-24 15:21:00.551: [iter 4 : loss : 1.6078 = 0.6930 + 0.9148 + 0.0000, time: 35.085227]
2023-05-24 15:21:00.950: epoch 4:	0.00484526  	0.01059586  	0.00875067  
2023-05-24 15:21:00.951: Find a better model.
2023-05-24 15:21:36.168: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 35.211374]
2023-05-24 15:21:36.592: epoch 5:	0.00561878  	0.01157434  	0.01024149  
2023-05-24 15:21:36.593: Find a better model.
2023-05-24 15:22:11.854: [iter 6 : loss : 1.6082 = 0.6928 + 0.9153 + 0.0000, time: 35.253319]
2023-05-24 15:22:12.276: epoch 6:	0.00639767  	0.01219901  	0.01102735  
2023-05-24 15:22:12.276: Find a better model.
2023-05-24 15:22:47.393: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 35.110239]
2023-05-24 15:22:47.796: epoch 7:	0.00711749  	0.01319541  	0.01213542  
2023-05-24 15:22:47.796: Find a better model.
2023-05-24 15:23:22.968: [iter 8 : loss : 1.6084 = 0.6926 + 0.9158 + 0.0000, time: 35.164081]
2023-05-24 15:23:23.382: epoch 8:	0.00789104  	0.01477515  	0.01373267  
2023-05-24 15:23:23.382: Find a better model.
2023-05-24 15:23:58.526: [iter 9 : loss : 1.6087 = 0.6924 + 0.9162 + 0.0000, time: 35.136774]
2023-05-24 15:23:58.926: epoch 9:	0.00973361  	0.01912601  	0.01729940  
2023-05-24 15:23:58.926: Find a better model.
2023-05-24 15:24:34.374: [iter 10 : loss : 1.6087 = 0.6922 + 0.9164 + 0.0000, time: 35.442006]
2023-05-24 15:24:34.799: epoch 10:	0.01112490  	0.02076957  	0.01930229  
2023-05-24 15:24:34.800: Find a better model.
2023-05-24 15:25:10.882: [iter 11 : loss : 1.6087 = 0.6919 + 0.9167 + 0.0000, time: 36.075148]
2023-05-24 15:25:11.302: epoch 11:	0.01340259  	0.02585892  	0.02421689  
2023-05-24 15:25:11.302: Find a better model.
2023-05-24 15:25:47.271: [iter 12 : loss : 1.6087 = 0.6915 + 0.9172 + 0.0000, time: 35.962020]
2023-05-24 15:25:47.670: epoch 12:	0.01669019  	0.03201315  	0.03062819  
2023-05-24 15:25:47.670: Find a better model.
2023-05-24 15:26:23.658: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 35.980201]
2023-05-24 15:26:24.055: epoch 13:	0.02133151  	0.04203999  	0.04094327  
2023-05-24 15:26:24.055: Find a better model.
2023-05-24 15:27:00.347: [iter 14 : loss : 1.6081 = 0.6898 + 0.9183 + 0.0000, time: 36.284726]
2023-05-24 15:27:00.749: epoch 14:	0.02827182  	0.05533377  	0.05376155  
2023-05-24 15:27:00.750: Find a better model.
2023-05-24 15:27:37.042: [iter 15 : loss : 1.6070 = 0.6879 + 0.9190 + 0.0001, time: 36.284618]
2023-05-24 15:27:37.450: epoch 15:	0.03646850  	0.07047253  	0.06988808  
2023-05-24 15:27:37.450: Find a better model.
2023-05-24 15:28:13.463: [iter 16 : loss : 1.6047 = 0.6843 + 0.9203 + 0.0001, time: 36.007121]
2023-05-24 15:28:13.891: epoch 16:	0.04747476  	0.09126856  	0.09108209  
2023-05-24 15:28:13.891: Find a better model.
2023-05-24 15:28:49.943: [iter 17 : loss : 1.5991 = 0.6770 + 0.9220 + 0.0001, time: 36.046251]
2023-05-24 15:28:50.373: epoch 17:	0.05962511  	0.11309426  	0.11412965  
2023-05-24 15:28:50.374: Find a better model.
2023-05-24 15:29:26.440: [iter 18 : loss : 1.5864 = 0.6612 + 0.9249 + 0.0003, time: 36.059370]
2023-05-24 15:29:26.845: epoch 18:	0.07021775  	0.13198496  	0.13297689  
2023-05-24 15:29:26.845: Find a better model.
2023-05-24 15:30:03.011: [iter 19 : loss : 1.5599 = 0.6299 + 0.9295 + 0.0005, time: 36.159998]
2023-05-24 15:30:03.427: epoch 19:	0.07724900  	0.14533980  	0.14631677  
2023-05-24 15:30:03.427: Find a better model.
2023-05-24 15:30:39.795: [iter 20 : loss : 1.5172 = 0.5804 + 0.9361 + 0.0008, time: 36.361686]
2023-05-24 15:30:40.218: epoch 20:	0.08117557  	0.15297902  	0.15288948  
2023-05-24 15:30:40.218: Find a better model.
2023-05-24 15:31:16.381: [iter 21 : loss : 1.4633 = 0.5187 + 0.9434 + 0.0012, time: 36.156169]
2023-05-24 15:31:16.784: epoch 21:	0.08332954  	0.15713550  	0.15689039  
2023-05-24 15:31:16.784: Find a better model.
2023-05-24 15:31:53.008: [iter 22 : loss : 1.4077 = 0.4565 + 0.9494 + 0.0017, time: 36.218192]
2023-05-24 15:31:53.413: epoch 22:	0.08455417  	0.15949950  	0.15893683  
2023-05-24 15:31:53.413: Find a better model.
2023-05-24 15:32:29.541: [iter 23 : loss : 1.3576 = 0.4020 + 0.9534 + 0.0022, time: 36.121271]
2023-05-24 15:32:29.935: epoch 23:	0.08544054  	0.16183855  	0.16098133  
2023-05-24 15:32:29.935: Find a better model.
2023-05-24 15:33:06.187: [iter 24 : loss : 1.3142 = 0.3560 + 0.9554 + 0.0027, time: 36.245086]
2023-05-24 15:33:06.584: epoch 24:	0.08633216  	0.16340347  	0.16236228  
2023-05-24 15:33:06.584: Find a better model.
2023-05-24 15:33:42.829: [iter 25 : loss : 1.2780 = 0.3189 + 0.9559 + 0.0032, time: 36.239362]
2023-05-24 15:33:43.250: epoch 25:	0.08705195  	0.16531815  	0.16354872  
2023-05-24 15:33:43.250: Find a better model.
2023-05-24 15:34:19.361: [iter 26 : loss : 1.2467 = 0.2873 + 0.9558 + 0.0036, time: 36.104245]
2023-05-24 15:34:19.780: epoch 26:	0.08757306  	0.16639614  	0.16422483  
2023-05-24 15:34:19.781: Find a better model.
2023-05-24 15:34:55.881: [iter 27 : loss : 1.2204 = 0.2613 + 0.9550 + 0.0041, time: 36.092294]
2023-05-24 15:34:56.310: epoch 27:	0.08775023  	0.16649851  	0.16437520  
2023-05-24 15:34:56.310: Find a better model.
2023-05-24 15:35:32.510: [iter 28 : loss : 1.1981 = 0.2395 + 0.9541 + 0.0045, time: 36.191244]
2023-05-24 15:35:32.903: epoch 28:	0.08796518  	0.16660918  	0.16427174  
2023-05-24 15:35:32.904: Find a better model.
2023-05-24 15:36:09.281: [iter 29 : loss : 1.1790 = 0.2212 + 0.9529 + 0.0049, time: 36.370477]
2023-05-24 15:36:09.674: epoch 29:	0.08786850  	0.16661775  	0.16424029  
2023-05-24 15:36:09.674: Find a better model.
2023-05-24 15:36:46.255: [iter 30 : loss : 1.1621 = 0.2052 + 0.9516 + 0.0053, time: 36.575396]
2023-05-24 15:36:46.651: epoch 30:	0.08805650  	0.16649190  	0.16433771  
2023-05-24 15:37:22.923: [iter 31 : loss : 1.1471 = 0.1909 + 0.9505 + 0.0057, time: 36.266338]
2023-05-24 15:37:23.338: epoch 31:	0.08791155  	0.16618447  	0.16391525  
2023-05-24 15:37:59.415: [iter 32 : loss : 1.1349 = 0.1794 + 0.9494 + 0.0060, time: 36.068229]
2023-05-24 15:37:59.813: epoch 32:	0.08773433  	0.16570780  	0.16340016  
2023-05-24 15:38:36.227: [iter 33 : loss : 1.1229 = 0.1682 + 0.9483 + 0.0064, time: 36.406043]
2023-05-24 15:38:36.619: epoch 33:	0.08760010  	0.16521093  	0.16302277  
2023-05-24 15:39:13.010: [iter 34 : loss : 1.1135 = 0.1595 + 0.9473 + 0.0067, time: 36.384806]
2023-05-24 15:39:13.414: epoch 34:	0.08751958  	0.16487701  	0.16241424  
2023-05-24 15:39:49.680: [iter 35 : loss : 1.1038 = 0.1503 + 0.9464 + 0.0070, time: 36.258292]
2023-05-24 15:39:50.098: epoch 35:	0.08735300  	0.16464745  	0.16206892  
2023-05-24 15:40:26.409: [iter 36 : loss : 1.0959 = 0.1432 + 0.9454 + 0.0073, time: 36.304897]
2023-05-24 15:40:26.805: epoch 36:	0.08729932  	0.16417710  	0.16177523  
2023-05-24 15:41:03.219: [iter 37 : loss : 1.0880 = 0.1359 + 0.9445 + 0.0076, time: 36.408175]
2023-05-24 15:41:03.617: epoch 37:	0.08731538  	0.16397697  	0.16154335  
2023-05-24 15:41:39.964: [iter 38 : loss : 1.0818 = 0.1302 + 0.9437 + 0.0079, time: 36.341109]
2023-05-24 15:41:40.372: epoch 38:	0.08731010  	0.16367322  	0.16139770  
2023-05-24 15:42:16.729: [iter 39 : loss : 1.0760 = 0.1249 + 0.9429 + 0.0082, time: 36.350101]
2023-05-24 15:42:17.121: epoch 39:	0.08713818  	0.16285610  	0.16066052  
2023-05-24 15:42:53.561: [iter 40 : loss : 1.0706 = 0.1200 + 0.9421 + 0.0085, time: 36.432054]
2023-05-24 15:42:53.954: epoch 40:	0.08691251  	0.16153638  	0.15974501  
2023-05-24 15:43:30.537: [iter 41 : loss : 1.0654 = 0.1152 + 0.9415 + 0.0087, time: 36.576221]
2023-05-24 15:43:30.963: epoch 41:	0.08679443  	0.16116662  	0.15930659  
2023-05-24 15:44:07.308: [iter 42 : loss : 1.0608 = 0.1109 + 0.9409 + 0.0090, time: 36.338718]
2023-05-24 15:44:07.710: epoch 42:	0.08674069  	0.16082363  	0.15874408  
2023-05-24 15:44:44.349: [iter 43 : loss : 1.0564 = 0.1068 + 0.9403 + 0.0092, time: 36.633167]
2023-05-24 15:44:44.808: epoch 43:	0.08652580  	0.15990143  	0.15811148  
2023-05-24 15:45:32.496: my pid: 12032
2023-05-24 15:45:32.496: model: model.general_recommender.SGL
2023-05-24 15:45:32.496: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 15:45:32.496: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 15:45:37.417: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 15:46:14.323: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 36.905919]
2023-05-24 15:46:14.728: epoch 1:	0.00337880  	0.00807749  	0.00656585  
2023-05-24 15:46:14.728: Find a better model.
2023-05-24 15:46:51.275: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 36.540651]
2023-05-24 15:46:51.702: epoch 2:	0.00420603  	0.00948111  	0.00820640  
2023-05-24 15:46:51.702: Find a better model.
2023-05-24 15:47:28.315: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 36.605502]
2023-05-24 15:47:28.716: epoch 3:	0.00493658  	0.01017637  	0.00911207  
2023-05-24 15:47:28.716: Find a better model.
2023-05-24 15:48:05.345: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 36.623542]
2023-05-24 15:48:05.776: epoch 4:	0.00538780  	0.01099415  	0.00942833  
2023-05-24 15:48:05.776: Find a better model.
2023-05-24 15:48:42.189: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 36.406325]
2023-05-24 15:48:42.589: epoch 5:	0.00636544  	0.01287323  	0.01113765  
2023-05-24 15:48:42.589: Find a better model.
2023-05-24 15:49:19.305: [iter 6 : loss : 1.6067 = 0.6929 + 0.9139 + 0.0000, time: 36.709351]
2023-05-24 15:49:19.709: epoch 6:	0.00684889  	0.01343150  	0.01244461  
2023-05-24 15:49:19.709: Find a better model.
2023-05-24 15:49:56.281: [iter 7 : loss : 1.6068 = 0.6928 + 0.9141 + 0.0000, time: 36.564997]
2023-05-24 15:49:56.681: epoch 7:	0.00780509  	0.01476091  	0.01331042  
2023-05-24 15:49:56.681: Find a better model.
2023-05-24 15:50:33.326: [iter 8 : loss : 1.6068 = 0.6927 + 0.9141 + 0.0000, time: 36.637138]
2023-05-24 15:50:33.728: epoch 8:	0.00943815  	0.01698818  	0.01583513  
2023-05-24 15:50:33.728: Find a better model.
2023-05-24 15:51:10.250: [iter 9 : loss : 1.6069 = 0.6925 + 0.9144 + 0.0000, time: 36.516158]
2023-05-24 15:51:10.650: epoch 9:	0.01121624  	0.02089916  	0.01911004  
2023-05-24 15:51:10.651: Find a better model.
2023-05-24 15:51:47.270: [iter 10 : loss : 1.6069 = 0.6923 + 0.9145 + 0.0000, time: 36.613146]
2023-05-24 15:51:47.668: epoch 10:	0.01245715  	0.02363614  	0.02191894  
2023-05-24 15:51:47.668: Find a better model.
2023-05-24 15:52:24.997: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 37.323092]
2023-05-24 15:52:25.407: epoch 11:	0.01529888  	0.02936167  	0.02787820  
2023-05-24 15:52:25.407: Find a better model.
2023-05-24 15:53:02.928: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 37.513899]
2023-05-24 15:53:03.343: epoch 12:	0.01864020  	0.03627537  	0.03464649  
2023-05-24 15:53:03.343: Find a better model.
2023-05-24 15:53:40.583: [iter 13 : loss : 1.6063 = 0.6909 + 0.9154 + 0.0000, time: 37.234167]
2023-05-24 15:53:40.981: epoch 13:	0.02290548  	0.04628789  	0.04387348  
2023-05-24 15:53:40.981: Find a better model.
2023-05-24 15:54:18.466: [iter 14 : loss : 1.6057 = 0.6898 + 0.9158 + 0.0000, time: 37.478597]
2023-05-24 15:54:18.888: epoch 14:	0.02881435  	0.05799001  	0.05606280  
2023-05-24 15:54:18.889: Find a better model.
2023-05-24 15:54:56.471: [iter 15 : loss : 1.6044 = 0.6879 + 0.9164 + 0.0001, time: 37.573588]
2023-05-24 15:54:56.867: epoch 15:	0.03826258  	0.07524455  	0.07414260  
2023-05-24 15:54:56.867: Find a better model.
2023-05-24 15:55:34.566: [iter 16 : loss : 1.6016 = 0.6841 + 0.9174 + 0.0001, time: 37.693635]
2023-05-24 15:55:34.990: epoch 16:	0.04882301  	0.09434405  	0.09416500  
2023-05-24 15:55:34.990: Find a better model.
2023-05-24 15:56:12.420: [iter 17 : loss : 1.5950 = 0.6760 + 0.9189 + 0.0001, time: 37.422580]
2023-05-24 15:56:12.823: epoch 17:	0.06082292  	0.11611920  	0.11668558  
2023-05-24 15:56:12.823: Find a better model.
2023-05-24 15:56:50.368: [iter 18 : loss : 1.5802 = 0.6582 + 0.9217 + 0.0003, time: 37.538119]
2023-05-24 15:56:50.788: epoch 18:	0.07118443  	0.13358818  	0.13533930  
2023-05-24 15:56:50.788: Find a better model.
2023-05-24 15:57:28.283: [iter 19 : loss : 1.5503 = 0.6239 + 0.9260 + 0.0005, time: 37.488493]
2023-05-24 15:57:28.682: epoch 19:	0.07771620  	0.14529753  	0.14766443  
2023-05-24 15:57:28.683: Find a better model.
2023-05-24 15:58:06.298: [iter 20 : loss : 1.5044 = 0.5716 + 0.9320 + 0.0008, time: 37.607384]
2023-05-24 15:58:06.692: epoch 20:	0.08124520  	0.15279730  	0.15395409  
2023-05-24 15:58:06.692: Find a better model.
2023-05-24 15:58:44.068: [iter 21 : loss : 1.4490 = 0.5090 + 0.9387 + 0.0012, time: 37.369097]
2023-05-24 15:58:44.467: epoch 21:	0.08354963  	0.15718143  	0.15766315  
2023-05-24 15:58:44.467: Find a better model.
2023-05-24 15:59:22.188: [iter 22 : loss : 1.3930 = 0.4472 + 0.9441 + 0.0017, time: 37.715194]
2023-05-24 15:59:22.582: epoch 22:	0.08496235  	0.15982571  	0.16012405  
2023-05-24 15:59:22.582: Find a better model.
2023-05-24 16:00:00.463: [iter 23 : loss : 1.3437 = 0.3936 + 0.9478 + 0.0023, time: 37.873387]
2023-05-24 16:00:00.856: epoch 23:	0.08623540  	0.16262913  	0.16194946  
2023-05-24 16:00:00.856: Find a better model.
2023-05-24 16:00:38.458: [iter 24 : loss : 1.3011 = 0.3486 + 0.9498 + 0.0028, time: 37.595112]
2023-05-24 16:00:38.877: epoch 24:	0.08686391  	0.16417018  	0.16292568  
2023-05-24 16:00:38.877: Find a better model.
2023-05-24 16:01:16.531: [iter 25 : loss : 1.2658 = 0.3123 + 0.9502 + 0.0032, time: 37.647462]
2023-05-24 16:01:16.925: epoch 25:	0.08741177  	0.16529544  	0.16356891  
2023-05-24 16:01:16.925: Find a better model.
2023-05-24 16:01:54.670: [iter 26 : loss : 1.2356 = 0.2818 + 0.9501 + 0.0037, time: 37.737897]
2023-05-24 16:01:55.066: epoch 26:	0.08795434  	0.16612040  	0.16428635  
2023-05-24 16:01:55.066: Find a better model.
2023-05-24 16:02:32.667: [iter 27 : loss : 1.2101 = 0.2565 + 0.9495 + 0.0041, time: 37.594099]
2023-05-24 16:02:33.062: epoch 27:	0.08798116  	0.16610251  	0.16430166  
2023-05-24 16:03:10.772: [iter 28 : loss : 1.1885 = 0.2353 + 0.9487 + 0.0046, time: 37.701397]
2023-05-24 16:03:11.216: epoch 28:	0.08811556  	0.16642970  	0.16444512  
2023-05-24 16:03:11.216: Find a better model.
2023-05-24 16:03:49.137: [iter 29 : loss : 1.1701 = 0.2176 + 0.9475 + 0.0050, time: 37.914398]
2023-05-24 16:03:49.564: epoch 29:	0.08797591  	0.16605702  	0.16403733  
2023-05-24 16:04:27.356: [iter 30 : loss : 1.1537 = 0.2020 + 0.9463 + 0.0054, time: 37.785440]
2023-05-24 16:04:27.753: epoch 30:	0.08793834  	0.16613798  	0.16392121  
2023-05-24 16:05:05.572: [iter 31 : loss : 1.1391 = 0.1881 + 0.9453 + 0.0057, time: 37.812074]
2023-05-24 16:05:05.992: epoch 31:	0.08791145  	0.16616634  	0.16370751  
2023-05-24 16:05:43.663: [iter 32 : loss : 1.1272 = 0.1768 + 0.9443 + 0.0061, time: 37.665207]
2023-05-24 16:05:44.085: epoch 32:	0.08790069  	0.16626251  	0.16363388  
2023-05-24 16:06:21.860: [iter 33 : loss : 1.1157 = 0.1661 + 0.9432 + 0.0064, time: 37.768095]
2023-05-24 16:06:22.281: epoch 33:	0.08779329  	0.16574860  	0.16308194  
2023-05-24 16:07:00.179: [iter 34 : loss : 1.1068 = 0.1578 + 0.9422 + 0.0068, time: 37.892110]
2023-05-24 16:07:00.572: epoch 34:	0.08764282  	0.16494396  	0.16253670  
2023-05-24 16:07:38.467: [iter 35 : loss : 1.0971 = 0.1487 + 0.9414 + 0.0071, time: 37.887870]
2023-05-24 16:07:38.887: epoch 35:	0.08737959  	0.16447549  	0.16190115  
2023-05-24 16:08:16.833: [iter 36 : loss : 1.0896 = 0.1418 + 0.9404 + 0.0074, time: 37.937930]
2023-05-24 16:08:17.254: epoch 36:	0.08713789  	0.16401252  	0.16139938  
2023-05-24 16:08:55.243: [iter 37 : loss : 1.0821 = 0.1349 + 0.9396 + 0.0077, time: 37.982193]
2023-05-24 16:08:55.641: epoch 37:	0.08699825  	0.16345298  	0.16103992  
2023-05-24 16:09:33.670: [iter 38 : loss : 1.0757 = 0.1289 + 0.9388 + 0.0080, time: 38.021387]
2023-05-24 16:09:34.093: epoch 38:	0.08683170  	0.16270466  	0.16049360  
2023-05-24 16:10:12.009: [iter 39 : loss : 1.0701 = 0.1238 + 0.9380 + 0.0082, time: 37.908999]
2023-05-24 16:10:12.423: epoch 39:	0.08662756  	0.16214497  	0.15986128  
2023-05-24 16:11:24.836: my pid: 1244
2023-05-24 16:11:24.836: model: model.general_recommender.SGL
2023-05-24 16:11:24.836: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 16:11:24.836: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 16:11:29.732: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 16:12:09.251: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 39.519352]
2023-05-24 16:12:09.678: epoch 1:	0.00349160  	0.00821223  	0.00674875  
2023-05-24 16:12:09.678: Find a better model.
2023-05-24 16:12:48.852: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 39.168122]
2023-05-24 16:12:49.283: epoch 2:	0.00411472  	0.00870434  	0.00735326  
2023-05-24 16:12:49.283: Find a better model.
2023-05-24 16:13:28.481: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 39.192008]
2023-05-24 16:13:28.884: epoch 3:	0.00513533  	0.01078933  	0.00928117  
2023-05-24 16:13:28.884: Find a better model.
2023-05-24 16:14:08.213: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 39.322011]
2023-05-24 16:14:08.617: epoch 4:	0.00604314  	0.01171840  	0.01048327  
2023-05-24 16:14:08.617: Find a better model.
2023-05-24 16:14:47.874: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 39.251227]
2023-05-24 16:14:48.298: epoch 5:	0.00712823  	0.01388803  	0.01248124  
2023-05-24 16:14:48.298: Find a better model.
2023-05-24 16:15:27.608: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 39.301970]
2023-05-24 16:15:28.038: epoch 6:	0.00838526  	0.01581074  	0.01438362  
2023-05-24 16:15:28.038: Find a better model.
2023-05-24 16:16:07.377: [iter 7 : loss : 1.6045 = 0.6928 + 0.9118 + 0.0000, time: 39.333614]
2023-05-24 16:16:07.778: epoch 7:	0.00974434  	0.01849503  	0.01673545  
2023-05-24 16:16:07.778: Find a better model.
2023-05-24 16:16:47.016: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 39.230291]
2023-05-24 16:16:47.436: epoch 8:	0.01081872  	0.02081267  	0.01917062  
2023-05-24 16:16:47.436: Find a better model.
2023-05-24 16:17:26.767: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 39.325115]
2023-05-24 16:17:27.170: epoch 9:	0.01225839  	0.02384916  	0.02214896  
2023-05-24 16:17:27.170: Find a better model.
2023-05-24 16:18:06.324: [iter 10 : loss : 1.6041 = 0.6922 + 0.9119 + 0.0000, time: 39.148138]
2023-05-24 16:18:06.723: epoch 10:	0.01446623  	0.02762912  	0.02612099  
2023-05-24 16:18:06.723: Find a better model.
2023-05-24 16:18:46.721: [iter 11 : loss : 1.6037 = 0.6919 + 0.9118 + 0.0000, time: 39.991614]
2023-05-24 16:18:47.121: epoch 11:	0.01736171  	0.03384026  	0.03227823  
2023-05-24 16:18:47.122: Find a better model.
2023-05-24 16:19:27.310: [iter 12 : loss : 1.6034 = 0.6914 + 0.9120 + 0.0000, time: 40.182432]
2023-05-24 16:19:27.715: epoch 12:	0.02106834  	0.04136984  	0.04008689  
2023-05-24 16:19:27.715: Find a better model.
2023-05-24 16:20:07.973: [iter 13 : loss : 1.6027 = 0.6906 + 0.9121 + 0.0000, time: 40.252246]
2023-05-24 16:20:08.391: epoch 13:	0.02565590  	0.05172282  	0.04978075  
2023-05-24 16:20:08.391: Find a better model.
2023-05-24 16:20:48.594: [iter 14 : loss : 1.6016 = 0.6891 + 0.9124 + 0.0000, time: 40.196035]
2023-05-24 16:20:49.021: epoch 14:	0.03224667  	0.06557053  	0.06405833  
2023-05-24 16:20:49.021: Find a better model.
2023-05-24 16:21:29.103: [iter 15 : loss : 1.5992 = 0.6864 + 0.9128 + 0.0001, time: 40.074355]
2023-05-24 16:21:29.522: epoch 15:	0.04109868  	0.08434731  	0.08243126  
2023-05-24 16:21:29.522: Find a better model.
2023-05-24 16:22:09.515: [iter 16 : loss : 1.5943 = 0.6806 + 0.9135 + 0.0001, time: 39.987154]
2023-05-24 16:22:09.939: epoch 16:	0.05183638  	0.10319595  	0.10254490  
2023-05-24 16:22:09.940: Find a better model.
2023-05-24 16:22:50.080: [iter 17 : loss : 1.5828 = 0.6677 + 0.9149 + 0.0002, time: 40.133164]
2023-05-24 16:22:50.498: epoch 17:	0.06392223  	0.12387842  	0.12369072  
2023-05-24 16:22:50.498: Find a better model.
2023-05-24 16:23:30.716: [iter 18 : loss : 1.5587 = 0.6406 + 0.9178 + 0.0003, time: 40.210484]
2023-05-24 16:23:31.139: epoch 18:	0.07337065  	0.13980362  	0.14012748  
2023-05-24 16:23:31.139: Find a better model.
2023-05-24 16:24:11.308: [iter 19 : loss : 1.5169 = 0.5937 + 0.9225 + 0.0006, time: 40.161384]
2023-05-24 16:24:11.703: epoch 19:	0.07894640  	0.14917123  	0.14991660  
2023-05-24 16:24:11.703: Find a better model.
2023-05-24 16:24:51.834: [iter 20 : loss : 1.4624 = 0.5326 + 0.9288 + 0.0010, time: 40.124101]
2023-05-24 16:24:52.260: epoch 20:	0.08220688  	0.15456836  	0.15534191  
2023-05-24 16:24:52.260: Find a better model.
2023-05-24 16:25:32.306: [iter 21 : loss : 1.4049 = 0.4688 + 0.9347 + 0.0015, time: 40.038647]
2023-05-24 16:25:32.710: epoch 21:	0.08428559  	0.15878433  	0.15885204  
2023-05-24 16:25:32.710: Find a better model.
2023-05-24 16:26:13.037: [iter 22 : loss : 1.3521 = 0.4111 + 0.9390 + 0.0020, time: 40.319708]
2023-05-24 16:26:13.442: epoch 22:	0.08544034  	0.16128759  	0.16091196  
2023-05-24 16:26:13.442: Find a better model.
2023-05-24 16:26:53.393: [iter 23 : loss : 1.3075 = 0.3634 + 0.9416 + 0.0025, time: 39.945597]
2023-05-24 16:26:53.796: epoch 23:	0.08590229  	0.16184981  	0.16185315  
2023-05-24 16:26:53.796: Find a better model.
2023-05-24 16:27:34.001: [iter 24 : loss : 1.2697 = 0.3238 + 0.9428 + 0.0030, time: 40.198043]
2023-05-24 16:27:34.412: epoch 24:	0.08672968  	0.16331290  	0.16276024  
2023-05-24 16:27:34.412: Find a better model.
2023-05-24 16:28:14.551: [iter 25 : loss : 1.2387 = 0.2923 + 0.9429 + 0.0035, time: 40.131561]
2023-05-24 16:28:14.974: epoch 25:	0.08715401  	0.16416723  	0.16317709  
2023-05-24 16:28:14.974: Find a better model.
2023-05-24 16:28:54.917: [iter 26 : loss : 1.2117 = 0.2653 + 0.9425 + 0.0039, time: 39.936636]
2023-05-24 16:28:55.336: epoch 26:	0.08728298  	0.16476639  	0.16359454  
2023-05-24 16:28:55.336: Find a better model.
2023-05-24 16:29:35.567: [iter 27 : loss : 1.1890 = 0.2428 + 0.9418 + 0.0044, time: 40.223438]
2023-05-24 16:29:35.964: epoch 27:	0.08765357  	0.16557017  	0.16391264  
2023-05-24 16:29:35.964: Find a better model.
2023-05-24 16:30:16.588: [iter 28 : loss : 1.1696 = 0.2238 + 0.9410 + 0.0048, time: 40.618224]
2023-05-24 16:30:16.986: epoch 28:	0.08776633  	0.16562828  	0.16411772  
2023-05-24 16:30:16.986: Find a better model.
2023-05-24 16:30:57.483: [iter 29 : loss : 1.1532 = 0.2082 + 0.9399 + 0.0052, time: 40.490650]
2023-05-24 16:30:57.879: epoch 29:	0.08755688  	0.16535643  	0.16396737  
2023-05-24 16:31:38.326: [iter 30 : loss : 1.1384 = 0.1940 + 0.9388 + 0.0055, time: 40.440553]
2023-05-24 16:31:38.755: epoch 30:	0.08752999  	0.16473639  	0.16343977  
2023-05-24 16:32:19.115: [iter 31 : loss : 1.1250 = 0.1813 + 0.9378 + 0.0059, time: 40.349491]
2023-05-24 16:32:19.518: epoch 31:	0.08744944  	0.16453744  	0.16307236  
2023-05-24 16:33:00.119: [iter 32 : loss : 1.1140 = 0.1709 + 0.9368 + 0.0062, time: 40.594158]
2023-05-24 16:33:00.520: epoch 32:	0.08756229  	0.16453275  	0.16295488  
2023-05-24 16:33:41.069: [iter 33 : loss : 1.1035 = 0.1610 + 0.9359 + 0.0066, time: 40.542354]
2023-05-24 16:33:41.476: epoch 33:	0.08725613  	0.16349442  	0.16243662  
2023-05-24 16:34:22.117: [iter 34 : loss : 1.0951 = 0.1533 + 0.9350 + 0.0069, time: 40.634897]
2023-05-24 16:34:22.526: epoch 34:	0.08722932  	0.16348939  	0.16215692  
2023-05-24 16:35:02.993: [iter 35 : loss : 1.0863 = 0.1449 + 0.9343 + 0.0072, time: 40.460133]
2023-05-24 16:35:03.408: epoch 35:	0.08692311  	0.16300967  	0.16156621  
2023-05-24 16:35:43.622: [iter 36 : loss : 1.0790 = 0.1382 + 0.9334 + 0.0075, time: 40.208085]
2023-05-24 16:35:44.047: epoch 36:	0.08664916  	0.16212285  	0.16070187  
2023-05-24 16:36:24.643: [iter 37 : loss : 1.0719 = 0.1316 + 0.9325 + 0.0078, time: 40.589496]
2023-05-24 16:36:25.044: epoch 37:	0.08665994  	0.16202460  	0.16041651  
2023-05-24 16:37:40.470: my pid: 9084
2023-05-24 16:37:40.470: model: model.general_recommender.SGL
2023-05-24 16:37:40.470: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 16:37:40.471: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 16:37:45.362: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 16:38:25.540: [iter 1 : loss : 1.6068 = 0.6931 + 0.9136 + 0.0000, time: 40.178562]
2023-05-24 16:38:25.947: epoch 1:	0.00398042  	0.00875837  	0.00757808  
2023-05-24 16:38:25.947: Find a better model.
2023-05-24 16:39:06.468: [iter 2 : loss : 1.6045 = 0.6931 + 0.9114 + 0.0000, time: 40.513759]
2023-05-24 16:39:06.873: epoch 2:	0.00478080  	0.00989423  	0.00854846  
2023-05-24 16:39:06.873: Find a better model.
2023-05-24 16:39:47.384: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 40.504870]
2023-05-24 16:39:47.785: epoch 3:	0.00566175  	0.01142239  	0.01010403  
2023-05-24 16:39:47.785: Find a better model.
2023-05-24 16:40:28.211: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 40.420544]
2023-05-24 16:40:28.616: epoch 4:	0.00656956  	0.01223412  	0.01126100  
2023-05-24 16:40:28.616: Find a better model.
2023-05-24 16:41:09.171: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 40.547227]
2023-05-24 16:41:09.590: epoch 5:	0.00781047  	0.01443362  	0.01366854  
2023-05-24 16:41:09.590: Find a better model.
2023-05-24 16:41:49.996: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 40.400088]
2023-05-24 16:41:50.430: epoch 6:	0.00903526  	0.01660175  	0.01595149  
2023-05-24 16:41:50.430: Find a better model.
2023-05-24 16:42:30.886: [iter 7 : loss : 1.6035 = 0.6927 + 0.9108 + 0.0000, time: 40.450559]
2023-05-24 16:42:31.334: epoch 7:	0.01024931  	0.01879452  	0.01769141  
2023-05-24 16:42:31.334: Find a better model.
2023-05-24 16:43:11.938: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 40.597998]
2023-05-24 16:43:12.381: epoch 8:	0.01145798  	0.02116834  	0.01978062  
2023-05-24 16:43:12.381: Find a better model.
2023-05-24 16:43:52.903: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 40.515564]
2023-05-24 16:43:53.333: epoch 9:	0.01377864  	0.02622136  	0.02398405  
2023-05-24 16:43:53.334: Find a better model.
2023-05-24 16:44:33.997: [iter 10 : loss : 1.6029 = 0.6921 + 0.9107 + 0.0000, time: 40.656736]
2023-05-24 16:44:34.419: epoch 10:	0.01519683  	0.02964116  	0.02722461  
2023-05-24 16:44:34.419: Find a better model.
2023-05-24 16:45:15.633: [iter 11 : loss : 1.6024 = 0.6917 + 0.9106 + 0.0000, time: 41.205585]
2023-05-24 16:45:16.034: epoch 11:	0.01809764  	0.03627735  	0.03382691  
2023-05-24 16:45:16.035: Find a better model.
2023-05-24 16:45:57.684: [iter 12 : loss : 1.6019 = 0.6911 + 0.9107 + 0.0000, time: 41.642772]
2023-05-24 16:45:58.093: epoch 12:	0.02148732  	0.04323922  	0.04108972  
2023-05-24 16:45:58.093: Find a better model.
2023-05-24 16:46:39.642: [iter 13 : loss : 1.6010 = 0.6901 + 0.9108 + 0.0000, time: 41.542869]
2023-05-24 16:46:40.042: epoch 13:	0.02601044  	0.05389835  	0.05102675  
2023-05-24 16:46:40.042: Find a better model.
2023-05-24 16:47:21.680: [iter 14 : loss : 1.5994 = 0.6883 + 0.9110 + 0.0000, time: 41.631146]
2023-05-24 16:47:22.082: epoch 14:	0.03179542  	0.06677122  	0.06329775  
2023-05-24 16:47:22.083: Find a better model.
2023-05-24 16:48:03.588: [iter 15 : loss : 1.5961 = 0.6846 + 0.9114 + 0.0001, time: 41.499493]
2023-05-24 16:48:03.984: epoch 15:	0.04074951  	0.08590627  	0.08108696  
2023-05-24 16:48:03.984: Find a better model.
2023-05-24 16:48:45.469: [iter 16 : loss : 1.5890 = 0.6767 + 0.9122 + 0.0001, time: 41.478076]
2023-05-24 16:48:45.875: epoch 16:	0.05126174  	0.10518083  	0.10154021  
2023-05-24 16:48:45.875: Find a better model.
2023-05-24 16:49:27.333: [iter 17 : loss : 1.5735 = 0.6595 + 0.9138 + 0.0002, time: 41.450951]
2023-05-24 16:49:27.755: epoch 17:	0.06329906  	0.12564789  	0.12360752  
2023-05-24 16:49:27.755: Find a better model.
2023-05-24 16:50:09.311: [iter 18 : loss : 1.5434 = 0.6260 + 0.9170 + 0.0004, time: 41.550078]
2023-05-24 16:50:09.705: epoch 18:	0.07290860  	0.14081733  	0.13995706  
2023-05-24 16:50:09.705: Find a better model.
2023-05-24 16:50:51.110: [iter 19 : loss : 1.4968 = 0.5742 + 0.9219 + 0.0007, time: 41.399367]
2023-05-24 16:50:51.521: epoch 19:	0.07868836  	0.15031600  	0.14937966  
2023-05-24 16:50:51.521: Find a better model.
2023-05-24 16:51:32.818: [iter 20 : loss : 1.4415 = 0.5127 + 0.9277 + 0.0012, time: 41.290724]
2023-05-24 16:51:33.237: epoch 20:	0.08190046  	0.15530750  	0.15470211  
2023-05-24 16:51:33.238: Find a better model.
2023-05-24 16:52:14.697: [iter 21 : loss : 1.3863 = 0.4517 + 0.9329 + 0.0017, time: 41.452163]
2023-05-24 16:52:15.093: epoch 21:	0.08376442  	0.15841210  	0.15811110  
2023-05-24 16:52:15.093: Find a better model.
2023-05-24 16:52:56.566: [iter 22 : loss : 1.3367 = 0.3978 + 0.9367 + 0.0021, time: 41.465672]
2023-05-24 16:52:56.960: epoch 22:	0.08517701  	0.16104591  	0.16030334  
2023-05-24 16:52:56.960: Find a better model.
2023-05-24 16:53:38.614: [iter 23 : loss : 1.2948 = 0.3533 + 0.9389 + 0.0026, time: 41.647860]
2023-05-24 16:53:39.008: epoch 23:	0.08633197  	0.16345230  	0.16205971  
2023-05-24 16:53:39.008: Find a better model.
2023-05-24 16:54:20.805: [iter 24 : loss : 1.2594 = 0.3163 + 0.9400 + 0.0031, time: 41.790324]
2023-05-24 16:54:21.228: epoch 24:	0.08700886  	0.16466965  	0.16291058  
2023-05-24 16:54:21.228: Find a better model.
2023-05-24 16:55:03.065: [iter 25 : loss : 1.2302 = 0.2866 + 0.9400 + 0.0036, time: 41.829061]
2023-05-24 16:55:03.494: epoch 25:	0.08719695  	0.16468112  	0.16346380  
2023-05-24 16:55:03.495: Find a better model.
2023-05-24 16:55:45.248: [iter 26 : loss : 1.2046 = 0.2609 + 0.9397 + 0.0040, time: 41.745159]
2023-05-24 16:55:45.644: epoch 26:	0.08748700  	0.16516085  	0.16383018  
2023-05-24 16:55:45.644: Find a better model.
2023-05-24 16:56:27.336: [iter 27 : loss : 1.1829 = 0.2395 + 0.9390 + 0.0045, time: 41.685776]
2023-05-24 16:56:27.734: epoch 27:	0.08740105  	0.16490434  	0.16370422  
2023-05-24 16:57:09.479: [iter 28 : loss : 1.1645 = 0.2214 + 0.9383 + 0.0049, time: 41.739085]
2023-05-24 16:57:09.877: epoch 28:	0.08746553  	0.16504632  	0.16347812  
2023-05-24 16:57:51.403: [iter 29 : loss : 1.1489 = 0.2063 + 0.9373 + 0.0052, time: 41.518798]
2023-05-24 16:57:51.801: epoch 29:	0.08734738  	0.16456057  	0.16317619  
2023-05-24 16:58:33.252: [iter 30 : loss : 1.1345 = 0.1926 + 0.9363 + 0.0056, time: 41.445657]
2023-05-24 16:58:33.645: epoch 30:	0.08728289  	0.16449711  	0.16298082  
2023-05-24 16:59:15.408: [iter 31 : loss : 1.1214 = 0.1801 + 0.9353 + 0.0060, time: 41.755409]
2023-05-24 16:59:15.817: epoch 31:	0.08713800  	0.16413206  	0.16252562  
2023-05-24 16:59:57.380: [iter 32 : loss : 1.1109 = 0.1702 + 0.9344 + 0.0063, time: 41.555541]
2023-05-24 16:59:57.798: epoch 32:	0.08728299  	0.16417909  	0.16229814  
2023-05-24 17:00:39.533: [iter 33 : loss : 1.1004 = 0.1603 + 0.9335 + 0.0067, time: 41.727967]
2023-05-24 17:00:39.924: epoch 33:	0.08715413  	0.16334249  	0.16184039  
2023-05-24 17:01:21.586: [iter 34 : loss : 1.0924 = 0.1528 + 0.9326 + 0.0070, time: 41.656122]
2023-05-24 17:01:21.980: epoch 34:	0.08688008  	0.16244619  	0.16110671  
2023-05-24 17:02:03.328: [iter 35 : loss : 1.0839 = 0.1447 + 0.9319 + 0.0073, time: 41.341942]
2023-05-24 17:02:03.723: epoch 35:	0.08658469  	0.16188978  	0.16063009  
2023-05-24 17:02:45.350: [iter 36 : loss : 1.0767 = 0.1380 + 0.9311 + 0.0076, time: 41.621062]
2023-05-24 17:02:45.744: epoch 36:	0.08638590  	0.16162041  	0.16003487  
2023-05-24 17:03:27.275: [iter 37 : loss : 1.0697 = 0.1315 + 0.9303 + 0.0079, time: 41.523895]
2023-05-24 17:03:27.693: epoch 37:	0.08624631  	0.16075049  	0.15940119  
2023-05-24 17:04:09.541: [iter 38 : loss : 1.0641 = 0.1264 + 0.9296 + 0.0082, time: 41.840200]
2023-05-24 17:04:09.942: epoch 38:	0.08606903  	0.15961601  	0.15878125  
2023-05-24 17:04:51.416: [iter 39 : loss : 1.0588 = 0.1214 + 0.9289 + 0.0084, time: 41.468872]
2023-05-24 17:04:51.815: epoch 39:	0.08588639  	0.15898989  	0.15814500  
2023-05-24 17:05:33.470: [iter 40 : loss : 1.0539 = 0.1168 + 0.9283 + 0.0087, time: 41.646587]
2023-05-24 17:05:33.866: epoch 40:	0.08554257  	0.15808876  	0.15737899  
2023-05-24 17:06:15.567: [iter 41 : loss : 1.0488 = 0.1122 + 0.9277 + 0.0089, time: 41.692731]
2023-05-24 17:06:15.968: epoch 41:	0.08544050  	0.15733589  	0.15688401  
2023-05-24 17:06:58.076: [iter 42 : loss : 1.0448 = 0.1084 + 0.9272 + 0.0092, time: 42.102025]
2023-05-24 17:06:58.491: epoch 42:	0.08513966  	0.15641524  	0.15623242  
2023-05-24 17:07:40.166: [iter 43 : loss : 1.0407 = 0.1045 + 0.9267 + 0.0094, time: 41.668406]
2023-05-24 17:07:40.576: epoch 43:	0.08494095  	0.15581456  	0.15569516  
2023-05-24 17:08:22.510: [iter 44 : loss : 1.0369 = 0.1009 + 0.9263 + 0.0097, time: 41.926340]
2023-05-24 17:08:22.933: epoch 44:	0.08471000  	0.15505730  	0.15498626  
2023-05-24 17:09:04.745: [iter 45 : loss : 1.0341 = 0.0984 + 0.9258 + 0.0099, time: 41.804287]
2023-05-24 17:09:05.168: epoch 45:	0.08439845  	0.15421282  	0.15409009  
2023-05-24 17:09:47.003: [iter 46 : loss : 1.0306 = 0.0951 + 0.9253 + 0.0101, time: 41.828472]
2023-05-24 17:09:47.431: epoch 46:	0.08424271  	0.15385458  	0.15378492  
2023-05-24 17:10:29.328: [iter 47 : loss : 1.0275 = 0.0922 + 0.9249 + 0.0103, time: 41.889650]
2023-05-24 17:10:29.729: epoch 47:	0.08410839  	0.15312116  	0.15320051  
2023-05-24 17:11:50.346: my pid: 7612
2023-05-24 17:11:50.346: model: model.general_recommender.SGL
2023-05-24 17:11:50.346: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 17:11:50.346: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 17:11:55.225: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 17:12:35.877: [iter 1 : loss : 1.6068 = 0.6931 + 0.9136 + 0.0000, time: 40.651093]
2023-05-24 17:12:36.303: epoch 1:	0.00398042  	0.00875837  	0.00757808  
2023-05-24 17:12:36.303: Find a better model.
2023-05-24 17:13:16.804: [iter 2 : loss : 1.6045 = 0.6931 + 0.9114 + 0.0000, time: 40.490351]
2023-05-24 17:13:17.201: epoch 2:	0.00478080  	0.00989423  	0.00854846  
2023-05-24 17:13:17.202: Find a better model.
2023-05-24 17:13:57.676: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 40.468482]
2023-05-24 17:13:58.077: epoch 3:	0.00566175  	0.01142239  	0.01010403  
2023-05-24 17:13:58.077: Find a better model.
2023-05-24 17:14:38.475: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 40.391126]
2023-05-24 17:14:38.871: epoch 4:	0.00656956  	0.01223412  	0.01126100  
2023-05-24 17:14:38.871: Find a better model.
2023-05-24 17:15:19.429: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 40.551621]
2023-05-24 17:15:19.829: epoch 5:	0.00781047  	0.01443362  	0.01366854  
2023-05-24 17:15:19.829: Find a better model.
2023-05-24 17:16:00.322: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 40.485243]
2023-05-24 17:16:00.736: epoch 6:	0.00903526  	0.01660175  	0.01595149  
2023-05-24 17:16:00.736: Find a better model.
2023-05-24 17:16:41.364: [iter 7 : loss : 1.6035 = 0.6927 + 0.9108 + 0.0000, time: 40.621208]
2023-05-24 17:16:41.787: epoch 7:	0.01024931  	0.01879452  	0.01769141  
2023-05-24 17:16:41.787: Find a better model.
2023-05-24 17:17:22.278: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 40.484833]
2023-05-24 17:17:22.704: epoch 8:	0.01145798  	0.02116834  	0.01978062  
2023-05-24 17:17:22.705: Find a better model.
2023-05-24 17:18:03.373: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 40.661199]
2023-05-24 17:18:03.802: epoch 9:	0.01377864  	0.02622136  	0.02398405  
2023-05-24 17:18:03.802: Find a better model.
2023-05-24 17:18:44.274: [iter 10 : loss : 1.6029 = 0.6921 + 0.9107 + 0.0000, time: 40.463609]
2023-05-24 17:18:44.669: epoch 10:	0.01519683  	0.02964116  	0.02722461  
2023-05-24 17:18:44.669: Find a better model.
2023-05-24 17:19:25.339: [iter 11 : loss : 1.6024 = 0.6917 + 0.9106 + 0.0000, time: 40.664044]
2023-05-24 17:19:25.735: epoch 11:	0.01746376  	0.03546352  	0.03276338  
2023-05-24 17:19:25.735: Find a better model.
2023-05-24 17:20:06.411: [iter 12 : loss : 1.6019 = 0.6911 + 0.9108 + 0.0000, time: 40.669646]
2023-05-24 17:20:06.831: epoch 12:	0.02043442  	0.04189388  	0.03929387  
2023-05-24 17:20:06.832: Find a better model.
2023-05-24 17:20:47.337: [iter 13 : loss : 1.6011 = 0.6902 + 0.9109 + 0.0000, time: 40.498071]
2023-05-24 17:20:47.735: epoch 13:	0.02497904  	0.05210627  	0.04830518  
2023-05-24 17:20:47.736: Find a better model.
2023-05-24 17:21:28.436: [iter 14 : loss : 1.5995 = 0.6883 + 0.9111 + 0.0000, time: 40.694311]
2023-05-24 17:21:28.856: epoch 14:	0.03057078  	0.06559827  	0.06054273  
2023-05-24 17:21:28.856: Find a better model.
2023-05-24 17:22:09.693: [iter 15 : loss : 1.5963 = 0.6847 + 0.9115 + 0.0001, time: 40.829337]
2023-05-24 17:22:10.085: epoch 15:	0.03916496  	0.08405378  	0.07853647  
2023-05-24 17:22:10.086: Find a better model.
2023-05-24 17:22:51.596: [iter 16 : loss : 1.5893 = 0.6769 + 0.9122 + 0.0001, time: 41.502951]
2023-05-24 17:22:51.992: epoch 16:	0.05004773  	0.10340785  	0.09968263  
2023-05-24 17:22:51.992: Find a better model.
2023-05-24 17:23:33.439: [iter 17 : loss : 1.5740 = 0.6600 + 0.9137 + 0.0002, time: 41.441136]
2023-05-24 17:23:33.836: epoch 17:	0.06246643  	0.12400533  	0.12209581  
2023-05-24 17:23:33.836: Find a better model.
2023-05-24 17:24:15.580: [iter 18 : loss : 1.5444 = 0.6272 + 0.9168 + 0.0004, time: 41.737109]
2023-05-24 17:24:15.978: epoch 18:	0.07240911  	0.14005610  	0.13912514  
2023-05-24 17:24:15.978: Find a better model.
2023-05-24 17:24:57.633: [iter 19 : loss : 1.4983 = 0.5759 + 0.9217 + 0.0007, time: 41.649138]
2023-05-24 17:24:58.028: epoch 19:	0.07816196  	0.14893968  	0.14871377  
2023-05-24 17:24:58.028: Find a better model.
2023-05-24 17:25:39.487: [iter 20 : loss : 1.4433 = 0.5146 + 0.9275 + 0.0012, time: 41.453188]
2023-05-24 17:25:39.883: epoch 20:	0.08144394  	0.15435858  	0.15415382  
2023-05-24 17:25:39.883: Find a better model.
2023-05-24 17:26:21.638: [iter 21 : loss : 1.3879 = 0.4534 + 0.9328 + 0.0016, time: 41.748563]
2023-05-24 17:26:22.035: epoch 21:	0.08371608  	0.15799734  	0.15772948  
2023-05-24 17:26:22.035: Find a better model.
2023-05-24 17:27:03.470: [iter 22 : loss : 1.3380 = 0.3992 + 0.9366 + 0.0021, time: 41.428274]
2023-05-24 17:27:03.862: epoch 22:	0.08490841  	0.16047442  	0.15973935  
2023-05-24 17:27:03.862: Find a better model.
2023-05-24 17:27:45.386: [iter 23 : loss : 1.2959 = 0.3544 + 0.9389 + 0.0026, time: 41.517150]
2023-05-24 17:27:45.783: epoch 23:	0.08609028  	0.16260339  	0.16146727  
2023-05-24 17:27:45.783: Find a better model.
2023-05-24 17:28:27.546: [iter 24 : loss : 1.2603 = 0.3172 + 0.9400 + 0.0031, time: 41.757118]
2023-05-24 17:28:27.942: epoch 24:	0.08675103  	0.16402961  	0.16249485  
2023-05-24 17:28:27.942: Find a better model.
2023-05-24 17:29:09.365: [iter 25 : loss : 1.2309 = 0.2873 + 0.9401 + 0.0036, time: 41.416506]
2023-05-24 17:29:09.762: epoch 25:	0.08703583  	0.16413675  	0.16280079  
2023-05-24 17:29:09.762: Find a better model.
2023-05-24 17:29:51.396: [iter 26 : loss : 1.2052 = 0.2614 + 0.9397 + 0.0040, time: 41.627703]
2023-05-24 17:29:51.794: epoch 26:	0.08720767  	0.16461174  	0.16327614  
2023-05-24 17:29:51.794: Find a better model.
2023-05-24 17:30:33.458: [iter 27 : loss : 1.1834 = 0.2399 + 0.9391 + 0.0044, time: 41.656909]
2023-05-24 17:30:33.873: epoch 27:	0.08734735  	0.16478990  	0.16346131  
2023-05-24 17:30:33.873: Find a better model.
2023-05-24 17:31:15.592: [iter 28 : loss : 1.1649 = 0.2217 + 0.9383 + 0.0048, time: 41.712031]
2023-05-24 17:31:16.009: epoch 28:	0.08740649  	0.16462828  	0.16317494  
2023-05-24 17:31:57.520: [iter 29 : loss : 1.1492 = 0.2066 + 0.9373 + 0.0052, time: 41.502243]
2023-05-24 17:31:57.910: epoch 29:	0.08732057  	0.16433798  	0.16301563  
2023-05-24 17:32:39.547: [iter 30 : loss : 1.1348 = 0.1928 + 0.9363 + 0.0056, time: 41.630757]
2023-05-24 17:32:39.938: epoch 30:	0.08723461  	0.16438158  	0.16256288  
2023-05-24 17:33:21.656: [iter 31 : loss : 1.1216 = 0.1803 + 0.9354 + 0.0060, time: 41.712200]
2023-05-24 17:33:22.049: epoch 31:	0.08704126  	0.16376121  	0.16219439  
2023-05-24 17:34:03.884: [iter 32 : loss : 1.1111 = 0.1704 + 0.9344 + 0.0063, time: 41.827636]
2023-05-24 17:34:04.323: epoch 32:	0.08715947  	0.16327065  	0.16178052  
2023-05-24 17:34:46.051: [iter 33 : loss : 1.1006 = 0.1604 + 0.9336 + 0.0066, time: 41.721165]
2023-05-24 17:34:46.470: epoch 33:	0.08707890  	0.16329126  	0.16163972  
2023-05-24 17:35:28.300: [iter 34 : loss : 1.0926 = 0.1529 + 0.9327 + 0.0070, time: 41.821156]
2023-05-24 17:35:28.715: epoch 34:	0.08681036  	0.16251263  	0.16096361  
2023-05-24 17:36:10.628: [iter 35 : loss : 1.0840 = 0.1448 + 0.9320 + 0.0073, time: 41.907157]
2023-05-24 17:36:11.026: epoch 35:	0.08662231  	0.16199623  	0.16044137  
2023-05-24 17:36:52.893: [iter 36 : loss : 1.0769 = 0.1381 + 0.9312 + 0.0076, time: 41.860120]
2023-05-24 17:36:53.314: epoch 36:	0.08642897  	0.16146755  	0.15987979  
2023-05-24 17:37:35.166: [iter 37 : loss : 1.0699 = 0.1316 + 0.9303 + 0.0079, time: 41.846258]
2023-05-24 17:37:35.572: epoch 37:	0.08619263  	0.16051735  	0.15933967  
2023-05-24 17:38:17.472: [iter 38 : loss : 1.0643 = 0.1265 + 0.9297 + 0.0082, time: 41.893746]
2023-05-24 17:38:17.870: epoch 38:	0.08602068  	0.15985937  	0.15875433  
2023-05-24 17:38:59.957: [iter 39 : loss : 1.0589 = 0.1215 + 0.9290 + 0.0084, time: 42.080254]
2023-05-24 17:39:00.387: epoch 39:	0.08582202  	0.15904140  	0.15808322  
2023-05-24 17:39:42.408: [iter 40 : loss : 1.0540 = 0.1169 + 0.9284 + 0.0087, time: 42.013140]
2023-05-24 17:39:42.802: epoch 40:	0.08553729  	0.15788619  	0.15735678  
2023-05-24 17:40:24.699: [iter 41 : loss : 1.0489 = 0.1123 + 0.9277 + 0.0089, time: 41.890188]
2023-05-24 17:40:25.095: epoch 41:	0.08536546  	0.15739921  	0.15671624  
2023-05-24 17:41:07.127: [iter 42 : loss : 1.0449 = 0.1085 + 0.9272 + 0.0092, time: 42.026238]
2023-05-24 17:41:07.536: epoch 42:	0.08515588  	0.15657836  	0.15612251  
2023-05-24 17:41:49.417: [iter 43 : loss : 1.0408 = 0.1046 + 0.9268 + 0.0094, time: 41.874290]
2023-05-24 17:41:49.809: epoch 43:	0.08515587  	0.15605670  	0.15573369  
2023-05-24 17:42:31.950: [iter 44 : loss : 1.0369 = 0.1010 + 0.9263 + 0.0097, time: 42.135125]
2023-05-24 17:42:32.373: epoch 44:	0.08475298  	0.15532143  	0.15497755  
2023-05-24 17:43:14.242: [iter 45 : loss : 1.0342 = 0.0985 + 0.9258 + 0.0099, time: 41.861388]
2023-05-24 17:43:14.637: epoch 45:	0.08434482  	0.15383404  	0.15397827  
2023-05-24 17:43:56.461: [iter 46 : loss : 1.0307 = 0.0952 + 0.9254 + 0.0101, time: 41.817513]
2023-05-24 17:43:56.852: epoch 46:	0.08409224  	0.15290505  	0.15328416  
2023-05-24 17:44:38.842: [iter 47 : loss : 1.0275 = 0.0923 + 0.9249 + 0.0103, time: 41.984230]
2023-05-24 17:44:39.238: epoch 47:	0.08393651  	0.15244585  	0.15275121  
2023-05-24 17:45:21.268: [iter 48 : loss : 1.0247 = 0.0896 + 0.9246 + 0.0105, time: 42.021408]
2023-05-24 17:45:21.664: epoch 48:	0.08375924  	0.15182734  	0.15216109  
2023-05-24 17:46:03.579: [iter 49 : loss : 1.0225 = 0.0875 + 0.9242 + 0.0107, time: 41.909371]
2023-05-24 17:46:04.006: epoch 49:	0.08358199  	0.15118232  	0.15142141  
2023-05-24 17:46:46.070: [iter 50 : loss : 1.0200 = 0.0852 + 0.9238 + 0.0110, time: 42.054532]
2023-05-24 17:46:46.486: epoch 50:	0.08325968  	0.15028623  	0.15083611  
2023-05-24 17:47:28.399: [iter 51 : loss : 1.0179 = 0.0833 + 0.9236 + 0.0111, time: 41.907400]
2023-05-24 17:47:28.794: epoch 51:	0.08306091  	0.14971159  	0.15035650  
2023-05-24 17:48:10.990: [iter 52 : loss : 1.0155 = 0.0809 + 0.9233 + 0.0113, time: 42.189476]
2023-05-24 17:48:11.407: epoch 52:	0.08280308  	0.14922842  	0.14991455  
2023-05-24 17:48:11.407: Early stopping is trigger at epoch: 52
2023-05-24 17:48:11.407: best_result@epoch 27:

2023-05-24 17:48:11.407: 		0.0873      	0.1648      	0.1635      
2023-05-24 19:04:27.418: my pid: 3676
2023-05-24 19:04:27.418: model: model.general_recommender.SGL
2023-05-24 19:04:27.418: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 19:04:27.418: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 19:04:32.368: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 19:05:12.110: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 39.742497]
2023-05-24 19:05:12.519: epoch 1:	0.00349160  	0.00821223  	0.00674875  
2023-05-24 19:05:12.519: Find a better model.
2023-05-24 19:05:52.163: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 39.636758]
2023-05-24 19:05:52.565: epoch 2:	0.00411472  	0.00870434  	0.00735326  
2023-05-24 19:05:52.565: Find a better model.
2023-05-24 19:06:32.149: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 39.576662]
2023-05-24 19:06:32.555: epoch 3:	0.00513533  	0.01078933  	0.00928117  
2023-05-24 19:06:32.555: Find a better model.
2023-05-24 19:07:11.933: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 39.371225]
2023-05-24 19:07:12.362: epoch 4:	0.00604314  	0.01171840  	0.01048327  
2023-05-24 19:07:12.362: Find a better model.
2023-05-24 19:07:52.153: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 39.783080]
2023-05-24 19:07:52.554: epoch 5:	0.00712823  	0.01388803  	0.01248124  
2023-05-24 19:07:52.554: Find a better model.
2023-05-24 19:08:32.100: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 39.539785]
2023-05-24 19:08:32.503: epoch 6:	0.00838526  	0.01581074  	0.01438362  
2023-05-24 19:08:32.503: Find a better model.
2023-05-24 19:09:12.291: [iter 7 : loss : 1.6045 = 0.6928 + 0.9118 + 0.0000, time: 39.782102]
2023-05-24 19:09:12.693: epoch 7:	0.00974434  	0.01849503  	0.01673545  
2023-05-24 19:09:12.693: Find a better model.
2023-05-24 19:09:52.278: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 39.577156]
2023-05-24 19:09:52.678: epoch 8:	0.01081872  	0.02081267  	0.01917062  
2023-05-24 19:09:52.678: Find a better model.
2023-05-24 19:10:32.283: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 39.599075]
2023-05-24 19:10:32.685: epoch 9:	0.01225839  	0.02384916  	0.02214896  
2023-05-24 19:10:32.685: Find a better model.
2023-05-24 19:11:12.236: [iter 10 : loss : 1.6041 = 0.6922 + 0.9119 + 0.0000, time: 39.545075]
2023-05-24 19:11:12.633: epoch 10:	0.01446623  	0.02762912  	0.02612099  
2023-05-24 19:11:12.633: Find a better model.
2023-05-24 19:11:51.798: [iter 11 : loss : 1.6037 = 0.6919 + 0.9118 + 0.0000, time: 39.159302]
2023-05-24 19:11:52.243: epoch 11:	0.01684063  	0.03299030  	0.03131263  
2023-05-24 19:11:52.243: Find a better model.
2023-05-24 19:12:31.594: [iter 12 : loss : 1.6034 = 0.6914 + 0.9120 + 0.0000, time: 39.343120]
2023-05-24 19:12:32.016: epoch 12:	0.02011749  	0.04012677  	0.03871176  
2023-05-24 19:12:32.017: Find a better model.
2023-05-24 19:13:11.414: [iter 13 : loss : 1.6028 = 0.6906 + 0.9122 + 0.0000, time: 39.391096]
2023-05-24 19:13:11.839: epoch 13:	0.02454392  	0.05044828  	0.04768474  
2023-05-24 19:13:11.839: Find a better model.
2023-05-24 19:13:51.600: [iter 14 : loss : 1.6017 = 0.6892 + 0.9125 + 0.0000, time: 39.754199]
2023-05-24 19:13:52.022: epoch 14:	0.03081251  	0.06410605  	0.06152410  
2023-05-24 19:13:52.022: Find a better model.
2023-05-24 19:14:31.375: [iter 15 : loss : 1.5995 = 0.6865 + 0.9129 + 0.0001, time: 39.344463]
2023-05-24 19:14:31.774: epoch 15:	0.03925627  	0.08156533  	0.07889908  
2023-05-24 19:14:31.774: Find a better model.
2023-05-24 19:15:11.959: [iter 16 : loss : 1.5945 = 0.6809 + 0.9135 + 0.0001, time: 40.178077]
2023-05-24 19:15:12.380: epoch 16:	0.05084273  	0.10205586  	0.10046183  
2023-05-24 19:15:12.380: Find a better model.
2023-05-24 19:15:52.557: [iter 17 : loss : 1.5834 = 0.6683 + 0.9149 + 0.0002, time: 40.169458]
2023-05-24 19:15:52.976: epoch 17:	0.06283182  	0.12253016  	0.12232517  
2023-05-24 19:15:52.976: Find a better model.
2023-05-24 19:16:33.384: [iter 18 : loss : 1.5598 = 0.6418 + 0.9176 + 0.0003, time: 40.401185]
2023-05-24 19:16:33.779: epoch 18:	0.07280137  	0.13890310  	0.13927850  
2023-05-24 19:16:33.779: Find a better model.
2023-05-24 19:17:14.135: [iter 19 : loss : 1.5187 = 0.5957 + 0.9223 + 0.0006, time: 40.350280]
2023-05-24 19:17:14.531: epoch 19:	0.07874767  	0.14884786  	0.14960538  
2023-05-24 19:17:14.531: Find a better model.
2023-05-24 19:17:54.930: [iter 20 : loss : 1.4645 = 0.5350 + 0.9285 + 0.0010, time: 40.393076]
2023-05-24 19:17:55.350: epoch 20:	0.08195435  	0.15443453  	0.15499388  
2023-05-24 19:17:55.350: Find a better model.
2023-05-24 19:18:35.736: [iter 21 : loss : 1.4071 = 0.4711 + 0.9345 + 0.0015, time: 40.379531]
2023-05-24 19:18:36.129: epoch 21:	0.08385587  	0.15796138  	0.15815333  
2023-05-24 19:18:36.129: Find a better model.
2023-05-24 19:19:16.693: [iter 22 : loss : 1.3539 = 0.4130 + 0.9389 + 0.0020, time: 40.558059]
2023-05-24 19:19:17.113: epoch 22:	0.08497849  	0.16011769  	0.16020404  
2023-05-24 19:19:17.113: Find a better model.
2023-05-24 19:19:57.626: [iter 23 : loss : 1.3090 = 0.3650 + 0.9416 + 0.0025, time: 40.502084]
2023-05-24 19:19:58.018: epoch 23:	0.08590771  	0.16196340  	0.16162226  
2023-05-24 19:19:58.018: Find a better model.
2023-05-24 19:20:38.508: [iter 24 : loss : 1.2710 = 0.3251 + 0.9428 + 0.0030, time: 40.484407]
2023-05-24 19:20:38.902: epoch 24:	0.08672424  	0.16345784  	0.16265796  
2023-05-24 19:20:38.902: Find a better model.
2023-05-24 19:21:19.678: [iter 25 : loss : 1.2397 = 0.2933 + 0.9429 + 0.0035, time: 40.768231]
2023-05-24 19:21:20.095: epoch 25:	0.08718621  	0.16440938  	0.16309923  
2023-05-24 19:21:20.095: Find a better model.
2023-05-24 19:22:00.830: [iter 26 : loss : 1.2125 = 0.2661 + 0.9426 + 0.0039, time: 40.728675]
2023-05-24 19:22:01.247: epoch 26:	0.08739576  	0.16489705  	0.16343835  
2023-05-24 19:22:01.247: Find a better model.
2023-05-24 19:22:42.008: [iter 27 : loss : 1.1896 = 0.2434 + 0.9419 + 0.0043, time: 40.752606]
2023-05-24 19:22:42.415: epoch 27:	0.08766431  	0.16537809  	0.16370045  
2023-05-24 19:22:42.416: Find a better model.
2023-05-24 19:23:23.268: [iter 28 : loss : 1.1702 = 0.2244 + 0.9410 + 0.0047, time: 40.846488]
2023-05-24 19:23:23.665: epoch 28:	0.08774484  	0.16541603  	0.16363446  
2023-05-24 19:23:23.666: Find a better model.
2023-05-24 19:24:04.565: [iter 29 : loss : 1.1537 = 0.2086 + 0.9400 + 0.0051, time: 40.892121]
2023-05-24 19:24:04.960: epoch 29:	0.08753537  	0.16535129  	0.16354983  
2023-05-24 19:24:45.804: [iter 30 : loss : 1.1388 = 0.1944 + 0.9389 + 0.0055, time: 40.838770]
2023-05-24 19:24:46.227: epoch 30:	0.08761057  	0.16508813  	0.16340919  
2023-05-24 19:25:26.950: [iter 31 : loss : 1.1254 = 0.1816 + 0.9379 + 0.0059, time: 40.716749]
2023-05-24 19:25:27.360: epoch 31:	0.08741182  	0.16468443  	0.16293645  
2023-05-24 19:26:07.968: [iter 32 : loss : 1.1144 = 0.1713 + 0.9369 + 0.0062, time: 40.601098]
2023-05-24 19:26:08.389: epoch 32:	0.08723991  	0.16404274  	0.16258201  
2023-05-24 19:26:49.118: [iter 33 : loss : 1.1038 = 0.1613 + 0.9360 + 0.0066, time: 40.723283]
2023-05-24 19:26:49.518: epoch 33:	0.08725609  	0.16408455  	0.16223566  
2023-05-24 19:27:30.340: [iter 34 : loss : 1.0954 = 0.1534 + 0.9350 + 0.0069, time: 40.814347]
2023-05-24 19:27:30.757: epoch 34:	0.08696068  	0.16357957  	0.16176942  
2023-05-24 19:28:11.893: [iter 35 : loss : 1.0866 = 0.1451 + 0.9343 + 0.0072, time: 41.126721]
2023-05-24 19:28:12.319: epoch 35:	0.08682111  	0.16284622  	0.16134351  
2023-05-24 19:28:53.281: [iter 36 : loss : 1.0793 = 0.1383 + 0.9334 + 0.0075, time: 40.956085]
2023-05-24 19:28:53.681: epoch 36:	0.08686403  	0.16287810  	0.16098700  
2023-05-24 19:29:34.420: [iter 37 : loss : 1.0721 = 0.1317 + 0.9326 + 0.0078, time: 40.732222]
2023-05-24 19:29:34.814: epoch 37:	0.08673503  	0.16238093  	0.16062281  
2023-05-24 19:30:16.074: [iter 38 : loss : 1.0663 = 0.1263 + 0.9319 + 0.0081, time: 41.253191]
2023-05-24 19:30:16.484: epoch 38:	0.08659001  	0.16198236  	0.16019215  
2023-05-24 19:30:57.400: [iter 39 : loss : 1.0609 = 0.1214 + 0.9312 + 0.0084, time: 40.909180]
2023-05-24 19:30:57.818: epoch 39:	0.08639663  	0.16117994  	0.15948842  
2023-05-24 19:31:39.074: [iter 40 : loss : 1.0560 = 0.1168 + 0.9305 + 0.0086, time: 41.248298]
2023-05-24 19:31:39.479: epoch 40:	0.08611738  	0.16022347  	0.15872794  
2023-05-24 19:32:20.856: [iter 41 : loss : 1.0508 = 0.1120 + 0.9299 + 0.0089, time: 41.371210]
2023-05-24 19:32:21.282: epoch 41:	0.08587028  	0.15950975  	0.15809888  
2023-05-24 19:33:02.253: [iter 42 : loss : 1.0467 = 0.1081 + 0.9294 + 0.0091, time: 40.964155]
2023-05-24 19:33:02.672: epoch 42:	0.08560708  	0.15865153  	0.15746833  
2023-05-24 19:33:43.945: [iter 43 : loss : 1.0425 = 0.1042 + 0.9289 + 0.0094, time: 41.265931]
2023-05-24 19:33:44.356: epoch 43:	0.08540294  	0.15805729  	0.15685730  
2023-05-24 19:34:25.333: [iter 44 : loss : 1.0386 = 0.1007 + 0.9284 + 0.0096, time: 40.970869]
2023-05-24 19:34:25.728: epoch 44:	0.08511820  	0.15749812  	0.15644261  
2023-05-24 19:35:06.939: [iter 45 : loss : 1.0357 = 0.0980 + 0.9279 + 0.0098, time: 41.205625]
2023-05-24 19:35:07.354: epoch 45:	0.08497318  	0.15671410  	0.15578955  
2023-05-24 19:35:48.523: [iter 46 : loss : 1.0323 = 0.0948 + 0.9275 + 0.0101, time: 41.161119]
2023-05-24 19:35:48.923: epoch 46:	0.08472072  	0.15590774  	0.15520567  
2023-05-24 19:36:30.282: [iter 47 : loss : 1.0293 = 0.0920 + 0.9270 + 0.0103, time: 41.352932]
2023-05-24 19:36:30.680: epoch 47:	0.08465086  	0.15558915  	0.15507674  
2023-05-24 19:37:11.720: [iter 48 : loss : 1.0266 = 0.0895 + 0.9266 + 0.0105, time: 41.034035]
2023-05-24 19:37:12.140: epoch 48:	0.08429097  	0.15450771  	0.15436107  
2023-05-24 19:37:53.519: [iter 49 : loss : 1.0239 = 0.0870 + 0.9262 + 0.0107, time: 41.365087]
2023-05-24 19:37:53.919: epoch 49:	0.08403320  	0.15374717  	0.15372832  
2023-05-24 19:38:35.280: [iter 50 : loss : 1.0216 = 0.0848 + 0.9258 + 0.0109, time: 41.353659]
2023-05-24 19:38:35.704: epoch 50:	0.08363032  	0.15289055  	0.15305600  
2023-05-24 19:39:17.481: [iter 51 : loss : 1.0195 = 0.0828 + 0.9256 + 0.0111, time: 41.770107]
2023-05-24 19:39:17.882: epoch 51:	0.08353901  	0.15253443  	0.15233137  
2023-05-24 19:39:59.686: [iter 52 : loss : 1.0172 = 0.0806 + 0.9253 + 0.0113, time: 41.798660]
2023-05-24 19:40:00.087: epoch 52:	0.08342083  	0.15224402  	0.15213075  
2023-05-24 19:40:41.219: [iter 53 : loss : 1.0152 = 0.0788 + 0.9249 + 0.0115, time: 41.125107]
2023-05-24 19:40:41.620: epoch 53:	0.08314151  	0.15151577  	0.15147488  
2023-05-24 19:40:41.620: Early stopping is trigger at epoch: 53
2023-05-24 19:40:41.620: best_result@epoch 28:

2023-05-24 19:40:41.620: 		0.0877      	0.1654      	0.1636      
2023-05-24 19:53:10.554: my pid: 10924
2023-05-24 19:53:10.554: model: model.general_recommender.SGL
2023-05-24 19:53:10.554: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 19:53:10.554: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 19:53:15.477: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 19:53:52.494: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 37.016572]
2023-05-24 19:53:52.915: epoch 1:	0.00337880  	0.00807749  	0.00656585  
2023-05-24 19:53:52.915: Find a better model.
2023-05-24 19:54:29.591: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 36.669786]
2023-05-24 19:54:30.000: epoch 2:	0.00420603  	0.00948111  	0.00820640  
2023-05-24 19:54:30.000: Find a better model.
2023-05-24 19:55:06.659: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 36.652181]
2023-05-24 19:55:07.060: epoch 3:	0.00493658  	0.01017637  	0.00911207  
2023-05-24 19:55:07.060: Find a better model.
2023-05-24 19:55:43.699: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 36.632663]
2023-05-24 19:55:44.131: epoch 4:	0.00538780  	0.01099415  	0.00942833  
2023-05-24 19:55:44.131: Find a better model.
2023-05-24 19:56:20.491: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 36.354083]
2023-05-24 19:56:20.902: epoch 5:	0.00636544  	0.01287323  	0.01113765  
2023-05-24 19:56:20.902: Find a better model.
2023-05-24 19:56:57.598: [iter 6 : loss : 1.6067 = 0.6929 + 0.9139 + 0.0000, time: 36.688987]
2023-05-24 19:56:58.001: epoch 6:	0.00684889  	0.01343150  	0.01244461  
2023-05-24 19:56:58.001: Find a better model.
2023-05-24 19:57:34.421: [iter 7 : loss : 1.6068 = 0.6928 + 0.9141 + 0.0000, time: 36.414140]
2023-05-24 19:57:34.833: epoch 7:	0.00780509  	0.01476091  	0.01331042  
2023-05-24 19:57:34.833: Find a better model.
2023-05-24 19:58:11.228: [iter 8 : loss : 1.6068 = 0.6927 + 0.9141 + 0.0000, time: 36.389109]
2023-05-24 19:58:11.672: epoch 8:	0.00943815  	0.01698818  	0.01583513  
2023-05-24 19:58:11.673: Find a better model.
2023-05-24 19:58:47.960: [iter 9 : loss : 1.6069 = 0.6925 + 0.9144 + 0.0000, time: 36.279104]
2023-05-24 19:58:48.387: epoch 9:	0.01121624  	0.02089916  	0.01911004  
2023-05-24 19:58:48.388: Find a better model.
2023-05-24 19:59:24.761: [iter 10 : loss : 1.6069 = 0.6923 + 0.9145 + 0.0000, time: 36.366076]
2023-05-24 19:59:25.164: epoch 10:	0.01245715  	0.02363614  	0.02191894  
2023-05-24 19:59:25.165: Find a better model.
2023-05-24 20:00:01.446: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 36.275312]
2023-05-24 20:00:01.857: epoch 11:	0.01471334  	0.02865947  	0.02756227  
2023-05-24 20:00:01.858: Find a better model.
2023-05-24 20:00:38.256: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 36.392303]
2023-05-24 20:00:38.703: epoch 12:	0.01783442  	0.03515960  	0.03334959  
2023-05-24 20:00:38.703: Find a better model.
2023-05-24 20:01:15.284: [iter 13 : loss : 1.6063 = 0.6909 + 0.9154 + 0.0000, time: 36.575221]
2023-05-24 20:01:15.708: epoch 13:	0.02180425  	0.04406047  	0.04224520  
2023-05-24 20:01:15.708: Find a better model.
2023-05-24 20:01:52.127: [iter 14 : loss : 1.6058 = 0.6899 + 0.9158 + 0.0000, time: 36.411428]
2023-05-24 20:01:52.559: epoch 14:	0.02780993  	0.05583351  	0.05436920  
2023-05-24 20:01:52.560: Find a better model.
2023-05-24 20:02:29.024: [iter 15 : loss : 1.6045 = 0.6880 + 0.9165 + 0.0001, time: 36.448599]
2023-05-24 20:02:29.452: epoch 15:	0.03626444  	0.07159533  	0.07095426  
2023-05-24 20:02:29.452: Find a better model.
2023-05-24 20:03:06.853: [iter 16 : loss : 1.6018 = 0.6843 + 0.9174 + 0.0001, time: 37.394255]
2023-05-24 20:03:07.280: epoch 16:	0.04794205  	0.09284183  	0.09229342  
2023-05-24 20:03:07.280: Find a better model.
2023-05-24 20:03:44.753: [iter 17 : loss : 1.5954 = 0.6764 + 0.9189 + 0.0001, time: 37.467168]
2023-05-24 20:03:45.154: epoch 17:	0.05969489  	0.11354442  	0.11443236  
2023-05-24 20:03:45.154: Find a better model.
2023-05-24 20:04:22.621: [iter 18 : loss : 1.5810 = 0.6592 + 0.9215 + 0.0003, time: 37.460034]
2023-05-24 20:04:23.019: epoch 18:	0.07081927  	0.13295481  	0.13466266  
2023-05-24 20:04:23.019: Find a better model.
2023-05-24 20:05:00.443: [iter 19 : loss : 1.5519 = 0.6256 + 0.9258 + 0.0005, time: 37.417141]
2023-05-24 20:05:00.855: epoch 19:	0.07712002  	0.14392285  	0.14674036  
2023-05-24 20:05:00.856: Find a better model.
2023-05-24 20:05:38.388: [iter 20 : loss : 1.5066 = 0.5741 + 0.9317 + 0.0008, time: 37.525487]
2023-05-24 20:05:38.799: epoch 20:	0.08083177  	0.15103577  	0.15312560  
2023-05-24 20:05:38.799: Find a better model.
2023-05-24 20:06:16.596: [iter 21 : loss : 1.4514 = 0.5118 + 0.9384 + 0.0012, time: 37.791371]
2023-05-24 20:06:16.991: epoch 21:	0.08324355  	0.15653989  	0.15741864  
2023-05-24 20:06:16.991: Find a better model.
2023-05-24 20:06:54.339: [iter 22 : loss : 1.3954 = 0.4498 + 0.9439 + 0.0017, time: 37.342053]
2023-05-24 20:06:54.745: epoch 22:	0.08486032  	0.15979339  	0.15999283  
2023-05-24 20:06:54.745: Find a better model.
2023-05-24 20:07:32.178: [iter 23 : loss : 1.3458 = 0.3958 + 0.9477 + 0.0022, time: 37.426638]
2023-05-24 20:07:32.602: epoch 23:	0.08588631  	0.16218442  	0.16155438  
2023-05-24 20:07:32.603: Find a better model.
2023-05-24 20:08:09.770: [iter 24 : loss : 1.3029 = 0.3504 + 0.9498 + 0.0027, time: 37.159521]
2023-05-24 20:08:10.192: epoch 24:	0.08653095  	0.16367324  	0.16277885  
2023-05-24 20:08:10.192: Find a better model.
2023-05-24 20:08:47.591: [iter 25 : loss : 1.2672 = 0.3138 + 0.9502 + 0.0032, time: 37.392024]
2023-05-24 20:08:48.012: epoch 25:	0.08712177  	0.16502994  	0.16347425  
2023-05-24 20:08:48.013: Find a better model.
2023-05-24 20:09:25.570: [iter 26 : loss : 1.2368 = 0.2830 + 0.9501 + 0.0037, time: 37.550089]
2023-05-24 20:09:25.985: epoch 26:	0.08737962  	0.16531132  	0.16371202  
2023-05-24 20:09:25.985: Find a better model.
2023-05-24 20:10:03.773: [iter 27 : loss : 1.2112 = 0.2576 + 0.9495 + 0.0041, time: 37.781082]
2023-05-24 20:10:04.170: epoch 27:	0.08769119  	0.16584417  	0.16414085  
2023-05-24 20:10:04.170: Find a better model.
2023-05-24 20:10:41.885: [iter 28 : loss : 1.1895 = 0.2362 + 0.9487 + 0.0046, time: 37.708055]
2023-05-24 20:10:42.302: epoch 28:	0.08779863  	0.16627380  	0.16413234  
2023-05-24 20:10:42.302: Find a better model.
2023-05-24 20:11:19.871: [iter 29 : loss : 1.1709 = 0.2184 + 0.9476 + 0.0050, time: 37.563054]
2023-05-24 20:11:20.265: epoch 29:	0.08780938  	0.16621628  	0.16399084  
2023-05-24 20:11:57.910: [iter 30 : loss : 1.1544 = 0.2027 + 0.9464 + 0.0053, time: 37.637469]
2023-05-24 20:11:58.305: epoch 30:	0.08788989  	0.16604248  	0.16407841  
2023-05-24 20:12:35.921: [iter 31 : loss : 1.1398 = 0.1888 + 0.9454 + 0.0057, time: 37.610093]
2023-05-24 20:12:36.343: epoch 31:	0.08789526  	0.16588004  	0.16391088  
2023-05-24 20:13:13.790: [iter 32 : loss : 1.1278 = 0.1774 + 0.9443 + 0.0061, time: 37.440047]
2023-05-24 20:13:14.211: epoch 32:	0.08800805  	0.16549243  	0.16378340  
2023-05-24 20:13:52.211: [iter 33 : loss : 1.1162 = 0.1666 + 0.9433 + 0.0064, time: 37.989656]
2023-05-24 20:13:52.654: epoch 33:	0.08790608  	0.16553773  	0.16348691  
2023-05-24 20:14:30.455: [iter 34 : loss : 1.1073 = 0.1583 + 0.9423 + 0.0067, time: 37.795616]
2023-05-24 20:14:30.862: epoch 34:	0.08764822  	0.16444924  	0.16257712  
2023-05-24 20:15:08.380: [iter 35 : loss : 1.0975 = 0.1490 + 0.9415 + 0.0071, time: 37.510346]
2023-05-24 20:15:08.787: epoch 35:	0.08750856  	0.16414723  	0.16210492  
2023-05-24 20:15:46.572: [iter 36 : loss : 1.0900 = 0.1422 + 0.9405 + 0.0074, time: 37.777107]
2023-05-24 20:15:46.995: epoch 36:	0.08720235  	0.16350159  	0.16146050  
2023-05-24 20:16:25.207: [iter 37 : loss : 1.0826 = 0.1353 + 0.9396 + 0.0077, time: 38.206213]
2023-05-24 20:16:25.635: epoch 37:	0.08714861  	0.16322009  	0.16119979  
2023-05-24 20:17:03.646: [iter 38 : loss : 1.0761 = 0.1292 + 0.9389 + 0.0080, time: 38.005214]
2023-05-24 20:17:04.042: epoch 38:	0.08676721  	0.16225709  	0.16056512  
2023-05-24 20:17:41.927: [iter 39 : loss : 1.0704 = 0.1241 + 0.9381 + 0.0082, time: 37.879130]
2023-05-24 20:17:42.325: epoch 39:	0.08643956  	0.16116489  	0.15989257  
2023-05-24 20:18:20.509: [iter 40 : loss : 1.0652 = 0.1193 + 0.9374 + 0.0085, time: 38.177471]
2023-05-24 20:18:20.915: epoch 40:	0.08613343  	0.16015080  	0.15907142  
2023-05-24 20:18:58.715: [iter 41 : loss : 1.0599 = 0.1144 + 0.9367 + 0.0088, time: 37.793095]
2023-05-24 20:18:59.111: epoch 41:	0.08577885  	0.15936624  	0.15838867  
2023-05-24 20:19:36.920: [iter 42 : loss : 1.0555 = 0.1104 + 0.9361 + 0.0090, time: 37.802747]
2023-05-24 20:19:37.341: epoch 42:	0.08556946  	0.15838523  	0.15804364  
2023-05-24 20:20:15.402: [iter 43 : loss : 1.0506 = 0.1057 + 0.9356 + 0.0093, time: 38.054037]
2023-05-24 20:20:15.808: epoch 43:	0.08529546  	0.15734546  	0.15721485  
2023-05-24 20:20:53.680: [iter 44 : loss : 1.0472 = 0.1027 + 0.9351 + 0.0095, time: 37.865566]
2023-05-24 20:20:54.105: epoch 44:	0.08497854  	0.15634558  	0.15671471  
2023-05-24 20:21:32.337: [iter 45 : loss : 1.0443 = 0.1000 + 0.9346 + 0.0097, time: 38.225100]
2023-05-24 20:21:32.749: epoch 45:	0.08486578  	0.15586370  	0.15606941  
2023-05-24 20:22:10.748: [iter 46 : loss : 1.0404 = 0.0964 + 0.9341 + 0.0099, time: 37.991218]
2023-05-24 20:22:11.151: epoch 46:	0.08467235  	0.15542345  	0.15570971  
2023-05-24 20:22:50.681: my pid: 14620
2023-05-24 20:22:50.681: model: model.general_recommender.SGL
2023-05-24 20:22:50.681: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 20:22:50.681: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 20:22:55.865: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 20:23:32.042: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 36.176456]
2023-05-24 20:23:32.440: epoch 1:	0.00296518  	0.00735567  	0.00575102  
2023-05-24 20:23:32.441: Find a better model.
2023-05-24 20:24:07.742: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 35.295870]
2023-05-24 20:24:08.140: epoch 2:	0.00394282  	0.00915322  	0.00758516  
2023-05-24 20:24:08.140: Find a better model.
2023-05-24 20:24:43.442: [iter 3 : loss : 1.6076 = 0.6930 + 0.9145 + 0.0000, time: 35.296301]
2023-05-24 20:24:43.881: epoch 3:	0.00465725  	0.00979082  	0.00850732  
2023-05-24 20:24:43.881: Find a better model.
2023-05-24 20:25:19.112: [iter 4 : loss : 1.6078 = 0.6930 + 0.9148 + 0.0000, time: 35.223616]
2023-05-24 20:25:19.511: epoch 4:	0.00484526  	0.01059586  	0.00875067  
2023-05-24 20:25:19.511: Find a better model.
2023-05-24 20:25:54.760: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 35.242079]
2023-05-24 20:25:55.157: epoch 5:	0.00561878  	0.01157434  	0.01024149  
2023-05-24 20:25:55.157: Find a better model.
2023-05-24 20:26:30.222: [iter 6 : loss : 1.6082 = 0.6928 + 0.9153 + 0.0000, time: 35.059033]
2023-05-24 20:26:30.670: epoch 6:	0.00639767  	0.01219901  	0.01102735  
2023-05-24 20:26:30.670: Find a better model.
2023-05-24 20:27:05.691: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 35.014672]
2023-05-24 20:27:06.121: epoch 7:	0.00711749  	0.01319541  	0.01213542  
2023-05-24 20:27:06.121: Find a better model.
2023-05-24 20:27:41.350: [iter 8 : loss : 1.6084 = 0.6926 + 0.9158 + 0.0000, time: 35.223518]
2023-05-24 20:27:41.775: epoch 8:	0.00789104  	0.01477515  	0.01373267  
2023-05-24 20:27:41.775: Find a better model.
2023-05-24 20:28:16.871: [iter 9 : loss : 1.6087 = 0.6924 + 0.9162 + 0.0000, time: 35.085560]
2023-05-24 20:28:17.275: epoch 9:	0.00973361  	0.01912601  	0.01729940  
2023-05-24 20:28:17.275: Find a better model.
2023-05-24 20:28:52.487: [iter 10 : loss : 1.6087 = 0.6922 + 0.9164 + 0.0000, time: 35.205112]
2023-05-24 20:28:52.899: epoch 10:	0.01112490  	0.02076957  	0.01930229  
2023-05-24 20:28:52.900: Find a better model.
2023-05-24 20:29:28.290: [iter 11 : loss : 1.6086 = 0.6919 + 0.9166 + 0.0000, time: 35.383792]
2023-05-24 20:29:28.711: epoch 11:	0.01337036  	0.02605434  	0.02441905  
2023-05-24 20:29:28.711: Find a better model.
2023-05-24 20:30:03.816: [iter 12 : loss : 1.6086 = 0.6915 + 0.9171 + 0.0000, time: 35.099286]
2023-05-24 20:30:04.215: epoch 12:	0.01587366  	0.03110991  	0.02961182  
2023-05-24 20:30:04.215: Find a better model.
2023-05-24 20:30:39.478: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 35.256018]
2023-05-24 20:30:39.886: epoch 13:	0.02033234  	0.04108478  	0.03917249  
2023-05-24 20:30:39.886: Find a better model.
2023-05-24 20:31:15.105: [iter 14 : loss : 1.6081 = 0.6898 + 0.9182 + 0.0000, time: 35.211872]
2023-05-24 20:31:15.525: epoch 14:	0.02634345  	0.05275756  	0.05064335  
2023-05-24 20:31:15.525: Find a better model.
2023-05-24 20:31:50.800: [iter 15 : loss : 1.6071 = 0.6880 + 0.9190 + 0.0001, time: 35.269197]
2023-05-24 20:31:51.221: epoch 15:	0.03443813  	0.06791695  	0.06646837  
2023-05-24 20:31:51.222: Find a better model.
2023-05-24 20:32:27.413: [iter 16 : loss : 1.6049 = 0.6845 + 0.9202 + 0.0001, time: 36.184345]
2023-05-24 20:32:27.818: epoch 16:	0.04636824  	0.08966854  	0.08857022  
2023-05-24 20:32:27.818: Find a better model.
2023-05-24 20:33:03.685: [iter 17 : loss : 1.5995 = 0.6774 + 0.9219 + 0.0001, time: 35.859050]
2023-05-24 20:33:04.083: epoch 17:	0.05865282  	0.11152685  	0.11126473  
2023-05-24 20:33:04.083: Find a better model.
2023-05-24 20:33:40.254: [iter 18 : loss : 1.5871 = 0.6621 + 0.9248 + 0.0002, time: 36.165054]
2023-05-24 20:33:40.696: epoch 18:	0.06955697  	0.13045041  	0.13128418  
2023-05-24 20:33:40.697: Find a better model.
2023-05-24 20:34:16.775: [iter 19 : loss : 1.5615 = 0.6317 + 0.9293 + 0.0004, time: 36.072482]
2023-05-24 20:34:17.175: epoch 19:	0.07679768  	0.14422135  	0.14509526  
2023-05-24 20:34:17.175: Find a better model.
2023-05-24 20:34:53.369: [iter 20 : loss : 1.5196 = 0.5831 + 0.9357 + 0.0008, time: 36.187598]
2023-05-24 20:34:53.778: epoch 20:	0.08084247  	0.15271541  	0.15244034  
2023-05-24 20:34:53.778: Find a better model.
2023-05-24 20:35:29.740: [iter 21 : loss : 1.4661 = 0.5219 + 0.9430 + 0.0012, time: 35.955996]
2023-05-24 20:35:30.137: epoch 21:	0.08325428  	0.15716985  	0.15657556  
2023-05-24 20:35:30.137: Find a better model.
2023-05-24 20:36:06.346: [iter 22 : loss : 1.4103 = 0.4595 + 0.9491 + 0.0017, time: 36.203052]
2023-05-24 20:36:06.769: epoch 22:	0.08454881  	0.16040744  	0.15886380  
2023-05-24 20:36:06.769: Find a better model.
2023-05-24 20:36:42.928: [iter 23 : loss : 1.3599 = 0.4045 + 0.9532 + 0.0022, time: 36.151963]
2023-05-24 20:36:43.316: epoch 23:	0.08567157  	0.16332214  	0.16123624  
2023-05-24 20:36:43.316: Find a better model.
2023-05-24 20:37:19.580: [iter 24 : loss : 1.3161 = 0.3581 + 0.9553 + 0.0027, time: 36.256164]
2023-05-24 20:37:19.976: epoch 24:	0.08633214  	0.16448629  	0.16224584  
2023-05-24 20:37:19.976: Find a better model.
2023-05-24 20:37:56.229: [iter 25 : loss : 1.2795 = 0.3205 + 0.9558 + 0.0032, time: 36.244664]
2023-05-24 20:37:56.646: epoch 25:	0.08697677  	0.16575949  	0.16333291  
2023-05-24 20:37:56.646: Find a better model.
2023-05-24 20:38:32.775: [iter 26 : loss : 1.2481 = 0.2887 + 0.9558 + 0.0036, time: 36.122836]
2023-05-24 20:38:33.165: epoch 26:	0.08717554  	0.16606866  	0.16354404  
2023-05-24 20:38:33.165: Find a better model.
2023-05-24 20:39:09.498: [iter 27 : loss : 1.2216 = 0.2625 + 0.9550 + 0.0041, time: 36.325386]
2023-05-24 20:39:09.898: epoch 27:	0.08783094  	0.16697280  	0.16407588  
2023-05-24 20:39:09.898: Find a better model.
2023-05-24 20:39:46.246: [iter 28 : loss : 1.1991 = 0.2404 + 0.9542 + 0.0045, time: 36.340763]
2023-05-24 20:39:46.682: epoch 28:	0.08777183  	0.16652955  	0.16383569  
2023-05-24 20:40:23.046: [iter 29 : loss : 1.1798 = 0.2220 + 0.9529 + 0.0049, time: 36.358583]
2023-05-24 20:40:23.439: epoch 29:	0.08795988  	0.16655110  	0.16389947  
2023-05-24 20:40:59.753: [iter 30 : loss : 1.1628 = 0.2059 + 0.9517 + 0.0053, time: 36.307390]
2023-05-24 20:41:00.149: epoch 30:	0.08784173  	0.16636524  	0.16376327  
2023-05-24 20:41:36.580: [iter 31 : loss : 1.1477 = 0.1914 + 0.9506 + 0.0057, time: 36.425028]
2023-05-24 20:41:36.995: epoch 31:	0.08780950  	0.16630995  	0.16352165  
2023-05-24 20:42:13.633: [iter 32 : loss : 1.1354 = 0.1799 + 0.9494 + 0.0060, time: 36.630660]
2023-05-24 20:42:14.027: epoch 32:	0.08792235  	0.16644917  	0.16337542  
2023-05-24 20:42:50.621: [iter 33 : loss : 1.1234 = 0.1687 + 0.9484 + 0.0064, time: 36.586037]
2023-05-24 20:42:51.015: epoch 33:	0.08799216  	0.16639644  	0.16352366  
2023-05-24 20:43:27.816: [iter 34 : loss : 1.1140 = 0.1600 + 0.9473 + 0.0067, time: 36.794669]
2023-05-24 20:43:28.213: epoch 34:	0.08776660  	0.16550526  	0.16280130  
2023-05-24 20:44:05.182: [iter 35 : loss : 1.1042 = 0.1507 + 0.9465 + 0.0070, time: 36.963042]
2023-05-24 20:44:05.589: epoch 35:	0.08773436  	0.16518201  	0.16259931  
2023-05-24 20:44:42.431: [iter 36 : loss : 1.0963 = 0.1435 + 0.9455 + 0.0073, time: 36.826103]
2023-05-24 20:44:42.837: epoch 36:	0.08769137  	0.16471562  	0.16217916  
2023-05-24 20:45:19.318: [iter 37 : loss : 1.0884 = 0.1363 + 0.9445 + 0.0076, time: 36.475077]
2023-05-24 20:45:19.751: epoch 37:	0.08735838  	0.16331945  	0.16161859  
2023-05-24 20:45:56.130: [iter 38 : loss : 1.0821 = 0.1304 + 0.9437 + 0.0079, time: 36.371722]
2023-05-24 20:45:56.526: epoch 38:	0.08718111  	0.16277175  	0.16100307  
2023-05-24 20:46:33.037: [iter 39 : loss : 1.0763 = 0.1251 + 0.9429 + 0.0082, time: 36.503756]
2023-05-24 20:46:33.455: epoch 39:	0.08711125  	0.16214080  	0.16033863  
2023-05-24 20:47:10.076: [iter 40 : loss : 1.0709 = 0.1203 + 0.9422 + 0.0085, time: 36.613832]
2023-05-24 20:47:10.474: epoch 40:	0.08684264  	0.16128643  	0.15972497  
2023-05-24 20:47:47.303: [iter 41 : loss : 1.0657 = 0.1154 + 0.9415 + 0.0087, time: 36.820049]
2023-05-24 20:47:47.718: epoch 41:	0.08662788  	0.16058403  	0.15918280  
2023-05-24 20:48:24.645: [iter 42 : loss : 1.0609 = 0.1110 + 0.9409 + 0.0090, time: 36.920093]
2023-05-24 20:48:25.072: epoch 42:	0.08625714  	0.15952584  	0.15827568  
2023-05-24 20:49:02.081: [iter 43 : loss : 1.0565 = 0.1069 + 0.9404 + 0.0092, time: 37.003750]
2023-05-24 20:49:02.498: epoch 43:	0.08613364  	0.15893933  	0.15796188  
2023-05-24 20:49:39.296: [iter 44 : loss : 1.0526 = 0.1033 + 0.9398 + 0.0095, time: 36.790856]
2023-05-24 20:49:39.726: epoch 44:	0.08599393  	0.15883948  	0.15766898  
2023-05-24 20:50:16.900: [iter 45 : loss : 1.0495 = 0.1005 + 0.9393 + 0.0097, time: 37.166473]
2023-05-24 20:50:17.300: epoch 45:	0.08572000  	0.15830727  	0.15713392  
2023-05-24 20:50:54.450: [iter 46 : loss : 1.0455 = 0.0968 + 0.9388 + 0.0099, time: 37.144055]
2023-05-24 20:50:54.865: epoch 46:	0.08552667  	0.15743840  	0.15642543  
2023-05-24 20:51:32.235: [iter 47 : loss : 1.0425 = 0.0942 + 0.9382 + 0.0101, time: 37.364145]
2023-05-24 20:51:32.653: epoch 47:	0.08522048  	0.15653773  	0.15573396  
2023-05-24 20:52:10.071: [iter 48 : loss : 1.0395 = 0.0914 + 0.9378 + 0.0104, time: 37.412021]
2023-05-24 20:52:10.473: epoch 48:	0.08500025  	0.15585370  	0.15515570  
2023-05-24 20:52:47.783: [iter 49 : loss : 1.0368 = 0.0888 + 0.9374 + 0.0106, time: 37.304073]
2023-05-24 20:52:48.180: epoch 49:	0.08467256  	0.15507777  	0.15451309  
2023-05-24 20:53:25.747: [iter 50 : loss : 1.0342 = 0.0864 + 0.9370 + 0.0108, time: 37.559732]
2023-05-24 20:53:26.151: epoch 50:	0.08457591  	0.15425839  	0.15384910  
2023-05-24 20:54:03.744: [iter 51 : loss : 1.0319 = 0.0842 + 0.9368 + 0.0110, time: 37.585795]
2023-05-24 20:54:04.143: epoch 51:	0.08428583  	0.15348646  	0.15320839  
2023-05-24 20:54:41.737: [iter 52 : loss : 1.0296 = 0.0821 + 0.9364 + 0.0111, time: 37.587095]
2023-05-24 20:54:42.131: epoch 52:	0.08402802  	0.15286535  	0.15260653  
2023-05-24 20:54:42.131: Early stopping is trigger at epoch: 52
2023-05-24 20:54:42.131: best_result@epoch 27:

2023-05-24 20:54:42.131: 		0.0878      	0.1670      	0.1641      
2023-05-24 21:04:17.052: my pid: 8816
2023-05-24 21:04:17.052: model: model.general_recommender.SGL
2023-05-24 21:04:17.052: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 21:04:17.052: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 21:04:21.936: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 21:04:55.806: [iter 1 : loss : 1.6101 = 0.6931 + 0.9169 + 0.0000, time: 33.869440]
2023-05-24 21:04:56.209: epoch 1:	0.00336268  	0.00757265  	0.00581332  
2023-05-24 21:04:56.210: Find a better model.
2023-05-24 21:05:29.714: [iter 2 : loss : 1.6093 = 0.6931 + 0.9163 + 0.0000, time: 33.497736]
2023-05-24 21:05:30.127: epoch 2:	0.00377093  	0.00776783  	0.00671197  
2023-05-24 21:05:30.127: Find a better model.
2023-05-24 21:06:03.812: [iter 3 : loss : 1.6096 = 0.6930 + 0.9166 + 0.0000, time: 33.676895]
2023-05-24 21:06:04.216: epoch 3:	0.00428661  	0.00853566  	0.00735380  
2023-05-24 21:06:04.216: Find a better model.
2023-05-24 21:06:38.111: [iter 4 : loss : 1.6101 = 0.6929 + 0.9171 + 0.0000, time: 33.888547]
2023-05-24 21:06:38.543: epoch 4:	0.00458742  	0.00906148  	0.00776350  
2023-05-24 21:06:38.543: Find a better model.
2023-05-24 21:07:12.133: [iter 5 : loss : 1.6104 = 0.6929 + 0.9176 + 0.0000, time: 33.582484]
2023-05-24 21:07:12.538: epoch 5:	0.00519979  	0.01071312  	0.00910474  
2023-05-24 21:07:12.538: Find a better model.
2023-05-24 21:07:46.151: [iter 6 : loss : 1.6108 = 0.6928 + 0.9180 + 0.0000, time: 33.607079]
2023-05-24 21:07:46.553: epoch 6:	0.00602165  	0.01205238  	0.01050938  
2023-05-24 21:07:46.553: Find a better model.
2023-05-24 21:08:20.094: [iter 7 : loss : 1.6112 = 0.6927 + 0.9185 + 0.0000, time: 33.533640]
2023-05-24 21:08:20.497: epoch 7:	0.00648899  	0.01254539  	0.01121084  
2023-05-24 21:08:20.497: Find a better model.
2023-05-24 21:08:54.085: [iter 8 : loss : 1.6113 = 0.6925 + 0.9188 + 0.0000, time: 33.582524]
2023-05-24 21:08:54.493: epoch 8:	0.00738609  	0.01452635  	0.01293297  
2023-05-24 21:08:54.493: Find a better model.
2023-05-24 21:09:28.154: [iter 9 : loss : 1.6117 = 0.6923 + 0.9194 + 0.0000, time: 33.653769]
2023-05-24 21:09:28.582: epoch 9:	0.00908897  	0.01719520  	0.01590477  
2023-05-24 21:09:28.582: Find a better model.
2023-05-24 21:10:02.124: [iter 10 : loss : 1.6118 = 0.6920 + 0.9197 + 0.0000, time: 33.535506]
2023-05-24 21:10:02.554: epoch 10:	0.01073278  	0.01988243  	0.01867465  
2023-05-24 21:10:02.554: Find a better model.
2023-05-24 21:10:36.129: [iter 11 : loss : 1.6118 = 0.6917 + 0.9201 + 0.0000, time: 33.568630]
2023-05-24 21:10:36.534: epoch 11:	0.01310177  	0.02535137  	0.02394846  
2023-05-24 21:10:36.534: Find a better model.
2023-05-24 21:11:10.056: [iter 12 : loss : 1.6119 = 0.6912 + 0.9207 + 0.0000, time: 33.516078]
2023-05-24 21:11:10.458: epoch 12:	0.01628730  	0.03197116  	0.03069072  
2023-05-24 21:11:10.458: Find a better model.
2023-05-24 21:11:44.052: [iter 13 : loss : 1.6119 = 0.6904 + 0.9214 + 0.0000, time: 33.586627]
2023-05-24 21:11:44.451: epoch 13:	0.02059017  	0.04024097  	0.03884361  
2023-05-24 21:11:44.451: Find a better model.
2023-05-24 21:12:18.265: [iter 14 : loss : 1.6116 = 0.6893 + 0.9223 + 0.0001, time: 33.807223]
2023-05-24 21:12:18.663: epoch 14:	0.02670869  	0.05253035  	0.05140349  
2023-05-24 21:12:18.663: Find a better model.
2023-05-24 21:12:52.289: [iter 15 : loss : 1.6107 = 0.6873 + 0.9233 + 0.0001, time: 33.618677]
2023-05-24 21:12:52.718: epoch 15:	0.03498598  	0.06837767  	0.06777806  
2023-05-24 21:12:52.718: Find a better model.
2023-05-24 21:13:27.255: [iter 16 : loss : 1.6088 = 0.6836 + 0.9251 + 0.0001, time: 34.529087]
2023-05-24 21:13:27.660: epoch 16:	0.04657769  	0.08913807  	0.08877435  
2023-05-24 21:13:27.660: Find a better model.
2023-05-24 21:14:02.063: [iter 17 : loss : 1.6038 = 0.6764 + 0.9272 + 0.0002, time: 34.397084]
2023-05-24 21:14:02.465: epoch 17:	0.05873337  	0.10965639  	0.11029796  
2023-05-24 21:14:02.465: Find a better model.
2023-05-24 21:14:37.076: [iter 18 : loss : 1.5925 = 0.6616 + 0.9306 + 0.0003, time: 34.603039]
2023-05-24 21:14:37.474: epoch 18:	0.06907895  	0.12780532  	0.12904993  
2023-05-24 21:14:37.475: Find a better model.
2023-05-24 21:15:12.175: [iter 19 : loss : 1.5692 = 0.6330 + 0.9358 + 0.0005, time: 34.694082]
2023-05-24 21:15:12.569: epoch 19:	0.07580400  	0.13918084  	0.14082853  
2023-05-24 21:15:12.569: Find a better model.
2023-05-24 21:15:47.047: [iter 20 : loss : 1.5311 = 0.5876 + 0.9428 + 0.0007, time: 34.471431]
2023-05-24 21:15:47.441: epoch 20:	0.08014423  	0.14851871  	0.14918038  
2023-05-24 21:15:47.442: Find a better model.
2023-05-24 21:16:22.003: [iter 21 : loss : 1.4810 = 0.5294 + 0.9505 + 0.0012, time: 34.553899]
2023-05-24 21:16:22.423: epoch 21:	0.08228749  	0.15347762  	0.15346532  
2023-05-24 21:16:22.424: Find a better model.
2023-05-24 21:16:56.978: [iter 22 : loss : 1.4270 = 0.4685 + 0.9569 + 0.0016, time: 34.547055]
2023-05-24 21:16:57.378: epoch 22:	0.08347452  	0.15627347  	0.15630840  
2023-05-24 21:16:57.378: Find a better model.
2023-05-24 21:17:31.992: [iter 23 : loss : 1.3769 = 0.4134 + 0.9614 + 0.0021, time: 34.606174]
2023-05-24 21:17:32.386: epoch 23:	0.08461325  	0.15929294  	0.15844916  
2023-05-24 21:17:32.387: Find a better model.
2023-05-24 21:18:07.145: [iter 24 : loss : 1.3323 = 0.3661 + 0.9635 + 0.0026, time: 34.751596]
2023-05-24 21:18:07.541: epoch 24:	0.08569833  	0.16161919  	0.16020530  
2023-05-24 21:18:07.541: Find a better model.
2023-05-24 21:18:42.173: [iter 25 : loss : 1.2947 = 0.3273 + 0.9643 + 0.0031, time: 34.625788]
2023-05-24 21:18:42.569: epoch 25:	0.08639127  	0.16330415  	0.16148493  
2023-05-24 21:18:42.570: Find a better model.
2023-05-24 21:19:17.136: [iter 26 : loss : 1.2623 = 0.2944 + 0.9643 + 0.0036, time: 34.559293]
2023-05-24 21:19:17.535: epoch 26:	0.08678879  	0.16397980  	0.16207615  
2023-05-24 21:19:17.535: Find a better model.
2023-05-24 21:19:51.940: [iter 27 : loss : 1.2343 = 0.2669 + 0.9633 + 0.0040, time: 34.398098]
2023-05-24 21:19:52.338: epoch 27:	0.08712180  	0.16461509  	0.16251098  
2023-05-24 21:19:52.344: Find a better model.
2023-05-24 21:20:26.857: [iter 28 : loss : 1.2113 = 0.2443 + 0.9625 + 0.0044, time: 34.507092]
2023-05-24 21:20:27.253: epoch 28:	0.08754085  	0.16545241  	0.16313535  
2023-05-24 21:20:27.253: Find a better model.
2023-05-24 21:21:01.870: [iter 29 : loss : 1.1915 = 0.2253 + 0.9614 + 0.0049, time: 34.611069]
2023-05-24 21:21:02.267: epoch 29:	0.08737957  	0.16520093  	0.16281225  
2023-05-24 21:21:36.899: [iter 30 : loss : 1.1739 = 0.2086 + 0.9600 + 0.0052, time: 34.625101]
2023-05-24 21:21:37.298: epoch 30:	0.08722383  	0.16513512  	0.16266419  
2023-05-24 21:22:12.080: [iter 31 : loss : 1.1583 = 0.1939 + 0.9588 + 0.0056, time: 34.774586]
2023-05-24 21:22:12.504: epoch 31:	0.08757296  	0.16586269  	0.16288365  
2023-05-24 21:22:12.504: Find a better model.
2023-05-24 21:22:47.046: [iter 32 : loss : 1.1454 = 0.1817 + 0.9577 + 0.0060, time: 34.535400]
2023-05-24 21:22:47.449: epoch 32:	0.08750319  	0.16545817  	0.16259243  
2023-05-24 21:23:22.027: [iter 33 : loss : 1.1332 = 0.1704 + 0.9565 + 0.0063, time: 34.571162]
2023-05-24 21:23:22.422: epoch 33:	0.08746023  	0.16511506  	0.16239803  
2023-05-24 21:23:57.218: [iter 34 : loss : 1.1234 = 0.1614 + 0.9553 + 0.0067, time: 34.789170]
2023-05-24 21:23:57.618: epoch 34:	0.08727762  	0.16446911  	0.16198476  
2023-05-24 21:24:32.279: [iter 35 : loss : 1.1137 = 0.1522 + 0.9545 + 0.0070, time: 34.653665]
2023-05-24 21:24:32.677: epoch 35:	0.08732594  	0.16448686  	0.16163252  
2023-05-24 21:25:07.628: [iter 36 : loss : 1.1055 = 0.1447 + 0.9534 + 0.0073, time: 34.945002]
2023-05-24 21:25:08.031: epoch 36:	0.08716480  	0.16379097  	0.16122358  
2023-05-24 21:25:42.951: [iter 37 : loss : 1.0976 = 0.1376 + 0.9524 + 0.0076, time: 34.914161]
2023-05-24 21:25:43.375: epoch 37:	0.08691778  	0.16309878  	0.16073765  
2023-05-24 21:26:18.128: [iter 38 : loss : 1.0908 = 0.1314 + 0.9515 + 0.0079, time: 34.746279]
2023-05-24 21:26:18.526: epoch 38:	0.08685338  	0.16275312  	0.16029505  
2023-05-24 21:26:53.127: [iter 39 : loss : 1.0849 = 0.1260 + 0.9507 + 0.0082, time: 34.595064]
2023-05-24 21:26:53.528: epoch 39:	0.08641284  	0.16162065  	0.15943299  
2023-05-24 21:27:28.286: [iter 40 : loss : 1.0796 = 0.1213 + 0.9499 + 0.0084, time: 34.750455]
2023-05-24 21:27:28.689: epoch 40:	0.08621951  	0.16091922  	0.15888949  
2023-05-24 21:28:03.297: [iter 41 : loss : 1.0741 = 0.1162 + 0.9492 + 0.0087, time: 34.600060]
2023-05-24 21:28:03.694: epoch 41:	0.08618197  	0.16080847  	0.15878193  
2023-05-24 21:28:38.492: [iter 42 : loss : 1.0696 = 0.1119 + 0.9487 + 0.0090, time: 34.791126]
2023-05-24 21:28:38.911: epoch 42:	0.08599932  	0.15993674  	0.15826142  
2023-05-24 21:29:13.886: [iter 43 : loss : 1.0647 = 0.1074 + 0.9480 + 0.0092, time: 34.966761]
2023-05-24 21:29:14.285: epoch 43:	0.08558031  	0.15865552  	0.15731525  
2023-05-24 21:29:49.055: [iter 44 : loss : 1.0610 = 0.1040 + 0.9476 + 0.0094, time: 34.763017]
2023-05-24 21:29:49.453: epoch 44:	0.08548365  	0.15851942  	0.15693784  
2023-05-24 21:30:24.084: [iter 45 : loss : 1.0578 = 0.1011 + 0.9470 + 0.0097, time: 34.623158]
2023-05-24 21:30:24.481: epoch 45:	0.08539771  	0.15807307  	0.15651187  
2023-05-24 21:30:59.615: [iter 46 : loss : 1.0540 = 0.0976 + 0.9465 + 0.0099, time: 35.127158]
2023-05-24 21:31:00.026: epoch 46:	0.08523650  	0.15755424  	0.15597406  
2023-05-24 21:31:35.024: [iter 47 : loss : 1.0504 = 0.0946 + 0.9457 + 0.0101, time: 34.988398]
2023-05-24 21:31:35.451: epoch 47:	0.08515061  	0.15707041  	0.15559478  
2023-05-24 21:32:10.058: [iter 48 : loss : 1.0475 = 0.0917 + 0.9454 + 0.0103, time: 34.601672]
2023-05-24 21:32:10.483: epoch 48:	0.08487128  	0.15628053  	0.15500467  
2023-05-24 21:32:45.233: [iter 49 : loss : 1.0450 = 0.0894 + 0.9450 + 0.0105, time: 34.742358]
2023-05-24 21:32:45.660: epoch 49:	0.08455428  	0.15555701  	0.15428367  
2023-05-24 21:33:20.644: [iter 50 : loss : 1.0422 = 0.0869 + 0.9445 + 0.0108, time: 34.976794]
2023-05-24 21:33:21.054: epoch 50:	0.08433405  	0.15483113  	0.15364341  
2023-05-24 21:33:55.982: [iter 51 : loss : 1.0399 = 0.0847 + 0.9443 + 0.0109, time: 34.921256]
2023-05-24 21:33:56.406: epoch 51:	0.08411379  	0.15408731  	0.15306117  
2023-05-24 21:34:31.187: [iter 52 : loss : 1.0377 = 0.0827 + 0.9439 + 0.0111, time: 34.775145]
2023-05-24 21:34:31.585: epoch 52:	0.08396874  	0.15391961  	0.15269552  
2023-05-24 21:35:06.323: [iter 53 : loss : 1.0355 = 0.0806 + 0.9436 + 0.0113, time: 34.731076]
2023-05-24 21:35:06.744: epoch 53:	0.08374854  	0.15314202  	0.15222934  
2023-05-24 21:35:41.554: [iter 54 : loss : 1.0329 = 0.0781 + 0.9432 + 0.0115, time: 34.801498]
2023-05-24 21:35:41.973: epoch 54:	0.08354981  	0.15214454  	0.15148062  
2023-05-24 21:36:16.723: [iter 55 : loss : 1.0315 = 0.0768 + 0.9430 + 0.0117, time: 34.742704]
2023-05-24 21:36:17.123: epoch 55:	0.08326505  	0.15146524  	0.15103938  
2023-05-24 21:36:52.095: [iter 56 : loss : 1.0297 = 0.0750 + 0.9428 + 0.0119, time: 34.965083]
2023-05-24 21:36:52.495: epoch 56:	0.08313079  	0.15106222  	0.15045831  
2023-05-24 21:36:52.495: Early stopping is trigger at epoch: 56
2023-05-24 21:36:52.495: best_result@epoch 31:

2023-05-24 21:36:52.495: 		0.0876      	0.1659      	0.1629      
2023-05-24 21:39:28.164: my pid: 8220
2023-05-24 21:39:28.164: model: model.general_recommender.SGL
2023-05-24 21:39:28.164: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-24 21:39:28.164: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-24 21:39:33.057: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-24 21:40:11.090: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 38.033351]
2023-05-24 21:40:11.496: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-05-24 21:40:11.496: Find a better model.
2023-05-24 21:40:48.563: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.060214]
2023-05-24 21:40:48.958: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-05-24 21:40:48.958: Find a better model.
2023-05-24 21:41:25.586: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 36.622094]
2023-05-24 21:41:25.983: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-05-24 21:41:25.983: Find a better model.
2023-05-24 21:42:02.713: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 36.723076]
2023-05-24 21:42:03.124: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-05-24 21:42:03.124: Find a better model.
2023-05-24 21:42:40.022: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 36.891373]
2023-05-24 21:42:40.417: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-05-24 21:42:40.417: Find a better model.
2023-05-24 21:43:18.150: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.725077]
2023-05-24 21:43:18.545: epoch 6:	0.00717658  	0.01480788  	0.01303477  
2023-05-24 21:43:18.545: Find a better model.
2023-05-24 21:43:56.268: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 37.716350]
2023-05-24 21:43:56.664: epoch 7:	0.00807906  	0.01563340  	0.01398509  
2023-05-24 21:43:56.664: Find a better model.
2023-05-24 21:44:34.291: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 37.619460]
2023-05-24 21:44:34.687: epoch 8:	0.00939518  	0.01842780  	0.01607837  
2023-05-24 21:44:34.687: Find a better model.
2023-05-24 21:45:12.350: [iter 9 : loss : 1.6056 = 0.6926 + 0.9130 + 0.0000, time: 37.657038]
2023-05-24 21:45:12.745: epoch 9:	0.01107658  	0.02175478  	0.01983246  
2023-05-24 21:45:12.745: Find a better model.
2023-05-24 21:45:50.420: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 37.668094]
2023-05-24 21:45:50.815: epoch 10:	0.01290300  	0.02526285  	0.02281626  
2023-05-24 21:45:50.815: Find a better model.
2023-05-24 21:46:28.259: [iter 11 : loss : 1.6052 = 0.6921 + 0.9131 + 0.0000, time: 37.437113]
2023-05-24 21:46:28.654: epoch 11:	0.01584683  	0.03107816  	0.02903584  
2023-05-24 21:46:28.654: Find a better model.
2023-05-24 21:47:06.285: [iter 12 : loss : 1.6050 = 0.6917 + 0.9132 + 0.0000, time: 37.623612]
2023-05-24 21:47:06.680: epoch 12:	0.01880672  	0.03685217  	0.03525729  
2023-05-24 21:47:06.680: Find a better model.
2023-05-24 21:47:44.274: [iter 13 : loss : 1.6047 = 0.6911 + 0.9135 + 0.0000, time: 37.588118]
2023-05-24 21:47:44.667: epoch 13:	0.02292698  	0.04659945  	0.04432834  
2023-05-24 21:47:44.667: Find a better model.
2023-05-24 21:48:22.359: [iter 14 : loss : 1.6040 = 0.6902 + 0.9138 + 0.0000, time: 37.686017]
2023-05-24 21:48:22.753: epoch 14:	0.02861566  	0.05788047  	0.05615758  
2023-05-24 21:48:22.753: Find a better model.
2023-05-24 21:49:00.457: [iter 15 : loss : 1.6027 = 0.6884 + 0.9142 + 0.0001, time: 37.698033]
2023-05-24 21:49:00.851: epoch 15:	0.03650068  	0.07374727  	0.07213871  
2023-05-24 21:49:00.851: Find a better model.
2023-05-24 21:49:38.298: [iter 16 : loss : 1.6000 = 0.6849 + 0.9150 + 0.0001, time: 37.441521]
2023-05-24 21:49:38.693: epoch 16:	0.04698590  	0.09378619  	0.09231741  
2023-05-24 21:49:38.693: Find a better model.
2023-05-24 21:50:16.377: [iter 17 : loss : 1.5936 = 0.6773 + 0.9161 + 0.0001, time: 37.677039]
2023-05-24 21:50:16.769: epoch 17:	0.05841105  	0.11453024  	0.11382106  
2023-05-24 21:50:16.769: Find a better model.
2023-05-24 21:50:54.375: [iter 18 : loss : 1.5791 = 0.6605 + 0.9183 + 0.0002, time: 37.599455]
2023-05-24 21:50:54.765: epoch 18:	0.06947099  	0.13289970  	0.13334091  
2023-05-24 21:50:54.765: Find a better model.
2023-05-24 21:51:32.416: [iter 19 : loss : 1.5495 = 0.6270 + 0.9221 + 0.0004, time: 37.645040]
2023-05-24 21:51:32.808: epoch 19:	0.07698040  	0.14538711  	0.14642295  
2023-05-24 21:51:32.808: Find a better model.
2023-05-24 21:52:10.346: [iter 20 : loss : 1.5033 = 0.5749 + 0.9276 + 0.0008, time: 37.532047]
2023-05-24 21:52:10.738: epoch 20:	0.08124532  	0.15272786  	0.15365954  
2023-05-24 21:52:10.738: Find a better model.
2023-05-24 21:52:48.294: [iter 21 : loss : 1.4470 = 0.5119 + 0.9338 + 0.0012, time: 37.550030]
2023-05-24 21:52:48.683: epoch 21:	0.08350677  	0.15758185  	0.15785763  
2023-05-24 21:52:48.683: Find a better model.
2023-05-24 21:53:26.543: [iter 22 : loss : 1.3903 = 0.4493 + 0.9392 + 0.0017, time: 37.852836]
2023-05-24 21:53:26.931: epoch 22:	0.08502691  	0.16015674  	0.16003437  
2023-05-24 21:53:26.931: Find a better model.
2023-05-24 21:54:04.565: [iter 23 : loss : 1.3403 = 0.3951 + 0.9429 + 0.0022, time: 37.628021]
2023-05-24 21:54:04.952: epoch 23:	0.08600459  	0.16254422  	0.16189541  
2023-05-24 21:54:04.953: Find a better model.
2023-05-24 21:54:42.737: [iter 24 : loss : 1.2973 = 0.3495 + 0.9451 + 0.0027, time: 37.778114]
2023-05-24 21:54:43.138: epoch 24:	0.08673516  	0.16434547  	0.16351424  
2023-05-24 21:54:43.138: Find a better model.
2023-05-24 21:55:20.909: [iter 25 : loss : 1.2619 = 0.3131 + 0.9457 + 0.0032, time: 37.765079]
2023-05-24 21:55:21.303: epoch 25:	0.08730983  	0.16539061  	0.16440471  
2023-05-24 21:55:21.303: Find a better model.
2023-05-24 21:55:58.888: [iter 26 : loss : 1.2314 = 0.2821 + 0.9457 + 0.0037, time: 37.579333]
2023-05-24 21:55:59.273: epoch 26:	0.08734203  	0.16565183  	0.16455634  
2023-05-24 21:55:59.273: Find a better model.
2023-05-24 21:56:37.095: [iter 27 : loss : 1.2058 = 0.2566 + 0.9452 + 0.0041, time: 37.816050]
2023-05-24 21:56:37.484: epoch 27:	0.08762135  	0.16624776  	0.16477960  
2023-05-24 21:56:37.485: Find a better model.
2023-05-24 21:57:15.401: [iter 28 : loss : 1.1846 = 0.2356 + 0.9445 + 0.0045, time: 37.910040]
2023-05-24 21:57:15.790: epoch 28:	0.08790613  	0.16633490  	0.16486958  
2023-05-24 21:57:15.790: Find a better model.
2023-05-24 21:57:53.454: [iter 29 : loss : 1.1661 = 0.2178 + 0.9434 + 0.0049, time: 37.658515]
2023-05-24 21:57:53.844: epoch 29:	0.08774497  	0.16593142  	0.16439609  
2023-05-24 21:58:31.665: [iter 30 : loss : 1.1497 = 0.2021 + 0.9423 + 0.0053, time: 37.813102]
2023-05-24 21:58:32.074: epoch 30:	0.08765369  	0.16588578  	0.16421364  
2023-05-24 21:59:10.015: [iter 31 : loss : 1.1351 = 0.1881 + 0.9413 + 0.0057, time: 37.933120]
2023-05-24 21:59:10.406: epoch 31:	0.08776653  	0.16561574  	0.16400841  
2023-05-24 21:59:48.405: [iter 32 : loss : 1.1233 = 0.1770 + 0.9402 + 0.0061, time: 37.992420]
2023-05-24 21:59:48.794: epoch 32:	0.08761621  	0.16520162  	0.16350859  
2023-05-24 22:00:26.643: [iter 33 : loss : 1.1119 = 0.1661 + 0.9393 + 0.0064, time: 37.842683]
2023-05-24 22:00:27.059: epoch 33:	0.08746580  	0.16489995  	0.16327037  
2023-05-24 22:01:05.026: [iter 34 : loss : 1.1029 = 0.1578 + 0.9383 + 0.0067, time: 37.961310]
2023-05-24 22:01:05.416: epoch 34:	0.08721331  	0.16387896  	0.16239664  
2023-05-24 22:01:43.618: [iter 35 : loss : 1.0937 = 0.1490 + 0.9376 + 0.0071, time: 38.194124]
2023-05-24 22:01:44.027: epoch 35:	0.08712192  	0.16357104  	0.16223842  
2023-05-24 22:02:22.075: [iter 36 : loss : 1.0860 = 0.1420 + 0.9367 + 0.0073, time: 38.034037]
2023-05-24 22:02:22.466: epoch 36:	0.08669752  	0.16241767  	0.16129437  
2023-05-24 22:03:00.347: [iter 37 : loss : 1.0784 = 0.1349 + 0.9358 + 0.0077, time: 37.874075]
2023-05-24 22:03:00.738: epoch 37:	0.08674055  	0.16195554  	0.16105619  
2023-05-24 22:03:38.932: [iter 38 : loss : 1.0720 = 0.1290 + 0.9351 + 0.0079, time: 38.188049]
2023-05-24 22:03:39.326: epoch 38:	0.08656859  	0.16146149  	0.16068859  
2023-05-24 22:04:17.499: [iter 39 : loss : 1.0666 = 0.1240 + 0.9344 + 0.0082, time: 38.167058]
2023-05-24 22:04:17.890: epoch 39:	0.08638587  	0.16098148  	0.15991713  
2023-05-24 22:04:56.089: [iter 40 : loss : 1.0615 = 0.1193 + 0.9337 + 0.0085, time: 38.192646]
2023-05-24 22:04:56.485: epoch 40:	0.08627304  	0.16029218  	0.15935653  
2023-05-24 22:05:34.559: [iter 41 : loss : 1.0559 = 0.1141 + 0.9331 + 0.0087, time: 38.067133]
2023-05-24 22:05:34.954: epoch 41:	0.08609043  	0.15928461  	0.15870245  
2023-05-24 22:06:12.827: [iter 42 : loss : 1.0516 = 0.1101 + 0.9325 + 0.0090, time: 37.867158]
2023-05-24 22:06:13.234: epoch 42:	0.08582192  	0.15842427  	0.15798429  
2023-05-24 22:06:51.162: [iter 43 : loss : 1.0470 = 0.1057 + 0.9320 + 0.0092, time: 37.920124]
2023-05-24 22:06:51.557: epoch 43:	0.08556405  	0.15722062  	0.15742649  
2023-05-24 22:07:29.869: [iter 44 : loss : 1.0433 = 0.1023 + 0.9315 + 0.0095, time: 38.306026]
2023-05-24 22:07:30.260: epoch 44:	0.08544587  	0.15704070  	0.15703465  
2023-05-24 22:08:08.625: [iter 45 : loss : 1.0403 = 0.0997 + 0.9309 + 0.0097, time: 38.358024]
2023-05-24 22:08:09.035: epoch 45:	0.08524175  	0.15670957  	0.15651478  
2023-05-24 22:08:47.052: [iter 46 : loss : 1.0366 = 0.0961 + 0.9305 + 0.0099, time: 38.005005]
2023-05-24 22:08:47.445: epoch 46:	0.08496241  	0.15589745  	0.15581490  
2023-05-24 22:09:25.658: [iter 47 : loss : 1.0334 = 0.0933 + 0.9300 + 0.0102, time: 38.206965]
2023-05-24 22:09:26.073: epoch 47:	0.08479054  	0.15522559  	0.15540457  
2023-05-24 22:10:04.441: [iter 48 : loss : 1.0304 = 0.0904 + 0.9296 + 0.0104, time: 38.360965]
2023-05-24 22:10:04.833: epoch 48:	0.08453272  	0.15435408  	0.15467483  
2023-05-24 22:10:43.115: [iter 49 : loss : 1.0279 = 0.0881 + 0.9293 + 0.0106, time: 38.276028]
2023-05-24 22:10:43.505: epoch 49:	0.08421037  	0.15383735  	0.15426882  
2023-05-24 22:11:21.561: [iter 50 : loss : 1.0254 = 0.0858 + 0.9288 + 0.0108, time: 38.049088]
2023-05-24 22:11:21.954: epoch 50:	0.08402231  	0.15336072  	0.15372416  
2023-05-24 22:12:00.167: [iter 51 : loss : 1.0232 = 0.0837 + 0.9286 + 0.0110, time: 38.207522]
2023-05-24 22:12:00.544: epoch 51:	0.08386654  	0.15281907  	0.15315771  
2023-05-24 22:12:38.559: [iter 52 : loss : 1.0209 = 0.0814 + 0.9283 + 0.0112, time: 38.008949]
2023-05-24 22:12:38.953: epoch 52:	0.08379140  	0.15228671  	0.15257709  
2023-05-24 22:13:17.066: [iter 53 : loss : 1.0186 = 0.0794 + 0.9278 + 0.0114, time: 38.105019]
2023-05-24 22:13:17.458: epoch 53:	0.08361413  	0.15180077  	0.15196280  
2023-05-24 22:13:17.458: Early stopping is trigger at epoch: 53
2023-05-24 22:13:17.458: best_result@epoch 28:

2023-05-24 22:13:17.458: 		0.0879      	0.1663      	0.1649      
2023-05-25 09:24:59.523: my pid: 6468
2023-05-25 09:24:59.523: model: model.general_recommender.SGL
2023-05-25 09:24:59.523: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 09:24:59.523: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 09:25:04.352: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 09:25:39.215: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 34.862752]
2023-05-25 09:25:39.612: epoch 1:	0.00296518  	0.00735567  	0.00575102  
2023-05-25 09:25:39.613: Find a better model.
2023-05-25 09:26:14.010: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 34.391215]
2023-05-25 09:26:14.419: epoch 2:	0.00394282  	0.00915322  	0.00758516  
2023-05-25 09:26:14.419: Find a better model.
2023-05-25 09:26:49.035: [iter 3 : loss : 1.6076 = 0.6930 + 0.9145 + 0.0000, time: 34.609093]
2023-05-25 09:26:49.442: epoch 3:	0.00465725  	0.00979082  	0.00850732  
2023-05-25 09:26:49.442: Find a better model.
2023-05-25 09:27:23.951: [iter 4 : loss : 1.6078 = 0.6930 + 0.9148 + 0.0000, time: 34.502063]
2023-05-25 09:27:24.366: epoch 4:	0.00484526  	0.01059586  	0.00875067  
2023-05-25 09:27:24.366: Find a better model.
2023-05-25 09:27:58.793: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 34.421034]
2023-05-25 09:27:59.190: epoch 5:	0.00561878  	0.01157434  	0.01024149  
2023-05-25 09:27:59.190: Find a better model.
2023-05-25 09:28:34.660: [iter 6 : loss : 1.6082 = 0.6928 + 0.9154 + 0.0000, time: 35.462648]
2023-05-25 09:28:35.059: epoch 6:	0.00608074  	0.01194737  	0.01055474  
2023-05-25 09:28:35.059: Find a better model.
2023-05-25 09:29:10.364: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 35.299184]
2023-05-25 09:29:10.760: epoch 7:	0.00650511  	0.01278844  	0.01154785  
2023-05-25 09:29:10.761: Find a better model.
2023-05-25 09:29:45.995: [iter 8 : loss : 1.6085 = 0.6926 + 0.9159 + 0.0000, time: 35.229108]
2023-05-25 09:29:46.405: epoch 8:	0.00740758  	0.01463524  	0.01331267  
2023-05-25 09:29:46.405: Find a better model.
2023-05-25 09:30:21.752: [iter 9 : loss : 1.6087 = 0.6925 + 0.9163 + 0.0000, time: 35.341142]
2023-05-25 09:30:22.148: epoch 9:	0.00920716  	0.01763699  	0.01603799  
2023-05-25 09:30:22.148: Find a better model.
2023-05-25 09:30:57.370: [iter 10 : loss : 1.6088 = 0.6922 + 0.9165 + 0.0000, time: 35.216161]
2023-05-25 09:30:57.765: epoch 10:	0.01075426  	0.01971202  	0.01860918  
2023-05-25 09:30:57.766: Find a better model.
2023-05-25 09:31:33.174: [iter 11 : loss : 1.6086 = 0.6919 + 0.9167 + 0.0000, time: 35.402026]
2023-05-25 09:31:33.567: epoch 11:	0.01248400  	0.02397276  	0.02272021  
2023-05-25 09:31:33.567: Find a better model.
2023-05-25 09:32:08.855: [iter 12 : loss : 1.6086 = 0.6915 + 0.9171 + 0.0000, time: 35.281623]
2023-05-25 09:32:09.251: epoch 12:	0.01577161  	0.03026486  	0.02886124  
2023-05-25 09:32:09.251: Find a better model.
2023-05-25 09:32:44.497: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 35.239029]
2023-05-25 09:32:44.892: epoch 13:	0.02057946  	0.04078451  	0.03925581  
2023-05-25 09:32:44.892: Find a better model.
2023-05-25 09:33:20.141: [iter 14 : loss : 1.6081 = 0.6898 + 0.9183 + 0.0000, time: 35.242782]
2023-05-25 09:33:20.542: epoch 14:	0.02689138  	0.05308669  	0.05144082  
2023-05-25 09:33:20.542: Find a better model.
2023-05-25 09:33:56.070: [iter 15 : loss : 1.6070 = 0.6879 + 0.9190 + 0.0001, time: 35.521102]
2023-05-25 09:33:56.467: epoch 15:	0.03614625  	0.07009690  	0.06921014  
2023-05-25 09:33:56.467: Find a better model.
2023-05-25 09:34:31.892: [iter 16 : loss : 1.6047 = 0.6843 + 0.9202 + 0.0001, time: 35.418146]
2023-05-25 09:34:32.308: epoch 16:	0.04701289  	0.09008299  	0.08995441  
2023-05-25 09:34:32.308: Find a better model.
2023-05-25 09:35:07.717: [iter 17 : loss : 1.5991 = 0.6769 + 0.9220 + 0.0001, time: 35.401398]
2023-05-25 09:35:08.111: epoch 17:	0.05963590  	0.11330142  	0.11312038  
2023-05-25 09:35:08.111: Find a better model.
2023-05-25 09:35:43.275: [iter 18 : loss : 1.5862 = 0.6610 + 0.9249 + 0.0003, time: 35.157138]
2023-05-25 09:35:43.672: epoch 18:	0.07089445  	0.13246556  	0.13387780  
2023-05-25 09:35:43.672: Find a better model.
2023-05-25 09:36:19.017: [iter 19 : loss : 1.5595 = 0.6295 + 0.9296 + 0.0005, time: 35.338061]
2023-05-25 09:36:19.417: epoch 19:	0.07721140  	0.14405070  	0.14632702  
2023-05-25 09:36:19.417: Find a better model.
2023-05-25 09:36:54.795: [iter 20 : loss : 1.5165 = 0.5797 + 0.9361 + 0.0008, time: 35.371041]
2023-05-25 09:36:55.184: epoch 20:	0.08092309  	0.15164456  	0.15314712  
2023-05-25 09:36:55.184: Find a better model.
2023-05-25 09:37:30.626: [iter 21 : loss : 1.4624 = 0.5177 + 0.9434 + 0.0012, time: 35.436517]
2023-05-25 09:37:31.017: epoch 21:	0.08309863  	0.15589218  	0.15680374  
2023-05-25 09:37:31.017: Find a better model.
2023-05-25 09:38:06.409: [iter 22 : loss : 1.4064 = 0.4553 + 0.9494 + 0.0017, time: 35.386089]
2023-05-25 09:38:06.800: epoch 22:	0.08458655  	0.15942815  	0.15919772  
2023-05-25 09:38:06.800: Find a better model.
2023-05-25 09:38:42.146: [iter 23 : loss : 1.3565 = 0.4009 + 0.9535 + 0.0022, time: 35.340174]
2023-05-25 09:38:42.531: epoch 23:	0.08547815  	0.16166812  	0.16083239  
2023-05-25 09:38:42.532: Find a better model.
2023-05-25 09:39:17.966: [iter 24 : loss : 1.3130 = 0.3548 + 0.9555 + 0.0027, time: 35.427083]
2023-05-25 09:39:18.370: epoch 24:	0.08634288  	0.16316633  	0.16187906  
2023-05-25 09:39:18.370: Find a better model.
2023-05-25 09:39:54.107: [iter 25 : loss : 1.2770 = 0.3179 + 0.9560 + 0.0032, time: 35.729567]
2023-05-25 09:39:54.496: epoch 25:	0.08659000  	0.16386959  	0.16245605  
2023-05-25 09:39:54.497: Find a better model.
2023-05-25 09:40:30.014: [iter 26 : loss : 1.2458 = 0.2864 + 0.9558 + 0.0036, time: 35.510253]
2023-05-25 09:40:30.415: epoch 26:	0.08686935  	0.16483732  	0.16296120  
2023-05-25 09:40:30.415: Find a better model.
2023-05-25 09:41:06.108: [iter 27 : loss : 1.2196 = 0.2605 + 0.9550 + 0.0041, time: 35.685228]
2023-05-25 09:41:06.499: epoch 27:	0.08725607  	0.16536288  	0.16313341  
2023-05-25 09:41:06.499: Find a better model.
2023-05-25 09:41:42.110: [iter 28 : loss : 1.1973 = 0.2387 + 0.9542 + 0.0045, time: 35.604552]
2023-05-25 09:41:42.503: epoch 28:	0.08747639  	0.16565137  	0.16349372  
2023-05-25 09:41:42.503: Find a better model.
2023-05-25 09:42:17.881: [iter 29 : loss : 1.1783 = 0.2205 + 0.9528 + 0.0049, time: 35.371995]
2023-05-25 09:42:18.277: epoch 29:	0.08746038  	0.16537175  	0.16316003  
2023-05-25 09:42:53.917: [iter 30 : loss : 1.1615 = 0.2046 + 0.9516 + 0.0053, time: 35.626083]
2023-05-25 09:42:54.331: epoch 30:	0.08762687  	0.16569607  	0.16329832  
2023-05-25 09:42:54.331: Find a better model.
2023-05-25 09:43:29.846: [iter 31 : loss : 1.1464 = 0.1903 + 0.9505 + 0.0057, time: 35.509028]
2023-05-25 09:43:30.238: epoch 31:	0.08746038  	0.16548157  	0.16288248  
2023-05-25 09:44:05.871: [iter 32 : loss : 1.1343 = 0.1789 + 0.9493 + 0.0060, time: 35.627331]
2023-05-25 09:44:06.268: epoch 32:	0.08771286  	0.16548994  	0.16310108  
2023-05-25 09:44:42.037: [iter 33 : loss : 1.1224 = 0.1677 + 0.9483 + 0.0064, time: 35.753491]
2023-05-25 09:44:42.439: epoch 33:	0.08751416  	0.16454878  	0.16271161  
2023-05-25 09:45:18.097: [iter 34 : loss : 1.1132 = 0.1592 + 0.9473 + 0.0067, time: 35.650919]
2023-05-25 09:45:18.491: epoch 34:	0.08746047  	0.16369170  	0.16228093  
2023-05-25 09:45:54.358: [iter 35 : loss : 1.1035 = 0.1500 + 0.9465 + 0.0070, time: 35.860714]
2023-05-25 09:45:54.740: epoch 35:	0.08733160  	0.16339521  	0.16184191  
2023-05-25 09:46:27.985: my pid: 13444
2023-05-25 09:46:27.986: model: model.general_recommender.SGL
2023-05-25 09:46:27.986: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 09:46:27.986: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 09:46:33.288: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 09:47:10.399: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 37.111293]
2023-05-25 09:47:10.806: epoch 1:	0.00337880  	0.00807749  	0.00656585  
2023-05-25 09:47:10.807: Find a better model.
2023-05-25 09:47:46.665: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 35.852330]
2023-05-25 09:47:47.069: epoch 2:	0.00420603  	0.00948111  	0.00820640  
2023-05-25 09:47:47.069: Find a better model.
2023-05-25 09:48:22.939: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 35.862709]
2023-05-25 09:48:23.365: epoch 3:	0.00493658  	0.01017637  	0.00911207  
2023-05-25 09:48:23.365: Find a better model.
2023-05-25 09:48:59.191: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 35.820482]
2023-05-25 09:48:59.604: epoch 4:	0.00538780  	0.01099415  	0.00942833  
2023-05-25 09:48:59.604: Find a better model.
2023-05-25 09:49:35.425: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 35.814322]
2023-05-25 09:49:35.832: epoch 5:	0.00636544  	0.01287323  	0.01113765  
2023-05-25 09:49:35.833: Find a better model.
2023-05-25 09:50:12.466: [iter 6 : loss : 1.6068 = 0.6929 + 0.9139 + 0.0000, time: 36.627114]
2023-05-25 09:50:12.872: epoch 6:	0.00682740  	0.01344570  	0.01219054  
2023-05-25 09:50:12.873: Find a better model.
2023-05-25 09:50:49.534: [iter 7 : loss : 1.6069 = 0.6928 + 0.9141 + 0.0000, time: 36.655410]
2023-05-25 09:50:49.939: epoch 7:	0.00774600  	0.01436552  	0.01302919  
2023-05-25 09:50:49.939: Find a better model.
2023-05-25 09:51:26.769: [iter 8 : loss : 1.6068 = 0.6927 + 0.9141 + 0.0000, time: 36.823766]
2023-05-25 09:51:27.171: epoch 8:	0.00913733  	0.01718748  	0.01586105  
2023-05-25 09:51:27.171: Find a better model.
2023-05-25 09:52:03.925: [iter 9 : loss : 1.6070 = 0.6925 + 0.9145 + 0.0000, time: 36.748083]
2023-05-25 09:52:04.351: epoch 9:	0.01079723  	0.02022989  	0.01855043  
2023-05-25 09:52:04.351: Find a better model.
2023-05-25 09:52:41.069: [iter 10 : loss : 1.6069 = 0.6923 + 0.9146 + 0.0000, time: 36.711147]
2023-05-25 09:52:41.487: epoch 10:	0.01248401  	0.02338119  	0.02186571  
2023-05-25 09:52:41.487: Find a better model.
2023-05-25 09:53:17.968: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 36.474348]
2023-05-25 09:53:18.391: epoch 11:	0.01469724  	0.02882809  	0.02682044  
2023-05-25 09:53:18.391: Find a better model.
2023-05-25 09:53:54.909: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 36.511743]
2023-05-25 09:53:55.334: epoch 12:	0.01824806  	0.03585981  	0.03374289  
2023-05-25 09:53:55.334: Find a better model.
2023-05-25 09:54:31.959: [iter 13 : loss : 1.6063 = 0.6909 + 0.9153 + 0.0000, time: 36.618074]
2023-05-25 09:54:32.379: epoch 13:	0.02226084  	0.04449483  	0.04285424  
2023-05-25 09:54:32.379: Find a better model.
2023-05-25 09:55:09.084: [iter 14 : loss : 1.6057 = 0.6899 + 0.9158 + 0.0000, time: 36.699411]
2023-05-25 09:55:09.495: epoch 14:	0.02856192  	0.05669481  	0.05503701  
2023-05-25 09:55:09.495: Find a better model.
2023-05-25 09:55:46.132: [iter 15 : loss : 1.6044 = 0.6879 + 0.9164 + 0.0001, time: 36.631318]
2023-05-25 09:55:46.535: epoch 15:	0.03722056  	0.07296624  	0.07221774  
2023-05-25 09:55:46.535: Find a better model.
2023-05-25 09:56:23.192: [iter 16 : loss : 1.6017 = 0.6842 + 0.9174 + 0.0001, time: 36.650290]
2023-05-25 09:56:23.599: epoch 16:	0.04839331  	0.09371125  	0.09362034  
2023-05-25 09:56:23.599: Find a better model.
2023-05-25 09:57:00.423: [iter 17 : loss : 1.5951 = 0.6760 + 0.9189 + 0.0001, time: 36.818027]
2023-05-25 09:57:00.825: epoch 17:	0.06050061  	0.11562708  	0.11617164  
2023-05-25 09:57:00.825: Find a better model.
2023-05-25 09:57:37.555: [iter 18 : loss : 1.5802 = 0.6583 + 0.9216 + 0.0003, time: 36.724541]
2023-05-25 09:57:37.956: epoch 18:	0.07128654  	0.13344938  	0.13509811  
2023-05-25 09:57:37.956: Find a better model.
2023-05-25 09:58:14.928: [iter 19 : loss : 1.5504 = 0.6240 + 0.9259 + 0.0005, time: 36.964458]
2023-05-25 09:58:15.353: epoch 19:	0.07727578  	0.14369042  	0.14679980  
2023-05-25 09:58:15.353: Find a better model.
2023-05-25 09:58:51.900: [iter 20 : loss : 1.5044 = 0.5716 + 0.9320 + 0.0008, time: 36.540072]
2023-05-25 09:58:52.324: epoch 20:	0.08093372  	0.15101276  	0.15312880  
2023-05-25 09:58:52.324: Find a better model.
2023-05-25 09:59:28.932: [iter 21 : loss : 1.4488 = 0.5089 + 0.9386 + 0.0012, time: 36.602490]
2023-05-25 09:59:29.349: epoch 21:	0.08300172  	0.15536317  	0.15684140  
2023-05-25 09:59:29.349: Find a better model.
2023-05-25 10:00:05.990: [iter 22 : loss : 1.3928 = 0.4470 + 0.9441 + 0.0017, time: 36.635067]
2023-05-25 10:00:06.406: epoch 22:	0.08461850  	0.15922771  	0.15964907  
2023-05-25 10:00:06.406: Find a better model.
2023-05-25 10:00:43.264: [iter 23 : loss : 1.3435 = 0.3934 + 0.9479 + 0.0022, time: 36.851113]
2023-05-25 10:00:43.666: epoch 23:	0.08538125  	0.16116640  	0.16131268  
2023-05-25 10:00:43.666: Find a better model.
2023-05-25 10:01:20.494: [iter 24 : loss : 1.3008 = 0.3482 + 0.9498 + 0.0028, time: 36.819156]
2023-05-25 10:01:20.888: epoch 24:	0.08605276  	0.16284584  	0.16253033  
2023-05-25 10:01:20.888: Find a better model.
2023-05-25 10:01:57.717: [iter 25 : loss : 1.2655 = 0.3121 + 0.9503 + 0.0032, time: 36.822752]
2023-05-25 10:01:58.111: epoch 25:	0.08652011  	0.16399206  	0.16325156  
2023-05-25 10:01:58.112: Find a better model.
2023-05-25 10:02:35.085: [iter 26 : loss : 1.2353 = 0.2814 + 0.9501 + 0.0037, time: 36.967044]
2023-05-25 10:02:35.487: epoch 26:	0.08692832  	0.16495177  	0.16375798  
2023-05-25 10:02:35.487: Find a better model.
2023-05-25 10:03:12.138: [iter 27 : loss : 1.2098 = 0.2561 + 0.9495 + 0.0041, time: 36.643228]
2023-05-25 10:03:12.532: epoch 27:	0.08694989  	0.16485070  	0.16384502  
2023-05-25 10:03:49.216: [iter 28 : loss : 1.1883 = 0.2350 + 0.9487 + 0.0046, time: 36.678262]
2023-05-25 10:03:49.617: epoch 28:	0.08710572  	0.16528201  	0.16380787  
2023-05-25 10:03:49.617: Find a better model.
2023-05-25 10:04:26.802: [iter 29 : loss : 1.1698 = 0.2173 + 0.9475 + 0.0050, time: 37.177997]
2023-05-25 10:04:27.200: epoch 29:	0.08695002  	0.16494432  	0.16352324  
2023-05-25 10:05:03.962: [iter 30 : loss : 1.1535 = 0.2018 + 0.9464 + 0.0054, time: 36.755016]
2023-05-25 10:05:04.377: epoch 30:	0.08698224  	0.16458175  	0.16313303  
2023-05-25 10:05:41.133: [iter 31 : loss : 1.1390 = 0.1879 + 0.9453 + 0.0057, time: 36.748057]
2023-05-25 10:05:41.535: epoch 31:	0.08689088  	0.16454829  	0.16279498  
2023-05-25 10:06:18.307: [iter 32 : loss : 1.1269 = 0.1765 + 0.9443 + 0.0061, time: 36.766186]
2023-05-25 10:06:18.703: epoch 32:	0.08706277  	0.16448170  	0.16262957  
2023-05-25 10:06:55.506: [iter 33 : loss : 1.1153 = 0.1657 + 0.9433 + 0.0064, time: 36.796155]
2023-05-25 10:06:55.903: epoch 33:	0.08705200  	0.16429335  	0.16243525  
2023-05-25 10:07:32.918: [iter 34 : loss : 1.1066 = 0.1576 + 0.9422 + 0.0068, time: 37.006773]
2023-05-25 10:07:33.334: epoch 34:	0.08697137  	0.16390564  	0.16192175  
2023-05-25 10:08:10.296: [iter 35 : loss : 1.0970 = 0.1485 + 0.9414 + 0.0071, time: 36.952724]
2023-05-25 10:08:10.691: epoch 35:	0.08688549  	0.16337700  	0.16141884  
2023-05-25 10:08:47.603: [iter 36 : loss : 1.0895 = 0.1416 + 0.9405 + 0.0074, time: 36.906639]
2023-05-25 10:08:48.001: epoch 36:	0.08661154  	0.16247112  	0.16088428  
2023-05-25 10:09:25.303: [iter 37 : loss : 1.0820 = 0.1347 + 0.9396 + 0.0077, time: 37.294204]
2023-05-25 10:09:25.704: epoch 37:	0.08630531  	0.16184798  	0.16028622  
2023-05-25 10:10:02.874: [iter 38 : loss : 1.0757 = 0.1289 + 0.9389 + 0.0080, time: 37.163530]
2023-05-25 10:10:03.271: epoch 38:	0.08611727  	0.16109239  	0.15972479  
2023-05-25 10:10:40.379: [iter 39 : loss : 1.0699 = 0.1236 + 0.9381 + 0.0082, time: 37.100480]
2023-05-25 10:10:40.777: epoch 39:	0.08580575  	0.16000840  	0.15882432  
2023-05-25 10:11:18.232: [iter 40 : loss : 1.0650 = 0.1191 + 0.9374 + 0.0085, time: 37.449363]
2023-05-25 10:11:18.636: epoch 40:	0.08570911  	0.15965219  	0.15840471  
2023-05-25 10:11:55.665: [iter 41 : loss : 1.0594 = 0.1140 + 0.9367 + 0.0088, time: 37.022199]
2023-05-25 10:11:56.063: epoch 41:	0.08552653  	0.15920202  	0.15782288  
2023-05-25 10:12:33.106: [iter 42 : loss : 1.0549 = 0.1098 + 0.9361 + 0.0090, time: 37.036243]
2023-05-25 10:12:33.513: epoch 42:	0.08509681  	0.15827121  	0.15704268  
2023-05-25 10:13:10.350: [iter 43 : loss : 1.0503 = 0.1055 + 0.9356 + 0.0093, time: 36.829216]
2023-05-25 10:13:10.748: epoch 43:	0.08486044  	0.15754318  	0.15643495  
2023-05-25 10:13:48.225: [iter 44 : loss : 1.0468 = 0.1023 + 0.9351 + 0.0095, time: 37.471438]
2023-05-25 10:13:48.627: epoch 44:	0.08468319  	0.15694816  	0.15597284  
2023-05-25 10:14:26.028: [iter 45 : loss : 1.0438 = 0.0995 + 0.9346 + 0.0097, time: 37.395339]
2023-05-25 10:14:26.437: epoch 45:	0.08445224  	0.15596522  	0.15517348  
2023-05-25 10:15:03.743: [iter 46 : loss : 1.0401 = 0.0961 + 0.9341 + 0.0099, time: 37.299418]
2023-05-25 10:15:04.143: epoch 46:	0.08433404  	0.15558961  	0.15461397  
2023-05-25 10:15:41.363: [iter 47 : loss : 1.0370 = 0.0933 + 0.9335 + 0.0102, time: 37.214418]
2023-05-25 10:15:41.765: epoch 47:	0.08410837  	0.15509015  	0.15394150  
2023-05-25 10:16:19.370: [iter 48 : loss : 1.0337 = 0.0902 + 0.9331 + 0.0104, time: 37.597407]
2023-05-25 10:16:19.769: epoch 48:	0.08385053  	0.15414043  	0.15335982  
2023-05-25 10:16:57.196: [iter 49 : loss : 1.0313 = 0.0879 + 0.9328 + 0.0106, time: 37.419310]
2023-05-25 10:16:57.601: epoch 49:	0.08359806  	0.15321733  	0.15286472  
2023-05-25 10:17:35.015: [iter 50 : loss : 1.0287 = 0.0856 + 0.9323 + 0.0108, time: 37.406237]
2023-05-25 10:17:35.434: epoch 50:	0.08343693  	0.15266739  	0.15236014  
2023-05-25 10:18:05.668: my pid: 12996
2023-05-25 10:18:05.668: model: model.general_recommender.SGL
2023-05-25 10:18:05.668: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 10:18:05.668: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 10:18:10.925: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 10:18:47.222: my pid: 1640
2023-05-25 10:18:47.222: model: model.general_recommender.SGL
2023-05-25 10:18:47.222: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 10:18:47.222: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 10:18:51.981: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 10:19:30.508: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 38.525370]
2023-05-25 10:19:30.909: epoch 1:	0.00349160  	0.00821223  	0.00674875  
2023-05-25 10:19:30.909: Find a better model.
2023-05-25 10:20:09.359: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 38.444920]
2023-05-25 10:20:09.765: epoch 2:	0.00411472  	0.00870434  	0.00735326  
2023-05-25 10:20:09.765: Find a better model.
2023-05-25 10:20:47.860: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 38.086949]
2023-05-25 10:20:48.263: epoch 3:	0.00513533  	0.01078933  	0.00928117  
2023-05-25 10:20:48.263: Find a better model.
2023-05-25 10:21:26.631: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 38.361100]
2023-05-25 10:21:27.031: epoch 4:	0.00604314  	0.01171840  	0.01048327  
2023-05-25 10:21:27.032: Find a better model.
2023-05-25 10:22:05.327: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 38.288273]
2023-05-25 10:22:05.730: epoch 5:	0.00712823  	0.01388803  	0.01248124  
2023-05-25 10:22:05.730: Find a better model.
2023-05-25 10:22:45.077: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 39.341536]
2023-05-25 10:22:45.492: epoch 6:	0.00842823  	0.01580496  	0.01441982  
2023-05-25 10:22:45.492: Find a better model.
2023-05-25 10:23:24.479: [iter 7 : loss : 1.6045 = 0.6928 + 0.9118 + 0.0000, time: 38.979430]
2023-05-25 10:23:24.879: epoch 7:	0.00992162  	0.01849694  	0.01717910  
2023-05-25 10:23:24.880: Find a better model.
2023-05-25 10:24:04.082: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 39.195090]
2023-05-25 10:24:04.490: epoch 8:	0.01096376  	0.02055814  	0.01935945  
2023-05-25 10:24:04.490: Find a better model.
2023-05-25 10:24:43.641: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 39.145352]
2023-05-25 10:24:44.040: epoch 9:	0.01251087  	0.02289000  	0.02217275  
2023-05-25 10:24:44.041: Find a better model.
2023-05-25 10:25:23.012: [iter 10 : loss : 1.6041 = 0.6922 + 0.9118 + 0.0000, time: 38.965209]
2023-05-25 10:25:23.429: epoch 10:	0.01447698  	0.02752482  	0.02588308  
2023-05-25 10:25:23.429: Find a better model.
2023-05-25 10:26:02.569: [iter 11 : loss : 1.6037 = 0.6919 + 0.9118 + 0.0000, time: 39.133421]
2023-05-25 10:26:02.969: epoch 11:	0.01705550  	0.03280131  	0.03118373  
2023-05-25 10:26:02.969: Find a better model.
2023-05-25 10:26:42.022: [iter 12 : loss : 1.6034 = 0.6914 + 0.9120 + 0.0000, time: 39.046895]
2023-05-25 10:26:42.435: epoch 12:	0.02095014  	0.04075135  	0.03915856  
2023-05-25 10:26:42.435: Find a better model.
2023-05-25 10:27:21.789: [iter 13 : loss : 1.6028 = 0.6906 + 0.9121 + 0.0000, time: 39.348446]
2023-05-25 10:27:22.186: epoch 13:	0.02540339  	0.05042424  	0.04863643  
2023-05-25 10:27:22.186: Find a better model.
2023-05-25 10:28:01.221: [iter 14 : loss : 1.6017 = 0.6892 + 0.9124 + 0.0000, time: 39.028444]
2023-05-25 10:28:01.613: epoch 14:	0.03190286  	0.06477942  	0.06242574  
2023-05-25 10:28:01.613: Find a better model.
2023-05-25 10:28:40.946: [iter 15 : loss : 1.5994 = 0.6866 + 0.9128 + 0.0001, time: 39.327283]
2023-05-25 10:28:41.366: epoch 15:	0.04079257  	0.08260309  	0.08051677  
2023-05-25 10:28:41.367: Find a better model.
2023-05-25 10:29:20.563: [iter 16 : loss : 1.5945 = 0.6809 + 0.9135 + 0.0001, time: 39.190305]
2023-05-25 10:29:20.962: epoch 16:	0.05147124  	0.10299524  	0.10117037  
2023-05-25 10:29:20.962: Find a better model.
2023-05-25 10:30:00.103: [iter 17 : loss : 1.5834 = 0.6684 + 0.9149 + 0.0002, time: 39.133471]
2023-05-25 10:30:00.503: epoch 17:	0.06343331  	0.12338238  	0.12316097  
2023-05-25 10:30:00.503: Find a better model.
2023-05-25 10:30:39.795: [iter 18 : loss : 1.5598 = 0.6418 + 0.9177 + 0.0003, time: 39.285302]
2023-05-25 10:30:40.192: epoch 18:	0.07318806  	0.13966589  	0.14034785  
2023-05-25 10:30:40.192: Find a better model.
2023-05-25 10:31:19.499: [iter 19 : loss : 1.5183 = 0.5953 + 0.9224 + 0.0006, time: 39.300464]
2023-05-25 10:31:19.896: epoch 19:	0.07894653  	0.14878203  	0.15002684  
2023-05-25 10:31:19.896: Find a better model.
2023-05-25 10:31:59.248: [iter 20 : loss : 1.4640 = 0.5344 + 0.9286 + 0.0010, time: 39.345298]
2023-05-25 10:31:59.650: epoch 20:	0.08226593  	0.15464760  	0.15582220  
2023-05-25 10:31:59.650: Find a better model.
2023-05-25 10:32:38.875: [iter 21 : loss : 1.4065 = 0.4704 + 0.9346 + 0.0015, time: 39.219030]
2023-05-25 10:32:39.270: epoch 21:	0.08413523  	0.15825143  	0.15898609  
2023-05-25 10:32:39.271: Find a better model.
2023-05-25 10:33:18.226: [iter 22 : loss : 1.3534 = 0.4124 + 0.9390 + 0.0020, time: 38.948132]
2023-05-25 10:33:18.625: epoch 22:	0.08530077  	0.16062774  	0.16131434  
2023-05-25 10:33:18.625: Find a better model.
2023-05-25 10:33:57.841: [iter 23 : loss : 1.3086 = 0.3645 + 0.9416 + 0.0025, time: 39.209890]
2023-05-25 10:33:58.238: epoch 23:	0.08628922  	0.16258721  	0.16271000  
2023-05-25 10:33:58.238: Find a better model.
2023-05-25 10:34:37.602: [iter 24 : loss : 1.2706 = 0.3248 + 0.9428 + 0.0030, time: 39.357293]
2023-05-25 10:34:37.999: epoch 24:	0.08699829  	0.16416708  	0.16370392  
2023-05-25 10:34:37.999: Find a better model.
2023-05-25 10:35:17.184: [iter 25 : loss : 1.2394 = 0.2930 + 0.9429 + 0.0035, time: 39.178471]
2023-05-25 10:35:17.574: epoch 25:	0.08719713  	0.16444367  	0.16389187  
2023-05-25 10:35:17.574: Find a better model.
2023-05-25 10:35:57.009: [iter 26 : loss : 1.2124 = 0.2659 + 0.9425 + 0.0039, time: 39.428179]
2023-05-25 10:35:57.418: epoch 26:	0.08753008  	0.16526033  	0.16445400  
2023-05-25 10:35:57.418: Find a better model.
2023-05-25 10:36:36.563: [iter 27 : loss : 1.1895 = 0.2433 + 0.9418 + 0.0043, time: 39.137061]
2023-05-25 10:36:36.959: epoch 27:	0.08778258  	0.16573952  	0.16456860  
2023-05-25 10:36:36.960: Find a better model.
2023-05-25 10:37:16.411: [iter 28 : loss : 1.1700 = 0.2242 + 0.9410 + 0.0048, time: 39.446076]
2023-05-25 10:37:16.806: epoch 28:	0.08766441  	0.16550286  	0.16439155  
2023-05-25 10:37:56.411: [iter 29 : loss : 1.1535 = 0.2085 + 0.9399 + 0.0051, time: 39.598576]
2023-05-25 10:37:56.805: epoch 29:	0.08749785  	0.16495326  	0.16423649  
2023-05-25 10:38:36.192: [iter 30 : loss : 1.1388 = 0.1944 + 0.9389 + 0.0055, time: 39.380226]
2023-05-25 10:38:36.593: epoch 30:	0.08755147  	0.16494042  	0.16405673  
2023-05-25 10:39:16.013: [iter 31 : loss : 1.1252 = 0.1814 + 0.9379 + 0.0059, time: 39.412590]
2023-05-25 10:39:16.427: epoch 31:	0.08737967  	0.16410254  	0.16346207  
2023-05-25 10:39:56.081: [iter 32 : loss : 1.1142 = 0.1711 + 0.9368 + 0.0062, time: 39.648083]
2023-05-25 10:39:56.485: epoch 32:	0.08728834  	0.16371012  	0.16309190  
2023-05-25 10:40:35.675: [iter 33 : loss : 1.1038 = 0.1613 + 0.9359 + 0.0066, time: 39.183667]
2023-05-25 10:40:36.070: epoch 33:	0.08712184  	0.16311508  	0.16255154  
2023-05-25 10:41:15.318: [iter 34 : loss : 1.0953 = 0.1534 + 0.9350 + 0.0069, time: 39.242051]
2023-05-25 10:41:15.718: epoch 34:	0.08704133  	0.16249648  	0.16220798  
2023-05-25 10:41:55.060: [iter 35 : loss : 1.0864 = 0.1449 + 0.9343 + 0.0072, time: 39.336787]
2023-05-25 10:41:55.464: epoch 35:	0.08688018  	0.16214235  	0.16172898  
2023-05-25 10:42:34.888: [iter 36 : loss : 1.0792 = 0.1383 + 0.9334 + 0.0075, time: 39.417885]
2023-05-25 10:42:35.285: epoch 36:	0.08678892  	0.16164593  	0.16118783  
2023-05-25 10:43:14.583: [iter 37 : loss : 1.0721 = 0.1318 + 0.9325 + 0.0078, time: 39.291392]
2023-05-25 10:43:14.977: epoch 37:	0.08664931  	0.16123714  	0.16079673  
2023-05-25 10:43:54.028: [iter 38 : loss : 1.0662 = 0.1263 + 0.9318 + 0.0081, time: 39.045404]
2023-05-25 10:43:54.432: epoch 38:	0.08649889  	0.16080160  	0.16038758  
2023-05-25 10:44:33.803: [iter 39 : loss : 1.0609 = 0.1214 + 0.9311 + 0.0084, time: 39.364245]
2023-05-25 10:44:34.198: epoch 39:	0.08627333  	0.16016753  	0.15969600  
2023-05-25 10:45:13.580: [iter 40 : loss : 1.0560 = 0.1168 + 0.9305 + 0.0086, time: 39.374408]
2023-05-25 10:45:13.974: epoch 40:	0.08601549  	0.15916054  	0.15899648  
2023-05-25 10:45:53.433: [iter 41 : loss : 1.0508 = 0.1120 + 0.9299 + 0.0089, time: 39.453634]
2023-05-25 10:45:53.832: epoch 41:	0.08591877  	0.15876783  	0.15864739  
2023-05-25 10:46:33.243: [iter 42 : loss : 1.0466 = 0.1082 + 0.9293 + 0.0091, time: 39.405525]
2023-05-25 10:46:33.644: epoch 42:	0.08577372  	0.15823381  	0.15801659  
2023-05-25 10:47:13.044: [iter 43 : loss : 1.0424 = 0.1042 + 0.9288 + 0.0094, time: 39.394090]
2023-05-25 10:47:13.448: epoch 43:	0.08551054  	0.15721720  	0.15731873  
2023-05-25 10:47:52.982: [iter 44 : loss : 1.0386 = 0.1006 + 0.9283 + 0.0096, time: 39.527221]
2023-05-25 10:47:53.396: epoch 44:	0.08559109  	0.15705705  	0.15698701  
2023-05-25 10:48:32.735: [iter 45 : loss : 1.0356 = 0.0980 + 0.9278 + 0.0098, time: 39.331179]
2023-05-25 10:48:33.132: epoch 45:	0.08534939  	0.15606408  	0.15622130  
2023-05-25 10:49:12.524: [iter 46 : loss : 1.0322 = 0.0948 + 0.9274 + 0.0101, time: 39.386010]
2023-05-25 10:49:12.919: epoch 46:	0.08516677  	0.15552190  	0.15581623  
2023-05-25 10:49:52.276: [iter 47 : loss : 1.0292 = 0.0920 + 0.9269 + 0.0103, time: 39.350243]
2023-05-25 10:49:52.675: epoch 47:	0.08483368  	0.15471280  	0.15510045  
2023-05-25 10:50:32.299: [iter 48 : loss : 1.0265 = 0.0895 + 0.9266 + 0.0105, time: 39.618411]
2023-05-25 10:50:32.699: epoch 48:	0.08466718  	0.15398090  	0.15441784  
2023-05-25 10:51:11.910: [iter 49 : loss : 1.0239 = 0.0870 + 0.9262 + 0.0107, time: 39.203529]
2023-05-25 10:51:12.308: epoch 49:	0.08418382  	0.15296516  	0.15384234  
2023-05-25 10:51:51.682: [iter 50 : loss : 1.0215 = 0.0848 + 0.9258 + 0.0109, time: 39.365098]
2023-05-25 10:51:52.078: epoch 50:	0.08397429  	0.15226167  	0.15331061  
2023-05-25 10:52:31.486: [iter 51 : loss : 1.0195 = 0.0829 + 0.9256 + 0.0111, time: 39.401087]
2023-05-25 10:52:31.884: epoch 51:	0.08380243  	0.15175277  	0.15288480  
2023-05-25 10:53:11.485: [iter 52 : loss : 1.0171 = 0.0806 + 0.9253 + 0.0113, time: 39.595219]
2023-05-25 10:53:11.881: epoch 52:	0.08344790  	0.15074158  	0.15203436  
2023-05-25 10:53:11.881: Early stopping is trigger at epoch: 52
2023-05-25 10:53:11.881: best_result@epoch 27:

2023-05-25 10:53:11.881: 		0.0878      	0.1657      	0.1646      
2023-05-25 11:07:28.186: my pid: 7096
2023-05-25 11:07:28.186: model: model.general_recommender.SGL
2023-05-25 11:07:28.187: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 11:07:28.187: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 11:07:32.966: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 11:08:12.853: [iter 1 : loss : 1.6068 = 0.6931 + 0.9136 + 0.0000, time: 39.886186]
2023-05-25 11:08:13.256: epoch 1:	0.00398042  	0.00875837  	0.00757808  
2023-05-25 11:08:13.256: Find a better model.
2023-05-25 11:08:52.825: [iter 2 : loss : 1.6045 = 0.6931 + 0.9114 + 0.0000, time: 39.562885]
2023-05-25 11:08:53.222: epoch 2:	0.00478080  	0.00989423  	0.00854846  
2023-05-25 11:08:53.222: Find a better model.
2023-05-25 11:09:32.447: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 39.218294]
2023-05-25 11:09:32.852: epoch 3:	0.00566175  	0.01142239  	0.01010403  
2023-05-25 11:09:32.852: Find a better model.
2023-05-25 11:10:12.290: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 39.429572]
2023-05-25 11:10:12.710: epoch 4:	0.00656956  	0.01223412  	0.01126100  
2023-05-25 11:10:12.710: Find a better model.
2023-05-25 11:10:52.206: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 39.488333]
2023-05-25 11:10:52.602: epoch 5:	0.00781047  	0.01443362  	0.01366854  
2023-05-25 11:10:52.602: Find a better model.
2023-05-25 11:11:32.895: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 40.286440]
2023-05-25 11:11:33.290: epoch 6:	0.00919105  	0.01666590  	0.01594254  
2023-05-25 11:11:33.291: Find a better model.
2023-05-25 11:12:13.565: [iter 7 : loss : 1.6035 = 0.6927 + 0.9107 + 0.0000, time: 40.266873]
2023-05-25 11:12:13.967: epoch 7:	0.01029228  	0.01901593  	0.01797655  
2023-05-25 11:12:13.967: Find a better model.
2023-05-25 11:12:54.236: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 40.263050]
2023-05-25 11:12:54.643: epoch 8:	0.01155467  	0.02138171  	0.02008740  
2023-05-25 11:12:54.643: Find a better model.
2023-05-25 11:13:34.960: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 40.311264]
2023-05-25 11:13:35.355: epoch 9:	0.01369268  	0.02535817  	0.02407111  
2023-05-25 11:13:35.355: Find a better model.
2023-05-25 11:14:15.985: [iter 10 : loss : 1.6028 = 0.6921 + 0.9107 + 0.0000, time: 40.622582]
2023-05-25 11:14:16.381: epoch 10:	0.01538483  	0.02981582  	0.02765272  
2023-05-25 11:14:16.381: Find a better model.
2023-05-25 11:14:56.715: [iter 11 : loss : 1.6024 = 0.6918 + 0.9106 + 0.0000, time: 40.328576]
2023-05-25 11:14:57.110: epoch 11:	0.01798484  	0.03553385  	0.03329113  
2023-05-25 11:14:57.110: Find a better model.
2023-05-25 11:15:37.306: [iter 12 : loss : 1.6019 = 0.6912 + 0.9107 + 0.0000, time: 40.189027]
2023-05-25 11:15:37.724: epoch 12:	0.02166459  	0.04364477  	0.04078729  
2023-05-25 11:15:37.724: Find a better model.
2023-05-25 11:16:17.931: [iter 13 : loss : 1.6010 = 0.6902 + 0.9108 + 0.0000, time: 40.199230]
2023-05-25 11:16:18.327: epoch 13:	0.02574720  	0.05343587  	0.04983761  
2023-05-25 11:16:18.327: Find a better model.
2023-05-25 11:16:58.743: [iter 14 : loss : 1.5995 = 0.6884 + 0.9110 + 0.0000, time: 40.409473]
2023-05-25 11:16:59.138: epoch 14:	0.03161817  	0.06700290  	0.06228782  
2023-05-25 11:16:59.138: Find a better model.
2023-05-25 11:17:39.475: [iter 15 : loss : 1.5963 = 0.6848 + 0.9114 + 0.0001, time: 40.330637]
2023-05-25 11:17:39.873: epoch 15:	0.04000290  	0.08484613  	0.07986715  
2023-05-25 11:17:39.873: Find a better model.
2023-05-25 11:18:20.119: [iter 16 : loss : 1.5894 = 0.6771 + 0.9122 + 0.0001, time: 40.240542]
2023-05-25 11:18:20.513: epoch 16:	0.05071384  	0.10450186  	0.10043623  
2023-05-25 11:18:20.514: Find a better model.
2023-05-25 11:19:00.486: [iter 17 : loss : 1.5743 = 0.6603 + 0.9137 + 0.0002, time: 39.966451]
2023-05-25 11:19:00.883: epoch 17:	0.06299278  	0.12535365  	0.12285214  
2023-05-25 11:19:00.883: Find a better model.
2023-05-25 11:19:41.221: [iter 18 : loss : 1.5447 = 0.6275 + 0.9168 + 0.0004, time: 40.330613]
2023-05-25 11:19:41.611: epoch 18:	0.07257029  	0.13974388  	0.13932644  
2023-05-25 11:19:41.611: Find a better model.
2023-05-25 11:20:21.988: [iter 19 : loss : 1.4985 = 0.5761 + 0.9217 + 0.0007, time: 40.369418]
2023-05-25 11:20:22.377: epoch 19:	0.07846812  	0.14984381  	0.14919010  
2023-05-25 11:20:22.377: Find a better model.
2023-05-25 11:21:02.912: [iter 20 : loss : 1.4432 = 0.5145 + 0.9276 + 0.0012, time: 40.529158]
2023-05-25 11:21:03.300: epoch 20:	0.08180918  	0.15535910  	0.15494141  
2023-05-25 11:21:03.300: Find a better model.
2023-05-25 11:21:43.630: [iter 21 : loss : 1.3878 = 0.4533 + 0.9329 + 0.0016, time: 40.324351]
2023-05-25 11:21:44.020: epoch 21:	0.08383426  	0.15848005  	0.15834059  
2023-05-25 11:21:44.020: Find a better model.
2023-05-25 11:22:24.273: [iter 22 : loss : 1.3379 = 0.3991 + 0.9367 + 0.0021, time: 40.247045]
2023-05-25 11:22:24.673: epoch 22:	0.08524694  	0.16114274  	0.16070868  
2023-05-25 11:22:24.674: Find a better model.
2023-05-25 11:23:05.167: [iter 23 : loss : 1.2958 = 0.3543 + 0.9389 + 0.0026, time: 40.477621]
2023-05-25 11:23:05.556: epoch 23:	0.08626226  	0.16250634  	0.16207728  
2023-05-25 11:23:05.557: Find a better model.
2023-05-25 11:23:46.093: [iter 24 : loss : 1.2602 = 0.3171 + 0.9400 + 0.0031, time: 40.531290]
2023-05-25 11:23:46.483: epoch 24:	0.08686389  	0.16361594  	0.16295898  
2023-05-25 11:23:46.483: Find a better model.
2023-05-25 11:24:26.992: [iter 25 : loss : 1.2309 = 0.2873 + 0.9400 + 0.0036, time: 40.503289]
2023-05-25 11:24:27.382: epoch 25:	0.08737423  	0.16467546  	0.16376093  
2023-05-25 11:24:27.382: Find a better model.
2023-05-25 11:25:07.961: [iter 26 : loss : 1.2053 = 0.2615 + 0.9397 + 0.0040, time: 40.571047]
2023-05-25 11:25:08.351: epoch 26:	0.08736883  	0.16462207  	0.16373025  
2023-05-25 11:25:48.461: [iter 27 : loss : 1.1835 = 0.2400 + 0.9391 + 0.0044, time: 40.103317]
2023-05-25 11:25:48.856: epoch 27:	0.08762138  	0.16511986  	0.16384675  
2023-05-25 11:25:48.856: Find a better model.
2023-05-25 11:26:29.613: [iter 28 : loss : 1.1650 = 0.2218 + 0.9383 + 0.0048, time: 40.751208]
2023-05-25 11:26:30.007: epoch 28:	0.08740114  	0.16474308  	0.16333057  
2023-05-25 11:27:10.465: [iter 29 : loss : 1.1493 = 0.2068 + 0.9373 + 0.0052, time: 40.450094]
2023-05-25 11:27:10.861: epoch 29:	0.08717013  	0.16472203  	0.16309883  
2023-05-25 11:27:51.341: [iter 30 : loss : 1.1348 = 0.1929 + 0.9363 + 0.0056, time: 40.474277]
2023-05-25 11:27:51.751: epoch 30:	0.08707350  	0.16460197  	0.16276965  
2023-05-25 11:28:32.200: [iter 31 : loss : 1.1218 = 0.1805 + 0.9354 + 0.0060, time: 40.442036]
2023-05-25 11:28:32.592: epoch 31:	0.08697679  	0.16422367  	0.16257487  
2023-05-25 11:29:12.876: [iter 32 : loss : 1.1112 = 0.1705 + 0.9344 + 0.0063, time: 40.276086]
2023-05-25 11:29:13.270: epoch 32:	0.08690162  	0.16385747  	0.16222833  
2023-05-25 11:29:54.063: [iter 33 : loss : 1.1007 = 0.1605 + 0.9335 + 0.0066, time: 40.786140]
2023-05-25 11:29:54.462: epoch 33:	0.08672968  	0.16325124  	0.16167015  
2023-05-25 11:30:35.217: [iter 34 : loss : 1.0927 = 0.1531 + 0.9327 + 0.0070, time: 40.749705]
2023-05-25 11:30:35.617: epoch 34:	0.08666527  	0.16235368  	0.16117038  
2023-05-25 11:31:16.486: [iter 35 : loss : 1.0841 = 0.1449 + 0.9319 + 0.0073, time: 40.861651]
2023-05-25 11:31:16.893: epoch 35:	0.08647731  	0.16164857  	0.16057512  
2023-05-25 11:31:57.516: [iter 36 : loss : 1.0770 = 0.1383 + 0.9311 + 0.0076, time: 40.616051]
2023-05-25 11:31:57.912: epoch 36:	0.08627313  	0.16086890  	0.15994087  
2023-05-25 11:32:38.370: [iter 37 : loss : 1.0700 = 0.1318 + 0.9303 + 0.0079, time: 40.452189]
2023-05-25 11:32:38.779: epoch 37:	0.08617111  	0.16018152  	0.15939787  
2023-05-25 11:33:19.596: [iter 38 : loss : 1.0644 = 0.1266 + 0.9296 + 0.0082, time: 40.809512]
2023-05-25 11:33:20.009: epoch 38:	0.08596165  	0.15948565  	0.15886727  
2023-05-25 11:34:01.462: [iter 39 : loss : 1.0590 = 0.1216 + 0.9289 + 0.0084, time: 41.445842]
2023-05-25 11:34:01.862: epoch 39:	0.08590253  	0.15913905  	0.15846086  
2023-05-25 11:34:43.043: [iter 40 : loss : 1.0541 = 0.1171 + 0.9284 + 0.0087, time: 41.174647]
2023-05-25 11:34:43.442: epoch 40:	0.08549426  	0.15812995  	0.15766363  
2023-05-25 11:35:24.384: [iter 41 : loss : 1.0491 = 0.1124 + 0.9277 + 0.0089, time: 40.935334]
2023-05-25 11:35:24.796: epoch 41:	0.08544591  	0.15743069  	0.15708806  
2023-05-25 11:36:05.638: [iter 42 : loss : 1.0451 = 0.1087 + 0.9272 + 0.0092, time: 40.836142]
2023-05-25 11:36:06.040: epoch 42:	0.08506457  	0.15659331  	0.15631355  
2023-05-25 11:36:46.867: [iter 43 : loss : 1.0408 = 0.1047 + 0.9267 + 0.0094, time: 40.821697]
2023-05-25 11:36:47.269: epoch 43:	0.08485506  	0.15569182  	0.15579225  
2023-05-25 11:37:28.203: [iter 44 : loss : 1.0371 = 0.1012 + 0.9263 + 0.0097, time: 40.924828]
2023-05-25 11:37:28.600: epoch 44:	0.08460261  	0.15483630  	0.15521742  
2023-05-25 11:38:09.511: [iter 45 : loss : 1.0342 = 0.0985 + 0.9258 + 0.0099, time: 40.905426]
2023-05-25 11:38:09.905: epoch 45:	0.08427492  	0.15409511  	0.15448941  
2023-05-25 11:38:50.812: [iter 46 : loss : 1.0306 = 0.0952 + 0.9254 + 0.0101, time: 40.898623]
2023-05-25 11:38:51.208: epoch 46:	0.08410300  	0.15337919  	0.15382430  
2023-05-25 11:39:32.135: [iter 47 : loss : 1.0277 = 0.0924 + 0.9249 + 0.0103, time: 40.921148]
2023-05-25 11:39:32.532: epoch 47:	0.08390433  	0.15297189  	0.15343043  
2023-05-25 11:40:13.558: [iter 48 : loss : 1.0248 = 0.0897 + 0.9245 + 0.0105, time: 41.019636]
2023-05-25 11:40:13.961: epoch 48:	0.08371098  	0.15220562  	0.15276714  
2023-05-25 11:40:54.820: [iter 49 : loss : 1.0225 = 0.0876 + 0.9242 + 0.0107, time: 40.852123]
2023-05-25 11:40:55.220: epoch 49:	0.08347463  	0.15138666  	0.15208972  
2023-05-25 11:41:36.317: [iter 50 : loss : 1.0201 = 0.0854 + 0.9238 + 0.0109, time: 41.091570]
2023-05-25 11:41:36.735: epoch 50:	0.08331886  	0.15050463  	0.15142742  
2023-05-25 11:42:17.799: [iter 51 : loss : 1.0181 = 0.0834 + 0.9236 + 0.0111, time: 41.056025]
2023-05-25 11:42:18.197: epoch 51:	0.08291057  	0.14977992  	0.15089253  
2023-05-25 11:42:59.275: [iter 52 : loss : 1.0156 = 0.0810 + 0.9233 + 0.0113, time: 41.070537]
2023-05-25 11:42:59.697: epoch 52:	0.08284073  	0.14934321  	0.15065013  
2023-05-25 11:42:59.697: Early stopping is trigger at epoch: 52
2023-05-25 11:42:59.697: best_result@epoch 27:

2023-05-25 11:42:59.697: 		0.0876      	0.1651      	0.1638      
2023-05-25 14:34:00.584: my pid: 15392
2023-05-25 14:34:00.584: model: model.general_recommender.SGL
2023-05-25 14:34:00.584: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 14:34:00.584: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 14:34:05.339: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 14:34:42.621: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 37.281549]
2023-05-25 14:34:43.031: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-05-25 14:34:43.031: Find a better model.
2023-05-25 14:35:20.362: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.325088]
2023-05-25 14:35:20.790: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-05-25 14:35:20.791: Find a better model.
2023-05-25 14:35:58.318: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 37.519523]
2023-05-25 14:35:58.751: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-05-25 14:35:58.751: Find a better model.
2023-05-25 14:36:36.075: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 37.317116]
2023-05-25 14:36:36.496: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-05-25 14:36:36.496: Find a better model.
2023-05-25 14:37:13.866: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.363438]
2023-05-25 14:37:14.270: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-05-25 14:37:14.270: Find a better model.
2023-05-25 14:37:51.424: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.147439]
2023-05-25 14:37:51.841: epoch 6:	0.00772451  	0.01568698  	0.01374723  
2023-05-25 14:37:51.841: Find a better model.
2023-05-25 14:38:29.134: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 37.287122]
2023-05-25 14:38:29.543: epoch 7:	0.00857865  	0.01634379  	0.01484605  
2023-05-25 14:38:29.543: Find a better model.
2023-05-25 14:39:06.970: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 37.420826]
2023-05-25 14:39:07.379: epoch 8:	0.00980345  	0.01916631  	0.01706018  
2023-05-25 14:39:07.380: Find a better model.
2023-05-25 14:39:44.633: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 37.248825]
2023-05-25 14:39:45.039: epoch 9:	0.01139889  	0.02280196  	0.02033713  
2023-05-25 14:39:45.039: Find a better model.
2023-05-25 14:40:22.294: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 37.247361]
2023-05-25 14:40:22.726: epoch 10:	0.01327366  	0.02668142  	0.02470750  
2023-05-25 14:40:22.727: Find a better model.
2023-05-25 14:40:59.988: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 37.255734]
2023-05-25 14:41:00.389: epoch 11:	0.01542245  	0.03111634  	0.02916739  
2023-05-25 14:41:00.389: Find a better model.
2023-05-25 14:41:37.593: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 37.198500]
2023-05-25 14:41:38.004: epoch 12:	0.01837162  	0.03774254  	0.03553504  
2023-05-25 14:41:38.004: Find a better model.
2023-05-25 14:42:15.373: [iter 13 : loss : 1.6047 = 0.6911 + 0.9135 + 0.0000, time: 37.362114]
2023-05-25 14:42:15.790: epoch 13:	0.02247574  	0.04678126  	0.04394830  
2023-05-25 14:42:15.790: Find a better model.
2023-05-25 14:42:53.273: [iter 14 : loss : 1.6041 = 0.6901 + 0.9139 + 0.0000, time: 37.475496]
2023-05-25 14:42:53.683: epoch 14:	0.02782069  	0.05873166  	0.05544734  
2023-05-25 14:42:53.683: Find a better model.
2023-05-25 14:43:31.139: [iter 15 : loss : 1.6027 = 0.6884 + 0.9143 + 0.0001, time: 37.441111]
2023-05-25 14:43:31.545: epoch 15:	0.03541569  	0.07228198  	0.07093161  
2023-05-25 14:43:31.545: Find a better model.
2023-05-25 14:44:08.956: [iter 16 : loss : 1.6001 = 0.6849 + 0.9151 + 0.0001, time: 37.404107]
2023-05-25 14:44:09.359: epoch 16:	0.04557317  	0.09196179  	0.09038765  
2023-05-25 14:44:09.359: Find a better model.
2023-05-25 14:44:46.708: [iter 17 : loss : 1.5938 = 0.6774 + 0.9162 + 0.0001, time: 37.343298]
2023-05-25 14:44:47.111: epoch 17:	0.05755161  	0.11398961  	0.11317725  
2023-05-25 14:44:47.111: Find a better model.
2023-05-25 14:45:24.543: [iter 18 : loss : 1.5796 = 0.6609 + 0.9185 + 0.0002, time: 37.425464]
2023-05-25 14:45:24.954: epoch 18:	0.06847719  	0.13218176  	0.13287163  
2023-05-25 14:45:24.954: Find a better model.
2023-05-25 14:46:02.503: [iter 19 : loss : 1.5506 = 0.6281 + 0.9221 + 0.0004, time: 37.543222]
2023-05-25 14:46:02.907: epoch 19:	0.07634110  	0.14508772  	0.14614482  
2023-05-25 14:46:02.907: Find a better model.
2023-05-25 14:46:40.480: [iter 20 : loss : 1.5053 = 0.5770 + 0.9275 + 0.0008, time: 37.567518]
2023-05-25 14:46:40.886: epoch 20:	0.08077267  	0.15228282  	0.15366140  
2023-05-25 14:46:40.886: Find a better model.
2023-05-25 14:47:19.176: [iter 21 : loss : 1.4495 = 0.5147 + 0.9336 + 0.0012, time: 38.283182]
2023-05-25 14:47:19.574: epoch 21:	0.08282457  	0.15667821  	0.15744640  
2023-05-25 14:47:19.574: Find a better model.
2023-05-25 14:47:58.005: [iter 22 : loss : 1.3930 = 0.4523 + 0.9390 + 0.0017, time: 38.424032]
2023-05-25 14:47:58.404: epoch 22:	0.08436086  	0.15958126  	0.16010210  
2023-05-25 14:47:58.405: Find a better model.
2023-05-25 14:48:36.569: [iter 23 : loss : 1.3428 = 0.3978 + 0.9428 + 0.0022, time: 38.158252]
2023-05-25 14:48:36.977: epoch 23:	0.08560167  	0.16231331  	0.16231792  
2023-05-25 14:48:36.978: Find a better model.
2023-05-25 14:49:15.225: [iter 24 : loss : 1.2996 = 0.3519 + 0.9450 + 0.0027, time: 38.240422]
2023-05-25 14:49:15.625: epoch 24:	0.08625159  	0.16390799  	0.16349564  
2023-05-25 14:49:15.625: Find a better model.
2023-05-25 14:49:53.972: [iter 25 : loss : 1.2638 = 0.3150 + 0.9456 + 0.0032, time: 38.340659]
2023-05-25 14:49:54.371: epoch 25:	0.08671892  	0.16451128  	0.16399613  
2023-05-25 14:49:54.371: Find a better model.
2023-05-25 14:50:32.981: [iter 26 : loss : 1.2331 = 0.2838 + 0.9457 + 0.0036, time: 38.603188]
2023-05-25 14:50:33.381: epoch 26:	0.08733132  	0.16585940  	0.16462938  
2023-05-25 14:50:33.382: Find a better model.
2023-05-25 14:51:11.606: [iter 27 : loss : 1.2073 = 0.2580 + 0.9452 + 0.0041, time: 38.217813]
2023-05-25 14:51:11.996: epoch 27:	0.08755149  	0.16641667  	0.16492908  
2023-05-25 14:51:11.996: Find a better model.
2023-05-25 14:51:50.680: [iter 28 : loss : 1.1857 = 0.2367 + 0.9445 + 0.0045, time: 38.678028]
2023-05-25 14:51:51.080: epoch 28:	0.08783083  	0.16697922  	0.16497229  
2023-05-25 14:51:51.080: Find a better model.
2023-05-25 14:52:29.454: [iter 29 : loss : 1.1671 = 0.2188 + 0.9434 + 0.0049, time: 38.366379]
2023-05-25 14:52:29.859: epoch 29:	0.08755157  	0.16675110  	0.16460028  
2023-05-25 14:53:08.263: [iter 30 : loss : 1.1506 = 0.2029 + 0.9423 + 0.0053, time: 38.397093]
2023-05-25 14:53:08.662: epoch 30:	0.08756234  	0.16678968  	0.16455279  
2023-05-25 14:53:47.065: [iter 31 : loss : 1.1359 = 0.1889 + 0.9414 + 0.0057, time: 38.396103]
2023-05-25 14:53:47.465: epoch 31:	0.08766977  	0.16704877  	0.16449492  
2023-05-25 14:53:47.466: Find a better model.
2023-05-25 14:54:25.851: [iter 32 : loss : 1.1240 = 0.1776 + 0.9403 + 0.0060, time: 38.378086]
2023-05-25 14:54:26.251: epoch 32:	0.08763218  	0.16685933  	0.16416091  
2023-05-25 14:55:04.651: [iter 33 : loss : 1.1124 = 0.1666 + 0.9394 + 0.0064, time: 38.392678]
2023-05-25 14:55:05.051: epoch 33:	0.08756778  	0.16652364  	0.16383575  
2023-05-25 14:55:43.474: [iter 34 : loss : 1.1035 = 0.1584 + 0.9384 + 0.0067, time: 38.416198]
2023-05-25 14:55:43.878: epoch 34:	0.08725082  	0.16549608  	0.16306992  
2023-05-25 14:56:22.534: [iter 35 : loss : 1.0940 = 0.1494 + 0.9376 + 0.0070, time: 38.649705]
2023-05-25 14:56:22.932: epoch 35:	0.08705208  	0.16471682  	0.16254221  
2023-05-25 14:57:01.352: [iter 36 : loss : 1.0864 = 0.1423 + 0.9367 + 0.0073, time: 38.413425]
2023-05-25 14:57:01.772: epoch 36:	0.08693929  	0.16392583  	0.16189420  
2023-05-25 14:57:40.180: [iter 37 : loss : 1.0788 = 0.1353 + 0.9359 + 0.0076, time: 38.402195]
2023-05-25 14:57:40.582: epoch 37:	0.08679423  	0.16328719  	0.16130984  
2023-05-25 14:58:19.087: [iter 38 : loss : 1.0724 = 0.1294 + 0.9351 + 0.0079, time: 38.497856]
2023-05-25 14:58:19.488: epoch 38:	0.08643430  	0.16251777  	0.16072215  
2023-05-25 14:58:58.204: [iter 39 : loss : 1.0668 = 0.1242 + 0.9344 + 0.0082, time: 38.708574]
2023-05-25 14:58:58.606: epoch 39:	0.08641821  	0.16165797  	0.16003652  
2023-05-25 14:59:37.678: [iter 40 : loss : 1.0616 = 0.1194 + 0.9337 + 0.0085, time: 39.065491]
2023-05-25 14:59:38.077: epoch 40:	0.08599386  	0.16045922  	0.15919384  
2023-05-25 15:00:16.837: [iter 41 : loss : 1.0561 = 0.1143 + 0.9331 + 0.0087, time: 38.752957]
2023-05-25 15:00:17.237: epoch 41:	0.08595086  	0.15998128  	0.15874648  
2023-05-25 15:00:56.113: [iter 42 : loss : 1.0518 = 0.1103 + 0.9325 + 0.0090, time: 38.868725]
2023-05-25 15:00:56.522: epoch 42:	0.08583807  	0.15934148  	0.15806232  
2023-05-25 15:01:35.265: [iter 43 : loss : 1.0472 = 0.1060 + 0.9320 + 0.0092, time: 38.737312]
2023-05-25 15:01:35.673: epoch 43:	0.08574135  	0.15886045  	0.15768179  
2023-05-25 15:02:15.236: [iter 44 : loss : 1.0435 = 0.1025 + 0.9315 + 0.0095, time: 39.548875]
2023-05-25 15:02:15.644: epoch 44:	0.08550501  	0.15799238  	0.15691499  
2023-05-25 15:02:54.926: [iter 45 : loss : 1.0404 = 0.0997 + 0.9310 + 0.0097, time: 39.273620]
2023-05-25 15:02:55.329: epoch 45:	0.08529019  	0.15760136  	0.15638480  
2023-05-25 15:03:34.325: [iter 46 : loss : 1.0366 = 0.0962 + 0.9305 + 0.0099, time: 38.990631]
2023-05-25 15:03:34.747: epoch 46:	0.08524184  	0.15687937  	0.15585768  
2023-05-25 15:04:13.897: [iter 47 : loss : 1.0335 = 0.0934 + 0.9300 + 0.0102, time: 39.142720]
2023-05-25 15:04:14.302: epoch 47:	0.08495714  	0.15608828  	0.15521236  
2023-05-25 15:04:53.573: [iter 48 : loss : 1.0305 = 0.0905 + 0.9296 + 0.0104, time: 39.264112]
2023-05-25 15:04:53.970: epoch 48:	0.08471544  	0.15511541  	0.15465540  
2023-05-25 15:05:33.047: [iter 49 : loss : 1.0279 = 0.0881 + 0.9293 + 0.0106, time: 39.069637]
2023-05-25 15:05:33.446: epoch 49:	0.08454348  	0.15431665  	0.15421849  
2023-05-25 15:06:12.608: [iter 50 : loss : 1.0255 = 0.0859 + 0.9288 + 0.0108, time: 39.156086]
2023-05-25 15:06:13.016: epoch 50:	0.08426415  	0.15370518  	0.15352915  
2023-05-25 15:06:52.064: [iter 51 : loss : 1.0234 = 0.0838 + 0.9286 + 0.0110, time: 39.040786]
2023-05-25 15:06:52.465: epoch 51:	0.08390427  	0.15305459  	0.15314357  
2023-05-25 15:07:31.983: [iter 52 : loss : 1.0209 = 0.0814 + 0.9283 + 0.0112, time: 39.512260]
2023-05-25 15:07:32.385: epoch 52:	0.08371093  	0.15239598  	0.15242235  
2023-05-25 15:08:12.020: [iter 53 : loss : 1.0187 = 0.0795 + 0.9278 + 0.0114, time: 39.628528]
2023-05-25 15:08:12.424: epoch 53:	0.08349600  	0.15213522  	0.15205227  
2023-05-25 15:08:51.379: [iter 54 : loss : 1.0162 = 0.0770 + 0.9276 + 0.0115, time: 38.949238]
2023-05-25 15:08:51.794: epoch 54:	0.08323818  	0.15117866  	0.15142839  
2023-05-25 15:09:31.170: [iter 55 : loss : 1.0150 = 0.0760 + 0.9273 + 0.0117, time: 39.368066]
2023-05-25 15:09:31.570: epoch 55:	0.08305024  	0.15043794  	0.15095848  
2023-05-25 15:10:10.871: [iter 56 : loss : 1.0130 = 0.0740 + 0.9271 + 0.0119, time: 39.294037]
2023-05-25 15:10:11.275: epoch 56:	0.08274940  	0.14975961  	0.15041235  
2023-05-25 15:10:11.275: Early stopping is trigger at epoch: 56
2023-05-25 15:10:11.275: best_result@epoch 31:

2023-05-25 15:10:11.275: 		0.0877      	0.1670      	0.1645      
2023-05-25 15:13:51.806: my pid: 14416
2023-05-25 15:13:51.806: model: model.general_recommender.SGL
2023-05-25 15:13:51.806: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 15:13:51.806: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 15:13:56.624: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 15:14:31.415: [iter 1 : loss : 1.6091 = 0.6931 + 0.9160 + 0.0000, time: 34.788856]
2023-05-25 15:14:31.821: epoch 1:	0.00296518  	0.00735567  	0.00575102  
2023-05-25 15:14:31.822: Find a better model.
2023-05-25 15:15:06.530: [iter 2 : loss : 1.6075 = 0.6931 + 0.9144 + 0.0000, time: 34.702749]
2023-05-25 15:15:06.930: epoch 2:	0.00394282  	0.00915322  	0.00758516  
2023-05-25 15:15:06.931: Find a better model.
2023-05-25 15:15:41.628: [iter 3 : loss : 1.6076 = 0.6930 + 0.9145 + 0.0000, time: 34.689698]
2023-05-25 15:15:42.034: epoch 3:	0.00465725  	0.00979082  	0.00850732  
2023-05-25 15:15:42.034: Find a better model.
2023-05-25 15:16:16.851: [iter 4 : loss : 1.6078 = 0.6930 + 0.9148 + 0.0000, time: 34.810399]
2023-05-25 15:16:17.254: epoch 4:	0.00484526  	0.01059586  	0.00875067  
2023-05-25 15:16:17.254: Find a better model.
2023-05-25 15:16:51.973: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 34.713520]
2023-05-25 15:16:52.375: epoch 5:	0.00561878  	0.01157434  	0.01024149  
2023-05-25 15:16:52.375: Find a better model.
2023-05-25 15:17:27.159: [iter 6 : loss : 1.6082 = 0.6928 + 0.9153 + 0.0000, time: 34.776790]
2023-05-25 15:17:27.571: epoch 6:	0.00639767  	0.01219901  	0.01102735  
2023-05-25 15:17:27.571: Find a better model.
2023-05-25 15:18:02.333: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 34.755715]
2023-05-25 15:18:02.732: epoch 7:	0.00711749  	0.01319541  	0.01213542  
2023-05-25 15:18:02.732: Find a better model.
2023-05-25 15:18:37.557: [iter 8 : loss : 1.6084 = 0.6926 + 0.9158 + 0.0000, time: 34.818119]
2023-05-25 15:18:37.960: epoch 8:	0.00789104  	0.01477515  	0.01373267  
2023-05-25 15:18:37.960: Find a better model.
2023-05-25 15:19:12.674: [iter 9 : loss : 1.6087 = 0.6924 + 0.9162 + 0.0000, time: 34.707563]
2023-05-25 15:19:13.079: epoch 9:	0.00973361  	0.01912601  	0.01729940  
2023-05-25 15:19:13.079: Find a better model.
2023-05-25 15:19:48.052: [iter 10 : loss : 1.6087 = 0.6922 + 0.9164 + 0.0000, time: 34.967058]
2023-05-25 15:19:48.481: epoch 10:	0.01112490  	0.02076957  	0.01930229  
2023-05-25 15:19:48.481: Find a better model.
2023-05-25 15:20:23.210: [iter 11 : loss : 1.6086 = 0.6919 + 0.9166 + 0.0000, time: 34.722758]
2023-05-25 15:20:23.626: epoch 11:	0.01337036  	0.02605434  	0.02441905  
2023-05-25 15:20:23.626: Find a better model.
2023-05-25 15:20:58.348: [iter 12 : loss : 1.6086 = 0.6915 + 0.9171 + 0.0000, time: 34.715812]
2023-05-25 15:20:58.745: epoch 12:	0.01587366  	0.03110991  	0.02961182  
2023-05-25 15:20:58.745: Find a better model.
2023-05-25 15:21:33.200: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 34.448635]
2023-05-25 15:21:33.614: epoch 13:	0.02033234  	0.04108478  	0.03917249  
2023-05-25 15:21:33.614: Find a better model.
2023-05-25 15:22:08.453: [iter 14 : loss : 1.6081 = 0.6898 + 0.9182 + 0.0000, time: 34.832243]
2023-05-25 15:22:08.857: epoch 14:	0.02634345  	0.05275756  	0.05064335  
2023-05-25 15:22:08.857: Find a better model.
2023-05-25 15:22:43.534: [iter 15 : loss : 1.6071 = 0.6880 + 0.9190 + 0.0001, time: 34.670174]
2023-05-25 15:22:43.937: epoch 15:	0.03443813  	0.06791695  	0.06646837  
2023-05-25 15:22:43.937: Find a better model.
2023-05-25 15:23:18.562: [iter 16 : loss : 1.6049 = 0.6846 + 0.9202 + 0.0001, time: 34.618278]
2023-05-25 15:23:18.964: epoch 16:	0.04544431  	0.08887696  	0.08750679  
2023-05-25 15:23:18.964: Find a better model.
2023-05-25 15:23:53.863: [iter 17 : loss : 1.5996 = 0.6775 + 0.9220 + 0.0001, time: 34.891132]
2023-05-25 15:23:54.264: epoch 17:	0.05752486  	0.10973946  	0.10976725  
2023-05-25 15:23:54.264: Find a better model.
2023-05-25 15:24:29.258: [iter 18 : loss : 1.5877 = 0.6625 + 0.9249 + 0.0002, time: 34.988125]
2023-05-25 15:24:29.666: epoch 18:	0.06893391  	0.12978040  	0.13005438  
2023-05-25 15:24:29.666: Find a better model.
2023-05-25 15:25:04.387: [iter 19 : loss : 1.5625 = 0.6327 + 0.9293 + 0.0004, time: 34.715625]
2023-05-25 15:25:04.788: epoch 19:	0.07609942  	0.14317587  	0.14359459  
2023-05-25 15:25:04.788: Find a better model.
2023-05-25 15:25:39.477: [iter 20 : loss : 1.5213 = 0.5851 + 0.9355 + 0.0007, time: 34.682149]
2023-05-25 15:25:39.874: epoch 20:	0.08019251  	0.15150554  	0.15108821  
2023-05-25 15:25:39.875: Find a better model.
2023-05-25 15:26:15.287: [iter 21 : loss : 1.4682 = 0.5244 + 0.9427 + 0.0012, time: 35.406005]
2023-05-25 15:26:15.689: epoch 21:	0.08264729  	0.15576600  	0.15562542  
2023-05-25 15:26:15.689: Find a better model.
2023-05-25 15:26:51.323: [iter 22 : loss : 1.4127 = 0.4622 + 0.9489 + 0.0016, time: 35.627492]
2023-05-25 15:26:51.718: epoch 22:	0.08439298  	0.15992039  	0.15859278  
2023-05-25 15:26:51.718: Find a better model.
2023-05-25 15:27:27.271: [iter 23 : loss : 1.3621 = 0.4070 + 0.9530 + 0.0021, time: 35.546071]
2023-05-25 15:27:27.666: epoch 23:	0.08552641  	0.16251849  	0.16081533  
2023-05-25 15:27:27.666: Find a better model.
2023-05-25 15:28:03.323: [iter 24 : loss : 1.3182 = 0.3603 + 0.9552 + 0.0026, time: 35.650792]
2023-05-25 15:28:03.719: epoch 24:	0.08617109  	0.16428252  	0.16214126  
2023-05-25 15:28:03.719: Find a better model.
2023-05-25 15:28:39.321: [iter 25 : loss : 1.2813 = 0.3224 + 0.9558 + 0.0031, time: 35.595258]
2023-05-25 15:28:39.712: epoch 25:	0.08685855  	0.16573557  	0.16328262  
2023-05-25 15:28:39.712: Find a better model.
2023-05-25 15:29:15.345: [iter 26 : loss : 1.2496 = 0.2902 + 0.9558 + 0.0036, time: 35.625813]
2023-05-25 15:29:15.751: epoch 26:	0.08726151  	0.16617374  	0.16365050  
2023-05-25 15:29:15.751: Find a better model.
2023-05-25 15:29:51.478: [iter 27 : loss : 1.2229 = 0.2638 + 0.9551 + 0.0040, time: 35.721246]
2023-05-25 15:29:51.877: epoch 27:	0.08777184  	0.16697536  	0.16415492  
2023-05-25 15:29:51.877: Find a better model.
2023-05-25 15:30:27.753: [iter 28 : loss : 1.2002 = 0.2415 + 0.9542 + 0.0045, time: 35.869497]
2023-05-25 15:30:28.147: epoch 28:	0.08797600  	0.16699935  	0.16421641  
2023-05-25 15:30:28.147: Find a better model.
2023-05-25 15:31:03.877: [iter 29 : loss : 1.1808 = 0.2229 + 0.9530 + 0.0049, time: 35.722988]
2023-05-25 15:31:04.272: epoch 29:	0.08795989  	0.16687502  	0.16411862  
2023-05-25 15:31:40.016: [iter 30 : loss : 1.1637 = 0.2067 + 0.9517 + 0.0053, time: 35.737140]
2023-05-25 15:31:40.413: epoch 30:	0.08784173  	0.16659142  	0.16383745  
2023-05-25 15:32:16.402: [iter 31 : loss : 1.1485 = 0.1922 + 0.9507 + 0.0056, time: 35.982569]
2023-05-25 15:32:16.801: epoch 31:	0.08780948  	0.16658801  	0.16366345  
2023-05-25 15:32:52.350: [iter 32 : loss : 1.1361 = 0.1805 + 0.9495 + 0.0060, time: 35.542393]
2023-05-25 15:32:52.748: epoch 32:	0.08784710  	0.16622759  	0.16348830  
2023-05-25 15:33:28.294: [iter 33 : loss : 1.1241 = 0.1693 + 0.9485 + 0.0064, time: 35.540219]
2023-05-25 15:33:28.689: epoch 33:	0.08772888  	0.16601212  	0.16295639  
2023-05-25 15:34:04.299: [iter 34 : loss : 1.1146 = 0.1605 + 0.9474 + 0.0067, time: 35.604281]
2023-05-25 15:34:04.695: epoch 34:	0.08760003  	0.16567387  	0.16263688  
2023-05-25 15:34:40.417: [iter 35 : loss : 1.1047 = 0.1511 + 0.9466 + 0.0070, time: 35.716157]
2023-05-25 15:34:40.817: epoch 35:	0.08742271  	0.16486958  	0.16228497  
2023-05-25 15:35:16.530: [iter 36 : loss : 1.0968 = 0.1439 + 0.9455 + 0.0073, time: 35.705516]
2023-05-25 15:35:16.926: epoch 36:	0.08712728  	0.16366583  	0.16144919  
2023-05-25 15:35:52.564: [iter 37 : loss : 1.0889 = 0.1367 + 0.9446 + 0.0076, time: 35.630549]
2023-05-25 15:35:52.966: epoch 37:	0.08685873  	0.16266462  	0.16092251  
2023-05-25 15:36:28.709: [iter 38 : loss : 1.0825 = 0.1308 + 0.9438 + 0.0079, time: 35.737238]
2023-05-25 15:36:29.111: epoch 38:	0.08663850  	0.16179658  	0.16035910  
2023-05-25 15:37:04.916: [iter 39 : loss : 1.0766 = 0.1254 + 0.9430 + 0.0082, time: 35.797929]
2023-05-25 15:37:05.315: epoch 39:	0.08647738  	0.16086577  	0.15981399  
2023-05-25 15:37:40.882: [iter 40 : loss : 1.0713 = 0.1206 + 0.9422 + 0.0084, time: 35.560397]
2023-05-25 15:37:41.280: epoch 40:	0.08640210  	0.16067128  	0.15948465  
2023-05-25 15:38:17.052: [iter 41 : loss : 1.0660 = 0.1157 + 0.9416 + 0.0087, time: 35.766173]
2023-05-25 15:38:17.473: epoch 41:	0.08628400  	0.16008572  	0.15894945  
2023-05-25 15:38:53.206: [iter 42 : loss : 1.0612 = 0.1112 + 0.9410 + 0.0090, time: 35.722056]
2023-05-25 15:38:53.616: epoch 42:	0.08599395  	0.15915363  	0.15812039  
2023-05-25 15:39:29.269: [iter 43 : loss : 1.0568 = 0.1071 + 0.9404 + 0.0092, time: 35.646392]
2023-05-25 15:39:29.677: epoch 43:	0.08584893  	0.15844457  	0.15749380  
2023-05-25 15:40:05.190: [iter 44 : loss : 1.0528 = 0.1035 + 0.9399 + 0.0094, time: 35.506476]
2023-05-25 15:40:05.598: epoch 44:	0.08574157  	0.15799768  	0.15718929  
2023-05-25 15:40:41.190: [iter 45 : loss : 1.0498 = 0.1007 + 0.9394 + 0.0097, time: 35.585136]
2023-05-25 15:40:41.600: epoch 45:	0.08541388  	0.15725701  	0.15665592  
2023-05-25 15:41:17.234: [iter 46 : loss : 1.0458 = 0.0970 + 0.9388 + 0.0099, time: 35.626594]
2023-05-25 15:41:17.643: epoch 46:	0.08528496  	0.15643360  	0.15601325  
2023-05-25 15:41:53.199: [iter 47 : loss : 1.0427 = 0.0943 + 0.9383 + 0.0101, time: 35.549160]
2023-05-25 15:41:53.608: epoch 47:	0.08508082  	0.15578523  	0.15552714  
2023-05-25 15:42:29.398: [iter 48 : loss : 1.0397 = 0.0915 + 0.9378 + 0.0103, time: 35.783488]
2023-05-25 15:42:29.802: epoch 48:	0.08484987  	0.15488639  	0.15486628  
2023-05-25 15:43:05.549: [iter 49 : loss : 1.0369 = 0.0889 + 0.9375 + 0.0106, time: 35.739625]
2023-05-25 15:43:05.947: epoch 49:	0.08446310  	0.15412974  	0.15421388  
2023-05-25 15:43:41.822: [iter 50 : loss : 1.0344 = 0.0866 + 0.9370 + 0.0108, time: 35.868869]
2023-05-25 15:43:42.223: epoch 50:	0.08426974  	0.15335898  	0.15349928  
2023-05-25 15:44:17.895: [iter 51 : loss : 1.0321 = 0.0843 + 0.9368 + 0.0109, time: 35.665974]
2023-05-25 15:44:18.300: epoch 51:	0.08422680  	0.15306923  	0.15326172  
2023-05-25 15:44:54.300: [iter 52 : loss : 1.0298 = 0.0822 + 0.9364 + 0.0111, time: 35.992972]
2023-05-25 15:44:54.698: epoch 52:	0.08407643  	0.15227461  	0.15244475  
2023-05-25 15:45:30.463: [iter 53 : loss : 1.0278 = 0.0804 + 0.9361 + 0.0113, time: 35.759198]
2023-05-25 15:45:30.862: epoch 53:	0.08378638  	0.15167871  	0.15187347  
2023-05-25 15:45:30.862: Early stopping is trigger at epoch: 53
2023-05-25 15:45:30.862: best_result@epoch 28:

2023-05-25 15:45:30.862: 		0.0880      	0.1670      	0.1642      
2023-05-25 16:09:28.424: my pid: 8112
2023-05-25 16:09:28.424: model: model.general_recommender.SGL
2023-05-25 16:09:28.425: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 16:09:28.425: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 16:09:33.222: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 16:10:09.308: [iter 1 : loss : 1.6087 = 0.6931 + 0.9156 + 0.0000, time: 36.084146]
2023-05-25 16:10:09.712: epoch 1:	0.00337880  	0.00807749  	0.00656585  
2023-05-25 16:10:09.712: Find a better model.
2023-05-25 16:10:45.418: [iter 2 : loss : 1.6066 = 0.6931 + 0.9135 + 0.0000, time: 35.699229]
2023-05-25 16:10:45.828: epoch 2:	0.00420603  	0.00948111  	0.00820640  
2023-05-25 16:10:45.828: Find a better model.
2023-05-25 16:11:21.692: [iter 3 : loss : 1.6065 = 0.6930 + 0.9135 + 0.0000, time: 35.857376]
2023-05-25 16:11:22.106: epoch 3:	0.00493658  	0.01017637  	0.00911207  
2023-05-25 16:11:22.106: Find a better model.
2023-05-25 16:11:58.076: [iter 4 : loss : 1.6066 = 0.6930 + 0.9136 + 0.0000, time: 35.964282]
2023-05-25 16:11:58.482: epoch 4:	0.00538780  	0.01099415  	0.00942833  
2023-05-25 16:11:58.482: Find a better model.
2023-05-25 16:12:34.358: [iter 5 : loss : 1.6066 = 0.6929 + 0.9137 + 0.0000, time: 35.868795]
2023-05-25 16:12:34.760: epoch 5:	0.00636544  	0.01287323  	0.01113765  
2023-05-25 16:12:34.760: Find a better model.
2023-05-25 16:13:10.563: [iter 6 : loss : 1.6067 = 0.6929 + 0.9139 + 0.0000, time: 35.796127]
2023-05-25 16:13:10.983: epoch 6:	0.00684889  	0.01343150  	0.01244461  
2023-05-25 16:13:10.983: Find a better model.
2023-05-25 16:13:46.761: [iter 7 : loss : 1.6068 = 0.6928 + 0.9141 + 0.0000, time: 35.770338]
2023-05-25 16:13:47.158: epoch 7:	0.00780509  	0.01476091  	0.01331042  
2023-05-25 16:13:47.159: Find a better model.
2023-05-25 16:14:23.000: [iter 8 : loss : 1.6068 = 0.6927 + 0.9141 + 0.0000, time: 35.835195]
2023-05-25 16:14:23.404: epoch 8:	0.00943815  	0.01698818  	0.01583513  
2023-05-25 16:14:23.404: Find a better model.
2023-05-25 16:14:59.111: [iter 9 : loss : 1.6069 = 0.6925 + 0.9144 + 0.0000, time: 35.700238]
2023-05-25 16:14:59.514: epoch 9:	0.01121624  	0.02089916  	0.01911004  
2023-05-25 16:14:59.514: Find a better model.
2023-05-25 16:15:35.421: [iter 10 : loss : 1.6069 = 0.6923 + 0.9145 + 0.0000, time: 35.900557]
2023-05-25 16:15:35.822: epoch 10:	0.01245715  	0.02363614  	0.02191894  
2023-05-25 16:15:35.822: Find a better model.
2023-05-25 16:16:11.700: [iter 11 : loss : 1.6067 = 0.6920 + 0.9147 + 0.0000, time: 35.871124]
2023-05-25 16:16:12.108: epoch 11:	0.01471334  	0.02865947  	0.02756227  
2023-05-25 16:16:12.108: Find a better model.
2023-05-25 16:16:48.108: [iter 12 : loss : 1.6066 = 0.6916 + 0.9150 + 0.0000, time: 35.994631]
2023-05-25 16:16:48.507: epoch 12:	0.01783442  	0.03515960  	0.03334959  
2023-05-25 16:16:48.508: Find a better model.
2023-05-25 16:17:24.525: [iter 13 : loss : 1.6063 = 0.6909 + 0.9154 + 0.0000, time: 36.010493]
2023-05-25 16:17:24.951: epoch 13:	0.02180425  	0.04406047  	0.04224520  
2023-05-25 16:17:24.951: Find a better model.
2023-05-25 16:18:00.751: [iter 14 : loss : 1.6058 = 0.6899 + 0.9158 + 0.0000, time: 35.794226]
2023-05-25 16:18:01.155: epoch 14:	0.02780993  	0.05583351  	0.05436920  
2023-05-25 16:18:01.155: Find a better model.
2023-05-25 16:18:37.145: [iter 15 : loss : 1.6045 = 0.6880 + 0.9165 + 0.0001, time: 35.984087]
2023-05-25 16:18:37.550: epoch 15:	0.03626444  	0.07159533  	0.07095426  
2023-05-25 16:18:37.550: Find a better model.
2023-05-25 16:19:13.732: [iter 16 : loss : 1.6019 = 0.6843 + 0.9175 + 0.0001, time: 36.175033]
2023-05-25 16:19:14.132: epoch 16:	0.04700745  	0.09165454  	0.09044846  
2023-05-25 16:19:14.132: Find a better model.
2023-05-25 16:19:49.718: [iter 17 : loss : 1.5956 = 0.6765 + 0.9190 + 0.0001, time: 35.578521]
2023-05-25 16:19:50.117: epoch 17:	0.05883551  	0.11261404  	0.11300911  
2023-05-25 16:19:50.117: Find a better model.
2023-05-25 16:20:26.002: [iter 18 : loss : 1.5815 = 0.6596 + 0.9217 + 0.0003, time: 35.878878]
2023-05-25 16:20:26.399: epoch 18:	0.06971812  	0.13111809  	0.13292237  
2023-05-25 16:20:26.399: Find a better model.
2023-05-25 16:21:02.196: [iter 19 : loss : 1.5528 = 0.6265 + 0.9258 + 0.0005, time: 35.791326]
2023-05-25 16:21:02.590: epoch 19:	0.07663126  	0.14289980  	0.14530519  
2023-05-25 16:21:02.591: Find a better model.
2023-05-25 16:21:38.571: [iter 20 : loss : 1.5082 = 0.5758 + 0.9316 + 0.0008, time: 35.975159]
2023-05-25 16:21:38.986: epoch 20:	0.08061690  	0.15009645  	0.15222371  
2023-05-25 16:21:38.987: Find a better model.
2023-05-25 16:22:15.375: [iter 21 : loss : 1.4533 = 0.5139 + 0.9382 + 0.0012, time: 36.380459]
2023-05-25 16:22:15.770: epoch 21:	0.08314147  	0.15583636  	0.15640800  
2023-05-25 16:22:15.770: Find a better model.
2023-05-25 16:22:52.502: [iter 22 : loss : 1.3974 = 0.4520 + 0.9437 + 0.0017, time: 36.726427]
2023-05-25 16:22:52.915: epoch 22:	0.08439837  	0.15881126  	0.15873271  
2023-05-25 16:22:52.915: Find a better model.
2023-05-25 16:23:29.535: [iter 23 : loss : 1.3477 = 0.3979 + 0.9476 + 0.0022, time: 36.603821]
2023-05-25 16:23:29.953: epoch 23:	0.08585941  	0.16211861  	0.16133769  
2023-05-25 16:23:29.953: Find a better model.
2023-05-25 16:24:06.562: [iter 24 : loss : 1.3046 = 0.3522 + 0.9497 + 0.0027, time: 36.603559]
2023-05-25 16:24:06.977: epoch 24:	0.08650944  	0.16344832  	0.16259310  
2023-05-25 16:24:06.977: Find a better model.
2023-05-25 16:24:43.589: [iter 25 : loss : 1.2688 = 0.3154 + 0.9502 + 0.0032, time: 36.605616]
2023-05-25 16:24:44.002: epoch 25:	0.08701435  	0.16418611  	0.16305695  
2023-05-25 16:24:44.002: Find a better model.
2023-05-25 16:25:20.767: [iter 26 : loss : 1.2381 = 0.2843 + 0.9501 + 0.0037, time: 36.757605]
2023-05-25 16:25:21.170: epoch 26:	0.08727746  	0.16533740  	0.16345564  
2023-05-25 16:25:21.170: Find a better model.
2023-05-25 16:25:57.784: [iter 27 : loss : 1.2123 = 0.2586 + 0.9496 + 0.0041, time: 36.608067]
2023-05-25 16:25:58.176: epoch 27:	0.08760522  	0.16545175  	0.16391329  
2023-05-25 16:25:58.176: Find a better model.
2023-05-25 16:26:34.837: [iter 28 : loss : 1.1905 = 0.2372 + 0.9488 + 0.0045, time: 36.655082]
2023-05-25 16:26:35.240: epoch 28:	0.08768047  	0.16565990  	0.16388902  
2023-05-25 16:26:35.241: Find a better model.
2023-05-25 16:27:12.043: [iter 29 : loss : 1.1718 = 0.2193 + 0.9476 + 0.0049, time: 36.795757]
2023-05-25 16:27:12.437: epoch 29:	0.08783086  	0.16591625  	0.16391511  
2023-05-25 16:27:12.437: Find a better model.
2023-05-25 16:27:49.081: [iter 30 : loss : 1.1552 = 0.2034 + 0.9465 + 0.0053, time: 36.637294]
2023-05-25 16:27:49.479: epoch 30:	0.08795975  	0.16569673  	0.16401905  
2023-05-25 16:28:26.078: [iter 31 : loss : 1.1405 = 0.1894 + 0.9454 + 0.0057, time: 36.593201]
2023-05-25 16:28:26.476: epoch 31:	0.08798122  	0.16601996  	0.16392547  
2023-05-25 16:28:26.477: Find a better model.
2023-05-25 16:29:03.376: [iter 32 : loss : 1.1284 = 0.1779 + 0.9444 + 0.0061, time: 36.892936]
2023-05-25 16:29:03.775: epoch 32:	0.08793292  	0.16553685  	0.16364829  
2023-05-25 16:29:40.611: [iter 33 : loss : 1.1168 = 0.1671 + 0.9433 + 0.0064, time: 36.829111]
2023-05-25 16:29:41.020: epoch 33:	0.08777180  	0.16481598  	0.16284554  
2023-05-25 16:30:17.856: [iter 34 : loss : 1.1077 = 0.1587 + 0.9423 + 0.0067, time: 36.830041]
2023-05-25 16:30:18.258: epoch 34:	0.08771810  	0.16459835  	0.16258000  
2023-05-25 16:30:54.946: [iter 35 : loss : 1.0980 = 0.1494 + 0.9415 + 0.0071, time: 36.680702]
2023-05-25 16:30:55.341: epoch 35:	0.08749254  	0.16387172  	0.16212201  
2023-05-25 16:31:31.973: [iter 36 : loss : 1.0904 = 0.1425 + 0.9406 + 0.0073, time: 36.624861]
2023-05-25 16:31:32.371: epoch 36:	0.08723996  	0.16325502  	0.16153520  
2023-05-25 16:32:09.173: [iter 37 : loss : 1.0829 = 0.1356 + 0.9397 + 0.0077, time: 36.796033]
2023-05-25 16:32:09.571: epoch 37:	0.08685316  	0.16220248  	0.16087681  
2023-05-25 16:32:46.406: [iter 38 : loss : 1.0764 = 0.1295 + 0.9389 + 0.0079, time: 36.828344]
2023-05-25 16:32:46.804: epoch 38:	0.08662218  	0.16156760  	0.16018069  
2023-05-25 16:33:23.462: [iter 39 : loss : 1.0707 = 0.1244 + 0.9381 + 0.0082, time: 36.650774]
2023-05-25 16:33:23.862: epoch 39:	0.08623004  	0.16037279  	0.15942633  
2023-05-25 16:34:00.550: [iter 40 : loss : 1.0655 = 0.1196 + 0.9375 + 0.0085, time: 36.680011]
2023-05-25 16:34:00.973: epoch 40:	0.08599907  	0.15950535  	0.15873399  
2023-05-25 16:34:37.530: [iter 41 : loss : 1.0601 = 0.1146 + 0.9368 + 0.0087, time: 36.551438]
2023-05-25 16:34:37.950: epoch 41:	0.08594000  	0.15913373  	0.15817179  
2023-05-25 16:35:14.549: [iter 42 : loss : 1.0558 = 0.1106 + 0.9362 + 0.0090, time: 36.592325]
2023-05-25 16:35:14.968: epoch 42:	0.08570372  	0.15828276  	0.15756899  
2023-05-25 16:35:51.844: [iter 43 : loss : 1.0508 = 0.1059 + 0.9356 + 0.0092, time: 36.869047]
2023-05-25 16:35:52.245: epoch 43:	0.08551032  	0.15763251  	0.15721102  
2023-05-25 16:36:29.233: [iter 44 : loss : 1.0474 = 0.1028 + 0.9351 + 0.0095, time: 36.981066]
2023-05-25 16:36:29.629: epoch 44:	0.08522025  	0.15671973  	0.15671773  
2023-05-25 16:37:06.682: [iter 45 : loss : 1.0445 = 0.1002 + 0.9346 + 0.0097, time: 37.047321]
2023-05-25 16:37:07.088: epoch 45:	0.08501615  	0.15595187  	0.15607432  
2023-05-25 16:37:43.858: [iter 46 : loss : 1.0406 = 0.0965 + 0.9341 + 0.0099, time: 36.764045]
2023-05-25 16:37:44.260: epoch 46:	0.08476905  	0.15512487  	0.15549080  
2023-05-25 16:38:21.005: [iter 47 : loss : 1.0374 = 0.0936 + 0.9336 + 0.0102, time: 36.738130]
2023-05-25 16:38:21.407: epoch 47:	0.08451662  	0.15387717  	0.15457815  
2023-05-25 16:38:58.288: [iter 48 : loss : 1.0342 = 0.0906 + 0.9332 + 0.0104, time: 36.873579]
2023-05-25 16:38:58.685: epoch 48:	0.08432864  	0.15324570  	0.15399957  
2023-05-25 16:39:35.666: [iter 49 : loss : 1.0318 = 0.0884 + 0.9328 + 0.0106, time: 36.975281]
2023-05-25 16:39:36.074: epoch 49:	0.08410307  	0.15260309  	0.15345496  
2023-05-25 16:40:12.941: [iter 50 : loss : 1.0292 = 0.0861 + 0.9324 + 0.0108, time: 36.860193]
2023-05-25 16:40:13.338: epoch 50:	0.08390967  	0.15207648  	0.15285069  
2023-05-25 16:40:50.186: [iter 51 : loss : 1.0269 = 0.0838 + 0.9321 + 0.0110, time: 36.841899]
2023-05-25 16:40:50.587: epoch 51:	0.08375927  	0.15154995  	0.15221310  
2023-05-25 16:41:27.159: [iter 52 : loss : 1.0247 = 0.0818 + 0.9318 + 0.0112, time: 36.566120]
2023-05-25 16:41:27.554: epoch 52:	0.08365720  	0.15116243  	0.15177913  
2023-05-25 16:42:04.397: [iter 53 : loss : 1.0227 = 0.0799 + 0.9314 + 0.0114, time: 36.836688]
2023-05-25 16:42:04.793: epoch 53:	0.08337260  	0.15045854  	0.15116805  
2023-05-25 16:42:41.691: [iter 54 : loss : 1.0203 = 0.0775 + 0.9312 + 0.0115, time: 36.891570]
2023-05-25 16:42:42.095: epoch 54:	0.08305026  	0.14980660  	0.15072928  
2023-05-25 16:43:19.063: [iter 55 : loss : 1.0183 = 0.0757 + 0.9309 + 0.0117, time: 36.960114]
2023-05-25 16:43:19.459: epoch 55:	0.08287299  	0.14925924  	0.15023379  
2023-05-25 16:43:56.368: [iter 56 : loss : 1.0167 = 0.0742 + 0.9306 + 0.0119, time: 36.902224]
2023-05-25 16:43:56.770: epoch 56:	0.08249163  	0.14842400  	0.14963666  
2023-05-25 16:43:56.771: Early stopping is trigger at epoch: 56
2023-05-25 16:43:56.771: best_result@epoch 31:

2023-05-25 16:43:56.771: 		0.0880      	0.1660      	0.1639      
2023-05-25 16:45:52.529: my pid: 11980
2023-05-25 16:45:52.529: model: model.general_recommender.SGL
2023-05-25 16:45:52.529: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 16:45:52.529: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 16:45:57.384: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 16:46:35.559: [iter 1 : loss : 1.6076 = 0.6931 + 0.9144 + 0.0000, time: 38.175642]
2023-05-25 16:46:35.940: epoch 1:	0.00349160  	0.00821223  	0.00674875  
2023-05-25 16:46:35.940: Find a better model.
2023-05-25 16:47:14.117: [iter 2 : loss : 1.6052 = 0.6931 + 0.9121 + 0.0000, time: 38.170099]
2023-05-25 16:47:14.525: epoch 2:	0.00411472  	0.00870434  	0.00735326  
2023-05-25 16:47:14.525: Find a better model.
2023-05-25 16:47:52.726: [iter 3 : loss : 1.6049 = 0.6930 + 0.9118 + 0.0000, time: 38.194700]
2023-05-25 16:47:53.126: epoch 3:	0.00513533  	0.01078933  	0.00928117  
2023-05-25 16:47:53.127: Find a better model.
2023-05-25 16:48:31.240: [iter 4 : loss : 1.6047 = 0.6930 + 0.9118 + 0.0000, time: 38.106607]
2023-05-25 16:48:31.644: epoch 4:	0.00604314  	0.01171840  	0.01048327  
2023-05-25 16:48:31.644: Find a better model.
2023-05-25 16:49:09.874: [iter 5 : loss : 1.6046 = 0.6929 + 0.9117 + 0.0000, time: 38.224345]
2023-05-25 16:49:10.291: epoch 5:	0.00712823  	0.01388803  	0.01248124  
2023-05-25 16:49:10.291: Find a better model.
2023-05-25 16:49:48.676: [iter 6 : loss : 1.6046 = 0.6928 + 0.9117 + 0.0000, time: 38.377663]
2023-05-25 16:49:49.077: epoch 6:	0.00838526  	0.01581074  	0.01438362  
2023-05-25 16:49:49.077: Find a better model.
2023-05-25 16:50:27.670: [iter 7 : loss : 1.6045 = 0.6928 + 0.9118 + 0.0000, time: 38.586736]
2023-05-25 16:50:28.072: epoch 7:	0.00974434  	0.01849503  	0.01673545  
2023-05-25 16:50:28.072: Find a better model.
2023-05-25 16:51:06.496: [iter 8 : loss : 1.6043 = 0.6926 + 0.9117 + 0.0000, time: 38.418149]
2023-05-25 16:51:06.903: epoch 8:	0.01081872  	0.02081267  	0.01917062  
2023-05-25 16:51:06.903: Find a better model.
2023-05-25 16:51:45.232: [iter 9 : loss : 1.6043 = 0.6925 + 0.9119 + 0.0000, time: 38.323009]
2023-05-25 16:51:45.639: epoch 9:	0.01225839  	0.02384916  	0.02214896  
2023-05-25 16:51:45.640: Find a better model.
2023-05-25 16:52:23.828: [iter 10 : loss : 1.6041 = 0.6922 + 0.9119 + 0.0000, time: 38.183073]
2023-05-25 16:52:24.249: epoch 10:	0.01446623  	0.02762912  	0.02612099  
2023-05-25 16:52:24.249: Find a better model.
2023-05-25 16:53:02.620: [iter 11 : loss : 1.6037 = 0.6919 + 0.9118 + 0.0000, time: 38.363696]
2023-05-25 16:53:03.024: epoch 11:	0.01684063  	0.03299030  	0.03131263  
2023-05-25 16:53:03.024: Find a better model.
2023-05-25 16:53:41.194: [iter 12 : loss : 1.6034 = 0.6914 + 0.9120 + 0.0000, time: 38.164122]
2023-05-25 16:53:41.595: epoch 12:	0.02011749  	0.04012677  	0.03871176  
2023-05-25 16:53:41.595: Find a better model.
2023-05-25 16:54:19.848: [iter 13 : loss : 1.6028 = 0.6906 + 0.9122 + 0.0000, time: 38.245196]
2023-05-25 16:54:20.268: epoch 13:	0.02454392  	0.05044828  	0.04768474  
2023-05-25 16:54:20.268: Find a better model.
2023-05-25 16:54:58.807: [iter 14 : loss : 1.6017 = 0.6892 + 0.9125 + 0.0000, time: 38.532957]
2023-05-25 16:54:59.230: epoch 14:	0.03081251  	0.06410605  	0.06152410  
2023-05-25 16:54:59.230: Find a better model.
2023-05-25 16:55:37.548: [iter 15 : loss : 1.5995 = 0.6865 + 0.9129 + 0.0001, time: 38.312322]
2023-05-25 16:55:37.949: epoch 15:	0.03925627  	0.08156533  	0.07889908  
2023-05-25 16:55:37.950: Find a better model.
2023-05-25 16:56:16.548: [iter 16 : loss : 1.5947 = 0.6809 + 0.9137 + 0.0001, time: 38.593115]
2023-05-25 16:56:16.946: epoch 16:	0.04988117  	0.10059800  	0.09907958  
2023-05-25 16:56:16.946: Find a better model.
2023-05-25 16:56:55.359: [iter 17 : loss : 1.5837 = 0.6685 + 0.9150 + 0.0002, time: 38.405982]
2023-05-25 16:56:55.757: epoch 17:	0.06223021  	0.12163071  	0.12117431  
2023-05-25 16:56:55.757: Find a better model.
2023-05-25 16:57:34.202: [iter 18 : loss : 1.5604 = 0.6423 + 0.9178 + 0.0003, time: 38.437646]
2023-05-25 16:57:34.603: epoch 18:	0.07218361  	0.13793622  	0.13815576  
2023-05-25 16:57:34.603: Find a better model.
2023-05-25 16:58:12.995: [iter 19 : loss : 1.5195 = 0.5966 + 0.9223 + 0.0006, time: 38.385273]
2023-05-25 16:58:13.393: epoch 19:	0.07819429  	0.14819573  	0.14893936  
2023-05-25 16:58:13.393: Find a better model.
2023-05-25 16:58:51.726: [iter 20 : loss : 1.4658 = 0.5364 + 0.9284 + 0.0010, time: 38.326034]
2023-05-25 16:58:52.121: epoch 20:	0.08143867  	0.15340436  	0.15408923  
2023-05-25 16:58:52.121: Find a better model.
2023-05-25 16:59:31.601: [iter 21 : loss : 1.4084 = 0.4726 + 0.9343 + 0.0015, time: 39.472466]
2023-05-25 16:59:32.004: epoch 21:	0.08374309  	0.15745270  	0.15784426  
2023-05-25 16:59:32.004: Find a better model.
2023-05-25 17:00:11.579: [iter 22 : loss : 1.3553 = 0.4145 + 0.9388 + 0.0020, time: 39.569251]
2023-05-25 17:00:11.956: epoch 22:	0.08503755  	0.16045943  	0.16005297  
2023-05-25 17:00:11.956: Find a better model.
2023-05-25 17:00:51.704: [iter 23 : loss : 1.3103 = 0.3663 + 0.9415 + 0.0025, time: 39.741679]
2023-05-25 17:00:52.104: epoch 23:	0.08591845  	0.16155922  	0.16133347  
2023-05-25 17:00:52.105: Find a better model.
2023-05-25 17:01:31.701: [iter 24 : loss : 1.2721 = 0.3263 + 0.9428 + 0.0030, time: 39.590386]
2023-05-25 17:01:32.102: epoch 24:	0.08672964  	0.16357461  	0.16245738  
2023-05-25 17:01:32.102: Find a better model.
2023-05-25 17:02:11.088: [iter 25 : loss : 1.2407 = 0.2943 + 0.9429 + 0.0034, time: 38.979678]
2023-05-25 17:02:11.490: epoch 25:	0.08720774  	0.16461658  	0.16304640  
2023-05-25 17:02:11.490: Find a better model.
2023-05-25 17:02:50.817: [iter 26 : loss : 1.2134 = 0.2669 + 0.9426 + 0.0039, time: 39.318940]
2023-05-25 17:02:51.230: epoch 26:	0.08746558  	0.16487329  	0.16350116  
2023-05-25 17:02:51.230: Find a better model.
2023-05-25 17:03:30.646: [iter 27 : loss : 1.1904 = 0.2441 + 0.9419 + 0.0043, time: 39.408962]
2023-05-25 17:03:31.042: epoch 27:	0.08762135  	0.16525298  	0.16361538  
2023-05-25 17:03:31.042: Find a better model.
2023-05-25 17:04:10.668: [iter 28 : loss : 1.1708 = 0.2250 + 0.9411 + 0.0047, time: 39.618971]
2023-05-25 17:04:11.065: epoch 28:	0.08773410  	0.16542417  	0.16364400  
2023-05-25 17:04:11.065: Find a better model.
2023-05-25 17:04:50.365: [iter 29 : loss : 1.1543 = 0.2091 + 0.9400 + 0.0051, time: 39.294517]
2023-05-25 17:04:50.762: epoch 29:	0.08754078  	0.16512103  	0.16347583  
2023-05-25 17:05:30.158: [iter 30 : loss : 1.1393 = 0.1949 + 0.9390 + 0.0055, time: 39.388555]
2023-05-25 17:05:30.558: epoch 30:	0.08762130  	0.16517599  	0.16355582  
2023-05-25 17:06:10.178: [iter 31 : loss : 1.1259 = 0.1820 + 0.9380 + 0.0059, time: 39.614186]
2023-05-25 17:06:10.572: epoch 31:	0.08722378  	0.16445948  	0.16289900  
2023-05-25 17:06:50.108: [iter 32 : loss : 1.1148 = 0.1716 + 0.9370 + 0.0062, time: 39.529090]
2023-05-25 17:06:50.507: epoch 32:	0.08726143  	0.16422260  	0.16259716  
2023-05-25 17:07:30.269: [iter 33 : loss : 1.1042 = 0.1616 + 0.9361 + 0.0066, time: 39.756224]
2023-05-25 17:07:30.668: epoch 33:	0.08723461  	0.16398756  	0.16226885  
2023-05-25 17:08:10.390: [iter 34 : loss : 1.0957 = 0.1537 + 0.9351 + 0.0069, time: 39.714109]
2023-05-25 17:08:10.786: epoch 34:	0.08703589  	0.16354591  	0.16183229  
2023-05-25 17:08:50.125: [iter 35 : loss : 1.0869 = 0.1453 + 0.9344 + 0.0072, time: 39.331292]
2023-05-25 17:08:50.528: epoch 35:	0.08678883  	0.16296437  	0.16128694  
2023-05-25 17:09:30.262: [iter 36 : loss : 1.0795 = 0.1386 + 0.9335 + 0.0075, time: 39.727114]
2023-05-25 17:09:30.658: epoch 36:	0.08665448  	0.16249403  	0.16086385  
2023-05-25 17:10:10.443: [iter 37 : loss : 1.0724 = 0.1319 + 0.9326 + 0.0078, time: 39.779109]
2023-05-25 17:10:10.840: epoch 37:	0.08651482  	0.16203502  	0.16039990  
2023-05-25 17:10:50.490: [iter 38 : loss : 1.0665 = 0.1265 + 0.9319 + 0.0081, time: 39.643386]
2023-05-25 17:10:50.885: epoch 38:	0.08652019  	0.16152628  	0.16004176  
2023-05-25 17:11:30.646: [iter 39 : loss : 1.0611 = 0.1216 + 0.9312 + 0.0084, time: 39.755047]
2023-05-25 17:11:31.044: epoch 39:	0.08631069  	0.16096529  	0.15957692  
2023-05-25 17:12:29.133: my pid: 6584
2023-05-25 17:12:29.133: model: model.general_recommender.SGL
2023-05-25 17:12:29.133: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-05-25 17:12:29.133: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-05-25 17:12:33.827: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-05-25 17:13:13.481: [iter 1 : loss : 1.6068 = 0.6931 + 0.9136 + 0.0000, time: 39.653816]
2023-05-25 17:13:13.882: epoch 1:	0.00398042  	0.00875837  	0.00757808  
2023-05-25 17:13:13.883: Find a better model.
2023-05-25 17:13:53.548: [iter 2 : loss : 1.6045 = 0.6931 + 0.9114 + 0.0000, time: 39.660666]
2023-05-25 17:13:53.950: epoch 2:	0.00478080  	0.00989423  	0.00854846  
2023-05-25 17:13:53.950: Find a better model.
2023-05-25 17:14:33.643: [iter 3 : loss : 1.6041 = 0.6930 + 0.9110 + 0.0000, time: 39.686445]
2023-05-25 17:14:34.048: epoch 3:	0.00566175  	0.01142239  	0.01010403  
2023-05-25 17:14:34.048: Find a better model.
2023-05-25 17:15:13.658: [iter 4 : loss : 1.6039 = 0.6930 + 0.9109 + 0.0000, time: 39.604195]
2023-05-25 17:15:14.058: epoch 4:	0.00656956  	0.01223412  	0.01126100  
2023-05-25 17:15:14.058: Find a better model.
2023-05-25 17:15:53.813: [iter 5 : loss : 1.6037 = 0.6929 + 0.9108 + 0.0000, time: 39.747375]
2023-05-25 17:15:54.226: epoch 5:	0.00781047  	0.01443362  	0.01366854  
2023-05-25 17:15:54.227: Find a better model.
2023-05-25 17:16:33.700: [iter 6 : loss : 1.6036 = 0.6928 + 0.9108 + 0.0000, time: 39.457492]
2023-05-25 17:16:34.100: epoch 6:	0.00903526  	0.01660175  	0.01595149  
2023-05-25 17:16:34.100: Find a better model.
2023-05-25 17:17:13.767: [iter 7 : loss : 1.6035 = 0.6927 + 0.9108 + 0.0000, time: 39.661518]
2023-05-25 17:17:14.169: epoch 7:	0.01024931  	0.01879452  	0.01769141  
2023-05-25 17:17:14.169: Find a better model.
2023-05-25 17:17:53.838: [iter 8 : loss : 1.6032 = 0.6926 + 0.9106 + 0.0000, time: 39.662073]
2023-05-25 17:17:54.262: epoch 8:	0.01145798  	0.02116834  	0.01978062  
2023-05-25 17:17:54.262: Find a better model.
2023-05-25 17:18:33.920: [iter 9 : loss : 1.6032 = 0.6924 + 0.9108 + 0.0000, time: 39.651058]
2023-05-25 17:18:34.336: epoch 9:	0.01377864  	0.02622136  	0.02398405  
2023-05-25 17:18:34.336: Find a better model.
2023-05-25 17:19:14.010: [iter 10 : loss : 1.6029 = 0.6921 + 0.9107 + 0.0000, time: 39.667856]
2023-05-25 17:19:14.412: epoch 10:	0.01519683  	0.02964116  	0.02722461  
2023-05-25 17:19:14.412: Find a better model.
2023-05-25 17:19:53.959: [iter 11 : loss : 1.6024 = 0.6917 + 0.9106 + 0.0000, time: 39.540632]
2023-05-25 17:19:54.372: epoch 11:	0.01746376  	0.03546352  	0.03276338  
2023-05-25 17:19:54.372: Find a better model.
2023-05-25 17:20:34.187: [iter 12 : loss : 1.6019 = 0.6911 + 0.9108 + 0.0000, time: 39.809381]
2023-05-25 17:20:34.589: epoch 12:	0.02043442  	0.04189388  	0.03929387  
2023-05-25 17:20:34.590: Find a better model.
2023-05-25 17:21:14.150: [iter 13 : loss : 1.6011 = 0.6902 + 0.9109 + 0.0000, time: 39.553099]
2023-05-25 17:21:14.554: epoch 13:	0.02497904  	0.05210627  	0.04830518  
2023-05-25 17:21:14.554: Find a better model.
2023-05-25 17:21:54.169: [iter 14 : loss : 1.5995 = 0.6883 + 0.9111 + 0.0000, time: 39.607717]
2023-05-25 17:21:54.571: epoch 14:	0.03057078  	0.06559827  	0.06054273  
2023-05-25 17:21:54.571: Find a better model.
2023-05-25 17:22:34.227: [iter 15 : loss : 1.5963 = 0.6847 + 0.9115 + 0.0001, time: 39.649106]
2023-05-25 17:22:34.624: epoch 15:	0.03916496  	0.08405378  	0.07853647  
2023-05-25 17:22:34.625: Find a better model.
2023-05-25 17:23:14.143: [iter 16 : loss : 1.5894 = 0.6770 + 0.9123 + 0.0001, time: 39.512676]
2023-05-25 17:23:14.551: epoch 16:	0.04953205  	0.10311379  	0.09912878  
2023-05-25 17:23:14.551: Find a better model.
2023-05-25 17:23:54.231: [iter 17 : loss : 1.5742 = 0.6602 + 0.9138 + 0.0002, time: 39.673222]
2023-05-25 17:23:54.628: epoch 17:	0.06203132  	0.12364715  	0.12135680  
2023-05-25 17:23:54.628: Find a better model.
2023-05-25 17:24:34.364: [iter 18 : loss : 1.5448 = 0.6275 + 0.9169 + 0.0004, time: 39.729127]
2023-05-25 17:24:34.764: epoch 18:	0.07196865  	0.13941117  	0.13838565  
2023-05-25 17:24:34.764: Find a better model.
2023-05-25 17:25:14.833: [iter 19 : loss : 1.4990 = 0.5766 + 0.9216 + 0.0007, time: 40.062006]
2023-05-25 17:25:15.255: epoch 19:	0.07775372  	0.14854443  	0.14807352  
2023-05-25 17:25:15.255: Find a better model.
2023-05-25 17:25:55.084: [iter 20 : loss : 1.4441 = 0.5156 + 0.9274 + 0.0012, time: 39.821611]
2023-05-25 17:25:55.474: epoch 20:	0.08106790  	0.15390742  	0.15374638  
2023-05-25 17:25:55.475: Find a better model.
2023-05-25 17:26:36.041: [iter 21 : loss : 1.3888 = 0.4545 + 0.9327 + 0.0016, time: 40.559797]
2023-05-25 17:26:36.437: epoch 21:	0.08366234  	0.15804462  	0.15745567  
2023-05-25 17:26:36.437: Find a better model.
2023-05-25 17:27:16.898: [iter 22 : loss : 1.3389 = 0.4002 + 0.9366 + 0.0021, time: 40.453842]
2023-05-25 17:27:17.308: epoch 22:	0.08487083  	0.16039832  	0.15962549  
2023-05-25 17:27:17.308: Find a better model.
2023-05-25 17:27:57.715: [iter 23 : loss : 1.2968 = 0.3553 + 0.9388 + 0.0026, time: 40.400302]
2023-05-25 17:27:58.110: epoch 23:	0.08598818  	0.16248088  	0.16126309  
2023-05-25 17:27:58.110: Find a better model.
2023-05-25 17:28:38.903: [iter 24 : loss : 1.2610 = 0.3180 + 0.9400 + 0.0031, time: 40.785541]
2023-05-25 17:28:39.314: epoch 24:	0.08675103  	0.16400023  	0.16238531  
2023-05-25 17:28:39.314: Find a better model.
2023-05-25 17:29:19.895: [iter 25 : loss : 1.2316 = 0.2879 + 0.9400 + 0.0036, time: 40.574024]
2023-05-25 17:29:20.308: epoch 25:	0.08696061  	0.16403092  	0.16269615  
2023-05-25 17:29:20.308: Find a better model.
2023-05-25 17:30:00.790: [iter 26 : loss : 1.2058 = 0.2620 + 0.9398 + 0.0040, time: 40.475248]
2023-05-25 17:30:01.196: epoch 26:	0.08718617  	0.16455948  	0.16338162  
2023-05-25 17:30:01.196: Find a better model.
2023-05-25 17:30:41.853: [iter 27 : loss : 1.1840 = 0.2404 + 0.9391 + 0.0044, time: 40.650160]
2023-05-25 17:30:42.269: epoch 27:	0.08736883  	0.16473055  	0.16339526  
2023-05-25 17:30:42.269: Find a better model.
2023-05-25 17:31:22.977: [iter 28 : loss : 1.1654 = 0.2221 + 0.9384 + 0.0048, time: 40.701539]
2023-05-25 17:31:23.383: epoch 28:	0.08739573  	0.16454870  	0.16306210  
2023-05-25 17:32:04.045: [iter 29 : loss : 1.1496 = 0.2070 + 0.9374 + 0.0052, time: 40.656356]
2023-05-25 17:32:04.444: epoch 29:	0.08719159  	0.16406064  	0.16283248  
2023-05-25 17:32:45.332: [iter 30 : loss : 1.1351 = 0.1931 + 0.9364 + 0.0056, time: 40.881159]
2023-05-25 17:32:45.729: epoch 30:	0.08723462  	0.16415283  	0.16267423  
2023-05-25 17:33:26.590: [iter 31 : loss : 1.1220 = 0.1806 + 0.9354 + 0.0060, time: 40.855878]
2023-05-25 17:33:26.986: epoch 31:	0.08700904  	0.16368107  	0.16211173  
2023-05-25 17:34:07.682: [iter 32 : loss : 1.1114 = 0.1706 + 0.9345 + 0.0063, time: 40.689942]
2023-05-25 17:34:08.081: epoch 32:	0.08711115  	0.16286185  	0.16174211  
2023-05-25 17:34:48.995: [iter 33 : loss : 1.1009 = 0.1606 + 0.9336 + 0.0066, time: 40.907027]
2023-05-25 17:34:49.401: epoch 33:	0.08698762  	0.16288286  	0.16141479  
2023-05-25 17:35:30.207: [iter 34 : loss : 1.0928 = 0.1531 + 0.9327 + 0.0070, time: 40.798067]
2023-05-25 17:35:30.604: epoch 34:	0.08678882  	0.16261649  	0.16088238  
2023-05-25 17:36:11.399: [iter 35 : loss : 1.0843 = 0.1450 + 0.9320 + 0.0073, time: 40.789460]
2023-05-25 17:36:11.797: epoch 35:	0.08674584  	0.16226807  	0.16044682  
2023-05-25 17:36:52.641: [iter 36 : loss : 1.0771 = 0.1383 + 0.9312 + 0.0076, time: 40.836916]
2023-05-25 17:36:53.040: epoch 36:	0.08636450  	0.16137134  	0.15971728  
2023-05-25 17:37:33.686: [iter 37 : loss : 1.0700 = 0.1318 + 0.9304 + 0.0079, time: 40.639079]
2023-05-25 17:37:34.085: epoch 37:	0.08626243  	0.16058008  	0.15916890  
2023-05-25 17:38:15.271: [iter 38 : loss : 1.0645 = 0.1266 + 0.9297 + 0.0082, time: 41.179547]
2023-05-25 17:38:15.668: epoch 38:	0.08598845  	0.15971839  	0.15863371  
2023-05-25 17:38:56.497: [iter 39 : loss : 1.0591 = 0.1217 + 0.9290 + 0.0084, time: 40.823228]
2023-05-25 17:38:56.892: epoch 39:	0.08574677  	0.15897623  	0.15798342  
2023-05-25 17:39:37.796: [iter 40 : loss : 1.0541 = 0.1170 + 0.9284 + 0.0087, time: 40.897111]
2023-05-25 17:39:38.192: epoch 40:	0.08552650  	0.15779035  	0.15723282  
2023-05-25 17:40:19.065: [iter 41 : loss : 1.0491 = 0.1124 + 0.9278 + 0.0089, time: 40.867069]
2023-05-25 17:40:19.471: epoch 41:	0.08526337  	0.15715367  	0.15657973  
2023-05-25 17:41:00.186: [iter 42 : loss : 1.0450 = 0.1086 + 0.9273 + 0.0092, time: 40.710179]
2023-05-25 17:41:00.586: epoch 42:	0.08500014  	0.15620805  	0.15592146  
2023-05-25 17:41:41.425: [iter 43 : loss : 1.0409 = 0.1047 + 0.9268 + 0.0094, time: 40.831101]
2023-05-25 17:41:41.821: epoch 43:	0.08494636  	0.15556182  	0.15539365  
2023-05-25 17:42:22.938: [iter 44 : loss : 1.0370 = 0.1011 + 0.9263 + 0.0097, time: 41.111032]
2023-05-25 17:42:23.350: epoch 44:	0.08462943  	0.15497200  	0.15473488  
2023-05-25 17:43:04.391: [iter 45 : loss : 1.0343 = 0.0985 + 0.9258 + 0.0099, time: 41.034051]
2023-05-25 17:43:04.792: epoch 45:	0.08432870  	0.15388229  	0.15402736  
2023-05-25 17:43:45.649: [iter 46 : loss : 1.0308 = 0.0952 + 0.9254 + 0.0101, time: 40.851037]
2023-05-25 17:43:46.045: epoch 46:	0.08404391  	0.15303473  	0.15325673  
2023-05-25 17:44:26.801: [iter 47 : loss : 1.0276 = 0.0924 + 0.9249 + 0.0103, time: 40.750105]
2023-05-25 17:44:27.199: epoch 47:	0.08401172  	0.15250018  	0.15291412  
2023-05-25 17:45:08.434: [iter 48 : loss : 1.0247 = 0.0896 + 0.9246 + 0.0105, time: 41.225077]
2023-05-25 17:45:08.829: epoch 48:	0.08377536  	0.15185311  	0.15228553  
2023-05-25 17:45:49.978: [iter 49 : loss : 1.0225 = 0.0876 + 0.9242 + 0.0107, time: 41.143109]
2023-05-25 17:45:50.382: epoch 49:	0.08358198  	0.15097845  	0.15140781  
2023-05-25 17:46:31.439: [iter 50 : loss : 1.0201 = 0.0853 + 0.9239 + 0.0110, time: 41.049803]
2023-05-25 17:46:31.837: epoch 50:	0.08315225  	0.14996828  	0.15075897  
2023-05-25 17:47:12.985: [iter 51 : loss : 1.0180 = 0.0833 + 0.9236 + 0.0111, time: 41.141453]
2023-05-25 17:47:13.390: epoch 51:	0.08303942  	0.14950052  	0.15027975  
2023-05-25 17:47:54.071: [iter 52 : loss : 1.0156 = 0.0809 + 0.9233 + 0.0113, time: 40.674049]
2023-05-25 17:47:54.464: epoch 52:	0.08281381  	0.14909381  	0.14987899  
2023-05-25 17:47:54.464: Early stopping is trigger at epoch: 52
2023-05-25 17:47:54.464: best_result@epoch 27:

2023-05-25 17:47:54.464: 		0.0874      	0.1647      	0.1634      
2023-06-08 15:42:42.776: my pid: 10764
2023-06-08 15:42:42.776: model: model.general_recommender.SGL
2023-06-08 15:42:42.776: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-08 15:42:42.776: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=1
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-08 15:42:48.793: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-08 15:43:25.563: [iter 1 : loss : 1.6059 = 0.6929 + 0.9131 + 0.0000, time: 36.765413]
2023-06-08 15:43:26.195: epoch 1:	0.00505476  	0.01229420  	0.01049836  
2023-06-08 15:43:26.195: Find a better model.
2023-06-08 15:44:03.021: [iter 2 : loss : 1.6043 = 0.6922 + 0.9121 + 0.0000, time: 36.815747]
2023-06-08 15:44:03.809: epoch 2:	0.00942740  	0.02222011  	0.01934563  
2023-06-08 15:44:03.809: Find a better model.
2023-06-08 15:44:42.337: [iter 3 : loss : 1.6029 = 0.6906 + 0.9123 + 0.0000, time: 38.517787]
2023-06-08 15:44:42.975: epoch 3:	0.02004227  	0.04473240  	0.04116090  
2023-06-08 15:44:42.975: Find a better model.
2023-06-08 15:45:17.618: [iter 4 : loss : 1.5986 = 0.6853 + 0.9133 + 0.0000, time: 34.635928]
2023-06-08 15:45:18.035: epoch 4:	0.03990623  	0.08398354  	0.08018902  
2023-06-08 15:45:18.035: Find a better model.
2023-06-08 15:45:52.265: [iter 5 : loss : 1.5785 = 0.6622 + 0.9163 + 0.0001, time: 34.224572]
2023-06-08 15:45:52.685: epoch 5:	0.06163401  	0.12032567  	0.12013397  
2023-06-08 15:45:52.685: Find a better model.
2023-06-08 15:46:26.271: [iter 6 : loss : 1.5185 = 0.5957 + 0.9226 + 0.0002, time: 33.578588]
2023-06-08 15:46:26.703: epoch 6:	0.07300003  	0.13832809  	0.14009674  
2023-06-08 15:46:26.704: Find a better model.
2023-06-08 15:47:00.442: [iter 7 : loss : 1.4288 = 0.4987 + 0.9297 + 0.0004, time: 33.731996]
2023-06-08 15:47:00.871: epoch 7:	0.07846291  	0.14822824  	0.14921807  
2023-06-08 15:47:00.871: Find a better model.
2023-06-08 15:47:34.500: [iter 8 : loss : 1.3438 = 0.4088 + 0.9343 + 0.0007, time: 33.621995]
2023-06-08 15:47:35.059: epoch 8:	0.08130984  	0.15332441  	0.15368271  
2023-06-08 15:47:35.059: Find a better model.
2023-06-08 15:48:09.259: [iter 9 : loss : 1.2768 = 0.3395 + 0.9363 + 0.0010, time: 34.193037]
2023-06-08 15:48:09.716: epoch 9:	0.08280849  	0.15656698  	0.15637054  
2023-06-08 15:48:09.716: Find a better model.
2023-06-08 15:48:43.629: [iter 10 : loss : 1.2257 = 0.2879 + 0.9366 + 0.0012, time: 33.905649]
2023-06-08 15:48:44.067: epoch 10:	0.08336721  	0.15748805  	0.15724272  
2023-06-08 15:48:44.067: Find a better model.
2023-06-08 15:49:19.217: [iter 11 : loss : 1.1855 = 0.2481 + 0.9359 + 0.0015, time: 35.143616]
2023-06-08 15:49:19.679: epoch 11:	0.08377008  	0.15754993  	0.15708944  
2023-06-08 15:49:19.679: Find a better model.
2023-06-08 15:49:54.158: [iter 12 : loss : 1.1547 = 0.2180 + 0.9349 + 0.0017, time: 34.472823]
2023-06-08 15:49:54.602: epoch 12:	0.08369487  	0.15749209  	0.15694471  
2023-06-08 15:50:29.393: [iter 13 : loss : 1.1302 = 0.1945 + 0.9338 + 0.0019, time: 34.784359]
2023-06-08 15:50:29.836: epoch 13:	0.08366799  	0.15681051  	0.15635379  
2023-06-08 15:51:04.379: [iter 14 : loss : 1.1096 = 0.1748 + 0.9327 + 0.0021, time: 34.537384]
2023-06-08 15:51:04.823: epoch 14:	0.08335637  	0.15576309  	0.15554243  
2023-06-08 15:51:40.162: [iter 15 : loss : 1.0930 = 0.1592 + 0.9315 + 0.0022, time: 35.332752]
2023-06-08 15:51:40.703: epoch 15:	0.08306098  	0.15420978  	0.15444234  
2023-06-08 15:52:23.183: [iter 16 : loss : 1.0791 = 0.1462 + 0.9304 + 0.0024, time: 42.471143]
2023-06-08 15:52:24.085: epoch 16:	0.08269567  	0.15331468  	0.15340988  
2023-06-08 15:53:03.947: [iter 17 : loss : 1.0664 = 0.1344 + 0.9294 + 0.0026, time: 39.849656]
2023-06-08 15:53:04.725: epoch 17:	0.08239487  	0.15233998  	0.15241940  
2023-06-08 15:53:46.946: [iter 18 : loss : 1.0563 = 0.1250 + 0.9285 + 0.0027, time: 42.214360]
2023-06-08 15:53:47.779: epoch 18:	0.08204041  	0.15119319  	0.15122682  
2023-06-08 15:54:29.570: [iter 19 : loss : 1.0478 = 0.1172 + 0.9277 + 0.0029, time: 41.776688]
2023-06-08 15:54:30.346: epoch 19:	0.08147644  	0.15011394  	0.15039669  
2023-06-08 15:55:13.142: [iter 20 : loss : 1.0403 = 0.1103 + 0.9270 + 0.0030, time: 42.789744]
2023-06-08 15:55:13.793: epoch 20:	0.08125083  	0.14901772  	0.14937826  
2023-06-08 15:55:55.957: [iter 21 : loss : 1.0331 = 0.1037 + 0.9262 + 0.0031, time: 42.154776]
2023-06-08 15:55:56.867: epoch 21:	0.08088558  	0.14798780  	0.14848372  
2023-06-08 15:56:37.973: [iter 22 : loss : 1.0269 = 0.0980 + 0.9256 + 0.0033, time: 41.085676]
2023-06-08 15:56:38.857: epoch 22:	0.08023557  	0.14638938  	0.14728400  
2023-06-08 15:57:21.199: [iter 23 : loss : 1.0215 = 0.0931 + 0.9250 + 0.0034, time: 42.328106]
2023-06-08 15:57:21.935: epoch 23:	0.07987569  	0.14528593  	0.14629859  
2023-06-08 15:58:05.027: [iter 24 : loss : 1.0165 = 0.0885 + 0.9245 + 0.0035, time: 43.082675]
2023-06-08 15:58:05.899: epoch 24:	0.07929550  	0.14385907  	0.14500886  
2023-06-08 15:58:46.953: [iter 25 : loss : 1.0128 = 0.0851 + 0.9240 + 0.0036, time: 41.048354]
2023-06-08 15:58:47.558: epoch 25:	0.07879599  	0.14218581  	0.14358279  
2023-06-08 15:59:29.791: [iter 26 : loss : 1.0085 = 0.0812 + 0.9236 + 0.0037, time: 42.219027]
2023-06-08 15:59:30.676: epoch 26:	0.07842528  	0.14121665  	0.14266749  
2023-06-08 16:00:11.717: [iter 27 : loss : 1.0048 = 0.0778 + 0.9232 + 0.0038, time: 41.033504]
2023-06-08 16:00:12.476: epoch 27:	0.07809231  	0.14030096  	0.14171797  
2023-06-08 16:00:55.287: [iter 28 : loss : 1.0016 = 0.0747 + 0.9229 + 0.0039, time: 42.802485]
2023-06-08 16:00:56.088: epoch 28:	0.07788283  	0.13973607  	0.14116496  
2023-06-08 16:01:38.617: [iter 29 : loss : 0.9987 = 0.0722 + 0.9225 + 0.0040, time: 42.515011]
2023-06-08 16:01:39.443: epoch 29:	0.07755517  	0.13903457  	0.14022899  
2023-06-08 16:02:19.788: [iter 30 : loss : 0.9957 = 0.0695 + 0.9221 + 0.0041, time: 40.337962]
2023-06-08 16:02:20.692: epoch 30:	0.07716305  	0.13788149  	0.13914417  
2023-06-08 16:03:03.210: [iter 31 : loss : 0.9929 = 0.0668 + 0.9218 + 0.0042, time: 42.508804]
2023-06-08 16:03:03.946: epoch 31:	0.07666878  	0.13671012  	0.13829656  
2023-06-08 16:03:45.993: [iter 32 : loss : 0.9912 = 0.0653 + 0.9216 + 0.0043, time: 42.040287]
2023-06-08 16:03:46.822: epoch 32:	0.07633575  	0.13609116  	0.13728604  
2023-06-08 16:04:27.872: [iter 33 : loss : 0.9884 = 0.0626 + 0.9213 + 0.0044, time: 41.043818]
2023-06-08 16:04:28.471: epoch 33:	0.07602958  	0.13535087  	0.13640723  
2023-06-08 16:05:08.895: [iter 34 : loss : 0.9872 = 0.0616 + 0.9211 + 0.0045, time: 40.417088]
2023-06-08 16:05:09.681: epoch 34:	0.07555690  	0.13409290  	0.13544689  
2023-06-08 16:05:50.502: [iter 35 : loss : 0.9847 = 0.0592 + 0.9209 + 0.0046, time: 40.813763]
2023-06-08 16:05:51.265: epoch 35:	0.07533661  	0.13325629  	0.13477689  
2023-06-08 16:06:29.394: [iter 36 : loss : 0.9830 = 0.0577 + 0.9207 + 0.0046, time: 38.121833]
2023-06-08 16:06:30.173: epoch 36:	0.07474583  	0.13212512  	0.13385753  
2023-06-08 16:06:30.174: Early stopping is trigger at epoch: 36
2023-06-08 16:06:30.174: best_result@epoch 11:

2023-06-08 16:06:30.174: 		0.0838      	0.1575      	0.1571      
2023-06-08 16:24:46.356: my pid: 14704
2023-06-08 16:24:46.357: model: model.general_recommender.SGL
2023-06-08 16:24:46.357: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-08 16:24:46.357: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=2
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-08 16:24:52.615: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-08 16:25:37.120: [iter 1 : loss : 1.6070 = 0.6931 + 0.9139 + 0.0000, time: 44.500549]
2023-06-08 16:25:37.914: epoch 1:	0.00155243  	0.00223527  	0.00209707  
2023-06-08 16:25:37.914: Find a better model.
2023-06-08 16:26:23.977: [iter 2 : loss : 1.6052 = 0.6930 + 0.9122 + 0.0000, time: 46.052555]
2023-06-08 16:26:24.844: epoch 2:	0.00188548  	0.00284518  	0.00259089  
2023-06-08 16:26:24.844: Find a better model.
2023-06-08 16:27:11.046: [iter 3 : loss : 1.6050 = 0.6929 + 0.9121 + 0.0000, time: 46.190031]
2023-06-08 16:27:11.914: epoch 3:	0.00253008  	0.00331929  	0.00356104  
2023-06-08 16:27:11.915: Find a better model.
2023-06-08 16:27:59.564: [iter 4 : loss : 1.6049 = 0.6927 + 0.9122 + 0.0000, time: 47.642707]
2023-06-08 16:28:00.429: epoch 4:	0.00348623  	0.00472642  	0.00500235  
2023-06-08 16:28:00.429: Find a better model.
2023-06-08 16:28:48.674: [iter 5 : loss : 1.6048 = 0.6925 + 0.9123 + 0.0000, time: 48.237410]
2023-06-08 16:28:49.132: epoch 5:	0.00485601  	0.00694804  	0.00695938  
2023-06-08 16:28:49.132: Find a better model.
2023-06-08 16:29:36.154: [iter 6 : loss : 1.6047 = 0.6922 + 0.9125 + 0.0000, time: 47.014163]
2023-06-08 16:29:36.960: epoch 6:	0.00692410  	0.01054768  	0.01064280  
2023-06-08 16:29:36.960: Find a better model.
2023-06-08 16:30:25.591: [iter 7 : loss : 1.6044 = 0.6916 + 0.9127 + 0.0000, time: 48.624784]
2023-06-08 16:30:26.421: epoch 7:	0.01015797  	0.01542032  	0.01612976  
2023-06-08 16:30:26.421: Find a better model.
2023-06-08 16:31:13.801: [iter 8 : loss : 1.6036 = 0.6906 + 0.9130 + 0.0000, time: 47.372615]
2023-06-08 16:31:14.677: epoch 8:	0.01506787  	0.02500241  	0.02572669  
2023-06-08 16:31:14.677: Find a better model.
2023-06-08 16:32:02.699: [iter 9 : loss : 1.6023 = 0.6886 + 0.9136 + 0.0000, time: 48.013225]
2023-06-08 16:32:03.147: epoch 9:	0.02365749  	0.04342972  	0.04451559  
2023-06-08 16:32:03.147: Find a better model.
2023-06-08 16:32:50.518: [iter 10 : loss : 1.5984 = 0.6838 + 0.9145 + 0.0000, time: 47.363747]
2023-06-08 16:32:51.228: epoch 10:	0.03790271  	0.07243072  	0.07333028  
2023-06-08 16:32:51.229: Find a better model.
2023-06-08 16:33:38.915: [iter 11 : loss : 1.5871 = 0.6710 + 0.9160 + 0.0001, time: 47.679574]
2023-06-08 16:33:39.742: epoch 11:	0.05712197  	0.10943859  	0.11095053  
2023-06-08 16:33:39.742: Find a better model.
2023-06-08 16:34:28.036: [iter 12 : loss : 1.5572 = 0.6372 + 0.9197 + 0.0002, time: 48.279016]
2023-06-08 16:34:28.779: epoch 12:	0.07228024  	0.13538417  	0.13784599  
2023-06-08 16:34:28.779: Find a better model.
2023-06-08 16:35:08.339: [iter 13 : loss : 1.4978 = 0.5705 + 0.9269 + 0.0004, time: 39.553584]
2023-06-08 16:35:08.778: epoch 13:	0.07982729  	0.14867382  	0.15103485  
2023-06-08 16:35:08.778: Find a better model.
2023-06-08 16:35:47.354: [iter 14 : loss : 1.4204 = 0.4838 + 0.9358 + 0.0008, time: 38.567941]
2023-06-08 16:35:47.783: epoch 14:	0.08295887  	0.15538390  	0.15680306  
2023-06-08 16:35:47.784: Find a better model.
2023-06-08 16:36:26.545: [iter 15 : loss : 1.3479 = 0.4046 + 0.9421 + 0.0012, time: 38.755222]
2023-06-08 16:36:26.988: epoch 15:	0.08470463  	0.15922090  	0.15968980  
2023-06-08 16:36:26.988: Find a better model.
2023-06-08 16:37:05.575: [iter 16 : loss : 1.2893 = 0.3426 + 0.9451 + 0.0016, time: 38.577732]
2023-06-08 16:37:06.002: epoch 16:	0.08588637  	0.16180050  	0.16176623  
2023-06-08 16:37:06.002: Find a better model.
2023-06-08 16:37:44.602: [iter 17 : loss : 1.2427 = 0.2949 + 0.9458 + 0.0019, time: 38.594370]
2023-06-08 16:37:45.014: epoch 17:	0.08650417  	0.16315357  	0.16266805  
2023-06-08 16:37:45.014: Find a better model.
2023-06-08 16:38:23.632: [iter 18 : loss : 1.2065 = 0.2589 + 0.9453 + 0.0023, time: 38.608041]
2023-06-08 16:38:24.169: epoch 18:	0.08691230  	0.16413155  	0.16307627  
2023-06-08 16:38:24.169: Find a better model.
2023-06-08 16:39:03.015: [iter 19 : loss : 1.1775 = 0.2306 + 0.9443 + 0.0026, time: 38.838743]
2023-06-08 16:39:03.568: epoch 19:	0.08673509  	0.16398512  	0.16271742  
2023-06-08 16:39:42.441: [iter 20 : loss : 1.1545 = 0.2087 + 0.9429 + 0.0029, time: 38.859629]
2023-06-08 16:39:42.992: epoch 20:	0.08685855  	0.16403198  	0.16241211  
2023-06-08 16:40:21.607: [iter 21 : loss : 1.1345 = 0.1899 + 0.9414 + 0.0032, time: 38.603625]
2023-06-08 16:40:22.150: epoch 21:	0.08691223  	0.16321759  	0.16203813  
2023-06-08 16:41:00.792: [iter 22 : loss : 1.1179 = 0.1744 + 0.9401 + 0.0035, time: 38.631450]
2023-06-08 16:41:01.365: epoch 22:	0.08667064  	0.16210672  	0.16112840  
2023-06-08 16:41:39.566: [iter 23 : loss : 1.1039 = 0.1615 + 0.9387 + 0.0037, time: 38.190385]
2023-06-08 16:41:40.048: epoch 23:	0.08665985  	0.16207701  	0.16071951  
2023-06-08 16:42:18.638: [iter 24 : loss : 1.0918 = 0.1503 + 0.9375 + 0.0040, time: 38.578204]
2023-06-08 16:42:19.183: epoch 24:	0.08636986  	0.16135642  	0.16021024  
2023-06-08 16:42:58.262: [iter 25 : loss : 1.0817 = 0.1411 + 0.9363 + 0.0042, time: 39.068722]
2023-06-08 16:42:58.787: epoch 25:	0.08623020  	0.16078001  	0.15941451  
2023-06-08 16:43:38.268: [iter 26 : loss : 1.0721 = 0.1324 + 0.9353 + 0.0045, time: 39.470208]
2023-06-08 16:43:38.812: epoch 26:	0.08584880  	0.15982503  	0.15861933  
2023-06-08 16:44:18.263: [iter 27 : loss : 1.0636 = 0.1246 + 0.9343 + 0.0047, time: 39.441465]
2023-06-08 16:44:18.816: epoch 27:	0.08570379  	0.15883838  	0.15758486  
2023-06-08 16:44:58.121: [iter 28 : loss : 1.0563 = 0.1180 + 0.9334 + 0.0049, time: 39.294546]
2023-06-08 16:44:58.691: epoch 28:	0.08550503  	0.15832984  	0.15677717  
2023-06-08 16:45:38.145: [iter 29 : loss : 1.0500 = 0.1125 + 0.9324 + 0.0051, time: 39.441331]
2023-06-08 16:45:38.624: epoch 29:	0.08526870  	0.15771365  	0.15622307  
2023-06-08 16:46:14.802: [iter 30 : loss : 1.0439 = 0.1071 + 0.9316 + 0.0053, time: 36.170146]
2023-06-08 16:46:15.199: epoch 30:	0.08500007  	0.15693435  	0.15550779  
2023-06-08 16:46:51.561: [iter 31 : loss : 1.0380 = 0.1016 + 0.9309 + 0.0055, time: 36.356468]
2023-06-08 16:46:51.958: epoch 31:	0.08450047  	0.15582708  	0.15430689  
2023-06-08 16:47:28.402: [iter 32 : loss : 1.0338 = 0.0979 + 0.9302 + 0.0057, time: 36.437397]
2023-06-08 16:47:28.798: epoch 32:	0.08415671  	0.15499313  	0.15359087  
2023-06-08 16:48:05.176: [iter 33 : loss : 1.0289 = 0.0934 + 0.9296 + 0.0058, time: 36.371992]
2023-06-08 16:48:05.589: epoch 33:	0.08385594  	0.15392274  	0.15272942  
2023-06-08 16:48:41.865: [iter 34 : loss : 1.0256 = 0.0905 + 0.9290 + 0.0060, time: 36.268813]
2023-06-08 16:48:42.264: epoch 34:	0.08351751  	0.15316126  	0.15193264  
2023-06-08 16:49:18.478: [iter 35 : loss : 1.0213 = 0.0866 + 0.9286 + 0.0062, time: 36.206944]
2023-06-08 16:49:18.871: epoch 35:	0.08317376  	0.15194808  	0.15106764  
2023-06-08 16:49:55.492: [iter 36 : loss : 1.0178 = 0.0834 + 0.9281 + 0.0063, time: 36.614664]
2023-06-08 16:49:55.884: epoch 36:	0.08286759  	0.15095516  	0.15034036  
2023-06-08 16:50:32.500: [iter 37 : loss : 1.0149 = 0.0808 + 0.9275 + 0.0065, time: 36.609779]
2023-06-08 16:50:32.893: epoch 37:	0.08257219  	0.15022931  	0.14964139  
2023-06-08 16:51:09.492: [iter 38 : loss : 1.0121 = 0.0783 + 0.9271 + 0.0067, time: 36.592156]
2023-06-08 16:51:09.896: epoch 38:	0.08235199  	0.14943868  	0.14920577  
2023-06-08 16:51:46.112: [iter 39 : loss : 1.0094 = 0.0759 + 0.9267 + 0.0068, time: 36.209932]
2023-06-08 16:51:46.530: epoch 39:	0.08189539  	0.14820750  	0.14824127  
2023-06-08 16:52:23.089: [iter 40 : loss : 1.0072 = 0.0740 + 0.9263 + 0.0069, time: 36.550968]
2023-06-08 16:52:23.507: epoch 40:	0.08172349  	0.14735468  	0.14756109  
2023-06-08 16:53:00.202: [iter 41 : loss : 1.0044 = 0.0714 + 0.9260 + 0.0071, time: 36.688456]
2023-06-08 16:53:00.607: epoch 41:	0.08136362  	0.14671931  	0.14694168  
2023-06-08 16:53:37.043: [iter 42 : loss : 1.0026 = 0.0698 + 0.9256 + 0.0072, time: 36.430313]
2023-06-08 16:53:37.462: epoch 42:	0.08107895  	0.14577228  	0.14618039  
2023-06-08 16:54:13.859: [iter 43 : loss : 1.0001 = 0.0674 + 0.9253 + 0.0073, time: 36.391313]
2023-06-08 16:54:14.253: epoch 43:	0.08074055  	0.14491941  	0.14535932  
2023-06-08 16:54:14.254: Early stopping is trigger at epoch: 43
2023-06-08 16:54:14.254: best_result@epoch 18:

2023-06-08 16:54:14.254: 		0.0869      	0.1641      	0.1631      
2023-06-08 17:00:29.810: my pid: 1500
2023-06-08 17:00:29.810: model: model.general_recommender.SGL
2023-06-08 17:00:29.810: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-08 17:00:29.810: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=4
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-08 17:00:36.165: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-08 17:01:36.322: [iter 1 : loss : 1.6094 = 0.6931 + 0.9163 + 0.0000, time: 60.156197]
2023-06-08 17:01:36.894: epoch 1:	0.00191771  	0.00261918  	0.00259556  
2023-06-08 17:01:36.894: Find a better model.
2023-06-08 17:02:34.612: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 57.706727]
2023-06-08 17:02:35.373: epoch 2:	0.00191771  	0.00250766  	0.00254998  
2023-06-08 17:03:34.811: [iter 3 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 59.423713]
2023-06-08 17:03:35.612: epoch 3:	0.00220778  	0.00270757  	0.00298408  
2023-06-08 17:03:35.613: Find a better model.
2023-06-08 17:04:34.827: [iter 4 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 59.193982]
2023-06-08 17:04:35.660: epoch 4:	0.00235281  	0.00278161  	0.00306436  
2023-06-08 17:04:35.660: Find a better model.
2023-06-08 17:05:35.532: [iter 5 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 59.861127]
2023-06-08 17:05:36.286: epoch 5:	0.00247099  	0.00300695  	0.00317896  
2023-06-08 17:05:36.286: Find a better model.
2023-06-08 17:06:35.991: [iter 6 : loss : 1.6057 = 0.6930 + 0.9126 + 0.0000, time: 59.695544]
2023-06-08 17:06:36.759: epoch 6:	0.00291684  	0.00341145  	0.00376997  
2023-06-08 17:06:36.759: Find a better model.
2023-06-08 17:07:22.541: [iter 7 : loss : 1.6057 = 0.6930 + 0.9127 + 0.0000, time: 45.776240]
2023-06-08 17:07:22.960: epoch 7:	0.00333583  	0.00390456  	0.00440111  
2023-06-08 17:07:22.960: Find a better model.
2023-06-08 17:08:07.565: [iter 8 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 44.597622]
2023-06-08 17:08:08.008: epoch 8:	0.00366887  	0.00424717  	0.00494273  
2023-06-08 17:08:08.008: Find a better model.
2023-06-08 17:08:52.832: [iter 9 : loss : 1.6058 = 0.6930 + 0.9128 + 0.0000, time: 44.816388]
2023-06-08 17:08:53.256: epoch 9:	0.00407174  	0.00465611  	0.00520936  
2023-06-08 17:08:53.256: Find a better model.
2023-06-08 17:09:37.622: [iter 10 : loss : 1.6058 = 0.6929 + 0.9128 + 0.0000, time: 44.359686]
2023-06-08 17:09:38.157: epoch 10:	0.00410935  	0.00495123  	0.00539715  
2023-06-08 17:09:38.157: Find a better model.
2023-06-08 17:10:24.365: [iter 11 : loss : 1.6057 = 0.6929 + 0.9128 + 0.0000, time: 46.197426]
2023-06-08 17:10:24.934: epoch 11:	0.00449073  	0.00591887  	0.00635562  
2023-06-08 17:10:24.934: Find a better model.
2023-06-08 17:11:10.764: [iter 12 : loss : 1.6057 = 0.6928 + 0.9129 + 0.0000, time: 45.823136]
2023-06-08 17:11:11.211: epoch 12:	0.00510310  	0.00627334  	0.00689773  
2023-06-08 17:11:11.211: Find a better model.
2023-06-08 17:11:56.804: [iter 13 : loss : 1.6058 = 0.6928 + 0.9130 + 0.0000, time: 45.585392]
2023-06-08 17:11:57.231: epoch 13:	0.00560804  	0.00705197  	0.00768992  
2023-06-08 17:11:57.232: Find a better model.
2023-06-08 17:12:42.510: [iter 14 : loss : 1.6058 = 0.6927 + 0.9130 + 0.0000, time: 45.270066]
2023-06-08 17:12:43.048: epoch 14:	0.00638156  	0.00810977  	0.00878067  
2023-06-08 17:12:43.049: Find a better model.
2023-06-08 17:13:28.920: [iter 15 : loss : 1.6057 = 0.6926 + 0.9131 + 0.0000, time: 45.862305]
2023-06-08 17:13:29.497: epoch 15:	0.00685427  	0.00907973  	0.00978418  
2023-06-08 17:13:29.497: Find a better model.
2023-06-08 17:14:15.203: [iter 16 : loss : 1.6057 = 0.6925 + 0.9131 + 0.0000, time: 45.698694]
2023-06-08 17:14:15.671: epoch 16:	0.00802534  	0.01059264  	0.01172164  
2023-06-08 17:14:15.672: Find a better model.
2023-06-08 17:15:01.159: [iter 17 : loss : 1.6055 = 0.6924 + 0.9131 + 0.0000, time: 45.478752]
2023-06-08 17:15:01.632: epoch 17:	0.00876665  	0.01202778  	0.01332113  
2023-06-08 17:15:01.632: Find a better model.
2023-06-08 17:15:46.973: [iter 18 : loss : 1.6055 = 0.6923 + 0.9132 + 0.0000, time: 45.334094]
2023-06-08 17:15:47.526: epoch 18:	0.01024393  	0.01508637  	0.01598075  
2023-06-08 17:15:47.526: Find a better model.
2023-06-08 17:16:33.108: [iter 19 : loss : 1.6054 = 0.6920 + 0.9133 + 0.0000, time: 45.575271]
2023-06-08 17:16:33.627: epoch 19:	0.01211870  	0.01858314  	0.01950624  
2023-06-08 17:16:33.627: Find a better model.
2023-06-08 17:17:19.522: [iter 20 : loss : 1.6053 = 0.6918 + 0.9135 + 0.0000, time: 45.883260]
2023-06-08 17:17:20.075: epoch 20:	0.01362821  	0.02102887  	0.02244053  
2023-06-08 17:17:20.075: Find a better model.
2023-06-08 17:18:05.668: [iter 21 : loss : 1.6050 = 0.6914 + 0.9136 + 0.0000, time: 45.586865]
2023-06-08 17:18:06.107: epoch 21:	0.01626044  	0.02546342  	0.02692242  
2023-06-08 17:18:06.108: Find a better model.
2023-06-08 17:18:51.513: [iter 22 : loss : 1.6046 = 0.6908 + 0.9138 + 0.0000, time: 45.398333]
2023-06-08 17:18:52.022: epoch 22:	0.02020880  	0.03374861  	0.03447038  
2023-06-08 17:18:52.022: Find a better model.
2023-06-08 17:19:35.053: [iter 23 : loss : 1.6040 = 0.6899 + 0.9140 + 0.0001, time: 43.023832]
2023-06-08 17:19:35.499: epoch 23:	0.02454388  	0.04282209  	0.04380196  
2023-06-08 17:19:35.499: Find a better model.
2023-06-08 17:20:17.769: [iter 24 : loss : 1.6029 = 0.6884 + 0.9144 + 0.0001, time: 42.263006]
2023-06-08 17:20:18.175: epoch 24:	0.03079102  	0.05606857  	0.05676533  
2023-06-08 17:20:18.175: Find a better model.
2023-06-08 17:21:01.323: [iter 25 : loss : 1.6010 = 0.6859 + 0.9149 + 0.0001, time: 43.139853]
2023-06-08 17:21:01.725: epoch 25:	0.03908441  	0.07366506  	0.07328400  
2023-06-08 17:21:01.725: Find a better model.
2023-06-08 17:21:44.088: [iter 26 : loss : 1.5972 = 0.6813 + 0.9157 + 0.0002, time: 42.356256]
2023-06-08 17:21:44.508: epoch 26:	0.04954825  	0.09558598  	0.09476233  
2023-06-08 17:21:44.509: Find a better model.
2023-06-08 17:22:26.757: [iter 27 : loss : 1.5897 = 0.6725 + 0.9169 + 0.0002, time: 42.241014]
2023-06-08 17:22:27.164: epoch 27:	0.05974318  	0.11463504  	0.11480398  
2023-06-08 17:22:27.164: Find a better model.
2023-06-08 17:23:09.505: [iter 28 : loss : 1.5752 = 0.6560 + 0.9188 + 0.0004, time: 42.334487]
2023-06-08 17:23:09.904: epoch 28:	0.06965370  	0.13199678  	0.13266653  
2023-06-08 17:23:09.905: Find a better model.
2023-06-08 17:23:52.438: [iter 29 : loss : 1.5503 = 0.6276 + 0.9221 + 0.0006, time: 42.525693]
2023-06-08 17:23:52.836: epoch 29:	0.07670654  	0.14470880  	0.14477697  
2023-06-08 17:23:52.837: Find a better model.
2023-06-08 17:24:35.412: [iter 30 : loss : 1.5132 = 0.5853 + 0.9269 + 0.0010, time: 42.568979]
2023-06-08 17:24:35.809: epoch 30:	0.08089633  	0.15156367  	0.15212712  
2023-06-08 17:24:35.809: Find a better model.
2023-06-08 17:25:18.354: [iter 31 : loss : 1.4677 = 0.5331 + 0.9331 + 0.0015, time: 42.538117]
2023-06-08 17:25:18.751: epoch 31:	0.08298042  	0.15586875  	0.15625082  
2023-06-08 17:25:18.751: Find a better model.
2023-06-08 17:26:01.387: [iter 32 : loss : 1.4200 = 0.4787 + 0.9392 + 0.0021, time: 42.628561]
2023-06-08 17:26:01.784: epoch 32:	0.08411917  	0.15892150  	0.15861440  
2023-06-08 17:26:01.784: Find a better model.
2023-06-08 17:26:44.387: [iter 33 : loss : 1.3747 = 0.4279 + 0.9441 + 0.0027, time: 42.596220]
2023-06-08 17:26:44.784: epoch 33:	0.08495179  	0.16077690  	0.16019747  
2023-06-08 17:26:44.784: Find a better model.
2023-06-08 17:27:27.517: [iter 34 : loss : 1.3349 = 0.3843 + 0.9472 + 0.0033, time: 42.725001]
2023-06-08 17:27:27.921: epoch 34:	0.08582743  	0.16260342  	0.16165385  
2023-06-08 17:27:27.921: Find a better model.
2023-06-08 17:28:10.539: [iter 35 : loss : 1.2996 = 0.3466 + 0.9490 + 0.0039, time: 42.610324]
2023-06-08 17:28:10.936: epoch 35:	0.08628392  	0.16410170  	0.16276729  
2023-06-08 17:28:10.936: Find a better model.
2023-06-08 17:28:53.540: [iter 36 : loss : 1.2697 = 0.3156 + 0.9496 + 0.0045, time: 42.598232]
2023-06-08 17:28:53.939: epoch 36:	0.08694468  	0.16534874  	0.16375072  
2023-06-08 17:28:53.940: Find a better model.
2023-06-08 17:29:36.672: [iter 37 : loss : 1.2432 = 0.2886 + 0.9495 + 0.0051, time: 42.726529]
2023-06-08 17:29:37.074: epoch 37:	0.08720253  	0.16564843  	0.16420579  
2023-06-08 17:29:37.074: Find a better model.
2023-06-08 17:30:19.724: [iter 38 : loss : 1.2206 = 0.2659 + 0.9491 + 0.0056, time: 42.641386]
2023-06-08 17:30:20.124: epoch 38:	0.08740669  	0.16585489  	0.16441220  
2023-06-08 17:30:20.125: Find a better model.
2023-06-08 17:31:02.735: [iter 39 : loss : 1.2014 = 0.2468 + 0.9484 + 0.0062, time: 42.604423]
2023-06-08 17:31:03.143: epoch 39:	0.08740133  	0.16570069  	0.16434267  
2023-06-08 17:31:45.857: [iter 40 : loss : 1.1848 = 0.2305 + 0.9476 + 0.0067, time: 42.705979]
2023-06-08 17:31:46.265: epoch 40:	0.08763766  	0.16589373  	0.16449319  
2023-06-08 17:31:46.265: Find a better model.
2023-06-08 17:32:29.239: [iter 41 : loss : 1.1691 = 0.2153 + 0.9466 + 0.0072, time: 42.968040]
2023-06-08 17:32:29.646: epoch 41:	0.08776656  	0.16620520  	0.16448206  
2023-06-08 17:32:29.646: Find a better model.
2023-06-08 17:33:12.436: [iter 42 : loss : 1.1558 = 0.2026 + 0.9456 + 0.0076, time: 42.783205]
2023-06-08 17:33:12.835: epoch 42:	0.08778267  	0.16613968  	0.16438460  
2023-06-08 17:33:55.866: [iter 43 : loss : 1.1435 = 0.1908 + 0.9447 + 0.0081, time: 43.022431]
2023-06-08 17:33:56.266: epoch 43:	0.08775040  	0.16586478  	0.16409941  
2023-06-08 17:34:39.243: [iter 44 : loss : 1.1330 = 0.1808 + 0.9437 + 0.0085, time: 42.970320]
2023-06-08 17:34:39.650: epoch 44:	0.08778799  	0.16596027  	0.16404070  
2023-06-08 17:35:22.366: [iter 45 : loss : 1.1239 = 0.1722 + 0.9427 + 0.0090, time: 42.709030]
2023-06-08 17:35:22.764: epoch 45:	0.08778798  	0.16575503  	0.16375923  
2023-06-08 17:36:05.805: [iter 46 : loss : 1.1148 = 0.1636 + 0.9418 + 0.0094, time: 43.033092]
2023-06-08 17:36:06.204: epoch 46:	0.08762680  	0.16547698  	0.16324814  
2023-06-08 17:36:49.222: [iter 47 : loss : 1.1065 = 0.1559 + 0.9408 + 0.0098, time: 43.009555]
2023-06-08 17:36:49.629: epoch 47:	0.08759453  	0.16533691  	0.16319634  
2023-06-08 17:37:32.667: [iter 48 : loss : 1.0993 = 0.1491 + 0.9400 + 0.0102, time: 43.029452]
2023-06-08 17:37:33.067: epoch 48:	0.08746029  	0.16497979  	0.16293746  
2023-06-08 17:38:16.107: [iter 49 : loss : 1.0928 = 0.1430 + 0.9392 + 0.0105, time: 43.033131]
2023-06-08 17:38:16.527: epoch 49:	0.08728303  	0.16445880  	0.16253535  
2023-06-08 17:38:59.318: [iter 50 : loss : 1.0866 = 0.1373 + 0.9383 + 0.0109, time: 42.784033]
2023-06-08 17:38:59.719: epoch 50:	0.08726690  	0.16383143  	0.16205691  
2023-06-08 17:39:42.713: [iter 51 : loss : 1.0811 = 0.1321 + 0.9378 + 0.0112, time: 42.988306]
2023-06-08 17:39:43.114: epoch 51:	0.08703595  	0.16306430  	0.16153131  
2023-06-08 17:40:26.058: [iter 52 : loss : 1.0760 = 0.1274 + 0.9371 + 0.0116, time: 42.935617]
2023-06-08 17:40:26.487: epoch 52:	0.08686935  	0.16234370  	0.16091076  
2023-06-08 17:41:09.498: [iter 53 : loss : 1.0710 = 0.1228 + 0.9363 + 0.0119, time: 43.003291]
2023-06-08 17:41:09.901: epoch 53:	0.08678340  	0.16197442  	0.16052549  
2023-06-08 17:41:52.881: [iter 54 : loss : 1.0662 = 0.1182 + 0.9358 + 0.0123, time: 42.973989]
2023-06-08 17:41:53.281: epoch 54:	0.08659537  	0.16161305  	0.16021194  
2023-06-08 17:42:36.352: [iter 55 : loss : 1.0625 = 0.1148 + 0.9352 + 0.0125, time: 43.063214]
2023-06-08 17:42:36.757: epoch 55:	0.08644500  	0.16097350  	0.15959518  
2023-06-08 17:43:19.583: [iter 56 : loss : 1.0587 = 0.1112 + 0.9346 + 0.0129, time: 42.818101]
2023-06-08 17:43:19.986: epoch 56:	0.08627311  	0.16022162  	0.15912110  
2023-06-08 17:44:03.028: [iter 57 : loss : 1.0547 = 0.1075 + 0.9341 + 0.0131, time: 43.035675]
2023-06-08 17:44:03.452: epoch 57:	0.08618719  	0.15976304  	0.15859999  
2023-06-08 17:44:46.429: [iter 58 : loss : 1.0520 = 0.1049 + 0.9337 + 0.0134, time: 42.970073]
2023-06-08 17:44:46.831: epoch 58:	0.08590250  	0.15913762  	0.15810157  
2023-06-08 17:45:29.932: [iter 59 : loss : 1.0486 = 0.1017 + 0.9332 + 0.0137, time: 43.095126]
2023-06-08 17:45:30.347: epoch 59:	0.08575746  	0.15873961  	0.15771151  
2023-06-08 17:46:13.417: [iter 60 : loss : 1.0459 = 0.0993 + 0.9326 + 0.0140, time: 43.054568]
2023-06-08 17:46:13.817: epoch 60:	0.08554791  	0.15805435  	0.15732878  
2023-06-08 17:46:56.629: [iter 61 : loss : 1.0430 = 0.0965 + 0.9323 + 0.0143, time: 42.804073]
2023-06-08 17:46:57.029: epoch 61:	0.08517723  	0.15699400  	0.15662529  
2023-06-08 17:47:40.206: [iter 62 : loss : 1.0408 = 0.0943 + 0.9319 + 0.0145, time: 43.171067]
2023-06-08 17:47:40.616: epoch 62:	0.08503754  	0.15661150  	0.15622573  
2023-06-08 17:48:23.501: [iter 63 : loss : 1.0383 = 0.0920 + 0.9315 + 0.0148, time: 42.878393]
2023-06-08 17:48:23.905: epoch 63:	0.08487640  	0.15619233  	0.15581068  
2023-06-08 17:49:06.709: [iter 64 : loss : 1.0359 = 0.0897 + 0.9312 + 0.0150, time: 42.796967]
2023-06-08 17:49:07.103: epoch 64:	0.08467229  	0.15563348  	0.15532349  
2023-06-08 17:49:49.872: [iter 65 : loss : 1.0336 = 0.0876 + 0.9308 + 0.0153, time: 42.761984]
2023-06-08 17:49:50.272: epoch 65:	0.08436079  	0.15492468  	0.15467882  
2023-06-08 17:50:33.414: [iter 66 : loss : 1.0315 = 0.0855 + 0.9305 + 0.0155, time: 43.136030]
2023-06-08 17:50:33.817: epoch 66:	0.08432320  	0.15455632  	0.15421592  
2023-06-08 17:50:33.818: Early stopping is trigger at epoch: 66
2023-06-08 17:50:33.818: best_result@epoch 41:

2023-06-08 17:50:33.818: 		0.0878      	0.1662      	0.1645      
2023-06-12 20:32:35.394: my pid: 6428
2023-06-12 20:32:35.394: model: model.general_recommender.SGL
2023-06-12 20:32:35.394: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 20:32:35.394: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=1
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 20:35:11.878: my pid: 11148
2023-06-12 20:35:11.878: model: model.general_recommender.SGL
2023-06-12 20:35:11.878: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 20:35:11.879: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=1
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 20:35:17.479: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-12 20:35:52.443: [iter 1 : loss : 1.6059 = 0.6929 + 0.9131 + 0.0000, time: 34.963425]
2023-06-12 20:35:52.886: epoch 1:	0.00500641  	0.01219350  	0.01044144  
2023-06-12 20:35:52.886: Find a better model.
2023-06-12 20:36:27.359: [iter 2 : loss : 1.6043 = 0.6922 + 0.9121 + 0.0000, time: 34.466297]
2023-06-12 20:36:27.863: epoch 2:	0.00947574  	0.02160250  	0.01919895  
2023-06-12 20:36:27.863: Find a better model.
2023-06-12 20:37:02.331: [iter 3 : loss : 1.6029 = 0.6906 + 0.9123 + 0.0000, time: 34.461872]
2023-06-12 20:37:02.762: epoch 3:	0.02026790  	0.04562599  	0.04185888  
2023-06-12 20:37:02.762: Find a better model.
2023-06-12 20:37:36.958: [iter 4 : loss : 1.5986 = 0.6853 + 0.9133 + 0.0000, time: 34.188908]
2023-06-12 20:37:37.441: epoch 4:	0.03968069  	0.08307218  	0.07973742  
2023-06-12 20:37:37.441: Find a better model.
2023-06-12 20:38:11.332: [iter 5 : loss : 1.5786 = 0.6623 + 0.9163 + 0.0001, time: 33.885049]
2023-06-12 20:38:11.770: epoch 5:	0.06121494  	0.11889733  	0.11928023  
2023-06-12 20:38:11.770: Find a better model.
2023-06-12 20:38:46.424: [iter 6 : loss : 1.5189 = 0.5961 + 0.9226 + 0.0002, time: 34.646450]
2023-06-12 20:38:46.830: epoch 6:	0.07253271  	0.13768972  	0.13923204  
2023-06-12 20:38:46.830: Find a better model.
2023-06-12 20:39:21.178: [iter 7 : loss : 1.4294 = 0.4992 + 0.9297 + 0.0004, time: 34.342476]
2023-06-12 20:39:21.605: epoch 7:	0.07823183  	0.14834504  	0.14898273  
2023-06-12 20:39:21.605: Find a better model.
2023-06-12 20:39:54.972: [iter 8 : loss : 1.3443 = 0.4093 + 0.9343 + 0.0007, time: 33.359602]
2023-06-12 20:39:55.499: epoch 8:	0.08127753  	0.15368329  	0.15384451  
2023-06-12 20:39:55.499: Find a better model.
2023-06-12 20:40:29.283: [iter 9 : loss : 1.2772 = 0.3399 + 0.9364 + 0.0010, time: 33.777003]
2023-06-12 20:40:29.701: epoch 9:	0.08280308  	0.15676314  	0.15617590  
2023-06-12 20:40:29.701: Find a better model.
2023-06-12 20:41:04.094: [iter 10 : loss : 1.2260 = 0.2882 + 0.9366 + 0.0012, time: 34.385457]
2023-06-12 20:41:04.570: epoch 10:	0.08353366  	0.15817584  	0.15743558  
2023-06-12 20:41:04.570: Find a better model.
2023-06-12 20:41:39.741: [iter 11 : loss : 1.1857 = 0.2484 + 0.9359 + 0.0015, time: 35.165078]
2023-06-12 20:41:40.144: epoch 11:	0.08345304  	0.15789869  	0.15711156  
2023-06-12 20:42:15.545: [iter 12 : loss : 1.1549 = 0.2182 + 0.9349 + 0.0017, time: 35.395456]
2023-06-12 20:42:15.974: epoch 12:	0.08349611  	0.15794547  	0.15704158  
2023-06-12 20:42:51.186: [iter 13 : loss : 1.1303 = 0.1946 + 0.9338 + 0.0019, time: 35.206975]
2023-06-12 20:42:51.749: epoch 13:	0.08345316  	0.15698524  	0.15635179  
2023-06-12 20:43:26.853: [iter 14 : loss : 1.1097 = 0.1750 + 0.9327 + 0.0021, time: 35.096919]
2023-06-12 20:43:27.291: epoch 14:	0.08320609  	0.15537673  	0.15530966  
2023-06-12 20:44:02.182: [iter 15 : loss : 1.0931 = 0.1593 + 0.9315 + 0.0022, time: 34.875227]
2023-06-12 20:44:02.726: epoch 15:	0.08277095  	0.15428336  	0.15433185  
2023-06-12 20:44:36.040: [iter 16 : loss : 1.0792 = 0.1464 + 0.9304 + 0.0024, time: 33.307988]
2023-06-12 20:44:36.450: epoch 16:	0.08244867  	0.15307724  	0.15342864  
2023-06-12 20:45:11.761: [iter 17 : loss : 1.0665 = 0.1345 + 0.9294 + 0.0026, time: 35.303439]
2023-06-12 20:45:12.156: epoch 17:	0.08196518  	0.15219517  	0.15222348  
2023-06-12 20:45:45.396: [iter 18 : loss : 1.0563 = 0.1251 + 0.9285 + 0.0027, time: 33.233196]
2023-06-12 20:45:45.790: epoch 18:	0.08177727  	0.15113415  	0.15111125  
2023-06-12 20:46:19.008: [iter 19 : loss : 1.0479 = 0.1173 + 0.9277 + 0.0029, time: 33.211040]
2023-06-12 20:46:19.434: epoch 19:	0.08132069  	0.14986151  	0.15000458  
2023-06-12 20:46:52.571: [iter 20 : loss : 1.0402 = 0.1103 + 0.9269 + 0.0030, time: 33.131444]
2023-06-12 20:46:52.969: epoch 20:	0.08087487  	0.14863099  	0.14887580  
2023-06-12 20:47:26.059: [iter 21 : loss : 1.0330 = 0.1037 + 0.9262 + 0.0031, time: 33.083655]
2023-06-12 20:47:26.473: epoch 21:	0.08050961  	0.14764377  	0.14794034  
2023-06-12 20:47:59.709: [iter 22 : loss : 1.0269 = 0.0980 + 0.9256 + 0.0033, time: 33.229117]
2023-06-12 20:48:00.110: epoch 22:	0.08026245  	0.14674476  	0.14692824  
2023-06-12 20:48:33.277: [iter 23 : loss : 1.0215 = 0.0931 + 0.9250 + 0.0034, time: 33.161126]
2023-06-12 20:48:33.679: epoch 23:	0.07967690  	0.14540692  	0.14589837  
2023-06-12 20:49:06.895: [iter 24 : loss : 1.0166 = 0.0885 + 0.9245 + 0.0035, time: 33.209990]
2023-06-12 20:49:07.302: epoch 24:	0.07930087  	0.14399785  	0.14461483  
2023-06-12 20:49:40.505: [iter 25 : loss : 1.0129 = 0.0853 + 0.9240 + 0.0036, time: 33.187268]
2023-06-12 20:49:40.903: epoch 25:	0.07880133  	0.14331731  	0.14376119  
2023-06-12 20:50:14.707: [iter 26 : loss : 1.0084 = 0.0811 + 0.9236 + 0.0037, time: 33.796940]
2023-06-12 20:50:15.103: epoch 26:	0.07856499  	0.14232320  	0.14302161  
2023-06-12 20:50:48.773: [iter 27 : loss : 1.0049 = 0.0778 + 0.9232 + 0.0038, time: 33.663171]
2023-06-12 20:50:49.171: epoch 27:	0.07823192  	0.14169009  	0.14215885  
2023-06-12 20:51:16.478: my pid: 11932
2023-06-12 20:51:16.478: model: model.general_recommender.SGL
2023-06-12 20:51:16.478: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 20:51:16.478: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 20:51:21.611: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-12 20:52:00.199: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 38.588567]
2023-06-12 20:52:00.610: epoch 1:	0.00331434  	0.00734849  	0.00643750  
2023-06-12 20:52:00.610: Find a better model.
2023-06-12 20:52:38.829: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 38.212257]
2023-06-12 20:52:39.233: epoch 2:	0.00402340  	0.00938057  	0.00780276  
2023-06-12 20:52:39.233: Find a better model.
2023-06-12 20:53:17.623: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 38.383166]
2023-06-12 20:53:18.026: epoch 3:	0.00507624  	0.01055637  	0.00893286  
2023-06-12 20:53:18.027: Find a better model.
2023-06-12 20:53:56.366: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 38.332059]
2023-06-12 20:53:56.767: epoch 4:	0.00546300  	0.01151542  	0.00965986  
2023-06-12 20:53:56.767: Find a better model.
2023-06-12 20:54:35.044: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 38.270495]
2023-06-12 20:54:35.466: epoch 5:	0.00641379  	0.01239533  	0.01094539  
2023-06-12 20:54:35.466: Find a better model.
2023-06-12 20:55:13.767: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 38.293988]
2023-06-12 20:55:14.171: epoch 6:	0.00772451  	0.01568698  	0.01374723  
2023-06-12 20:55:14.171: Find a better model.
2023-06-12 20:55:52.462: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 38.283425]
2023-06-12 20:55:52.863: epoch 7:	0.00857865  	0.01634379  	0.01484605  
2023-06-12 20:55:52.863: Find a better model.
2023-06-12 20:56:30.895: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 38.025635]
2023-06-12 20:56:31.320: epoch 8:	0.00980345  	0.01916631  	0.01706018  
2023-06-12 20:56:31.321: Find a better model.
2023-06-12 20:57:09.508: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 38.172153]
2023-06-12 20:57:09.919: epoch 9:	0.01139889  	0.02280196  	0.02033713  
2023-06-12 20:57:09.919: Find a better model.
2023-06-12 20:57:48.081: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 38.155020]
2023-06-12 20:57:48.502: epoch 10:	0.01327366  	0.02668142  	0.02470750  
2023-06-12 20:57:48.502: Find a better model.
2023-06-12 20:58:27.078: [iter 11 : loss : 1.6052 = 0.6921 + 0.9131 + 0.0000, time: 38.567058]
2023-06-12 20:58:27.498: epoch 11:	0.01582534  	0.03182322  	0.02958031  
2023-06-12 20:58:27.498: Find a better model.
2023-06-12 20:59:06.512: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 39.007202]
2023-06-12 20:59:06.916: epoch 12:	0.01929559  	0.03931639  	0.03642214  
2023-06-12 20:59:06.916: Find a better model.
2023-06-12 20:59:46.127: [iter 13 : loss : 1.6046 = 0.6911 + 0.9135 + 0.0000, time: 39.204010]
2023-06-12 20:59:46.540: epoch 13:	0.02358774  	0.04787140  	0.04561435  
2023-06-12 20:59:46.540: Find a better model.
2023-06-12 21:00:25.773: [iter 14 : loss : 1.6040 = 0.6901 + 0.9139 + 0.0000, time: 39.224983]
2023-06-12 21:00:26.176: epoch 14:	0.02935687  	0.06059671  	0.05719132  
2023-06-12 21:00:26.176: Find a better model.
2023-06-12 21:01:05.256: [iter 15 : loss : 1.6026 = 0.6883 + 0.9143 + 0.0001, time: 39.074220]
2023-06-12 21:01:05.666: epoch 15:	0.03736554  	0.07617891  	0.07382537  
2023-06-12 21:01:05.667: Find a better model.
2023-06-12 21:01:44.873: [iter 16 : loss : 1.5998 = 0.6847 + 0.9150 + 0.0001, time: 39.198306]
2023-06-12 21:01:45.274: epoch 16:	0.04747470  	0.09555506  	0.09369494  
2023-06-12 21:01:45.274: Find a better model.
2023-06-12 21:02:24.445: [iter 17 : loss : 1.5932 = 0.6769 + 0.9162 + 0.0001, time: 39.165064]
2023-06-12 21:02:24.846: epoch 17:	0.05913622  	0.11708698  	0.11532641  
2023-06-12 21:02:24.846: Find a better model.
2023-06-12 21:03:04.072: [iter 18 : loss : 1.5784 = 0.6597 + 0.9184 + 0.0002, time: 39.220237]
2023-06-12 21:03:04.494: epoch 18:	0.07035188  	0.13532549  	0.13524866  
2023-06-12 21:03:04.494: Find a better model.
2023-06-12 21:03:43.687: [iter 19 : loss : 1.5483 = 0.6256 + 0.9222 + 0.0004, time: 39.187080]
2023-06-12 21:03:44.094: epoch 19:	0.07720600  	0.14589074  	0.14760943  
2023-06-12 21:03:44.094: Find a better model.
2023-06-12 21:04:23.395: [iter 20 : loss : 1.5018 = 0.5732 + 0.9278 + 0.0008, time: 39.295037]
2023-06-12 21:04:23.795: epoch 20:	0.08130982  	0.15302810  	0.15476142  
2023-06-12 21:04:23.795: Find a better model.
2023-06-12 21:05:03.093: [iter 21 : loss : 1.4455 = 0.5103 + 0.9340 + 0.0012, time: 39.291908]
2023-06-12 21:05:03.514: epoch 21:	0.08320590  	0.15684645  	0.15804432  
2023-06-12 21:05:03.514: Find a better model.
2023-06-12 21:05:42.591: [iter 22 : loss : 1.3890 = 0.4480 + 0.9393 + 0.0017, time: 39.070043]
2023-06-12 21:05:42.988: epoch 22:	0.08464019  	0.16029434  	0.16066864  
2023-06-12 21:05:42.988: Find a better model.
2023-06-12 21:06:22.146: [iter 23 : loss : 1.3392 = 0.3940 + 0.9430 + 0.0022, time: 39.152202]
2023-06-12 21:06:22.559: epoch 23:	0.08551575  	0.16208963  	0.16250920  
2023-06-12 21:06:22.559: Find a better model.
2023-06-12 21:07:01.958: [iter 24 : loss : 1.2965 = 0.3487 + 0.9450 + 0.0027, time: 39.391154]
2023-06-12 21:07:02.381: epoch 24:	0.08653631  	0.16462055  	0.16401327  
2023-06-12 21:07:02.381: Find a better model.
2023-06-12 21:07:41.711: [iter 25 : loss : 1.2612 = 0.3124 + 0.9456 + 0.0032, time: 39.322346]
2023-06-12 21:07:42.111: epoch 25:	0.08692300  	0.16537604  	0.16437854  
2023-06-12 21:07:42.111: Find a better model.
2023-06-12 21:08:21.329: [iter 26 : loss : 1.2308 = 0.2815 + 0.9456 + 0.0037, time: 39.212034]
2023-06-12 21:08:21.729: epoch 26:	0.08732055  	0.16625264  	0.16480823  
2023-06-12 21:08:21.729: Find a better model.
2023-06-12 21:09:00.963: [iter 27 : loss : 1.2053 = 0.2561 + 0.9451 + 0.0041, time: 39.227243]
2023-06-12 21:09:01.392: epoch 27:	0.08732055  	0.16601786  	0.16489501  
2023-06-12 21:09:40.846: [iter 28 : loss : 1.1840 = 0.2351 + 0.9444 + 0.0045, time: 39.448051]
2023-06-12 21:09:41.277: epoch 28:	0.08763207  	0.16666016  	0.16522217  
2023-06-12 21:09:41.277: Find a better model.
2023-06-12 21:10:10.106: my pid: 14880
2023-06-12 21:10:10.106: model: model.general_recommender.SGL
2023-06-12 21:10:10.107: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 21:10:10.107: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 21:10:14.975: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-12 21:10:53.206: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 38.229812]
2023-06-12 21:10:53.625: epoch 1:	0.00338417  	0.00765856  	0.00619460  
2023-06-12 21:10:53.625: Find a better model.
2023-06-12 21:11:31.818: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 38.185396]
2023-06-12 21:11:32.225: epoch 2:	0.00371184  	0.00796943  	0.00671735  
2023-06-12 21:11:32.226: Find a better model.
2023-06-12 21:12:10.405: [iter 3 : loss : 1.6057 = 0.6930 + 0.9126 + 0.0000, time: 38.171875]
2023-06-12 21:12:10.836: epoch 3:	0.00511921  	0.01029075  	0.00878430  
2023-06-12 21:12:10.836: Find a better model.
2023-06-12 21:12:49.009: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 38.165562]
2023-06-12 21:12:49.436: epoch 4:	0.00572621  	0.01225033  	0.01038142  
2023-06-12 21:12:49.436: Find a better model.
2023-06-12 21:13:27.670: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 38.227605]
2023-06-12 21:13:28.077: epoch 5:	0.00661790  	0.01298141  	0.01170743  
2023-06-12 21:13:28.077: Find a better model.
2023-06-12 21:14:06.190: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 38.106686]
2023-06-12 21:14:06.610: epoch 6:	0.00785344  	0.01549213  	0.01382516  
2023-06-12 21:14:06.610: Find a better model.
2023-06-12 21:14:47.053: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 40.436904]
2023-06-12 21:14:47.477: epoch 7:	0.00863774  	0.01624420  	0.01500531  
2023-06-12 21:14:47.477: Find a better model.
2023-06-12 21:15:25.735: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 38.251276]
2023-06-12 21:15:26.135: epoch 8:	0.00942741  	0.01753901  	0.01670228  
2023-06-12 21:15:26.135: Find a better model.
2023-06-12 21:16:04.538: [iter 9 : loss : 1.6056 = 0.6925 + 0.9131 + 0.0000, time: 38.396073]
2023-06-12 21:16:04.940: epoch 9:	0.01157078  	0.02258874  	0.02077845  
2023-06-12 21:16:04.940: Find a better model.
2023-06-12 21:16:43.320: [iter 10 : loss : 1.6054 = 0.6923 + 0.9131 + 0.0000, time: 38.374095]
2023-06-12 21:16:43.722: epoch 10:	0.01363357  	0.02605279  	0.02392966  
2023-06-12 21:16:43.722: Find a better model.
2023-06-12 21:17:23.372: [iter 11 : loss : 1.6052 = 0.6920 + 0.9132 + 0.0000, time: 39.644766]
2023-06-12 21:17:23.796: epoch 11:	0.01647533  	0.03159960  	0.02988730  
2023-06-12 21:17:23.796: Find a better model.
2023-06-12 21:18:02.517: [iter 12 : loss : 1.6049 = 0.6916 + 0.9134 + 0.0000, time: 38.714325]
2023-06-12 21:18:02.919: epoch 12:	0.02014433  	0.03927943  	0.03761946  
2023-06-12 21:18:02.919: Find a better model.
2023-06-12 21:18:41.941: [iter 13 : loss : 1.6045 = 0.6909 + 0.9136 + 0.0000, time: 39.016265]
2023-06-12 21:18:42.371: epoch 13:	0.02473190  	0.04868311  	0.04695774  
2023-06-12 21:18:42.371: Find a better model.
2023-06-12 21:19:21.460: [iter 14 : loss : 1.6037 = 0.6897 + 0.9139 + 0.0000, time: 39.081975]
2023-06-12 21:19:21.860: epoch 14:	0.03032366  	0.06056010  	0.05891715  
2023-06-12 21:19:21.860: Find a better model.
2023-06-12 21:20:01.045: [iter 15 : loss : 1.6021 = 0.6876 + 0.9144 + 0.0001, time: 39.177686]
2023-06-12 21:20:01.468: epoch 15:	0.03895548  	0.07706068  	0.07639429  
2023-06-12 21:20:01.468: Find a better model.
2023-06-12 21:20:40.490: [iter 16 : loss : 1.5986 = 0.6833 + 0.9152 + 0.0001, time: 39.016211]
2023-06-12 21:20:40.916: epoch 16:	0.04962876  	0.09718754  	0.09650750  
2023-06-12 21:20:40.916: Find a better model.
2023-06-12 21:21:19.912: [iter 17 : loss : 1.5905 = 0.6739 + 0.9165 + 0.0002, time: 38.988708]
2023-06-12 21:21:20.366: epoch 17:	0.06175759  	0.11890423  	0.11901724  
2023-06-12 21:21:20.366: Find a better model.
2023-06-12 21:22:00.800: [iter 18 : loss : 1.5725 = 0.6532 + 0.9190 + 0.0003, time: 40.426909]
2023-06-12 21:22:01.199: epoch 18:	0.07126511  	0.13524094  	0.13638872  
2023-06-12 21:22:01.200: Find a better model.
2023-06-12 21:22:40.668: [iter 19 : loss : 1.5380 = 0.6141 + 0.9234 + 0.0005, time: 39.462260]
2023-06-12 21:22:41.065: epoch 19:	0.07765178  	0.14570987  	0.14731148  
2023-06-12 21:22:41.065: Find a better model.
2023-06-12 21:23:20.246: [iter 20 : loss : 1.4877 = 0.5573 + 0.9296 + 0.0009, time: 39.173913]
2023-06-12 21:23:20.646: epoch 20:	0.08131500  	0.15292615  	0.15358345  
2023-06-12 21:23:20.646: Find a better model.
2023-06-12 21:24:00.121: [iter 21 : loss : 1.4301 = 0.4927 + 0.9361 + 0.0013, time: 39.467664]
2023-06-12 21:24:00.534: epoch 21:	0.08337244  	0.15677193  	0.15711029  
2023-06-12 21:24:00.535: Find a better model.
2023-06-12 21:24:39.788: [iter 22 : loss : 1.3749 = 0.4318 + 0.9412 + 0.0018, time: 39.245421]
2023-06-12 21:24:40.183: epoch 22:	0.08469384  	0.15948352  	0.15929651  
2023-06-12 21:24:40.183: Find a better model.
2023-06-12 21:25:19.610: [iter 23 : loss : 1.3270 = 0.3803 + 0.9443 + 0.0024, time: 39.420303]
2023-06-12 21:25:20.013: epoch 23:	0.08565529  	0.16133544  	0.16066845  
2023-06-12 21:25:20.013: Find a better model.
2023-06-12 21:25:59.497: [iter 24 : loss : 1.2865 = 0.3378 + 0.9458 + 0.0029, time: 39.477463]
2023-06-12 21:25:59.895: epoch 24:	0.08661147  	0.16372372  	0.16214438  
2023-06-12 21:25:59.895: Find a better model.
2023-06-12 21:26:39.557: [iter 25 : loss : 1.2529 = 0.3034 + 0.9462 + 0.0033, time: 39.655313]
2023-06-12 21:26:39.953: epoch 25:	0.08674041  	0.16444944  	0.16259722  
2023-06-12 21:26:39.953: Find a better model.
2023-06-12 21:27:19.568: [iter 26 : loss : 1.2239 = 0.2743 + 0.9458 + 0.0038, time: 39.608437]
2023-06-12 21:27:19.964: epoch 26:	0.08725069  	0.16510318  	0.16302449  
2023-06-12 21:27:19.965: Find a better model.
2023-06-12 21:27:59.550: [iter 27 : loss : 1.1998 = 0.2505 + 0.9451 + 0.0042, time: 39.578267]
2023-06-12 21:27:59.950: epoch 27:	0.08747631  	0.16573319  	0.16334511  
2023-06-12 21:27:59.950: Find a better model.
2023-06-12 21:28:39.390: [iter 28 : loss : 1.1791 = 0.2301 + 0.9443 + 0.0047, time: 39.433762]
2023-06-12 21:28:39.785: epoch 28:	0.08739040  	0.16560794  	0.16327934  
2023-06-12 21:29:19.275: [iter 29 : loss : 1.1615 = 0.2133 + 0.9431 + 0.0051, time: 39.483433]
2023-06-12 21:29:19.677: epoch 29:	0.08751926  	0.16555285  	0.16320142  
2023-06-12 21:29:59.216: [iter 30 : loss : 1.1461 = 0.1985 + 0.9422 + 0.0054, time: 39.531318]
2023-06-12 21:29:59.618: epoch 30:	0.08767500  	0.16551827  	0.16313751  
2023-06-12 21:30:39.222: [iter 31 : loss : 1.1318 = 0.1850 + 0.9410 + 0.0058, time: 39.597608]
2023-06-12 21:30:39.627: epoch 31:	0.08740642  	0.16459490  	0.16267179  
2023-06-12 21:31:19.211: [iter 32 : loss : 1.1202 = 0.1741 + 0.9400 + 0.0062, time: 39.575952]
2023-06-12 21:31:19.623: epoch 32:	0.08744942  	0.16405523  	0.16253141  
2023-06-12 21:31:59.525: [iter 33 : loss : 1.1093 = 0.1638 + 0.9390 + 0.0065, time: 39.895931]
2023-06-12 21:31:59.925: epoch 33:	0.08723994  	0.16339147  	0.16190530  
2023-06-12 21:32:39.767: [iter 34 : loss : 1.1006 = 0.1557 + 0.9381 + 0.0068, time: 39.836746]
2023-06-12 21:32:40.172: epoch 34:	0.08727211  	0.16280359  	0.16152248  
2023-06-12 21:33:07.135: my pid: 15104
2023-06-12 21:33:07.135: model: model.general_recommender.SGL
2023-06-12 21:33:07.135: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 21:33:07.135: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 21:33:12.334: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-12 21:33:50.493: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 38.158530]
2023-06-12 21:33:50.895: epoch 1:	0.00338417  	0.00765856  	0.00619460  
2023-06-12 21:33:50.895: Find a better model.
2023-06-12 21:34:28.071: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 37.170242]
2023-06-12 21:34:28.481: epoch 2:	0.00371184  	0.00796943  	0.00671735  
2023-06-12 21:34:28.481: Find a better model.
2023-06-12 21:35:05.869: [iter 3 : loss : 1.6057 = 0.6930 + 0.9126 + 0.0000, time: 37.380987]
2023-06-12 21:35:06.271: epoch 3:	0.00511921  	0.01029075  	0.00878430  
2023-06-12 21:35:06.271: Find a better model.
2023-06-12 21:35:43.309: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 37.030642]
2023-06-12 21:35:43.711: epoch 4:	0.00572621  	0.01225033  	0.01038142  
2023-06-12 21:35:43.711: Find a better model.
2023-06-12 21:36:21.166: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.448028]
2023-06-12 21:36:21.568: epoch 5:	0.00661790  	0.01298141  	0.01170743  
2023-06-12 21:36:21.568: Find a better model.
2023-06-12 21:36:58.913: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.339321]
2023-06-12 21:36:59.321: epoch 6:	0.00785344  	0.01549213  	0.01382516  
2023-06-12 21:36:59.321: Find a better model.
2023-06-12 21:37:36.535: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 37.197961]
2023-06-12 21:37:36.922: epoch 7:	0.00863774  	0.01624420  	0.01500531  
2023-06-12 21:37:36.923: Find a better model.
2023-06-12 21:38:16.382: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 39.452835]
2023-06-12 21:38:16.769: epoch 8:	0.00942741  	0.01753901  	0.01670228  
2023-06-12 21:38:16.769: Find a better model.
2023-06-12 21:38:54.181: [iter 9 : loss : 1.6056 = 0.6925 + 0.9131 + 0.0000, time: 37.405078]
2023-06-12 21:38:54.575: epoch 9:	0.01157078  	0.02258874  	0.02077845  
2023-06-12 21:38:54.575: Find a better model.
2023-06-12 21:39:32.135: [iter 10 : loss : 1.6054 = 0.6923 + 0.9131 + 0.0000, time: 37.553614]
2023-06-12 21:39:32.530: epoch 10:	0.01363357  	0.02605279  	0.02392966  
2023-06-12 21:39:32.530: Find a better model.
2023-06-12 21:40:10.962: [iter 11 : loss : 1.6052 = 0.6920 + 0.9132 + 0.0000, time: 38.425723]
2023-06-12 21:40:11.372: epoch 11:	0.01647533  	0.03159960  	0.02988730  
2023-06-12 21:40:11.372: Find a better model.
2023-06-12 21:40:49.538: [iter 12 : loss : 1.6049 = 0.6916 + 0.9134 + 0.0000, time: 38.159997]
2023-06-12 21:40:49.924: epoch 12:	0.02014433  	0.03927943  	0.03761946  
2023-06-12 21:40:49.924: Find a better model.
2023-06-12 21:41:28.343: [iter 13 : loss : 1.6045 = 0.6909 + 0.9136 + 0.0000, time: 38.412724]
2023-06-12 21:41:28.729: epoch 13:	0.02473190  	0.04868311  	0.04695774  
2023-06-12 21:41:28.729: Find a better model.
2023-06-12 21:42:07.240: [iter 14 : loss : 1.6037 = 0.6897 + 0.9139 + 0.0000, time: 38.504903]
2023-06-12 21:42:07.633: epoch 14:	0.03032366  	0.06056010  	0.05891715  
2023-06-12 21:42:07.633: Find a better model.
2023-06-12 21:42:46.108: [iter 15 : loss : 1.6021 = 0.6876 + 0.9144 + 0.0001, time: 38.468141]
2023-06-12 21:42:46.511: epoch 15:	0.03895548  	0.07706068  	0.07639429  
2023-06-12 21:42:46.511: Find a better model.
2023-06-12 21:43:24.891: [iter 16 : loss : 1.5986 = 0.6833 + 0.9152 + 0.0001, time: 38.372742]
2023-06-12 21:43:25.274: epoch 16:	0.04962876  	0.09718754  	0.09650750  
2023-06-12 21:43:25.274: Find a better model.
2023-06-12 21:44:03.536: [iter 17 : loss : 1.5905 = 0.6739 + 0.9165 + 0.0002, time: 38.255208]
2023-06-12 21:44:03.919: epoch 17:	0.06175759  	0.11890423  	0.11901724  
2023-06-12 21:44:03.919: Find a better model.
2023-06-12 21:44:42.407: [iter 18 : loss : 1.5725 = 0.6532 + 0.9190 + 0.0003, time: 38.480597]
2023-06-12 21:44:42.788: epoch 18:	0.07126511  	0.13524094  	0.13638872  
2023-06-12 21:44:42.788: Find a better model.
2023-06-12 21:45:21.308: [iter 19 : loss : 1.5380 = 0.6141 + 0.9234 + 0.0005, time: 38.512586]
2023-06-12 21:45:21.690: epoch 19:	0.07765178  	0.14570987  	0.14731148  
2023-06-12 21:45:21.690: Find a better model.
2023-06-12 21:46:00.273: [iter 20 : loss : 1.4877 = 0.5573 + 0.9296 + 0.0009, time: 38.575753]
2023-06-12 21:46:00.651: epoch 20:	0.08131500  	0.15292615  	0.15358345  
2023-06-12 21:46:00.651: Find a better model.
2023-06-12 21:46:38.766: [iter 21 : loss : 1.4301 = 0.4927 + 0.9361 + 0.0013, time: 38.107622]
2023-06-12 21:46:39.149: epoch 21:	0.08337244  	0.15677193  	0.15711029  
2023-06-12 21:46:39.149: Find a better model.
2023-06-12 21:47:17.411: [iter 22 : loss : 1.3749 = 0.4318 + 0.9412 + 0.0018, time: 38.255861]
2023-06-12 21:47:17.790: epoch 22:	0.08469384  	0.15948352  	0.15929651  
2023-06-12 21:47:17.790: Find a better model.
2023-06-12 21:47:56.446: [iter 23 : loss : 1.3270 = 0.3803 + 0.9443 + 0.0024, time: 38.649002]
2023-06-12 21:47:56.828: epoch 23:	0.08565529  	0.16133544  	0.16066845  
2023-06-12 21:47:56.828: Find a better model.
2023-06-12 21:48:35.325: [iter 24 : loss : 1.2865 = 0.3378 + 0.9458 + 0.0029, time: 38.489747]
2023-06-12 21:48:35.709: epoch 24:	0.08661147  	0.16372372  	0.16214438  
2023-06-12 21:48:35.709: Find a better model.
2023-06-12 21:49:14.169: [iter 25 : loss : 1.2529 = 0.3034 + 0.9462 + 0.0033, time: 38.454189]
2023-06-12 21:49:14.562: epoch 25:	0.08674041  	0.16444944  	0.16259722  
2023-06-12 21:49:14.562: Find a better model.
2023-06-12 21:49:53.205: [iter 26 : loss : 1.2239 = 0.2743 + 0.9458 + 0.0038, time: 38.635886]
2023-06-12 21:49:53.592: epoch 26:	0.08725069  	0.16510318  	0.16302449  
2023-06-12 21:49:53.593: Find a better model.
2023-06-12 21:50:31.977: [iter 27 : loss : 1.1998 = 0.2505 + 0.9451 + 0.0042, time: 38.376464]
2023-06-12 21:50:32.377: epoch 27:	0.08747631  	0.16573319  	0.16334511  
2023-06-12 21:50:32.377: Find a better model.
2023-06-12 21:51:10.884: [iter 28 : loss : 1.1791 = 0.2301 + 0.9443 + 0.0047, time: 38.499172]
2023-06-12 21:51:11.265: epoch 28:	0.08739040  	0.16560794  	0.16327934  
2023-06-12 21:51:49.936: [iter 29 : loss : 1.1615 = 0.2133 + 0.9431 + 0.0051, time: 38.664120]
2023-06-12 21:51:50.339: epoch 29:	0.08751926  	0.16555285  	0.16320142  
2023-06-12 21:52:28.884: [iter 30 : loss : 1.1461 = 0.1985 + 0.9422 + 0.0054, time: 38.536337]
2023-06-12 21:52:29.265: epoch 30:	0.08767500  	0.16551827  	0.16313751  
2023-06-12 21:53:07.952: [iter 31 : loss : 1.1318 = 0.1850 + 0.9410 + 0.0058, time: 38.680398]
2023-06-12 21:53:08.358: epoch 31:	0.08740642  	0.16459490  	0.16267179  
2023-06-12 21:53:46.858: [iter 32 : loss : 1.1202 = 0.1741 + 0.9400 + 0.0062, time: 38.492030]
2023-06-12 21:53:47.238: epoch 32:	0.08744942  	0.16405523  	0.16253141  
2023-06-12 21:54:26.058: [iter 33 : loss : 1.1093 = 0.1638 + 0.9390 + 0.0065, time: 38.812564]
2023-06-12 21:54:26.456: epoch 33:	0.08723994  	0.16339147  	0.16190530  
2023-06-12 21:55:05.068: [iter 34 : loss : 1.1006 = 0.1557 + 0.9381 + 0.0068, time: 38.605392]
2023-06-12 21:55:05.466: epoch 34:	0.08727211  	0.16280359  	0.16152248  
2023-06-12 21:55:44.354: [iter 35 : loss : 1.0914 = 0.1470 + 0.9373 + 0.0071, time: 38.882319]
2023-06-12 21:55:44.735: epoch 35:	0.08710024  	0.16247749  	0.16114606  
2023-06-12 21:56:24.222: [iter 36 : loss : 1.0841 = 0.1402 + 0.9364 + 0.0074, time: 39.479821]
2023-06-12 21:56:24.647: epoch 36:	0.08693375  	0.16186674  	0.16068517  
2023-06-12 21:56:44.380: my pid: 11816
2023-06-12 21:56:44.381: model: model.general_recommender.SGL
2023-06-12 21:56:44.381: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-12 21:56:44.381: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-12 21:56:49.683: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-12 21:57:27.171: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 37.487046]
2023-06-12 21:57:27.577: epoch 1:	0.00338417  	0.00765856  	0.00619460  
2023-06-12 21:57:27.577: Find a better model.
2023-06-12 21:58:04.556: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 36.972594]
2023-06-12 21:58:04.963: epoch 2:	0.00371184  	0.00796943  	0.00671735  
2023-06-12 21:58:04.963: Find a better model.
2023-06-12 21:58:42.159: [iter 3 : loss : 1.6057 = 0.6930 + 0.9126 + 0.0000, time: 37.188961]
2023-06-12 21:58:42.560: epoch 3:	0.00511921  	0.01029075  	0.00878430  
2023-06-12 21:58:42.560: Find a better model.
2023-06-12 21:59:19.785: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 37.217474]
2023-06-12 21:59:20.187: epoch 4:	0.00572621  	0.01225033  	0.01038142  
2023-06-12 21:59:20.187: Find a better model.
2023-06-12 21:59:57.419: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.226467]
2023-06-12 21:59:57.818: epoch 5:	0.00661790  	0.01298141  	0.01170743  
2023-06-12 21:59:57.818: Find a better model.
2023-06-12 22:00:34.963: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.137163]
2023-06-12 22:00:35.386: epoch 6:	0.00785344  	0.01549213  	0.01382516  
2023-06-12 22:00:35.386: Find a better model.
2023-06-12 22:01:13.003: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 37.610961]
2023-06-12 22:01:13.394: epoch 7:	0.00863774  	0.01624420  	0.01500531  
2023-06-12 22:01:13.394: Find a better model.
2023-06-12 22:01:52.860: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 39.460355]
2023-06-12 22:01:53.249: epoch 8:	0.00942741  	0.01753901  	0.01670228  
2023-06-12 22:01:53.249: Find a better model.
2023-06-12 22:02:30.731: [iter 9 : loss : 1.6056 = 0.6925 + 0.9131 + 0.0000, time: 37.476166]
2023-06-12 22:02:31.119: epoch 9:	0.01157078  	0.02258874  	0.02077845  
2023-06-12 22:02:31.119: Find a better model.
2023-06-12 22:03:08.464: [iter 10 : loss : 1.6054 = 0.6923 + 0.9131 + 0.0000, time: 37.337970]
2023-06-12 22:03:08.851: epoch 10:	0.01363357  	0.02605279  	0.02392966  
2023-06-12 22:03:08.851: Find a better model.
2023-06-12 22:03:47.076: [iter 11 : loss : 1.6052 = 0.6920 + 0.9132 + 0.0000, time: 38.218241]
2023-06-12 22:03:47.478: epoch 11:	0.01647533  	0.03159960  	0.02988730  
2023-06-12 22:03:47.478: Find a better model.
2023-06-12 22:04:25.658: [iter 12 : loss : 1.6049 = 0.6916 + 0.9134 + 0.0000, time: 38.172646]
2023-06-12 22:04:26.043: epoch 12:	0.02014433  	0.03927943  	0.03761946  
2023-06-12 22:04:26.043: Find a better model.
2023-06-12 22:05:04.290: [iter 13 : loss : 1.6045 = 0.6909 + 0.9136 + 0.0000, time: 38.240370]
2023-06-12 22:05:04.679: epoch 13:	0.02473190  	0.04868311  	0.04695774  
2023-06-12 22:05:04.679: Find a better model.
2023-06-12 22:05:43.009: [iter 14 : loss : 1.6037 = 0.6897 + 0.9139 + 0.0000, time: 38.322833]
2023-06-12 22:05:43.412: epoch 14:	0.03032366  	0.06056010  	0.05891715  
2023-06-12 22:05:43.412: Find a better model.
2023-06-12 22:06:21.602: [iter 15 : loss : 1.6021 = 0.6876 + 0.9144 + 0.0001, time: 38.182485]
2023-06-12 22:06:21.981: epoch 15:	0.03895548  	0.07706068  	0.07639429  
2023-06-12 22:06:21.982: Find a better model.
2023-06-12 22:07:00.235: [iter 16 : loss : 1.5986 = 0.6833 + 0.9152 + 0.0001, time: 38.247717]
2023-06-12 22:07:00.625: epoch 16:	0.04962876  	0.09718754  	0.09650750  
2023-06-12 22:07:00.625: Find a better model.
2023-06-12 22:07:39.056: [iter 17 : loss : 1.5905 = 0.6739 + 0.9165 + 0.0002, time: 38.424940]
2023-06-12 22:07:39.455: epoch 17:	0.06175759  	0.11890423  	0.11901724  
2023-06-12 22:07:39.455: Find a better model.
2023-06-12 22:08:17.953: [iter 18 : loss : 1.5725 = 0.6532 + 0.9190 + 0.0003, time: 38.490572]
2023-06-12 22:08:18.359: epoch 18:	0.07126511  	0.13524094  	0.13638872  
2023-06-12 22:08:18.359: Find a better model.
2023-06-12 22:08:56.809: [iter 19 : loss : 1.5380 = 0.6141 + 0.9234 + 0.0005, time: 38.443366]
2023-06-12 22:08:57.192: epoch 19:	0.07765178  	0.14570987  	0.14731148  
2023-06-12 22:08:57.192: Find a better model.
2023-06-12 22:09:35.612: [iter 20 : loss : 1.4877 = 0.5573 + 0.9296 + 0.0009, time: 38.412713]
2023-06-12 22:09:35.999: epoch 20:	0.08131500  	0.15292615  	0.15358345  
2023-06-12 22:09:35.999: Find a better model.
2023-06-12 22:10:14.120: [iter 21 : loss : 1.4301 = 0.4927 + 0.9361 + 0.0013, time: 38.114978]
2023-06-12 22:10:14.517: epoch 21:	0.08337244  	0.15677193  	0.15711029  
2023-06-12 22:10:14.517: Find a better model.
2023-06-12 22:10:52.941: [iter 22 : loss : 1.3749 = 0.4318 + 0.9412 + 0.0018, time: 38.416477]
2023-06-12 22:10:53.352: epoch 22:	0.08469384  	0.15948352  	0.15929651  
2023-06-12 22:10:53.352: Find a better model.
2023-06-12 22:11:31.786: [iter 23 : loss : 1.3270 = 0.3803 + 0.9443 + 0.0024, time: 38.425991]
2023-06-12 22:11:32.167: epoch 23:	0.08565529  	0.16133544  	0.16066845  
2023-06-12 22:11:32.167: Find a better model.
2023-06-12 22:12:10.664: [iter 24 : loss : 1.2865 = 0.3378 + 0.9458 + 0.0029, time: 38.489641]
2023-06-12 22:12:11.045: epoch 24:	0.08661147  	0.16372372  	0.16214438  
2023-06-12 22:12:11.046: Find a better model.
2023-06-12 22:12:49.542: [iter 25 : loss : 1.2529 = 0.3034 + 0.9462 + 0.0033, time: 38.489469]
2023-06-12 22:12:49.924: epoch 25:	0.08674041  	0.16444944  	0.16259722  
2023-06-12 22:12:49.924: Find a better model.
2023-06-12 22:13:28.536: [iter 26 : loss : 1.2239 = 0.2743 + 0.9458 + 0.0038, time: 38.604477]
2023-06-12 22:13:28.919: epoch 26:	0.08725069  	0.16510318  	0.16302449  
2023-06-12 22:13:28.919: Find a better model.
2023-06-12 22:14:07.518: [iter 27 : loss : 1.1998 = 0.2505 + 0.9451 + 0.0042, time: 38.593497]
2023-06-12 22:14:07.900: epoch 27:	0.08747631  	0.16573319  	0.16334511  
2023-06-12 22:14:07.900: Find a better model.
2023-06-12 22:14:46.600: [iter 28 : loss : 1.1791 = 0.2301 + 0.9443 + 0.0047, time: 38.692713]
2023-06-12 22:14:46.986: epoch 28:	0.08739040  	0.16560794  	0.16327934  
2023-06-12 22:15:25.628: [iter 29 : loss : 1.1615 = 0.2133 + 0.9431 + 0.0051, time: 38.636346]
2023-06-12 22:15:26.010: epoch 29:	0.08751926  	0.16555285  	0.16320142  
2023-06-12 22:16:04.773: [iter 30 : loss : 1.1461 = 0.1985 + 0.9422 + 0.0054, time: 38.756462]
2023-06-12 22:16:05.155: epoch 30:	0.08767500  	0.16551827  	0.16313751  
2023-06-12 22:16:43.813: [iter 31 : loss : 1.1318 = 0.1850 + 0.9410 + 0.0058, time: 38.651255]
2023-06-12 22:16:44.197: epoch 31:	0.08740642  	0.16459490  	0.16267179  
2023-06-12 22:17:23.012: [iter 32 : loss : 1.1202 = 0.1741 + 0.9400 + 0.0062, time: 38.807820]
2023-06-12 22:17:23.412: epoch 32:	0.08744942  	0.16405523  	0.16253141  
2023-06-12 22:18:02.170: [iter 33 : loss : 1.1093 = 0.1638 + 0.9390 + 0.0065, time: 38.750986]
2023-06-12 22:18:02.561: epoch 33:	0.08723994  	0.16339147  	0.16190530  
2023-06-12 22:18:41.573: [iter 34 : loss : 1.1006 = 0.1557 + 0.9381 + 0.0068, time: 39.004985]
2023-06-12 22:18:41.955: epoch 34:	0.08727211  	0.16280359  	0.16152248  
2023-06-12 22:19:20.833: [iter 35 : loss : 1.0914 = 0.1470 + 0.9373 + 0.0071, time: 38.871181]
2023-06-12 22:19:21.214: epoch 35:	0.08710024  	0.16247749  	0.16114606  
2023-06-12 22:19:59.877: [iter 36 : loss : 1.0841 = 0.1402 + 0.9364 + 0.0074, time: 38.655582]
2023-06-12 22:20:00.265: epoch 36:	0.08693375  	0.16186674  	0.16068517  
2023-06-12 22:20:39.004: [iter 37 : loss : 1.0766 = 0.1333 + 0.9356 + 0.0077, time: 38.731181]
2023-06-12 22:20:39.409: epoch 37:	0.08655234  	0.16112302  	0.16013826  
2023-06-12 22:21:18.286: [iter 38 : loss : 1.0707 = 0.1278 + 0.9348 + 0.0080, time: 38.869958]
2023-06-12 22:21:18.669: epoch 38:	0.08653627  	0.16076143  	0.15985866  
2023-06-12 22:21:57.654: [iter 39 : loss : 1.0647 = 0.1223 + 0.9341 + 0.0083, time: 38.978978]
2023-06-12 22:21:58.035: epoch 39:	0.08624617  	0.16026503  	0.15952663  
2023-06-12 22:22:36.907: [iter 40 : loss : 1.0597 = 0.1177 + 0.9334 + 0.0086, time: 38.863977]
2023-06-12 22:22:37.290: epoch 40:	0.08607969  	0.15997401  	0.15891321  
2023-06-12 22:23:16.259: [iter 41 : loss : 1.0547 = 0.1132 + 0.9327 + 0.0088, time: 38.962970]
2023-06-12 22:23:16.645: epoch 41:	0.08577343  	0.15904123  	0.15814434  
2023-06-12 22:23:55.369: [iter 42 : loss : 1.0505 = 0.1092 + 0.9323 + 0.0091, time: 38.717816]
2023-06-12 22:23:55.753: epoch 42:	0.08553714  	0.15792377  	0.15749834  
2023-06-12 22:24:34.814: [iter 43 : loss : 1.0459 = 0.1049 + 0.9317 + 0.0093, time: 39.054615]
2023-06-12 22:24:35.197: epoch 43:	0.08554784  	0.15756434  	0.15711483  
2023-06-12 22:25:14.265: [iter 44 : loss : 1.0421 = 0.1013 + 0.9312 + 0.0096, time: 39.061967]
2023-06-12 22:25:14.650: epoch 44:	0.08529540  	0.15672173  	0.15643556  
2023-06-12 22:25:53.663: [iter 45 : loss : 1.0393 = 0.0988 + 0.9307 + 0.0098, time: 39.004964]
2023-06-12 22:25:54.046: epoch 45:	0.08513968  	0.15624267  	0.15585914  
2023-06-12 22:26:33.013: [iter 46 : loss : 1.0357 = 0.0954 + 0.9303 + 0.0100, time: 38.959855]
2023-06-12 22:26:33.414: epoch 46:	0.08480668  	0.15522026  	0.15521438  
2023-06-12 22:27:12.191: [iter 47 : loss : 1.0325 = 0.0925 + 0.9298 + 0.0102, time: 38.770001]
2023-06-12 22:27:12.581: epoch 47:	0.08466700  	0.15474090  	0.15456657  
2023-06-12 22:27:51.823: [iter 48 : loss : 1.0299 = 0.0900 + 0.9294 + 0.0104, time: 39.234738]
2023-06-12 22:27:52.205: epoch 48:	0.08459178  	0.15381171  	0.15392120  
2023-06-12 22:28:31.293: [iter 49 : loss : 1.0272 = 0.0875 + 0.9290 + 0.0107, time: 39.081058]
2023-06-12 22:28:31.674: epoch 49:	0.08429640  	0.15299807  	0.15336707  
2023-06-12 22:29:10.741: [iter 50 : loss : 1.0244 = 0.0850 + 0.9286 + 0.0109, time: 39.060284]
2023-06-12 22:29:11.127: epoch 50:	0.08397409  	0.15215221  	0.15256362  
2023-06-12 22:29:50.344: [iter 51 : loss : 1.0223 = 0.0829 + 0.9284 + 0.0110, time: 39.209971]
2023-06-12 22:29:50.732: epoch 51:	0.08384516  	0.15165864  	0.15215217  
2023-06-12 22:30:29.895: [iter 52 : loss : 1.0203 = 0.0810 + 0.9281 + 0.0112, time: 39.155950]
2023-06-12 22:30:30.278: epoch 52:	0.08360347  	0.15116854  	0.15168497  
2023-06-12 22:30:30.278: Early stopping is trigger at epoch: 52
2023-06-12 22:30:30.278: best_result@epoch 27:

2023-06-12 22:30:30.278: 		0.0875      	0.1657      	0.1633      
2023-06-13 09:14:02.072: my pid: 3704
2023-06-13 09:14:02.072: model: model.general_recommender.SGL
2023-06-13 09:14:02.072: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 09:14:02.072: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 09:14:06.830: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 09:14:44.432: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 37.600608]
2023-06-13 09:14:44.865: epoch 1:	0.00307261  	0.00705829  	0.00584905  
2023-06-13 09:14:44.865: Find a better model.
2023-06-13 09:15:22.223: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.351369]
2023-06-13 09:15:22.629: epoch 2:	0.00441016  	0.00968080  	0.00822038  
2023-06-13 09:15:22.630: Find a better model.
2023-06-13 09:16:00.218: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 37.581573]
2023-06-13 09:16:00.611: epoch 3:	0.00522128  	0.01134836  	0.00972930  
2023-06-13 09:16:00.611: Find a better model.
2023-06-13 09:16:37.969: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 37.351436]
2023-06-13 09:16:38.376: epoch 4:	0.00600017  	0.01209456  	0.01066851  
2023-06-13 09:16:38.377: Find a better model.
2023-06-13 09:17:15.833: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.449167]
2023-06-13 09:17:16.243: epoch 5:	0.00715509  	0.01452264  	0.01289094  
2023-06-13 09:17:16.243: Find a better model.
2023-06-13 09:17:53.797: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 37.548249]
2023-06-13 09:17:54.208: epoch 6:	0.00768154  	0.01485046  	0.01372305  
2023-06-13 09:17:54.208: Find a better model.
2023-06-13 09:18:34.068: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 39.854179]
2023-06-13 09:18:34.464: epoch 7:	0.00892782  	0.01778491  	0.01616124  
2023-06-13 09:18:34.464: Find a better model.
2023-06-13 09:19:12.053: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 37.582876]
2023-06-13 09:19:12.444: epoch 8:	0.00993775  	0.01964860  	0.01795743  
2023-06-13 09:19:12.444: Find a better model.
2023-06-13 09:19:50.108: [iter 9 : loss : 1.6056 = 0.6925 + 0.9130 + 0.0000, time: 37.657613]
2023-06-13 09:19:50.498: epoch 9:	0.01147409  	0.02184244  	0.02048319  
2023-06-13 09:19:50.498: Find a better model.
2023-06-13 09:20:28.074: [iter 10 : loss : 1.6054 = 0.6923 + 0.9131 + 0.0000, time: 37.570433]
2023-06-13 09:20:28.466: epoch 10:	0.01312864  	0.02638712  	0.02422930  
2023-06-13 09:20:28.466: Find a better model.
2023-06-13 09:21:06.892: [iter 11 : loss : 1.6052 = 0.6920 + 0.9131 + 0.0000, time: 38.418671]
2023-06-13 09:21:07.282: epoch 11:	0.01572327  	0.03183348  	0.02921871  
2023-06-13 09:21:07.283: Find a better model.
2023-06-13 09:21:45.931: [iter 12 : loss : 1.6050 = 0.6916 + 0.9133 + 0.0000, time: 38.640948]
2023-06-13 09:21:46.323: epoch 12:	0.01937615  	0.03818303  	0.03590516  
2023-06-13 09:21:46.323: Find a better model.
2023-06-13 09:22:24.861: [iter 13 : loss : 1.6046 = 0.6910 + 0.9136 + 0.0000, time: 38.531033]
2023-06-13 09:22:25.250: epoch 13:	0.02343731  	0.04745441  	0.04504065  
2023-06-13 09:22:25.250: Find a better model.
2023-06-13 09:23:03.775: [iter 14 : loss : 1.6038 = 0.6899 + 0.9139 + 0.0000, time: 38.517180]
2023-06-13 09:23:04.171: epoch 14:	0.02999605  	0.06073505  	0.05828450  
2023-06-13 09:23:04.171: Find a better model.
2023-06-13 09:23:42.793: [iter 15 : loss : 1.6022 = 0.6878 + 0.9144 + 0.0001, time: 38.614867]
2023-06-13 09:23:43.187: epoch 15:	0.03868148  	0.07827728  	0.07600808  
2023-06-13 09:23:43.188: Find a better model.
2023-06-13 09:24:21.867: [iter 16 : loss : 1.5990 = 0.6838 + 0.9151 + 0.0001, time: 38.672941]
2023-06-13 09:24:22.257: epoch 16:	0.04922045  	0.09645247  	0.09583414  
2023-06-13 09:24:22.257: Find a better model.
2023-06-13 09:25:01.012: [iter 17 : loss : 1.5914 = 0.6749 + 0.9164 + 0.0001, time: 38.747539]
2023-06-13 09:25:01.400: epoch 17:	0.06173071  	0.11775595  	0.11770049  
2023-06-13 09:25:01.400: Find a better model.
2023-06-13 09:25:39.978: [iter 18 : loss : 1.5742 = 0.6552 + 0.9188 + 0.0003, time: 38.569851]
2023-06-13 09:25:40.366: epoch 18:	0.07151756  	0.13483289  	0.13529044  
2023-06-13 09:25:40.366: Find a better model.
2023-06-13 09:26:18.982: [iter 19 : loss : 1.5408 = 0.6171 + 0.9232 + 0.0005, time: 38.608022]
2023-06-13 09:26:19.370: epoch 19:	0.07799552  	0.14609577  	0.14713198  
2023-06-13 09:26:19.370: Find a better model.
2023-06-13 09:26:57.978: [iter 20 : loss : 1.4910 = 0.5608 + 0.9293 + 0.0009, time: 38.600481]
2023-06-13 09:26:58.369: epoch 20:	0.08186287  	0.15281896  	0.15424922  
2023-06-13 09:26:58.369: Find a better model.
2023-06-13 09:27:36.924: [iter 21 : loss : 1.4332 = 0.4960 + 0.9359 + 0.0013, time: 38.548892]
2023-06-13 09:27:37.309: epoch 21:	0.08377513  	0.15696518  	0.15787216  
2023-06-13 09:27:37.309: Find a better model.
2023-06-13 09:28:15.984: [iter 22 : loss : 1.3777 = 0.4346 + 0.9413 + 0.0018, time: 38.667605]
2023-06-13 09:28:16.364: epoch 22:	0.08513956  	0.15972985  	0.16026969  
2023-06-13 09:28:16.364: Find a better model.
2023-06-13 09:28:55.183: [iter 23 : loss : 1.3294 = 0.3826 + 0.9444 + 0.0023, time: 38.811749]
2023-06-13 09:28:55.569: epoch 23:	0.08598290  	0.16148268  	0.16175187  
2023-06-13 09:28:55.570: Find a better model.
2023-06-13 09:29:34.285: [iter 24 : loss : 1.2884 = 0.3396 + 0.9460 + 0.0028, time: 38.708522]
2023-06-13 09:29:34.669: epoch 24:	0.08649860  	0.16301925  	0.16291896  
2023-06-13 09:29:34.669: Find a better model.
2023-06-13 09:30:13.338: [iter 25 : loss : 1.2545 = 0.3049 + 0.9463 + 0.0033, time: 38.662151]
2023-06-13 09:30:13.728: epoch 25:	0.08679399  	0.16343519  	0.16347024  
2023-06-13 09:30:13.728: Find a better model.
2023-06-13 09:30:52.590: [iter 26 : loss : 1.2254 = 0.2756 + 0.9460 + 0.0038, time: 38.856003]
2023-06-13 09:30:52.992: epoch 26:	0.08706801  	0.16364627  	0.16349274  
2023-06-13 09:30:52.992: Find a better model.
2023-06-13 09:31:31.480: [iter 27 : loss : 1.2008 = 0.2514 + 0.9452 + 0.0042, time: 38.479540]
2023-06-13 09:31:31.884: epoch 27:	0.08712170  	0.16354494  	0.16344190  
2023-06-13 09:32:10.595: [iter 28 : loss : 1.1801 = 0.2309 + 0.9445 + 0.0046, time: 38.703634]
2023-06-13 09:32:10.996: epoch 28:	0.08708952  	0.16372733  	0.16324317  
2023-06-13 09:32:10.996: Find a better model.
2023-06-13 09:32:49.857: [iter 29 : loss : 1.1625 = 0.2141 + 0.9434 + 0.0050, time: 38.853065]
2023-06-13 09:32:50.250: epoch 29:	0.08706266  	0.16357927  	0.16275536  
2023-06-13 09:33:29.210: [iter 30 : loss : 1.1466 = 0.1989 + 0.9423 + 0.0054, time: 38.954132]
2023-06-13 09:33:29.597: epoch 30:	0.08681022  	0.16292667  	0.16212617  
2023-06-13 09:34:08.421: [iter 31 : loss : 1.1325 = 0.1856 + 0.9412 + 0.0058, time: 38.816590]
2023-06-13 09:34:08.806: epoch 31:	0.08684248  	0.16286084  	0.16178851  
2023-06-13 09:34:47.577: [iter 32 : loss : 1.1208 = 0.1745 + 0.9402 + 0.0061, time: 38.764990]
2023-06-13 09:34:47.983: epoch 32:	0.08661693  	0.16252416  	0.16143911  
2023-06-13 09:35:27.012: [iter 33 : loss : 1.1097 = 0.1641 + 0.9392 + 0.0065, time: 39.022990]
2023-06-13 09:35:27.404: epoch 33:	0.08663302  	0.16250472  	0.16118686  
2023-06-13 09:36:06.604: [iter 34 : loss : 1.1008 = 0.1558 + 0.9382 + 0.0068, time: 39.192604]
2023-06-13 09:36:07.006: epoch 34:	0.08661149  	0.16243097  	0.16088015  
2023-06-13 09:36:47.857: [iter 35 : loss : 1.0917 = 0.1472 + 0.9374 + 0.0071, time: 40.845187]
2023-06-13 09:36:48.274: epoch 35:	0.08638597  	0.16181621  	0.16035290  
2023-06-13 09:37:07.473: my pid: 7192
2023-06-13 09:37:07.473: model: model.general_recommender.SGL
2023-06-13 09:37:07.473: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 09:37:07.473: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 09:37:12.699: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 09:37:50.348: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 37.649359]
2023-06-13 09:37:50.756: epoch 1:	0.00329822  	0.00820983  	0.00649548  
2023-06-13 09:37:50.756: Find a better model.
2023-06-13 09:38:28.119: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 37.357796]
2023-06-13 09:38:28.526: epoch 2:	0.00405563  	0.00909277  	0.00773999  
2023-06-13 09:38:28.527: Find a better model.
2023-06-13 09:39:05.908: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 37.374748]
2023-06-13 09:39:06.327: epoch 3:	0.00526425  	0.01151979  	0.00989079  
2023-06-13 09:39:06.327: Find a better model.
2023-06-13 09:39:43.674: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 37.340303]
2023-06-13 09:39:44.083: epoch 4:	0.00569935  	0.01156400  	0.01021302  
2023-06-13 09:39:44.083: Find a better model.
2023-06-13 09:40:21.528: [iter 5 : loss : 1.6055 = 0.6929 + 0.9125 + 0.0000, time: 37.437401]
2023-06-13 09:40:21.956: epoch 5:	0.00693484  	0.01417891  	0.01275199  
2023-06-13 09:40:21.956: Find a better model.
2023-06-13 09:40:59.678: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 37.714259]
2023-06-13 09:41:00.109: epoch 6:	0.00771377  	0.01568955  	0.01420714  
2023-06-13 09:41:00.109: Find a better model.
2023-06-13 09:41:37.612: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 37.497195]
2023-06-13 09:41:38.006: epoch 7:	0.00877204  	0.01763901  	0.01666114  
2023-06-13 09:41:38.006: Find a better model.
2023-06-13 09:42:17.575: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 39.563234]
2023-06-13 09:42:17.985: epoch 8:	0.00950261  	0.01905200  	0.01731170  
2023-06-13 09:42:17.986: Find a better model.
2023-06-13 09:42:55.627: [iter 9 : loss : 1.6055 = 0.6925 + 0.9129 + 0.0000, time: 37.635426]
2023-06-13 09:42:56.031: epoch 9:	0.01175881  	0.02387182  	0.02163914  
2023-06-13 09:42:56.032: Find a better model.
2023-06-13 09:43:33.604: [iter 10 : loss : 1.6054 = 0.6923 + 0.9130 + 0.0000, time: 37.564204]
2023-06-13 09:43:34.007: epoch 10:	0.01323607  	0.02574793  	0.02424686  
2023-06-13 09:43:34.007: Find a better model.
2023-06-13 09:44:12.157: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 38.144164]
2023-06-13 09:44:12.544: epoch 11:	0.01601334  	0.03148158  	0.03027921  
2023-06-13 09:44:12.544: Find a better model.
2023-06-13 09:44:50.918: [iter 12 : loss : 1.6050 = 0.6917 + 0.9133 + 0.0000, time: 38.368532]
2023-06-13 09:44:51.309: epoch 12:	0.01930094  	0.03828139  	0.03707097  
2023-06-13 09:44:51.309: Find a better model.
2023-06-13 09:45:29.763: [iter 13 : loss : 1.6046 = 0.6910 + 0.9135 + 0.0000, time: 38.447695]
2023-06-13 09:45:30.159: epoch 13:	0.02318484  	0.04695345  	0.04527042  
2023-06-13 09:45:30.159: Find a better model.
2023-06-13 09:46:08.562: [iter 14 : loss : 1.6039 = 0.6900 + 0.9138 + 0.0000, time: 38.396350]
2023-06-13 09:46:08.970: epoch 14:	0.02886274  	0.05830448  	0.05646978  
2023-06-13 09:46:08.970: Find a better model.
2023-06-13 09:46:47.320: [iter 15 : loss : 1.6025 = 0.6882 + 0.9143 + 0.0001, time: 38.343544]
2023-06-13 09:46:47.708: epoch 15:	0.03733335  	0.07459860  	0.07359762  
2023-06-13 09:46:47.709: Find a better model.
2023-06-13 09:47:25.897: [iter 16 : loss : 1.5995 = 0.6845 + 0.9150 + 0.0001, time: 38.181614]
2023-06-13 09:47:26.286: epoch 16:	0.04790981  	0.09465243  	0.09342773  
2023-06-13 09:47:26.286: Find a better model.
2023-06-13 09:48:04.929: [iter 17 : loss : 1.5927 = 0.6764 + 0.9162 + 0.0001, time: 38.635201]
2023-06-13 09:48:05.315: epoch 17:	0.05942624  	0.11523048  	0.11533154  
2023-06-13 09:48:05.315: Find a better model.
2023-06-13 09:48:43.922: [iter 18 : loss : 1.5774 = 0.6586 + 0.9185 + 0.0002, time: 38.600291]
2023-06-13 09:48:44.313: epoch 18:	0.07035724  	0.13411711  	0.13516933  
2023-06-13 09:48:44.313: Find a better model.
2023-06-13 09:49:22.911: [iter 19 : loss : 1.5467 = 0.6237 + 0.9225 + 0.0005, time: 38.591036]
2023-06-13 09:49:23.296: epoch 19:	0.07772166  	0.14623801  	0.14784072  
2023-06-13 09:49:23.296: Find a better model.
2023-06-13 09:50:01.920: [iter 20 : loss : 1.4992 = 0.5701 + 0.9282 + 0.0008, time: 38.617671]
2023-06-13 09:50:02.309: epoch 20:	0.08156213  	0.15321571  	0.15471283  
2023-06-13 09:50:02.309: Find a better model.
2023-06-13 09:50:40.693: [iter 21 : loss : 1.4422 = 0.5064 + 0.9346 + 0.0012, time: 38.377228]
2023-06-13 09:50:41.088: epoch 21:	0.08387735  	0.15697932  	0.15836994  
2023-06-13 09:50:41.088: Find a better model.
2023-06-13 09:51:19.862: [iter 22 : loss : 1.3858 = 0.4441 + 0.9400 + 0.0017, time: 38.766241]
2023-06-13 09:51:20.241: epoch 22:	0.08505367  	0.16007431  	0.16055942  
2023-06-13 09:51:20.241: Find a better model.
2023-06-13 09:51:58.807: [iter 23 : loss : 1.3363 = 0.3905 + 0.9435 + 0.0022, time: 38.559070]
2023-06-13 09:51:59.192: epoch 23:	0.08623543  	0.16196363  	0.16224736  
2023-06-13 09:51:59.193: Find a better model.
2023-06-13 09:52:38.607: [iter 24 : loss : 1.2942 = 0.3461 + 0.9454 + 0.0028, time: 39.408658]
2023-06-13 09:52:39.015: epoch 24:	0.08686385  	0.16332099  	0.16291147  
2023-06-13 09:52:39.015: Find a better model.
2023-06-13 09:53:17.829: [iter 25 : loss : 1.2595 = 0.3102 + 0.9461 + 0.0032, time: 38.805604]
2023-06-13 09:53:18.230: epoch 25:	0.08718085  	0.16395967  	0.16341995  
2023-06-13 09:53:18.230: Find a better model.
2023-06-13 09:53:56.974: [iter 26 : loss : 1.2293 = 0.2798 + 0.9458 + 0.0037, time: 38.737423]
2023-06-13 09:53:57.373: epoch 26:	0.08737423  	0.16469285  	0.16382650  
2023-06-13 09:53:57.374: Find a better model.
2023-06-13 09:54:35.987: [iter 27 : loss : 1.2042 = 0.2548 + 0.9452 + 0.0041, time: 38.606206]
2023-06-13 09:54:36.397: epoch 27:	0.08739034  	0.16436110  	0.16374475  
2023-06-13 09:55:15.191: [iter 28 : loss : 1.1829 = 0.2338 + 0.9445 + 0.0046, time: 38.787310]
2023-06-13 09:55:15.590: epoch 28:	0.08742251  	0.16451982  	0.16385379  
2023-06-13 09:55:56.109: [iter 29 : loss : 1.1648 = 0.2164 + 0.9435 + 0.0050, time: 40.512199]
2023-06-13 09:55:56.521: epoch 29:	0.08749239  	0.16429171  	0.16345274  
2023-06-13 09:56:36.339: [iter 30 : loss : 1.1491 = 0.2012 + 0.9425 + 0.0054, time: 39.809734]
2023-06-13 09:56:36.993: epoch 30:	0.08745484  	0.16434854  	0.16349316  
2023-06-13 09:57:17.655: [iter 31 : loss : 1.1344 = 0.1873 + 0.9413 + 0.0057, time: 40.652005]
2023-06-13 09:57:18.121: epoch 31:	0.08747098  	0.16442786  	0.16331983  
2023-06-13 09:58:01.668: [iter 32 : loss : 1.1228 = 0.1765 + 0.9402 + 0.0061, time: 43.539321]
2023-06-13 09:58:02.192: epoch 32:	0.08734748  	0.16394432  	0.16286066  
2023-06-13 09:58:09.468: my pid: 13072
2023-06-13 09:58:09.468: model: model.general_recommender.SGL
2023-06-13 09:58:09.468: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 09:58:09.468: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 09:58:15.328: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 09:58:59.181: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 43.851957]
2023-06-13 09:58:59.620: epoch 1:	0.00353458  	0.00901025  	0.00723370  
2023-06-13 09:58:59.620: Find a better model.
2023-06-13 09:59:41.767: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 42.139938]
2023-06-13 09:59:42.271: epoch 2:	0.00413083  	0.00968497  	0.00792988  
2023-06-13 09:59:42.271: Find a better model.
2023-06-13 10:00:24.484: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 42.204761]
2023-06-13 10:00:25.062: epoch 3:	0.00502252  	0.01084717  	0.00931875  
2023-06-13 10:00:25.062: Find a better model.
2023-06-13 10:01:05.824: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.752036]
2023-06-13 10:01:06.334: epoch 4:	0.00517830  	0.01158867  	0.00973839  
2023-06-13 10:01:06.334: Find a better model.
2023-06-13 10:01:49.822: [iter 5 : loss : 1.6056 = 0.6929 + 0.9126 + 0.0000, time: 43.476423]
2023-06-13 10:01:50.380: epoch 5:	0.00616669  	0.01320906  	0.01136707  
2023-06-13 10:01:50.380: Find a better model.
2023-06-13 10:02:37.726: [iter 6 : loss : 1.6056 = 0.6928 + 0.9127 + 0.0000, time: 47.338402]
2023-06-13 10:02:38.251: epoch 6:	0.00759021  	0.01567278  	0.01346537  
2023-06-13 10:02:38.251: Find a better model.
2023-06-13 10:03:25.219: [iter 7 : loss : 1.6056 = 0.6927 + 0.9129 + 0.0000, time: 46.960490]
2023-06-13 10:03:25.758: epoch 7:	0.00882575  	0.01788215  	0.01571670  
2023-06-13 10:03:25.759: Find a better model.
2023-06-13 10:04:12.642: [iter 8 : loss : 1.6055 = 0.6926 + 0.9128 + 0.0000, time: 46.875839]
2023-06-13 10:04:13.142: epoch 8:	0.00964228  	0.01932092  	0.01771905  
2023-06-13 10:04:13.142: Find a better model.
2023-06-13 10:04:59.740: [iter 9 : loss : 1.6055 = 0.6925 + 0.9131 + 0.0000, time: 46.592618]
2023-06-13 10:05:00.251: epoch 9:	0.01161376  	0.02321719  	0.02142632  
2023-06-13 10:05:00.251: Find a better model.
2023-06-13 10:05:47.145: [iter 10 : loss : 1.6053 = 0.6922 + 0.9131 + 0.0000, time: 46.881174]
2023-06-13 10:05:47.718: epoch 10:	0.01307490  	0.02657443  	0.02482238  
2023-06-13 10:05:47.718: Find a better model.
2023-06-13 10:06:35.579: [iter 11 : loss : 1.6051 = 0.6919 + 0.9132 + 0.0000, time: 47.855224]
2023-06-13 10:06:36.128: epoch 11:	0.01644309  	0.03274340  	0.03098698  
2023-06-13 10:06:36.129: Find a better model.
2023-06-13 10:07:23.950: [iter 12 : loss : 1.6048 = 0.6914 + 0.9134 + 0.0000, time: 47.814084]
2023-06-13 10:07:24.488: epoch 12:	0.02032696  	0.04107454  	0.03897017  
2023-06-13 10:07:24.488: Find a better model.
2023-06-13 10:08:12.535: [iter 13 : loss : 1.6044 = 0.6906 + 0.9137 + 0.0000, time: 48.040188]
2023-06-13 10:08:13.050: epoch 13:	0.02467282  	0.05103509  	0.04798564  
2023-06-13 10:08:13.050: Find a better model.
2023-06-13 10:08:54.893: [iter 14 : loss : 1.6034 = 0.6893 + 0.9140 + 0.0000, time: 41.836550]
2023-06-13 10:08:55.306: epoch 14:	0.03141945  	0.06478097  	0.06195331  
2023-06-13 10:08:55.306: Find a better model.
2023-06-13 10:09:36.256: [iter 15 : loss : 1.6015 = 0.6869 + 0.9146 + 0.0001, time: 40.944300]
2023-06-13 10:09:36.673: epoch 15:	0.04106651  	0.08316208  	0.08092666  
2023-06-13 10:09:36.673: Find a better model.
2023-06-13 10:10:17.201: [iter 16 : loss : 1.5973 = 0.6818 + 0.9154 + 0.0001, time: 40.520076]
2023-06-13 10:10:17.620: epoch 16:	0.05151946  	0.10207786  	0.10139287  
2023-06-13 10:10:17.620: Find a better model.
2023-06-13 10:10:59.056: [iter 17 : loss : 1.5877 = 0.6706 + 0.9170 + 0.0002, time: 41.429271]
2023-06-13 10:10:59.531: epoch 17:	0.06356225  	0.12296891  	0.12377834  
2023-06-13 10:10:59.531: Find a better model.
2023-06-13 10:11:43.499: [iter 18 : loss : 1.5667 = 0.6467 + 0.9198 + 0.0003, time: 43.961144]
2023-06-13 10:11:44.043: epoch 18:	0.07297307  	0.13902414  	0.14004241  
2023-06-13 10:11:44.043: Find a better model.
2023-06-13 10:12:26.300: [iter 19 : loss : 1.5288 = 0.6036 + 0.9245 + 0.0006, time: 42.251129]
2023-06-13 10:12:26.724: epoch 19:	0.07839303  	0.14800641  	0.14988616  
2023-06-13 10:12:26.724: Find a better model.
2023-06-13 10:13:08.737: [iter 20 : loss : 1.4764 = 0.5444 + 0.9310 + 0.0010, time: 42.006565]
2023-06-13 10:13:09.168: epoch 20:	0.08158899  	0.15355882  	0.15518309  
2023-06-13 10:13:09.168: Find a better model.
2023-06-13 10:13:51.668: [iter 21 : loss : 1.4190 = 0.4801 + 0.9374 + 0.0014, time: 42.492284]
2023-06-13 10:13:52.110: epoch 21:	0.08353353  	0.15757494  	0.15846281  
2023-06-13 10:13:52.110: Find a better model.
2023-06-13 10:14:34.884: [iter 22 : loss : 1.3652 = 0.4211 + 0.9421 + 0.0019, time: 42.766817]
2023-06-13 10:14:35.328: epoch 22:	0.08504824  	0.16065027  	0.16058113  
2023-06-13 10:14:35.328: Find a better model.
2023-06-13 10:15:21.724: [iter 23 : loss : 1.3188 = 0.3714 + 0.9449 + 0.0025, time: 46.388179]
2023-06-13 10:15:22.236: epoch 23:	0.08618170  	0.16277166  	0.16248876  
2023-06-13 10:15:22.236: Find a better model.
2023-06-13 10:16:11.454: [iter 24 : loss : 1.2798 = 0.3306 + 0.9462 + 0.0030, time: 49.209315]
2023-06-13 10:16:11.983: epoch 24:	0.08677261  	0.16405261  	0.16316475  
2023-06-13 10:16:11.983: Find a better model.
2023-06-13 10:17:00.190: [iter 25 : loss : 1.2473 = 0.2976 + 0.9463 + 0.0034, time: 48.198814]
2023-06-13 10:17:00.757: epoch 25:	0.08691222  	0.16475658  	0.16378282  
2023-06-13 10:17:00.757: Find a better model.
2023-06-13 10:17:49.240: [iter 26 : loss : 1.2195 = 0.2697 + 0.9459 + 0.0039, time: 48.474950]
2023-06-13 10:17:49.731: epoch 26:	0.08715391  	0.16518424  	0.16401619  
2023-06-13 10:17:49.732: Find a better model.
2023-06-13 10:18:38.034: [iter 27 : loss : 1.1958 = 0.2463 + 0.9451 + 0.0043, time: 48.294307]
2023-06-13 10:18:38.532: epoch 27:	0.08737420  	0.16545343  	0.16389826  
2023-06-13 10:18:38.532: Find a better model.
2023-06-13 10:19:20.369: [iter 28 : loss : 1.1758 = 0.2267 + 0.9443 + 0.0047, time: 41.829973]
2023-06-13 10:19:20.797: epoch 28:	0.08743329  	0.16547562  	0.16388227  
2023-06-13 10:19:20.797: Find a better model.
2023-06-13 10:20:02.361: [iter 29 : loss : 1.1588 = 0.2105 + 0.9432 + 0.0051, time: 41.558450]
2023-06-13 10:20:02.780: epoch 29:	0.08735807  	0.16521084  	0.16349009  
2023-06-13 10:20:43.773: [iter 30 : loss : 1.1435 = 0.1958 + 0.9421 + 0.0055, time: 40.987034]
2023-06-13 10:20:44.225: epoch 30:	0.08744404  	0.16474605  	0.16315719  
2023-06-13 10:21:24.531: [iter 31 : loss : 1.1297 = 0.1828 + 0.9410 + 0.0059, time: 40.300054]
2023-06-13 10:21:24.936: epoch 31:	0.08740111  	0.16436431  	0.16273421  
2023-06-13 10:22:03.784: [iter 32 : loss : 1.1184 = 0.1722 + 0.9400 + 0.0062, time: 38.840084]
2023-06-13 10:22:04.171: epoch 32:	0.08741724  	0.16447546  	0.16263250  
2023-06-13 10:22:42.773: [iter 33 : loss : 1.1078 = 0.1622 + 0.9390 + 0.0066, time: 38.595973]
2023-06-13 10:22:43.161: epoch 33:	0.08729910  	0.16385195  	0.16203177  
2023-06-13 10:23:21.927: [iter 34 : loss : 1.0990 = 0.1539 + 0.9382 + 0.0069, time: 38.758664]
2023-06-13 10:23:22.312: epoch 34:	0.08707344  	0.16329274  	0.16163285  
2023-06-13 10:24:01.366: [iter 35 : loss : 1.0901 = 0.1455 + 0.9373 + 0.0072, time: 39.045985]
2023-06-13 10:24:01.751: epoch 35:	0.08699290  	0.16296104  	0.16112030  
2023-06-13 10:24:40.645: [iter 36 : loss : 1.0827 = 0.1387 + 0.9365 + 0.0075, time: 38.886977]
2023-06-13 10:24:41.041: epoch 36:	0.08683706  	0.16240709  	0.16073763  
2023-06-13 10:25:19.804: [iter 37 : loss : 1.0755 = 0.1321 + 0.9356 + 0.0078, time: 38.757052]
2023-06-13 10:25:20.191: epoch 37:	0.08654163  	0.16133063  	0.16004401  
2023-06-13 10:25:59.272: [iter 38 : loss : 1.0695 = 0.1266 + 0.9349 + 0.0081, time: 39.074032]
2023-06-13 10:25:59.654: epoch 38:	0.08634288  	0.16059661  	0.15954375  
2023-06-13 10:26:38.468: [iter 39 : loss : 1.0640 = 0.1216 + 0.9341 + 0.0084, time: 38.805233]
2023-06-13 10:26:38.875: epoch 39:	0.08588094  	0.15918291  	0.15854259  
2023-06-13 10:27:18.040: [iter 40 : loss : 1.0592 = 0.1171 + 0.9335 + 0.0086, time: 39.157992]
2023-06-13 10:27:18.426: epoch 40:	0.08561770  	0.15841304  	0.15785721  
2023-06-13 10:27:57.580: [iter 41 : loss : 1.0541 = 0.1124 + 0.9328 + 0.0089, time: 39.147974]
2023-06-13 10:27:57.983: epoch 41:	0.08548884  	0.15777965  	0.15746431  
2023-06-13 10:28:37.000: [iter 42 : loss : 1.0498 = 0.1084 + 0.9323 + 0.0091, time: 39.011986]
2023-06-13 10:28:37.383: epoch 42:	0.08522563  	0.15696330  	0.15692678  
2023-06-13 10:29:16.394: [iter 43 : loss : 1.0454 = 0.1043 + 0.9317 + 0.0094, time: 39.004989]
2023-06-13 10:29:16.778: epoch 43:	0.08510751  	0.15639044  	0.15645196  
2023-06-13 10:29:55.767: [iter 44 : loss : 1.0415 = 0.1006 + 0.9313 + 0.0096, time: 38.983001]
2023-06-13 10:29:56.156: epoch 44:	0.08481202  	0.15562737  	0.15585096  
2023-06-13 10:30:35.415: [iter 45 : loss : 1.0387 = 0.0981 + 0.9307 + 0.0098, time: 39.252011]
2023-06-13 10:30:35.800: epoch 45:	0.08482276  	0.15553641  	0.15535842  
2023-06-13 10:31:15.166: [iter 46 : loss : 1.0353 = 0.0950 + 0.9303 + 0.0100, time: 39.360002]
2023-06-13 10:31:15.550: epoch 46:	0.08460254  	0.15504356  	0.15468009  
2023-06-13 10:31:54.920: [iter 47 : loss : 1.0321 = 0.0920 + 0.9298 + 0.0103, time: 39.361319]
2023-06-13 10:31:55.307: epoch 47:	0.08446293  	0.15438889  	0.15425317  
2023-06-13 10:32:34.711: [iter 48 : loss : 1.0290 = 0.0892 + 0.9294 + 0.0105, time: 39.397993]
2023-06-13 10:32:35.105: epoch 48:	0.08430716  	0.15376684  	0.15365188  
2023-06-13 10:33:14.513: [iter 49 : loss : 1.0267 = 0.0870 + 0.9290 + 0.0107, time: 39.402533]
2023-06-13 10:33:14.920: epoch 49:	0.08418364  	0.15330933  	0.15311608  
2023-06-13 10:33:54.138: [iter 50 : loss : 1.0243 = 0.0847 + 0.9287 + 0.0109, time: 39.210981]
2023-06-13 10:33:54.525: epoch 50:	0.08393655  	0.15258799  	0.15241522  
2023-06-13 10:34:34.131: [iter 51 : loss : 1.0218 = 0.0823 + 0.9284 + 0.0111, time: 39.599974]
2023-06-13 10:34:34.517: epoch 51:	0.08373776  	0.15175340  	0.15175095  
2023-06-13 10:35:14.056: [iter 52 : loss : 1.0199 = 0.0806 + 0.9281 + 0.0113, time: 39.531392]
2023-06-13 10:35:14.443: epoch 52:	0.08350679  	0.15130286  	0.15132639  
2023-06-13 10:35:54.059: [iter 53 : loss : 1.0176 = 0.0784 + 0.9278 + 0.0115, time: 39.610120]
2023-06-13 10:35:54.446: epoch 53:	0.08317379  	0.15060726  	0.15065907  
2023-06-13 10:35:54.446: Early stopping is trigger at epoch: 53
2023-06-13 10:35:54.446: best_result@epoch 28:

2023-06-13 10:35:54.447: 		0.0874      	0.1655      	0.1639      
2023-06-13 10:48:12.891: my pid: 13584
2023-06-13 10:48:12.891: model: model.general_recommender.SGL
2023-06-13 10:48:12.891: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 10:48:12.891: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 10:48:19.012: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 10:49:05.265: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 46.251699]
2023-06-13 10:49:05.840: epoch 1:	0.00286312  	0.00713173  	0.00567958  
2023-06-13 10:49:05.840: Find a better model.
2023-06-13 10:49:47.152: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 41.294805]
2023-06-13 10:49:47.578: epoch 2:	0.00350235  	0.00879855  	0.00689643  
2023-06-13 10:49:47.579: Find a better model.
2023-06-13 10:50:28.140: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.554088]
2023-06-13 10:50:28.593: epoch 3:	0.00452296  	0.01112597  	0.00874949  
2023-06-13 10:50:28.593: Find a better model.
2023-06-13 10:51:09.214: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.614268]
2023-06-13 10:51:09.716: epoch 4:	0.00498492  	0.01205145  	0.00965554  
2023-06-13 10:51:09.716: Find a better model.
2023-06-13 10:51:50.172: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.446656]
2023-06-13 10:51:50.640: epoch 5:	0.00590348  	0.01352153  	0.01133334  
2023-06-13 10:51:50.640: Find a better model.
2023-06-13 10:52:31.271: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 40.624449]
2023-06-13 10:52:31.709: epoch 6:	0.00658567  	0.01450626  	0.01216942  
2023-06-13 10:52:31.709: Find a better model.
2023-06-13 10:53:14.105: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 42.389206]
2023-06-13 10:53:14.530: epoch 7:	0.00735385  	0.01603389  	0.01392532  
2023-06-13 10:53:14.531: Find a better model.
2023-06-13 10:53:55.396: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 40.857034]
2023-06-13 10:53:55.928: epoch 8:	0.00851955  	0.01818416  	0.01602638  
2023-06-13 10:53:55.929: Find a better model.
2023-06-13 10:54:37.163: [iter 9 : loss : 1.6055 = 0.6925 + 0.9129 + 0.0000, time: 41.191752]
2023-06-13 10:54:37.582: epoch 9:	0.01030840  	0.02204186  	0.01911759  
2023-06-13 10:54:37.582: Find a better model.
2023-06-13 10:55:17.683: [iter 10 : loss : 1.6053 = 0.6923 + 0.9129 + 0.0000, time: 40.091326]
2023-06-13 10:55:18.193: epoch 10:	0.01179640  	0.02618817  	0.02224350  
2023-06-13 10:55:18.193: Find a better model.
2023-06-13 10:55:59.841: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 41.637966]
2023-06-13 10:56:00.285: epoch 11:	0.01445010  	0.03129447  	0.02794528  
2023-06-13 10:56:00.285: Find a better model.
2023-06-13 10:56:41.231: [iter 12 : loss : 1.6049 = 0.6917 + 0.9133 + 0.0000, time: 40.938448]
2023-06-13 10:56:41.718: epoch 12:	0.01760342  	0.03768428  	0.03389241  
2023-06-13 10:56:41.718: Find a better model.
2023-06-13 10:57:23.891: [iter 13 : loss : 1.6046 = 0.6911 + 0.9135 + 0.0000, time: 42.165470]
2023-06-13 10:57:24.397: epoch 13:	0.02135300  	0.04454996  	0.04152900  
2023-06-13 10:57:24.397: Find a better model.
2023-06-13 10:58:06.546: [iter 14 : loss : 1.6039 = 0.6900 + 0.9138 + 0.0000, time: 42.140580]
2023-06-13 10:58:06.990: epoch 14:	0.02713849  	0.05692746  	0.05304438  
2023-06-13 10:58:06.990: Find a better model.
2023-06-13 10:58:48.992: [iter 15 : loss : 1.6025 = 0.6882 + 0.9142 + 0.0001, time: 41.991150]
2023-06-13 10:58:49.502: epoch 15:	0.03480877  	0.07261801  	0.06878752  
2023-06-13 10:58:49.502: Find a better model.
2023-06-13 10:59:31.640: [iter 16 : loss : 1.5997 = 0.6847 + 0.9150 + 0.0001, time: 42.129569]
2023-06-13 10:59:32.108: epoch 16:	0.04467082  	0.09021790  	0.08786709  
2023-06-13 10:59:32.108: Find a better model.
2023-06-13 11:00:14.714: [iter 17 : loss : 1.5933 = 0.6770 + 0.9161 + 0.0001, time: 42.599581]
2023-06-13 11:00:15.146: epoch 17:	0.05761074  	0.11387283  	0.11101586  
2023-06-13 11:00:15.146: Find a better model.
2023-06-13 11:00:57.598: [iter 18 : loss : 1.5787 = 0.6600 + 0.9184 + 0.0002, time: 42.443539]
2023-06-13 11:00:58.167: epoch 18:	0.06819797  	0.13095778  	0.13094220  
2023-06-13 11:00:58.167: Find a better model.
2023-06-13 11:01:40.418: [iter 19 : loss : 1.5491 = 0.6264 + 0.9222 + 0.0004, time: 42.242821]
2023-06-13 11:01:40.886: epoch 19:	0.07608332  	0.14435801  	0.14461799  
2023-06-13 11:01:40.887: Find a better model.
2023-06-13 11:02:22.297: [iter 20 : loss : 1.5028 = 0.5741 + 0.9279 + 0.0008, time: 41.393779]
2023-06-13 11:02:22.729: epoch 20:	0.08045042  	0.15227358  	0.15229946  
2023-06-13 11:02:22.729: Find a better model.
2023-06-13 11:03:02.709: [iter 21 : loss : 1.4464 = 0.5108 + 0.9344 + 0.0012, time: 39.972821]
2023-06-13 11:03:03.121: epoch 21:	0.08290514  	0.15665953  	0.15670899  
2023-06-13 11:03:03.121: Find a better model.
2023-06-13 11:03:42.634: [iter 22 : loss : 1.3898 = 0.4482 + 0.9399 + 0.0017, time: 39.505951]
2023-06-13 11:03:43.047: epoch 22:	0.08444136  	0.15902664  	0.15909322  
2023-06-13 11:03:43.048: Find a better model.
2023-06-13 11:04:22.440: [iter 23 : loss : 1.3401 = 0.3942 + 0.9436 + 0.0022, time: 39.382895]
2023-06-13 11:04:22.867: epoch 23:	0.08554249  	0.16117142  	0.16111800  
2023-06-13 11:04:22.867: Find a better model.
2023-06-13 11:05:02.206: [iter 24 : loss : 1.2974 = 0.3490 + 0.9456 + 0.0027, time: 39.329228]
2023-06-13 11:05:02.602: epoch 24:	0.08618722  	0.16284098  	0.16230842  
2023-06-13 11:05:02.602: Find a better model.
2023-06-13 11:05:41.909: [iter 25 : loss : 1.2621 = 0.3126 + 0.9463 + 0.0032, time: 39.299314]
2023-06-13 11:05:42.307: epoch 25:	0.08649878  	0.16376896  	0.16296469  
2023-06-13 11:05:42.307: Find a better model.
2023-06-13 11:06:21.812: [iter 26 : loss : 1.2317 = 0.2818 + 0.9462 + 0.0037, time: 39.498522]
2023-06-13 11:06:22.210: epoch 26:	0.08674590  	0.16410734  	0.16339539  
2023-06-13 11:06:22.210: Find a better model.
2023-06-13 11:07:01.775: [iter 27 : loss : 1.2064 = 0.2567 + 0.9456 + 0.0041, time: 39.559125]
2023-06-13 11:07:02.178: epoch 27:	0.08713256  	0.16466776  	0.16391575  
2023-06-13 11:07:02.178: Find a better model.
2023-06-13 11:07:41.316: [iter 28 : loss : 1.1847 = 0.2353 + 0.9448 + 0.0045, time: 39.130361]
2023-06-13 11:07:41.714: epoch 28:	0.08723465  	0.16458784  	0.16402321  
2023-06-13 11:08:21.137: [iter 29 : loss : 1.1668 = 0.2180 + 0.9438 + 0.0049, time: 39.416462]
2023-06-13 11:08:21.538: epoch 29:	0.08706269  	0.16414337  	0.16374283  
2023-06-13 11:09:01.089: [iter 30 : loss : 1.1504 = 0.2024 + 0.9427 + 0.0053, time: 39.544693]
2023-06-13 11:09:01.486: epoch 30:	0.08703578  	0.16413714  	0.16360712  
2023-06-13 11:09:41.219: [iter 31 : loss : 1.1358 = 0.1885 + 0.9416 + 0.0057, time: 39.725897]
2023-06-13 11:09:41.619: epoch 31:	0.08710027  	0.16442910  	0.16364248  
2023-06-13 11:10:21.855: [iter 32 : loss : 1.1241 = 0.1775 + 0.9406 + 0.0061, time: 40.230650]
2023-06-13 11:10:22.258: epoch 32:	0.08707880  	0.16438474  	0.16347386  
2023-06-13 11:11:04.657: [iter 33 : loss : 1.1124 = 0.1664 + 0.9396 + 0.0064, time: 42.391617]
2023-06-13 11:11:05.122: epoch 33:	0.08714329  	0.16402221  	0.16326858  
2023-06-13 11:11:46.931: [iter 34 : loss : 1.1033 = 0.1579 + 0.9387 + 0.0067, time: 41.801936]
2023-06-13 11:11:47.375: epoch 34:	0.08698749  	0.16349290  	0.16270007  
2023-06-13 11:12:29.415: [iter 35 : loss : 1.0941 = 0.1492 + 0.9379 + 0.0071, time: 42.033535]
2023-06-13 11:12:29.996: epoch 35:	0.08710572  	0.16349049  	0.16255587  
2023-06-13 11:13:11.982: [iter 36 : loss : 1.0864 = 0.1421 + 0.9370 + 0.0073, time: 41.978070]
2023-06-13 11:13:12.431: epoch 36:	0.08693922  	0.16276924  	0.16196072  
2023-06-13 11:13:54.336: [iter 37 : loss : 1.0788 = 0.1350 + 0.9361 + 0.0077, time: 41.899961]
2023-06-13 11:13:54.775: epoch 37:	0.08668140  	0.16198541  	0.16124257  
2023-06-13 11:14:36.984: [iter 38 : loss : 1.0726 = 0.1292 + 0.9354 + 0.0079, time: 42.202003]
2023-06-13 11:14:37.399: epoch 38:	0.08659011  	0.16165039  	0.16090311  
2023-06-13 11:15:20.076: [iter 39 : loss : 1.0667 = 0.1239 + 0.9346 + 0.0082, time: 42.670579]
2023-06-13 11:15:20.526: epoch 39:	0.08639137  	0.16090280  	0.16028117  
2023-06-13 11:16:07.085: [iter 40 : loss : 1.0616 = 0.1192 + 0.9339 + 0.0085, time: 46.551197]
2023-06-13 11:16:07.656: epoch 40:	0.08620334  	0.16043326  	0.15986221  
2023-06-13 11:16:25.818: my pid: 15124
2023-06-13 11:16:25.818: model: model.general_recommender.SGL
2023-06-13 11:16:25.818: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 11:16:25.818: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 11:16:31.871: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 11:17:19.049: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 47.176147]
2023-06-13 11:17:19.581: epoch 1:	0.00286312  	0.00834406  	0.00592803  
2023-06-13 11:17:19.581: Find a better model.
2023-06-13 11:18:05.750: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 46.160361]
2023-06-13 11:18:06.291: epoch 2:	0.00353995  	0.00912924  	0.00701270  
2023-06-13 11:18:06.291: Find a better model.
2023-06-13 11:18:48.070: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 41.771895]
2023-06-13 11:18:48.575: epoch 3:	0.00441553  	0.01106305  	0.00874775  
2023-06-13 11:18:48.575: Find a better model.
2023-06-13 11:19:29.167: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.584505]
2023-06-13 11:19:29.591: epoch 4:	0.00497418  	0.01264040  	0.00970624  
2023-06-13 11:19:29.591: Find a better model.
2023-06-13 11:20:09.807: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 40.208930]
2023-06-13 11:20:10.356: epoch 5:	0.00561340  	0.01371013  	0.01077658  
2023-06-13 11:20:10.356: Find a better model.
2023-06-13 11:20:51.526: [iter 6 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 41.163023]
2023-06-13 11:20:52.003: epoch 6:	0.00677905  	0.01600496  	0.01306857  
2023-06-13 11:20:52.003: Find a better model.
2023-06-13 11:21:33.505: [iter 7 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 41.494862]
2023-06-13 11:21:33.985: epoch 7:	0.00776748  	0.01805804  	0.01523073  
2023-06-13 11:21:33.986: Find a better model.
2023-06-13 11:22:20.411: [iter 8 : loss : 1.6054 = 0.6926 + 0.9128 + 0.0000, time: 46.416022]
2023-06-13 11:22:20.941: epoch 8:	0.00883650  	0.01999701  	0.01680950  
2023-06-13 11:22:20.941: Find a better model.
2023-06-13 11:23:07.348: [iter 9 : loss : 1.6055 = 0.6924 + 0.9130 + 0.0000, time: 46.398049]
2023-06-13 11:23:07.908: epoch 9:	0.01031378  	0.02328327  	0.01985900  
2023-06-13 11:23:07.908: Find a better model.
2023-06-13 11:23:53.350: [iter 10 : loss : 1.6053 = 0.6922 + 0.9131 + 0.0000, time: 45.430585]
2023-06-13 11:23:53.824: epoch 10:	0.01238195  	0.02660097  	0.02354374  
2023-06-13 11:23:53.825: Find a better model.
2023-06-13 11:24:38.570: [iter 11 : loss : 1.6050 = 0.6919 + 0.9131 + 0.0000, time: 44.720829]
2023-06-13 11:24:39.065: epoch 11:	0.01521828  	0.03331403  	0.02975753  
2023-06-13 11:24:39.065: Find a better model.
2023-06-13 11:25:20.252: [iter 12 : loss : 1.6048 = 0.6914 + 0.9134 + 0.0000, time: 41.179377]
2023-06-13 11:25:20.654: epoch 12:	0.01908607  	0.04082770  	0.03742579  
2023-06-13 11:25:20.654: Find a better model.
2023-06-13 11:25:58.664: [iter 13 : loss : 1.6044 = 0.6907 + 0.9137 + 0.0000, time: 38.004054]
2023-06-13 11:25:59.074: epoch 13:	0.02303441  	0.04971240  	0.04638581  
2023-06-13 11:25:59.074: Find a better model.
2023-06-13 11:26:37.523: [iter 14 : loss : 1.6034 = 0.6894 + 0.9140 + 0.0000, time: 38.443128]
2023-06-13 11:26:37.928: epoch 14:	0.02941058  	0.06280950  	0.06011160  
2023-06-13 11:26:37.929: Find a better model.
2023-06-13 11:27:16.105: [iter 15 : loss : 1.6016 = 0.6870 + 0.9145 + 0.0001, time: 38.168904]
2023-06-13 11:27:16.502: epoch 15:	0.03849899  	0.08023170  	0.07708354  
2023-06-13 11:27:16.502: Find a better model.
2023-06-13 11:27:54.809: [iter 16 : loss : 1.5977 = 0.6823 + 0.9153 + 0.0001, time: 38.299001]
2023-06-13 11:27:55.207: epoch 16:	0.04923667  	0.09905418  	0.09738122  
2023-06-13 11:27:55.207: Find a better model.
2023-06-13 11:28:33.474: [iter 17 : loss : 1.5890 = 0.6720 + 0.9168 + 0.0002, time: 38.260490]
2023-06-13 11:28:33.897: epoch 17:	0.06203139  	0.12179188  	0.12052158  
2023-06-13 11:28:33.897: Find a better model.
2023-06-13 11:29:12.735: [iter 18 : loss : 1.5699 = 0.6501 + 0.9195 + 0.0003, time: 38.832023]
2023-06-13 11:29:13.125: epoch 18:	0.07223731  	0.13777675  	0.13853970  
2023-06-13 11:29:13.125: Find a better model.
2023-06-13 11:29:51.571: [iter 19 : loss : 1.5343 = 0.6098 + 0.9240 + 0.0006, time: 38.439793]
2023-06-13 11:29:51.971: epoch 19:	0.07841443  	0.14794971  	0.14901973  
2023-06-13 11:29:51.971: Find a better model.
2023-06-13 11:30:30.548: [iter 20 : loss : 1.4838 = 0.5528 + 0.9300 + 0.0009, time: 38.569262]
2023-06-13 11:30:30.947: epoch 20:	0.08187909  	0.15424176  	0.15511934  
2023-06-13 11:30:30.948: Find a better model.
2023-06-13 11:31:09.333: [iter 21 : loss : 1.4268 = 0.4889 + 0.9364 + 0.0014, time: 38.379651]
2023-06-13 11:31:09.715: epoch 21:	0.08387733  	0.15776928  	0.15823264  
2023-06-13 11:31:09.715: Find a better model.
2023-06-13 11:31:48.179: [iter 22 : loss : 1.3723 = 0.4289 + 0.9415 + 0.0019, time: 38.455627]
2023-06-13 11:31:48.559: epoch 22:	0.08515035  	0.16024548  	0.16055518  
2023-06-13 11:31:48.560: Find a better model.
2023-06-13 11:32:26.942: [iter 23 : loss : 1.3250 = 0.3781 + 0.9445 + 0.0024, time: 38.375718]
2023-06-13 11:32:27.326: epoch 23:	0.08631604  	0.16219032  	0.16222011  
2023-06-13 11:32:27.326: Find a better model.
2023-06-13 11:33:05.894: [iter 24 : loss : 1.2849 = 0.3360 + 0.9460 + 0.0029, time: 38.561199]
2023-06-13 11:33:06.280: epoch 24:	0.08694988  	0.16384920  	0.16335903  
2023-06-13 11:33:06.280: Find a better model.
2023-06-13 11:33:44.920: [iter 25 : loss : 1.2520 = 0.3022 + 0.9464 + 0.0034, time: 38.634318]
2023-06-13 11:33:45.302: epoch 25:	0.08763207  	0.16521783  	0.16438779  
2023-06-13 11:33:45.302: Find a better model.
2023-06-13 11:34:24.060: [iter 26 : loss : 1.2232 = 0.2733 + 0.9461 + 0.0038, time: 38.749620]
2023-06-13 11:34:24.444: epoch 26:	0.08762671  	0.16544034  	0.16453731  
2023-06-13 11:34:24.444: Find a better model.
2023-06-13 11:35:03.249: [iter 27 : loss : 1.1991 = 0.2494 + 0.9455 + 0.0043, time: 38.799132]
2023-06-13 11:35:03.632: epoch 27:	0.08782010  	0.16589914  	0.16466127  
2023-06-13 11:35:03.633: Find a better model.
2023-06-13 11:35:42.085: [iter 28 : loss : 1.1786 = 0.2293 + 0.9446 + 0.0047, time: 38.444872]
2023-06-13 11:35:42.470: epoch 28:	0.08802965  	0.16585809  	0.16458489  
2023-06-13 11:36:21.226: [iter 29 : loss : 1.1614 = 0.2128 + 0.9436 + 0.0051, time: 38.749117]
2023-06-13 11:36:21.606: epoch 29:	0.08806726  	0.16552873  	0.16455616  
2023-06-13 11:37:00.419: [iter 30 : loss : 1.1457 = 0.1977 + 0.9426 + 0.0054, time: 38.806116]
2023-06-13 11:37:00.802: epoch 30:	0.08801886  	0.16521922  	0.16432917  
2023-06-13 11:37:39.655: [iter 31 : loss : 1.1317 = 0.1845 + 0.9414 + 0.0058, time: 38.847059]
2023-06-13 11:37:40.045: epoch 31:	0.08797061  	0.16509074  	0.16418688  
2023-06-13 11:38:18.723: [iter 32 : loss : 1.1200 = 0.1734 + 0.9404 + 0.0062, time: 38.672384]
2023-06-13 11:38:19.111: epoch 32:	0.08788465  	0.16477889  	0.16403860  
2023-06-13 11:38:57.771: [iter 33 : loss : 1.1090 = 0.1631 + 0.9395 + 0.0065, time: 38.652240]
2023-06-13 11:38:58.156: epoch 33:	0.08780406  	0.16424869  	0.16374746  
2023-06-13 11:39:37.119: [iter 34 : loss : 1.1003 = 0.1549 + 0.9385 + 0.0068, time: 38.956050]
2023-06-13 11:39:37.503: epoch 34:	0.08773961  	0.16413538  	0.16355838  
2023-06-13 11:40:16.317: [iter 35 : loss : 1.0914 = 0.1466 + 0.9377 + 0.0072, time: 38.807373]
2023-06-13 11:40:16.701: epoch 35:	0.08735283  	0.16279663  	0.16280560  
2023-06-13 11:40:55.548: [iter 36 : loss : 1.0841 = 0.1398 + 0.9369 + 0.0074, time: 38.840723]
2023-06-13 11:40:55.950: epoch 36:	0.08697689  	0.16204429  	0.16243835  
2023-06-13 11:41:34.727: [iter 37 : loss : 1.0768 = 0.1331 + 0.9360 + 0.0077, time: 38.769218]
2023-06-13 11:41:35.116: epoch 37:	0.08674055  	0.16107161  	0.16159908  
2023-06-13 11:42:14.140: [iter 38 : loss : 1.0706 = 0.1274 + 0.9352 + 0.0080, time: 39.016923]
2023-06-13 11:42:14.526: epoch 38:	0.08655795  	0.16031535  	0.16093725  
2023-06-13 11:42:53.510: [iter 39 : loss : 1.0651 = 0.1222 + 0.9345 + 0.0083, time: 38.977768]
2023-06-13 11:42:53.917: epoch 39:	0.08635379  	0.16003226  	0.16046841  
2023-06-13 11:43:33.037: [iter 40 : loss : 1.0601 = 0.1177 + 0.9338 + 0.0086, time: 39.114699]
2023-06-13 11:43:33.421: epoch 40:	0.08602624  	0.15890266  	0.15963565  
2023-06-13 11:44:12.615: [iter 41 : loss : 1.0549 = 0.1130 + 0.9332 + 0.0088, time: 39.186982]
2023-06-13 11:44:13.013: epoch 41:	0.08585968  	0.15843323  	0.15898737  
2023-06-13 11:44:51.864: [iter 42 : loss : 1.0504 = 0.1086 + 0.9327 + 0.0091, time: 38.844269]
2023-06-13 11:44:52.254: epoch 42:	0.08585425  	0.15828894  	0.15872663  
2023-06-13 11:45:31.373: [iter 43 : loss : 1.0460 = 0.1046 + 0.9321 + 0.0093, time: 39.111946]
2023-06-13 11:45:31.760: epoch 43:	0.08565011  	0.15769598  	0.15810952  
2023-06-13 11:46:10.601: [iter 44 : loss : 1.0424 = 0.1012 + 0.9317 + 0.0096, time: 38.834486]
2023-06-13 11:46:10.997: epoch 44:	0.08547284  	0.15696503  	0.15757561  
2023-06-13 11:46:49.863: [iter 45 : loss : 1.0396 = 0.0986 + 0.9312 + 0.0098, time: 38.860236]
2023-06-13 11:46:50.246: epoch 45:	0.08529563  	0.15644392  	0.15711100  
2023-06-13 11:47:29.607: [iter 46 : loss : 1.0357 = 0.0950 + 0.9307 + 0.0100, time: 39.354787]
2023-06-13 11:47:30.006: epoch 46:	0.08513442  	0.15609059  	0.15673864  
2023-06-13 11:48:09.221: [iter 47 : loss : 1.0329 = 0.0925 + 0.9302 + 0.0102, time: 39.209052]
2023-06-13 11:48:09.608: epoch 47:	0.08491419  	0.15497625  	0.15609424  
2023-06-13 11:48:49.033: [iter 48 : loss : 1.0300 = 0.0897 + 0.9298 + 0.0104, time: 39.418593]
2023-06-13 11:48:49.418: epoch 48:	0.08464559  	0.15440640  	0.15541604  
2023-06-13 11:49:28.740: [iter 49 : loss : 1.0273 = 0.0872 + 0.9295 + 0.0106, time: 39.314587]
2023-06-13 11:49:29.128: epoch 49:	0.08443074  	0.15334712  	0.15462804  
2023-06-13 11:50:08.526: [iter 50 : loss : 1.0248 = 0.0849 + 0.9290 + 0.0109, time: 39.389230]
2023-06-13 11:50:08.932: epoch 50:	0.08425887  	0.15270807  	0.15405437  
2023-06-13 11:50:48.482: [iter 51 : loss : 1.0225 = 0.0828 + 0.9287 + 0.0110, time: 39.542965]
2023-06-13 11:50:48.888: epoch 51:	0.08411925  	0.15213013  	0.15349881  
2023-06-13 11:51:28.338: [iter 52 : loss : 1.0205 = 0.0808 + 0.9285 + 0.0112, time: 39.444046]
2023-06-13 11:51:28.721: epoch 52:	0.08395810  	0.15152587  	0.15293661  
2023-06-13 11:51:28.721: Early stopping is trigger at epoch: 52
2023-06-13 11:51:28.721: best_result@epoch 27:

2023-06-13 11:51:28.721: 		0.0878      	0.1659      	0.1647      
2023-06-13 14:39:03.633: my pid: 8636
2023-06-13 14:39:03.633: model: model.general_recommender.SGL
2023-06-13 14:39:03.634: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 14:39:03.634: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 14:39:09.080: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 14:39:50.314: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 41.232587]
2023-06-13 14:39:50.784: epoch 1:	0.00272345  	0.00749215  	0.00557737  
2023-06-13 14:39:50.784: Find a better model.
2023-06-13 14:40:32.461: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 41.668632]
2023-06-13 14:40:32.891: epoch 2:	0.00315856  	0.00882741  	0.00669713  
2023-06-13 14:40:32.891: Find a better model.
2023-06-13 14:41:13.079: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 40.180987]
2023-06-13 14:41:13.601: epoch 3:	0.00427586  	0.01184595  	0.00869479  
2023-06-13 14:41:13.601: Find a better model.
2023-06-13 14:41:54.690: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 41.083645]
2023-06-13 14:41:55.110: epoch 4:	0.00452833  	0.01199068  	0.00917923  
2023-06-13 14:41:55.110: Find a better model.
2023-06-13 14:42:36.791: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 41.673682]
2023-06-13 14:42:37.213: epoch 5:	0.00539317  	0.01329195  	0.01083292  
2023-06-13 14:42:37.213: Find a better model.
2023-06-13 14:43:17.508: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 40.288066]
2023-06-13 14:43:18.065: epoch 6:	0.00600553  	0.01522922  	0.01196603  
2023-06-13 14:43:18.065: Find a better model.
2023-06-13 14:43:59.276: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 41.202960]
2023-06-13 14:43:59.737: epoch 7:	0.00653733  	0.01659402  	0.01274451  
2023-06-13 14:43:59.737: Find a better model.
2023-06-13 14:44:40.056: [iter 8 : loss : 1.6053 = 0.6926 + 0.9127 + 0.0000, time: 40.312891]
2023-06-13 14:44:40.534: epoch 8:	0.00762245  	0.01824893  	0.01492043  
2023-06-13 14:44:40.534: Find a better model.
2023-06-13 14:45:21.911: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 41.367648]
2023-06-13 14:45:22.327: epoch 9:	0.00961543  	0.02289743  	0.01894769  
2023-06-13 14:45:22.327: Find a better model.
2023-06-13 14:46:02.961: [iter 10 : loss : 1.6052 = 0.6923 + 0.9130 + 0.0000, time: 40.626054]
2023-06-13 14:46:03.440: epoch 10:	0.01074890  	0.02512700  	0.02123591  
2023-06-13 14:46:03.440: Find a better model.
2023-06-13 14:46:45.587: [iter 11 : loss : 1.6050 = 0.6920 + 0.9131 + 0.0000, time: 42.139096]
2023-06-13 14:46:46.001: epoch 11:	0.01343483  	0.02998189  	0.02629483  
2023-06-13 14:46:46.001: Find a better model.
2023-06-13 14:47:27.384: [iter 12 : loss : 1.6048 = 0.6915 + 0.9133 + 0.0000, time: 41.373805]
2023-06-13 14:47:27.822: epoch 12:	0.01668486  	0.03677886  	0.03280284  
2023-06-13 14:47:27.822: Find a better model.
2023-06-13 14:48:09.742: [iter 13 : loss : 1.6044 = 0.6908 + 0.9136 + 0.0000, time: 41.912135]
2023-06-13 14:48:10.195: epoch 13:	0.02105221  	0.04634113  	0.04273431  
2023-06-13 14:48:10.195: Find a better model.
2023-06-13 14:48:51.690: [iter 14 : loss : 1.6036 = 0.6896 + 0.9139 + 0.0000, time: 41.483203]
2023-06-13 14:48:52.251: epoch 14:	0.02717076  	0.05906513  	0.05533533  
2023-06-13 14:48:52.251: Find a better model.
2023-06-13 14:49:35.313: [iter 15 : loss : 1.6019 = 0.6874 + 0.9144 + 0.0001, time: 43.054372]
2023-06-13 14:49:35.775: epoch 15:	0.03551240  	0.07448564  	0.07212919  
2023-06-13 14:49:35.776: Find a better model.
2023-06-13 14:50:17.899: [iter 16 : loss : 1.5984 = 0.6831 + 0.9152 + 0.0001, time: 42.108256]
2023-06-13 14:50:18.537: epoch 16:	0.04713099  	0.09557883  	0.09310421  
2023-06-13 14:50:18.537: Find a better model.
2023-06-13 14:51:02.074: [iter 17 : loss : 1.5904 = 0.6736 + 0.9167 + 0.0002, time: 43.530009]
2023-06-13 14:51:02.544: epoch 17:	0.05974314  	0.11728065  	0.11650898  
2023-06-13 14:51:02.544: Find a better model.
2023-06-13 14:51:44.971: [iter 18 : loss : 1.5727 = 0.6531 + 0.9193 + 0.0003, time: 42.419605]
2023-06-13 14:51:45.580: epoch 18:	0.06997589  	0.13427214  	0.13448757  
2023-06-13 14:51:45.580: Find a better model.
2023-06-13 14:52:28.467: [iter 19 : loss : 1.5392 = 0.6151 + 0.9236 + 0.0005, time: 42.878542]
2023-06-13 14:52:28.877: epoch 19:	0.07689980  	0.14514717  	0.14615071  
2023-06-13 14:52:28.877: Find a better model.
2023-06-13 14:53:11.138: [iter 20 : loss : 1.4909 = 0.5602 + 0.9298 + 0.0009, time: 42.253968]
2023-06-13 14:53:11.686: epoch 20:	0.08104654  	0.15261012  	0.15279451  
2023-06-13 14:53:11.686: Find a better model.
2023-06-13 14:53:54.465: [iter 21 : loss : 1.4350 = 0.4977 + 0.9360 + 0.0013, time: 42.771084]
2023-06-13 14:53:54.880: epoch 21:	0.08357124  	0.15737528  	0.15687057  
2023-06-13 14:53:54.880: Find a better model.
2023-06-13 14:54:37.080: [iter 22 : loss : 1.3809 = 0.4379 + 0.9411 + 0.0018, time: 42.193264]
2023-06-13 14:54:37.652: epoch 22:	0.08501080  	0.16073510  	0.15967357  
2023-06-13 14:54:37.654: Find a better model.
2023-06-13 14:55:20.304: [iter 23 : loss : 1.3332 = 0.3866 + 0.9443 + 0.0023, time: 42.642722]
2023-06-13 14:55:20.740: epoch 23:	0.08587566  	0.16222109  	0.16095917  
2023-06-13 14:55:20.740: Find a better model.
2023-06-13 14:56:02.553: [iter 24 : loss : 1.2923 = 0.3436 + 0.9459 + 0.0028, time: 41.805612]
2023-06-13 14:56:02.969: epoch 24:	0.08660082  	0.16394362  	0.16260515  
2023-06-13 14:56:02.969: Find a better model.
2023-06-13 14:56:45.260: [iter 25 : loss : 1.2585 = 0.3088 + 0.9464 + 0.0033, time: 42.283816]
2023-06-13 14:56:45.667: epoch 25:	0.08701986  	0.16508059  	0.16325226  
2023-06-13 14:56:45.667: Find a better model.
2023-06-13 14:57:25.249: [iter 26 : loss : 1.2290 = 0.2791 + 0.9461 + 0.0038, time: 39.576016]
2023-06-13 14:57:25.653: epoch 26:	0.08712187  	0.16493301  	0.16325721  
2023-06-13 14:58:05.007: [iter 27 : loss : 1.2042 = 0.2545 + 0.9455 + 0.0042, time: 39.346229]
2023-06-13 14:58:05.429: epoch 27:	0.08730453  	0.16493140  	0.16363734  
2023-06-13 14:58:45.287: [iter 28 : loss : 1.1832 = 0.2338 + 0.9448 + 0.0046, time: 39.849693]
2023-06-13 14:58:45.694: epoch 28:	0.08742807  	0.16496177  	0.16396199  
2023-06-13 14:59:26.819: [iter 29 : loss : 1.1653 = 0.2166 + 0.9438 + 0.0050, time: 41.118415]
2023-06-13 14:59:27.331: epoch 29:	0.08729368  	0.16455126  	0.16369225  
2023-06-13 15:00:10.088: [iter 30 : loss : 1.1494 = 0.2012 + 0.9428 + 0.0054, time: 42.749098]
2023-06-13 15:00:10.658: epoch 30:	0.08731514  	0.16424583  	0.16361672  
2023-06-13 15:00:53.495: [iter 31 : loss : 1.1351 = 0.1875 + 0.9417 + 0.0058, time: 42.831272]
2023-06-13 15:00:53.903: epoch 31:	0.08727758  	0.16384101  	0.16335227  
2023-06-13 15:01:35.308: [iter 32 : loss : 1.1233 = 0.1765 + 0.9407 + 0.0061, time: 41.398484]
2023-06-13 15:01:35.800: epoch 32:	0.08718632  	0.16349594  	0.16311541  
2023-06-13 15:02:18.182: [iter 33 : loss : 1.1119 = 0.1657 + 0.9397 + 0.0065, time: 42.374925]
2023-06-13 15:02:18.629: epoch 33:	0.08704660  	0.16300991  	0.16290413  
2023-06-13 15:03:00.244: [iter 34 : loss : 1.1029 = 0.1574 + 0.9387 + 0.0068, time: 41.607579]
2023-06-13 15:03:00.724: epoch 34:	0.08702514  	0.16266246  	0.16244122  
2023-06-13 15:03:43.160: [iter 35 : loss : 1.0936 = 0.1485 + 0.9380 + 0.0071, time: 42.428586]
2023-06-13 15:03:43.617: epoch 35:	0.08674582  	0.16172846  	0.16166171  
2023-06-13 15:04:25.765: [iter 36 : loss : 1.0860 = 0.1415 + 0.9371 + 0.0074, time: 42.139722]
2023-06-13 15:04:26.193: epoch 36:	0.08654706  	0.16088620  	0.16117355  
2023-06-13 15:05:09.440: [iter 37 : loss : 1.0786 = 0.1347 + 0.9362 + 0.0077, time: 43.239682]
2023-06-13 15:05:09.910: epoch 37:	0.08621939  	0.16001357  	0.16085847  
2023-06-13 15:05:52.534: [iter 38 : loss : 1.0721 = 0.1287 + 0.9354 + 0.0080, time: 42.616303]
2023-06-13 15:05:52.950: epoch 38:	0.08614962  	0.15929754  	0.16036862  
2023-06-13 15:06:34.948: [iter 39 : loss : 1.0668 = 0.1237 + 0.9348 + 0.0083, time: 41.991328]
2023-06-13 15:06:35.505: epoch 39:	0.08593474  	0.15873434  	0.15981334  
2023-06-13 15:07:18.698: [iter 40 : loss : 1.0615 = 0.1188 + 0.9341 + 0.0085, time: 43.187126]
2023-06-13 15:07:19.120: epoch 40:	0.08574677  	0.15803772  	0.15927199  
2023-06-13 15:08:01.482: [iter 41 : loss : 1.0562 = 0.1141 + 0.9334 + 0.0088, time: 42.355210]
2023-06-13 15:08:01.953: epoch 41:	0.08556418  	0.15728091  	0.15867262  
2023-06-13 15:08:45.022: [iter 42 : loss : 1.0518 = 0.1099 + 0.9328 + 0.0090, time: 43.061437]
2023-06-13 15:08:45.472: epoch 42:	0.08544068  	0.15648897  	0.15801880  
2023-06-13 15:09:28.081: [iter 43 : loss : 1.0473 = 0.1057 + 0.9323 + 0.0093, time: 42.601206]
2023-06-13 15:09:28.555: epoch 43:	0.08533865  	0.15634145  	0.15772888  
2023-06-13 15:10:11.318: [iter 44 : loss : 1.0435 = 0.1021 + 0.9319 + 0.0095, time: 42.757209]
2023-06-13 15:10:11.737: epoch 44:	0.08516677  	0.15563869  	0.15728959  
2023-06-13 15:10:54.763: [iter 45 : loss : 1.0406 = 0.0995 + 0.9313 + 0.0098, time: 43.018331]
2023-06-13 15:10:55.311: epoch 45:	0.08487134  	0.15447557  	0.15636961  
2023-06-13 15:11:37.935: [iter 46 : loss : 1.0371 = 0.0962 + 0.9309 + 0.0100, time: 42.612126]
2023-06-13 15:11:38.483: epoch 46:	0.08451148  	0.15398961  	0.15562929  
2023-06-13 15:12:20.906: [iter 47 : loss : 1.0338 = 0.0931 + 0.9304 + 0.0102, time: 42.413972]
2023-06-13 15:12:21.335: epoch 47:	0.08424827  	0.15311904  	0.15481709  
2023-06-13 15:13:04.816: [iter 48 : loss : 1.0308 = 0.0904 + 0.9300 + 0.0104, time: 43.475137]
2023-06-13 15:13:05.240: epoch 48:	0.08418915  	0.15280628  	0.15437734  
2023-06-13 15:13:48.073: [iter 49 : loss : 1.0280 = 0.0878 + 0.9295 + 0.0106, time: 42.825278]
2023-06-13 15:13:48.646: epoch 49:	0.08386146  	0.15218319  	0.15362735  
2023-06-13 15:14:31.288: [iter 50 : loss : 1.0255 = 0.0854 + 0.9292 + 0.0108, time: 42.635003]
2023-06-13 15:14:31.757: epoch 50:	0.08355530  	0.15150325  	0.15291880  
2023-06-13 15:14:31.757: Early stopping is trigger at epoch: 50
2023-06-13 15:14:31.757: best_result@epoch 25:

2023-06-13 15:14:31.757: 		0.0870      	0.1651      	0.1633      
2023-06-13 15:24:09.770: my pid: 16228
2023-06-13 15:24:09.770: model: model.general_recommender.SGL
2023-06-13 15:24:09.770: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 15:24:09.770: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 15:24:15.222: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 15:24:55.693: [iter 1 : loss : 1.6081 = 0.6931 + 0.9149 + 0.0000, time: 40.470304]
2023-06-13 15:24:56.199: epoch 1:	0.00254619  	0.00745429  	0.00548705  
2023-06-13 15:24:56.199: Find a better model.
2023-06-13 15:25:37.098: [iter 2 : loss : 1.6057 = 0.6931 + 0.9127 + 0.0000, time: 40.892376]
2023-06-13 15:25:37.579: epoch 2:	0.00296518  	0.00872861  	0.00619178  
2023-06-13 15:25:37.579: Find a better model.
2023-06-13 15:26:17.892: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 40.305534]
2023-06-13 15:26:18.417: epoch 3:	0.00364738  	0.01022288  	0.00753114  
2023-06-13 15:26:18.418: Find a better model.
2023-06-13 15:26:59.321: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.894469]
2023-06-13 15:26:59.784: epoch 4:	0.00425438  	0.01145276  	0.00845029  
2023-06-13 15:26:59.784: Find a better model.
2023-06-13 15:27:40.232: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.439880]
2023-06-13 15:27:40.690: epoch 5:	0.00485600  	0.01298664  	0.00972920  
2023-06-13 15:27:40.690: Find a better model.
2023-06-13 15:28:21.814: [iter 6 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 41.115983]
2023-06-13 15:28:22.267: epoch 6:	0.00558655  	0.01508454  	0.01132806  
2023-06-13 15:28:22.267: Find a better model.
2023-06-13 15:29:02.357: [iter 7 : loss : 1.6055 = 0.6927 + 0.9127 + 0.0000, time: 40.083791]
2023-06-13 15:29:02.835: epoch 7:	0.00657493  	0.01664910  	0.01333663  
2023-06-13 15:29:02.836: Find a better model.
2023-06-13 15:29:46.031: [iter 8 : loss : 1.6053 = 0.6926 + 0.9127 + 0.0000, time: 43.187145]
2023-06-13 15:29:46.512: epoch 8:	0.00732162  	0.01873642  	0.01492309  
2023-06-13 15:29:46.512: Find a better model.
2023-06-13 15:30:26.990: [iter 9 : loss : 1.6054 = 0.6925 + 0.9130 + 0.0000, time: 40.470074]
2023-06-13 15:30:27.537: epoch 9:	0.00853567  	0.02156768  	0.01804902  
2023-06-13 15:30:27.537: Find a better model.
2023-06-13 15:31:08.817: [iter 10 : loss : 1.6052 = 0.6923 + 0.9130 + 0.0000, time: 41.270930]
2023-06-13 15:31:09.245: epoch 10:	0.01007204  	0.02541688  	0.02101274  
2023-06-13 15:31:09.245: Find a better model.
2023-06-13 15:31:51.301: [iter 11 : loss : 1.6050 = 0.6919 + 0.9130 + 0.0000, time: 42.047583]
2023-06-13 15:31:51.727: epoch 11:	0.01252162  	0.03021731  	0.02632765  
2023-06-13 15:31:51.728: Find a better model.
2023-06-13 15:32:33.335: [iter 12 : loss : 1.6048 = 0.6915 + 0.9133 + 0.0000, time: 41.599579]
2023-06-13 15:32:33.898: epoch 12:	0.01559432  	0.03624566  	0.03206129  
2023-06-13 15:32:33.898: Find a better model.
2023-06-13 15:33:16.147: [iter 13 : loss : 1.6044 = 0.6908 + 0.9135 + 0.0000, time: 42.242711]
2023-06-13 15:33:16.680: epoch 13:	0.01951583  	0.04436234  	0.03997683  
2023-06-13 15:33:16.680: Find a better model.
2023-06-13 15:33:59.073: [iter 14 : loss : 1.6036 = 0.6896 + 0.9139 + 0.0000, time: 42.384931]
2023-06-13 15:33:59.559: epoch 14:	0.02515095  	0.05628148  	0.05172439  
2023-06-13 15:33:59.560: Find a better model.
2023-06-13 15:34:41.267: [iter 15 : loss : 1.6020 = 0.6875 + 0.9144 + 0.0001, time: 41.700047]
2023-06-13 15:34:41.722: epoch 15:	0.03431997  	0.07315782  	0.06893141  
2023-06-13 15:34:41.722: Find a better model.
2023-06-13 15:35:23.706: [iter 16 : loss : 1.5987 = 0.6833 + 0.9152 + 0.0001, time: 41.976512]
2023-06-13 15:35:24.153: epoch 16:	0.04560004  	0.09394502  	0.09086117  
2023-06-13 15:35:24.153: Find a better model.
2023-06-13 15:36:06.712: [iter 17 : loss : 1.5910 = 0.6743 + 0.9165 + 0.0001, time: 42.548620]
2023-06-13 15:36:07.148: epoch 17:	0.05872272  	0.11673941  	0.11501625  
2023-06-13 15:36:07.148: Find a better model.
2023-06-13 15:36:49.108: [iter 18 : loss : 1.5743 = 0.6550 + 0.9191 + 0.0003, time: 41.950091]
2023-06-13 15:36:49.658: epoch 18:	0.07021226  	0.13538110  	0.13524656  
2023-06-13 15:36:49.658: Find a better model.
2023-06-13 15:37:32.255: [iter 19 : loss : 1.5419 = 0.6182 + 0.9231 + 0.0005, time: 42.590217]
2023-06-13 15:37:32.786: epoch 19:	0.07728654  	0.14626522  	0.14743924  
2023-06-13 15:37:32.786: Find a better model.
2023-06-13 15:38:15.236: [iter 20 : loss : 1.4937 = 0.5637 + 0.9292 + 0.0008, time: 42.441876]
2023-06-13 15:38:15.696: epoch 20:	0.08133129  	0.15387069  	0.15432198  
2023-06-13 15:38:15.696: Find a better model.
2023-06-13 15:38:57.530: [iter 21 : loss : 1.4372 = 0.5002 + 0.9357 + 0.0013, time: 41.823019]
2023-06-13 15:38:58.080: epoch 21:	0.08351745  	0.15782520  	0.15807684  
2023-06-13 15:38:58.080: Find a better model.
2023-06-13 15:39:40.869: [iter 22 : loss : 1.3819 = 0.4390 + 0.9412 + 0.0018, time: 42.781172]
2023-06-13 15:39:41.411: epoch 22:	0.08458097  	0.16020131  	0.15995978  
2023-06-13 15:39:41.411: Find a better model.
2023-06-13 15:40:24.049: [iter 23 : loss : 1.3337 = 0.3868 + 0.9446 + 0.0023, time: 42.629238]
2023-06-13 15:40:24.603: epoch 23:	0.08577354  	0.16257691  	0.16188946  
2023-06-13 15:40:24.603: Find a better model.
2023-06-13 15:41:06.564: [iter 24 : loss : 1.2924 = 0.3432 + 0.9464 + 0.0028, time: 41.953032]
2023-06-13 15:41:07.108: epoch 24:	0.08645577  	0.16380729  	0.16304520  
2023-06-13 15:41:07.109: Find a better model.
2023-06-13 15:41:47.539: [iter 25 : loss : 1.2581 = 0.3080 + 0.9468 + 0.0033, time: 40.421304]
2023-06-13 15:41:47.935: epoch 25:	0.08690695  	0.16435692  	0.16358469  
2023-06-13 15:41:47.935: Find a better model.
2023-06-13 15:42:27.566: [iter 26 : loss : 1.2287 = 0.2784 + 0.9466 + 0.0037, time: 39.623283]
2023-06-13 15:42:27.962: epoch 26:	0.08701436  	0.16486926  	0.16340302  
2023-06-13 15:42:27.962: Find a better model.
2023-06-13 15:43:07.562: [iter 27 : loss : 1.2036 = 0.2536 + 0.9459 + 0.0042, time: 39.591981]
2023-06-13 15:43:07.958: epoch 27:	0.08740655  	0.16506371  	0.16394731  
2023-06-13 15:43:07.958: Find a better model.
2023-06-13 15:43:47.696: [iter 28 : loss : 1.1828 = 0.2330 + 0.9452 + 0.0046, time: 39.732509]
2023-06-13 15:43:48.092: epoch 28:	0.08756774  	0.16507787  	0.16394073  
2023-06-13 15:43:48.092: Find a better model.
2023-06-13 15:44:27.687: [iter 29 : loss : 1.1648 = 0.2159 + 0.9440 + 0.0050, time: 39.588967]
2023-06-13 15:44:28.091: epoch 29:	0.08768588  	0.16516361  	0.16391401  
2023-06-13 15:44:28.091: Find a better model.
2023-06-13 15:45:07.648: [iter 30 : loss : 1.1490 = 0.2006 + 0.9430 + 0.0054, time: 39.551003]
2023-06-13 15:45:08.041: epoch 30:	0.08750874  	0.16441751  	0.16337298  
2023-06-13 15:45:47.281: [iter 31 : loss : 1.1344 = 0.1867 + 0.9419 + 0.0057, time: 39.232960]
2023-06-13 15:45:47.686: epoch 31:	0.08734222  	0.16431768  	0.16311800  
2023-06-13 15:46:27.872: [iter 32 : loss : 1.1226 = 0.1757 + 0.9408 + 0.0061, time: 40.180220]
2023-06-13 15:46:28.278: epoch 32:	0.08721326  	0.16357557  	0.16278870  
2023-06-13 15:47:08.352: [iter 33 : loss : 1.1115 = 0.1652 + 0.9399 + 0.0064, time: 40.067688]
2023-06-13 15:47:08.779: epoch 33:	0.08726701  	0.16330841  	0.16264421  
2023-06-13 15:47:51.768: [iter 34 : loss : 1.1024 = 0.1567 + 0.9389 + 0.0068, time: 42.983158]
2023-06-13 15:47:52.185: epoch 34:	0.08719715  	0.16325960  	0.16250299  
2023-06-13 15:48:42.868: my pid: 9364
2023-06-13 15:48:42.868: model: model.general_recommender.SGL
2023-06-13 15:48:42.868: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 15:48:42.868: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 15:48:48.315: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 15:49:29.126: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 40.811025]
2023-06-13 15:49:29.607: epoch 1:	0.00239041  	0.00736513  	0.00501427  
2023-06-13 15:49:29.607: Find a better model.
2023-06-13 15:50:10.726: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 41.112064]
2023-06-13 15:50:11.148: epoch 2:	0.00297055  	0.00863721  	0.00630979  
2023-06-13 15:50:11.148: Find a better model.
2023-06-13 15:50:52.689: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 41.534134]
2023-06-13 15:50:53.119: epoch 3:	0.00377630  	0.01131611  	0.00848429  
2023-06-13 15:50:53.120: Find a better model.
2023-06-13 15:51:33.193: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.065656]
2023-06-13 15:51:33.655: epoch 4:	0.00402877  	0.01218804  	0.00877225  
2023-06-13 15:51:33.655: Find a better model.
2023-06-13 15:52:15.078: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 41.414078]
2023-06-13 15:52:15.570: epoch 5:	0.00493658  	0.01424454  	0.01056754  
2023-06-13 15:52:15.570: Find a better model.
2023-06-13 15:52:56.678: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 41.102385]
2023-06-13 15:52:57.122: epoch 6:	0.00530722  	0.01451822  	0.01084834  
2023-06-13 15:52:57.122: Find a better model.
2023-06-13 15:53:38.436: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 41.306625]
2023-06-13 15:53:38.864: epoch 7:	0.00609685  	0.01632496  	0.01253045  
2023-06-13 15:53:38.865: Find a better model.
2023-06-13 15:54:19.211: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 40.339176]
2023-06-13 15:54:19.674: epoch 8:	0.00719269  	0.01937586  	0.01522418  
2023-06-13 15:54:19.674: Find a better model.
2023-06-13 15:55:00.977: [iter 9 : loss : 1.6054 = 0.6925 + 0.9128 + 0.0000, time: 41.297187]
2023-06-13 15:55:01.435: epoch 9:	0.00842286  	0.02106219  	0.01722529  
2023-06-13 15:55:01.436: Find a better model.
2023-06-13 15:55:43.242: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 41.797645]
2023-06-13 15:55:43.694: epoch 10:	0.00972287  	0.02341548  	0.01983000  
2023-06-13 15:55:43.694: Find a better model.
2023-06-13 15:56:25.933: [iter 11 : loss : 1.6050 = 0.6920 + 0.9129 + 0.0000, time: 42.231424]
2023-06-13 15:56:26.442: epoch 11:	0.01143650  	0.02655275  	0.02272942  
2023-06-13 15:56:26.442: Find a better model.
2023-06-13 15:57:09.300: [iter 12 : loss : 1.6048 = 0.6916 + 0.9132 + 0.0000, time: 42.852958]
2023-06-13 15:57:09.750: epoch 12:	0.01452533  	0.03241597  	0.02833452  
2023-06-13 15:57:09.750: Find a better model.
2023-06-13 15:57:51.871: [iter 13 : loss : 1.6045 = 0.6910 + 0.9134 + 0.0000, time: 42.114123]
2023-06-13 15:57:52.416: epoch 13:	0.01769475  	0.04076682  	0.03551263  
2023-06-13 15:57:52.416: Find a better model.
2023-06-13 15:58:35.462: [iter 14 : loss : 1.6038 = 0.6900 + 0.9138 + 0.0000, time: 43.039401]
2023-06-13 15:58:35.913: epoch 14:	0.02409267  	0.05351366  	0.04741502  
2023-06-13 15:58:35.913: Find a better model.
2023-06-13 15:59:17.692: [iter 15 : loss : 1.6024 = 0.6881 + 0.9142 + 0.0001, time: 41.771652]
2023-06-13 15:59:18.226: epoch 15:	0.03184376  	0.06877314  	0.06374386  
2023-06-13 15:59:18.226: Find a better model.
2023-06-13 16:00:02.640: [iter 16 : loss : 1.5996 = 0.6845 + 0.9150 + 0.0001, time: 44.406695]
2023-06-13 16:00:03.075: epoch 16:	0.04245233  	0.08892660  	0.08454645  
2023-06-13 16:00:03.075: Find a better model.
2023-06-13 16:00:44.572: [iter 17 : loss : 1.5930 = 0.6767 + 0.9162 + 0.0001, time: 41.491587]
2023-06-13 16:00:45.088: epoch 17:	0.05583820  	0.11212116  	0.10928168  
2023-06-13 16:00:45.088: Find a better model.
2023-06-13 16:01:27.592: [iter 18 : loss : 1.5784 = 0.6597 + 0.9185 + 0.0002, time: 42.497163]
2023-06-13 16:01:28.044: epoch 18:	0.06778429  	0.13085119  	0.13044804  
2023-06-13 16:01:28.044: Find a better model.
2023-06-13 16:02:09.707: [iter 19 : loss : 1.5489 = 0.6262 + 0.9223 + 0.0004, time: 41.654742]
2023-06-13 16:02:10.158: epoch 19:	0.07549789  	0.14319548  	0.14431071  
2023-06-13 16:02:10.158: Find a better model.
2023-06-13 16:02:52.692: [iter 20 : loss : 1.5031 = 0.5741 + 0.9282 + 0.0008, time: 42.527279]
2023-06-13 16:02:53.192: epoch 20:	0.08010124  	0.15056404  	0.15159361  
2023-06-13 16:02:53.192: Find a better model.
2023-06-13 16:03:35.916: [iter 21 : loss : 1.4468 = 0.5108 + 0.9348 + 0.0012, time: 42.716470]
2023-06-13 16:03:36.359: epoch 21:	0.08266339  	0.15528275  	0.15606812  
2023-06-13 16:03:36.359: Find a better model.
2023-06-13 16:04:18.162: [iter 22 : loss : 1.3907 = 0.4486 + 0.9405 + 0.0017, time: 41.783564]
2023-06-13 16:04:18.685: epoch 22:	0.08423188  	0.15856603  	0.15872495  
2023-06-13 16:04:18.685: Find a better model.
2023-06-13 16:05:01.596: [iter 23 : loss : 1.3411 = 0.3947 + 0.9442 + 0.0022, time: 42.902959]
2023-06-13 16:05:02.028: epoch 23:	0.08526319  	0.16080618  	0.16034879  
2023-06-13 16:05:02.028: Find a better model.
2023-06-13 16:05:44.118: [iter 24 : loss : 1.2986 = 0.3498 + 0.9462 + 0.0027, time: 42.083433]
2023-06-13 16:05:44.715: epoch 24:	0.08616032  	0.16245468  	0.16177003  
2023-06-13 16:05:44.715: Find a better model.
2023-06-13 16:06:27.270: [iter 25 : loss : 1.2632 = 0.3134 + 0.9466 + 0.0032, time: 42.547078]
2023-06-13 16:06:27.696: epoch 25:	0.08649877  	0.16281849  	0.16238475  
2023-06-13 16:06:27.697: Find a better model.
2023-06-13 16:07:09.985: [iter 26 : loss : 1.2329 = 0.2827 + 0.9465 + 0.0037, time: 42.276276]
2023-06-13 16:07:10.590: epoch 26:	0.08686413  	0.16396466  	0.16308609  
2023-06-13 16:07:10.590: Find a better model.
2023-06-13 16:07:53.454: [iter 27 : loss : 1.2075 = 0.2575 + 0.9458 + 0.0041, time: 42.856038]
2023-06-13 16:07:53.879: epoch 27:	0.08691774  	0.16366407  	0.16288300  
2023-06-13 16:08:36.055: [iter 28 : loss : 1.1858 = 0.2361 + 0.9452 + 0.0045, time: 42.169344]
2023-06-13 16:08:36.663: epoch 28:	0.08745488  	0.16437376  	0.16336910  
2023-06-13 16:08:36.663: Find a better model.
2023-06-13 16:09:19.631: [iter 29 : loss : 1.1676 = 0.2186 + 0.9441 + 0.0049, time: 42.960700]
2023-06-13 16:09:20.049: epoch 29:	0.08740657  	0.16419706  	0.16311440  
2023-06-13 16:10:02.506: [iter 30 : loss : 1.1512 = 0.2028 + 0.9430 + 0.0053, time: 42.448945]
2023-06-13 16:10:03.054: epoch 30:	0.08746567  	0.16459557  	0.16306250  
2023-06-13 16:10:03.054: Find a better model.
2023-06-13 16:10:46.712: [iter 31 : loss : 1.1366 = 0.1889 + 0.9421 + 0.0057, time: 43.651701]
2023-06-13 16:10:47.148: epoch 31:	0.08736362  	0.16459443  	0.16296996  
2023-06-13 16:11:30.170: [iter 32 : loss : 1.1245 = 0.1775 + 0.9409 + 0.0060, time: 43.012816]
2023-06-13 16:11:30.741: epoch 32:	0.08747106  	0.16467297  	0.16291918  
2023-06-13 16:11:30.741: Find a better model.
2023-06-13 16:12:13.980: [iter 33 : loss : 1.1130 = 0.1666 + 0.9400 + 0.0064, time: 43.231860]
2023-06-13 16:12:14.433: epoch 33:	0.08734753  	0.16462322  	0.16277660  
2023-06-13 16:12:56.648: [iter 34 : loss : 1.1038 = 0.1580 + 0.9391 + 0.0067, time: 42.208376]
2023-06-13 16:12:57.214: epoch 34:	0.08730453  	0.16401026  	0.16226365  
2023-06-13 16:13:40.190: [iter 35 : loss : 1.0944 = 0.1492 + 0.9382 + 0.0070, time: 42.968978]
2023-06-13 16:13:40.626: epoch 35:	0.08739046  	0.16377553  	0.16189687  
2023-06-13 16:14:23.705: [iter 36 : loss : 1.0867 = 0.1420 + 0.9373 + 0.0073, time: 43.071881]
2023-06-13 16:14:24.224: epoch 36:	0.08719168  	0.16316365  	0.16141862  
2023-06-13 16:15:07.136: [iter 37 : loss : 1.0793 = 0.1352 + 0.9364 + 0.0076, time: 42.904619]
2023-06-13 16:15:07.578: epoch 37:	0.08696072  	0.16227113  	0.16101255  
2023-06-13 16:15:50.578: [iter 38 : loss : 1.0729 = 0.1293 + 0.9357 + 0.0079, time: 42.990037]
2023-06-13 16:15:51.087: epoch 38:	0.08693924  	0.16197021  	0.16081978  
2023-06-13 16:16:33.849: [iter 39 : loss : 1.0673 = 0.1241 + 0.9349 + 0.0082, time: 42.755717]
2023-06-13 16:16:34.269: epoch 39:	0.08684793  	0.16122182  	0.16001332  
2023-06-13 16:17:17.252: [iter 40 : loss : 1.0619 = 0.1192 + 0.9342 + 0.0085, time: 42.976054]
2023-06-13 16:17:17.787: epoch 40:	0.08655248  	0.16038904  	0.15941334  
2023-06-13 16:17:59.482: [iter 41 : loss : 1.0566 = 0.1143 + 0.9335 + 0.0087, time: 41.687957]
2023-06-13 16:17:59.887: epoch 41:	0.08633225  	0.15946645  	0.15872239  
2023-06-13 16:18:41.557: [iter 42 : loss : 1.0524 = 0.1104 + 0.9331 + 0.0090, time: 41.663475]
2023-06-13 16:18:41.957: epoch 42:	0.08613352  	0.15918875  	0.15830326  
2023-06-13 16:19:21.951: [iter 43 : loss : 1.0478 = 0.1061 + 0.9325 + 0.0092, time: 39.986666]
2023-06-13 16:19:22.354: epoch 43:	0.08587572  	0.15822566  	0.15769234  
2023-06-13 16:20:02.578: [iter 44 : loss : 1.0436 = 0.1021 + 0.9320 + 0.0095, time: 40.206801]
2023-06-13 16:20:02.978: epoch 44:	0.08564469  	0.15771818  	0.15730190  
2023-06-13 16:20:42.951: [iter 45 : loss : 1.0407 = 0.0996 + 0.9314 + 0.0097, time: 39.967160]
2023-06-13 16:20:43.358: epoch 45:	0.08522032  	0.15668288  	0.15634947  
2023-06-13 16:21:23.303: [iter 46 : loss : 1.0371 = 0.0962 + 0.9310 + 0.0099, time: 39.928213]
2023-06-13 16:21:23.710: epoch 46:	0.08494096  	0.15584582  	0.15590701  
2023-06-13 16:22:04.378: [iter 47 : loss : 1.0340 = 0.0933 + 0.9305 + 0.0102, time: 40.661589]
2023-06-13 16:22:04.793: epoch 47:	0.08476909  	0.15488391  	0.15519619  
2023-06-13 16:22:46.147: [iter 48 : loss : 1.0310 = 0.0905 + 0.9302 + 0.0104, time: 41.348041]
2023-06-13 16:22:46.711: epoch 48:	0.08461872  	0.15439634  	0.15470752  
2023-06-13 16:23:26.869: my pid: 15244
2023-06-13 16:23:26.869: model: model.general_recommender.SGL
2023-06-13 16:23:26.869: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 16:23:26.869: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 16:23:32.291: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 16:24:14.488: [iter 1 : loss : 1.6080 = 0.6931 + 0.9148 + 0.0000, time: 42.197413]
2023-06-13 16:24:14.922: epoch 1:	0.00287386  	0.00867634  	0.00606640  
2023-06-13 16:24:14.922: Find a better model.
2023-06-13 16:24:55.906: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 40.976965]
2023-06-13 16:24:56.353: epoch 2:	0.00316930  	0.00996075  	0.00683654  
2023-06-13 16:24:56.354: Find a better model.
2023-06-13 16:25:37.216: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.843794]
2023-06-13 16:25:37.688: epoch 3:	0.00404488  	0.01115138  	0.00835379  
2023-06-13 16:25:37.688: Find a better model.
2023-06-13 16:26:18.424: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.728502]
2023-06-13 16:26:18.851: epoch 4:	0.00486675  	0.01270134  	0.00984732  
2023-06-13 16:26:18.851: Find a better model.
2023-06-13 16:26:59.908: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 41.050659]
2023-06-13 16:27:00.339: epoch 5:	0.00549523  	0.01447934  	0.01118696  
2023-06-13 16:27:00.339: Find a better model.
2023-06-13 16:27:40.626: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 40.279565]
2023-06-13 16:27:41.057: epoch 6:	0.00588199  	0.01481013  	0.01182258  
2023-06-13 16:27:41.057: Find a better model.
2023-06-13 16:28:22.321: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 41.257631]
2023-06-13 16:28:22.835: epoch 7:	0.00703153  	0.01720778  	0.01379441  
2023-06-13 16:28:22.835: Find a better model.
2023-06-13 16:29:03.905: [iter 8 : loss : 1.6054 = 0.6926 + 0.9127 + 0.0000, time: 41.061462]
2023-06-13 16:29:04.317: epoch 8:	0.00782658  	0.01868621  	0.01572962  
2023-06-13 16:29:04.317: Find a better model.
2023-06-13 16:29:46.228: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 41.905044]
2023-06-13 16:29:46.693: epoch 9:	0.00957245  	0.02239622  	0.01874755  
2023-06-13 16:29:46.693: Find a better model.
2023-06-13 16:30:27.495: [iter 10 : loss : 1.6052 = 0.6923 + 0.9130 + 0.0000, time: 40.794788]
2023-06-13 16:30:28.007: epoch 10:	0.01081337  	0.02517262  	0.02152250  
2023-06-13 16:30:28.007: Find a better model.
2023-06-13 16:31:10.491: [iter 11 : loss : 1.6050 = 0.6919 + 0.9130 + 0.0000, time: 42.471534]
2023-06-13 16:31:11.059: epoch 11:	0.01382162  	0.03111447  	0.02742046  
2023-06-13 16:31:11.059: Find a better model.
2023-06-13 16:31:53.758: [iter 12 : loss : 1.6048 = 0.6915 + 0.9132 + 0.0000, time: 42.693019]
2023-06-13 16:31:54.198: epoch 12:	0.01709849  	0.03835378  	0.03385881  
2023-06-13 16:31:54.198: Find a better model.
2023-06-13 16:32:35.502: [iter 13 : loss : 1.6044 = 0.6908 + 0.9136 + 0.0000, time: 41.296314]
2023-06-13 16:32:35.945: epoch 13:	0.02150883  	0.04706940  	0.04239446  
2023-06-13 16:32:35.945: Find a better model.
2023-06-13 16:33:18.562: [iter 14 : loss : 1.6035 = 0.6896 + 0.9139 + 0.0000, time: 42.610696]
2023-06-13 16:33:18.977: epoch 14:	0.02746620  	0.06009893  	0.05503566  
2023-06-13 16:33:18.977: Find a better model.
2023-06-13 16:34:01.677: [iter 15 : loss : 1.6018 = 0.6873 + 0.9144 + 0.0001, time: 42.691612]
2023-06-13 16:34:02.112: epoch 15:	0.03626435  	0.07630010  	0.07247534  
2023-06-13 16:34:02.112: Find a better model.
2023-06-13 16:34:44.234: [iter 16 : loss : 1.5983 = 0.6828 + 0.9154 + 0.0001, time: 42.114487]
2023-06-13 16:34:44.748: epoch 16:	0.04717387  	0.09584837  	0.09347056  
2023-06-13 16:34:44.749: Find a better model.
2023-06-13 16:35:27.512: [iter 17 : loss : 1.5900 = 0.6730 + 0.9168 + 0.0002, time: 42.754574]
2023-06-13 16:35:27.958: epoch 17:	0.05929742  	0.11607810  	0.11505950  
2023-06-13 16:35:27.958: Find a better model.
2023-06-13 16:36:09.428: [iter 18 : loss : 1.5718 = 0.6520 + 0.9196 + 0.0003, time: 41.463484]
2023-06-13 16:36:09.901: epoch 18:	0.07006719  	0.13299970  	0.13332102  
2023-06-13 16:36:09.902: Find a better model.
2023-06-13 16:36:52.667: [iter 19 : loss : 1.5380 = 0.6134 + 0.9241 + 0.0005, time: 42.758585]
2023-06-13 16:36:53.096: epoch 19:	0.07689442  	0.14384019  	0.14505348  
2023-06-13 16:36:53.096: Find a better model.
2023-06-13 16:37:34.570: [iter 20 : loss : 1.4895 = 0.5583 + 0.9303 + 0.0009, time: 41.465503]
2023-06-13 16:37:34.992: epoch 20:	0.08048256  	0.15052538  	0.15139133  
2023-06-13 16:37:34.992: Find a better model.
2023-06-13 16:38:17.409: [iter 21 : loss : 1.4336 = 0.4959 + 0.9363 + 0.0014, time: 42.408695]
2023-06-13 16:38:17.921: epoch 21:	0.08267410  	0.15488021  	0.15511188  
2023-06-13 16:38:17.921: Find a better model.
2023-06-13 16:38:59.717: [iter 22 : loss : 1.3799 = 0.4366 + 0.9415 + 0.0018, time: 41.789155]
2023-06-13 16:39:00.173: epoch 22:	0.08408684  	0.15787996  	0.15781705  
2023-06-13 16:39:00.173: Find a better model.
2023-06-13 16:39:43.495: [iter 23 : loss : 1.3326 = 0.3857 + 0.9445 + 0.0024, time: 43.315748]
2023-06-13 16:39:44.023: epoch 23:	0.08520951  	0.16026573  	0.15976892  
2023-06-13 16:39:44.023: Find a better model.
2023-06-13 16:40:25.292: [iter 24 : loss : 1.2919 = 0.3428 + 0.9462 + 0.0028, time: 41.261601]
2023-06-13 16:40:25.763: epoch 24:	0.08614419  	0.16235441  	0.16108787  
2023-06-13 16:40:25.763: Find a better model.
2023-06-13 16:41:07.700: [iter 25 : loss : 1.2580 = 0.3081 + 0.9465 + 0.0033, time: 41.929455]
2023-06-13 16:41:08.139: epoch 25:	0.08650406  	0.16336212  	0.16186467  
2023-06-13 16:41:08.139: Find a better model.
2023-06-13 16:41:50.787: [iter 26 : loss : 1.2288 = 0.2786 + 0.9465 + 0.0038, time: 42.640378]
2023-06-13 16:41:51.213: epoch 26:	0.08668669  	0.16362524  	0.16227403  
2023-06-13 16:41:51.213: Find a better model.
2023-06-13 16:42:32.275: [iter 27 : loss : 1.2041 = 0.2541 + 0.9457 + 0.0042, time: 41.055127]
2023-06-13 16:42:32.720: epoch 27:	0.08690703  	0.16372950  	0.16266313  
2023-06-13 16:42:32.720: Find a better model.
2023-06-13 16:43:14.925: [iter 28 : loss : 1.1830 = 0.2333 + 0.9450 + 0.0046, time: 42.195555]
2023-06-13 16:43:15.483: epoch 28:	0.08720790  	0.16391833  	0.16282745  
2023-06-13 16:43:15.483: Find a better model.
2023-06-13 16:43:57.236: [iter 29 : loss : 1.1653 = 0.2162 + 0.9440 + 0.0050, time: 41.746053]
2023-06-13 16:43:57.754: epoch 29:	0.08710579  	0.16362561  	0.16284473  
2023-06-13 16:44:40.479: [iter 30 : loss : 1.1495 = 0.2011 + 0.9429 + 0.0054, time: 42.718620]
2023-06-13 16:44:40.911: epoch 30:	0.08708423  	0.16306557  	0.16264772  
2023-06-13 16:45:23.566: [iter 31 : loss : 1.1348 = 0.1871 + 0.9419 + 0.0058, time: 42.647490]
2023-06-13 16:45:24.000: epoch 31:	0.08712721  	0.16317193  	0.16261831  
2023-06-13 16:46:05.793: [iter 32 : loss : 1.1231 = 0.1762 + 0.9408 + 0.0061, time: 41.786148]
2023-06-13 16:46:06.318: epoch 32:	0.08694997  	0.16270357  	0.16222030  
2023-06-13 16:46:48.688: [iter 33 : loss : 1.1119 = 0.1657 + 0.9398 + 0.0065, time: 42.362952]
2023-06-13 16:46:49.119: epoch 33:	0.08677811  	0.16168891  	0.16181329  
2023-06-13 16:47:32.824: [iter 34 : loss : 1.1029 = 0.1572 + 0.9389 + 0.0068, time: 43.698598]
2023-06-13 16:47:33.290: epoch 34:	0.08669212  	0.16120271  	0.16152182  
2023-06-13 16:48:16.107: [iter 35 : loss : 1.0935 = 0.1483 + 0.9381 + 0.0071, time: 42.811145]
2023-06-13 16:48:16.571: epoch 35:	0.08655783  	0.16083118  	0.16109699  
2023-06-13 16:48:58.304: [iter 36 : loss : 1.0861 = 0.1414 + 0.9372 + 0.0074, time: 41.726115]
2023-06-13 16:48:58.842: epoch 36:	0.08619799  	0.15975870  	0.16035724  
2023-06-13 16:49:41.673: [iter 37 : loss : 1.0784 = 0.1343 + 0.9363 + 0.0077, time: 42.824428]
2023-06-13 16:49:42.101: epoch 37:	0.08612279  	0.15926901  	0.16014995  
2023-06-13 16:50:24.335: [iter 38 : loss : 1.0722 = 0.1286 + 0.9355 + 0.0080, time: 42.227195]
2023-06-13 16:50:24.895: epoch 38:	0.08590791  	0.15851340  	0.15945069  
2023-06-13 16:51:07.946: [iter 39 : loss : 1.0668 = 0.1238 + 0.9348 + 0.0083, time: 43.044803]
2023-06-13 16:51:08.390: epoch 39:	0.08576825  	0.15841092  	0.15904081  
2023-06-13 16:51:51.365: [iter 40 : loss : 1.0617 = 0.1189 + 0.9342 + 0.0085, time: 42.960377]
2023-06-13 16:51:51.785: epoch 40:	0.08553188  	0.15761693  	0.15829790  
2023-06-13 16:52:34.643: [iter 41 : loss : 1.0564 = 0.1140 + 0.9335 + 0.0088, time: 42.850915]
2023-06-13 16:52:35.074: epoch 41:	0.08538149  	0.15718564  	0.15783773  
2023-06-13 16:53:18.360: [iter 42 : loss : 1.0519 = 0.1099 + 0.9329 + 0.0091, time: 43.279896]
2023-06-13 16:53:18.788: epoch 42:	0.08516119  	0.15624243  	0.15719040  
2023-06-13 16:54:01.537: [iter 43 : loss : 1.0473 = 0.1057 + 0.9323 + 0.0093, time: 42.721742]
2023-06-13 16:54:02.083: epoch 43:	0.08504302  	0.15578151  	0.15680012  
2023-06-13 16:54:44.713: [iter 44 : loss : 1.0437 = 0.1023 + 0.9319 + 0.0095, time: 42.623096]
2023-06-13 16:54:45.145: epoch 44:	0.08489268  	0.15535480  	0.15639959  
2023-06-13 16:55:28.660: [iter 45 : loss : 1.0406 = 0.0995 + 0.9314 + 0.0098, time: 43.507391]
2023-06-13 16:55:29.082: epoch 45:	0.08459189  	0.15462543  	0.15562215  
2023-06-13 16:56:12.487: [iter 46 : loss : 1.0370 = 0.0960 + 0.9310 + 0.0100, time: 43.398105]
2023-06-13 16:56:12.901: epoch 46:	0.08439311  	0.15391523  	0.15503012  
2023-06-13 16:56:55.723: [iter 47 : loss : 1.0341 = 0.0935 + 0.9305 + 0.0102, time: 42.815600]
2023-06-13 16:56:56.135: epoch 47:	0.08420508  	0.15339480  	0.15447849  
2023-06-13 16:57:39.717: [iter 48 : loss : 1.0307 = 0.0902 + 0.9300 + 0.0104, time: 43.573706]
2023-06-13 16:57:40.136: epoch 48:	0.08416751  	0.15314226  	0.15407521  
2023-06-13 16:58:23.399: [iter 49 : loss : 1.0283 = 0.0881 + 0.9296 + 0.0106, time: 43.253710]
2023-06-13 16:58:23.817: epoch 49:	0.08374858  	0.15221487  	0.15319327  
2023-06-13 16:59:06.694: [iter 50 : loss : 1.0256 = 0.0856 + 0.9292 + 0.0108, time: 42.870016]
2023-06-13 16:59:07.196: epoch 50:	0.08342090  	0.15163176  	0.15260108  
2023-06-13 16:59:50.706: [iter 51 : loss : 1.0230 = 0.0831 + 0.9289 + 0.0110, time: 43.502122]
2023-06-13 16:59:51.148: epoch 51:	0.08315769  	0.15096088  	0.15216848  
2023-06-13 17:00:34.073: [iter 52 : loss : 1.0213 = 0.0815 + 0.9286 + 0.0112, time: 42.917122]
2023-06-13 17:00:34.495: epoch 52:	0.08294817  	0.15014929  	0.15134306  
2023-06-13 17:01:15.307: [iter 53 : loss : 1.0189 = 0.0793 + 0.9282 + 0.0114, time: 40.804775]
2023-06-13 17:01:15.715: epoch 53:	0.08272790  	0.14971511  	0.15081456  
2023-06-13 17:01:15.715: Early stopping is trigger at epoch: 53
2023-06-13 17:01:15.715: best_result@epoch 28:

2023-06-13 17:01:15.715: 		0.0872      	0.1639      	0.1628      
2023-06-13 17:10:44.032: my pid: 4468
2023-06-13 17:10:44.032: model: model.general_recommender.SGL
2023-06-13 17:10:44.032: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 17:10:44.032: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 17:10:49.087: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 17:11:28.670: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 39.582190]
2023-06-13 17:11:29.088: epoch 1:	0.00314245  	0.00826931  	0.00622987  
2023-06-13 17:11:29.088: Find a better model.
2023-06-13 17:12:09.908: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 40.812539]
2023-06-13 17:12:10.340: epoch 2:	0.00337880  	0.00829029  	0.00663711  
2023-06-13 17:12:10.340: Find a better model.
2023-06-13 17:12:50.773: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.427087]
2023-06-13 17:12:51.210: epoch 3:	0.00413620  	0.00999542  	0.00776168  
2023-06-13 17:12:51.211: Find a better model.
2023-06-13 17:13:32.419: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 41.200787]
2023-06-13 17:13:32.836: epoch 4:	0.00468948  	0.01149942  	0.00924572  
2023-06-13 17:13:32.836: Find a better model.
2023-06-13 17:14:13.679: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.835645]
2023-06-13 17:14:14.116: epoch 5:	0.00564027  	0.01304420  	0.01063674  
2023-06-13 17:14:14.116: Find a better model.
2023-06-13 17:14:55.319: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 41.196246]
2023-06-13 17:14:55.776: epoch 6:	0.00673071  	0.01555569  	0.01283946  
2023-06-13 17:14:55.776: Find a better model.
2023-06-13 17:15:35.922: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 40.139038]
2023-06-13 17:15:36.474: epoch 7:	0.00726253  	0.01660698  	0.01395004  
2023-06-13 17:15:36.474: Find a better model.
2023-06-13 17:16:17.360: [iter 8 : loss : 1.6053 = 0.6926 + 0.9127 + 0.0000, time: 40.879213]
2023-06-13 17:16:17.797: epoch 8:	0.00833154  	0.01906552  	0.01612330  
2023-06-13 17:16:17.797: Find a better model.
2023-06-13 17:16:57.983: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 40.177403]
2023-06-13 17:16:58.544: epoch 9:	0.01021708  	0.02270190  	0.01961235  
2023-06-13 17:16:58.544: Find a better model.
2023-06-13 17:17:39.398: [iter 10 : loss : 1.6053 = 0.6923 + 0.9130 + 0.0000, time: 40.846454]
2023-06-13 17:17:39.828: epoch 10:	0.01139352  	0.02491390  	0.02252899  
2023-06-13 17:17:39.828: Find a better model.
2023-06-13 17:18:21.052: [iter 11 : loss : 1.6050 = 0.6920 + 0.9130 + 0.0000, time: 41.216248]
2023-06-13 17:18:21.633: epoch 11:	0.01453608  	0.03199771  	0.02844217  
2023-06-13 17:18:21.633: Find a better model.
2023-06-13 17:19:03.873: [iter 12 : loss : 1.6048 = 0.6915 + 0.9133 + 0.0000, time: 42.232911]
2023-06-13 17:19:04.297: epoch 12:	0.01737245  	0.03760300  	0.03411030  
2023-06-13 17:19:04.297: Find a better model.
2023-06-13 17:19:46.585: [iter 13 : loss : 1.6044 = 0.6908 + 0.9135 + 0.0000, time: 42.280269]
2023-06-13 17:19:47.118: epoch 13:	0.02170757  	0.04636327  	0.04316928  
2023-06-13 17:19:47.118: Find a better model.
2023-06-13 17:20:28.204: [iter 14 : loss : 1.6036 = 0.6897 + 0.9139 + 0.0000, time: 41.079323]
2023-06-13 17:20:28.730: epoch 14:	0.02768104  	0.05926707  	0.05604206  
2023-06-13 17:20:28.730: Find a better model.
2023-06-13 17:21:10.729: [iter 15 : loss : 1.6020 = 0.6875 + 0.9144 + 0.0001, time: 41.991465]
2023-06-13 17:21:11.153: epoch 15:	0.03726881  	0.07738031  	0.07429922  
2023-06-13 17:21:11.153: Find a better model.
2023-06-13 17:21:53.241: [iter 16 : loss : 1.5986 = 0.6833 + 0.9152 + 0.0001, time: 42.081228]
2023-06-13 17:21:53.671: epoch 16:	0.04749620  	0.09611339  	0.09371803  
2023-06-13 17:21:53.671: Find a better model.
2023-06-13 17:22:35.326: [iter 17 : loss : 1.5908 = 0.6741 + 0.9166 + 0.0002, time: 41.646230]
2023-06-13 17:22:35.775: epoch 17:	0.05962497  	0.11728742  	0.11574733  
2023-06-13 17:22:35.776: Find a better model.
2023-06-13 17:23:18.042: [iter 18 : loss : 1.5736 = 0.6543 + 0.9191 + 0.0003, time: 42.258468]
2023-06-13 17:23:18.525: epoch 18:	0.07058297  	0.13493001  	0.13452357  
2023-06-13 17:23:18.525: Find a better model.
2023-06-13 17:24:00.542: [iter 19 : loss : 1.5408 = 0.6171 + 0.9232 + 0.0005, time: 42.010632]
2023-06-13 17:24:00.961: epoch 19:	0.07732952  	0.14578766  	0.14599474  
2023-06-13 17:24:00.962: Find a better model.
2023-06-13 17:24:42.881: [iter 20 : loss : 1.4927 = 0.5627 + 0.9291 + 0.0009, time: 41.911294]
2023-06-13 17:24:43.324: epoch 20:	0.08100892  	0.15255918  	0.15235940  
2023-06-13 17:24:43.324: Find a better model.
2023-06-13 17:25:25.792: [iter 21 : loss : 1.4363 = 0.4997 + 0.9353 + 0.0013, time: 42.461968]
2023-06-13 17:25:26.206: epoch 21:	0.08317364  	0.15663071  	0.15594192  
2023-06-13 17:25:26.206: Find a better model.
2023-06-13 17:26:08.560: [iter 22 : loss : 1.3812 = 0.4388 + 0.9406 + 0.0018, time: 42.348547]
2023-06-13 17:26:08.990: epoch 22:	0.08440370  	0.15955773  	0.15839517  
2023-06-13 17:26:08.990: Find a better model.
2023-06-13 17:26:50.666: [iter 23 : loss : 1.3328 = 0.3866 + 0.9439 + 0.0023, time: 41.669273]
2023-06-13 17:26:51.189: epoch 23:	0.08551028  	0.16190390  	0.16034488  
2023-06-13 17:26:51.189: Find a better model.
2023-06-13 17:27:33.831: [iter 24 : loss : 1.2917 = 0.3431 + 0.9458 + 0.0028, time: 42.633254]
2023-06-13 17:27:34.306: epoch 24:	0.08616564  	0.16319302  	0.16163279  
2023-06-13 17:27:34.306: Find a better model.
2023-06-13 17:28:16.828: [iter 25 : loss : 1.2576 = 0.3080 + 0.9463 + 0.0033, time: 42.491673]
2023-06-13 17:28:17.271: epoch 25:	0.08691224  	0.16470495  	0.16266571  
2023-06-13 17:28:17.271: Find a better model.
2023-06-13 17:28:59.349: [iter 26 : loss : 1.2279 = 0.2781 + 0.9461 + 0.0038, time: 42.069248]
2023-06-13 17:28:59.861: epoch 26:	0.08712719  	0.16519681  	0.16317657  
2023-06-13 17:28:59.861: Find a better model.
2023-06-13 17:29:42.663: [iter 27 : loss : 1.2033 = 0.2535 + 0.9456 + 0.0042, time: 42.795487]
2023-06-13 17:29:43.058: epoch 27:	0.08729911  	0.16546091  	0.16323175  
2023-06-13 17:29:43.058: Find a better model.
2023-06-13 17:30:22.471: [iter 28 : loss : 1.1822 = 0.2328 + 0.9448 + 0.0046, time: 39.407305]
2023-06-13 17:30:22.866: epoch 28:	0.08734211  	0.16557002  	0.16335626  
2023-06-13 17:30:22.866: Find a better model.
2023-06-13 17:31:02.392: [iter 29 : loss : 1.1643 = 0.2156 + 0.9438 + 0.0050, time: 39.520091]
2023-06-13 17:31:02.788: epoch 29:	0.08726139  	0.16519457  	0.16319472  
2023-06-13 17:31:42.425: [iter 30 : loss : 1.1484 = 0.2003 + 0.9427 + 0.0054, time: 39.627870]
2023-06-13 17:31:42.822: epoch 30:	0.08755684  	0.16567972  	0.16316672  
2023-06-13 17:31:42.823: Find a better model.
2023-06-13 17:32:22.401: [iter 31 : loss : 1.1341 = 0.1867 + 0.9416 + 0.0058, time: 39.570093]
2023-06-13 17:32:22.800: epoch 31:	0.08757297  	0.16521391  	0.16277158  
2023-06-13 17:33:02.415: [iter 32 : loss : 1.1224 = 0.1757 + 0.9406 + 0.0061, time: 39.608649]
2023-06-13 17:33:02.811: epoch 32:	0.08746018  	0.16487077  	0.16251327  
2023-06-13 17:33:42.646: [iter 33 : loss : 1.1112 = 0.1651 + 0.9397 + 0.0065, time: 39.828074]
2023-06-13 17:33:43.072: epoch 33:	0.08745485  	0.16448534  	0.16212048  
2023-06-13 17:34:23.385: [iter 34 : loss : 1.1019 = 0.1565 + 0.9387 + 0.0068, time: 40.305122]
2023-06-13 17:34:23.810: epoch 34:	0.08740122  	0.16394067  	0.16197710  
2023-06-13 17:35:04.286: [iter 35 : loss : 1.0929 = 0.1479 + 0.9379 + 0.0071, time: 40.469123]
2023-06-13 17:35:04.712: epoch 35:	0.08734207  	0.16380267  	0.16175252  
2023-06-13 17:35:45.120: [iter 36 : loss : 1.0855 = 0.1410 + 0.9370 + 0.0074, time: 40.402077]
2023-06-13 17:35:45.543: epoch 36:	0.08690163  	0.16257620  	0.16103972  
2023-06-13 17:36:25.935: [iter 37 : loss : 1.0778 = 0.1340 + 0.9361 + 0.0077, time: 40.385383]
2023-06-13 17:36:26.360: epoch 37:	0.08681028  	0.16196233  	0.16074999  
2023-06-13 17:37:06.520: [iter 38 : loss : 1.0718 = 0.1285 + 0.9354 + 0.0080, time: 40.154151]
2023-06-13 17:37:06.945: epoch 38:	0.08660614  	0.16110788  	0.16050184  
2023-06-13 17:37:46.923: [iter 39 : loss : 1.0662 = 0.1232 + 0.9347 + 0.0083, time: 39.971091]
2023-06-13 17:37:47.352: epoch 39:	0.08640743  	0.16028124  	0.15971543  
2023-06-13 17:38:27.715: [iter 40 : loss : 1.0609 = 0.1184 + 0.9340 + 0.0085, time: 40.356090]
2023-06-13 17:38:28.143: epoch 40:	0.08623018  	0.15965484  	0.15895905  
2023-06-13 17:39:08.626: [iter 41 : loss : 1.0557 = 0.1136 + 0.9333 + 0.0088, time: 40.476071]
2023-06-13 17:39:09.054: epoch 41:	0.08604224  	0.15912236  	0.15856358  
2023-06-13 17:39:49.710: [iter 42 : loss : 1.0517 = 0.1099 + 0.9328 + 0.0090, time: 40.650081]
2023-06-13 17:39:50.137: epoch 42:	0.08569309  	0.15855135  	0.15803786  
2023-06-13 17:40:30.613: [iter 43 : loss : 1.0468 = 0.1053 + 0.9322 + 0.0093, time: 40.469086]
2023-06-13 17:40:31.037: epoch 43:	0.08556415  	0.15818910  	0.15753011  
2023-06-13 17:41:11.468: [iter 44 : loss : 1.0431 = 0.1018 + 0.9318 + 0.0095, time: 40.425028]
2023-06-13 17:41:11.893: epoch 44:	0.08544593  	0.15754813  	0.15714735  
2023-06-13 17:41:52.435: [iter 45 : loss : 1.0402 = 0.0992 + 0.9312 + 0.0098, time: 40.534014]
2023-06-13 17:41:52.859: epoch 45:	0.08510219  	0.15671112  	0.15649803  
2023-06-13 17:42:33.354: [iter 46 : loss : 1.0366 = 0.0959 + 0.9308 + 0.0100, time: 40.489080]
2023-06-13 17:42:33.780: epoch 46:	0.08451128  	0.15523674  	0.15540476  
2023-06-13 17:43:14.209: [iter 47 : loss : 1.0332 = 0.0927 + 0.9303 + 0.0102, time: 40.423068]
2023-06-13 17:43:14.640: epoch 47:	0.08433942  	0.15459894  	0.15475935  
2023-06-13 17:43:55.164: [iter 48 : loss : 1.0305 = 0.0901 + 0.9299 + 0.0104, time: 40.514090]
2023-06-13 17:43:55.594: epoch 48:	0.08412992  	0.15417320  	0.15421861  
2023-06-13 17:44:35.977: [iter 49 : loss : 1.0279 = 0.0878 + 0.9295 + 0.0106, time: 40.377105]
2023-06-13 17:44:36.403: epoch 49:	0.08394735  	0.15339483  	0.15363090  
2023-06-13 17:45:16.578: [iter 50 : loss : 1.0253 = 0.0854 + 0.9291 + 0.0108, time: 40.168572]
2023-06-13 17:45:17.003: epoch 50:	0.08369490  	0.15288007  	0.15292889  
2023-06-13 17:45:57.775: [iter 51 : loss : 1.0230 = 0.0831 + 0.9288 + 0.0110, time: 40.763046]
2023-06-13 17:45:58.210: epoch 51:	0.08345317  	0.15223368  	0.15247914  
2023-06-13 17:46:39.167: [iter 52 : loss : 1.0208 = 0.0811 + 0.9285 + 0.0112, time: 40.948537]
2023-06-13 17:46:39.593: epoch 52:	0.08318997  	0.15165053  	0.15213063  
2023-06-13 17:47:20.066: [iter 53 : loss : 1.0184 = 0.0788 + 0.9282 + 0.0114, time: 40.467198]
2023-06-13 17:47:20.484: epoch 53:	0.08292142  	0.15110675  	0.15148948  
2023-06-13 17:48:01.059: [iter 54 : loss : 1.0164 = 0.0769 + 0.9279 + 0.0116, time: 40.568098]
2023-06-13 17:48:01.483: epoch 54:	0.08257223  	0.15002672  	0.15067004  
2023-06-13 17:48:41.891: [iter 55 : loss : 1.0149 = 0.0755 + 0.9277 + 0.0117, time: 40.401050]
2023-06-13 17:48:42.317: epoch 55:	0.08241109  	0.14961275  	0.15039931  
2023-06-13 17:48:42.318: Early stopping is trigger at epoch: 55
2023-06-13 17:48:42.318: best_result@epoch 30:

2023-06-13 17:48:42.318: 		0.0876      	0.1657      	0.1632      
2023-06-13 18:40:35.974: my pid: 15824
2023-06-13 18:40:35.974: model: model.general_recommender.SGL
2023-06-13 18:40:35.974: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 18:40:35.974: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 18:40:41.354: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 18:41:22.317: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 40.962797]
2023-06-13 18:41:22.789: epoch 1:	0.00300815  	0.00762201  	0.00599054  
2023-06-13 18:41:22.789: Find a better model.
2023-06-13 18:42:02.829: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 40.030762]
2023-06-13 18:42:03.385: epoch 2:	0.00378167  	0.00897285  	0.00754399  
2023-06-13 18:42:03.386: Find a better model.
2023-06-13 18:42:44.342: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 40.948288]
2023-06-13 18:42:44.795: epoch 3:	0.00435644  	0.01045577  	0.00837779  
2023-06-13 18:42:44.795: Find a better model.
2023-06-13 18:43:25.595: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.792995]
2023-06-13 18:43:26.030: epoch 4:	0.00500104  	0.01169166  	0.00997983  
2023-06-13 18:43:26.030: Find a better model.
2023-06-13 18:44:06.507: [iter 5 : loss : 1.6054 = 0.6929 + 0.9124 + 0.0000, time: 40.468847]
2023-06-13 18:44:06.994: epoch 5:	0.00603777  	0.01393667  	0.01179410  
2023-06-13 18:44:06.994: Find a better model.
2023-06-13 18:44:48.261: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 41.258475]
2023-06-13 18:44:48.758: epoch 6:	0.00666625  	0.01424424  	0.01228994  
2023-06-13 18:44:48.759: Find a better model.
2023-06-13 18:45:31.566: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 42.796107]
2023-06-13 18:45:32.136: epoch 7:	0.00735922  	0.01599245  	0.01340659  
2023-06-13 18:45:32.136: Find a better model.
2023-06-13 18:46:13.130: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 40.985612]
2023-06-13 18:46:13.556: epoch 8:	0.00856791  	0.01850986  	0.01600713  
2023-06-13 18:46:13.556: Find a better model.
2023-06-13 18:46:54.732: [iter 9 : loss : 1.6055 = 0.6926 + 0.9129 + 0.0000, time: 41.169744]
2023-06-13 18:46:55.154: epoch 9:	0.00985717  	0.02092854  	0.01880958  
2023-06-13 18:46:55.154: Find a better model.
2023-06-13 18:47:35.990: [iter 10 : loss : 1.6053 = 0.6924 + 0.9129 + 0.0000, time: 40.829336]
2023-06-13 18:47:36.436: epoch 10:	0.01121625  	0.02402509  	0.02138274  
2023-06-13 18:47:36.436: Find a better model.
2023-06-13 18:48:18.332: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 41.888872]
2023-06-13 18:48:18.816: epoch 11:	0.01369269  	0.02966680  	0.02654034  
2023-06-13 18:48:18.816: Find a better model.
2023-06-13 18:48:59.892: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 41.066192]
2023-06-13 18:49:00.429: epoch 12:	0.01673319  	0.03549440  	0.03241848  
2023-06-13 18:49:00.429: Find a better model.
2023-06-13 18:49:42.323: [iter 13 : loss : 1.6046 = 0.6911 + 0.9134 + 0.0000, time: 41.886098]
2023-06-13 18:49:42.779: epoch 13:	0.02076750  	0.04390623  	0.04023271  
2023-06-13 18:49:42.779: Find a better model.
2023-06-13 18:50:25.110: [iter 14 : loss : 1.6040 = 0.6902 + 0.9137 + 0.0000, time: 42.322301]
2023-06-13 18:50:25.531: epoch 14:	0.02625219  	0.05531897  	0.05148509  
2023-06-13 18:50:25.531: Find a better model.
2023-06-13 18:51:07.573: [iter 15 : loss : 1.6027 = 0.6885 + 0.9142 + 0.0001, time: 42.035228]
2023-06-13 18:51:08.039: epoch 15:	0.03363243  	0.06961639  	0.06612563  
2023-06-13 18:51:08.039: Find a better model.
2023-06-13 18:51:49.357: [iter 16 : loss : 1.6002 = 0.6852 + 0.9148 + 0.0001, time: 41.309838]
2023-06-13 18:51:49.851: epoch 16:	0.04378985  	0.08876784  	0.08556379  
2023-06-13 18:51:49.851: Find a better model.
2023-06-13 18:52:31.662: [iter 17 : loss : 1.5943 = 0.6782 + 0.9160 + 0.0001, time: 41.801792]
2023-06-13 18:52:32.086: epoch 17:	0.05614438  	0.11081578  	0.10907443  
2023-06-13 18:52:32.086: Find a better model.
2023-06-13 18:53:14.403: [iter 18 : loss : 1.5809 = 0.6625 + 0.9181 + 0.0002, time: 42.309743]
2023-06-13 18:53:14.877: epoch 18:	0.06790254  	0.13095005  	0.13033965  
2023-06-13 18:53:14.878: Find a better model.
2023-06-13 18:53:56.990: [iter 19 : loss : 1.5530 = 0.6308 + 0.9218 + 0.0004, time: 42.106441]
2023-06-13 18:53:57.528: epoch 19:	0.07611553  	0.14360562  	0.14416035  
2023-06-13 18:53:57.528: Find a better model.
2023-06-13 18:54:39.955: [iter 20 : loss : 1.5083 = 0.5800 + 0.9276 + 0.0007, time: 42.418118]
2023-06-13 18:54:40.412: epoch 20:	0.08050932  	0.15153003  	0.15212692  
2023-06-13 18:54:40.412: Find a better model.
2023-06-13 18:55:21.760: [iter 21 : loss : 1.4525 = 0.5173 + 0.9340 + 0.0012, time: 41.341368]
2023-06-13 18:55:22.296: epoch 21:	0.08306083  	0.15591027  	0.15673421  
2023-06-13 18:55:22.296: Find a better model.
2023-06-13 18:56:04.328: [iter 22 : loss : 1.3959 = 0.4545 + 0.9398 + 0.0017, time: 42.025471]
2023-06-13 18:56:04.823: epoch 22:	0.08484418  	0.15929289  	0.15965632  
2023-06-13 18:56:04.823: Find a better model.
2023-06-13 18:56:46.808: [iter 23 : loss : 1.3454 = 0.3998 + 0.9435 + 0.0022, time: 41.978370]
2023-06-13 18:56:47.224: epoch 23:	0.08578413  	0.16190115  	0.16168378  
2023-06-13 18:56:47.225: Find a better model.
2023-06-13 18:57:28.949: [iter 24 : loss : 1.3023 = 0.3540 + 0.9456 + 0.0027, time: 41.717505]
2023-06-13 18:57:29.468: epoch 24:	0.08687457  	0.16472542  	0.16337322  
2023-06-13 18:57:29.468: Find a better model.
2023-06-13 18:58:11.916: [iter 25 : loss : 1.2662 = 0.3168 + 0.9463 + 0.0032, time: 42.442657]
2023-06-13 18:58:12.331: epoch 25:	0.08720232  	0.16534974  	0.16412193  
2023-06-13 18:58:12.332: Find a better model.
2023-06-13 18:58:54.047: [iter 26 : loss : 1.2353 = 0.2855 + 0.9462 + 0.0036, time: 41.708033]
2023-06-13 18:58:54.580: epoch 26:	0.08749232  	0.16598682  	0.16475630  
2023-06-13 18:58:54.580: Find a better model.
2023-06-13 18:59:36.272: [iter 27 : loss : 1.2094 = 0.2597 + 0.9456 + 0.0041, time: 41.683654]
2023-06-13 18:59:36.843: epoch 27:	0.08788440  	0.16685268  	0.16523281  
2023-06-13 18:59:36.843: Find a better model.
2023-06-13 19:00:16.441: [iter 28 : loss : 1.1874 = 0.2379 + 0.9449 + 0.0045, time: 39.590549]
2023-06-13 19:00:16.861: epoch 28:	0.08812080  	0.16747086  	0.16548593  
2023-06-13 19:00:16.861: Find a better model.
2023-06-13 19:00:58.861: [iter 29 : loss : 1.1691 = 0.2204 + 0.9439 + 0.0049, time: 41.992888]
2023-06-13 19:00:59.302: epoch 29:	0.08799726  	0.16739990  	0.16508187  
2023-06-13 19:01:41.403: [iter 30 : loss : 1.1524 = 0.2042 + 0.9428 + 0.0053, time: 42.089563]
2023-06-13 19:01:41.968: epoch 30:	0.08795968  	0.16725056  	0.16515933  
2023-06-13 19:02:23.587: [iter 31 : loss : 1.1377 = 0.1903 + 0.9417 + 0.0057, time: 41.611912]
2023-06-13 19:02:24.149: epoch 31:	0.08793818  	0.16679186  	0.16473369  
2023-06-13 19:03:06.380: [iter 32 : loss : 1.1256 = 0.1789 + 0.9407 + 0.0060, time: 42.223162]
2023-06-13 19:03:06.854: epoch 32:	0.08781996  	0.16664638  	0.16478544  
2023-06-13 19:03:48.677: [iter 33 : loss : 1.1136 = 0.1675 + 0.9397 + 0.0064, time: 41.815830]
2023-06-13 19:03:49.118: epoch 33:	0.08768565  	0.16593428  	0.16427116  
2023-06-13 19:04:30.946: [iter 34 : loss : 1.1045 = 0.1590 + 0.9388 + 0.0067, time: 41.818115]
2023-06-13 19:04:31.437: epoch 34:	0.08757290  	0.16517317  	0.16377674  
2023-06-13 19:05:14.377: [iter 35 : loss : 1.0949 = 0.1500 + 0.9379 + 0.0070, time: 42.931565]
2023-06-13 19:05:14.824: epoch 35:	0.08758894  	0.16481206  	0.16336714  
2023-06-13 19:05:56.766: [iter 36 : loss : 1.0872 = 0.1428 + 0.9371 + 0.0073, time: 41.929542]
2023-06-13 19:05:57.265: epoch 36:	0.08739027  	0.16407651  	0.16276754  
2023-06-13 19:06:40.080: [iter 37 : loss : 1.0795 = 0.1357 + 0.9362 + 0.0076, time: 42.807044]
2023-06-13 19:06:40.522: epoch 37:	0.08727743  	0.16332005  	0.16227828  
2023-06-13 19:07:22.146: [iter 38 : loss : 1.0732 = 0.1299 + 0.9354 + 0.0079, time: 41.616830]
2023-06-13 19:07:22.715: epoch 38:	0.08695515  	0.16224100  	0.16140287  
2023-06-13 19:08:06.090: [iter 39 : loss : 1.0673 = 0.1245 + 0.9346 + 0.0082, time: 43.357128]
2023-06-13 19:08:06.544: epoch 39:	0.08689607  	0.16173545  	0.16092987  
2023-06-13 19:08:50.343: [iter 40 : loss : 1.0622 = 0.1199 + 0.9339 + 0.0085, time: 43.791580]
2023-06-13 19:08:50.898: epoch 40:	0.08665974  	0.16091658  	0.16035451  
2023-06-13 19:09:34.196: [iter 41 : loss : 1.0565 = 0.1145 + 0.9333 + 0.0087, time: 43.290101]
2023-06-13 19:09:34.622: epoch 41:	0.08656305  	0.16059580  	0.16012558  
2023-06-13 19:10:17.060: [iter 42 : loss : 1.0524 = 0.1107 + 0.9327 + 0.0090, time: 42.431147]
2023-06-13 19:10:17.582: epoch 42:	0.08631057  	0.15989423  	0.15958330  
2023-06-13 19:11:00.972: [iter 43 : loss : 1.0476 = 0.1063 + 0.9321 + 0.0092, time: 43.383232]
2023-06-13 19:11:01.387: epoch 43:	0.08618707  	0.15944910  	0.15899739  
2023-06-13 19:11:44.493: [iter 44 : loss : 1.0441 = 0.1029 + 0.9317 + 0.0095, time: 43.098628]
2023-06-13 19:11:44.937: epoch 44:	0.08609035  	0.15897402  	0.15836789  
2023-06-13 19:12:27.759: [iter 45 : loss : 1.0408 = 0.1000 + 0.9312 + 0.0097, time: 42.813967]
2023-06-13 19:12:28.237: epoch 45:	0.08587550  	0.15848368  	0.15765770  
2023-06-13 19:13:11.670: [iter 46 : loss : 1.0371 = 0.0965 + 0.9307 + 0.0099, time: 43.426701]
2023-06-13 19:13:12.111: epoch 46:	0.08555323  	0.15760703  	0.15700102  
2023-06-13 19:13:54.790: [iter 47 : loss : 1.0340 = 0.0937 + 0.9302 + 0.0101, time: 42.672579]
2023-06-13 19:13:55.294: epoch 47:	0.08527930  	0.15686363  	0.15618749  
2023-06-13 19:14:38.951: [iter 48 : loss : 1.0310 = 0.0909 + 0.9298 + 0.0104, time: 43.649353]
2023-06-13 19:14:39.371: epoch 48:	0.08495158  	0.15589127  	0.15566573  
2023-06-13 19:15:22.614: [iter 49 : loss : 1.0282 = 0.0882 + 0.9294 + 0.0106, time: 43.236910]
2023-06-13 19:15:23.060: epoch 49:	0.08486030  	0.15540956  	0.15509698  
2023-06-13 19:16:06.139: [iter 50 : loss : 1.0255 = 0.0858 + 0.9290 + 0.0108, time: 43.072616]
2023-06-13 19:16:06.588: epoch 50:	0.08462401  	0.15483049  	0.15453047  
2023-06-13 19:16:50.162: [iter 51 : loss : 1.0232 = 0.0835 + 0.9287 + 0.0110, time: 43.567343]
2023-06-13 19:16:50.613: epoch 51:	0.08437689  	0.15423688  	0.15395796  
2023-06-13 19:17:33.643: [iter 52 : loss : 1.0213 = 0.0818 + 0.9284 + 0.0111, time: 43.018639]
2023-06-13 19:17:34.171: epoch 52:	0.08416202  	0.15393439  	0.15352970  
2023-06-13 19:18:17.372: [iter 53 : loss : 1.0187 = 0.0793 + 0.9280 + 0.0113, time: 43.192640]
2023-06-13 19:18:17.914: epoch 53:	0.08390953  	0.15324447  	0.15282227  
2023-06-13 19:18:17.914: Early stopping is trigger at epoch: 53
2023-06-13 19:18:17.914: best_result@epoch 28:

2023-06-13 19:18:17.914: 		0.0881      	0.1675      	0.1655      
2023-06-13 19:40:20.926: my pid: 8000
2023-06-13 19:40:20.926: model: model.general_recommender.SGL
2023-06-13 19:40:20.926: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 19:40:20.926: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 19:40:26.283: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 19:41:07.180: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 40.896663]
2023-06-13 19:41:07.729: epoch 1:	0.00326062  	0.00792951  	0.00632099  
2023-06-13 19:41:07.729: Find a better model.
2023-06-13 19:41:48.441: [iter 2 : loss : 1.6057 = 0.6931 + 0.9127 + 0.0000, time: 40.690666]
2023-06-13 19:41:48.901: epoch 2:	0.00437255  	0.01032111  	0.00846069  
2023-06-13 19:41:48.901: Find a better model.
2023-06-13 19:42:29.494: [iter 3 : loss : 1.6056 = 0.6930 + 0.9125 + 0.0000, time: 40.585525]
2023-06-13 19:42:29.937: epoch 3:	0.00484526  	0.01090922  	0.00896176  
2023-06-13 19:42:29.937: Find a better model.
2023-06-13 19:43:11.550: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.606778]
2023-06-13 19:43:12.101: epoch 4:	0.00538242  	0.01190049  	0.00978228  
2023-06-13 19:43:12.101: Find a better model.
2023-06-13 19:43:53.116: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 41.007065]
2023-06-13 19:43:53.558: epoch 5:	0.00627412  	0.01292857  	0.01150745  
2023-06-13 19:43:53.558: Find a better model.
2023-06-13 19:44:34.998: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 41.433101]
2023-06-13 19:44:35.448: epoch 6:	0.00706914  	0.01424211  	0.01247567  
2023-06-13 19:44:35.449: Find a better model.
2023-06-13 19:45:16.292: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 40.835172]
2023-06-13 19:45:16.754: epoch 7:	0.00793402  	0.01602188  	0.01400237  
2023-06-13 19:45:16.755: Find a better model.
2023-06-13 19:45:57.577: [iter 8 : loss : 1.6054 = 0.6927 + 0.9128 + 0.0000, time: 40.805434]
2023-06-13 19:45:58.036: epoch 8:	0.00914807  	0.01863720  	0.01656080  
2023-06-13 19:45:58.036: Find a better model.
2023-06-13 19:46:38.666: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 40.624065]
2023-06-13 19:46:39.128: epoch 9:	0.01091543  	0.02232615  	0.01980573  
2023-06-13 19:46:39.129: Find a better model.
2023-06-13 19:47:19.567: [iter 10 : loss : 1.6053 = 0.6923 + 0.9130 + 0.0000, time: 40.430871]
2023-06-13 19:47:20.016: epoch 10:	0.01248940  	0.02544436  	0.02380731  
2023-06-13 19:47:20.016: Find a better model.
2023-06-13 19:48:03.245: [iter 11 : loss : 1.6051 = 0.6920 + 0.9131 + 0.0000, time: 43.223678]
2023-06-13 19:48:03.666: epoch 11:	0.01540632  	0.03082142  	0.02921437  
2023-06-13 19:48:03.667: Find a better model.
2023-06-13 19:48:44.687: [iter 12 : loss : 1.6049 = 0.6916 + 0.9133 + 0.0000, time: 41.013185]
2023-06-13 19:48:45.127: epoch 12:	0.01853277  	0.03706102  	0.03560312  
2023-06-13 19:48:45.127: Find a better model.
2023-06-13 19:49:26.947: [iter 13 : loss : 1.6046 = 0.6909 + 0.9136 + 0.0000, time: 41.812707]
2023-06-13 19:49:27.423: epoch 13:	0.02258855  	0.04526825  	0.04338760  
2023-06-13 19:49:27.423: Find a better model.
2023-06-13 19:50:09.293: [iter 14 : loss : 1.6037 = 0.6898 + 0.9139 + 0.0000, time: 41.860675]
2023-06-13 19:50:09.885: epoch 14:	0.02864246  	0.05831573  	0.05635893  
2023-06-13 19:50:09.885: Find a better model.
2023-06-13 19:50:52.018: [iter 15 : loss : 1.6022 = 0.6878 + 0.9143 + 0.0001, time: 42.126029]
2023-06-13 19:50:52.453: epoch 15:	0.03735480  	0.07537796  	0.07364497  
2023-06-13 19:50:52.453: Find a better model.
2023-06-13 19:51:34.169: [iter 16 : loss : 1.5989 = 0.6837 + 0.9151 + 0.0001, time: 41.709250]
2023-06-13 19:51:34.578: epoch 16:	0.04840932  	0.09623132  	0.09493316  
2023-06-13 19:51:34.578: Find a better model.
2023-06-13 19:52:15.854: [iter 17 : loss : 1.5913 = 0.6748 + 0.9163 + 0.0001, time: 41.268529]
2023-06-13 19:52:16.295: epoch 17:	0.06013528  	0.11621685  	0.11631379  
2023-06-13 19:52:16.295: Find a better model.
2023-06-13 19:52:58.586: [iter 18 : loss : 1.5743 = 0.6552 + 0.9188 + 0.0003, time: 42.283011]
2023-06-13 19:52:59.090: epoch 18:	0.07086758  	0.13379493  	0.13525730  
2023-06-13 19:52:59.090: Find a better model.
2023-06-13 19:53:41.077: [iter 19 : loss : 1.5411 = 0.6175 + 0.9230 + 0.0005, time: 41.980155]
2023-06-13 19:53:41.576: epoch 19:	0.07747459  	0.14427115  	0.14653040  
2023-06-13 19:53:41.577: Find a better model.
2023-06-13 19:54:23.926: [iter 20 : loss : 1.4917 = 0.5617 + 0.9292 + 0.0009, time: 42.343125]
2023-06-13 19:54:24.354: epoch 20:	0.08140104  	0.15168209  	0.15350799  
2023-06-13 19:54:24.354: Find a better model.
2023-06-13 19:55:05.364: [iter 21 : loss : 1.4344 = 0.4974 + 0.9357 + 0.0013, time: 41.002615]
2023-06-13 19:55:05.846: epoch 21:	0.08344758  	0.15632772  	0.15716176  
2023-06-13 19:55:05.846: Find a better model.
2023-06-13 19:55:47.735: [iter 22 : loss : 1.3789 = 0.4360 + 0.9411 + 0.0018, time: 41.877594]
2023-06-13 19:55:48.203: epoch 22:	0.08520406  	0.15993464  	0.15984902  
2023-06-13 19:55:48.203: Find a better model.
2023-06-13 19:56:30.463: [iter 23 : loss : 1.3307 = 0.3840 + 0.9444 + 0.0023, time: 42.254062]
2023-06-13 19:56:30.941: epoch 23:	0.08589699  	0.16158451  	0.16124494  
2023-06-13 19:56:30.941: Find a better model.
2023-06-13 19:57:13.134: [iter 24 : loss : 1.2895 = 0.3407 + 0.9460 + 0.0028, time: 42.184854]
2023-06-13 19:57:13.558: epoch 24:	0.08681557  	0.16364501  	0.16260503  
2023-06-13 19:57:13.558: Find a better model.
2023-06-13 19:57:54.691: [iter 25 : loss : 1.2557 = 0.3061 + 0.9463 + 0.0033, time: 41.125954]
2023-06-13 19:57:55.160: epoch 25:	0.08748167  	0.16487429  	0.16352974  
2023-06-13 19:57:55.160: Find a better model.
2023-06-13 19:58:37.398: [iter 26 : loss : 1.2263 = 0.2765 + 0.9460 + 0.0038, time: 42.229995]
2023-06-13 19:58:37.874: epoch 26:	0.08760512  	0.16555631  	0.16351296  
2023-06-13 19:58:37.874: Find a better model.
2023-06-13 19:59:19.992: [iter 27 : loss : 1.2016 = 0.2520 + 0.9454 + 0.0042, time: 42.110798]
2023-06-13 19:59:20.401: epoch 27:	0.08799180  	0.16609892  	0.16380407  
2023-06-13 19:59:20.401: Find a better model.
2023-06-13 20:00:02.668: [iter 28 : loss : 1.1809 = 0.2318 + 0.9445 + 0.0046, time: 42.259986]
2023-06-13 20:00:03.117: epoch 28:	0.08788982  	0.16561720  	0.16349275  
2023-06-13 20:00:44.309: [iter 29 : loss : 1.1630 = 0.2147 + 0.9433 + 0.0050, time: 41.185833]
2023-06-13 20:00:44.771: epoch 29:	0.08784693  	0.16549224  	0.16323557  
2023-06-13 20:01:25.983: [iter 30 : loss : 1.1473 = 0.1995 + 0.9423 + 0.0054, time: 41.203490]
2023-06-13 20:01:26.379: epoch 30:	0.08795968  	0.16561924  	0.16315643  
2023-06-13 20:02:05.684: [iter 31 : loss : 1.1328 = 0.1859 + 0.9412 + 0.0058, time: 39.298933]
2023-06-13 20:02:06.090: epoch 31:	0.08769114  	0.16474947  	0.16249922  
2023-06-13 20:02:45.322: [iter 32 : loss : 1.1212 = 0.1750 + 0.9401 + 0.0061, time: 39.223879]
2023-06-13 20:02:45.752: epoch 32:	0.08759979  	0.16420977  	0.16226737  
2023-06-13 20:03:25.098: [iter 33 : loss : 1.1103 = 0.1646 + 0.9392 + 0.0065, time: 39.340054]
2023-06-13 20:03:25.499: epoch 33:	0.08756758  	0.16390499  	0.16201133  
2023-06-13 20:04:05.717: [iter 34 : loss : 1.1012 = 0.1561 + 0.9383 + 0.0068, time: 40.210367]
2023-06-13 20:04:06.135: epoch 34:	0.08731506  	0.16314928  	0.16153389  
2023-06-13 20:04:48.177: [iter 35 : loss : 1.0919 = 0.1474 + 0.9374 + 0.0071, time: 42.034403]
2023-06-13 20:04:48.610: epoch 35:	0.08710562  	0.16245972  	0.16119231  
2023-06-13 20:05:06.161: my pid: 3812
2023-06-13 20:05:06.161: model: model.general_recommender.SGL
2023-06-13 20:05:06.161: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 20:05:06.161: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 20:05:11.617: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 20:05:53.148: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 41.529661]
2023-06-13 20:05:53.587: epoch 1:	0.00343789  	0.00807347  	0.00673710  
2023-06-13 20:05:53.588: Find a better model.
2023-06-13 20:06:34.286: [iter 2 : loss : 1.6056 = 0.6931 + 0.9126 + 0.0000, time: 40.692777]
2023-06-13 20:06:34.775: epoch 2:	0.00441016  	0.01000160  	0.00827605  
2023-06-13 20:06:34.775: Find a better model.
2023-06-13 20:07:15.324: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 40.541276]
2023-06-13 20:07:15.789: epoch 3:	0.00523202  	0.01119571  	0.00933224  
2023-06-13 20:07:15.789: Find a better model.
2023-06-13 20:07:55.827: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.031010]
2023-06-13 20:07:56.277: epoch 4:	0.00589810  	0.01229194  	0.01059174  
2023-06-13 20:07:56.278: Find a better model.
2023-06-13 20:08:37.115: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.829678]
2023-06-13 20:08:37.633: epoch 5:	0.00666088  	0.01407546  	0.01251063  
2023-06-13 20:08:37.633: Find a better model.
2023-06-13 20:09:18.800: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 41.160128]
2023-06-13 20:09:19.217: epoch 6:	0.00764393  	0.01511305  	0.01401369  
2023-06-13 20:09:19.217: Find a better model.
2023-06-13 20:10:00.782: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 41.558555]
2023-06-13 20:10:01.220: epoch 7:	0.00864311  	0.01727644  	0.01570879  
2023-06-13 20:10:01.220: Find a better model.
2023-06-13 20:10:43.757: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 42.530597]
2023-06-13 20:10:44.268: epoch 8:	0.00941667  	0.01865646  	0.01741390  
2023-06-13 20:10:44.268: Find a better model.
2023-06-13 20:11:25.021: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 40.744389]
2023-06-13 20:11:25.583: epoch 9:	0.01091006  	0.02181006  	0.02048047  
2023-06-13 20:11:25.583: Find a better model.
2023-06-13 20:12:06.709: [iter 10 : loss : 1.6054 = 0.6924 + 0.9130 + 0.0000, time: 41.119272]
2023-06-13 20:12:07.146: epoch 10:	0.01306417  	0.02642721  	0.02435599  
2023-06-13 20:12:07.147: Find a better model.
2023-06-13 20:12:49.785: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 42.631915]
2023-06-13 20:12:50.194: epoch 11:	0.01523443  	0.03059732  	0.02854243  
2023-06-13 20:12:50.195: Find a better model.
2023-06-13 20:13:31.329: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 41.128738]
2023-06-13 20:13:31.795: epoch 12:	0.01880672  	0.03696902  	0.03547337  
2023-06-13 20:13:31.795: Find a better model.
2023-06-13 20:14:13.892: [iter 13 : loss : 1.6046 = 0.6911 + 0.9135 + 0.0000, time: 42.089003]
2023-06-13 20:14:14.405: epoch 13:	0.02244353  	0.04539768  	0.04323984  
2023-06-13 20:14:14.405: Find a better model.
2023-06-13 20:14:57.169: [iter 14 : loss : 1.6039 = 0.6901 + 0.9138 + 0.0000, time: 42.755550]
2023-06-13 20:14:57.588: epoch 14:	0.02825042  	0.05721634  	0.05474516  
2023-06-13 20:14:57.588: Find a better model.
2023-06-13 20:15:38.895: [iter 15 : loss : 1.6026 = 0.6883 + 0.9142 + 0.0001, time: 41.300372]
2023-06-13 20:15:39.355: epoch 15:	0.03626439  	0.07295481  	0.07042175  
2023-06-13 20:15:39.355: Find a better model.
2023-06-13 20:16:21.666: [iter 16 : loss : 1.5998 = 0.6848 + 0.9149 + 0.0001, time: 42.303090]
2023-06-13 20:16:22.198: epoch 16:	0.04702354  	0.09271826  	0.09062206  
2023-06-13 20:16:22.198: Find a better model.
2023-06-13 20:17:04.034: [iter 17 : loss : 1.5933 = 0.6771 + 0.9161 + 0.0001, time: 41.829654]
2023-06-13 20:17:04.543: epoch 17:	0.05886762  	0.11515093  	0.11399923  
2023-06-13 20:17:04.543: Find a better model.
2023-06-13 20:17:47.207: [iter 18 : loss : 1.5786 = 0.6600 + 0.9184 + 0.0002, time: 42.656590]
2023-06-13 20:17:47.771: epoch 18:	0.06950332  	0.13270767  	0.13299519  
2023-06-13 20:17:47.771: Find a better model.
2023-06-13 20:18:30.552: [iter 19 : loss : 1.5486 = 0.6259 + 0.9222 + 0.0004, time: 42.764359]
2023-06-13 20:18:31.002: epoch 19:	0.07709847  	0.14556724  	0.14649591  
2023-06-13 20:18:31.002: Find a better model.
2023-06-13 20:19:13.108: [iter 20 : loss : 1.5017 = 0.5728 + 0.9281 + 0.0008, time: 42.098200]
2023-06-13 20:19:13.633: epoch 20:	0.08106259  	0.15308869  	0.15382199  
2023-06-13 20:19:13.633: Find a better model.
2023-06-13 20:19:56.582: [iter 21 : loss : 1.4450 = 0.5090 + 0.9348 + 0.0012, time: 42.941027]
2023-06-13 20:19:57.049: epoch 21:	0.08334552  	0.15744558  	0.15803263  
2023-06-13 20:19:57.049: Find a better model.
2023-06-13 20:20:38.745: [iter 22 : loss : 1.3883 = 0.4463 + 0.9403 + 0.0017, time: 41.688198]
2023-06-13 20:20:39.289: epoch 22:	0.08490328  	0.16068110  	0.16064730  
2023-06-13 20:20:39.289: Find a better model.
2023-06-13 20:21:21.830: [iter 23 : loss : 1.3387 = 0.3926 + 0.9439 + 0.0022, time: 42.532972]
2023-06-13 20:21:22.286: epoch 23:	0.08589706  	0.16310290  	0.16221471  
2023-06-13 20:21:22.286: Find a better model.
2023-06-13 20:22:03.824: [iter 24 : loss : 1.2963 = 0.3478 + 0.9458 + 0.0027, time: 41.529931]
2023-06-13 20:22:04.312: epoch 24:	0.08657381  	0.16469635  	0.16334544  
2023-06-13 20:22:04.312: Find a better model.
2023-06-13 20:22:47.208: [iter 25 : loss : 1.2611 = 0.3115 + 0.9463 + 0.0032, time: 42.888581]
2023-06-13 20:22:47.658: epoch 25:	0.08707336  	0.16566148  	0.16441186  
2023-06-13 20:22:47.658: Find a better model.
2023-06-13 20:23:29.566: [iter 26 : loss : 1.2311 = 0.2813 + 0.9461 + 0.0037, time: 41.900897]
2023-06-13 20:23:30.016: epoch 26:	0.08725599  	0.16567735  	0.16447672  
2023-06-13 20:23:30.017: Find a better model.
2023-06-13 20:24:12.916: [iter 27 : loss : 1.2057 = 0.2562 + 0.9454 + 0.0041, time: 42.892252]
2023-06-13 20:24:13.339: epoch 27:	0.08758900  	0.16614798  	0.16480039  
2023-06-13 20:24:13.339: Find a better model.
2023-06-13 20:24:55.168: [iter 28 : loss : 1.1842 = 0.2350 + 0.9446 + 0.0046, time: 41.822186]
2023-06-13 20:24:55.591: epoch 28:	0.08754066  	0.16569138  	0.16458295  
2023-06-13 20:25:38.284: [iter 29 : loss : 1.1661 = 0.2175 + 0.9436 + 0.0050, time: 42.684565]
2023-06-13 20:25:38.877: epoch 29:	0.08774490  	0.16649295  	0.16479060  
2023-06-13 20:25:38.877: Find a better model.
2023-06-13 20:26:19.793: [iter 30 : loss : 1.1500 = 0.2022 + 0.9425 + 0.0053, time: 40.908376]
2023-06-13 20:26:20.197: epoch 30:	0.08749776  	0.16576187  	0.16414347  
2023-06-13 20:26:59.879: [iter 31 : loss : 1.1353 = 0.1882 + 0.9414 + 0.0057, time: 39.676318]
2023-06-13 20:27:00.289: epoch 31:	0.08755151  	0.16585854  	0.16381860  
2023-06-13 20:27:40.026: [iter 32 : loss : 1.1236 = 0.1772 + 0.9403 + 0.0061, time: 39.729393]
2023-06-13 20:27:40.426: epoch 32:	0.08742257  	0.16510734  	0.16344161  
2023-06-13 20:28:20.000: [iter 33 : loss : 1.1119 = 0.1662 + 0.9393 + 0.0064, time: 39.567060]
2023-06-13 20:28:20.403: epoch 33:	0.08730443  	0.16445202  	0.16302794  
2023-06-13 20:29:00.228: [iter 34 : loss : 1.1028 = 0.1577 + 0.9384 + 0.0067, time: 39.817940]
2023-06-13 20:29:00.632: epoch 34:	0.08723461  	0.16400915  	0.16272347  
2023-06-13 20:29:40.633: [iter 35 : loss : 1.0936 = 0.1489 + 0.9375 + 0.0071, time: 39.994277]
2023-06-13 20:29:41.046: epoch 35:	0.08703586  	0.16343237  	0.16227451  
2023-06-13 20:30:20.797: [iter 36 : loss : 1.0860 = 0.1419 + 0.9367 + 0.0074, time: 39.745011]
2023-06-13 20:30:21.196: epoch 36:	0.08685324  	0.16260839  	0.16181718  
2023-06-13 20:31:00.920: [iter 37 : loss : 1.0783 = 0.1349 + 0.9358 + 0.0077, time: 39.717258]
2023-06-13 20:31:01.318: epoch 37:	0.08668134  	0.16192043  	0.16123798  
2023-06-13 20:31:40.937: [iter 38 : loss : 1.0721 = 0.1291 + 0.9351 + 0.0080, time: 39.612259]
2023-06-13 20:31:41.338: epoch 38:	0.08647721  	0.16142082  	0.16083425  
2023-06-13 20:32:20.983: [iter 39 : loss : 1.0664 = 0.1238 + 0.9343 + 0.0082, time: 39.639016]
2023-06-13 20:32:21.386: epoch 39:	0.08627310  	0.16055489  	0.16012000  
2023-06-13 20:33:01.121: [iter 40 : loss : 1.0614 = 0.1192 + 0.9336 + 0.0085, time: 39.729231]
2023-06-13 20:33:01.522: epoch 40:	0.08610120  	0.15971120  	0.15931398  
2023-06-13 20:33:41.298: [iter 41 : loss : 1.0561 = 0.1144 + 0.9329 + 0.0088, time: 39.769053]
2023-06-13 20:33:41.710: epoch 41:	0.08595616  	0.15926319  	0.15880418  
2023-06-13 20:34:22.179: [iter 42 : loss : 1.0514 = 0.1100 + 0.9324 + 0.0090, time: 40.453050]
2023-06-13 20:34:22.589: epoch 42:	0.08581121  	0.15849607  	0.15808679  
2023-06-13 20:34:45.443: my pid: 11772
2023-06-13 20:34:45.443: model: model.general_recommender.SGL
2023-06-13 20:34:45.443: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 20:34:45.443: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 20:34:50.461: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 20:35:29.444: [iter 1 : loss : 1.6083 = 0.6931 + 0.9152 + 0.0000, time: 38.981754]
2023-06-13 20:35:29.917: epoch 1:	0.00336806  	0.00803773  	0.00656165  
2023-06-13 20:35:29.918: Find a better model.
2023-06-13 20:36:10.285: [iter 2 : loss : 1.6059 = 0.6931 + 0.9128 + 0.0000, time: 40.360658]
2023-06-13 20:36:10.754: epoch 2:	0.00451222  	0.00957768  	0.00824576  
2023-06-13 20:36:10.754: Find a better model.
2023-06-13 20:36:51.603: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.842614]
2023-06-13 20:36:52.091: epoch 3:	0.00514070  	0.01062757  	0.00925435  
2023-06-13 20:36:52.091: Find a better model.
2023-06-13 20:37:33.355: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.256070]
2023-06-13 20:37:33.939: epoch 4:	0.00576918  	0.01159838  	0.01047802  
2023-06-13 20:37:33.939: Find a better model.
2023-06-13 20:38:15.352: [iter 5 : loss : 1.6056 = 0.6929 + 0.9126 + 0.0000, time: 41.406025]
2023-06-13 20:38:15.860: epoch 5:	0.00697781  	0.01362225  	0.01226233  
2023-06-13 20:38:15.860: Find a better model.
2023-06-13 20:38:56.588: [iter 6 : loss : 1.6056 = 0.6929 + 0.9128 + 0.0000, time: 40.718815]
2023-06-13 20:38:57.050: epoch 6:	0.00801996  	0.01523126  	0.01410489  
2023-06-13 20:38:57.050: Find a better model.
2023-06-13 20:39:38.656: [iter 7 : loss : 1.6057 = 0.6928 + 0.9129 + 0.0000, time: 41.596542]
2023-06-13 20:39:39.179: epoch 7:	0.00915344  	0.01691090  	0.01576215  
2023-06-13 20:39:39.179: Find a better model.
2023-06-13 20:40:20.761: [iter 8 : loss : 1.6055 = 0.6926 + 0.9129 + 0.0000, time: 41.574885]
2023-06-13 20:40:21.186: epoch 8:	0.01015262  	0.01960461  	0.01835900  
2023-06-13 20:40:21.186: Find a better model.
2023-06-13 20:41:02.245: [iter 9 : loss : 1.6056 = 0.6925 + 0.9131 + 0.0000, time: 41.053625]
2023-06-13 20:41:02.666: epoch 9:	0.01250549  	0.02381220  	0.02213206  
2023-06-13 20:41:02.666: Find a better model.
2023-06-13 20:41:43.031: [iter 10 : loss : 1.6054 = 0.6922 + 0.9131 + 0.0000, time: 40.357044]
2023-06-13 20:41:43.483: epoch 10:	0.01418688  	0.02769097  	0.02600538  
2023-06-13 20:41:43.483: Find a better model.
2023-06-13 20:42:25.908: [iter 11 : loss : 1.6052 = 0.6919 + 0.9132 + 0.0000, time: 42.416937]
2023-06-13 20:42:26.439: epoch 11:	0.01725425  	0.03349123  	0.03211493  
2023-06-13 20:42:26.439: Find a better model.
2023-06-13 20:43:08.316: [iter 12 : loss : 1.6049 = 0.6914 + 0.9134 + 0.0000, time: 41.871229]
2023-06-13 20:43:08.847: epoch 12:	0.02052574  	0.04086547  	0.03880606  
2023-06-13 20:43:08.847: Find a better model.
2023-06-13 20:43:51.474: [iter 13 : loss : 1.6044 = 0.6907 + 0.9137 + 0.0000, time: 42.619769]
2023-06-13 20:43:52.025: epoch 13:	0.02539265  	0.05029991  	0.04876670  
2023-06-13 20:43:52.025: Find a better model.
2023-06-13 20:44:34.357: [iter 14 : loss : 1.6035 = 0.6894 + 0.9140 + 0.0000, time: 42.325981]
2023-06-13 20:44:34.807: epoch 14:	0.03256892  	0.06509128  	0.06291909  
2023-06-13 20:44:34.807: Find a better model.
2023-06-13 20:45:16.958: [iter 15 : loss : 1.6015 = 0.6869 + 0.9146 + 0.0001, time: 42.144207]
2023-06-13 20:45:17.512: epoch 15:	0.04188300  	0.08301356  	0.08147247  
2023-06-13 20:45:17.513: Find a better model.
2023-06-13 20:46:00.215: [iter 16 : loss : 1.5974 = 0.6819 + 0.9154 + 0.0001, time: 42.694904]
2023-06-13 20:46:00.645: epoch 16:	0.05307192  	0.10379607  	0.10330148  
2023-06-13 20:46:00.645: Find a better model.
2023-06-13 20:46:42.227: [iter 17 : loss : 1.5877 = 0.6706 + 0.9169 + 0.0002, time: 41.574160]
2023-06-13 20:46:42.778: epoch 17:	0.06497492  	0.12535076  	0.12502480  
2023-06-13 20:46:42.778: Find a better model.
2023-06-13 20:47:25.682: [iter 18 : loss : 1.5666 = 0.6463 + 0.9199 + 0.0003, time: 42.897145]
2023-06-13 20:47:26.143: epoch 18:	0.07356400  	0.13994628  	0.14060740  
2023-06-13 20:47:26.144: Find a better model.
2023-06-13 20:48:08.287: [iter 19 : loss : 1.5281 = 0.6027 + 0.9249 + 0.0006, time: 42.136179]
2023-06-13 20:48:08.908: epoch 19:	0.07918797  	0.14935535  	0.14997372  
2023-06-13 20:48:08.908: Find a better model.
2023-06-13 20:48:51.484: [iter 20 : loss : 1.4755 = 0.5431 + 0.9313 + 0.0010, time: 42.570207]
2023-06-13 20:48:51.921: epoch 20:	0.08217447  	0.15524799  	0.15559229  
2023-06-13 20:48:51.921: Find a better model.
2023-06-13 20:49:34.498: [iter 21 : loss : 1.4183 = 0.4792 + 0.9376 + 0.0014, time: 42.570140]
2023-06-13 20:49:35.044: epoch 21:	0.08416194  	0.15905942  	0.15895332  
2023-06-13 20:49:35.044: Find a better model.
2023-06-13 20:50:17.588: [iter 22 : loss : 1.3646 = 0.4205 + 0.9421 + 0.0019, time: 42.538004]
2023-06-13 20:50:18.023: epoch 22:	0.08540812  	0.16138765  	0.16097102  
2023-06-13 20:50:18.023: Find a better model.
2023-06-13 20:51:00.781: [iter 23 : loss : 1.3186 = 0.3713 + 0.9449 + 0.0025, time: 42.750921]
2023-06-13 20:51:01.301: epoch 23:	0.08652015  	0.16361220  	0.16237020  
2023-06-13 20:51:01.301: Find a better model.
2023-06-13 20:51:44.085: [iter 24 : loss : 1.2793 = 0.3303 + 0.9461 + 0.0030, time: 42.776906]
2023-06-13 20:51:44.497: epoch 24:	0.08713251  	0.16496532  	0.16316867  
2023-06-13 20:51:44.497: Find a better model.
2023-06-13 20:52:27.122: [iter 25 : loss : 1.2473 = 0.2977 + 0.9462 + 0.0034, time: 42.617361]
2023-06-13 20:52:27.635: epoch 25:	0.08749786  	0.16634853  	0.16422288  
2023-06-13 20:52:27.635: Find a better model.
2023-06-13 20:53:10.387: [iter 26 : loss : 1.2193 = 0.2696 + 0.9458 + 0.0039, time: 42.743823]
2023-06-13 20:53:10.838: epoch 26:	0.08774496  	0.16647384  	0.16448554  
2023-06-13 20:53:10.838: Find a better model.
2023-06-13 20:53:53.510: [iter 27 : loss : 1.1957 = 0.2463 + 0.9451 + 0.0043, time: 42.665454]
2023-06-13 20:53:54.050: epoch 27:	0.08797058  	0.16723092  	0.16460972  
2023-06-13 20:53:54.051: Find a better model.
2023-06-13 20:54:36.292: [iter 28 : loss : 1.1757 = 0.2268 + 0.9443 + 0.0047, time: 42.235067]
2023-06-13 20:54:36.734: epoch 28:	0.08781482  	0.16669297  	0.16426413  
2023-06-13 20:55:20.271: [iter 29 : loss : 1.1585 = 0.2103 + 0.9431 + 0.0051, time: 43.521755]
2023-06-13 20:55:20.679: epoch 29:	0.08786318  	0.16660935  	0.16417648  
2023-06-13 20:56:00.829: [iter 30 : loss : 1.1434 = 0.1959 + 0.9420 + 0.0055, time: 40.142044]
2023-06-13 20:56:01.234: epoch 30:	0.08792224  	0.16681395  	0.16417713  
2023-06-13 20:56:40.611: [iter 31 : loss : 1.1297 = 0.1829 + 0.9410 + 0.0059, time: 39.369686]
2023-06-13 20:56:41.019: epoch 31:	0.08800820  	0.16683306  	0.16395721  
2023-06-13 20:57:20.482: [iter 32 : loss : 1.1184 = 0.1723 + 0.9399 + 0.0062, time: 39.455736]
2023-06-13 20:57:20.901: epoch 32:	0.08811569  	0.16659638  	0.16369876  
2023-06-13 20:58:00.549: [iter 33 : loss : 1.1074 = 0.1619 + 0.9389 + 0.0066, time: 39.642514]
2023-06-13 20:58:00.962: epoch 33:	0.08794912  	0.16582853  	0.16349618  
2023-06-13 20:58:40.482: [iter 34 : loss : 1.0988 = 0.1539 + 0.9380 + 0.0069, time: 39.511592]
2023-06-13 20:58:40.900: epoch 34:	0.08789010  	0.16560775  	0.16316308  
2023-06-13 20:59:20.758: [iter 35 : loss : 1.0898 = 0.1454 + 0.9372 + 0.0072, time: 39.851108]
2023-06-13 20:59:21.158: epoch 35:	0.08768059  	0.16477616  	0.16268624  
2023-06-13 21:00:01.147: [iter 36 : loss : 1.0827 = 0.1389 + 0.9363 + 0.0075, time: 39.981521]
2023-06-13 21:00:01.580: epoch 36:	0.08756238  	0.16445005  	0.16229007  
2023-06-13 21:00:41.730: [iter 37 : loss : 1.0754 = 0.1321 + 0.9355 + 0.0078, time: 40.143026]
2023-06-13 21:00:42.158: epoch 37:	0.08731525  	0.16344015  	0.16156507  
2023-06-13 21:01:22.495: [iter 38 : loss : 1.0693 = 0.1265 + 0.9347 + 0.0081, time: 40.331318]
2023-06-13 21:01:22.922: epoch 38:	0.08713266  	0.16277272  	0.16113542  
2023-06-13 21:02:02.884: [iter 39 : loss : 1.0639 = 0.1216 + 0.9340 + 0.0084, time: 39.956040]
2023-06-13 21:02:03.312: epoch 39:	0.08681040  	0.16173460  	0.16043504  
2023-06-13 21:02:43.632: [iter 40 : loss : 1.0590 = 0.1170 + 0.9334 + 0.0086, time: 40.311983]
2023-06-13 21:02:44.065: epoch 40:	0.08638072  	0.16042291  	0.15944715  
2023-06-13 21:03:24.446: [iter 41 : loss : 1.0538 = 0.1123 + 0.9326 + 0.0089, time: 40.374489]
2023-06-13 21:03:24.877: epoch 41:	0.08634845  	0.16031030  	0.15910123  
2023-06-13 21:04:05.253: [iter 42 : loss : 1.0497 = 0.1085 + 0.9321 + 0.0091, time: 40.367984]
2023-06-13 21:04:05.684: epoch 42:	0.08603147  	0.15967704  	0.15862836  
2023-06-13 21:04:46.085: [iter 43 : loss : 1.0453 = 0.1043 + 0.9316 + 0.0094, time: 40.395074]
2023-06-13 21:04:46.517: epoch 43:	0.08567157  	0.15799841  	0.15760918  
2023-06-13 21:05:26.991: [iter 44 : loss : 1.0417 = 0.1009 + 0.9312 + 0.0096, time: 40.464466]
2023-06-13 21:05:27.419: epoch 44:	0.08553724  	0.15770592  	0.15718605  
2023-06-13 21:06:07.769: [iter 45 : loss : 1.0388 = 0.0984 + 0.9306 + 0.0098, time: 40.342366]
2023-06-13 21:06:08.201: epoch 45:	0.08540834  	0.15734127  	0.15660885  
2023-06-13 21:06:48.578: [iter 46 : loss : 1.0353 = 0.0950 + 0.9302 + 0.0100, time: 40.370986]
2023-06-13 21:06:49.009: epoch 46:	0.08529551  	0.15698713  	0.15622795  
2023-06-13 21:07:30.487: [iter 47 : loss : 1.0324 = 0.0924 + 0.9298 + 0.0103, time: 41.469467]
2023-06-13 21:07:30.922: epoch 47:	0.08518812  	0.15658219  	0.15584619  
2023-06-13 21:08:11.339: [iter 48 : loss : 1.0289 = 0.0891 + 0.9293 + 0.0105, time: 40.410895]
2023-06-13 21:08:11.774: epoch 48:	0.08488190  	0.15590921  	0.15517829  
2023-06-13 21:08:51.800: [iter 49 : loss : 1.0266 = 0.0870 + 0.9289 + 0.0107, time: 40.019939]
2023-06-13 21:08:52.216: epoch 49:	0.08459185  	0.15469199  	0.15432486  
2023-06-13 21:09:29.924: my pid: 1160
2023-06-13 21:09:29.924: model: model.general_recommender.SGL
2023-06-13 21:09:29.925: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 21:09:29.925: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 21:09:35.548: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 21:10:17.978: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 42.429685]
2023-06-13 21:10:18.405: epoch 1:	0.00327674  	0.00799594  	0.00653715  
2023-06-13 21:10:18.405: Find a better model.
2023-06-13 21:10:59.156: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 40.745116]
2023-06-13 21:10:59.599: epoch 2:	0.00436181  	0.00903598  	0.00801343  
2023-06-13 21:10:59.599: Find a better model.
2023-06-13 21:11:41.270: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.663958]
2023-06-13 21:11:41.840: epoch 3:	0.00522127  	0.01081450  	0.00925025  
2023-06-13 21:11:41.840: Find a better model.
2023-06-13 21:12:23.042: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.157275]
2023-06-13 21:12:23.456: epoch 4:	0.00616669  	0.01217050  	0.01082897  
2023-06-13 21:12:23.456: Find a better model.
2023-06-13 21:13:05.122: [iter 5 : loss : 1.6056 = 0.6929 + 0.9126 + 0.0000, time: 41.660016]
2023-06-13 21:13:05.570: epoch 5:	0.00704765  	0.01391705  	0.01261049  
2023-06-13 21:13:05.570: Find a better model.
2023-06-13 21:13:46.069: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 40.492736]
2023-06-13 21:13:46.511: epoch 6:	0.00807368  	0.01601256  	0.01450421  
2023-06-13 21:13:46.511: Find a better model.
2023-06-13 21:14:28.195: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 41.677002]
2023-06-13 21:14:28.613: epoch 7:	0.00882575  	0.01738222  	0.01588885  
2023-06-13 21:14:28.613: Find a better model.
2023-06-13 21:15:10.441: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 41.819598]
2023-06-13 21:15:10.919: epoch 8:	0.01017947  	0.02016233  	0.01824575  
2023-06-13 21:15:10.919: Find a better model.
2023-06-13 21:15:51.385: [iter 9 : loss : 1.6056 = 0.6925 + 0.9130 + 0.0000, time: 40.459056]
2023-06-13 21:15:51.868: epoch 9:	0.01188772  	0.02375945  	0.02224217  
2023-06-13 21:15:51.868: Find a better model.
2023-06-13 21:16:33.559: [iter 10 : loss : 1.6054 = 0.6923 + 0.9130 + 0.0000, time: 41.684550]
2023-06-13 21:16:34.135: epoch 10:	0.01370880  	0.02734721  	0.02516038  
2023-06-13 21:16:34.135: Find a better model.
2023-06-13 21:17:15.917: [iter 11 : loss : 1.6052 = 0.6920 + 0.9131 + 0.0000, time: 41.775819]
2023-06-13 21:17:16.351: epoch 11:	0.01712533  	0.03237628  	0.03135397  
2023-06-13 21:17:16.351: Find a better model.
2023-06-13 21:17:58.760: [iter 12 : loss : 1.6049 = 0.6916 + 0.9133 + 0.0000, time: 42.402316]
2023-06-13 21:17:59.299: epoch 12:	0.02028938  	0.03934654  	0.03804018  
2023-06-13 21:17:59.299: Find a better model.
2023-06-13 21:18:41.276: [iter 13 : loss : 1.6045 = 0.6910 + 0.9136 + 0.0000, time: 41.969827]
2023-06-13 21:18:41.847: epoch 13:	0.02396911  	0.04768398  	0.04626501  
2023-06-13 21:18:41.848: Find a better model.
2023-06-13 21:19:24.581: [iter 14 : loss : 1.6038 = 0.6898 + 0.9139 + 0.0000, time: 42.727213]
2023-06-13 21:19:25.060: epoch 14:	0.03021628  	0.06084717  	0.05924287  
2023-06-13 21:19:25.060: Find a better model.
2023-06-13 21:20:07.598: [iter 15 : loss : 1.6022 = 0.6878 + 0.9143 + 0.0001, time: 42.529126]
2023-06-13 21:20:08.135: epoch 15:	0.03922410  	0.07787244  	0.07656216  
2023-06-13 21:20:08.135: Find a better model.
2023-06-13 21:20:50.344: [iter 16 : loss : 1.5989 = 0.6837 + 0.9151 + 0.0001, time: 42.200087]
2023-06-13 21:20:50.856: epoch 16:	0.04921509  	0.09600249  	0.09537725  
2023-06-13 21:20:50.856: Find a better model.
2023-06-13 21:21:33.502: [iter 17 : loss : 1.5913 = 0.6748 + 0.9164 + 0.0001, time: 42.638355]
2023-06-13 21:21:33.951: epoch 17:	0.06125258  	0.11651799  	0.11744688  
2023-06-13 21:21:33.951: Find a better model.
2023-06-13 21:22:16.557: [iter 18 : loss : 1.5742 = 0.6551 + 0.9189 + 0.0003, time: 42.599585]
2023-06-13 21:22:17.119: epoch 18:	0.07115760  	0.13374698  	0.13529238  
2023-06-13 21:22:17.119: Find a better model.
2023-06-13 21:23:00.000: [iter 19 : loss : 1.5409 = 0.6174 + 0.9230 + 0.0005, time: 42.874159]
2023-06-13 21:23:00.439: epoch 19:	0.07802247  	0.14627120  	0.14769298  
2023-06-13 21:23:00.439: Find a better model.
2023-06-13 21:23:42.421: [iter 20 : loss : 1.4915 = 0.5615 + 0.9291 + 0.0009, time: 41.974998]
2023-06-13 21:23:43.004: epoch 20:	0.08165357  	0.15343404  	0.15457080  
2023-06-13 21:23:43.004: Find a better model.
2023-06-13 21:24:25.283: [iter 21 : loss : 1.4339 = 0.4969 + 0.9357 + 0.0013, time: 42.271656]
2023-06-13 21:24:25.706: epoch 21:	0.08355507  	0.15718311  	0.15799695  
2023-06-13 21:24:25.707: Find a better model.
2023-06-13 21:25:08.582: [iter 22 : loss : 1.3780 = 0.4351 + 0.9410 + 0.0018, time: 42.858145]
2023-06-13 21:25:09.037: epoch 22:	0.08524168  	0.16084211  	0.16066833  
2023-06-13 21:25:09.038: Find a better model.
2023-06-13 21:25:51.241: [iter 23 : loss : 1.3295 = 0.3828 + 0.9444 + 0.0023, time: 42.196797]
2023-06-13 21:25:51.682: epoch 23:	0.08611187  	0.16310993  	0.16232535  
2023-06-13 21:25:51.682: Find a better model.
2023-06-13 21:26:34.548: [iter 24 : loss : 1.2883 = 0.3393 + 0.9461 + 0.0028, time: 42.859027]
2023-06-13 21:26:35.004: epoch 24:	0.08677793  	0.16414441  	0.16323833  
2023-06-13 21:26:35.004: Find a better model.
2023-06-13 21:27:15.477: [iter 25 : loss : 1.2544 = 0.3048 + 0.9464 + 0.0033, time: 40.465358]
2023-06-13 21:27:15.916: epoch 25:	0.08728823  	0.16510928  	0.16397497  
2023-06-13 21:27:15.917: Find a better model.
2023-06-13 21:27:56.094: [iter 26 : loss : 1.2253 = 0.2753 + 0.9462 + 0.0038, time: 40.170213]
2023-06-13 21:27:56.548: epoch 26:	0.08739029  	0.16545540  	0.16411299  
2023-06-13 21:27:56.548: Find a better model.
2023-06-13 21:28:36.502: [iter 27 : loss : 1.2008 = 0.2511 + 0.9455 + 0.0042, time: 39.947687]
2023-06-13 21:28:36.941: epoch 27:	0.08759438  	0.16560942  	0.16403012  
2023-06-13 21:28:36.941: Find a better model.
2023-06-13 21:29:16.187: [iter 28 : loss : 1.1801 = 0.2308 + 0.9446 + 0.0046, time: 39.239497]
2023-06-13 21:29:16.589: epoch 28:	0.08769112  	0.16537315  	0.16387454  
2023-06-13 21:29:56.479: [iter 29 : loss : 1.1625 = 0.2140 + 0.9435 + 0.0050, time: 39.882680]
2023-06-13 21:29:56.903: epoch 29:	0.08769108  	0.16528895  	0.16350390  
2023-06-13 21:30:36.535: [iter 30 : loss : 1.1467 = 0.1988 + 0.9424 + 0.0054, time: 39.623769]
2023-06-13 21:30:36.947: epoch 30:	0.08767503  	0.16493116  	0.16316715  
2023-06-13 21:31:16.325: [iter 31 : loss : 1.1325 = 0.1854 + 0.9413 + 0.0058, time: 39.371041]
2023-06-13 21:31:16.755: epoch 31:	0.08766963  	0.16513176  	0.16301993  
2023-06-13 21:31:56.106: [iter 32 : loss : 1.1209 = 0.1746 + 0.9402 + 0.0061, time: 39.342874]
2023-06-13 21:31:56.509: epoch 32:	0.08761058  	0.16457276  	0.16262734  
2023-06-13 21:32:36.065: [iter 33 : loss : 1.1098 = 0.1640 + 0.9393 + 0.0065, time: 39.549438]
2023-06-13 21:32:36.463: epoch 33:	0.08747636  	0.16375282  	0.16202039  
2023-06-13 21:33:16.541: [iter 34 : loss : 1.1011 = 0.1560 + 0.9383 + 0.0068, time: 40.070953]
2023-06-13 21:33:16.952: epoch 34:	0.08748711  	0.16371503  	0.16176414  
2023-06-13 21:33:56.402: [iter 35 : loss : 1.0917 = 0.1472 + 0.9374 + 0.0071, time: 39.443632]
2023-06-13 21:33:56.829: epoch 35:	0.08723997  	0.16317652  	0.16118678  
2023-06-13 21:34:36.400: [iter 36 : loss : 1.0846 = 0.1405 + 0.9366 + 0.0074, time: 39.565052]
2023-06-13 21:34:36.839: epoch 36:	0.08713789  	0.16255717  	0.16066281  
2023-06-13 21:35:16.224: [iter 37 : loss : 1.0770 = 0.1335 + 0.9357 + 0.0077, time: 39.378444]
2023-06-13 21:35:16.634: epoch 37:	0.08692838  	0.16156009  	0.16018276  
2023-06-13 21:35:58.311: [iter 38 : loss : 1.0710 = 0.1280 + 0.9349 + 0.0080, time: 41.670143]
2023-06-13 21:35:58.906: epoch 38:	0.08666518  	0.16082846  	0.15979539  
2023-06-13 21:36:23.065: my pid: 12056
2023-06-13 21:36:23.065: model: model.general_recommender.SGL
2023-06-13 21:36:23.065: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-13 21:36:23.065: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-13 21:36:28.570: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-13 21:37:09.800: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 41.229997]
2023-06-13 21:37:10.226: epoch 1:	0.00327674  	0.00799594  	0.00653715  
2023-06-13 21:37:10.226: Find a better model.
2023-06-13 21:37:50.906: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 40.672506]
2023-06-13 21:37:51.332: epoch 2:	0.00436181  	0.00903598  	0.00801343  
2023-06-13 21:37:51.332: Find a better model.
2023-06-13 21:38:32.229: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.891367]
2023-06-13 21:38:32.660: epoch 3:	0.00522127  	0.01081450  	0.00925025  
2023-06-13 21:38:32.661: Find a better model.
2023-06-13 21:39:13.202: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.534601]
2023-06-13 21:39:13.612: epoch 4:	0.00616669  	0.01217050  	0.01082897  
2023-06-13 21:39:13.612: Find a better model.
2023-06-13 21:39:53.527: [iter 5 : loss : 1.6056 = 0.6929 + 0.9126 + 0.0000, time: 39.908284]
2023-06-13 21:39:53.978: epoch 5:	0.00704765  	0.01391705  	0.01261049  
2023-06-13 21:39:53.978: Find a better model.
2023-06-13 21:40:33.982: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 39.997570]
2023-06-13 21:40:34.396: epoch 6:	0.00807368  	0.01601256  	0.01450421  
2023-06-13 21:40:34.396: Find a better model.
2023-06-13 21:41:14.548: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 40.145603]
2023-06-13 21:41:14.960: epoch 7:	0.00882575  	0.01738222  	0.01588885  
2023-06-13 21:41:14.960: Find a better model.
2023-06-13 21:41:57.245: [iter 8 : loss : 1.6055 = 0.6927 + 0.9128 + 0.0000, time: 42.279608]
2023-06-13 21:41:57.646: epoch 8:	0.01017947  	0.02016233  	0.01824575  
2023-06-13 21:41:57.646: Find a better model.
2023-06-13 21:42:38.974: [iter 9 : loss : 1.6056 = 0.6925 + 0.9130 + 0.0000, time: 41.320046]
2023-06-13 21:42:39.375: epoch 9:	0.01188772  	0.02375945  	0.02224217  
2023-06-13 21:42:39.375: Find a better model.
2023-06-13 21:43:20.570: [iter 10 : loss : 1.6054 = 0.6923 + 0.9130 + 0.0000, time: 41.186715]
2023-06-13 21:43:21.050: epoch 10:	0.01370880  	0.02734721  	0.02516038  
2023-06-13 21:43:21.050: Find a better model.
2023-06-13 21:44:03.013: [iter 11 : loss : 1.6052 = 0.6920 + 0.9131 + 0.0000, time: 41.957349]
2023-06-13 21:44:03.429: epoch 11:	0.01712533  	0.03237628  	0.03135397  
2023-06-13 21:44:03.430: Find a better model.
2023-06-13 21:44:45.402: [iter 12 : loss : 1.6049 = 0.6916 + 0.9133 + 0.0000, time: 41.965268]
2023-06-13 21:44:45.866: epoch 12:	0.02028938  	0.03934654  	0.03804018  
2023-06-13 21:44:45.866: Find a better model.
2023-06-13 21:45:27.348: [iter 13 : loss : 1.6045 = 0.6910 + 0.9136 + 0.0000, time: 41.474891]
2023-06-13 21:45:27.809: epoch 13:	0.02396911  	0.04768398  	0.04626501  
2023-06-13 21:45:27.810: Find a better model.
2023-06-13 21:46:09.275: [iter 14 : loss : 1.6038 = 0.6898 + 0.9139 + 0.0000, time: 41.459242]
2023-06-13 21:46:09.690: epoch 14:	0.03021628  	0.06084717  	0.05924287  
2023-06-13 21:46:09.690: Find a better model.
2023-06-13 21:46:50.974: [iter 15 : loss : 1.6022 = 0.6878 + 0.9143 + 0.0001, time: 41.269203]
2023-06-13 21:46:51.363: epoch 15:	0.03922410  	0.07787244  	0.07656216  
2023-06-13 21:46:51.363: Find a better model.
2023-06-13 21:47:32.255: [iter 16 : loss : 1.5989 = 0.6837 + 0.9151 + 0.0001, time: 40.886214]
2023-06-13 21:47:32.763: epoch 16:	0.04921509  	0.09600249  	0.09537725  
2023-06-13 21:47:32.763: Find a better model.
2023-06-13 21:48:14.522: [iter 17 : loss : 1.5913 = 0.6748 + 0.9164 + 0.0001, time: 41.749438]
2023-06-13 21:48:15.003: epoch 17:	0.06125258  	0.11651799  	0.11744688  
2023-06-13 21:48:15.003: Find a better model.
2023-06-13 21:48:57.032: [iter 18 : loss : 1.5742 = 0.6551 + 0.9189 + 0.0003, time: 42.022750]
2023-06-13 21:48:57.425: epoch 18:	0.07115760  	0.13374698  	0.13529238  
2023-06-13 21:48:57.425: Find a better model.
2023-06-13 21:49:39.803: [iter 19 : loss : 1.5409 = 0.6174 + 0.9230 + 0.0005, time: 42.370723]
2023-06-13 21:49:40.225: epoch 19:	0.07802247  	0.14627120  	0.14769298  
2023-06-13 21:49:40.225: Find a better model.
2023-06-13 21:50:21.758: [iter 20 : loss : 1.4915 = 0.5615 + 0.9291 + 0.0009, time: 41.527150]
2023-06-13 21:50:22.151: epoch 20:	0.08165357  	0.15343404  	0.15457080  
2023-06-13 21:50:22.151: Find a better model.
2023-06-13 21:51:03.189: [iter 21 : loss : 1.4339 = 0.4969 + 0.9357 + 0.0013, time: 41.031087]
2023-06-13 21:51:03.676: epoch 21:	0.08355507  	0.15718311  	0.15799695  
2023-06-13 21:51:03.676: Find a better model.
2023-06-13 21:51:45.590: [iter 22 : loss : 1.3780 = 0.4351 + 0.9410 + 0.0018, time: 41.907699]
2023-06-13 21:51:46.021: epoch 22:	0.08524168  	0.16084211  	0.16066833  
2023-06-13 21:51:46.021: Find a better model.
2023-06-13 21:52:28.594: [iter 23 : loss : 1.3295 = 0.3828 + 0.9444 + 0.0023, time: 42.566876]
2023-06-13 21:52:29.038: epoch 23:	0.08611187  	0.16310993  	0.16232535  
2023-06-13 21:52:29.038: Find a better model.
2023-06-13 21:53:10.105: [iter 24 : loss : 1.2883 = 0.3393 + 0.9461 + 0.0028, time: 41.060192]
2023-06-13 21:53:10.582: epoch 24:	0.08677793  	0.16414441  	0.16323833  
2023-06-13 21:53:10.583: Find a better model.
2023-06-13 21:53:52.434: [iter 25 : loss : 1.2544 = 0.3048 + 0.9464 + 0.0033, time: 41.844109]
2023-06-13 21:53:52.912: epoch 25:	0.08728823  	0.16510928  	0.16397497  
2023-06-13 21:53:52.912: Find a better model.
2023-06-13 21:54:35.512: [iter 26 : loss : 1.2253 = 0.2753 + 0.9462 + 0.0038, time: 42.593096]
2023-06-13 21:54:35.955: epoch 26:	0.08739029  	0.16545540  	0.16411299  
2023-06-13 21:54:35.955: Find a better model.
2023-06-13 21:55:17.263: [iter 27 : loss : 1.2008 = 0.2511 + 0.9455 + 0.0042, time: 41.301642]
2023-06-13 21:55:17.784: epoch 27:	0.08759438  	0.16560942  	0.16403012  
2023-06-13 21:55:17.784: Find a better model.
2023-06-13 21:55:59.925: [iter 28 : loss : 1.1801 = 0.2308 + 0.9446 + 0.0046, time: 42.132150]
2023-06-13 21:56:00.404: epoch 28:	0.08769112  	0.16537315  	0.16387454  
2023-06-13 21:56:43.026: [iter 29 : loss : 1.1625 = 0.2140 + 0.9435 + 0.0050, time: 42.613091]
2023-06-13 21:56:43.440: epoch 29:	0.08769108  	0.16528895  	0.16350390  
2023-06-13 21:57:24.996: [iter 30 : loss : 1.1467 = 0.1988 + 0.9424 + 0.0054, time: 41.549127]
2023-06-13 21:57:25.392: epoch 30:	0.08767503  	0.16493116  	0.16316715  
2023-06-13 21:58:06.497: [iter 31 : loss : 1.1325 = 0.1854 + 0.9413 + 0.0058, time: 41.093580]
2023-06-13 21:58:07.017: epoch 31:	0.08766963  	0.16513176  	0.16301993  
2023-06-13 21:58:49.191: [iter 32 : loss : 1.1209 = 0.1746 + 0.9402 + 0.0061, time: 42.166113]
2023-06-13 21:58:49.585: epoch 32:	0.08761058  	0.16457276  	0.16262734  
2023-06-13 21:59:31.856: [iter 33 : loss : 1.1098 = 0.1640 + 0.9393 + 0.0065, time: 42.264411]
2023-06-13 21:59:32.275: epoch 33:	0.08747636  	0.16375282  	0.16202039  
2023-06-13 22:00:13.969: [iter 34 : loss : 1.1011 = 0.1560 + 0.9383 + 0.0068, time: 41.686357]
2023-06-13 22:00:14.386: epoch 34:	0.08748711  	0.16371503  	0.16176414  
2023-06-13 22:00:56.633: [iter 35 : loss : 1.0917 = 0.1472 + 0.9374 + 0.0071, time: 42.240620]
2023-06-13 22:00:57.101: epoch 35:	0.08723997  	0.16317652  	0.16118678  
2023-06-13 22:01:35.933: [iter 36 : loss : 1.0846 = 0.1405 + 0.9366 + 0.0074, time: 38.824620]
2023-06-13 22:01:36.319: epoch 36:	0.08713789  	0.16255717  	0.16066281  
2023-06-13 22:02:15.199: [iter 37 : loss : 1.0770 = 0.1335 + 0.9357 + 0.0077, time: 38.874096]
2023-06-13 22:02:15.583: epoch 37:	0.08692838  	0.16156009  	0.16018276  
2023-06-13 22:02:54.565: [iter 38 : loss : 1.0710 = 0.1280 + 0.9349 + 0.0080, time: 38.976033]
2023-06-13 22:02:54.958: epoch 38:	0.08666518  	0.16082846  	0.15979539  
2023-06-13 22:03:33.996: [iter 39 : loss : 1.0652 = 0.1227 + 0.9342 + 0.0083, time: 39.031536]
2023-06-13 22:03:34.385: epoch 39:	0.08656314  	0.16026178  	0.15922509  
2023-06-13 22:04:13.530: [iter 40 : loss : 1.0601 = 0.1180 + 0.9336 + 0.0086, time: 39.139254]
2023-06-13 22:04:13.924: epoch 40:	0.08632137  	0.15964739  	0.15871373  
2023-06-13 22:04:52.685: [iter 41 : loss : 1.0551 = 0.1134 + 0.9329 + 0.0088, time: 38.755055]
2023-06-13 22:04:53.072: epoch 41:	0.08604210  	0.15870611  	0.15822151  
2023-06-13 22:05:32.120: [iter 42 : loss : 1.0506 = 0.1092 + 0.9323 + 0.0091, time: 39.039921]
2023-06-13 22:05:32.505: epoch 42:	0.08581100  	0.15817767  	0.15780038  
2023-06-13 22:06:11.490: [iter 43 : loss : 1.0461 = 0.1050 + 0.9317 + 0.0093, time: 38.978376]
2023-06-13 22:06:11.890: epoch 43:	0.08568748  	0.15753520  	0.15738033  
2023-06-13 22:06:50.860: [iter 44 : loss : 1.0424 = 0.1016 + 0.9313 + 0.0095, time: 38.964800]
2023-06-13 22:06:51.242: epoch 44:	0.08539745  	0.15688196  	0.15689079  
2023-06-13 22:07:30.312: [iter 45 : loss : 1.0396 = 0.0990 + 0.9307 + 0.0098, time: 39.063536]
2023-06-13 22:07:30.701: epoch 45:	0.08497847  	0.15573215  	0.15581018  
2023-06-13 22:08:09.841: [iter 46 : loss : 1.0359 = 0.0956 + 0.9303 + 0.0100, time: 39.125018]
2023-06-13 22:08:10.226: epoch 46:	0.08470989  	0.15511948  	0.15517336  
2023-06-13 22:08:49.441: [iter 47 : loss : 1.0329 = 0.0928 + 0.9298 + 0.0102, time: 39.208012]
2023-06-13 22:08:49.844: epoch 47:	0.08454876  	0.15493813  	0.15498523  
2023-06-13 22:09:29.019: [iter 48 : loss : 1.0299 = 0.0901 + 0.9294 + 0.0104, time: 39.169059]
2023-06-13 22:09:29.402: epoch 48:	0.08437692  	0.15447845  	0.15434185  
2023-06-13 22:10:08.413: [iter 49 : loss : 1.0273 = 0.0876 + 0.9290 + 0.0106, time: 39.005409]
2023-06-13 22:10:08.815: epoch 49:	0.08404923  	0.15321186  	0.15358043  
2023-06-13 22:10:47.783: [iter 50 : loss : 1.0247 = 0.0852 + 0.9287 + 0.0109, time: 38.960373]
2023-06-13 22:10:48.171: epoch 50:	0.08407610  	0.15268795  	0.15322527  
2023-06-13 22:11:27.199: [iter 51 : loss : 1.0224 = 0.0830 + 0.9283 + 0.0110, time: 39.022481]
2023-06-13 22:11:27.583: epoch 51:	0.08376987  	0.15207902  	0.15258944  
2023-06-13 22:12:06.755: [iter 52 : loss : 1.0203 = 0.0810 + 0.9281 + 0.0112, time: 39.164439]
2023-06-13 22:12:07.139: epoch 52:	0.08364090  	0.15147947  	0.15215290  
2023-06-13 22:12:07.139: Early stopping is trigger at epoch: 52
2023-06-13 22:12:07.139: best_result@epoch 27:

2023-06-13 22:12:07.139: 		0.0876      	0.1656      	0.1640      
2023-06-14 09:15:08.657: my pid: 15208
2023-06-14 09:15:08.657: model: model.general_recommender.SGL
2023-06-14 09:15:08.657: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 09:15:08.657: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 09:15:13.629: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 09:15:51.292: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 37.660941]
2023-06-14 09:15:51.719: epoch 1:	0.00323376  	0.00725407  	0.00581071  
2023-06-14 09:15:51.719: Find a better model.
2023-06-14 09:16:31.196: [iter 2 : loss : 1.6057 = 0.6931 + 0.9127 + 0.0000, time: 39.469975]
2023-06-14 09:16:31.637: epoch 2:	0.00425975  	0.00905280  	0.00746836  
2023-06-14 09:16:31.637: Find a better model.
2023-06-14 09:17:11.153: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 39.507412]
2023-06-14 09:17:11.597: epoch 3:	0.00545226  	0.01109858  	0.00959585  
2023-06-14 09:17:11.597: Find a better model.
2023-06-14 09:17:51.942: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 40.337356]
2023-06-14 09:17:52.472: epoch 4:	0.00564564  	0.01168656  	0.01002202  
2023-06-14 09:17:52.472: Find a better model.
2023-06-14 09:18:32.785: [iter 5 : loss : 1.6055 = 0.6929 + 0.9125 + 0.0000, time: 40.306227]
2023-06-14 09:18:33.185: epoch 5:	0.00654808  	0.01285265  	0.01124859  
2023-06-14 09:18:33.185: Find a better model.
2023-06-14 09:19:13.730: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 40.537917]
2023-06-14 09:19:14.155: epoch 6:	0.00824021  	0.01606951  	0.01430211  
2023-06-14 09:19:14.156: Find a better model.
2023-06-14 09:19:54.568: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 40.405606]
2023-06-14 09:19:54.980: epoch 7:	0.00891709  	0.01738410  	0.01569517  
2023-06-14 09:19:54.980: Find a better model.
2023-06-14 09:20:34.423: [iter 8 : loss : 1.6054 = 0.6927 + 0.9128 + 0.0000, time: 39.435238]
2023-06-14 09:20:34.877: epoch 8:	0.00995385  	0.01886240  	0.01760058  
2023-06-14 09:20:34.877: Find a better model.
2023-06-14 09:21:16.307: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 41.422331]
2023-06-14 09:21:16.850: epoch 9:	0.01142037  	0.02130285  	0.01967769  
2023-06-14 09:21:16.850: Find a better model.
2023-06-14 09:21:57.455: [iter 10 : loss : 1.6054 = 0.6923 + 0.9130 + 0.0000, time: 40.579804]
2023-06-14 09:21:57.853: epoch 10:	0.01305880  	0.02506782  	0.02323888  
2023-06-14 09:21:57.853: Find a better model.
2023-06-14 09:22:38.822: [iter 11 : loss : 1.6051 = 0.6920 + 0.9131 + 0.0000, time: 40.961833]
2023-06-14 09:22:39.306: epoch 11:	0.01586296  	0.03117077  	0.02907495  
2023-06-14 09:22:39.306: Find a better model.
2023-06-14 09:23:20.942: [iter 12 : loss : 1.6049 = 0.6916 + 0.9133 + 0.0000, time: 41.629833]
2023-06-14 09:23:21.444: epoch 12:	0.01975220  	0.03872171  	0.03663962  
2023-06-14 09:23:21.444: Find a better model.
2023-06-14 09:24:03.329: [iter 13 : loss : 1.6045 = 0.6909 + 0.9135 + 0.0000, time: 41.876891]
2023-06-14 09:24:03.762: epoch 13:	0.02439351  	0.04837978  	0.04653858  
2023-06-14 09:24:03.762: Find a better model.
2023-06-14 09:24:44.536: [iter 14 : loss : 1.6037 = 0.6898 + 0.9139 + 0.0000, time: 40.765633]
2023-06-14 09:24:45.071: epoch 14:	0.03085545  	0.06167858  	0.05974565  
2023-06-14 09:24:45.071: Find a better model.
2023-06-14 09:25:26.811: [iter 15 : loss : 1.6021 = 0.6877 + 0.9143 + 0.0001, time: 41.732701]
2023-06-14 09:25:27.229: epoch 15:	0.03961617  	0.07964584  	0.07780610  
2023-06-14 09:25:27.229: Find a better model.
2023-06-14 09:26:08.363: [iter 16 : loss : 1.5987 = 0.6835 + 0.9151 + 0.0001, time: 41.126566]
2023-06-14 09:26:08.798: epoch 16:	0.04996182  	0.09746978  	0.09716405  
2023-06-14 09:26:08.798: Find a better model.
2023-06-14 09:26:50.583: [iter 17 : loss : 1.5908 = 0.6742 + 0.9165 + 0.0001, time: 41.778925]
2023-06-14 09:26:51.088: epoch 17:	0.06205299  	0.11897781  	0.11958326  
2023-06-14 09:26:51.088: Find a better model.
2023-06-14 09:27:33.003: [iter 18 : loss : 1.5732 = 0.6539 + 0.9190 + 0.0003, time: 41.909506]
2023-06-14 09:27:33.466: epoch 18:	0.07266162  	0.13768537  	0.13823965  
2023-06-14 09:27:33.466: Find a better model.
2023-06-14 09:28:14.271: [iter 19 : loss : 1.5392 = 0.6153 + 0.9233 + 0.0005, time: 40.798020]
2023-06-14 09:28:14.808: epoch 19:	0.07872619  	0.14790969  	0.14850679  
2023-06-14 09:28:14.808: Find a better model.
2023-06-14 09:28:56.682: [iter 20 : loss : 1.4895 = 0.5592 + 0.9294 + 0.0009, time: 41.866575]
2023-06-14 09:28:57.091: epoch 20:	0.08227669  	0.15390682  	0.15500893  
2023-06-14 09:28:57.091: Find a better model.
2023-06-14 09:29:37.784: [iter 21 : loss : 1.4322 = 0.4950 + 0.9359 + 0.0013, time: 40.686486]
2023-06-14 09:29:38.190: epoch 21:	0.08407615  	0.15787727  	0.15870339  
2023-06-14 09:29:38.190: Find a better model.
2023-06-14 09:30:20.005: [iter 22 : loss : 1.3767 = 0.4339 + 0.9410 + 0.0018, time: 41.808105]
2023-06-14 09:30:20.439: epoch 22:	0.08540823  	0.16085017  	0.16087449  
2023-06-14 09:30:20.439: Find a better model.
2023-06-14 09:31:03.741: [iter 23 : loss : 1.3287 = 0.3821 + 0.9443 + 0.0023, time: 43.294293]
2023-06-14 09:31:04.223: epoch 23:	0.08595622  	0.16245539  	0.16199449  
2023-06-14 09:31:04.223: Find a better model.
2023-06-14 09:31:46.187: [iter 24 : loss : 1.2877 = 0.3390 + 0.9459 + 0.0028, time: 41.958501]
2023-06-14 09:31:46.714: epoch 24:	0.08684788  	0.16454276  	0.16352975  
2023-06-14 09:31:46.715: Find a better model.
2023-06-14 09:32:29.033: [iter 25 : loss : 1.2542 = 0.3046 + 0.9463 + 0.0033, time: 42.311684]
2023-06-14 09:32:29.470: epoch 25:	0.08711645  	0.16487862  	0.16380849  
2023-06-14 09:32:29.470: Find a better model.
2023-06-14 09:33:10.443: [iter 26 : loss : 1.2251 = 0.2753 + 0.9460 + 0.0038, time: 40.965208]
2023-06-14 09:33:10.837: epoch 26:	0.08744408  	0.16553675  	0.16392511  
2023-06-14 09:33:10.837: Find a better model.
2023-06-14 09:33:52.924: [iter 27 : loss : 1.2006 = 0.2511 + 0.9453 + 0.0042, time: 42.081788]
2023-06-14 09:33:53.366: epoch 27:	0.08763738  	0.16573660  	0.16407186  
2023-06-14 09:33:53.366: Find a better model.
2023-06-14 09:34:34.622: [iter 28 : loss : 1.1799 = 0.2307 + 0.9446 + 0.0046, time: 41.239822]
2023-06-14 09:34:35.112: epoch 28:	0.08770186  	0.16548403  	0.16371100  
2023-06-14 09:35:17.270: [iter 29 : loss : 1.1623 = 0.2139 + 0.9434 + 0.0050, time: 42.150648]
2023-06-14 09:35:17.771: epoch 29:	0.08766963  	0.16571143  	0.16362761  
2023-06-14 09:36:00.213: [iter 30 : loss : 1.1466 = 0.1989 + 0.9423 + 0.0054, time: 42.435650]
2023-06-14 09:36:00.660: epoch 30:	0.08769123  	0.16547184  	0.16343878  
2023-06-14 09:36:40.266: [iter 31 : loss : 1.1323 = 0.1853 + 0.9412 + 0.0058, time: 39.598802]
2023-06-14 09:36:40.674: epoch 31:	0.08752473  	0.16478024  	0.16295505  
2023-06-14 09:37:20.477: [iter 32 : loss : 1.1209 = 0.1746 + 0.9402 + 0.0061, time: 39.797400]
2023-06-14 09:37:20.885: epoch 32:	0.08756762  	0.16488041  	0.16295843  
2023-06-14 09:38:00.639: [iter 33 : loss : 1.1097 = 0.1639 + 0.9393 + 0.0065, time: 39.748277]
2023-06-14 09:38:01.050: epoch 33:	0.08755151  	0.16476019  	0.16260603  
2023-06-14 09:38:40.613: [iter 34 : loss : 1.1009 = 0.1558 + 0.9383 + 0.0068, time: 39.554347]
2023-06-14 09:38:41.015: epoch 34:	0.08742791  	0.16430645  	0.16217726  
2023-06-14 09:39:21.042: [iter 35 : loss : 1.0916 = 0.1470 + 0.9374 + 0.0071, time: 40.021807]
2023-06-14 09:39:21.471: epoch 35:	0.08725607  	0.16385747  	0.16170938  
2023-06-14 09:40:01.153: [iter 36 : loss : 1.0843 = 0.1403 + 0.9366 + 0.0074, time: 39.672339]
2023-06-14 09:40:01.564: epoch 36:	0.08708426  	0.16321018  	0.16124485  
2023-06-14 09:40:41.877: [iter 37 : loss : 1.0770 = 0.1335 + 0.9357 + 0.0077, time: 40.307518]
2023-06-14 09:40:42.400: epoch 37:	0.08708419  	0.16258936  	0.16091600  
2023-06-14 09:41:25.391: [iter 38 : loss : 1.0708 = 0.1278 + 0.9349 + 0.0080, time: 42.983212]
2023-06-14 09:41:25.913: epoch 38:	0.08691765  	0.16188636  	0.16034511  
2023-06-14 09:42:09.179: [iter 39 : loss : 1.0651 = 0.1226 + 0.9342 + 0.0083, time: 43.259264]
2023-06-14 09:42:09.656: epoch 39:	0.08673500  	0.16109487  	0.15979412  
2023-06-14 09:42:52.202: [iter 40 : loss : 1.0601 = 0.1180 + 0.9336 + 0.0086, time: 42.537967]
2023-06-14 09:42:52.711: epoch 40:	0.08649328  	0.16058047  	0.15913390  
2023-06-14 09:43:36.086: [iter 41 : loss : 1.0550 = 0.1133 + 0.9329 + 0.0088, time: 43.367967]
2023-06-14 09:43:36.525: epoch 41:	0.08644495  	0.15995724  	0.15865417  
2023-06-14 09:44:20.309: [iter 42 : loss : 1.0506 = 0.1092 + 0.9323 + 0.0091, time: 43.776546]
2023-06-14 09:44:20.762: epoch 42:	0.08625697  	0.15888330  	0.15797850  
2023-06-14 09:45:03.267: [iter 43 : loss : 1.0463 = 0.1053 + 0.9318 + 0.0093, time: 42.498155]
2023-06-14 09:45:03.746: epoch 43:	0.08606900  	0.15847087  	0.15750720  
2023-06-14 09:45:49.311: [iter 44 : loss : 1.0424 = 0.1015 + 0.9313 + 0.0095, time: 45.555782]
2023-06-14 09:45:49.759: epoch 44:	0.08585946  	0.15777768  	0.15691525  
2023-06-14 09:46:33.162: [iter 45 : loss : 1.0396 = 0.0990 + 0.9308 + 0.0098, time: 43.395782]
2023-06-14 09:46:33.663: epoch 45:	0.08565536  	0.15716511  	0.15628405  
2023-06-14 09:47:17.246: [iter 46 : loss : 1.0360 = 0.0956 + 0.9303 + 0.0100, time: 43.574564]
2023-06-14 09:47:17.765: epoch 46:	0.08525254  	0.15661393  	0.15573588  
2023-06-14 09:48:01.416: [iter 47 : loss : 1.0330 = 0.0929 + 0.9299 + 0.0102, time: 43.642528]
2023-06-14 09:48:01.957: epoch 47:	0.08517195  	0.15632175  	0.15529138  
2023-06-14 09:48:45.083: [iter 48 : loss : 1.0298 = 0.0900 + 0.9294 + 0.0104, time: 43.117669]
2023-06-14 09:48:45.622: epoch 48:	0.08483352  	0.15553054  	0.15463693  
2023-06-14 09:49:28.671: [iter 49 : loss : 1.0273 = 0.0876 + 0.9291 + 0.0106, time: 43.042070]
2023-06-14 09:49:29.138: epoch 49:	0.08457042  	0.15465674  	0.15398178  
2023-06-14 09:50:29.597: my pid: 1972
2023-06-14 09:50:29.597: model: model.general_recommender.SGL
2023-06-14 09:50:29.597: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 09:50:29.597: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 09:50:35.153: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 09:51:17.059: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 41.902973]
2023-06-14 09:51:17.590: epoch 1:	0.00331434  	0.00750123  	0.00627317  
2023-06-14 09:51:17.590: Find a better model.
2023-06-14 09:51:59.164: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 41.567384]
2023-06-14 09:51:59.644: epoch 2:	0.00406100  	0.00843877  	0.00712949  
2023-06-14 09:51:59.644: Find a better model.
2023-06-14 09:52:40.175: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.525054]
2023-06-14 09:52:40.744: epoch 3:	0.00506013  	0.01063083  	0.00895085  
2023-06-14 09:52:40.744: Find a better model.
2023-06-14 09:53:22.467: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.715716]
2023-06-14 09:53:22.921: epoch 4:	0.00553821  	0.01116652  	0.00975337  
2023-06-14 09:53:22.921: Find a better model.
2023-06-14 09:54:03.895: [iter 5 : loss : 1.6056 = 0.6929 + 0.9126 + 0.0000, time: 40.966968]
2023-06-14 09:54:04.474: epoch 5:	0.00648899  	0.01309519  	0.01165926  
2023-06-14 09:54:04.474: Find a better model.
2023-06-14 09:54:46.187: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 41.706188]
2023-06-14 09:54:46.663: epoch 6:	0.00736460  	0.01472269  	0.01302967  
2023-06-14 09:54:46.663: Find a better model.
2023-06-14 09:55:27.668: [iter 7 : loss : 1.6056 = 0.6928 + 0.9129 + 0.0000, time: 40.998592]
2023-06-14 09:55:28.231: epoch 7:	0.00842823  	0.01630655  	0.01507686  
2023-06-14 09:55:28.231: Find a better model.
2023-06-14 09:56:09.933: [iter 8 : loss : 1.6055 = 0.6926 + 0.9128 + 0.0000, time: 41.694278]
2023-06-14 09:56:10.452: epoch 8:	0.00962079  	0.01874245  	0.01733080  
2023-06-14 09:56:10.452: Find a better model.
2023-06-14 09:56:53.155: [iter 9 : loss : 1.6056 = 0.6925 + 0.9131 + 0.0000, time: 42.695698]
2023-06-14 09:56:53.666: epoch 9:	0.01144724  	0.02234074  	0.02040824  
2023-06-14 09:56:53.666: Find a better model.
2023-06-14 09:57:35.562: [iter 10 : loss : 1.6054 = 0.6923 + 0.9131 + 0.0000, time: 41.890371]
2023-06-14 09:57:35.993: epoch 10:	0.01325754  	0.02556555  	0.02347992  
2023-06-14 09:57:35.994: Find a better model.
2023-06-14 09:58:17.452: [iter 11 : loss : 1.6051 = 0.6919 + 0.9132 + 0.0000, time: 41.450070]
2023-06-14 09:58:18.024: epoch 11:	0.01581996  	0.03060576  	0.02896147  
2023-06-14 09:58:18.024: Find a better model.
2023-06-14 09:59:00.778: [iter 12 : loss : 1.6049 = 0.6915 + 0.9134 + 0.0000, time: 42.746281]
2023-06-14 09:59:01.225: epoch 12:	0.01977368  	0.03807422  	0.03600639  
2023-06-14 09:59:01.225: Find a better model.
2023-06-14 09:59:43.923: [iter 13 : loss : 1.6044 = 0.6907 + 0.9137 + 0.0000, time: 42.690592]
2023-06-14 09:59:44.368: epoch 13:	0.02439350  	0.04705729  	0.04559283  
2023-06-14 09:59:44.368: Find a better model.
2023-06-14 10:00:26.956: [iter 14 : loss : 1.6035 = 0.6895 + 0.9140 + 0.0000, time: 42.572280]
2023-06-14 10:00:27.454: epoch 14:	0.03137652  	0.06245342  	0.06038106  
2023-06-14 10:00:27.454: Find a better model.
2023-06-14 10:01:07.983: [iter 15 : loss : 1.6017 = 0.6871 + 0.9145 + 0.0001, time: 40.522331]
2023-06-14 10:01:08.431: epoch 15:	0.04042728  	0.08075340  	0.07930811  
2023-06-14 10:01:08.431: Find a better model.
2023-06-14 10:01:47.942: [iter 16 : loss : 1.5977 = 0.6823 + 0.9153 + 0.0001, time: 39.504091]
2023-06-14 10:01:48.383: epoch 16:	0.05198684  	0.10098997  	0.10113642  
2023-06-14 10:01:48.383: Find a better model.
2023-06-14 10:02:29.122: [iter 17 : loss : 1.5886 = 0.6718 + 0.9167 + 0.0002, time: 40.732385]
2023-06-14 10:02:29.569: epoch 17:	0.06365364  	0.12171403  	0.12287779  
2023-06-14 10:02:29.569: Find a better model.
2023-06-14 10:03:11.607: [iter 18 : loss : 1.5686 = 0.6488 + 0.9196 + 0.0003, time: 42.032206]
2023-06-14 10:03:12.049: epoch 18:	0.07342449  	0.13755681  	0.13935414  
2023-06-14 10:03:12.049: Find a better model.
2023-06-14 10:03:53.607: [iter 19 : loss : 1.5314 = 0.6065 + 0.9243 + 0.0006, time: 41.552027]
2023-06-14 10:03:54.071: epoch 19:	0.07882274  	0.14757363  	0.14965832  
2023-06-14 10:03:54.071: Find a better model.
2023-06-14 10:04:36.709: [iter 20 : loss : 1.4793 = 0.5477 + 0.9307 + 0.0009, time: 42.632015]
2023-06-14 10:04:37.143: epoch 20:	0.08170725  	0.15269622  	0.15516450  
2023-06-14 10:04:37.143: Find a better model.
2023-06-14 10:05:19.215: [iter 21 : loss : 1.4217 = 0.4831 + 0.9372 + 0.0014, time: 42.064610]
2023-06-14 10:05:19.642: epoch 21:	0.08399550  	0.15701704  	0.15870962  
2023-06-14 10:05:19.643: Find a better model.
2023-06-14 10:06:02.611: [iter 22 : loss : 1.3673 = 0.4234 + 0.9420 + 0.0019, time: 42.961978]
2023-06-14 10:06:03.020: epoch 22:	0.08532769  	0.15972695  	0.16088291  
2023-06-14 10:06:03.020: Find a better model.
2023-06-14 10:06:45.331: [iter 23 : loss : 1.3208 = 0.3735 + 0.9448 + 0.0024, time: 42.304557]
2023-06-14 10:06:45.836: epoch 23:	0.08656314  	0.16197725  	0.16252838  
2023-06-14 10:06:45.836: Find a better model.
2023-06-14 10:07:28.776: [iter 24 : loss : 1.2812 = 0.3321 + 0.9462 + 0.0029, time: 42.932488]
2023-06-14 10:07:29.188: epoch 24:	0.08707341  	0.16331135  	0.16348837  
2023-06-14 10:07:29.188: Find a better model.
2023-06-14 10:08:11.149: [iter 25 : loss : 1.2486 = 0.2990 + 0.9462 + 0.0034, time: 41.954551]
2023-06-14 10:08:11.607: epoch 25:	0.08745466  	0.16439360  	0.16421482  
2023-06-14 10:08:11.607: Find a better model.
2023-06-14 10:08:54.472: [iter 26 : loss : 1.2204 = 0.2707 + 0.9459 + 0.0039, time: 42.859569]
2023-06-14 10:08:54.909: epoch 26:	0.08760515  	0.16497426  	0.16432647  
2023-06-14 10:08:54.909: Find a better model.
2023-06-14 10:09:37.554: [iter 27 : loss : 1.1967 = 0.2473 + 0.9451 + 0.0043, time: 42.637294]
2023-06-14 10:09:37.961: epoch 27:	0.08766425  	0.16519390  	0.16451995  
2023-06-14 10:09:37.961: Find a better model.
2023-06-14 10:10:20.256: [iter 28 : loss : 1.1764 = 0.2274 + 0.9443 + 0.0047, time: 42.287342]
2023-06-14 10:10:20.709: epoch 28:	0.08776633  	0.16486441  	0.16445345  
2023-06-14 10:11:03.603: [iter 29 : loss : 1.1595 = 0.2112 + 0.9432 + 0.0051, time: 42.887022]
2023-06-14 10:11:04.010: epoch 29:	0.08760512  	0.16486956  	0.16415474  
2023-06-14 10:11:46.159: [iter 30 : loss : 1.1441 = 0.1965 + 0.9421 + 0.0055, time: 42.142385]
2023-06-14 10:11:46.714: epoch 30:	0.08748164  	0.16439825  	0.16407326  
2023-06-14 10:12:29.725: [iter 31 : loss : 1.1302 = 0.1833 + 0.9411 + 0.0058, time: 43.002529]
2023-06-14 10:12:30.143: epoch 31:	0.08722918  	0.16409065  	0.16368519  
2023-06-14 10:13:12.930: [iter 32 : loss : 1.1189 = 0.1727 + 0.9399 + 0.0062, time: 42.781667]
2023-06-14 10:13:13.372: epoch 32:	0.08728290  	0.16422874  	0.16356607  
2023-06-14 10:13:55.362: [iter 33 : loss : 1.1081 = 0.1625 + 0.9390 + 0.0065, time: 41.968798]
2023-06-14 10:13:55.800: epoch 33:	0.08733665  	0.16396140  	0.16331124  
2023-06-14 10:14:38.606: [iter 34 : loss : 1.0993 = 0.1543 + 0.9381 + 0.0069, time: 42.795913]
2023-06-14 10:14:39.058: epoch 34:	0.08700896  	0.16331261  	0.16278665  
2023-06-14 10:15:21.266: [iter 35 : loss : 1.0904 = 0.1459 + 0.9373 + 0.0072, time: 42.199101]
2023-06-14 10:15:21.784: epoch 35:	0.08681563  	0.16237068  	0.16227296  
2023-06-14 10:16:04.323: [iter 36 : loss : 1.0831 = 0.1393 + 0.9363 + 0.0075, time: 42.531161]
2023-06-14 10:16:04.829: epoch 36:	0.08653092  	0.16158633  	0.16167223  
2023-06-14 10:16:47.924: [iter 37 : loss : 1.0760 = 0.1327 + 0.9355 + 0.0078, time: 43.087323]
2023-06-14 10:16:48.507: epoch 37:	0.08657929  	0.16141175  	0.16132064  
2023-06-14 10:17:30.529: [iter 38 : loss : 1.0698 = 0.1270 + 0.9348 + 0.0081, time: 42.015905]
2023-06-14 10:17:31.087: epoch 38:	0.08642893  	0.16099997  	0.16091016  
2023-06-14 10:18:13.788: [iter 39 : loss : 1.0643 = 0.1219 + 0.9341 + 0.0083, time: 42.694452]
2023-06-14 10:18:14.290: epoch 39:	0.08627306  	0.16012935  	0.16024286  
2023-06-14 10:18:57.462: [iter 40 : loss : 1.0593 = 0.1173 + 0.9333 + 0.0086, time: 43.164257]
2023-06-14 10:18:57.912: epoch 40:	0.08612270  	0.15971035  	0.15967770  
2023-06-14 10:19:41.761: [iter 41 : loss : 1.0541 = 0.1125 + 0.9327 + 0.0088, time: 43.840775]
2023-06-14 10:19:42.291: epoch 41:	0.08615497  	0.15927763  	0.15942623  
2023-06-14 10:20:25.531: [iter 42 : loss : 1.0499 = 0.1086 + 0.9322 + 0.0091, time: 43.232564]
2023-06-14 10:20:25.946: epoch 42:	0.08583263  	0.15809736  	0.15861574  
2023-06-14 10:21:09.038: [iter 43 : loss : 1.0457 = 0.1047 + 0.9316 + 0.0093, time: 43.083426]
2023-06-14 10:21:09.507: epoch 43:	0.08553185  	0.15739177  	0.15785322  
2023-06-14 10:21:51.739: [iter 44 : loss : 1.0420 = 0.1012 + 0.9312 + 0.0096, time: 42.224225]
2023-06-14 10:21:52.188: epoch 44:	0.08542975  	0.15693261  	0.15747820  
2023-06-14 10:22:35.404: [iter 45 : loss : 1.0389 = 0.0984 + 0.9307 + 0.0098, time: 43.209126]
2023-06-14 10:22:35.833: epoch 45:	0.08519882  	0.15617582  	0.15670398  
2023-06-14 10:23:18.593: [iter 46 : loss : 1.0354 = 0.0952 + 0.9302 + 0.0100, time: 42.752718]
2023-06-14 10:23:19.086: epoch 46:	0.08502156  	0.15554874  	0.15613715  
2023-06-14 10:24:01.531: [iter 47 : loss : 1.0325 = 0.0925 + 0.9298 + 0.0103, time: 42.436517]
2023-06-14 10:24:01.943: epoch 47:	0.08466695  	0.15470193  	0.15546490  
2023-06-14 10:24:44.908: [iter 48 : loss : 1.0292 = 0.0895 + 0.9293 + 0.0105, time: 42.957816]
2023-06-14 10:24:45.348: epoch 48:	0.08452194  	0.15439796  	0.15498036  
2023-06-14 10:25:28.214: [iter 49 : loss : 1.0268 = 0.0871 + 0.9290 + 0.0107, time: 42.847399]
2023-06-14 10:25:28.764: epoch 49:	0.08416203  	0.15347035  	0.15427747  
2023-06-14 10:26:11.229: [iter 50 : loss : 1.0244 = 0.0850 + 0.9285 + 0.0109, time: 42.458160]
2023-06-14 10:26:11.686: epoch 50:	0.08399012  	0.15289703  	0.15384562  
2023-06-14 10:26:54.970: [iter 51 : loss : 1.0221 = 0.0828 + 0.9283 + 0.0111, time: 43.278085]
2023-06-14 10:26:55.433: epoch 51:	0.08383975  	0.15229142  	0.15324175  
2023-06-14 10:27:38.622: [iter 52 : loss : 1.0202 = 0.0810 + 0.9280 + 0.0112, time: 43.180458]
2023-06-14 10:27:39.034: epoch 52:	0.08353357  	0.15157989  	0.15270467  
2023-06-14 10:27:39.034: Early stopping is trigger at epoch: 52
2023-06-14 10:27:39.034: best_result@epoch 27:

2023-06-14 10:27:39.034: 		0.0877      	0.1652      	0.1645      
2023-06-14 10:41:23.773: my pid: 11536
2023-06-14 10:41:23.774: model: model.general_recommender.SGL
2023-06-14 10:41:23.774: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 10:41:23.774: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 10:41:29.276: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 10:42:10.436: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 41.158955]
2023-06-14 10:42:11.004: epoch 1:	0.00339491  	0.00820197  	0.00664284  
2023-06-14 10:42:11.004: Find a better model.
2023-06-14 10:42:52.289: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 41.278647]
2023-06-14 10:42:52.742: epoch 2:	0.00414157  	0.00972121  	0.00814261  
2023-06-14 10:42:52.742: Find a better model.
2023-06-14 10:43:34.361: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 41.612424]
2023-06-14 10:43:34.799: epoch 3:	0.00511921  	0.01078312  	0.00921200  
2023-06-14 10:43:34.799: Find a better model.
2023-06-14 10:44:16.468: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 41.661885]
2023-06-14 10:44:16.897: epoch 4:	0.00573696  	0.01197398  	0.01057105  
2023-06-14 10:44:16.897: Find a better model.
2023-06-14 10:44:58.033: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 41.129514]
2023-06-14 10:44:58.524: epoch 5:	0.00703153  	0.01472488  	0.01278895  
2023-06-14 10:44:58.524: Find a better model.
2023-06-14 10:45:38.795: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 40.261516]
2023-06-14 10:45:39.267: epoch 6:	0.00808444  	0.01562444  	0.01436647  
2023-06-14 10:45:39.267: Find a better model.
2023-06-14 10:46:22.075: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 42.800072]
2023-06-14 10:46:22.629: epoch 7:	0.00872906  	0.01683940  	0.01551933  
2023-06-14 10:46:22.629: Find a better model.
2023-06-14 10:47:04.311: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 41.673598]
2023-06-14 10:47:04.771: epoch 8:	0.00965841  	0.01976242  	0.01785981  
2023-06-14 10:47:04.772: Find a better model.
2023-06-14 10:47:46.736: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 41.958762]
2023-06-14 10:47:47.165: epoch 9:	0.01138814  	0.02246075  	0.02096011  
2023-06-14 10:47:47.165: Find a better model.
2023-06-14 10:48:28.077: [iter 10 : loss : 1.6053 = 0.6923 + 0.9130 + 0.0000, time: 40.904893]
2023-06-14 10:48:28.548: epoch 10:	0.01251623  	0.02523528  	0.02320814  
2023-06-14 10:48:28.548: Find a better model.
2023-06-14 10:49:10.937: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 42.381519]
2023-06-14 10:49:11.558: epoch 11:	0.01564807  	0.03102226  	0.02910236  
2023-06-14 10:49:11.558: Find a better model.
2023-06-14 10:49:54.525: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 42.959433]
2023-06-14 10:49:54.956: epoch 12:	0.01894640  	0.03803740  	0.03595537  
2023-06-14 10:49:54.956: Find a better model.
2023-06-14 10:50:36.731: [iter 13 : loss : 1.6046 = 0.6911 + 0.9135 + 0.0000, time: 41.765252]
2023-06-14 10:50:37.153: epoch 13:	0.02315259  	0.04600776  	0.04371751  
2023-06-14 10:50:37.153: Find a better model.
2023-06-14 10:51:20.138: [iter 14 : loss : 1.6039 = 0.6901 + 0.9138 + 0.0000, time: 42.977355]
2023-06-14 10:51:20.727: epoch 14:	0.02844375  	0.05724024  	0.05549050  
2023-06-14 10:51:20.727: Find a better model.
2023-06-14 10:52:02.605: [iter 15 : loss : 1.6026 = 0.6883 + 0.9142 + 0.0001, time: 41.871705]
2023-06-14 10:52:03.054: epoch 15:	0.03667262  	0.07340907  	0.07228414  
2023-06-14 10:52:03.054: Find a better model.
2023-06-14 10:52:45.767: [iter 16 : loss : 1.5998 = 0.6847 + 0.9149 + 0.0001, time: 42.706642]
2023-06-14 10:52:46.282: epoch 16:	0.04699126  	0.09231612  	0.09156861  
2023-06-14 10:52:46.282: Find a better model.
2023-06-14 10:53:29.370: [iter 17 : loss : 1.5932 = 0.6770 + 0.9161 + 0.0001, time: 43.080444]
2023-06-14 10:53:29.836: epoch 17:	0.05944245  	0.11466094  	0.11459666  
2023-06-14 10:53:29.836: Find a better model.
2023-06-14 10:54:11.637: [iter 18 : loss : 1.5785 = 0.6598 + 0.9184 + 0.0002, time: 41.792441]
2023-06-14 10:54:12.068: epoch 18:	0.07022293  	0.13236700  	0.13368973  
2023-06-14 10:54:12.068: Find a better model.
2023-06-14 10:54:54.816: [iter 19 : loss : 1.5486 = 0.6259 + 0.9223 + 0.0004, time: 42.742690]
2023-06-14 10:54:55.326: epoch 19:	0.07796321  	0.14540637  	0.14675091  
2023-06-14 10:54:55.326: Find a better model.
2023-06-14 10:55:38.322: [iter 20 : loss : 1.5019 = 0.5731 + 0.9281 + 0.0008, time: 42.989082]
2023-06-14 10:55:38.783: epoch 20:	0.08154614  	0.15202856  	0.15396480  
2023-06-14 10:55:38.783: Find a better model.
2023-06-14 10:56:20.681: [iter 21 : loss : 1.4454 = 0.5096 + 0.9346 + 0.0012, time: 41.889571]
2023-06-14 10:56:21.127: epoch 21:	0.08392571  	0.15634421  	0.15797019  
2023-06-14 10:56:21.127: Find a better model.
2023-06-14 10:57:03.868: [iter 22 : loss : 1.3888 = 0.4470 + 0.9401 + 0.0017, time: 42.734829]
2023-06-14 10:57:04.281: epoch 22:	0.08528467  	0.15899773  	0.16026857  
2023-06-14 10:57:04.282: Find a better model.
2023-06-14 10:57:46.659: [iter 23 : loss : 1.3390 = 0.3931 + 0.9436 + 0.0022, time: 42.367019]
2023-06-14 10:57:47.164: epoch 23:	0.08618719  	0.16099741  	0.16190650  
2023-06-14 10:57:47.164: Find a better model.
2023-06-14 10:58:30.165: [iter 24 : loss : 1.2964 = 0.3481 + 0.9456 + 0.0027, time: 42.994350]
2023-06-14 10:58:30.728: epoch 24:	0.08690157  	0.16252778  	0.16313796  
2023-06-14 10:58:30.728: Find a better model.
2023-06-14 10:59:13.841: [iter 25 : loss : 1.2614 = 0.3119 + 0.9462 + 0.0032, time: 43.106776]
2023-06-14 10:59:14.265: epoch 25:	0.08741722  	0.16398488  	0.16404711  
2023-06-14 10:59:14.265: Find a better model.
2023-06-14 10:59:56.358: [iter 26 : loss : 1.2311 = 0.2814 + 0.9460 + 0.0037, time: 42.086580]
2023-06-14 10:59:56.894: epoch 26:	0.08792211  	0.16484572  	0.16476394  
2023-06-14 10:59:56.894: Find a better model.
2023-06-14 11:00:40.033: [iter 27 : loss : 1.2058 = 0.2562 + 0.9455 + 0.0041, time: 43.130092]
2023-06-14 11:00:40.486: epoch 27:	0.08797587  	0.16550340  	0.16483152  
2023-06-14 11:00:40.486: Find a better model.
2023-06-14 11:01:22.674: [iter 28 : loss : 1.1844 = 0.2350 + 0.9448 + 0.0045, time: 42.179404]
2023-06-14 11:01:23.130: epoch 28:	0.08792757  	0.16582768  	0.16503969  
2023-06-14 11:01:23.130: Find a better model.
2023-06-14 11:02:06.454: [iter 29 : loss : 1.1662 = 0.2176 + 0.9436 + 0.0049, time: 43.316391]
2023-06-14 11:02:06.896: epoch 29:	0.08784708  	0.16563675  	0.16510890  
2023-06-14 11:02:49.040: [iter 30 : loss : 1.1499 = 0.2020 + 0.9426 + 0.0053, time: 42.136020]
2023-06-14 11:02:49.594: epoch 30:	0.08801359  	0.16570839  	0.16513704  
2023-06-14 11:03:32.882: [iter 31 : loss : 1.1352 = 0.1880 + 0.9415 + 0.0057, time: 43.281440]
2023-06-14 11:03:33.334: epoch 31:	0.08799741  	0.16584605  	0.16471034  
2023-06-14 11:03:33.334: Find a better model.
2023-06-14 11:04:15.291: [iter 32 : loss : 1.1235 = 0.1771 + 0.9404 + 0.0061, time: 41.949961]
2023-06-14 11:04:15.842: epoch 32:	0.08789001  	0.16530040  	0.16427906  
2023-06-14 11:04:59.354: [iter 33 : loss : 1.1120 = 0.1661 + 0.9395 + 0.0064, time: 43.505719]
2023-06-14 11:04:59.821: epoch 33:	0.08778258  	0.16454132  	0.16384721  
2023-06-14 11:05:42.479: [iter 34 : loss : 1.1031 = 0.1578 + 0.9386 + 0.0067, time: 42.649713]
2023-06-14 11:05:42.985: epoch 34:	0.08740115  	0.16360836  	0.16320860  
2023-06-14 11:06:26.671: [iter 35 : loss : 1.0938 = 0.1490 + 0.9377 + 0.0071, time: 43.679897]
2023-06-14 11:06:27.089: epoch 35:	0.08730979  	0.16321084  	0.16290912  
2023-06-14 11:07:09.765: [iter 36 : loss : 1.0861 = 0.1419 + 0.9369 + 0.0074, time: 42.667904]
2023-06-14 11:07:10.271: epoch 36:	0.08715939  	0.16271934  	0.16246489  
2023-06-14 11:07:53.510: [iter 37 : loss : 1.0786 = 0.1350 + 0.9359 + 0.0077, time: 43.230180]
2023-06-14 11:07:53.921: epoch 37:	0.08700366  	0.16198674  	0.16187692  
2023-06-14 11:08:36.083: [iter 38 : loss : 1.0722 = 0.1291 + 0.9351 + 0.0080, time: 42.154853]
2023-06-14 11:08:36.626: epoch 38:	0.08689085  	0.16145866  	0.16141732  
2023-06-14 11:09:18.677: [iter 39 : loss : 1.0664 = 0.1238 + 0.9344 + 0.0082, time: 42.043999]
2023-06-14 11:09:19.078: epoch 39:	0.08663832  	0.16082337  	0.16062611  
2023-06-14 11:09:59.091: [iter 40 : loss : 1.0614 = 0.1191 + 0.9338 + 0.0085, time: 40.005413]
2023-06-14 11:09:59.516: epoch 40:	0.08626772  	0.15973958  	0.16002025  
2023-06-14 11:10:39.521: [iter 41 : loss : 1.0561 = 0.1142 + 0.9331 + 0.0088, time: 39.999107]
2023-06-14 11:10:39.923: epoch 41:	0.08634287  	0.15941417  	0.15962900  
2023-06-14 11:11:19.901: [iter 42 : loss : 1.0516 = 0.1100 + 0.9325 + 0.0090, time: 39.970592]
2023-06-14 11:11:20.311: epoch 42:	0.08605812  	0.15938592  	0.15929855  
2023-06-14 11:11:59.931: [iter 43 : loss : 1.0472 = 0.1060 + 0.9319 + 0.0093, time: 39.614137]
2023-06-14 11:12:00.337: epoch 43:	0.08580036  	0.15862410  	0.15871596  
2023-06-14 11:12:40.275: [iter 44 : loss : 1.0435 = 0.1025 + 0.9315 + 0.0095, time: 39.931657]
2023-06-14 11:12:40.690: epoch 44:	0.08557472  	0.15789072  	0.15823236  
2023-06-14 11:13:20.631: [iter 45 : loss : 1.0404 = 0.0997 + 0.9309 + 0.0097, time: 39.932583]
2023-06-14 11:13:21.034: epoch 45:	0.08525240  	0.15713724  	0.15764406  
2023-06-14 11:14:00.984: [iter 46 : loss : 1.0366 = 0.0962 + 0.9305 + 0.0099, time: 39.944299]
2023-06-14 11:14:01.411: epoch 46:	0.08513959  	0.15641043  	0.15699902  
2023-06-14 11:14:41.190: [iter 47 : loss : 1.0335 = 0.0933 + 0.9301 + 0.0102, time: 39.771971]
2023-06-14 11:14:41.610: epoch 47:	0.08490321  	0.15562153  	0.15646824  
2023-06-14 11:15:21.613: [iter 48 : loss : 1.0303 = 0.0903 + 0.9296 + 0.0104, time: 39.995613]
2023-06-14 11:15:22.014: epoch 48:	0.08488175  	0.15525422  	0.15602945  
2023-06-14 11:16:01.857: [iter 49 : loss : 1.0279 = 0.0881 + 0.9292 + 0.0106, time: 39.835219]
2023-06-14 11:16:02.258: epoch 49:	0.08462927  	0.15473683  	0.15546335  
2023-06-14 11:16:42.179: [iter 50 : loss : 1.0253 = 0.0856 + 0.9289 + 0.0108, time: 39.914690]
2023-06-14 11:16:42.598: epoch 50:	0.08436608  	0.15425198  	0.15499489  
2023-06-14 11:17:22.616: [iter 51 : loss : 1.0230 = 0.0835 + 0.9285 + 0.0110, time: 40.009637]
2023-06-14 11:17:23.014: epoch 51:	0.08421032  	0.15355802  	0.15440230  
2023-06-14 11:18:03.293: [iter 52 : loss : 1.0210 = 0.0816 + 0.9282 + 0.0112, time: 40.270538]
2023-06-14 11:18:03.700: epoch 52:	0.08403849  	0.15312971  	0.15382414  
2023-06-14 11:18:43.740: [iter 53 : loss : 1.0186 = 0.0794 + 0.9279 + 0.0114, time: 40.033966]
2023-06-14 11:18:44.142: epoch 53:	0.08383974  	0.15239938  	0.15327731  
2023-06-14 11:19:24.122: [iter 54 : loss : 1.0164 = 0.0773 + 0.9275 + 0.0116, time: 39.972862]
2023-06-14 11:19:24.545: epoch 54:	0.08357652  	0.15197754  	0.15270627  
2023-06-14 11:20:05.063: [iter 55 : loss : 1.0148 = 0.0757 + 0.9273 + 0.0117, time: 40.510287]
2023-06-14 11:20:05.489: epoch 55:	0.08341540  	0.15109177  	0.15197979  
2023-06-14 11:20:46.089: [iter 56 : loss : 1.0127 = 0.0738 + 0.9270 + 0.0119, time: 40.593920]
2023-06-14 11:20:46.542: epoch 56:	0.08323818  	0.15046796  	0.15162843  
2023-06-14 11:20:46.542: Early stopping is trigger at epoch: 56
2023-06-14 11:20:46.542: best_result@epoch 31:

2023-06-14 11:20:46.543: 		0.0880      	0.1658      	0.1647      
2023-06-14 11:21:28.160: my pid: 3588
2023-06-14 11:21:28.160: model: model.general_recommender.SGL
2023-06-14 11:21:28.160: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 11:21:28.160: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 11:21:33.633: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 11:22:15.013: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 41.379813]
2023-06-14 11:22:15.494: epoch 1:	0.00329285  	0.00819437  	0.00631816  
2023-06-14 11:22:15.494: Find a better model.
2023-06-14 11:22:56.789: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 41.287117]
2023-06-14 11:22:57.302: epoch 2:	0.00379779  	0.00836190  	0.00717738  
2023-06-14 11:22:57.302: Find a better model.
2023-06-14 11:23:38.463: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 41.153594]
2023-06-14 11:23:39.000: epoch 3:	0.00472709  	0.01043044  	0.00874777  
2023-06-14 11:23:39.000: Find a better model.
2023-06-14 11:24:19.950: [iter 4 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 40.943712]
2023-06-14 11:24:20.504: epoch 4:	0.00555432  	0.01190087  	0.01030930  
2023-06-14 11:24:20.504: Find a better model.
2023-06-14 11:25:01.471: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 40.959060]
2023-06-14 11:25:01.890: epoch 5:	0.00652659  	0.01433623  	0.01205257  
2023-06-14 11:25:01.890: Find a better model.
2023-06-14 11:25:42.914: [iter 6 : loss : 1.6056 = 0.6929 + 0.9127 + 0.0000, time: 41.014173]
2023-06-14 11:25:43.457: epoch 6:	0.00725179  	0.01611264  	0.01365246  
2023-06-14 11:25:43.457: Find a better model.
2023-06-14 11:26:24.923: [iter 7 : loss : 1.6056 = 0.6928 + 0.9128 + 0.0000, time: 41.456248]
2023-06-14 11:26:25.345: epoch 7:	0.00819724  	0.01692488  	0.01524915  
2023-06-14 11:26:25.345: Find a better model.
2023-06-14 11:27:06.037: [iter 8 : loss : 1.6054 = 0.6926 + 0.9128 + 0.0000, time: 40.685035]
2023-06-14 11:27:06.543: epoch 8:	0.00890634  	0.01891304  	0.01678859  
2023-06-14 11:27:06.543: Find a better model.
2023-06-14 11:27:47.909: [iter 9 : loss : 1.6055 = 0.6925 + 0.9131 + 0.0000, time: 41.358835]
2023-06-14 11:27:48.344: epoch 9:	0.01073278  	0.02163156  	0.02025876  
2023-06-14 11:27:48.344: Find a better model.
2023-06-14 11:28:29.630: [iter 10 : loss : 1.6053 = 0.6923 + 0.9131 + 0.0000, time: 41.278510]
2023-06-14 11:28:30.050: epoch 10:	0.01263443  	0.02516249  	0.02334972  
2023-06-14 11:28:30.050: Find a better model.
2023-06-14 11:29:11.966: [iter 11 : loss : 1.6051 = 0.6919 + 0.9131 + 0.0000, time: 41.908641]
2023-06-14 11:29:12.413: epoch 11:	0.01526666  	0.03114550  	0.02886457  
2023-06-14 11:29:12.413: Find a better model.
2023-06-14 11:29:54.149: [iter 12 : loss : 1.6049 = 0.6915 + 0.9133 + 0.0000, time: 41.718918]
2023-06-14 11:29:54.654: epoch 12:	0.01851127  	0.03730022  	0.03478018  
2023-06-14 11:29:54.654: Find a better model.
2023-06-14 11:30:36.560: [iter 13 : loss : 1.6044 = 0.6908 + 0.9136 + 0.0000, time: 41.896855]
2023-06-14 11:30:36.993: epoch 13:	0.02331909  	0.04714482  	0.04445212  
2023-06-14 11:30:36.993: Find a better model.
2023-06-14 11:31:19.411: [iter 14 : loss : 1.6035 = 0.6895 + 0.9139 + 0.0000, time: 42.410821]
2023-06-14 11:31:19.826: epoch 14:	0.02959856  	0.06044393  	0.05749228  
2023-06-14 11:31:19.826: Find a better model.
2023-06-14 11:32:02.228: [iter 15 : loss : 1.6018 = 0.6873 + 0.9144 + 0.0001, time: 42.393383]
2023-06-14 11:32:02.709: epoch 15:	0.03847739  	0.07790274  	0.07631084  
2023-06-14 11:32:02.709: Find a better model.
2023-06-14 11:32:44.709: [iter 16 : loss : 1.5981 = 0.6828 + 0.9152 + 0.0001, time: 41.993944]
2023-06-14 11:32:45.220: epoch 16:	0.04962876  	0.09781124  	0.09685162  
2023-06-14 11:32:45.221: Find a better model.
2023-06-14 11:33:27.150: [iter 17 : loss : 1.5896 = 0.6728 + 0.9166 + 0.0002, time: 41.922579]
2023-06-14 11:33:27.656: epoch 17:	0.06185960  	0.11886381  	0.11960354  
2023-06-14 11:33:27.656: Find a better model.
2023-06-14 11:34:09.588: [iter 18 : loss : 1.5707 = 0.6511 + 0.9193 + 0.0003, time: 41.924765]
2023-06-14 11:34:10.023: epoch 18:	0.07279590  	0.13754168  	0.13814531  
2023-06-14 11:34:10.023: Find a better model.
2023-06-14 11:34:52.169: [iter 19 : loss : 1.5350 = 0.6107 + 0.9238 + 0.0005, time: 42.138026]
2023-06-14 11:34:52.657: epoch 19:	0.07860243  	0.14835261  	0.14903313  
2023-06-14 11:34:52.657: Find a better model.
2023-06-14 11:35:34.889: [iter 20 : loss : 1.4839 = 0.5527 + 0.9303 + 0.0009, time: 42.224084]
2023-06-14 11:35:35.297: epoch 20:	0.08169101  	0.15319644  	0.15461567  
2023-06-14 11:35:35.297: Find a better model.
2023-06-14 11:36:18.141: [iter 21 : loss : 1.4261 = 0.4880 + 0.9368 + 0.0014, time: 42.836453]
2023-06-14 11:36:18.577: epoch 21:	0.08387721  	0.15784954  	0.15851535  
2023-06-14 11:36:18.578: Find a better model.
2023-06-14 11:37:01.025: [iter 22 : loss : 1.3712 = 0.4275 + 0.9418 + 0.0019, time: 42.441089]
2023-06-14 11:37:01.559: epoch 22:	0.08515567  	0.16058651  	0.16082694  
2023-06-14 11:37:01.559: Find a better model.
2023-06-14 11:37:43.110: [iter 23 : loss : 1.3240 = 0.3768 + 0.9449 + 0.0024, time: 41.542865]
2023-06-14 11:37:43.611: epoch 23:	0.08587542  	0.16285247  	0.16248694  
2023-06-14 11:37:43.611: Find a better model.
2023-06-14 11:38:26.136: [iter 24 : loss : 1.2838 = 0.3347 + 0.9463 + 0.0029, time: 42.518083]
2023-06-14 11:38:26.586: epoch 24:	0.08645017  	0.16452202  	0.16355966  
2023-06-14 11:38:26.586: Find a better model.
2023-06-14 11:39:07.315: [iter 25 : loss : 1.2506 = 0.3008 + 0.9465 + 0.0034, time: 40.721812]
2023-06-14 11:39:07.866: epoch 25:	0.08697655  	0.16558443  	0.16413145  
2023-06-14 11:39:07.866: Find a better model.
2023-06-14 11:39:48.747: [iter 26 : loss : 1.2222 = 0.2723 + 0.9461 + 0.0038, time: 40.875169]
2023-06-14 11:39:49.155: epoch 26:	0.08726665  	0.16594017  	0.16436280  
2023-06-14 11:39:49.155: Find a better model.
2023-06-14 11:40:30.506: [iter 27 : loss : 1.1982 = 0.2486 + 0.9453 + 0.0043, time: 41.344335]
2023-06-14 11:40:30.913: epoch 27:	0.08759968  	0.16654916  	0.16445133  
2023-06-14 11:40:30.913: Find a better model.
2023-06-14 11:41:12.333: [iter 28 : loss : 1.1781 = 0.2289 + 0.9445 + 0.0047, time: 41.412904]
2023-06-14 11:41:12.766: epoch 28:	0.08750836  	0.16594025  	0.16417615  
2023-06-14 11:41:54.232: [iter 29 : loss : 1.1605 = 0.2120 + 0.9434 + 0.0051, time: 41.460253]
2023-06-14 11:41:54.725: epoch 29:	0.08763729  	0.16586703  	0.16406259  
2023-06-14 11:42:36.358: [iter 30 : loss : 1.1452 = 0.1974 + 0.9424 + 0.0054, time: 41.627218]
2023-06-14 11:42:36.763: epoch 30:	0.08751914  	0.16575338  	0.16377795  
2023-06-14 11:43:18.338: [iter 31 : loss : 1.1311 = 0.1842 + 0.9412 + 0.0058, time: 41.568460]
2023-06-14 11:43:18.770: epoch 31:	0.08733106  	0.16532077  	0.16325675  
2023-06-14 11:43:59.999: [iter 32 : loss : 1.1198 = 0.1735 + 0.9401 + 0.0062, time: 41.220421]
2023-06-14 11:44:00.461: epoch 32:	0.08738483  	0.16531137  	0.16299085  
2023-06-14 11:44:41.523: [iter 33 : loss : 1.1087 = 0.1629 + 0.9393 + 0.0065, time: 41.053613]
2023-06-14 11:44:42.028: epoch 33:	0.08727203  	0.16506253  	0.16248123  
2023-06-14 11:45:25.310: [iter 34 : loss : 1.0999 = 0.1548 + 0.9383 + 0.0068, time: 43.274793]
2023-06-14 11:45:25.744: epoch 34:	0.08723449  	0.16431463  	0.16185188  
2023-06-14 11:46:07.324: [iter 35 : loss : 1.0908 = 0.1462 + 0.9375 + 0.0072, time: 41.572678]
2023-06-14 11:46:07.822: epoch 35:	0.08724524  	0.16367175  	0.16162759  
2023-06-14 11:46:49.301: [iter 36 : loss : 1.0838 = 0.1398 + 0.9366 + 0.0074, time: 41.471977]
2023-06-14 11:46:49.730: epoch 36:	0.08696057  	0.16275509  	0.16100681  
2023-06-14 11:47:31.296: [iter 37 : loss : 1.0766 = 0.1331 + 0.9357 + 0.0078, time: 41.558319]
2023-06-14 11:47:31.723: epoch 37:	0.08667047  	0.16171025  	0.16037036  
2023-06-14 11:48:12.901: [iter 38 : loss : 1.0703 = 0.1274 + 0.9349 + 0.0080, time: 41.169564]
2023-06-14 11:48:13.421: epoch 38:	0.08651470  	0.16086562  	0.15986340  
2023-06-14 11:48:54.365: [iter 39 : loss : 1.0649 = 0.1225 + 0.9341 + 0.0083, time: 40.927023]
2023-06-14 11:48:54.903: epoch 39:	0.08633744  	0.16015677  	0.15928113  
2023-06-14 11:49:36.010: [iter 40 : loss : 1.0600 = 0.1179 + 0.9336 + 0.0086, time: 41.097921]
2023-06-14 11:49:36.545: epoch 40:	0.08602595  	0.15886135  	0.15841800  
2023-06-14 11:50:18.015: [iter 41 : loss : 1.0545 = 0.1129 + 0.9328 + 0.0088, time: 41.445638]
2023-06-14 11:50:18.548: epoch 41:	0.08587018  	0.15793134  	0.15780659  
2023-06-14 11:50:59.255: [iter 42 : loss : 1.0506 = 0.1092 + 0.9323 + 0.0091, time: 40.700528]
2023-06-14 11:50:59.646: epoch 42:	0.08556400  	0.15745015  	0.15736289  
2023-06-14 11:51:38.592: [iter 43 : loss : 1.0461 = 0.1050 + 0.9317 + 0.0093, time: 38.937766]
2023-06-14 11:51:38.975: epoch 43:	0.08543506  	0.15673506  	0.15685458  
2023-06-14 11:52:17.536: [iter 44 : loss : 1.0423 = 0.1015 + 0.9313 + 0.0096, time: 38.554590]
2023-06-14 11:52:17.917: epoch 44:	0.08508591  	0.15599702  	0.15614101  
2023-06-14 11:52:56.903: [iter 45 : loss : 1.0393 = 0.0988 + 0.9308 + 0.0098, time: 38.978070]
2023-06-14 11:52:57.288: epoch 45:	0.08479050  	0.15493448  	0.15522675  
2023-06-14 11:53:36.175: [iter 46 : loss : 1.0359 = 0.0956 + 0.9303 + 0.0100, time: 38.880270]
2023-06-14 11:53:36.569: epoch 46:	0.08462936  	0.15413360  	0.15473282  
2023-06-14 11:54:15.298: [iter 47 : loss : 1.0324 = 0.0923 + 0.9298 + 0.0102, time: 38.723289]
2023-06-14 11:54:15.685: epoch 47:	0.08428020  	0.15317048  	0.15398364  
2023-06-14 11:54:54.675: [iter 48 : loss : 1.0295 = 0.0896 + 0.9294 + 0.0104, time: 38.983478]
2023-06-14 11:54:55.058: epoch 48:	0.08398478  	0.15241390  	0.15334436  
2023-06-14 11:55:34.096: [iter 49 : loss : 1.0269 = 0.0872 + 0.9290 + 0.0107, time: 39.031869]
2023-06-14 11:55:34.499: epoch 49:	0.08364097  	0.15145680  	0.15246502  
2023-06-14 11:56:13.411: [iter 50 : loss : 1.0244 = 0.0849 + 0.9286 + 0.0109, time: 38.905095]
2023-06-14 11:56:13.795: epoch 50:	0.08333480  	0.15086086  	0.15190321  
2023-06-14 11:56:52.809: [iter 51 : loss : 1.0222 = 0.0828 + 0.9284 + 0.0110, time: 39.007286]
2023-06-14 11:56:53.196: epoch 51:	0.08322201  	0.15026166  	0.15145475  
2023-06-14 11:57:32.304: [iter 52 : loss : 1.0201 = 0.0808 + 0.9280 + 0.0112, time: 39.100659]
2023-06-14 11:57:32.696: epoch 52:	0.08307695  	0.14958042  	0.15104842  
2023-06-14 11:57:32.696: Early stopping is trigger at epoch: 52
2023-06-14 11:57:32.696: best_result@epoch 27:

2023-06-14 11:57:32.696: 		0.0876      	0.1665      	0.1645      
2023-06-14 14:35:42.720: my pid: 2108
2023-06-14 14:35:42.720: model: model.general_recommender.SGL
2023-06-14 14:35:42.720: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 14:35:42.720: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 14:35:47.766: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 14:36:25.418: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 37.651912]
2023-06-14 14:36:25.834: epoch 1:	0.00308873  	0.00749564  	0.00598206  
2023-06-14 14:36:25.834: Find a better model.
2023-06-14 14:37:03.219: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 37.379621]
2023-06-14 14:37:03.642: epoch 2:	0.00403951  	0.00955267  	0.00777235  
2023-06-14 14:37:03.642: Find a better model.
2023-06-14 14:37:41.195: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 37.547053]
2023-06-14 14:37:41.617: epoch 3:	0.00479692  	0.01083058  	0.00902361  
2023-06-14 14:37:41.617: Find a better model.
2023-06-14 14:38:19.156: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 37.532270]
2023-06-14 14:38:19.580: epoch 4:	0.00528036  	0.01135618  	0.00978752  
2023-06-14 14:38:19.581: Find a better model.
2023-06-14 14:38:57.150: [iter 5 : loss : 1.6054 = 0.6929 + 0.9124 + 0.0000, time: 37.561534]
2023-06-14 14:38:57.579: epoch 5:	0.00653733  	0.01441188  	0.01241495  
2023-06-14 14:38:57.580: Find a better model.
2023-06-14 14:39:35.229: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 37.643781]
2023-06-14 14:39:35.653: epoch 6:	0.00719807  	0.01649765  	0.01393481  
2023-06-14 14:39:35.653: Find a better model.
2023-06-14 14:40:13.379: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 37.718809]
2023-06-14 14:40:13.801: epoch 7:	0.00832617  	0.01857751  	0.01598376  
2023-06-14 14:40:13.801: Find a better model.
2023-06-14 14:40:51.746: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 37.938215]
2023-06-14 14:40:52.167: epoch 8:	0.00865923  	0.01913148  	0.01659488  
2023-06-14 14:40:52.167: Find a better model.
2023-06-14 14:41:30.135: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 37.961065]
2023-06-14 14:41:30.550: epoch 9:	0.01023320  	0.02200940  	0.01893127  
2023-06-14 14:41:30.550: Find a better model.
2023-06-14 14:42:08.640: [iter 10 : loss : 1.6053 = 0.6923 + 0.9129 + 0.0000, time: 38.083284]
2023-06-14 14:42:09.057: epoch 10:	0.01168360  	0.02488614  	0.02164791  
2023-06-14 14:42:09.058: Find a better model.
2023-06-14 14:42:48.081: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 39.017149]
2023-06-14 14:42:48.502: epoch 11:	0.01418690  	0.03005236  	0.02681440  
2023-06-14 14:42:48.502: Find a better model.
2023-06-14 14:43:27.698: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 39.189603]
2023-06-14 14:43:28.116: epoch 12:	0.01764104  	0.03671921  	0.03426385  
2023-06-14 14:43:28.116: Find a better model.
2023-06-14 14:44:07.306: [iter 13 : loss : 1.6046 = 0.6911 + 0.9134 + 0.0000, time: 39.184248]
2023-06-14 14:44:07.727: epoch 13:	0.02135302  	0.04467274  	0.04178465  
2023-06-14 14:44:07.727: Find a better model.
2023-06-14 14:44:46.886: [iter 14 : loss : 1.6039 = 0.6901 + 0.9138 + 0.0000, time: 39.152592]
2023-06-14 14:44:47.306: epoch 14:	0.02686991  	0.05617295  	0.05373560  
2023-06-14 14:44:47.306: Find a better model.
2023-06-14 14:45:26.422: [iter 15 : loss : 1.6026 = 0.6884 + 0.9142 + 0.0001, time: 39.110009]
2023-06-14 14:45:26.836: epoch 15:	0.03488391  	0.07175555  	0.07033201  
2023-06-14 14:45:26.837: Find a better model.
2023-06-14 14:46:05.881: [iter 16 : loss : 1.5999 = 0.6849 + 0.9149 + 0.0001, time: 39.038042]
2023-06-14 14:46:06.294: epoch 16:	0.04489632  	0.09027476  	0.08940550  
2023-06-14 14:46:06.294: Find a better model.
2023-06-14 14:46:45.473: [iter 17 : loss : 1.5937 = 0.6774 + 0.9161 + 0.0001, time: 39.173013]
2023-06-14 14:46:45.891: epoch 17:	0.05690705  	0.11133499  	0.11039849  
2023-06-14 14:46:45.891: Find a better model.
2023-06-14 14:47:25.045: [iter 18 : loss : 1.5796 = 0.6610 + 0.9184 + 0.0002, time: 39.148103]
2023-06-14 14:47:25.459: epoch 18:	0.06816027  	0.13064153  	0.13004266  
2023-06-14 14:47:25.459: Find a better model.
2023-06-14 14:48:04.570: [iter 19 : loss : 1.5511 = 0.6284 + 0.9223 + 0.0004, time: 39.105005]
2023-06-14 14:48:04.988: epoch 19:	0.07550861  	0.14308232  	0.14378627  
2023-06-14 14:48:04.988: Find a better model.
2023-06-14 14:48:44.194: [iter 20 : loss : 1.5061 = 0.5776 + 0.9278 + 0.0008, time: 39.198025]
2023-06-14 14:48:44.611: epoch 20:	0.07997219  	0.15114492  	0.15170769  
2023-06-14 14:48:44.611: Find a better model.
2023-06-14 14:49:23.791: [iter 21 : loss : 1.4511 = 0.5158 + 0.9341 + 0.0012, time: 39.172681]
2023-06-14 14:49:24.205: epoch 21:	0.08264715  	0.15606134  	0.15608843  
2023-06-14 14:49:24.205: Find a better model.
2023-06-14 14:50:03.415: [iter 22 : loss : 1.3953 = 0.4541 + 0.9395 + 0.0017, time: 39.203755]
2023-06-14 14:50:03.833: epoch 22:	0.08429621  	0.15948620  	0.15875444  
2023-06-14 14:50:03.833: Find a better model.
2023-06-14 14:50:43.565: [iter 23 : loss : 1.3455 = 0.4001 + 0.9432 + 0.0022, time: 39.726149]
2023-06-14 14:50:43.982: epoch 23:	0.08555851  	0.16186447  	0.16078703  
2023-06-14 14:50:43.982: Find a better model.
2023-06-14 14:51:23.346: [iter 24 : loss : 1.3022 = 0.3543 + 0.9452 + 0.0027, time: 39.356716]
2023-06-14 14:51:23.759: epoch 24:	0.08637496  	0.16331561  	0.16189091  
2023-06-14 14:51:23.759: Find a better model.
2023-06-14 14:52:03.118: [iter 25 : loss : 1.2666 = 0.3175 + 0.9460 + 0.0032, time: 39.352037]
2023-06-14 14:52:03.533: epoch 25:	0.08698200  	0.16479284  	0.16301633  
2023-06-14 14:52:03.534: Find a better model.
2023-06-14 14:52:42.733: [iter 26 : loss : 1.2356 = 0.2861 + 0.9459 + 0.0036, time: 39.193038]
2023-06-14 14:52:43.152: epoch 26:	0.08721299  	0.16494991  	0.16343687  
2023-06-14 14:52:43.152: Find a better model.
2023-06-14 14:53:22.505: [iter 27 : loss : 1.2097 = 0.2602 + 0.9454 + 0.0041, time: 39.347283]
2023-06-14 14:53:22.918: epoch 27:	0.08751914  	0.16598934  	0.16381511  
2023-06-14 14:53:22.918: Find a better model.
2023-06-14 14:54:02.278: [iter 28 : loss : 1.1879 = 0.2386 + 0.9448 + 0.0045, time: 39.353404]
2023-06-14 14:54:02.693: epoch 28:	0.08766423  	0.16591693  	0.16391116  
2023-06-14 14:54:42.079: [iter 29 : loss : 1.1694 = 0.2208 + 0.9437 + 0.0049, time: 39.380016]
2023-06-14 14:54:42.499: epoch 29:	0.08774488  	0.16604047  	0.16409597  
2023-06-14 14:54:42.499: Find a better model.
2023-06-14 14:55:21.837: [iter 30 : loss : 1.1528 = 0.2049 + 0.9427 + 0.0053, time: 39.331116]
2023-06-14 14:55:22.251: epoch 30:	0.08779323  	0.16589075  	0.16388844  
2023-06-14 14:56:01.451: [iter 31 : loss : 1.1378 = 0.1905 + 0.9417 + 0.0057, time: 39.193780]
2023-06-14 14:56:01.864: epoch 31:	0.08761591  	0.16529682  	0.16352956  
2023-06-14 14:56:41.436: [iter 32 : loss : 1.1257 = 0.1791 + 0.9406 + 0.0060, time: 39.564303]
2023-06-14 14:56:41.852: epoch 32:	0.08755690  	0.16495763  	0.16327488  
2023-06-14 14:57:21.395: [iter 33 : loss : 1.1141 = 0.1680 + 0.9397 + 0.0064, time: 39.536326]
2023-06-14 14:57:21.812: epoch 33:	0.08745483  	0.16428284  	0.16277134  
2023-06-14 14:58:01.399: [iter 34 : loss : 1.1047 = 0.1593 + 0.9387 + 0.0067, time: 39.579493]
2023-06-14 14:58:01.819: epoch 34:	0.08714861  	0.16355945  	0.16234039  
2023-06-14 14:58:41.394: [iter 35 : loss : 1.0951 = 0.1502 + 0.9378 + 0.0070, time: 39.569711]
2023-06-14 14:58:41.816: epoch 35:	0.08692840  	0.16258392  	0.16181505  
2023-06-14 14:59:21.209: [iter 36 : loss : 1.0876 = 0.1432 + 0.9370 + 0.0073, time: 39.385443]
2023-06-14 14:59:21.628: epoch 36:	0.08674581  	0.16184309  	0.16131118  
2023-06-14 15:00:01.314: [iter 37 : loss : 1.0798 = 0.1360 + 0.9361 + 0.0076, time: 39.678119]
2023-06-14 15:00:01.735: epoch 37:	0.08678338  	0.16111596  	0.16087793  
2023-06-14 15:00:41.581: [iter 38 : loss : 1.0734 = 0.1302 + 0.9354 + 0.0079, time: 39.840209]
2023-06-14 15:00:42.000: epoch 38:	0.08656852  	0.16071647  	0.16031119  
2023-06-14 15:01:21.968: [iter 39 : loss : 1.0677 = 0.1249 + 0.9346 + 0.0082, time: 39.961175]
2023-06-14 15:01:22.386: epoch 39:	0.08642345  	0.16009958  	0.15983203  
2023-06-14 15:02:02.290: [iter 40 : loss : 1.0624 = 0.1200 + 0.9339 + 0.0085, time: 39.898008]
2023-06-14 15:02:02.708: epoch 40:	0.08612265  	0.15936202  	0.15922326  
2023-06-14 15:02:42.340: [iter 41 : loss : 1.0570 = 0.1150 + 0.9332 + 0.0087, time: 39.626127]
2023-06-14 15:02:42.760: epoch 41:	0.08592391  	0.15843329  	0.15853268  
2023-06-14 15:03:22.887: [iter 42 : loss : 1.0525 = 0.1108 + 0.9327 + 0.0090, time: 40.120547]
2023-06-14 15:03:23.306: epoch 42:	0.08563924  	0.15772477  	0.15797348  
2023-06-14 15:04:03.283: [iter 43 : loss : 1.0481 = 0.1067 + 0.9322 + 0.0092, time: 39.969550]
2023-06-14 15:04:03.699: epoch 43:	0.08555333  	0.15734465  	0.15767604  
2023-06-14 15:04:44.046: [iter 44 : loss : 1.0442 = 0.1029 + 0.9317 + 0.0095, time: 40.339024]
2023-06-14 15:04:44.467: epoch 44:	0.08523642  	0.15628785  	0.15699664  
2023-06-14 15:05:24.775: [iter 45 : loss : 1.0411 = 0.1003 + 0.9312 + 0.0097, time: 40.300173]
2023-06-14 15:05:25.196: epoch 45:	0.08489802  	0.15552038  	0.15615156  
2023-06-14 15:06:05.443: [iter 46 : loss : 1.0376 = 0.0969 + 0.9307 + 0.0099, time: 40.240288]
2023-06-14 15:06:05.868: epoch 46:	0.08472080  	0.15484908  	0.15556708  
2023-06-14 15:06:46.454: [iter 47 : loss : 1.0341 = 0.0937 + 0.9302 + 0.0102, time: 40.579065]
2023-06-14 15:06:46.874: epoch 47:	0.08436631  	0.15386853  	0.15468721  
2023-06-14 15:07:27.404: [iter 48 : loss : 1.0312 = 0.0909 + 0.9299 + 0.0104, time: 40.523482]
2023-06-14 15:07:27.825: epoch 48:	0.08403326  	0.15319373  	0.15407206  
2023-06-14 15:08:08.173: [iter 49 : loss : 1.0284 = 0.0884 + 0.9293 + 0.0106, time: 40.342233]
2023-06-14 15:08:08.594: epoch 49:	0.08389896  	0.15268204  	0.15360849  
2023-06-14 15:08:49.028: [iter 50 : loss : 1.0259 = 0.0862 + 0.9290 + 0.0108, time: 40.426854]
2023-06-14 15:08:49.445: epoch 50:	0.08362509  	0.15193209  	0.15285152  
2023-06-14 15:09:29.975: [iter 51 : loss : 1.0235 = 0.0838 + 0.9287 + 0.0110, time: 40.524425]
2023-06-14 15:09:30.392: epoch 51:	0.08330275  	0.15113626  	0.15209474  
2023-06-14 15:10:10.513: [iter 52 : loss : 1.0216 = 0.0820 + 0.9285 + 0.0112, time: 40.113542]
2023-06-14 15:10:10.937: epoch 52:	0.08311476  	0.15056129  	0.15161265  
2023-06-14 15:10:51.358: [iter 53 : loss : 1.0191 = 0.0797 + 0.9281 + 0.0114, time: 40.414331]
2023-06-14 15:10:51.778: epoch 53:	0.08295898  	0.15019566  	0.15118988  
2023-06-14 15:11:32.300: [iter 54 : loss : 1.0169 = 0.0777 + 0.9277 + 0.0115, time: 40.515117]
2023-06-14 15:11:32.720: epoch 54:	0.08287303  	0.15005645  	0.15091492  
2023-06-14 15:11:32.720: Early stopping is trigger at epoch: 54
2023-06-14 15:11:32.720: best_result@epoch 29:

2023-06-14 15:11:32.720: 		0.0877      	0.1660      	0.1641      
2023-06-14 15:16:51.382: my pid: 9372
2023-06-14 15:16:51.383: model: model.general_recommender.SGL
2023-06-14 15:16:51.383: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 15:16:51.383: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 15:16:56.139: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 15:17:34.069: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 37.929679]
2023-06-14 15:17:34.471: epoch 1:	0.00286849  	0.00750079  	0.00572356  
2023-06-14 15:17:34.471: Find a better model.
2023-06-14 15:18:11.895: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 37.418644]
2023-06-14 15:18:12.301: epoch 2:	0.00340566  	0.00874756  	0.00670066  
2023-06-14 15:18:12.302: Find a better model.
2023-06-14 15:18:49.772: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 37.463979]
2023-06-14 15:18:50.179: epoch 3:	0.00445850  	0.01014317  	0.00805423  
2023-06-14 15:18:50.180: Find a better model.
2023-06-14 15:19:27.584: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 37.396104]
2023-06-14 15:19:27.972: epoch 4:	0.00459279  	0.01171856  	0.00908505  
2023-06-14 15:19:27.973: Find a better model.
2023-06-14 15:20:05.529: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 37.550558]
2023-06-14 15:20:05.939: epoch 5:	0.00555432  	0.01272546  	0.01084099  
2023-06-14 15:20:05.939: Find a better model.
2023-06-14 15:20:43.529: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 37.584258]
2023-06-14 15:20:43.933: epoch 6:	0.00647287  	0.01570366  	0.01298180  
2023-06-14 15:20:43.933: Find a better model.
2023-06-14 15:21:21.495: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 37.555596]
2023-06-14 15:21:21.911: epoch 7:	0.00730013  	0.01688174  	0.01406345  
2023-06-14 15:21:21.911: Find a better model.
2023-06-14 15:21:59.496: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 37.578332]
2023-06-14 15:21:59.903: epoch 8:	0.00776749  	0.01684200  	0.01442842  
2023-06-14 15:22:37.317: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 37.407991]
2023-06-14 15:22:37.713: epoch 9:	0.00958319  	0.02153779  	0.01875853  
2023-06-14 15:22:37.713: Find a better model.
2023-06-14 15:23:15.454: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 37.733283]
2023-06-14 15:23:15.876: epoch 10:	0.01100136  	0.02443870  	0.02130806  
2023-06-14 15:23:15.876: Find a better model.
2023-06-14 15:23:54.663: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 38.780384]
2023-06-14 15:23:55.083: epoch 11:	0.01339723  	0.02938451  	0.02571670  
2023-06-14 15:23:55.084: Find a better model.
2023-06-14 15:24:34.245: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 39.154815]
2023-06-14 15:24:34.662: epoch 12:	0.01624970  	0.03517658  	0.03124307  
2023-06-14 15:24:34.662: Find a better model.
2023-06-14 15:25:13.794: [iter 13 : loss : 1.6045 = 0.6911 + 0.9134 + 0.0000, time: 39.124743]
2023-06-14 15:25:14.209: epoch 13:	0.01966087  	0.04207252  	0.03893461  
2023-06-14 15:25:14.209: Find a better model.
2023-06-14 15:25:53.407: [iter 14 : loss : 1.6039 = 0.6901 + 0.9137 + 0.0000, time: 39.191273]
2023-06-14 15:25:53.822: epoch 14:	0.02553235  	0.05419159  	0.04991756  
2023-06-14 15:25:53.822: Find a better model.
2023-06-14 15:26:33.062: [iter 15 : loss : 1.6026 = 0.6883 + 0.9142 + 0.0001, time: 39.233614]
2023-06-14 15:26:33.476: epoch 15:	0.03326716  	0.07023130  	0.06622383  
2023-06-14 15:26:33.476: Find a better model.
2023-06-14 15:27:12.445: [iter 16 : loss : 1.5999 = 0.6849 + 0.9149 + 0.0001, time: 38.962037]
2023-06-14 15:27:12.857: epoch 16:	0.04384890  	0.08909671  	0.08607310  
2023-06-14 15:27:12.857: Find a better model.
2023-06-14 15:27:52.042: [iter 17 : loss : 1.5937 = 0.6776 + 0.9160 + 0.0001, time: 39.178600]
2023-06-14 15:27:52.459: epoch 17:	0.05656324  	0.11134806  	0.10957558  
2023-06-14 15:27:52.459: Find a better model.
2023-06-14 15:28:31.656: [iter 18 : loss : 1.5798 = 0.6613 + 0.9182 + 0.0002, time: 39.191143]
2023-06-14 15:28:32.075: epoch 18:	0.06814408  	0.13074058  	0.13028832  
2023-06-14 15:28:32.075: Find a better model.
2023-06-14 15:29:11.376: [iter 19 : loss : 1.5513 = 0.6290 + 0.9219 + 0.0004, time: 39.294760]
2023-06-14 15:29:11.790: epoch 19:	0.07628737  	0.14399482  	0.14434026  
2023-06-14 15:29:11.790: Find a better model.
2023-06-14 15:29:51.013: [iter 20 : loss : 1.5061 = 0.5779 + 0.9275 + 0.0008, time: 39.216254]
2023-06-14 15:29:51.423: epoch 20:	0.08075645  	0.15151043  	0.15210515  
2023-06-14 15:29:51.423: Find a better model.
2023-06-14 15:30:30.575: [iter 21 : loss : 1.4503 = 0.5153 + 0.9338 + 0.0012, time: 39.144428]
2023-06-14 15:30:30.989: epoch 21:	0.08321655  	0.15641545  	0.15679561  
2023-06-14 15:30:30.989: Find a better model.
2023-06-14 15:31:10.383: [iter 22 : loss : 1.3936 = 0.4524 + 0.9395 + 0.0017, time: 39.385998]
2023-06-14 15:31:10.793: epoch 22:	0.08467752  	0.15955186  	0.15959862  
2023-06-14 15:31:10.793: Find a better model.
2023-06-14 15:31:50.132: [iter 23 : loss : 1.3434 = 0.3979 + 0.9433 + 0.0022, time: 39.333347]
2023-06-14 15:31:50.541: epoch 23:	0.08588080  	0.16217129  	0.16161954  
2023-06-14 15:31:50.541: Find a better model.
2023-06-14 15:32:29.896: [iter 24 : loss : 1.3002 = 0.3521 + 0.9454 + 0.0027, time: 39.348518]
2023-06-14 15:32:30.310: epoch 24:	0.08660059  	0.16335997  	0.16260844  
2023-06-14 15:32:30.310: Find a better model.
2023-06-14 15:33:09.630: [iter 25 : loss : 1.2645 = 0.3153 + 0.9460 + 0.0032, time: 39.312402]
2023-06-14 15:33:10.039: epoch 25:	0.08706257  	0.16434874  	0.16339964  
2023-06-14 15:33:10.040: Find a better model.
2023-06-14 15:33:49.472: [iter 26 : loss : 1.2335 = 0.2838 + 0.9461 + 0.0036, time: 39.425245]
2023-06-14 15:33:49.886: epoch 26:	0.08744399  	0.16506764  	0.16394502  
2023-06-14 15:33:49.886: Find a better model.
2023-06-14 15:34:29.313: [iter 27 : loss : 1.2080 = 0.2584 + 0.9455 + 0.0041, time: 39.419401]
2023-06-14 15:34:29.722: epoch 27:	0.08749239  	0.16528943  	0.16383797  
2023-06-14 15:34:29.722: Find a better model.
2023-06-14 15:35:09.104: [iter 28 : loss : 1.1862 = 0.2368 + 0.9449 + 0.0045, time: 39.375846]
2023-06-14 15:35:09.518: epoch 28:	0.08762673  	0.16571046  	0.16408618  
2023-06-14 15:35:09.518: Find a better model.
2023-06-14 15:35:49.034: [iter 29 : loss : 1.1679 = 0.2191 + 0.9438 + 0.0049, time: 39.508509]
2023-06-14 15:35:49.446: epoch 29:	0.08762675  	0.16565539  	0.16383876  
2023-06-14 15:36:30.243: [iter 30 : loss : 1.1512 = 0.2032 + 0.9427 + 0.0053, time: 40.790026]
2023-06-14 15:36:30.737: epoch 30:	0.08772878  	0.16559920  	0.16368011  
2023-06-14 15:37:11.054: [iter 31 : loss : 1.1365 = 0.1890 + 0.9418 + 0.0057, time: 40.309125]
2023-06-14 15:37:11.470: epoch 31:	0.08775567  	0.16552077  	0.16336554  
2023-06-14 15:37:50.979: [iter 32 : loss : 1.1246 = 0.1779 + 0.9407 + 0.0060, time: 39.502755]
2023-06-14 15:37:51.383: epoch 32:	0.08758380  	0.16493550  	0.16305360  
2023-06-14 15:38:32.137: [iter 33 : loss : 1.1130 = 0.1669 + 0.9396 + 0.0064, time: 40.745456]
2023-06-14 15:38:32.575: epoch 33:	0.08752465  	0.16459759  	0.16247976  
2023-06-14 15:39:13.149: [iter 34 : loss : 1.1038 = 0.1583 + 0.9388 + 0.0067, time: 40.567517]
2023-06-14 15:39:13.637: epoch 34:	0.08733670  	0.16355449  	0.16179088  
2023-06-14 15:39:57.308: [iter 35 : loss : 1.0942 = 0.1493 + 0.9379 + 0.0070, time: 43.664746]
2023-06-14 15:39:57.763: epoch 35:	0.08713260  	0.16314401  	0.16148511  
2023-06-14 15:40:41.741: [iter 36 : loss : 1.0869 = 0.1424 + 0.9371 + 0.0073, time: 43.970192]
2023-06-14 15:40:42.174: epoch 36:	0.08694458  	0.16252513  	0.16069436  
2023-06-14 15:41:25.898: [iter 37 : loss : 1.0791 = 0.1352 + 0.9362 + 0.0076, time: 43.715898]
2023-06-14 15:41:26.306: epoch 37:	0.08678884  	0.16189405  	0.16017029  
2023-06-14 15:42:10.027: [iter 38 : loss : 1.0730 = 0.1297 + 0.9354 + 0.0079, time: 43.713584]
2023-06-14 15:42:10.473: epoch 38:	0.08660082  	0.16123466  	0.15959316  
2023-06-14 15:42:54.303: [iter 39 : loss : 1.0672 = 0.1243 + 0.9347 + 0.0082, time: 43.823482]
2023-06-14 15:42:54.937: epoch 39:	0.08649337  	0.16067971  	0.15901469  
2023-06-14 15:43:38.969: [iter 40 : loss : 1.0619 = 0.1193 + 0.9341 + 0.0085, time: 44.023353]
2023-06-14 15:43:39.484: epoch 40:	0.08626240  	0.15997183  	0.15835026  
2023-06-14 15:44:23.952: [iter 41 : loss : 1.0565 = 0.1144 + 0.9334 + 0.0087, time: 44.459441]
2023-06-14 15:44:24.482: epoch 41:	0.08630535  	0.15965632  	0.15812890  
2023-06-14 15:45:08.996: [iter 42 : loss : 1.0522 = 0.1103 + 0.9329 + 0.0090, time: 44.507114]
2023-06-14 15:45:09.734: epoch 42:	0.08601530  	0.15894106  	0.15737689  
2023-06-14 15:45:53.649: [iter 43 : loss : 1.0474 = 0.1060 + 0.9322 + 0.0092, time: 43.905442]
2023-06-14 15:45:54.307: epoch 43:	0.08578430  	0.15813614  	0.15690121  
2023-06-14 15:46:40.203: [iter 44 : loss : 1.0437 = 0.1025 + 0.9317 + 0.0095, time: 45.889433]
2023-06-14 15:46:40.715: epoch 44:	0.08570912  	0.15797846  	0.15655042  
2023-06-14 15:46:48.820: my pid: 14340
2023-06-14 15:46:48.820: model: model.general_recommender.SGL
2023-06-14 15:46:48.820: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 15:46:48.820: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 15:46:54.216: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 15:47:36.702: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 42.485658]
2023-06-14 15:47:37.095: epoch 1:	0.00253008  	0.00806749  	0.00584187  
2023-06-14 15:47:37.095: Find a better model.
2023-06-14 15:48:17.230: [iter 2 : loss : 1.6055 = 0.6931 + 0.9124 + 0.0000, time: 40.127414]
2023-06-14 15:48:17.728: epoch 2:	0.00334120  	0.00982877  	0.00714127  
2023-06-14 15:48:17.728: Find a better model.
2023-06-14 15:48:58.070: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 40.335917]
2023-06-14 15:48:58.531: epoch 3:	0.00368498  	0.01061061  	0.00773496  
2023-06-14 15:48:58.532: Find a better model.
2023-06-14 15:49:39.094: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 40.544925]
2023-06-14 15:49:39.510: epoch 4:	0.00451759  	0.01227686  	0.00910329  
2023-06-14 15:49:39.511: Find a better model.
2023-06-14 15:50:20.225: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 40.696558]
2023-06-14 15:50:20.994: epoch 5:	0.00499567  	0.01207742  	0.00957946  
2023-06-14 15:51:03.158: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 42.156777]
2023-06-14 15:51:03.590: epoch 6:	0.00576918  	0.01398558  	0.01145272  
2023-06-14 15:51:03.590: Find a better model.
2023-06-14 15:51:45.870: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 42.271735]
2023-06-14 15:51:46.278: epoch 7:	0.00633858  	0.01490367  	0.01185578  
2023-06-14 15:51:46.278: Find a better model.
2023-06-14 15:52:28.921: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 42.636913]
2023-06-14 15:52:29.371: epoch 8:	0.00683277  	0.01631001  	0.01350831  
2023-06-14 15:52:29.371: Find a better model.
2023-06-14 15:53:12.448: [iter 9 : loss : 1.6053 = 0.6926 + 0.9128 + 0.0000, time: 43.067900]
2023-06-14 15:53:12.858: epoch 9:	0.00836914  	0.02027050  	0.01656684  
2023-06-14 15:53:12.858: Find a better model.
2023-06-14 15:53:55.592: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 42.728385]
2023-06-14 15:53:56.002: epoch 10:	0.00951873  	0.02200155  	0.01887245  
2023-06-14 15:53:56.002: Find a better model.
2023-06-14 15:54:39.103: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 43.093354]
2023-06-14 15:54:39.520: epoch 11:	0.01138815  	0.02642246  	0.02286013  
2023-06-14 15:54:39.520: Find a better model.
2023-06-14 15:55:22.682: [iter 12 : loss : 1.6049 = 0.6918 + 0.9131 + 0.0000, time: 43.146584]
2023-06-14 15:55:23.102: epoch 12:	0.01381623  	0.03239118  	0.02818558  
2023-06-14 15:55:23.102: Find a better model.
2023-06-14 15:56:06.556: [iter 13 : loss : 1.6046 = 0.6912 + 0.9133 + 0.0000, time: 43.445165]
2023-06-14 15:56:06.976: epoch 13:	0.01644312  	0.03815028  	0.03371413  
2023-06-14 15:56:06.976: Find a better model.
2023-06-14 15:56:50.604: [iter 14 : loss : 1.6040 = 0.6904 + 0.9136 + 0.0000, time: 43.622307]
2023-06-14 15:56:51.016: epoch 14:	0.02173444  	0.04963809  	0.04448229  
2023-06-14 15:56:51.016: Find a better model.
2023-06-14 15:57:34.966: [iter 15 : loss : 1.6029 = 0.6888 + 0.9140 + 0.0000, time: 43.944031]
2023-06-14 15:57:35.371: epoch 15:	0.02906685  	0.06429293  	0.05889986  
2023-06-14 15:57:35.371: Find a better model.
2023-06-14 15:58:18.129: [iter 16 : loss : 1.6007 = 0.6859 + 0.9147 + 0.0001, time: 42.746534]
2023-06-14 15:58:18.671: epoch 16:	0.03936367  	0.08367157  	0.07853188  
2023-06-14 15:58:18.672: Find a better model.
2023-06-14 15:59:01.121: [iter 17 : loss : 1.5955 = 0.6797 + 0.9158 + 0.0001, time: 42.440731]
2023-06-14 15:59:01.737: epoch 17:	0.05173973  	0.10507533  	0.10185220  
2023-06-14 15:59:01.738: Find a better model.
2023-06-14 15:59:44.181: [iter 18 : loss : 1.5838 = 0.6659 + 0.9177 + 0.0002, time: 42.437879]
2023-06-14 15:59:44.795: epoch 18:	0.06427673  	0.12612174  	0.12394372  
2023-06-14 15:59:44.795: Find a better model.
2023-06-14 16:00:27.238: [iter 19 : loss : 1.5590 = 0.6374 + 0.9212 + 0.0004, time: 42.430725]
2023-06-14 16:00:27.841: epoch 19:	0.07409049  	0.14179209  	0.14031102  
2023-06-14 16:00:27.841: Find a better model.
2023-06-14 16:01:09.912: [iter 20 : loss : 1.5175 = 0.5903 + 0.9265 + 0.0007, time: 42.063715]
2023-06-14 16:01:10.524: epoch 20:	0.07949422  	0.15114871  	0.14977674  
2023-06-14 16:01:10.524: Find a better model.
2023-06-14 16:01:53.001: [iter 21 : loss : 1.4634 = 0.5293 + 0.9329 + 0.0011, time: 42.457393]
2023-06-14 16:01:53.627: epoch 21:	0.08232497  	0.15602821  	0.15434013  
2023-06-14 16:01:53.627: Find a better model.
2023-06-14 16:02:36.153: [iter 22 : loss : 1.4067 = 0.4662 + 0.9390 + 0.0016, time: 42.516292]
2023-06-14 16:02:36.767: epoch 22:	0.08390969  	0.15922278  	0.15745860  
2023-06-14 16:02:36.767: Find a better model.
2023-06-14 16:03:19.500: [iter 23 : loss : 1.3551 = 0.4099 + 0.9431 + 0.0021, time: 42.720826]
2023-06-14 16:03:20.100: epoch 23:	0.08517735  	0.16139601  	0.15983365  
2023-06-14 16:03:20.100: Find a better model.
2023-06-14 16:04:02.613: [iter 24 : loss : 1.3106 = 0.3625 + 0.9455 + 0.0026, time: 42.503590]
2023-06-14 16:04:03.212: epoch 24:	0.08597770  	0.16281584  	0.16128753  
2023-06-14 16:04:03.212: Find a better model.
2023-06-14 16:04:46.498: [iter 25 : loss : 1.2736 = 0.3241 + 0.9464 + 0.0031, time: 43.276750]
2023-06-14 16:04:47.102: epoch 25:	0.08641813  	0.16342258  	0.16225450  
2023-06-14 16:04:47.102: Find a better model.
2023-06-14 16:05:30.584: [iter 26 : loss : 1.2415 = 0.2914 + 0.9465 + 0.0035, time: 43.469132]
2023-06-14 16:05:31.178: epoch 26:	0.08680490  	0.16444936  	0.16283275  
2023-06-14 16:05:31.178: Find a better model.
2023-06-14 16:06:14.516: [iter 27 : loss : 1.2147 = 0.2647 + 0.9460 + 0.0040, time: 43.328071]
2023-06-14 16:06:15.110: epoch 27:	0.08724003  	0.16523115  	0.16337660  
2023-06-14 16:06:15.110: Find a better model.
2023-06-14 16:06:57.514: [iter 28 : loss : 1.1921 = 0.2424 + 0.9453 + 0.0044, time: 42.391201]
2023-06-14 16:06:58.107: epoch 28:	0.08741190  	0.16544357  	0.16361825  
2023-06-14 16:06:58.107: Find a better model.
2023-06-14 16:07:41.342: [iter 29 : loss : 1.1726 = 0.2236 + 0.9442 + 0.0048, time: 43.220438]
2023-06-14 16:07:41.947: epoch 29:	0.08748174  	0.16484725  	0.16335274  
2023-06-14 16:08:25.491: [iter 30 : loss : 1.1558 = 0.2073 + 0.9432 + 0.0052, time: 43.533518]
2023-06-14 16:08:26.093: epoch 30:	0.08757308  	0.16474073  	0.16331701  
2023-06-14 16:09:09.570: [iter 31 : loss : 1.1401 = 0.1924 + 0.9421 + 0.0056, time: 43.467926]
2023-06-14 16:09:10.146: epoch 31:	0.08738505  	0.16447377  	0.16300565  
2023-06-14 16:09:53.865: [iter 32 : loss : 1.1279 = 0.1809 + 0.9410 + 0.0060, time: 43.708043]
2023-06-14 16:09:54.379: epoch 32:	0.08724542  	0.16418831  	0.16252142  
2023-06-14 16:10:37.676: [iter 33 : loss : 1.1160 = 0.1696 + 0.9400 + 0.0063, time: 43.290135]
2023-06-14 16:10:38.236: epoch 33:	0.08737976  	0.16424000  	0.16241923  
2023-06-14 16:11:22.171: [iter 34 : loss : 1.1066 = 0.1609 + 0.9391 + 0.0066, time: 43.927424]
2023-06-14 16:11:22.727: epoch 34:	0.08714343  	0.16362715  	0.16191381  
2023-06-14 16:12:08.017: [iter 35 : loss : 1.0968 = 0.1516 + 0.9383 + 0.0070, time: 45.282037]
2023-06-14 16:12:09.144: epoch 35:	0.08697689  	0.16273028  	0.16136083  
2023-06-14 16:12:51.231: [iter 36 : loss : 1.0888 = 0.1442 + 0.9373 + 0.0073, time: 42.080312]
2023-06-14 16:12:51.659: epoch 36:	0.08696073  	0.16246521  	0.16094483  
2023-06-14 16:13:31.579: [iter 37 : loss : 1.0811 = 0.1370 + 0.9364 + 0.0076, time: 39.912976]
2023-06-14 16:13:31.990: epoch 37:	0.08677274  	0.16189197  	0.16038939  
2023-06-14 16:14:17.947: [iter 38 : loss : 1.0743 = 0.1309 + 0.9356 + 0.0079, time: 45.950075]
2023-06-14 16:14:18.359: epoch 38:	0.08654178  	0.16082764  	0.15988685  
2023-06-14 16:15:04.935: [iter 39 : loss : 1.0687 = 0.1256 + 0.9349 + 0.0082, time: 46.569362]
2023-06-14 16:15:05.709: epoch 39:	0.08628930  	0.15971214  	0.15912378  
2023-06-14 16:15:47.182: [iter 40 : loss : 1.0633 = 0.1207 + 0.9342 + 0.0084, time: 41.455492]
2023-06-14 16:15:47.822: epoch 40:	0.08598848  	0.15896852  	0.15843743  
2023-06-14 16:16:29.603: [iter 41 : loss : 1.0580 = 0.1158 + 0.9335 + 0.0087, time: 41.773958]
2023-06-14 16:16:30.070: epoch 41:	0.08567693  	0.15813038  	0.15780628  
2023-06-14 16:17:15.299: [iter 42 : loss : 1.0530 = 0.1111 + 0.9330 + 0.0089, time: 45.221507]
2023-06-14 16:17:15.721: epoch 42:	0.08558028  	0.15735346  	0.15722634  
2023-06-14 16:18:01.806: [iter 43 : loss : 1.0487 = 0.1071 + 0.9324 + 0.0092, time: 46.077206]
2023-06-14 16:18:02.209: epoch 43:	0.08545133  	0.15716124  	0.15680690  
2023-06-14 16:18:44.530: [iter 44 : loss : 1.0451 = 0.1036 + 0.9320 + 0.0094, time: 42.313985]
2023-06-14 16:18:45.186: epoch 44:	0.08513445  	0.15589459  	0.15598512  
2023-06-14 16:19:29.741: [iter 45 : loss : 1.0416 = 0.1005 + 0.9314 + 0.0097, time: 44.548802]
2023-06-14 16:19:30.170: epoch 45:	0.08485515  	0.15501684  	0.15520196  
2023-06-14 16:20:15.217: [iter 46 : loss : 1.0381 = 0.0973 + 0.9309 + 0.0099, time: 45.039662]
2023-06-14 16:20:15.658: epoch 46:	0.08447909  	0.15430656  	0.15445381  
2023-06-14 16:21:02.019: [iter 47 : loss : 1.0346 = 0.0941 + 0.9304 + 0.0101, time: 46.352390]
2023-06-14 16:21:02.426: epoch 47:	0.08424271  	0.15333357  	0.15368614  
2023-06-14 16:21:47.300: [iter 48 : loss : 1.0315 = 0.0911 + 0.9300 + 0.0103, time: 44.865753]
2023-06-14 16:21:47.914: epoch 48:	0.08416220  	0.15277839  	0.15315679  
2023-06-14 16:22:30.326: [iter 49 : loss : 1.0289 = 0.0888 + 0.9296 + 0.0105, time: 42.405383]
2023-06-14 16:22:30.788: epoch 49:	0.08375930  	0.15182306  	0.15243524  
2023-06-14 16:23:13.832: [iter 50 : loss : 1.0262 = 0.0862 + 0.9293 + 0.0107, time: 43.035910]
2023-06-14 16:23:14.284: epoch 50:	0.08365183  	0.15138371  	0.15205605  
2023-06-14 16:24:00.435: [iter 51 : loss : 1.0238 = 0.0839 + 0.9289 + 0.0109, time: 46.143535]
2023-06-14 16:24:00.958: epoch 51:	0.08335102  	0.15062295  	0.15138175  
2023-06-14 16:24:47.999: [iter 52 : loss : 1.0216 = 0.0818 + 0.9286 + 0.0111, time: 47.034173]
2023-06-14 16:24:48.409: epoch 52:	0.08298572  	0.14992602  	0.15043375  
2023-06-14 16:25:32.103: [iter 53 : loss : 1.0191 = 0.0796 + 0.9282 + 0.0113, time: 43.685920]
2023-06-14 16:25:32.734: epoch 53:	0.08278165  	0.14967480  	0.14998443  
2023-06-14 16:25:32.734: Early stopping is trigger at epoch: 53
2023-06-14 16:25:32.734: best_result@epoch 28:

2023-06-14 16:25:32.734: 		0.0874      	0.1654      	0.1636      
2023-06-14 16:35:33.957: my pid: 6828
2023-06-14 16:35:33.957: model: model.general_recommender.SGL
2023-06-14 16:35:33.957: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 16:35:33.957: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 16:35:39.489: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 16:36:19.173: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 39.683541]
2023-06-14 16:36:19.708: epoch 1:	0.00247099  	0.00753289  	0.00511617  
2023-06-14 16:36:19.708: Find a better model.
2023-06-14 16:36:59.172: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 39.457171]
2023-06-14 16:36:59.608: epoch 2:	0.00321765  	0.00870135  	0.00656146  
2023-06-14 16:36:59.608: Find a better model.
2023-06-14 16:37:39.056: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 39.441744]
2023-06-14 16:37:39.500: epoch 3:	0.00382465  	0.01016405  	0.00776124  
2023-06-14 16:37:39.500: Find a better model.
2023-06-14 16:38:19.776: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.260580]
2023-06-14 16:38:20.257: epoch 4:	0.00420603  	0.01181193  	0.00865573  
2023-06-14 16:38:20.257: Find a better model.
2023-06-14 16:39:00.473: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 40.209657]
2023-06-14 16:39:00.926: epoch 5:	0.00489360  	0.01345828  	0.01029926  
2023-06-14 16:39:00.926: Find a better model.
2023-06-14 16:39:42.243: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 41.310086]
2023-06-14 16:39:42.679: epoch 6:	0.00611297  	0.01577182  	0.01215619  
2023-06-14 16:39:42.679: Find a better model.
2023-06-14 16:40:24.564: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 41.879466]
2023-06-14 16:40:24.976: epoch 7:	0.00663939  	0.01684179  	0.01346583  
2023-06-14 16:40:24.977: Find a better model.
2023-06-14 16:41:07.206: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 42.221967]
2023-06-14 16:41:07.630: epoch 8:	0.00737533  	0.01890697  	0.01521505  
2023-06-14 16:41:07.630: Find a better model.
2023-06-14 16:41:50.298: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 42.661381]
2023-06-14 16:41:50.781: epoch 9:	0.00863774  	0.02110944  	0.01719513  
2023-06-14 16:41:50.781: Find a better model.
2023-06-14 16:42:33.335: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 42.548455]
2023-06-14 16:42:33.799: epoch 10:	0.01006667  	0.02497009  	0.02080766  
2023-06-14 16:42:33.799: Find a better model.
2023-06-14 16:43:17.479: [iter 11 : loss : 1.6050 = 0.6920 + 0.9129 + 0.0000, time: 43.671947]
2023-06-14 16:43:17.893: epoch 11:	0.01234972  	0.02984167  	0.02500372  
2023-06-14 16:43:17.893: Find a better model.
2023-06-14 16:44:01.786: [iter 12 : loss : 1.6048 = 0.6916 + 0.9131 + 0.0000, time: 43.885768]
2023-06-14 16:44:02.193: epoch 12:	0.01521293  	0.03588372  	0.03056348  
2023-06-14 16:44:02.193: Find a better model.
2023-06-14 16:44:44.975: [iter 13 : loss : 1.6044 = 0.6910 + 0.9134 + 0.0000, time: 42.774875]
2023-06-14 16:44:45.439: epoch 13:	0.01869932  	0.04320442  	0.03841757  
2023-06-14 16:44:45.439: Find a better model.
2023-06-14 16:45:28.037: [iter 14 : loss : 1.6037 = 0.6899 + 0.9138 + 0.0000, time: 42.587293]
2023-06-14 16:45:28.667: epoch 14:	0.02453854  	0.05521307  	0.05036050  
2023-06-14 16:45:28.668: Find a better model.
2023-06-14 16:46:10.913: [iter 15 : loss : 1.6024 = 0.6881 + 0.9143 + 0.0001, time: 42.235818]
2023-06-14 16:46:11.534: epoch 15:	0.03278371  	0.07143644  	0.06695360  
2023-06-14 16:46:11.534: Find a better model.
2023-06-14 16:46:53.140: [iter 16 : loss : 1.5995 = 0.6844 + 0.9150 + 0.0001, time: 41.584712]
2023-06-14 16:46:53.745: epoch 16:	0.04340858  	0.08951698  	0.08662319  
2023-06-14 16:46:53.745: Find a better model.
2023-06-14 16:47:35.184: [iter 17 : loss : 1.5930 = 0.6765 + 0.9163 + 0.0001, time: 41.433168]
2023-06-14 16:47:35.740: epoch 17:	0.05567169  	0.11067080  	0.10910683  
2023-06-14 16:47:35.740: Find a better model.
2023-06-14 16:48:14.687: [iter 18 : loss : 1.5783 = 0.6594 + 0.9187 + 0.0002, time: 38.940020]
2023-06-14 16:48:15.100: epoch 18:	0.06720416  	0.12850986  	0.12852247  
2023-06-14 16:48:15.100: Find a better model.
2023-06-14 16:48:54.306: [iter 19 : loss : 1.5492 = 0.6262 + 0.9226 + 0.0005, time: 39.199939]
2023-06-14 16:48:54.727: epoch 19:	0.07479952  	0.14034803  	0.14178725  
2023-06-14 16:48:54.727: Find a better model.
2023-06-14 16:49:33.955: [iter 20 : loss : 1.5043 = 0.5752 + 0.9283 + 0.0008, time: 39.221528]
2023-06-14 16:49:34.372: epoch 20:	0.07961246  	0.14876463  	0.14968094  
2023-06-14 16:49:34.372: Find a better model.
2023-06-14 16:50:14.184: [iter 21 : loss : 1.4497 = 0.5140 + 0.9345 + 0.0012, time: 39.805796]
2023-06-14 16:50:14.598: epoch 21:	0.08251837  	0.15462267  	0.15462795  
2023-06-14 16:50:14.598: Find a better model.
2023-06-14 16:50:53.894: [iter 22 : loss : 1.3944 = 0.4528 + 0.9399 + 0.0017, time: 39.288820]
2023-06-14 16:50:54.308: epoch 22:	0.08439304  	0.15756668  	0.15728614  
2023-06-14 16:50:54.308: Find a better model.
2023-06-14 16:51:33.676: [iter 23 : loss : 1.3449 = 0.3992 + 0.9435 + 0.0022, time: 39.362655]
2023-06-14 16:51:34.092: epoch 23:	0.08558029  	0.16030069  	0.15930602  
2023-06-14 16:51:34.092: Find a better model.
2023-06-14 16:52:13.491: [iter 24 : loss : 1.3021 = 0.3538 + 0.9456 + 0.0027, time: 39.392034]
2023-06-14 16:52:13.907: epoch 24:	0.08648801  	0.16236730  	0.16116211  
2023-06-14 16:52:13.908: Find a better model.
2023-06-14 16:52:53.312: [iter 25 : loss : 1.2668 = 0.3172 + 0.9463 + 0.0032, time: 39.397189]
2023-06-14 16:52:53.725: epoch 25:	0.08714877  	0.16327272  	0.16214009  
2023-06-14 16:52:53.725: Find a better model.
2023-06-14 16:53:33.197: [iter 26 : loss : 1.2359 = 0.2859 + 0.9463 + 0.0036, time: 39.466084]
2023-06-14 16:53:33.610: epoch 26:	0.08759450  	0.16400187  	0.16265918  
2023-06-14 16:53:33.610: Find a better model.
2023-06-14 16:54:13.012: [iter 27 : loss : 1.2101 = 0.2601 + 0.9459 + 0.0041, time: 39.396187]
2023-06-14 16:54:13.425: epoch 27:	0.08780931  	0.16436327  	0.16278207  
2023-06-14 16:54:13.425: Find a better model.
2023-06-14 16:54:53.088: [iter 28 : loss : 1.1883 = 0.2386 + 0.9451 + 0.0045, time: 39.655723]
2023-06-14 16:54:53.497: epoch 28:	0.08779864  	0.16420935  	0.16297536  
2023-06-14 16:55:32.953: [iter 29 : loss : 1.1695 = 0.2205 + 0.9442 + 0.0049, time: 39.449487]
2023-06-14 16:55:33.368: epoch 29:	0.08799202  	0.16485529  	0.16304693  
2023-06-14 16:55:33.369: Find a better model.
2023-06-14 16:56:12.877: [iter 30 : loss : 1.1529 = 0.2045 + 0.9431 + 0.0053, time: 39.500861]
2023-06-14 16:56:13.291: epoch 30:	0.08780934  	0.16391544  	0.16251273  
2023-06-14 16:56:52.759: [iter 31 : loss : 1.1384 = 0.1906 + 0.9422 + 0.0057, time: 39.459509]
2023-06-14 16:56:53.174: epoch 31:	0.08798660  	0.16456455  	0.16266744  
2023-06-14 16:57:32.930: [iter 32 : loss : 1.1262 = 0.1791 + 0.9410 + 0.0060, time: 39.749272]
2023-06-14 16:57:33.345: epoch 32:	0.08782002  	0.16380523  	0.16228943  
2023-06-14 16:58:13.561: [iter 33 : loss : 1.1144 = 0.1680 + 0.9401 + 0.0064, time: 40.208405]
2023-06-14 16:58:13.966: epoch 33:	0.08772875  	0.16340065  	0.16196409  
2023-06-14 16:58:53.315: [iter 34 : loss : 1.1051 = 0.1592 + 0.9392 + 0.0067, time: 39.342604]
2023-06-14 16:58:53.751: epoch 34:	0.08763748  	0.16304412  	0.16166425  
2023-06-14 16:59:34.341: [iter 35 : loss : 1.0954 = 0.1501 + 0.9383 + 0.0070, time: 40.581663]
2023-06-14 16:59:34.784: epoch 35:	0.08747626  	0.16288762  	0.16121687  
2023-06-14 17:00:14.965: [iter 36 : loss : 1.0878 = 0.1431 + 0.9374 + 0.0073, time: 40.168386]
2023-06-14 17:00:15.374: epoch 36:	0.08739573  	0.16258025  	0.16088730  
2023-06-14 17:00:55.798: [iter 37 : loss : 1.0802 = 0.1360 + 0.9366 + 0.0076, time: 40.417596]
2023-06-14 17:00:56.226: epoch 37:	0.08729902  	0.16194615  	0.16040020  
2023-06-14 17:01:37.315: [iter 38 : loss : 1.0737 = 0.1300 + 0.9358 + 0.0079, time: 41.083170]
2023-06-14 17:01:37.798: epoch 38:	0.08727760  	0.16223468  	0.16026779  
2023-06-14 17:02:19.189: [iter 39 : loss : 1.0680 = 0.1248 + 0.9350 + 0.0082, time: 41.382878]
2023-06-14 17:02:19.622: epoch 39:	0.08695529  	0.16095512  	0.15946069  
2023-06-14 17:02:59.831: [iter 40 : loss : 1.0630 = 0.1201 + 0.9344 + 0.0085, time: 40.202525]
2023-06-14 17:03:00.281: epoch 40:	0.08667064  	0.16008532  	0.15873416  
2023-06-14 17:03:40.523: [iter 41 : loss : 1.0574 = 0.1149 + 0.9337 + 0.0087, time: 40.234836]
2023-06-14 17:03:40.949: epoch 41:	0.08633762  	0.15933572  	0.15820310  
2023-06-14 17:04:20.901: [iter 42 : loss : 1.0531 = 0.1109 + 0.9332 + 0.0090, time: 39.945008]
2023-06-14 17:04:21.318: epoch 42:	0.08619254  	0.15846077  	0.15764050  
2023-06-14 17:05:00.592: [iter 43 : loss : 1.0483 = 0.1065 + 0.9326 + 0.0092, time: 39.267842]
2023-06-14 17:05:01.009: epoch 43:	0.08609580  	0.15796939  	0.15723369  
2023-06-14 17:05:40.819: [iter 44 : loss : 1.0443 = 0.1027 + 0.9321 + 0.0095, time: 39.804893]
2023-06-14 17:05:41.234: epoch 44:	0.08583798  	0.15756226  	0.15665333  
2023-06-14 17:06:21.009: [iter 45 : loss : 1.0413 = 0.1000 + 0.9316 + 0.0097, time: 39.767844]
2023-06-14 17:06:21.426: epoch 45:	0.08560705  	0.15669972  	0.15593483  
2023-06-14 17:07:01.154: [iter 46 : loss : 1.0376 = 0.0965 + 0.9312 + 0.0099, time: 39.722027]
2023-06-14 17:07:01.572: epoch 46:	0.08532236  	0.15586051  	0.15521990  
2023-06-14 17:07:41.148: [iter 47 : loss : 1.0346 = 0.0938 + 0.9306 + 0.0101, time: 39.569313]
2023-06-14 17:07:41.562: epoch 47:	0.08515584  	0.15500185  	0.15466632  
2023-06-14 17:08:20.952: [iter 48 : loss : 1.0312 = 0.0906 + 0.9302 + 0.0104, time: 39.384205]
2023-06-14 17:08:21.370: epoch 48:	0.08488725  	0.15447401  	0.15377480  
2023-06-14 17:09:00.991: [iter 49 : loss : 1.0289 = 0.0885 + 0.9298 + 0.0106, time: 39.614943]
2023-06-14 17:09:01.410: epoch 49:	0.08480670  	0.15365022  	0.15341373  
2023-06-14 17:09:41.265: [iter 50 : loss : 1.0260 = 0.0859 + 0.9294 + 0.0108, time: 39.848331]
2023-06-14 17:09:41.709: epoch 50:	0.08453808  	0.15289633  	0.15275736  
2023-06-14 17:10:17.180: my pid: 12828
2023-06-14 17:10:17.180: model: model.general_recommender.SGL
2023-06-14 17:10:17.180: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 17:10:17.180: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 17:10:22.706: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 17:11:01.945: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 39.237675]
2023-06-14 17:11:02.363: epoch 1:	0.00248710  	0.00759266  	0.00551627  
2023-06-14 17:11:02.364: Find a better model.
2023-06-14 17:11:40.965: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 38.594573]
2023-06-14 17:11:41.424: epoch 2:	0.00327674  	0.00971557  	0.00715361  
2023-06-14 17:11:41.424: Find a better model.
2023-06-14 17:12:20.034: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 38.603388]
2023-06-14 17:12:20.453: epoch 3:	0.00390522  	0.01104282  	0.00833059  
2023-06-14 17:12:20.453: Find a better model.
2023-06-14 17:12:58.882: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 38.421743]
2023-06-14 17:12:59.297: epoch 4:	0.00438330  	0.01184429  	0.00890879  
2023-06-14 17:12:59.297: Find a better model.
2023-06-14 17:13:38.055: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 38.752366]
2023-06-14 17:13:38.470: epoch 5:	0.00496881  	0.01408369  	0.01047082  
2023-06-14 17:13:38.470: Find a better model.
2023-06-14 17:14:18.679: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 40.203214]
2023-06-14 17:14:19.132: epoch 6:	0.00596794  	0.01584242  	0.01231193  
2023-06-14 17:14:19.133: Find a better model.
2023-06-14 17:14:59.532: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 40.392040]
2023-06-14 17:15:00.006: epoch 7:	0.00648899  	0.01650688  	0.01328054  
2023-06-14 17:15:00.006: Find a better model.
2023-06-14 17:15:46.786: [iter 8 : loss : 1.6052 = 0.6927 + 0.9126 + 0.0000, time: 46.771788]
2023-06-14 17:15:47.247: epoch 8:	0.00754187  	0.01906387  	0.01518033  
2023-06-14 17:15:47.247: Find a better model.
2023-06-14 17:16:30.773: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 43.516797]
2023-06-14 17:16:31.400: epoch 9:	0.00842286  	0.02085754  	0.01737375  
2023-06-14 17:16:31.400: Find a better model.
2023-06-14 17:17:11.831: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 40.424789]
2023-06-14 17:17:12.224: epoch 10:	0.01004519  	0.02394608  	0.02026354  
2023-06-14 17:17:12.224: Find a better model.
2023-06-14 17:17:54.513: [iter 11 : loss : 1.6049 = 0.6920 + 0.9129 + 0.0000, time: 42.281544]
2023-06-14 17:17:54.944: epoch 11:	0.01240880  	0.02983964  	0.02560472  
2023-06-14 17:17:54.944: Find a better model.
2023-06-14 17:18:39.933: [iter 12 : loss : 1.6048 = 0.6916 + 0.9131 + 0.0000, time: 44.982450]
2023-06-14 17:18:40.348: epoch 12:	0.01472410  	0.03491107  	0.03085645  
2023-06-14 17:18:40.349: Find a better model.
2023-06-14 17:19:25.939: [iter 13 : loss : 1.6044 = 0.6910 + 0.9134 + 0.0000, time: 45.583807]
2023-06-14 17:19:26.348: epoch 13:	0.01846294  	0.04337887  	0.03876036  
2023-06-14 17:19:26.348: Find a better model.
2023-06-14 17:20:07.679: [iter 14 : loss : 1.6037 = 0.6899 + 0.9137 + 0.0000, time: 41.324574]
2023-06-14 17:20:08.293: epoch 14:	0.02448483  	0.05489759  	0.05067438  
2023-06-14 17:20:08.293: Find a better model.
2023-06-14 17:20:49.029: [iter 15 : loss : 1.6023 = 0.6880 + 0.9142 + 0.0001, time: 40.728021]
2023-06-14 17:20:49.464: epoch 15:	0.03282675  	0.07070363  	0.06715221  
2023-06-14 17:20:49.464: Find a better model.
2023-06-14 17:21:32.091: [iter 16 : loss : 1.5994 = 0.6843 + 0.9150 + 0.0001, time: 42.619628]
2023-06-14 17:21:32.529: epoch 16:	0.04357494  	0.09065640  	0.08748085  
2023-06-14 17:21:32.529: Find a better model.
2023-06-14 17:22:17.602: [iter 17 : loss : 1.5927 = 0.6764 + 0.9162 + 0.0001, time: 45.054023]
2023-06-14 17:22:18.000: epoch 17:	0.05670298  	0.11344897  	0.11187516  
2023-06-14 17:22:18.000: Find a better model.
2023-06-14 17:23:03.760: [iter 18 : loss : 1.5779 = 0.6590 + 0.9186 + 0.0002, time: 45.752883]
2023-06-14 17:23:04.166: epoch 18:	0.06804744  	0.13194552  	0.13134138  
2023-06-14 17:23:04.167: Find a better model.
2023-06-14 17:23:47.591: [iter 19 : loss : 1.5482 = 0.6252 + 0.9225 + 0.0005, time: 43.408139]
2023-06-14 17:23:48.253: epoch 19:	0.07616387  	0.14421587  	0.14481455  
2023-06-14 17:23:48.253: Find a better model.
2023-06-14 17:24:30.521: [iter 20 : loss : 1.5024 = 0.5733 + 0.9283 + 0.0008, time: 42.261128]
2023-06-14 17:24:31.067: epoch 20:	0.08013342  	0.15092070  	0.15193890  
2023-06-14 17:24:31.067: Find a better model.
2023-06-14 17:25:13.782: [iter 21 : loss : 1.4469 = 0.5109 + 0.9347 + 0.0012, time: 42.708242]
2023-06-14 17:25:14.545: epoch 21:	0.08259897  	0.15568836  	0.15596029  
2023-06-14 17:25:14.546: Find a better model.
2023-06-14 17:26:00.310: [iter 22 : loss : 1.3913 = 0.4494 + 0.9402 + 0.0017, time: 45.748063]
2023-06-14 17:26:00.786: epoch 22:	0.08421048  	0.15852928  	0.15848474  
2023-06-14 17:26:00.786: Find a better model.
2023-06-14 17:26:46.881: [iter 23 : loss : 1.3421 = 0.3960 + 0.9438 + 0.0022, time: 46.088524]
2023-06-14 17:26:47.694: epoch 23:	0.08517735  	0.16091345  	0.16054374  
2023-06-14 17:26:47.694: Find a better model.
2023-06-14 17:27:30.054: [iter 24 : loss : 1.2994 = 0.3509 + 0.9458 + 0.0027, time: 42.341202]
2023-06-14 17:27:30.689: epoch 24:	0.08604760  	0.16331096  	0.16217816  
2023-06-14 17:27:30.689: Find a better model.
2023-06-14 17:28:12.051: [iter 25 : loss : 1.2644 = 0.3147 + 0.9464 + 0.0032, time: 41.353858]
2023-06-14 17:28:12.468: epoch 25:	0.08641831  	0.16334614  	0.16269460  
2023-06-14 17:28:12.468: Find a better model.
2023-06-14 17:28:55.860: [iter 26 : loss : 1.2339 = 0.2838 + 0.9464 + 0.0037, time: 43.386516]
2023-06-14 17:28:56.274: epoch 26:	0.08690707  	0.16430974  	0.16342683  
2023-06-14 17:28:56.274: Find a better model.
2023-06-14 17:29:42.206: [iter 27 : loss : 1.2083 = 0.2584 + 0.9458 + 0.0041, time: 45.924699]
2023-06-14 17:29:42.661: epoch 27:	0.08725619  	0.16490604  	0.16380076  
2023-06-14 17:29:42.661: Find a better model.
2023-06-14 17:30:27.603: [iter 28 : loss : 1.1866 = 0.2369 + 0.9451 + 0.0045, time: 44.933701]
2023-06-14 17:30:28.210: epoch 28:	0.08735282  	0.16504095  	0.16378768  
2023-06-14 17:30:28.210: Find a better model.
2023-06-14 17:31:10.184: [iter 29 : loss : 1.1683 = 0.2193 + 0.9441 + 0.0049, time: 41.966026]
2023-06-14 17:31:10.810: epoch 29:	0.08713793  	0.16427572  	0.16323972  
2023-06-14 17:31:52.647: [iter 30 : loss : 1.1517 = 0.2034 + 0.9430 + 0.0053, time: 41.831743]
2023-06-14 17:31:53.065: epoch 30:	0.08727228  	0.16451551  	0.16322649  
2023-06-14 17:32:36.618: [iter 31 : loss : 1.1371 = 0.1895 + 0.9420 + 0.0057, time: 43.547194]
2023-06-14 17:32:37.235: epoch 31:	0.08704666  	0.16390918  	0.16283496  
2023-06-14 17:33:23.428: [iter 32 : loss : 1.1252 = 0.1782 + 0.9410 + 0.0060, time: 46.186929]
2023-06-14 17:33:23.924: epoch 32:	0.08706269  	0.16385901  	0.16260223  
2023-06-14 17:34:10.025: [iter 33 : loss : 1.1134 = 0.1671 + 0.9399 + 0.0064, time: 46.091591]
2023-06-14 17:34:10.881: epoch 33:	0.08699828  	0.16309765  	0.16221491  
2023-06-14 17:34:53.382: [iter 34 : loss : 1.1043 = 0.1586 + 0.9390 + 0.0067, time: 42.492980]
2023-06-14 17:34:53.992: epoch 34:	0.08677267  	0.16219397  	0.16153495  
2023-06-14 17:35:35.734: [iter 35 : loss : 1.0949 = 0.1497 + 0.9382 + 0.0070, time: 41.735351]
2023-06-14 17:35:36.163: epoch 35:	0.08681029  	0.16227211  	0.16149904  
2023-06-14 17:36:19.360: [iter 36 : loss : 1.0876 = 0.1429 + 0.9373 + 0.0073, time: 43.190221]
2023-06-14 17:36:20.067: epoch 36:	0.08665984  	0.16177228  	0.16094221  
2023-06-14 17:37:06.132: [iter 37 : loss : 1.0797 = 0.1356 + 0.9364 + 0.0076, time: 46.058237]
2023-06-14 17:37:06.642: epoch 37:	0.08649876  	0.16143911  	0.16025223  
2023-06-14 17:37:53.062: [iter 38 : loss : 1.0734 = 0.1298 + 0.9357 + 0.0079, time: 46.411932]
2023-06-14 17:37:53.469: epoch 38:	0.08615496  	0.16042633  	0.15954682  
2023-06-14 17:38:36.369: [iter 39 : loss : 1.0675 = 0.1243 + 0.9349 + 0.0082, time: 42.893234]
2023-06-14 17:38:36.984: epoch 39:	0.08608509  	0.16028821  	0.15912744  
2023-06-14 17:39:19.263: [iter 40 : loss : 1.0623 = 0.1196 + 0.9342 + 0.0085, time: 42.272284]
2023-06-14 17:39:19.732: epoch 40:	0.08604218  	0.15998161  	0.15885028  
2023-06-14 17:40:01.978: [iter 41 : loss : 1.0571 = 0.1148 + 0.9336 + 0.0087, time: 42.239108]
2023-06-14 17:40:02.398: epoch 41:	0.08601528  	0.15972628  	0.15841208  
2023-06-14 17:40:48.446: [iter 42 : loss : 1.0525 = 0.1105 + 0.9331 + 0.0090, time: 46.041622]
2023-06-14 17:40:48.850: epoch 42:	0.08561780  	0.15888189  	0.15781654  
2023-06-14 17:41:35.540: [iter 43 : loss : 1.0478 = 0.1061 + 0.9325 + 0.0092, time: 46.681848]
2023-06-14 17:41:35.947: epoch 43:	0.08546740  	0.15792570  	0.15715124  
2023-06-14 17:42:21.915: [iter 44 : loss : 1.0443 = 0.1028 + 0.9320 + 0.0095, time: 45.959723]
2023-06-14 17:42:22.544: epoch 44:	0.08539756  	0.15738477  	0.15669626  
2023-06-14 17:43:02.606: [iter 45 : loss : 1.0413 = 0.1001 + 0.9315 + 0.0097, time: 40.053446]
2023-06-14 17:43:02.994: epoch 45:	0.08510213  	0.15693279  	0.15614201  
2023-06-14 17:43:43.044: [iter 46 : loss : 1.0373 = 0.0963 + 0.9311 + 0.0099, time: 40.042279]
2023-06-14 17:43:43.436: epoch 46:	0.08481208  	0.15611275  	0.15530108  
2023-06-14 17:44:23.432: [iter 47 : loss : 1.0339 = 0.0933 + 0.9305 + 0.0102, time: 39.989714]
2023-06-14 17:44:23.830: epoch 47:	0.08457568  	0.15551256  	0.15453081  
2023-06-14 17:45:03.840: [iter 48 : loss : 1.0310 = 0.0905 + 0.9301 + 0.0104, time: 40.003592]
2023-06-14 17:45:04.228: epoch 48:	0.08433940  	0.15468676  	0.15389363  
2023-06-14 17:45:44.193: [iter 49 : loss : 1.0285 = 0.0882 + 0.9297 + 0.0106, time: 39.957429]
2023-06-14 17:45:44.602: epoch 49:	0.08399021  	0.15389110  	0.15309264  
2023-06-14 17:46:24.332: [iter 50 : loss : 1.0260 = 0.0858 + 0.9293 + 0.0108, time: 39.724042]
2023-06-14 17:46:24.730: epoch 50:	0.08366258  	0.15294959  	0.15230663  
2023-06-14 17:47:05.006: [iter 51 : loss : 1.0236 = 0.0837 + 0.9290 + 0.0110, time: 40.269409]
2023-06-14 17:47:05.396: epoch 51:	0.08337254  	0.15223226  	0.15169090  
2023-06-14 17:47:45.712: [iter 52 : loss : 1.0213 = 0.0814 + 0.9287 + 0.0112, time: 40.309106]
2023-06-14 17:47:46.102: epoch 52:	0.08318450  	0.15176250  	0.15117757  
2023-06-14 17:48:26.353: [iter 53 : loss : 1.0190 = 0.0794 + 0.9283 + 0.0113, time: 40.243106]
2023-06-14 17:48:26.752: epoch 53:	0.08289448  	0.15101242  	0.15050572  
2023-06-14 17:48:26.752: Early stopping is trigger at epoch: 53
2023-06-14 17:48:26.752: best_result@epoch 28:

2023-06-14 17:48:26.752: 		0.0874      	0.1650      	0.1638      
2023-06-14 18:13:28.015: my pid: 12736
2023-06-14 18:13:28.015: model: model.general_recommender.SGL
2023-06-14 18:13:28.015: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 18:13:28.015: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 18:13:33.427: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 18:14:17.626: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 44.192429]
2023-06-14 18:14:18.148: epoch 1:	0.00277180  	0.00869186  	0.00643541  
2023-06-14 18:14:18.148: Find a better model.
2023-06-14 18:14:57.715: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 39.557977]
2023-06-14 18:14:58.204: epoch 2:	0.00342177  	0.01001134  	0.00734691  
2023-06-14 18:14:58.205: Find a better model.
2023-06-14 18:15:37.795: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 39.583394]
2023-06-14 18:15:38.205: epoch 3:	0.00400191  	0.01086069  	0.00813258  
2023-06-14 18:15:38.205: Find a better model.
2023-06-14 18:16:21.728: [iter 4 : loss : 1.6053 = 0.6930 + 0.9124 + 0.0000, time: 43.516816]
2023-06-14 18:16:22.140: epoch 4:	0.00471097  	0.01223903  	0.00922509  
2023-06-14 18:16:22.140: Find a better model.
2023-06-14 18:17:06.217: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 44.070568]
2023-06-14 18:17:06.660: epoch 5:	0.00575844  	0.01445622  	0.01118714  
2023-06-14 18:17:06.660: Find a better model.
2023-06-14 18:17:46.723: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.054587]
2023-06-14 18:17:47.361: epoch 6:	0.00649973  	0.01553627  	0.01263656  
2023-06-14 18:17:47.361: Find a better model.
2023-06-14 18:18:26.974: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.606798]
2023-06-14 18:18:27.395: epoch 7:	0.00713360  	0.01722531  	0.01352100  
2023-06-14 18:18:27.395: Find a better model.
2023-06-14 18:19:10.364: [iter 8 : loss : 1.6053 = 0.6926 + 0.9126 + 0.0000, time: 42.961853]
2023-06-14 18:19:10.800: epoch 8:	0.00812204  	0.01982283  	0.01607562  
2023-06-14 18:19:10.800: Find a better model.
2023-06-14 18:19:54.866: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 44.059078]
2023-06-14 18:19:55.276: epoch 9:	0.00983568  	0.02291980  	0.01924991  
2023-06-14 18:19:55.276: Find a better model.
2023-06-14 18:20:36.896: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 41.609339]
2023-06-14 18:20:37.522: epoch 10:	0.01122701  	0.02596935  	0.02183770  
2023-06-14 18:20:37.522: Find a better model.
2023-06-14 18:21:18.539: [iter 11 : loss : 1.6049 = 0.6920 + 0.9130 + 0.0000, time: 41.010564]
2023-06-14 18:21:19.066: epoch 11:	0.01362284  	0.03088412  	0.02670812  
2023-06-14 18:21:19.066: Find a better model.
2023-06-14 18:22:01.493: [iter 12 : loss : 1.6047 = 0.6915 + 0.9132 + 0.0000, time: 42.418978]
2023-06-14 18:22:02.153: epoch 12:	0.01686749  	0.03784429  	0.03330182  
2023-06-14 18:22:02.153: Find a better model.
2023-06-14 18:22:47.654: [iter 13 : loss : 1.6043 = 0.6908 + 0.9135 + 0.0000, time: 45.465081]
2023-06-14 18:22:48.053: epoch 13:	0.02106297  	0.04643890  	0.04262858  
2023-06-14 18:22:48.053: Find a better model.
2023-06-14 18:23:34.052: [iter 14 : loss : 1.6035 = 0.6896 + 0.9139 + 0.0000, time: 45.989794]
2023-06-14 18:23:34.559: epoch 14:	0.02761660  	0.06007742  	0.05597617  
2023-06-14 18:23:34.559: Find a better model.
2023-06-14 18:24:16.050: [iter 15 : loss : 1.6019 = 0.6875 + 0.9144 + 0.0001, time: 41.480094]
2023-06-14 18:24:16.632: epoch 15:	0.03595291  	0.07584674  	0.07283716  
2023-06-14 18:24:16.632: Find a better model.
2023-06-14 18:24:58.070: [iter 16 : loss : 1.5984 = 0.6831 + 0.9152 + 0.0001, time: 41.431298]
2023-06-14 18:24:58.510: epoch 16:	0.04722758  	0.09540033  	0.09381115  
2023-06-14 18:24:58.511: Find a better model.
2023-06-14 18:25:43.295: [iter 17 : loss : 1.5904 = 0.6737 + 0.9166 + 0.0002, time: 44.759522]
2023-06-14 18:25:43.702: epoch 17:	0.05982378  	0.11651739  	0.11643329  
2023-06-14 18:25:43.702: Find a better model.
2023-06-14 18:26:29.272: [iter 18 : loss : 1.5729 = 0.6533 + 0.9193 + 0.0003, time: 45.564207]
2023-06-14 18:26:29.697: epoch 18:	0.06985243  	0.13296542  	0.13380986  
2023-06-14 18:26:29.697: Find a better model.
2023-06-14 18:27:11.372: [iter 19 : loss : 1.5398 = 0.6156 + 0.9237 + 0.0005, time: 41.666648]
2023-06-14 18:27:11.984: epoch 19:	0.07674401  	0.14416817  	0.14549182  
2023-06-14 18:27:11.984: Find a better model.
2023-06-14 18:27:53.364: [iter 20 : loss : 1.4920 = 0.5613 + 0.9298 + 0.0009, time: 41.374126]
2023-06-14 18:27:53.859: epoch 20:	0.08047190  	0.15050259  	0.15215090  
2023-06-14 18:27:53.859: Find a better model.
2023-06-14 18:28:37.375: [iter 21 : loss : 1.4365 = 0.4991 + 0.9360 + 0.0013, time: 43.508748]
2023-06-14 18:28:37.797: epoch 21:	0.08258821  	0.15438133  	0.15571283  
2023-06-14 18:28:37.797: Find a better model.
2023-06-14 18:29:22.881: [iter 22 : loss : 1.3825 = 0.4397 + 0.9410 + 0.0018, time: 45.077540]
2023-06-14 18:29:23.513: epoch 22:	0.08397940  	0.15710235  	0.15865307  
2023-06-14 18:29:23.513: Find a better model.
2023-06-14 18:30:08.683: [iter 23 : loss : 1.3349 = 0.3884 + 0.9441 + 0.0023, time: 45.159975]
2023-06-14 18:30:09.283: epoch 23:	0.08482811  	0.15956903  	0.16034503  
2023-06-14 18:30:09.283: Find a better model.
2023-06-14 18:30:50.931: [iter 24 : loss : 1.2941 = 0.3455 + 0.9458 + 0.0028, time: 41.640439]
2023-06-14 18:30:51.321: epoch 24:	0.08584335  	0.16174532  	0.16181983  
2023-06-14 18:30:51.321: Find a better model.
2023-06-14 18:31:33.571: [iter 25 : loss : 1.2601 = 0.3106 + 0.9462 + 0.0033, time: 42.243648]
2023-06-14 18:31:34.033: epoch 25:	0.08655233  	0.16324548  	0.16269785  
2023-06-14 18:31:34.034: Find a better model.
2023-06-14 18:32:19.532: [iter 26 : loss : 1.2304 = 0.2806 + 0.9460 + 0.0038, time: 45.492170]
2023-06-14 18:32:19.983: epoch 26:	0.08667044  	0.16366223  	0.16296528  
2023-06-14 18:32:19.984: Find a better model.
2023-06-14 18:33:06.261: [iter 27 : loss : 1.2055 = 0.2560 + 0.9453 + 0.0042, time: 46.270606]
2023-06-14 18:33:06.877: epoch 27:	0.08698208  	0.16411150  	0.16317943  
2023-06-14 18:33:06.878: Find a better model.
2023-06-14 18:33:49.315: [iter 28 : loss : 1.1842 = 0.2349 + 0.9447 + 0.0046, time: 42.372476]
2023-06-14 18:33:49.936: epoch 28:	0.08723463  	0.16427101  	0.16353105  
2023-06-14 18:33:49.936: Find a better model.
2023-06-14 18:34:31.550: [iter 29 : loss : 1.1662 = 0.2176 + 0.9436 + 0.0050, time: 41.608872]
2023-06-14 18:34:32.108: epoch 29:	0.08706820  	0.16338208  	0.16288865  
2023-06-14 18:35:14.425: [iter 30 : loss : 1.1501 = 0.2022 + 0.9426 + 0.0054, time: 42.309204]
2023-06-14 18:35:14.826: epoch 30:	0.08702524  	0.16336530  	0.16271392  
2023-06-14 18:35:53.996: [iter 31 : loss : 1.1356 = 0.1883 + 0.9416 + 0.0058, time: 39.164325]
2023-06-14 18:35:54.382: epoch 31:	0.08717562  	0.16315885  	0.16251124  
2023-06-14 18:36:33.356: [iter 32 : loss : 1.1237 = 0.1770 + 0.9405 + 0.0061, time: 38.967232]
2023-06-14 18:36:33.755: epoch 32:	0.08710573  	0.16321331  	0.16245249  
2023-06-14 18:37:12.684: [iter 33 : loss : 1.1121 = 0.1661 + 0.9396 + 0.0065, time: 38.921902]
2023-06-14 18:37:13.069: epoch 33:	0.08713800  	0.16331629  	0.16230279  
2023-06-14 18:37:52.128: [iter 34 : loss : 1.1031 = 0.1576 + 0.9387 + 0.0068, time: 39.051050]
2023-06-14 18:37:52.505: epoch 34:	0.08714338  	0.16274792  	0.16185510  
2023-06-14 18:38:31.656: [iter 35 : loss : 1.0937 = 0.1488 + 0.9378 + 0.0071, time: 39.143402]
2023-06-14 18:38:32.039: epoch 35:	0.08691233  	0.16218412  	0.16134220  
2023-06-14 18:39:11.262: [iter 36 : loss : 1.0863 = 0.1419 + 0.9370 + 0.0074, time: 39.217509]
2023-06-14 18:39:11.673: epoch 36:	0.08675111  	0.16135427  	0.16072011  
2023-06-14 18:39:50.637: [iter 37 : loss : 1.0785 = 0.1347 + 0.9361 + 0.0077, time: 38.958139]
2023-06-14 18:39:51.020: epoch 37:	0.08671886  	0.16124138  	0.16033091  
2023-06-14 18:40:30.069: [iter 38 : loss : 1.0722 = 0.1289 + 0.9353 + 0.0080, time: 39.042094]
2023-06-14 18:40:30.459: epoch 38:	0.08642879  	0.16036397  	0.15984449  
2023-06-14 18:41:09.808: [iter 39 : loss : 1.0667 = 0.1238 + 0.9346 + 0.0083, time: 39.342859]
2023-06-14 18:41:10.192: epoch 39:	0.08615487  	0.15909415  	0.15905917  
2023-06-14 18:41:49.294: [iter 40 : loss : 1.0615 = 0.1190 + 0.9340 + 0.0085, time: 39.096180]
2023-06-14 18:41:49.701: epoch 40:	0.08583792  	0.15830316  	0.15829861  
2023-06-14 18:42:28.803: [iter 41 : loss : 1.0562 = 0.1142 + 0.9333 + 0.0088, time: 39.095006]
2023-06-14 18:42:29.190: epoch 41:	0.08566060  	0.15787935  	0.15790141  
2023-06-14 18:43:08.414: [iter 42 : loss : 1.0518 = 0.1100 + 0.9328 + 0.0091, time: 39.216899]
2023-06-14 18:43:08.809: epoch 42:	0.08544578  	0.15725031  	0.15732187  
2023-06-14 18:43:47.980: [iter 43 : loss : 1.0472 = 0.1057 + 0.9322 + 0.0093, time: 39.164259]
2023-06-14 18:43:48.366: epoch 43:	0.08526853  	0.15666942  	0.15691678  
2023-06-14 18:44:27.549: [iter 44 : loss : 1.0434 = 0.1022 + 0.9317 + 0.0095, time: 39.177661]
2023-06-14 18:44:27.938: epoch 44:	0.08516107  	0.15598495  	0.15650827  
2023-06-14 18:45:07.138: [iter 45 : loss : 1.0406 = 0.0996 + 0.9312 + 0.0098, time: 39.193436]
2023-06-14 18:45:07.525: epoch 45:	0.08484416  	0.15507890  	0.15579392  
2023-06-14 18:45:46.747: [iter 46 : loss : 1.0369 = 0.0961 + 0.9308 + 0.0100, time: 39.216614]
2023-06-14 18:45:47.135: epoch 46:	0.08457555  	0.15467039  	0.15519418  
2023-06-14 18:46:27.843: [iter 47 : loss : 1.0336 = 0.0931 + 0.9302 + 0.0102, time: 40.701299]
2023-06-14 18:46:28.246: epoch 47:	0.08452722  	0.15387988  	0.15452346  
2023-06-14 18:47:14.972: [iter 48 : loss : 1.0305 = 0.0902 + 0.9298 + 0.0104, time: 46.719157]
2023-06-14 18:47:15.675: epoch 48:	0.08417817  	0.15260427  	0.15353566  
2023-06-14 18:47:21.613: my pid: 9876
2023-06-14 18:47:21.613: model: model.general_recommender.SGL
2023-06-14 18:47:21.613: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 18:47:21.614: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 18:47:27.945: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 18:48:12.473: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 44.526577]
2023-06-14 18:48:12.902: epoch 1:	0.00275031  	0.00777119  	0.00569093  
2023-06-14 18:48:12.903: Find a better model.
2023-06-14 18:48:56.026: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 43.115340]
2023-06-14 18:48:56.678: epoch 2:	0.00359366  	0.01041260  	0.00764938  
2023-06-14 18:48:56.678: Find a better model.
2023-06-14 18:49:36.388: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 39.702619]
2023-06-14 18:49:36.862: epoch 3:	0.00439941  	0.01112510  	0.00862615  
2023-06-14 18:49:36.862: Find a better model.
2023-06-14 18:50:18.278: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 41.409422]
2023-06-14 18:50:19.047: epoch 4:	0.00509773  	0.01242784  	0.01030910  
2023-06-14 18:50:19.047: Find a better model.
2023-06-14 18:51:02.526: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 43.472046]
2023-06-14 18:51:02.991: epoch 5:	0.00575307  	0.01401530  	0.01158629  
2023-06-14 18:51:02.991: Find a better model.
2023-06-14 18:51:46.423: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 43.424733]
2023-06-14 18:51:47.066: epoch 6:	0.00654808  	0.01580246  	0.01282447  
2023-06-14 18:51:47.067: Find a better model.
2023-06-14 18:52:27.013: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.939327]
2023-06-14 18:52:27.439: epoch 7:	0.00755799  	0.01699505  	0.01442222  
2023-06-14 18:52:27.439: Find a better model.
2023-06-14 18:53:09.259: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 41.814497]
2023-06-14 18:53:09.681: epoch 8:	0.00854105  	0.01957247  	0.01615576  
2023-06-14 18:53:09.681: Find a better model.
2023-06-14 18:53:53.764: [iter 9 : loss : 1.6054 = 0.6925 + 0.9128 + 0.0000, time: 44.076111]
2023-06-14 18:53:54.160: epoch 9:	0.01005592  	0.02294582  	0.01937868  
2023-06-14 18:53:54.160: Find a better model.
2023-06-14 18:54:38.709: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 44.541544]
2023-06-14 18:54:39.119: epoch 10:	0.01133980  	0.02566206  	0.02186376  
2023-06-14 18:54:39.119: Find a better model.
2023-06-14 18:55:20.828: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 41.700523]
2023-06-14 18:55:21.448: epoch 11:	0.01405257  	0.03077912  	0.02690152  
2023-06-14 18:55:21.448: Find a better model.
2023-06-14 18:56:02.542: [iter 12 : loss : 1.6048 = 0.6917 + 0.9132 + 0.0000, time: 41.085410]
2023-06-14 18:56:03.026: epoch 12:	0.01644848  	0.03645880  	0.03275434  
2023-06-14 18:56:03.027: Find a better model.
2023-06-14 18:56:47.512: [iter 13 : loss : 1.6045 = 0.6910 + 0.9134 + 0.0000, time: 44.479681]
2023-06-14 18:56:47.938: epoch 13:	0.02038073  	0.04442384  	0.04044887  
2023-06-14 18:56:47.938: Find a better model.
2023-06-14 18:57:33.353: [iter 14 : loss : 1.6038 = 0.6901 + 0.9137 + 0.0000, time: 45.407776]
2023-06-14 18:57:33.782: epoch 14:	0.02601584  	0.05658527  	0.05154765  
2023-06-14 18:57:33.783: Find a better model.
2023-06-14 18:58:16.312: [iter 15 : loss : 1.6024 = 0.6883 + 0.9141 + 0.0001, time: 42.522256]
2023-06-14 18:58:16.945: epoch 15:	0.03368073  	0.07159443  	0.06710968  
2023-06-14 18:58:16.945: Find a better model.
2023-06-14 18:58:58.357: [iter 16 : loss : 1.5997 = 0.6848 + 0.9148 + 0.0001, time: 41.404776]
2023-06-14 18:58:58.931: epoch 16:	0.04465465  	0.09223013  	0.08835460  
2023-06-14 18:58:58.932: Find a better model.
2023-06-14 18:59:41.557: [iter 17 : loss : 1.5934 = 0.6773 + 0.9160 + 0.0001, time: 42.617748]
2023-06-14 18:59:42.181: epoch 17:	0.05689104  	0.11409404  	0.11132602  
2023-06-14 18:59:42.181: Find a better model.
2023-06-14 19:00:28.180: [iter 18 : loss : 1.5794 = 0.6609 + 0.9182 + 0.0002, time: 45.992967]
2023-06-14 19:00:28.595: epoch 18:	0.06833224  	0.13282716  	0.13184054  
2023-06-14 19:00:28.595: Find a better model.
2023-06-14 19:01:14.834: [iter 19 : loss : 1.5507 = 0.6284 + 0.9219 + 0.0004, time: 46.223062]
2023-06-14 19:01:15.298: epoch 19:	0.07649688  	0.14610235  	0.14568119  
2023-06-14 19:01:15.298: Find a better model.
2023-06-14 19:01:56.664: [iter 20 : loss : 1.5059 = 0.5777 + 0.9275 + 0.0008, time: 41.358391]
2023-06-14 19:01:57.105: epoch 20:	0.08098213  	0.15298748  	0.15356255  
2023-06-14 19:01:57.105: Find a better model.
2023-06-14 19:02:38.832: [iter 21 : loss : 1.4505 = 0.5155 + 0.9338 + 0.0012, time: 41.719794]
2023-06-14 19:02:39.312: epoch 21:	0.08344767  	0.15691073  	0.15755513  
2023-06-14 19:02:39.312: Find a better model.
2023-06-14 19:03:24.236: [iter 22 : loss : 1.3940 = 0.4529 + 0.9394 + 0.0017, time: 44.914012]
2023-06-14 19:03:24.681: epoch 22:	0.08481735  	0.15943259  	0.15990797  
2023-06-14 19:03:24.681: Find a better model.
2023-06-14 19:04:09.957: [iter 23 : loss : 1.3438 = 0.3983 + 0.9433 + 0.0022, time: 45.268499]
2023-06-14 19:04:10.362: epoch 23:	0.08587020  	0.16159178  	0.16177493  
2023-06-14 19:04:10.363: Find a better model.
2023-06-14 19:04:52.611: [iter 24 : loss : 1.3006 = 0.3526 + 0.9454 + 0.0027, time: 42.242139]
2023-06-14 19:04:53.214: epoch 24:	0.08636440  	0.16271187  	0.16299605  
2023-06-14 19:04:53.214: Find a better model.
2023-06-14 19:05:34.902: [iter 25 : loss : 1.2650 = 0.3156 + 0.9462 + 0.0032, time: 41.681981]
2023-06-14 19:05:35.341: epoch 25:	0.08675649  	0.16348274  	0.16386499  
2023-06-14 19:05:35.342: Find a better model.
2023-06-14 19:06:18.261: [iter 26 : loss : 1.2342 = 0.2843 + 0.9462 + 0.0036, time: 42.913599]
2023-06-14 19:06:18.955: epoch 26:	0.08692303  	0.16407104  	0.16420858  
2023-06-14 19:06:18.955: Find a better model.
2023-06-14 19:07:04.890: [iter 27 : loss : 1.2085 = 0.2588 + 0.9457 + 0.0041, time: 45.927495]
2023-06-14 19:07:05.290: epoch 27:	0.08707884  	0.16442762  	0.16419874  
2023-06-14 19:07:05.290: Find a better model.
2023-06-14 19:07:51.348: [iter 28 : loss : 1.1868 = 0.2373 + 0.9450 + 0.0045, time: 46.051585]
2023-06-14 19:07:51.882: epoch 28:	0.08736346  	0.16483173  	0.16445687  
2023-06-14 19:07:51.882: Find a better model.
2023-06-14 19:08:33.683: [iter 29 : loss : 1.1684 = 0.2194 + 0.9440 + 0.0049, time: 41.793332]
2023-06-14 19:08:34.276: epoch 29:	0.08748705  	0.16505127  	0.16444363  
2023-06-14 19:08:34.276: Find a better model.
2023-06-14 19:09:15.968: [iter 30 : loss : 1.1520 = 0.2038 + 0.9429 + 0.0053, time: 41.684062]
2023-06-14 19:09:16.400: epoch 30:	0.08746018  	0.16487677  	0.16416557  
2023-06-14 19:10:01.114: [iter 31 : loss : 1.1374 = 0.1898 + 0.9419 + 0.0057, time: 44.704798]
2023-06-14 19:10:01.528: epoch 31:	0.08727227  	0.16445039  	0.16384499  
2023-06-14 19:10:47.044: [iter 32 : loss : 1.1251 = 0.1783 + 0.9408 + 0.0060, time: 45.509503]
2023-06-14 19:10:47.450: epoch 32:	0.08744418  	0.16394109  	0.16381776  
2023-06-14 19:11:31.761: [iter 33 : loss : 1.1135 = 0.1673 + 0.9398 + 0.0064, time: 44.295744]
2023-06-14 19:11:32.362: epoch 33:	0.08717561  	0.16336289  	0.16329041  
2023-06-14 19:12:14.092: [iter 34 : loss : 1.1043 = 0.1587 + 0.9389 + 0.0067, time: 41.721803]
2023-06-14 19:12:14.487: epoch 34:	0.08701448  	0.16290720  	0.16280796  
2023-06-14 19:12:57.252: [iter 35 : loss : 1.0950 = 0.1499 + 0.9380 + 0.0070, time: 42.758323]
2023-06-14 19:12:58.045: epoch 35:	0.08689088  	0.16261433  	0.16247301  
2023-06-14 19:13:43.878: [iter 36 : loss : 1.0875 = 0.1429 + 0.9373 + 0.0073, time: 45.826811]
2023-06-14 19:13:44.303: epoch 36:	0.08678344  	0.16188526  	0.16192502  
2023-06-14 19:14:31.013: [iter 37 : loss : 1.0796 = 0.1357 + 0.9363 + 0.0076, time: 46.702786]
2023-06-14 19:14:31.409: epoch 37:	0.08652021  	0.16091779  	0.16132604  
2023-06-14 19:15:11.004: [iter 38 : loss : 1.0734 = 0.1299 + 0.9355 + 0.0079, time: 39.587344]
2023-06-14 19:15:11.394: epoch 38:	0.08659547  	0.16095094  	0.16092512  
2023-06-14 19:15:50.540: [iter 39 : loss : 1.0676 = 0.1245 + 0.9349 + 0.0082, time: 39.140176]
2023-06-14 19:15:50.931: epoch 39:	0.08626775  	0.15981166  	0.16025017  
2023-06-14 19:16:30.487: [iter 40 : loss : 1.0623 = 0.1197 + 0.9341 + 0.0085, time: 39.550184]
2023-06-14 19:16:30.885: epoch 40:	0.08595625  	0.15896139  	0.15948702  
2023-06-14 19:17:10.503: [iter 41 : loss : 1.0570 = 0.1148 + 0.9335 + 0.0087, time: 39.611355]
2023-06-14 19:17:10.895: epoch 41:	0.08578440  	0.15828097  	0.15899104  
2023-06-14 19:17:50.501: [iter 42 : loss : 1.0525 = 0.1106 + 0.9329 + 0.0090, time: 39.600657]
2023-06-14 19:17:50.893: epoch 42:	0.08570925  	0.15788209  	0.15834276  
2023-06-14 19:18:31.315: [iter 43 : loss : 1.0477 = 0.1061 + 0.9323 + 0.0092, time: 40.414731]
2023-06-14 19:18:31.785: epoch 43:	0.08545673  	0.15725069  	0.15789710  
2023-06-14 19:19:13.497: [iter 44 : loss : 1.0441 = 0.1028 + 0.9319 + 0.0095, time: 41.705114]
2023-06-14 19:19:13.957: epoch 44:	0.08527407  	0.15680343  	0.15715863  
2023-06-14 19:19:54.629: my pid: 11824
2023-06-14 19:19:54.629: model: model.general_recommender.SGL
2023-06-14 19:19:54.629: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 19:19:54.629: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 19:20:00.493: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 19:20:45.848: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 45.354865]
2023-06-14 19:20:46.303: epoch 1:	0.00317467  	0.00808232  	0.00623435  
2023-06-14 19:20:46.303: Find a better model.
2023-06-14 19:21:25.990: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 39.680976]
2023-06-14 19:21:26.403: epoch 2:	0.00366887  	0.00899578  	0.00704346  
2023-06-14 19:21:26.403: Find a better model.
2023-06-14 19:22:07.373: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 40.963137]
2023-06-14 19:22:08.104: epoch 3:	0.00480766  	0.01133611  	0.00946411  
2023-06-14 19:22:08.104: Find a better model.
2023-06-14 19:22:51.806: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 43.695552]
2023-06-14 19:22:52.204: epoch 4:	0.00517830  	0.01191592  	0.00994877  
2023-06-14 19:22:52.204: Find a better model.
2023-06-14 19:23:35.441: [iter 5 : loss : 1.6054 = 0.6929 + 0.9124 + 0.0000, time: 43.230070]
2023-06-14 19:23:36.096: epoch 5:	0.00648361  	0.01535606  	0.01232738  
2023-06-14 19:23:36.096: Find a better model.
2023-06-14 19:24:15.936: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 39.834736]
2023-06-14 19:24:16.351: epoch 6:	0.00733237  	0.01709137  	0.01409678  
2023-06-14 19:24:16.351: Find a better model.
2023-06-14 19:24:57.843: [iter 7 : loss : 1.6054 = 0.6928 + 0.9127 + 0.0000, time: 41.486427]
2023-06-14 19:24:58.461: epoch 7:	0.00824021  	0.01838844  	0.01594233  
2023-06-14 19:24:58.461: Find a better model.
2023-06-14 19:25:42.323: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 43.855049]
2023-06-14 19:25:42.766: epoch 8:	0.00900303  	0.01955249  	0.01712425  
2023-06-14 19:25:42.767: Find a better model.
2023-06-14 19:26:27.884: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 45.109420]
2023-06-14 19:26:28.501: epoch 9:	0.01060923  	0.02339487  	0.02039722  
2023-06-14 19:26:28.501: Find a better model.
2023-06-14 19:27:08.267: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 39.759850]
2023-06-14 19:27:08.687: epoch 10:	0.01222615  	0.02618366  	0.02370075  
2023-06-14 19:27:08.687: Find a better model.
2023-06-14 19:27:51.099: [iter 11 : loss : 1.6050 = 0.6920 + 0.9129 + 0.0000, time: 42.404917]
2023-06-14 19:27:51.794: epoch 11:	0.01550838  	0.03326196  	0.03000449  
2023-06-14 19:27:51.794: Find a better model.
2023-06-14 19:28:37.143: [iter 12 : loss : 1.6048 = 0.6916 + 0.9132 + 0.0000, time: 45.340984]
2023-06-14 19:28:37.684: epoch 12:	0.01894642  	0.03927872  	0.03699528  
2023-06-14 19:28:37.685: Find a better model.
2023-06-14 19:29:23.356: [iter 13 : loss : 1.6044 = 0.6909 + 0.9135 + 0.0000, time: 45.664649]
2023-06-14 19:29:23.911: epoch 13:	0.02294309  	0.04782860  	0.04528394  
2023-06-14 19:29:23.911: Find a better model.
2023-06-14 19:30:05.203: [iter 14 : loss : 1.6036 = 0.6898 + 0.9138 + 0.0000, time: 41.283235]
2023-06-14 19:30:05.680: epoch 14:	0.02935687  	0.06097427  	0.05883410  
2023-06-14 19:30:05.680: Find a better model.
2023-06-14 19:30:46.965: [iter 15 : loss : 1.6020 = 0.6877 + 0.9143 + 0.0001, time: 41.277107]
2023-06-14 19:30:47.361: epoch 15:	0.03767172  	0.07729969  	0.07470854  
2023-06-14 19:30:47.361: Find a better model.
2023-06-14 19:31:32.312: [iter 16 : loss : 1.5988 = 0.6836 + 0.9151 + 0.0001, time: 44.943799]
2023-06-14 19:31:32.841: epoch 16:	0.04867806  	0.09757779  	0.09573392  
2023-06-14 19:31:32.841: Find a better model.
2023-06-14 19:32:18.590: [iter 17 : loss : 1.5911 = 0.6746 + 0.9164 + 0.0001, time: 45.741172]
2023-06-14 19:32:19.304: epoch 17:	0.06060807  	0.11770380  	0.11677283  
2023-06-14 19:32:19.304: Find a better model.
2023-06-14 19:33:00.965: [iter 18 : loss : 1.5742 = 0.6550 + 0.9190 + 0.0003, time: 41.652143]
2023-06-14 19:33:01.611: epoch 18:	0.07062054  	0.13449721  	0.13508409  
2023-06-14 19:33:01.612: Find a better model.
2023-06-14 19:33:42.634: [iter 19 : loss : 1.5415 = 0.6179 + 0.9231 + 0.0005, time: 41.015398]
2023-06-14 19:33:43.122: epoch 19:	0.07722208  	0.14610039  	0.14692436  
2023-06-14 19:33:43.123: Find a better model.
2023-06-14 19:34:28.136: [iter 20 : loss : 1.4930 = 0.5632 + 0.9290 + 0.0009, time: 45.006072]
2023-06-14 19:34:28.534: epoch 20:	0.08076721  	0.15156302  	0.15330631  
2023-06-14 19:34:28.534: Find a better model.
2023-06-14 19:35:13.977: [iter 21 : loss : 1.4367 = 0.5001 + 0.9352 + 0.0013, time: 45.436381]
2023-06-14 19:35:14.386: epoch 21:	0.08307700  	0.15659948  	0.15714794  
2023-06-14 19:35:14.386: Find a better model.
2023-06-14 19:35:56.298: [iter 22 : loss : 1.3815 = 0.4394 + 0.9403 + 0.0018, time: 41.902665]
2023-06-14 19:35:56.914: epoch 22:	0.08453802  	0.15967900  	0.15949181  
2023-06-14 19:35:56.914: Find a better model.
2023-06-14 19:36:38.106: [iter 23 : loss : 1.3331 = 0.3872 + 0.9435 + 0.0023, time: 41.185482]
2023-06-14 19:36:38.671: epoch 23:	0.08558546  	0.16253719  	0.16145575  
2023-06-14 19:36:38.672: Find a better model.
2023-06-14 19:37:23.651: [iter 24 : loss : 1.2919 = 0.3437 + 0.9454 + 0.0028, time: 44.962117]
2023-06-14 19:37:24.058: epoch 24:	0.08679941  	0.16501416  	0.16311510  
2023-06-14 19:37:24.058: Find a better model.
2023-06-14 19:38:09.499: [iter 25 : loss : 1.2575 = 0.3085 + 0.9457 + 0.0033, time: 45.435097]
2023-06-14 19:38:10.007: epoch 25:	0.08714326  	0.16546571  	0.16363965  
2023-06-14 19:38:10.007: Find a better model.
2023-06-14 19:38:52.337: [iter 26 : loss : 1.2279 = 0.2785 + 0.9457 + 0.0038, time: 42.321392]
2023-06-14 19:38:52.958: epoch 26:	0.08727758  	0.16565147  	0.16380501  
2023-06-14 19:38:52.958: Find a better model.
2023-06-14 19:39:34.527: [iter 27 : loss : 1.2032 = 0.2539 + 0.9451 + 0.0042, time: 41.561136]
2023-06-14 19:39:35.009: epoch 27:	0.08757305  	0.16636078  	0.16409197  
2023-06-14 19:39:35.009: Find a better model.
2023-06-14 19:40:19.529: [iter 28 : loss : 1.1823 = 0.2333 + 0.9444 + 0.0046, time: 44.511900]
2023-06-14 19:40:19.949: epoch 28:	0.08762141  	0.16639958  	0.16393898  
2023-06-14 19:40:19.949: Find a better model.
2023-06-14 19:41:05.425: [iter 29 : loss : 1.1641 = 0.2158 + 0.9433 + 0.0050, time: 45.470145]
2023-06-14 19:41:05.844: epoch 29:	0.08754085  	0.16614158  	0.16389191  
2023-06-14 19:41:48.644: [iter 30 : loss : 1.1482 = 0.2005 + 0.9423 + 0.0054, time: 42.793934]
2023-06-14 19:41:49.282: epoch 30:	0.08761068  	0.16599467  	0.16364168  
2023-06-14 19:42:30.665: [iter 31 : loss : 1.1338 = 0.1868 + 0.9412 + 0.0058, time: 41.377039]
2023-06-14 19:42:31.120: epoch 31:	0.08751933  	0.16578391  	0.16348176  
2023-06-14 19:43:13.761: [iter 32 : loss : 1.1221 = 0.1758 + 0.9402 + 0.0061, time: 42.634113]
2023-06-14 19:43:14.510: epoch 32:	0.08769659  	0.16537099  	0.16323538  
2023-06-14 19:43:59.751: [iter 33 : loss : 1.1108 = 0.1651 + 0.9392 + 0.0065, time: 45.218408]
2023-06-14 19:44:00.217: epoch 33:	0.08757305  	0.16441630  	0.16252381  
2023-06-14 19:44:45.831: [iter 34 : loss : 1.1019 = 0.1568 + 0.9383 + 0.0068, time: 45.604383]
2023-06-14 19:44:46.407: epoch 34:	0.08744416  	0.16391273  	0.16221841  
2023-06-14 19:45:28.018: [iter 35 : loss : 1.0926 = 0.1480 + 0.9375 + 0.0071, time: 41.603182]
2023-06-14 19:45:28.675: epoch 35:	0.08737980  	0.16352431  	0.16181377  
2023-06-14 19:46:10.291: [iter 36 : loss : 1.0852 = 0.1411 + 0.9367 + 0.0074, time: 41.608298]
2023-06-14 19:46:10.789: epoch 36:	0.08714876  	0.16285570  	0.16139044  
2023-06-14 19:46:54.500: [iter 37 : loss : 1.0776 = 0.1341 + 0.9358 + 0.0077, time: 43.703324]
2023-06-14 19:46:54.930: epoch 37:	0.08697685  	0.16218185  	0.16093966  
2023-06-14 19:47:40.247: [iter 38 : loss : 1.0714 = 0.1284 + 0.9350 + 0.0080, time: 45.310903]
2023-06-14 19:47:40.684: epoch 38:	0.08679415  	0.16164888  	0.16049597  
2023-06-14 19:48:21.069: [iter 39 : loss : 1.0659 = 0.1233 + 0.9343 + 0.0083, time: 40.377837]
2023-06-14 19:48:21.484: epoch 39:	0.08670820  	0.16094735  	0.15993489  
2023-06-14 19:49:00.490: [iter 40 : loss : 1.0606 = 0.1184 + 0.9337 + 0.0085, time: 39.000376]
2023-06-14 19:49:00.913: epoch 40:	0.08652555  	0.16030873  	0.15925880  
2023-06-14 19:49:40.291: [iter 41 : loss : 1.0555 = 0.1137 + 0.9330 + 0.0088, time: 39.372260]
2023-06-14 19:49:40.705: epoch 41:	0.08636975  	0.15974097  	0.15887643  
2023-06-14 19:50:20.221: [iter 42 : loss : 1.0510 = 0.1095 + 0.9325 + 0.0090, time: 39.508537]
2023-06-14 19:50:20.637: epoch 42:	0.08615488  	0.15887538  	0.15820211  
2023-06-14 19:51:00.222: [iter 43 : loss : 1.0466 = 0.1054 + 0.9319 + 0.0093, time: 39.579258]
2023-06-14 19:51:00.638: epoch 43:	0.08586489  	0.15811481  	0.15761995  
2023-06-14 19:51:43.644: [iter 44 : loss : 1.0429 = 0.1020 + 0.9315 + 0.0095, time: 42.999187]
2023-06-14 19:51:44.058: epoch 44:	0.08544587  	0.15706398  	0.15693070  
2023-06-14 19:52:22.597: my pid: 16172
2023-06-14 19:52:22.597: model: model.general_recommender.SGL
2023-06-14 19:52:22.597: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 19:52:22.597: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 19:52:28.011: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 19:53:14.169: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 46.158544]
2023-06-14 19:53:14.659: epoch 1:	0.00338417  	0.00833153  	0.00691803  
2023-06-14 19:53:14.659: Find a better model.
2023-06-14 19:53:54.279: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 39.611273]
2023-06-14 19:53:54.953: epoch 2:	0.00414695  	0.00990317  	0.00800082  
2023-06-14 19:53:54.953: Find a better model.
2023-06-14 19:54:34.334: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 39.375710]
2023-06-14 19:54:34.766: epoch 3:	0.00539854  	0.01195411  	0.01002326  
2023-06-14 19:54:34.766: Find a better model.
2023-06-14 19:55:18.340: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 43.565976]
2023-06-14 19:55:18.769: epoch 4:	0.00577993  	0.01276116  	0.01037134  
2023-06-14 19:55:18.769: Find a better model.
2023-06-14 19:56:02.897: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 44.122168]
2023-06-14 19:56:03.318: epoch 5:	0.00666625  	0.01414746  	0.01209912  
2023-06-14 19:56:03.318: Find a better model.
2023-06-14 19:56:42.792: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 39.457383]
2023-06-14 19:56:43.446: epoch 6:	0.00756336  	0.01464676  	0.01347065  
2023-06-14 19:56:43.446: Find a better model.
2023-06-14 19:57:23.053: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 39.600729]
2023-06-14 19:57:23.452: epoch 7:	0.00866998  	0.01719957  	0.01560737  
2023-06-14 19:57:23.452: Find a better model.
2023-06-14 19:58:07.099: [iter 8 : loss : 1.6053 = 0.6927 + 0.9127 + 0.0000, time: 43.639959]
2023-06-14 19:58:07.505: epoch 8:	0.00974972  	0.01960470  	0.01768984  
2023-06-14 19:58:07.506: Find a better model.
2023-06-14 19:58:52.656: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 45.143618]
2023-06-14 19:58:53.064: epoch 9:	0.01151170  	0.02318544  	0.02072752  
2023-06-14 19:58:53.064: Find a better model.
2023-06-14 19:59:33.219: [iter 10 : loss : 1.6053 = 0.6923 + 0.9129 + 0.0000, time: 40.146868]
2023-06-14 19:59:33.863: epoch 10:	0.01315548  	0.02641248  	0.02450312  
2023-06-14 19:59:33.863: Find a better model.
2023-06-14 20:00:14.910: [iter 11 : loss : 1.6050 = 0.6920 + 0.9130 + 0.0000, time: 41.040965]
2023-06-14 20:00:15.355: epoch 11:	0.01604020  	0.03260687  	0.03011490  
2023-06-14 20:00:15.355: Find a better model.
2023-06-14 20:00:58.250: [iter 12 : loss : 1.6048 = 0.6916 + 0.9132 + 0.0000, time: 42.888916]
2023-06-14 20:00:58.904: epoch 12:	0.01985426  	0.03959480  	0.03754912  
2023-06-14 20:00:58.904: Find a better model.
2023-06-14 20:01:44.500: [iter 13 : loss : 1.6044 = 0.6909 + 0.9135 + 0.0000, time: 45.588482]
2023-06-14 20:01:44.937: epoch 13:	0.02367903  	0.04815954  	0.04554648  
2023-06-14 20:01:44.938: Find a better model.
2023-06-14 20:02:31.007: [iter 14 : loss : 1.6036 = 0.6898 + 0.9138 + 0.0000, time: 46.062721]
2023-06-14 20:02:31.511: epoch 14:	0.02971133  	0.06035250  	0.05754019  
2023-06-14 20:02:31.511: Find a better model.
2023-06-14 20:03:12.667: [iter 15 : loss : 1.6021 = 0.6878 + 0.9143 + 0.0001, time: 41.147272]
2023-06-14 20:03:13.072: epoch 15:	0.03805845  	0.07566918  	0.07365908  
2023-06-14 20:03:13.072: Find a better model.
2023-06-14 20:03:55.067: [iter 16 : loss : 1.5988 = 0.6837 + 0.9151 + 0.0001, time: 41.989561]
2023-06-14 20:03:55.780: epoch 16:	0.04826973  	0.09505022  	0.09391071  
2023-06-14 20:03:55.781: Find a better model.
2023-06-14 20:04:41.615: [iter 17 : loss : 1.5914 = 0.6749 + 0.9164 + 0.0001, time: 45.826924]
2023-06-14 20:04:42.035: epoch 17:	0.06021054  	0.11659585  	0.11634244  
2023-06-14 20:04:42.035: Find a better model.
2023-06-14 20:05:28.419: [iter 18 : loss : 1.5747 = 0.6557 + 0.9187 + 0.0003, time: 46.377492]
2023-06-14 20:05:28.896: epoch 18:	0.07065260  	0.13424908  	0.13555400  
2023-06-14 20:05:28.896: Find a better model.
2023-06-14 20:06:10.864: [iter 19 : loss : 1.5422 = 0.6189 + 0.9228 + 0.0005, time: 41.957365]
2023-06-14 20:06:11.486: epoch 19:	0.07765705  	0.14676932  	0.14719565  
2023-06-14 20:06:11.486: Find a better model.
2023-06-14 20:06:52.812: [iter 20 : loss : 1.4935 = 0.5641 + 0.9286 + 0.0008, time: 41.319983]
2023-06-14 20:06:53.243: epoch 20:	0.08169649  	0.15362985  	0.15422966  
2023-06-14 20:06:53.243: Find a better model.
2023-06-14 20:07:37.782: [iter 21 : loss : 1.4365 = 0.5002 + 0.9350 + 0.0013, time: 44.532302]
2023-06-14 20:07:38.187: epoch 21:	0.08359255  	0.15736088  	0.15796874  
2023-06-14 20:07:38.187: Find a better model.
2023-06-14 20:08:23.686: [iter 22 : loss : 1.3805 = 0.4385 + 0.9403 + 0.0018, time: 45.493528]
2023-06-14 20:08:24.089: epoch 22:	0.08474198  	0.16010688  	0.16038436  
2023-06-14 20:08:24.089: Find a better model.
2023-06-14 20:09:07.902: [iter 23 : loss : 1.3318 = 0.3858 + 0.9437 + 0.0023, time: 43.805512]
2023-06-14 20:09:08.508: epoch 23:	0.08566058  	0.16209643  	0.16223685  
2023-06-14 20:09:08.509: Find a better model.
2023-06-14 20:09:49.861: [iter 24 : loss : 1.2903 = 0.3421 + 0.9454 + 0.0028, time: 41.345968]
2023-06-14 20:09:50.253: epoch 24:	0.08628901  	0.16317266  	0.16327329  
2023-06-14 20:09:50.254: Find a better model.
2023-06-14 20:10:33.078: [iter 25 : loss : 1.2562 = 0.3070 + 0.9459 + 0.0033, time: 42.818283]
2023-06-14 20:10:33.476: epoch 25:	0.08672956  	0.16369960  	0.16368940  
2023-06-14 20:10:33.476: Find a better model.
2023-06-14 20:11:19.148: [iter 26 : loss : 1.2265 = 0.2772 + 0.9456 + 0.0037, time: 45.664981]
2023-06-14 20:11:19.612: epoch 26:	0.08708410  	0.16439091  	0.16408251  
2023-06-14 20:11:19.612: Find a better model.
2023-06-14 20:12:05.938: [iter 27 : loss : 1.2018 = 0.2527 + 0.9449 + 0.0042, time: 46.307113]
2023-06-14 20:12:06.374: epoch 27:	0.08716474  	0.16457097  	0.16406520  
2023-06-14 20:12:06.374: Find a better model.
2023-06-14 20:12:49.068: [iter 28 : loss : 1.1809 = 0.2321 + 0.9442 + 0.0046, time: 42.685655]
2023-06-14 20:12:49.711: epoch 28:	0.08726682  	0.16455700  	0.16400005  
2023-06-14 20:13:31.128: [iter 29 : loss : 1.1632 = 0.2150 + 0.9431 + 0.0050, time: 41.409409]
2023-06-14 20:13:31.534: epoch 29:	0.08733122  	0.16480340  	0.16367963  
2023-06-14 20:13:31.534: Find a better model.
2023-06-14 20:14:13.998: [iter 30 : loss : 1.1476 = 0.2000 + 0.9422 + 0.0054, time: 42.457387]
2023-06-14 20:14:14.431: epoch 30:	0.08744402  	0.16484816  	0.16346854  
2023-06-14 20:14:14.431: Find a better model.
2023-06-14 20:14:59.603: [iter 31 : loss : 1.1331 = 0.1862 + 0.9411 + 0.0058, time: 45.165215]
2023-06-14 20:15:00.010: epoch 31:	0.08721306  	0.16417971  	0.16308674  
2023-06-14 20:15:46.034: [iter 32 : loss : 1.1213 = 0.1752 + 0.9400 + 0.0061, time: 46.016322]
2023-06-14 20:15:46.439: epoch 32:	0.08714866  	0.16392452  	0.16267022  
2023-06-14 20:16:28.997: [iter 33 : loss : 1.1101 = 0.1646 + 0.9391 + 0.0065, time: 42.549613]
2023-06-14 20:16:29.657: epoch 33:	0.08711636  	0.16356388  	0.16234407  
2023-06-14 20:17:11.055: [iter 34 : loss : 1.1012 = 0.1563 + 0.9381 + 0.0068, time: 41.391282]
2023-06-14 20:17:11.462: epoch 34:	0.08682092  	0.16292199  	0.16184199  
2023-06-14 20:17:53.972: [iter 35 : loss : 1.0921 = 0.1477 + 0.9373 + 0.0071, time: 42.504111]
2023-06-14 20:17:54.382: epoch 35:	0.08683164  	0.16264208  	0.16150415  
2023-06-14 20:18:39.703: [iter 36 : loss : 1.0845 = 0.1406 + 0.9365 + 0.0074, time: 45.314872]
2023-06-14 20:18:40.108: epoch 36:	0.08671892  	0.16192211  	0.16091990  
2023-06-14 20:19:26.238: [iter 37 : loss : 1.0770 = 0.1336 + 0.9357 + 0.0077, time: 46.122975]
2023-06-14 20:19:26.666: epoch 37:	0.08657380  	0.16133854  	0.16044572  
2023-06-14 20:20:09.344: [iter 38 : loss : 1.0709 = 0.1281 + 0.9348 + 0.0080, time: 42.662228]
2023-06-14 20:20:10.006: epoch 38:	0.08631063  	0.16098633  	0.15992782  
2023-06-14 20:20:51.515: [iter 39 : loss : 1.0652 = 0.1228 + 0.9341 + 0.0083, time: 41.500453]
2023-06-14 20:20:51.930: epoch 39:	0.08612265  	0.15986575  	0.15927550  
2023-06-14 20:21:33.964: [iter 40 : loss : 1.0604 = 0.1183 + 0.9335 + 0.0085, time: 42.028088]
2023-06-14 20:21:34.398: epoch 40:	0.08594000  	0.15912735  	0.15859699  
2023-06-14 20:22:19.888: [iter 41 : loss : 1.0549 = 0.1133 + 0.9328 + 0.0088, time: 45.484560]
2023-06-14 20:22:20.306: epoch 41:	0.08578421  	0.15869659  	0.15812093  
2023-06-14 20:23:07.900: [iter 42 : loss : 1.0506 = 0.1092 + 0.9323 + 0.0090, time: 47.588094]
2023-06-14 20:23:08.307: epoch 42:	0.08570365  	0.15829003  	0.15750124  
2023-06-14 20:23:53.305: [iter 43 : loss : 1.0462 = 0.1052 + 0.9317 + 0.0093, time: 44.991608]
2023-06-14 20:23:53.937: epoch 43:	0.08536532  	0.15746635  	0.15705702  
2023-06-14 20:24:35.798: [iter 44 : loss : 1.0423 = 0.1015 + 0.9313 + 0.0095, time: 41.854432]
2023-06-14 20:24:36.202: epoch 44:	0.08499465  	0.15653099  	0.15628932  
2023-06-14 20:25:18.346: [iter 45 : loss : 1.0395 = 0.0990 + 0.9307 + 0.0098, time: 42.137498]
2023-06-14 20:25:18.851: epoch 45:	0.08469920  	0.15551387  	0.15527302  
2023-06-14 20:26:03.407: [iter 46 : loss : 1.0360 = 0.0957 + 0.9303 + 0.0100, time: 44.550009]
2023-06-14 20:26:03.831: epoch 46:	0.08442527  	0.15474927  	0.15467545  
2023-06-14 20:26:49.816: [iter 47 : loss : 1.0327 = 0.0927 + 0.9298 + 0.0102, time: 45.976551]
2023-06-14 20:26:50.328: epoch 47:	0.08433399  	0.15402183  	0.15414423  
2023-06-14 20:27:36.155: [iter 48 : loss : 1.0299 = 0.0901 + 0.9294 + 0.0104, time: 45.819510]
2023-06-14 20:27:36.769: epoch 48:	0.08414060  	0.15362829  	0.15360843  
2023-06-14 20:28:18.982: [iter 49 : loss : 1.0272 = 0.0876 + 0.9290 + 0.0106, time: 42.204473]
2023-06-14 20:28:19.625: epoch 49:	0.08372694  	0.15270609  	0.15292466  
2023-06-14 20:29:01.206: [iter 50 : loss : 1.0249 = 0.0853 + 0.9287 + 0.0108, time: 41.574617]
2023-06-14 20:29:01.741: epoch 50:	0.08353896  	0.15185909  	0.15227668  
2023-06-14 20:29:44.677: [iter 51 : loss : 1.0226 = 0.0832 + 0.9284 + 0.0110, time: 42.918315]
2023-06-14 20:29:45.097: epoch 51:	0.08333479  	0.15145339  	0.15178946  
2023-06-14 20:30:31.233: [iter 52 : loss : 1.0205 = 0.0811 + 0.9281 + 0.0112, time: 46.129363]
2023-06-14 20:30:31.656: epoch 52:	0.08318440  	0.15076806  	0.15123641  
2023-06-14 20:31:12.872: [iter 53 : loss : 1.0179 = 0.0788 + 0.9277 + 0.0114, time: 41.208970]
2023-06-14 20:31:13.268: epoch 53:	0.08318441  	0.15045391  	0.15086922  
2023-06-14 20:31:40.324: my pid: 15992
2023-06-14 20:31:40.324: model: model.general_recommender.SGL
2023-06-14 20:31:40.324: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 20:31:40.324: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 20:31:45.315: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 20:32:24.482: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 39.165927]
2023-06-14 20:32:24.897: epoch 1:	0.00329285  	0.00739440  	0.00618579  
2023-06-14 20:32:24.897: Find a better model.
2023-06-14 20:33:08.649: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 43.746765]
2023-06-14 20:33:09.160: epoch 2:	0.00428124  	0.00914528  	0.00762958  
2023-06-14 20:33:09.161: Find a better model.
2023-06-14 20:33:50.261: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 41.090759]
2023-06-14 20:33:50.918: epoch 3:	0.00512459  	0.01031346  	0.00921537  
2023-06-14 20:33:50.918: Find a better model.
2023-06-14 20:34:30.202: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 39.277157]
2023-06-14 20:34:30.735: epoch 4:	0.00577993  	0.01166230  	0.01056541  
2023-06-14 20:34:30.735: Find a better model.
2023-06-14 20:35:13.031: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 42.277499]
2023-06-14 20:35:13.444: epoch 5:	0.00678980  	0.01369792  	0.01243473  
2023-06-14 20:35:13.444: Find a better model.
2023-06-14 20:35:57.276: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 43.824979]
2023-06-14 20:35:57.708: epoch 6:	0.00800923  	0.01583733  	0.01458323  
2023-06-14 20:35:57.708: Find a better model.
2023-06-14 20:36:37.758: [iter 7 : loss : 1.6055 = 0.6928 + 0.9128 + 0.0000, time: 40.041764]
2023-06-14 20:36:38.378: epoch 7:	0.00863774  	0.01641055  	0.01479942  
2023-06-14 20:36:38.378: Find a better model.
2023-06-14 20:37:17.478: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 39.093611]
2023-06-14 20:37:17.893: epoch 8:	0.00976583  	0.01917814  	0.01752360  
2023-06-14 20:37:17.893: Find a better model.
2023-06-14 20:38:01.132: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 43.231769]
2023-06-14 20:38:01.553: epoch 9:	0.01147411  	0.02248633  	0.02057319  
2023-06-14 20:38:01.553: Find a better model.
2023-06-14 20:38:46.314: [iter 10 : loss : 1.6053 = 0.6923 + 0.9130 + 0.0000, time: 44.754392]
2023-06-14 20:38:46.748: epoch 10:	0.01295671  	0.02556246  	0.02359470  
2023-06-14 20:38:46.748: Find a better model.
2023-06-14 20:39:28.042: [iter 11 : loss : 1.6050 = 0.6920 + 0.9130 + 0.0000, time: 41.285664]
2023-06-14 20:39:28.684: epoch 11:	0.01570714  	0.03110714  	0.02932087  
2023-06-14 20:39:28.684: Find a better model.
2023-06-14 20:40:09.175: [iter 12 : loss : 1.6048 = 0.6916 + 0.9132 + 0.0000, time: 40.484456]
2023-06-14 20:40:09.605: epoch 12:	0.01903237  	0.03783789  	0.03611584  
2023-06-14 20:40:09.605: Find a better model.
2023-06-14 20:40:52.262: [iter 13 : loss : 1.6045 = 0.6909 + 0.9135 + 0.0000, time: 42.641008]
2023-06-14 20:40:52.702: epoch 13:	0.02294847  	0.04607818  	0.04403855  
2023-06-14 20:40:52.702: Find a better model.
2023-06-14 20:41:37.977: [iter 14 : loss : 1.6037 = 0.6898 + 0.9138 + 0.0000, time: 45.266579]
2023-06-14 20:41:38.536: epoch 14:	0.02901313  	0.05809218  	0.05626718  
2023-06-14 20:41:38.537: Find a better model.
2023-06-14 20:42:23.183: [iter 15 : loss : 1.6021 = 0.6878 + 0.9143 + 0.0001, time: 44.640289]
2023-06-14 20:42:23.815: epoch 15:	0.03731183  	0.07508248  	0.07187243  
2023-06-14 20:42:23.815: Find a better model.
2023-06-14 20:43:05.123: [iter 16 : loss : 1.5988 = 0.6837 + 0.9150 + 0.0001, time: 41.300679]
2023-06-14 20:43:05.520: epoch 16:	0.04801190  	0.09508361  	0.09270822  
2023-06-14 20:43:05.520: Find a better model.
2023-06-14 20:43:47.802: [iter 17 : loss : 1.5914 = 0.6749 + 0.9163 + 0.0001, time: 42.274507]
2023-06-14 20:43:48.436: epoch 17:	0.05988830  	0.11638355  	0.11539984  
2023-06-14 20:43:48.436: Find a better model.
2023-06-14 20:44:33.702: [iter 18 : loss : 1.5745 = 0.6555 + 0.9187 + 0.0003, time: 45.258452]
2023-06-14 20:44:34.135: epoch 18:	0.07036809  	0.13362563  	0.13427491  
2023-06-14 20:44:34.135: Find a better model.
2023-06-14 20:45:20.290: [iter 19 : loss : 1.5416 = 0.6182 + 0.9229 + 0.0005, time: 46.146979]
2023-06-14 20:45:21.074: epoch 19:	0.07690509  	0.14478669  	0.14646609  
2023-06-14 20:45:21.075: Find a better model.
2023-06-14 20:46:02.657: [iter 20 : loss : 1.4927 = 0.5629 + 0.9289 + 0.0008, time: 41.568119]
2023-06-14 20:46:03.291: epoch 20:	0.08064353  	0.15084104  	0.15265219  
2023-06-14 20:46:03.291: Find a better model.
2023-06-14 20:46:44.397: [iter 21 : loss : 1.4356 = 0.4989 + 0.9353 + 0.0013, time: 41.099026]
2023-06-14 20:46:44.849: epoch 21:	0.08281358  	0.15494041  	0.15627573  
2023-06-14 20:46:44.850: Find a better model.
2023-06-14 20:47:29.113: [iter 22 : loss : 1.3799 = 0.4376 + 0.9406 + 0.0018, time: 44.257483]
2023-06-14 20:47:29.535: epoch 22:	0.08451644  	0.15787481  	0.15852664  
2023-06-14 20:47:29.535: Find a better model.
2023-06-14 20:48:15.303: [iter 23 : loss : 1.3313 = 0.3852 + 0.9438 + 0.0023, time: 45.760754]
2023-06-14 20:48:15.750: epoch 23:	0.08552109  	0.16031000  	0.16000479  
2023-06-14 20:48:15.750: Find a better model.
2023-06-14 20:48:57.730: [iter 24 : loss : 1.2900 = 0.3416 + 0.9456 + 0.0028, time: 41.973463]
2023-06-14 20:48:58.380: epoch 24:	0.08599377  	0.16165999  	0.16090415  
2023-06-14 20:48:58.380: Find a better model.
2023-06-14 20:49:39.814: [iter 25 : loss : 1.2560 = 0.3067 + 0.9461 + 0.0033, time: 41.427032]
2023-06-14 20:49:40.226: epoch 25:	0.08646119  	0.16267268  	0.16173965  
2023-06-14 20:49:40.226: Find a better model.
2023-06-14 20:50:25.085: [iter 26 : loss : 1.2265 = 0.2769 + 0.9458 + 0.0038, time: 44.852074]
2023-06-14 20:50:25.495: epoch 26:	0.08683192  	0.16320401  	0.16212812  
2023-06-14 20:50:25.495: Find a better model.
2023-06-14 20:51:10.997: [iter 27 : loss : 1.2019 = 0.2525 + 0.9451 + 0.0042, time: 45.495705]
2023-06-14 20:51:11.415: epoch 27:	0.08711123  	0.16394289  	0.16237542  
2023-06-14 20:51:11.415: Find a better model.
2023-06-14 20:51:55.533: [iter 28 : loss : 1.1810 = 0.2320 + 0.9444 + 0.0046, time: 44.110746]
2023-06-14 20:51:56.199: epoch 28:	0.08732061  	0.16402274  	0.16214880  
2023-06-14 20:51:56.199: Find a better model.
2023-06-14 20:52:37.242: [iter 29 : loss : 1.1633 = 0.2150 + 0.9433 + 0.0050, time: 41.035473]
2023-06-14 20:52:37.730: epoch 29:	0.08728304  	0.16350755  	0.16217367  
2023-06-14 20:53:22.286: [iter 30 : loss : 1.1473 = 0.1997 + 0.9422 + 0.0054, time: 44.549023]
2023-06-14 20:53:22.709: epoch 30:	0.08721855  	0.16318116  	0.16210201  
2023-06-14 20:54:08.203: [iter 31 : loss : 1.1330 = 0.1861 + 0.9412 + 0.0058, time: 45.487152]
2023-06-14 20:54:08.613: epoch 31:	0.08706810  	0.16289255  	0.16147397  
2023-06-14 20:54:50.118: [iter 32 : loss : 1.1213 = 0.1751 + 0.9401 + 0.0061, time: 41.497386]
2023-06-14 20:54:50.759: epoch 32:	0.08708428  	0.16259779  	0.16117771  
2023-06-14 20:55:34.008: [iter 33 : loss : 1.1101 = 0.1645 + 0.9391 + 0.0065, time: 43.243459]
2023-06-14 20:55:34.498: epoch 33:	0.08713267  	0.16273186  	0.16093084  
2023-06-14 20:56:19.791: [iter 34 : loss : 1.1015 = 0.1564 + 0.9383 + 0.0068, time: 45.284918]
2023-06-14 20:56:20.207: epoch 34:	0.08682647  	0.16220815  	0.16047361  
2023-06-14 20:57:06.329: [iter 35 : loss : 1.0920 = 0.1475 + 0.9374 + 0.0071, time: 46.115568]
2023-06-14 20:57:06.737: epoch 35:	0.08679963  	0.16156612  	0.15991430  
2023-06-14 20:57:48.435: [iter 36 : loss : 1.0847 = 0.1407 + 0.9366 + 0.0074, time: 41.689210]
2023-06-14 20:57:49.086: epoch 36:	0.08659018  	0.16086380  	0.15925124  
2023-06-14 20:58:30.385: [iter 37 : loss : 1.0774 = 0.1340 + 0.9357 + 0.0077, time: 41.291325]
2023-06-14 20:58:30.863: epoch 37:	0.08630009  	0.16035202  	0.15877880  
2023-06-14 20:59:15.938: [iter 38 : loss : 1.0713 = 0.1284 + 0.9349 + 0.0080, time: 45.066674]
2023-06-14 20:59:16.345: epoch 38:	0.08629476  	0.16002643  	0.15840399  
2023-06-14 21:00:02.437: [iter 39 : loss : 1.0656 = 0.1231 + 0.9342 + 0.0083, time: 46.085342]
2023-06-14 21:00:02.851: epoch 39:	0.08614978  	0.15976228  	0.15789688  
2023-06-14 21:00:44.735: [iter 40 : loss : 1.0605 = 0.1184 + 0.9335 + 0.0085, time: 41.876486]
2023-06-14 21:00:45.370: epoch 40:	0.08593490  	0.15887938  	0.15721504  
2023-06-14 21:01:27.163: [iter 41 : loss : 1.0552 = 0.1136 + 0.9328 + 0.0088, time: 41.784997]
2023-06-14 21:01:27.591: epoch 41:	0.08577909  	0.15803859  	0.15661922  
2023-06-14 21:02:12.633: [iter 42 : loss : 1.0509 = 0.1096 + 0.9323 + 0.0091, time: 45.035697]
2023-06-14 21:02:13.089: epoch 42:	0.08553742  	0.15719177  	0.15601355  
2023-06-14 21:02:58.779: [iter 43 : loss : 1.0465 = 0.1055 + 0.9317 + 0.0093, time: 45.678227]
2023-06-14 21:02:59.223: epoch 43:	0.08523657  	0.15615602  	0.15533239  
2023-06-14 21:03:41.569: [iter 44 : loss : 1.0428 = 0.1020 + 0.9313 + 0.0095, time: 42.338000]
2023-06-14 21:03:42.200: epoch 44:	0.08495723  	0.15538335  	0.15476279  
2023-06-14 21:04:24.041: [iter 45 : loss : 1.0399 = 0.0993 + 0.9308 + 0.0098, time: 41.832577]
2023-06-14 21:04:24.584: epoch 45:	0.08464031  	0.15434702  	0.15400234  
2023-06-14 21:05:07.845: [iter 46 : loss : 1.0362 = 0.0958 + 0.9303 + 0.0100, time: 43.253684]
2023-06-14 21:05:08.631: epoch 46:	0.08435029  	0.15350667  	0.15333444  
2023-06-14 21:05:54.837: [iter 47 : loss : 1.0331 = 0.0931 + 0.9298 + 0.0102, time: 46.199328]
2023-06-14 21:05:55.373: epoch 47:	0.08415151  	0.15312184  	0.15284076  
2023-06-14 21:06:41.506: [iter 48 : loss : 1.0300 = 0.0901 + 0.9294 + 0.0104, time: 46.126019]
2023-06-14 21:06:42.387: epoch 48:	0.08388828  	0.15233223  	0.15223354  
2023-06-14 21:07:24.886: [iter 49 : loss : 1.0275 = 0.0879 + 0.9290 + 0.0106, time: 42.491203]
2023-06-14 21:07:25.503: epoch 49:	0.08356602  	0.15128790  	0.15147126  
2023-06-14 21:08:07.855: [iter 50 : loss : 1.0250 = 0.0855 + 0.9286 + 0.0108, time: 42.344547]
2023-06-14 21:08:08.425: epoch 50:	0.08335120  	0.15061539  	0.15085326  
2023-06-14 21:08:51.633: [iter 51 : loss : 1.0228 = 0.0834 + 0.9284 + 0.0110, time: 43.202596]
2023-06-14 21:08:52.549: epoch 51:	0.08315244  	0.15043058  	0.15049188  
2023-06-14 21:09:39.103: [iter 52 : loss : 1.0206 = 0.0812 + 0.9281 + 0.0112, time: 46.545905]
2023-06-14 21:09:39.579: epoch 52:	0.08275497  	0.14950639  	0.14973497  
2023-06-14 21:10:27.308: [iter 53 : loss : 1.0184 = 0.0793 + 0.9277 + 0.0114, time: 47.721508]
2023-06-14 21:10:27.893: epoch 53:	0.08262065  	0.14936478  	0.14940231  
2023-06-14 21:10:27.893: Early stopping is trigger at epoch: 53
2023-06-14 21:10:27.893: best_result@epoch 28:

2023-06-14 21:10:27.893: 		0.0873      	0.1640      	0.1621      
2023-06-14 21:13:39.331: my pid: 420
2023-06-14 21:13:39.331: model: model.general_recommender.SGL
2023-06-14 21:13:39.331: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-14 21:13:39.331: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-14 21:13:44.557: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-14 21:14:24.421: [iter 1 : loss : 1.6082 = 0.6931 + 0.9151 + 0.0000, time: 39.863790]
2023-06-14 21:14:24.856: epoch 1:	0.00348623  	0.00857307  	0.00671847  
2023-06-14 21:14:24.856: Find a better model.
2023-06-14 21:15:08.891: [iter 2 : loss : 1.6058 = 0.6931 + 0.9127 + 0.0000, time: 44.028896]
2023-06-14 21:15:09.327: epoch 2:	0.00424901  	0.00976490  	0.00822128  
2023-06-14 21:15:09.327: Find a better model.
2023-06-14 21:15:52.772: [iter 3 : loss : 1.6056 = 0.6930 + 0.9126 + 0.0000, time: 43.438379]
2023-06-14 21:15:53.444: epoch 3:	0.00524813  	0.01182887  	0.00997995  
2023-06-14 21:15:53.444: Find a better model.
2023-06-14 21:16:32.645: [iter 4 : loss : 1.6055 = 0.6930 + 0.9126 + 0.0000, time: 39.195276]
2023-06-14 21:16:33.051: epoch 4:	0.00586588  	0.01291279  	0.01123502  
2023-06-14 21:16:33.051: Find a better model.
2023-06-14 21:17:14.225: [iter 5 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 41.165735]
2023-06-14 21:17:14.638: epoch 5:	0.00711211  	0.01429597  	0.01283457  
2023-06-14 21:17:14.638: Find a better model.
2023-06-14 21:17:57.959: [iter 6 : loss : 1.6055 = 0.6929 + 0.9126 + 0.0000, time: 43.315222]
2023-06-14 21:17:58.609: epoch 6:	0.00792327  	0.01620414  	0.01481526  
2023-06-14 21:17:58.609: Find a better model.
2023-06-14 21:18:40.249: [iter 7 : loss : 1.6055 = 0.6928 + 0.9128 + 0.0000, time: 41.612308]
2023-06-14 21:18:40.866: epoch 7:	0.00898693  	0.01769372  	0.01591405  
2023-06-14 21:18:40.866: Find a better model.
2023-06-14 21:19:20.038: [iter 8 : loss : 1.6054 = 0.6927 + 0.9128 + 0.0000, time: 39.166209]
2023-06-14 21:19:20.498: epoch 8:	0.01006128  	0.01930888  	0.01778936  
2023-06-14 21:19:20.499: Find a better model.
2023-06-14 21:20:04.506: [iter 9 : loss : 1.6055 = 0.6925 + 0.9130 + 0.0000, time: 43.998890]
2023-06-14 21:20:04.916: epoch 9:	0.01156003  	0.02204219  	0.02074341  
2023-06-14 21:20:04.916: Find a better model.
2023-06-14 21:20:48.856: [iter 10 : loss : 1.6053 = 0.6923 + 0.9130 + 0.0000, time: 43.933310]
2023-06-14 21:20:49.283: epoch 10:	0.01356912  	0.02648629  	0.02510033  
2023-06-14 21:20:49.283: Find a better model.
2023-06-14 21:21:30.372: [iter 11 : loss : 1.6051 = 0.6920 + 0.9131 + 0.0000, time: 41.079777]
2023-06-14 21:21:30.978: epoch 11:	0.01653441  	0.03223635  	0.03033976  
2023-06-14 21:21:30.978: Find a better model.
2023-06-14 21:22:11.449: [iter 12 : loss : 1.6049 = 0.6916 + 0.9133 + 0.0000, time: 40.463987]
2023-06-14 21:22:11.882: epoch 12:	0.01978979  	0.03862939  	0.03745779  
2023-06-14 21:22:11.882: Find a better model.
2023-06-14 21:22:54.006: [iter 13 : loss : 1.6045 = 0.6909 + 0.9135 + 0.0000, time: 42.117227]
2023-06-14 21:22:54.426: epoch 13:	0.02369513  	0.04707356  	0.04589087  
2023-06-14 21:22:54.426: Find a better model.
2023-06-14 21:23:39.611: [iter 14 : loss : 1.6037 = 0.6898 + 0.9138 + 0.0000, time: 45.178143]
2023-06-14 21:23:40.326: epoch 14:	0.02992082  	0.05936400  	0.05855928  
2023-06-14 21:23:40.326: Find a better model.
2023-06-14 21:24:24.385: [iter 15 : loss : 1.6021 = 0.6878 + 0.9143 + 0.0001, time: 44.052937]
2023-06-14 21:24:24.992: epoch 15:	0.03839149  	0.07663684  	0.07586899  
2023-06-14 21:24:24.992: Find a better model.
2023-06-14 21:25:05.821: [iter 16 : loss : 1.5988 = 0.6837 + 0.9151 + 0.0001, time: 40.821305]
2023-06-14 21:25:06.320: epoch 16:	0.04931720  	0.09633948  	0.09608728  
2023-06-14 21:25:06.321: Find a better model.
2023-06-14 21:25:48.958: [iter 17 : loss : 1.5912 = 0.6747 + 0.9163 + 0.0001, time: 42.631454]
2023-06-14 21:25:49.372: epoch 17:	0.06154257  	0.11857754  	0.11850881  
2023-06-14 21:25:49.372: Find a better model.
2023-06-14 21:26:34.487: [iter 18 : loss : 1.5740 = 0.6549 + 0.9188 + 0.0003, time: 45.107275]
2023-06-14 21:26:34.898: epoch 18:	0.07177532  	0.13564773  	0.13671790  
2023-06-14 21:26:34.899: Find a better model.
2023-06-14 21:27:18.015: [iter 19 : loss : 1.5402 = 0.6167 + 0.9231 + 0.0005, time: 43.101542]
2023-06-14 21:27:18.628: epoch 19:	0.07844681  	0.14720120  	0.14829212  
2023-06-14 21:27:18.629: Find a better model.
2023-06-14 21:27:59.313: [iter 20 : loss : 1.4904 = 0.5602 + 0.9293 + 0.0009, time: 40.678029]
2023-06-14 21:27:59.732: epoch 20:	0.08213697  	0.15368295  	0.15434910  
2023-06-14 21:27:59.733: Find a better model.
2023-06-14 21:28:44.476: [iter 21 : loss : 1.4330 = 0.4957 + 0.9359 + 0.0013, time: 44.736122]
2023-06-14 21:28:44.865: epoch 21:	0.08400091  	0.15713567  	0.15803443  
2023-06-14 21:28:44.865: Find a better model.
2023-06-14 21:29:30.597: [iter 22 : loss : 1.3775 = 0.4346 + 0.9411 + 0.0018, time: 45.724502]
2023-06-14 21:29:31.003: epoch 22:	0.08529010  	0.15926719  	0.16017729  
2023-06-14 21:29:31.003: Find a better model.
2023-06-14 21:30:12.002: [iter 23 : loss : 1.3294 = 0.3828 + 0.9442 + 0.0023, time: 40.983488]
2023-06-14 21:30:12.646: epoch 23:	0.08632134  	0.16196454  	0.16202718  
2023-06-14 21:30:12.646: Find a better model.
2023-06-14 21:30:53.935: [iter 24 : loss : 1.2885 = 0.3399 + 0.9458 + 0.0028, time: 41.282132]
2023-06-14 21:30:54.413: epoch 24:	0.08684235  	0.16356987  	0.16324484  
2023-06-14 21:30:54.413: Find a better model.
2023-06-14 21:31:39.600: [iter 25 : loss : 1.2548 = 0.3055 + 0.9460 + 0.0033, time: 45.179380]
2023-06-14 21:31:39.989: epoch 25:	0.08718614  	0.16433296  	0.16384947  
2023-06-14 21:31:39.989: Find a better model.
2023-06-14 21:32:25.758: [iter 26 : loss : 1.2255 = 0.2760 + 0.9457 + 0.0038, time: 45.763813]
2023-06-14 21:32:26.268: epoch 26:	0.08761594  	0.16486324  	0.16428564  
2023-06-14 21:32:26.269: Find a better model.
2023-06-14 21:33:07.623: [iter 27 : loss : 1.2011 = 0.2519 + 0.9449 + 0.0042, time: 41.337374]
2023-06-14 21:33:08.269: epoch 27:	0.08788455  	0.16502178  	0.16450493  
2023-06-14 21:33:08.270: Find a better model.
2023-06-14 21:33:49.482: [iter 28 : loss : 1.1801 = 0.2313 + 0.9442 + 0.0046, time: 41.205379]
2023-06-14 21:33:49.905: epoch 28:	0.08805642  	0.16557901  	0.16446781  
2023-06-14 21:33:49.905: Find a better model.
2023-06-14 21:34:34.577: [iter 29 : loss : 1.1625 = 0.2145 + 0.9430 + 0.0050, time: 44.664737]
2023-06-14 21:34:34.988: epoch 29:	0.08780932  	0.16510248  	0.16410033  
2023-06-14 21:35:20.377: [iter 30 : loss : 1.1467 = 0.1993 + 0.9420 + 0.0054, time: 45.382079]
2023-06-14 21:35:20.782: epoch 30:	0.08788450  	0.16505274  	0.16397379  
2023-06-14 21:36:02.623: [iter 31 : loss : 1.1327 = 0.1860 + 0.9409 + 0.0058, time: 41.833527]
2023-06-14 21:36:03.249: epoch 31:	0.08768578  	0.16435081  	0.16354400  
2023-06-14 21:36:44.273: [iter 32 : loss : 1.1210 = 0.1750 + 0.9399 + 0.0061, time: 41.018736]
2023-06-14 21:36:44.706: epoch 32:	0.08779864  	0.16453494  	0.16340955  
2023-06-14 21:37:29.461: [iter 33 : loss : 1.1097 = 0.1643 + 0.9389 + 0.0065, time: 44.747100]
2023-06-14 21:37:29.875: epoch 33:	0.08775568  	0.16416691  	0.16315578  
2023-06-14 21:38:15.309: [iter 34 : loss : 1.1009 = 0.1561 + 0.9380 + 0.0068, time: 45.427028]
2023-06-14 21:38:15.711: epoch 34:	0.08772336  	0.16354489  	0.16275752  
2023-06-14 21:38:57.630: [iter 35 : loss : 1.0915 = 0.1473 + 0.9371 + 0.0071, time: 41.912489]
2023-06-14 21:38:58.256: epoch 35:	0.08759981  	0.16312258  	0.16231853  
2023-06-14 21:39:39.585: [iter 36 : loss : 1.0842 = 0.1405 + 0.9363 + 0.0074, time: 41.322156]
2023-06-14 21:39:40.015: epoch 36:	0.08729899  	0.16200978  	0.16180599  
2023-06-14 21:40:23.244: [iter 37 : loss : 1.0771 = 0.1339 + 0.9355 + 0.0077, time: 43.222217]
2023-06-14 21:40:23.652: epoch 37:	0.08734736  	0.16180773  	0.16160771  
2023-06-14 21:41:09.710: [iter 38 : loss : 1.0708 = 0.1280 + 0.9347 + 0.0080, time: 46.051210]
2023-06-14 21:41:10.132: epoch 38:	0.08716474  	0.16172262  	0.16104460  
2023-06-14 21:41:56.327: [iter 39 : loss : 1.0652 = 0.1230 + 0.9339 + 0.0083, time: 46.178911]
2023-06-14 21:41:56.833: epoch 39:	0.08679415  	0.16056627  	0.16029172  
2023-06-14 21:42:39.416: [iter 40 : loss : 1.0603 = 0.1184 + 0.9333 + 0.0086, time: 42.573066]
2023-06-14 21:42:40.035: epoch 40:	0.08648799  	0.15964620  	0.15958323  
2023-06-14 21:43:21.481: [iter 41 : loss : 1.0550 = 0.1135 + 0.9327 + 0.0088, time: 41.438520]
2023-06-14 21:43:21.891: epoch 41:	0.08634832  	0.15875056  	0.15878595  
2023-06-14 21:44:05.252: [iter 42 : loss : 1.0506 = 0.1094 + 0.9321 + 0.0091, time: 43.354576]
2023-06-14 21:44:05.658: epoch 42:	0.08610128  	0.15799537  	0.15820281  
2023-06-14 21:44:51.633: [iter 43 : loss : 1.0463 = 0.1054 + 0.9316 + 0.0093, time: 45.968581]
2023-06-14 21:44:52.028: epoch 43:	0.08565544  	0.15698662  	0.15759204  
2023-06-14 21:45:38.454: [iter 44 : loss : 1.0424 = 0.1018 + 0.9311 + 0.0095, time: 46.412290]
2023-06-14 21:45:38.954: epoch 44:	0.08553722  	0.15650715  	0.15707192  
2023-06-14 21:46:20.381: [iter 45 : loss : 1.0396 = 0.0992 + 0.9306 + 0.0098, time: 41.419091]
2023-06-14 21:46:20.859: epoch 45:	0.08527941  	0.15610363  	0.15655351  
2023-06-14 21:47:02.754: [iter 46 : loss : 1.0358 = 0.0956 + 0.9302 + 0.0100, time: 41.887033]
2023-06-14 21:47:03.338: epoch 46:	0.08504845  	0.15532976  	0.15591425  
2023-06-14 21:47:47.665: [iter 47 : loss : 1.0325 = 0.0926 + 0.9297 + 0.0102, time: 44.319071]
2023-06-14 21:47:48.083: epoch 47:	0.08476909  	0.15448047  	0.15526888  
2023-06-14 21:48:33.403: [iter 48 : loss : 1.0297 = 0.0900 + 0.9293 + 0.0104, time: 45.304132]
2023-06-14 21:48:33.804: epoch 48:	0.08486585  	0.15420248  	0.15483667  
2023-06-14 21:49:16.857: [iter 49 : loss : 1.0272 = 0.0876 + 0.9289 + 0.0107, time: 43.045487]
2023-06-14 21:49:17.474: epoch 49:	0.08454893  	0.15341623  	0.15424290  
2023-06-14 21:49:58.966: [iter 50 : loss : 1.0246 = 0.0852 + 0.9285 + 0.0109, time: 41.485015]
2023-06-14 21:49:59.438: epoch 50:	0.08439853  	0.15298718  	0.15377532  
2023-06-14 21:50:42.046: [iter 51 : loss : 1.0222 = 0.0830 + 0.9282 + 0.0110, time: 42.600924]
2023-06-14 21:50:42.680: epoch 51:	0.08399563  	0.15212747  	0.15316172  
2023-06-14 21:51:28.657: [iter 52 : loss : 1.0202 = 0.0810 + 0.9280 + 0.0112, time: 45.970075]
2023-06-14 21:51:29.046: epoch 52:	0.08363039  	0.15156922  	0.15253030  
2023-06-14 21:52:14.989: [iter 53 : loss : 1.0178 = 0.0788 + 0.9275 + 0.0114, time: 45.932806]
2023-06-14 21:52:15.508: epoch 53:	0.08342090  	0.15087207  	0.15184502  
2023-06-14 21:52:15.508: Early stopping is trigger at epoch: 53
2023-06-14 21:52:15.508: best_result@epoch 28:

2023-06-14 21:52:15.508: 		0.0881      	0.1656      	0.1645      
2023-06-15 09:25:18.680: my pid: 12088
2023-06-15 09:25:18.681: model: model.general_recommender.SGL
2023-06-15 09:25:18.681: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 09:25:18.681: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 09:25:23.733: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 09:26:03.126: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 39.392737]
2023-06-15 09:26:03.556: epoch 1:	0.00334120  	0.00819481  	0.00645556  
2023-06-15 09:26:03.556: Find a better model.
2023-06-15 09:26:46.758: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 43.190219]
2023-06-15 09:26:47.424: epoch 2:	0.00427587  	0.00917148  	0.00798218  
2023-06-15 09:26:47.424: Find a better model.
2023-06-15 09:27:26.249: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 38.819585]
2023-06-15 09:27:26.685: epoch 3:	0.00508161  	0.01091605  	0.00922775  
2023-06-15 09:27:26.685: Find a better model.
2023-06-15 09:28:10.099: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 43.406102]
2023-06-15 09:28:10.532: epoch 4:	0.00590348  	0.01280458  	0.01085001  
2023-06-15 09:28:10.532: Find a better model.
2023-06-15 09:28:49.685: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 39.146425]
2023-06-15 09:28:50.097: epoch 5:	0.00706376  	0.01499803  	0.01300994  
2023-06-15 09:28:50.097: Find a better model.
2023-06-15 09:29:33.990: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 43.886310]
2023-06-15 09:29:34.417: epoch 6:	0.00772989  	0.01530874  	0.01414680  
2023-06-15 09:29:34.417: Find a better model.
2023-06-15 09:30:17.149: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 42.715739]
2023-06-15 09:30:17.822: epoch 7:	0.00893856  	0.01802430  	0.01662358  
2023-06-15 09:30:17.822: Find a better model.
2023-06-15 09:30:56.909: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 39.078617]
2023-06-15 09:30:57.352: epoch 8:	0.00983030  	0.01946159  	0.01778827  
2023-06-15 09:30:57.352: Find a better model.
2023-06-15 09:31:41.340: [iter 9 : loss : 1.6055 = 0.6925 + 0.9129 + 0.0000, time: 43.982001]
2023-06-15 09:31:41.762: epoch 9:	0.01204887  	0.02348315  	0.02192292  
2023-06-15 09:31:41.763: Find a better model.
2023-06-15 09:32:20.756: [iter 10 : loss : 1.6053 = 0.6924 + 0.9129 + 0.0000, time: 38.987257]
2023-06-15 09:32:21.162: epoch 10:	0.01342408  	0.02655519  	0.02450860  
2023-06-15 09:32:21.162: Find a better model.
2023-06-15 09:33:04.837: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 43.668428]
2023-06-15 09:33:05.276: epoch 11:	0.01611005  	0.03242619  	0.03045235  
2023-06-15 09:33:05.276: Find a better model.
2023-06-15 09:33:49.539: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 44.248435]
2023-06-15 09:33:50.202: epoch 12:	0.01997245  	0.04026118  	0.03768611  
2023-06-15 09:33:50.203: Find a better model.
2023-06-15 09:34:30.099: [iter 13 : loss : 1.6046 = 0.6911 + 0.9134 + 0.0000, time: 39.890105]
2023-06-15 09:34:30.558: epoch 13:	0.02378110  	0.04762788  	0.04556966  
2023-06-15 09:34:30.558: Find a better model.
2023-06-15 09:35:16.031: [iter 14 : loss : 1.6039 = 0.6901 + 0.9137 + 0.0000, time: 45.466944]
2023-06-15 09:35:16.463: epoch 14:	0.02959318  	0.05939877  	0.05781935  
2023-06-15 09:35:16.463: Find a better model.
2023-06-15 09:35:58.966: [iter 15 : loss : 1.6025 = 0.6883 + 0.9142 + 0.0001, time: 42.496653]
2023-06-15 09:35:59.657: epoch 15:	0.03753208  	0.07516065  	0.07383364  
2023-06-15 09:35:59.658: Find a better model.
2023-06-15 09:36:40.650: [iter 16 : loss : 1.5997 = 0.6847 + 0.9149 + 0.0001, time: 40.984768]
2023-06-15 09:36:41.572: epoch 16:	0.04743719  	0.09358256  	0.09275336  
2023-06-15 09:36:41.572: Find a better model.
2023-06-15 09:37:26.882: [iter 17 : loss : 1.5932 = 0.6769 + 0.9161 + 0.0001, time: 45.304388]
2023-06-15 09:37:27.378: epoch 17:	0.05912022  	0.11450318  	0.11432274  
2023-06-15 09:37:27.378: Find a better model.
2023-06-15 09:38:07.376: [iter 18 : loss : 1.5783 = 0.6596 + 0.9185 + 0.0002, time: 39.991005]
2023-06-15 09:38:07.798: epoch 18:	0.06963202  	0.13225403  	0.13244757  
2023-06-15 09:38:07.798: Find a better model.
2023-06-15 09:38:53.083: [iter 19 : loss : 1.5485 = 0.6256 + 0.9224 + 0.0005, time: 45.277117]
2023-06-15 09:38:53.584: epoch 19:	0.07710931  	0.14448595  	0.14536564  
2023-06-15 09:38:53.584: Find a better model.
2023-06-15 09:39:37.632: [iter 20 : loss : 1.5023 = 0.5734 + 0.9281 + 0.0008, time: 44.040917]
2023-06-15 09:39:38.307: epoch 20:	0.08078861  	0.15094152  	0.15271650  
2023-06-15 09:39:38.307: Find a better model.
2023-06-15 09:40:18.771: [iter 21 : loss : 1.4463 = 0.5108 + 0.9343 + 0.0012, time: 40.456894]
2023-06-15 09:40:19.231: epoch 21:	0.08310369  	0.15544727  	0.15674029  
2023-06-15 09:40:19.231: Find a better model.
2023-06-15 09:41:04.258: [iter 22 : loss : 1.3901 = 0.4488 + 0.9396 + 0.0017, time: 45.020995]
2023-06-15 09:41:04.669: epoch 22:	0.08459707  	0.15888715  	0.15940408  
2023-06-15 09:41:04.669: Find a better model.
2023-06-15 09:41:45.109: [iter 23 : loss : 1.3405 = 0.3950 + 0.9433 + 0.0022, time: 40.433757]
2023-06-15 09:41:45.523: epoch 23:	0.08544039  	0.16024955  	0.16093321  
2023-06-15 09:41:45.523: Find a better model.
2023-06-15 09:42:28.931: [iter 24 : loss : 1.2977 = 0.3496 + 0.9453 + 0.0027, time: 43.402382]
2023-06-15 09:42:29.362: epoch 24:	0.08624074  	0.16190548  	0.16224538  
2023-06-15 09:42:29.362: Find a better model.
2023-06-15 09:43:14.412: [iter 25 : loss : 1.2624 = 0.3133 + 0.9459 + 0.0032, time: 45.042629]
2023-06-15 09:43:14.931: epoch 25:	0.08643955  	0.16271473  	0.16309012  
2023-06-15 09:43:14.931: Find a better model.
2023-06-15 09:43:55.638: [iter 26 : loss : 1.2319 = 0.2823 + 0.9459 + 0.0037, time: 40.698673]
2023-06-15 09:43:56.085: epoch 26:	0.08679950  	0.16336976  	0.16379873  
2023-06-15 09:43:56.086: Find a better model.
2023-06-15 09:44:41.809: [iter 27 : loss : 1.2065 = 0.2570 + 0.9454 + 0.0041, time: 45.716802]
2023-06-15 09:44:42.278: epoch 27:	0.08709496  	0.16405176  	0.16404034  
2023-06-15 09:44:42.278: Find a better model.
2023-06-15 09:45:26.951: [iter 28 : loss : 1.1851 = 0.2360 + 0.9446 + 0.0046, time: 44.650598]
2023-06-15 09:45:27.622: epoch 28:	0.08727753  	0.16417697  	0.16401562  
2023-06-15 09:45:27.622: Find a better model.
2023-06-15 09:46:08.813: [iter 29 : loss : 1.1667 = 0.2182 + 0.9435 + 0.0050, time: 41.183930]
2023-06-15 09:46:09.217: epoch 29:	0.08721313  	0.16409384  	0.16375808  
2023-06-15 09:46:54.822: [iter 30 : loss : 1.1502 = 0.2024 + 0.9425 + 0.0053, time: 45.586903]
2023-06-15 09:46:55.369: epoch 30:	0.08736354  	0.16398989  	0.16372474  
2023-06-15 09:47:37.799: [iter 31 : loss : 1.1357 = 0.1885 + 0.9415 + 0.0057, time: 42.418784]
2023-06-15 09:47:38.485: epoch 31:	0.08735278  	0.16397069  	0.16336052  
2023-06-15 09:48:20.064: [iter 32 : loss : 1.1236 = 0.1771 + 0.9404 + 0.0061, time: 41.572513]
2023-06-15 09:48:20.711: epoch 32:	0.08727757  	0.16394036  	0.16312939  
2023-06-15 09:49:07.239: [iter 33 : loss : 1.1124 = 0.1665 + 0.9394 + 0.0064, time: 46.520429]
2023-06-15 09:49:07.681: epoch 33:	0.08725610  	0.16349989  	0.16271056  
2023-06-15 09:49:50.043: [iter 34 : loss : 1.1033 = 0.1580 + 0.9385 + 0.0067, time: 42.354850]
2023-06-15 09:49:50.528: epoch 34:	0.08725072  	0.16321550  	0.16239569  
2023-06-15 09:50:34.092: [iter 35 : loss : 1.0938 = 0.1491 + 0.9377 + 0.0071, time: 43.556980]
2023-06-15 09:50:34.515: epoch 35:	0.08724542  	0.16284688  	0.16211700  
2023-06-15 09:51:14.055: [iter 36 : loss : 1.0862 = 0.1419 + 0.9368 + 0.0074, time: 39.532619]
2023-06-15 09:51:14.499: epoch 36:	0.08708957  	0.16225444  	0.16166480  
2023-06-15 09:51:55.486: [iter 37 : loss : 1.0787 = 0.1351 + 0.9359 + 0.0077, time: 40.981885]
2023-06-15 09:51:55.907: epoch 37:	0.08700358  	0.16190128  	0.16126931  
2023-06-15 09:52:36.243: [iter 38 : loss : 1.0724 = 0.1292 + 0.9352 + 0.0080, time: 40.328853]
2023-06-15 09:52:36.627: epoch 38:	0.08672965  	0.16132599  	0.16071047  
2023-06-15 09:53:16.671: [iter 39 : loss : 1.0668 = 0.1242 + 0.9344 + 0.0082, time: 40.036781]
2023-06-15 09:53:17.077: epoch 39:	0.08642344  	0.15991929  	0.15955272  
2023-06-15 09:53:57.821: [iter 40 : loss : 1.0616 = 0.1193 + 0.9338 + 0.0085, time: 40.738818]
2023-06-15 09:53:58.238: epoch 40:	0.08610653  	0.15859891  	0.15886439  
2023-06-15 09:54:39.542: [iter 41 : loss : 1.0561 = 0.1144 + 0.9330 + 0.0088, time: 41.285957]
2023-06-15 09:54:39.946: epoch 41:	0.08596155  	0.15802802  	0.15843648  
2023-06-15 09:55:28.585: [iter 42 : loss : 1.0516 = 0.1101 + 0.9325 + 0.0090, time: 48.632260]
2023-06-15 09:55:29.040: epoch 42:	0.08560164  	0.15705737  	0.15748322  
2023-06-15 09:56:14.455: [iter 43 : loss : 1.0472 = 0.1061 + 0.9319 + 0.0093, time: 45.407954]
2023-06-15 09:56:15.162: epoch 43:	0.08562312  	0.15653586  	0.15717658  
2023-06-15 09:56:59.741: [iter 44 : loss : 1.0435 = 0.1025 + 0.9314 + 0.0095, time: 44.571585]
2023-06-15 09:57:00.184: epoch 44:	0.08528471  	0.15588240  	0.15653864  
2023-06-15 09:57:46.434: [iter 45 : loss : 1.0405 = 0.0999 + 0.9309 + 0.0097, time: 46.243229]
2023-06-15 09:57:46.857: epoch 45:	0.08489259  	0.15500595  	0.15567063  
2023-06-15 09:58:31.385: [iter 46 : loss : 1.0368 = 0.0963 + 0.9305 + 0.0099, time: 44.521608]
2023-06-15 09:58:32.050: epoch 46:	0.08466157  	0.15446684  	0.15497616  
2023-06-15 09:59:13.355: [iter 47 : loss : 1.0333 = 0.0932 + 0.9300 + 0.0102, time: 41.296761]
2023-06-15 09:59:13.761: epoch 47:	0.08444676  	0.15383717  	0.15445648  
2023-06-15 09:59:59.466: [iter 48 : loss : 1.0305 = 0.0905 + 0.9296 + 0.0104, time: 45.698664]
2023-06-15 09:59:59.909: epoch 48:	0.08446825  	0.15335828  	0.15414964  
2023-06-15 10:00:46.036: [iter 49 : loss : 1.0280 = 0.0882 + 0.9292 + 0.0106, time: 46.112772]
2023-06-15 10:00:46.711: epoch 49:	0.08394178  	0.15221295  	0.15316020  
2023-06-15 10:01:27.970: [iter 50 : loss : 1.0255 = 0.0860 + 0.9287 + 0.0108, time: 41.252686]
2023-06-15 10:01:28.448: epoch 50:	0.08380214  	0.15176037  	0.15263125  
2023-06-15 10:02:12.452: [iter 51 : loss : 1.0230 = 0.0835 + 0.9285 + 0.0110, time: 43.996414]
2023-06-15 10:02:12.859: epoch 51:	0.08363561  	0.15113810  	0.15213193  
2023-06-15 10:02:58.978: [iter 52 : loss : 1.0210 = 0.0816 + 0.9282 + 0.0112, time: 46.113431]
2023-06-15 10:02:59.396: epoch 52:	0.08343147  	0.15057869  	0.15155211  
2023-06-15 10:03:40.621: [iter 53 : loss : 1.0185 = 0.0793 + 0.9278 + 0.0114, time: 41.216954]
2023-06-15 10:03:41.025: epoch 53:	0.08320589  	0.14958730  	0.15088521  
2023-06-15 10:03:41.025: Early stopping is trigger at epoch: 53
2023-06-15 10:03:41.025: best_result@epoch 28:

2023-06-15 10:03:41.025: 		0.0873      	0.1642      	0.1640      
2023-06-15 10:20:24.983: my pid: 12632
2023-06-15 10:20:24.983: model: model.general_recommender.SGL
2023-06-15 10:20:24.983: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 10:20:24.983: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 10:20:29.915: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 10:21:11.581: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 41.665081]
2023-06-15 10:21:11.992: epoch 1:	0.00334120  	0.00819481  	0.00645556  
2023-06-15 10:21:11.993: Find a better model.
2023-06-15 10:21:55.555: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 43.555969]
2023-06-15 10:21:55.965: epoch 2:	0.00427587  	0.00917148  	0.00798218  
2023-06-15 10:21:55.965: Find a better model.
2023-06-15 10:22:35.179: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 39.208247]
2023-06-15 10:22:35.606: epoch 3:	0.00508161  	0.01091605  	0.00922775  
2023-06-15 10:22:35.607: Find a better model.
2023-06-15 10:23:17.325: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 41.712610]
2023-06-15 10:23:17.739: epoch 4:	0.00590348  	0.01280458  	0.01085001  
2023-06-15 10:23:17.739: Find a better model.
2023-06-15 10:24:01.405: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 43.658787]
2023-06-15 10:24:01.811: epoch 5:	0.00706376  	0.01499803  	0.01300994  
2023-06-15 10:24:01.811: Find a better model.
2023-06-15 10:24:40.998: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 39.179859]
2023-06-15 10:24:41.441: epoch 6:	0.00772989  	0.01530874  	0.01414680  
2023-06-15 10:24:41.441: Find a better model.
2023-06-15 10:25:23.071: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 41.622775]
2023-06-15 10:25:23.508: epoch 7:	0.00893856  	0.01802430  	0.01662358  
2023-06-15 10:25:23.508: Find a better model.
2023-06-15 10:26:07.372: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 43.856589]
2023-06-15 10:26:07.781: epoch 8:	0.00983030  	0.01946159  	0.01778827  
2023-06-15 10:26:07.781: Find a better model.
2023-06-15 10:26:46.856: [iter 9 : loss : 1.6055 = 0.6925 + 0.9129 + 0.0000, time: 39.066026]
2023-06-15 10:26:47.536: epoch 9:	0.01204887  	0.02348315  	0.02192292  
2023-06-15 10:26:47.536: Find a better model.
2023-06-15 10:27:28.158: [iter 10 : loss : 1.6053 = 0.6924 + 0.9129 + 0.0000, time: 40.614881]
2023-06-15 10:27:28.869: epoch 10:	0.01342408  	0.02655519  	0.02450860  
2023-06-15 10:27:28.870: Find a better model.
2023-06-15 10:28:13.282: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 44.406175]
2023-06-15 10:28:13.729: epoch 11:	0.01611005  	0.03242619  	0.03045235  
2023-06-15 10:28:13.730: Find a better model.
2023-06-15 10:28:57.356: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 43.619475]
2023-06-15 10:28:57.998: epoch 12:	0.01997245  	0.04026118  	0.03768611  
2023-06-15 10:28:57.998: Find a better model.
2023-06-15 10:29:38.569: [iter 13 : loss : 1.6046 = 0.6911 + 0.9134 + 0.0000, time: 40.564428]
2023-06-15 10:29:39.049: epoch 13:	0.02378110  	0.04762788  	0.04556966  
2023-06-15 10:29:39.049: Find a better model.
2023-06-15 10:30:24.246: [iter 14 : loss : 1.6039 = 0.6901 + 0.9137 + 0.0000, time: 45.189867]
2023-06-15 10:30:24.717: epoch 14:	0.02959318  	0.05939877  	0.05781935  
2023-06-15 10:30:24.717: Find a better model.
2023-06-15 10:31:10.155: [iter 15 : loss : 1.6025 = 0.6883 + 0.9142 + 0.0001, time: 45.428604]
2023-06-15 10:31:10.798: epoch 15:	0.03753208  	0.07516065  	0.07383364  
2023-06-15 10:31:10.798: Find a better model.
2023-06-15 10:31:51.642: [iter 16 : loss : 1.5997 = 0.6847 + 0.9149 + 0.0001, time: 40.836943]
2023-06-15 10:31:52.064: epoch 16:	0.04743719  	0.09358256  	0.09275336  
2023-06-15 10:31:52.064: Find a better model.
2023-06-15 10:32:37.354: [iter 17 : loss : 1.5932 = 0.6769 + 0.9161 + 0.0001, time: 45.282920]
2023-06-15 10:32:37.798: epoch 17:	0.05912022  	0.11450318  	0.11432274  
2023-06-15 10:32:37.799: Find a better model.
2023-06-15 10:33:22.655: [iter 18 : loss : 1.5783 = 0.6596 + 0.9185 + 0.0002, time: 44.848846]
2023-06-15 10:33:23.310: epoch 18:	0.06963202  	0.13225403  	0.13244757  
2023-06-15 10:33:23.311: Find a better model.
2023-06-15 10:34:04.223: [iter 19 : loss : 1.5485 = 0.6256 + 0.9224 + 0.0005, time: 40.905237]
2023-06-15 10:34:04.711: epoch 19:	0.07710931  	0.14448595  	0.14536564  
2023-06-15 10:34:04.711: Find a better model.
2023-06-15 10:34:50.047: [iter 20 : loss : 1.5023 = 0.5734 + 0.9281 + 0.0008, time: 45.330198]
2023-06-15 10:34:50.468: epoch 20:	0.08078861  	0.15094152  	0.15271650  
2023-06-15 10:34:50.468: Find a better model.
2023-06-15 10:35:36.363: [iter 21 : loss : 1.4463 = 0.5108 + 0.9343 + 0.0012, time: 45.887046]
2023-06-15 10:35:36.924: epoch 21:	0.08310369  	0.15544727  	0.15674029  
2023-06-15 10:35:36.924: Find a better model.
2023-06-15 10:36:17.802: [iter 22 : loss : 1.3901 = 0.4488 + 0.9396 + 0.0017, time: 40.871658]
2023-06-15 10:36:18.215: epoch 22:	0.08459707  	0.15888715  	0.15940408  
2023-06-15 10:36:18.216: Find a better model.
2023-06-15 10:37:01.751: [iter 23 : loss : 1.3405 = 0.3950 + 0.9433 + 0.0022, time: 43.528965]
2023-06-15 10:37:02.153: epoch 23:	0.08544039  	0.16024955  	0.16093321  
2023-06-15 10:37:02.153: Find a better model.
2023-06-15 10:37:47.706: [iter 24 : loss : 1.2977 = 0.3496 + 0.9453 + 0.0027, time: 45.546317]
2023-06-15 10:37:48.113: epoch 24:	0.08624074  	0.16190548  	0.16224538  
2023-06-15 10:37:48.113: Find a better model.
2023-06-15 10:38:28.622: [iter 25 : loss : 1.2624 = 0.3133 + 0.9459 + 0.0032, time: 40.502414]
2023-06-15 10:38:29.025: epoch 25:	0.08643955  	0.16271473  	0.16309012  
2023-06-15 10:38:29.025: Find a better model.
2023-06-15 10:39:12.745: [iter 26 : loss : 1.2319 = 0.2823 + 0.9459 + 0.0037, time: 43.712760]
2023-06-15 10:39:13.150: epoch 26:	0.08679950  	0.16336976  	0.16379873  
2023-06-15 10:39:13.150: Find a better model.
2023-06-15 10:39:58.870: [iter 27 : loss : 1.2065 = 0.2570 + 0.9454 + 0.0041, time: 45.714104]
2023-06-15 10:39:59.272: epoch 27:	0.08709496  	0.16405176  	0.16404034  
2023-06-15 10:39:59.272: Find a better model.
2023-06-15 10:40:39.663: [iter 28 : loss : 1.1851 = 0.2360 + 0.9446 + 0.0046, time: 40.384585]
2023-06-15 10:40:40.072: epoch 28:	0.08727753  	0.16417697  	0.16401562  
2023-06-15 10:40:40.073: Find a better model.
2023-06-15 10:41:24.343: [iter 29 : loss : 1.1667 = 0.2182 + 0.9435 + 0.0050, time: 44.263177]
2023-06-15 10:41:24.767: epoch 29:	0.08721313  	0.16409384  	0.16375808  
2023-06-15 10:42:09.972: [iter 30 : loss : 1.1502 = 0.2024 + 0.9425 + 0.0053, time: 45.197632]
2023-06-15 10:42:10.507: epoch 30:	0.08736354  	0.16398989  	0.16372474  
2023-06-15 10:42:51.843: [iter 31 : loss : 1.1357 = 0.1885 + 0.9415 + 0.0057, time: 41.328268]
2023-06-15 10:42:52.291: epoch 31:	0.08735278  	0.16397069  	0.16336052  
2023-06-15 10:43:37.497: [iter 32 : loss : 1.1236 = 0.1771 + 0.9404 + 0.0061, time: 45.198685]
2023-06-15 10:43:37.897: epoch 32:	0.08727757  	0.16394036  	0.16312939  
2023-06-15 10:44:24.028: [iter 33 : loss : 1.1124 = 0.1665 + 0.9394 + 0.0064, time: 46.117920]
2023-06-15 10:44:24.560: epoch 33:	0.08725610  	0.16349989  	0.16271056  
2023-06-15 10:45:05.684: [iter 34 : loss : 1.1033 = 0.1580 + 0.9385 + 0.0067, time: 41.115908]
2023-06-15 10:45:06.126: epoch 34:	0.08725072  	0.16321550  	0.16239569  
2023-06-15 10:45:50.191: [iter 35 : loss : 1.0938 = 0.1491 + 0.9377 + 0.0071, time: 44.057710]
2023-06-15 10:45:50.621: epoch 35:	0.08724542  	0.16284688  	0.16211700  
2023-06-15 10:46:36.330: [iter 36 : loss : 1.0862 = 0.1419 + 0.9368 + 0.0074, time: 45.700154]
2023-06-15 10:46:36.849: epoch 36:	0.08708957  	0.16225444  	0.16166480  
2023-06-15 10:47:17.936: [iter 37 : loss : 1.0787 = 0.1351 + 0.9359 + 0.0077, time: 41.079934]
2023-06-15 10:47:18.376: epoch 37:	0.08700358  	0.16190128  	0.16126931  
2023-06-15 10:48:00.742: [iter 38 : loss : 1.0724 = 0.1292 + 0.9352 + 0.0080, time: 42.349729]
2023-06-15 10:48:01.142: epoch 38:	0.08672965  	0.16132599  	0.16071047  
2023-06-15 10:48:40.081: [iter 39 : loss : 1.0668 = 0.1242 + 0.9344 + 0.0082, time: 38.931375]
2023-06-15 10:48:40.495: epoch 39:	0.08642344  	0.15991929  	0.15955272  
2023-06-15 10:49:20.220: [iter 40 : loss : 1.0616 = 0.1193 + 0.9338 + 0.0085, time: 39.716641]
2023-06-15 10:49:20.656: epoch 40:	0.08610653  	0.15859891  	0.15886439  
2023-06-15 10:50:06.540: [iter 41 : loss : 1.0561 = 0.1144 + 0.9330 + 0.0088, time: 45.877279]
2023-06-15 10:50:07.238: epoch 41:	0.08596155  	0.15802802  	0.15843648  
2023-06-15 10:50:49.604: my pid: 8748
2023-06-15 10:50:49.604: model: model.general_recommender.SGL
2023-06-15 10:50:49.604: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 10:50:49.604: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 10:50:55.816: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 10:51:36.644: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 40.827299]
2023-06-15 10:51:37.064: epoch 1:	0.00334120  	0.00819481  	0.00645556  
2023-06-15 10:51:37.065: Find a better model.
2023-06-15 10:52:22.010: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 44.935740]
2023-06-15 10:52:22.444: epoch 2:	0.00427587  	0.00917148  	0.00798218  
2023-06-15 10:52:22.444: Find a better model.
2023-06-15 10:53:06.863: [iter 3 : loss : 1.6055 = 0.6930 + 0.9124 + 0.0000, time: 44.411166]
2023-06-15 10:53:07.370: epoch 3:	0.00508161  	0.01091605  	0.00922775  
2023-06-15 10:53:07.370: Find a better model.
2023-06-15 10:53:47.006: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 39.617949]
2023-06-15 10:53:47.455: epoch 4:	0.00590348  	0.01280458  	0.01085001  
2023-06-15 10:53:47.455: Find a better model.
2023-06-15 10:54:28.639: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 41.176138]
2023-06-15 10:54:29.324: epoch 5:	0.00706376  	0.01499803  	0.01300994  
2023-06-15 10:54:29.324: Find a better model.
2023-06-15 10:55:13.110: [iter 6 : loss : 1.6054 = 0.6929 + 0.9126 + 0.0000, time: 43.778608]
2023-06-15 10:55:13.558: epoch 6:	0.00772989  	0.01530874  	0.01414680  
2023-06-15 10:55:13.558: Find a better model.
2023-06-15 10:55:56.599: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 43.034543]
2023-06-15 10:55:57.266: epoch 7:	0.00893856  	0.01802430  	0.01662358  
2023-06-15 10:55:57.267: Find a better model.
2023-06-15 10:56:36.765: [iter 8 : loss : 1.6054 = 0.6927 + 0.9127 + 0.0000, time: 39.492264]
2023-06-15 10:56:37.202: epoch 8:	0.00983030  	0.01946159  	0.01778827  
2023-06-15 10:56:37.202: Find a better model.
2023-06-15 10:57:19.546: [iter 9 : loss : 1.6055 = 0.6925 + 0.9129 + 0.0000, time: 42.336877]
2023-06-15 10:57:19.956: epoch 9:	0.01204887  	0.02348315  	0.02192292  
2023-06-15 10:57:19.956: Find a better model.
2023-06-15 10:58:04.296: [iter 10 : loss : 1.6053 = 0.6924 + 0.9129 + 0.0000, time: 44.332757]
2023-06-15 10:58:04.705: epoch 10:	0.01342408  	0.02655519  	0.02450860  
2023-06-15 10:58:04.705: Find a better model.
2023-06-15 10:58:46.161: [iter 11 : loss : 1.6051 = 0.6921 + 0.9130 + 0.0000, time: 41.448145]
2023-06-15 10:58:46.812: epoch 11:	0.01611005  	0.03242619  	0.03045235  
2023-06-15 10:58:46.812: Find a better model.
2023-06-15 10:59:27.405: [iter 12 : loss : 1.6049 = 0.6917 + 0.9132 + 0.0000, time: 40.587236]
2023-06-15 10:59:27.816: epoch 12:	0.01997245  	0.04026118  	0.03768611  
2023-06-15 10:59:27.816: Find a better model.
2023-06-15 11:00:12.980: [iter 13 : loss : 1.6046 = 0.6911 + 0.9134 + 0.0000, time: 45.158017]
2023-06-15 11:00:13.503: epoch 13:	0.02378110  	0.04762788  	0.04556966  
2023-06-15 11:00:13.503: Find a better model.
2023-06-15 11:00:58.795: [iter 14 : loss : 1.6039 = 0.6901 + 0.9137 + 0.0000, time: 45.284440]
2023-06-15 11:00:59.381: epoch 14:	0.02959318  	0.05939877  	0.05781935  
2023-06-15 11:00:59.381: Find a better model.
2023-06-15 11:01:40.543: [iter 15 : loss : 1.6025 = 0.6883 + 0.9142 + 0.0001, time: 41.137787]
2023-06-15 11:01:40.951: epoch 15:	0.03753208  	0.07516065  	0.07383364  
2023-06-15 11:01:40.951: Find a better model.
2023-06-15 11:02:23.173: [iter 16 : loss : 1.5997 = 0.6847 + 0.9149 + 0.0001, time: 42.216159]
2023-06-15 11:02:23.826: epoch 16:	0.04743719  	0.09358256  	0.09275336  
2023-06-15 11:02:23.827: Find a better model.
2023-06-15 11:03:09.093: [iter 17 : loss : 1.5932 = 0.6769 + 0.9161 + 0.0001, time: 45.256184]
2023-06-15 11:03:09.747: epoch 17:	0.05912022  	0.11450318  	0.11432274  
2023-06-15 11:03:09.747: Find a better model.
2023-06-15 11:03:53.388: [iter 18 : loss : 1.5783 = 0.6596 + 0.9185 + 0.0002, time: 43.632963]
2023-06-15 11:03:54.022: epoch 18:	0.06963202  	0.13225403  	0.13244757  
2023-06-15 11:03:54.022: Find a better model.
2023-06-15 11:04:34.774: [iter 19 : loss : 1.5485 = 0.6256 + 0.9224 + 0.0005, time: 40.744370]
2023-06-15 11:04:35.202: epoch 19:	0.07710931  	0.14448595  	0.14536564  
2023-06-15 11:04:35.202: Find a better model.
2023-06-15 11:05:19.642: [iter 20 : loss : 1.5023 = 0.5734 + 0.9281 + 0.0008, time: 44.431526]
2023-06-15 11:05:20.047: epoch 20:	0.08078861  	0.15094152  	0.15271650  
2023-06-15 11:05:20.047: Find a better model.
2023-06-15 11:06:05.427: [iter 21 : loss : 1.4463 = 0.5108 + 0.9343 + 0.0012, time: 45.374710]
2023-06-15 11:06:06.151: epoch 21:	0.08310369  	0.15544727  	0.15674029  
2023-06-15 11:06:06.151: Find a better model.
2023-06-15 11:06:46.458: [iter 22 : loss : 1.3901 = 0.4488 + 0.9396 + 0.0017, time: 40.299917]
2023-06-15 11:06:46.858: epoch 22:	0.08459707  	0.15888715  	0.15940408  
2023-06-15 11:06:46.858: Find a better model.
2023-06-15 11:07:29.510: [iter 23 : loss : 1.3405 = 0.3950 + 0.9433 + 0.0022, time: 42.645152]
2023-06-15 11:07:29.920: epoch 23:	0.08544039  	0.16024955  	0.16093321  
2023-06-15 11:07:29.920: Find a better model.
2023-06-15 11:08:15.176: [iter 24 : loss : 1.2977 = 0.3496 + 0.9453 + 0.0027, time: 45.249053]
2023-06-15 11:08:15.619: epoch 24:	0.08624074  	0.16190548  	0.16224538  
2023-06-15 11:08:15.619: Find a better model.
2023-06-15 11:08:57.809: [iter 25 : loss : 1.2624 = 0.3133 + 0.9459 + 0.0032, time: 42.182461]
2023-06-15 11:08:58.224: epoch 25:	0.08643955  	0.16271473  	0.16309012  
2023-06-15 11:08:58.224: Find a better model.
2023-06-15 11:09:37.521: [iter 26 : loss : 1.2319 = 0.2823 + 0.9459 + 0.0037, time: 39.290535]
2023-06-15 11:09:37.929: epoch 26:	0.08679950  	0.16336976  	0.16379873  
2023-06-15 11:09:37.929: Find a better model.
2023-06-15 11:10:17.424: [iter 27 : loss : 1.2065 = 0.2570 + 0.9454 + 0.0041, time: 39.488162]
2023-06-15 11:10:17.822: epoch 27:	0.08709496  	0.16405176  	0.16404034  
2023-06-15 11:10:17.822: Find a better model.
2023-06-15 11:10:57.467: [iter 28 : loss : 1.1851 = 0.2360 + 0.9446 + 0.0046, time: 39.637994]
2023-06-15 11:10:57.918: epoch 28:	0.08727753  	0.16417697  	0.16401562  
2023-06-15 11:10:57.918: Find a better model.
2023-06-15 11:11:39.997: [iter 29 : loss : 1.1667 = 0.2182 + 0.9435 + 0.0050, time: 42.070355]
2023-06-15 11:11:40.439: epoch 29:	0.08721313  	0.16409384  	0.16375808  
2023-06-15 11:12:25.111: [iter 30 : loss : 1.1502 = 0.2024 + 0.9425 + 0.0053, time: 44.642738]
2023-06-15 11:12:25.554: epoch 30:	0.08736354  	0.16398989  	0.16372474  
2023-06-15 11:13:10.673: [iter 31 : loss : 1.1357 = 0.1885 + 0.9415 + 0.0057, time: 45.112725]
2023-06-15 11:13:11.088: epoch 31:	0.08735278  	0.16397069  	0.16336052  
2023-06-15 11:13:53.555: [iter 32 : loss : 1.1236 = 0.1771 + 0.9404 + 0.0061, time: 42.458489]
2023-06-15 11:13:54.191: epoch 32:	0.08727757  	0.16394036  	0.16312939  
2023-06-15 11:14:34.503: [iter 33 : loss : 1.1124 = 0.1665 + 0.9394 + 0.0064, time: 40.305002]
2023-06-15 11:14:34.952: epoch 33:	0.08725610  	0.16349989  	0.16271056  
2023-06-15 11:15:17.317: [iter 34 : loss : 1.1033 = 0.1580 + 0.9385 + 0.0067, time: 42.358604]
2023-06-15 11:15:18.039: epoch 34:	0.08725072  	0.16321550  	0.16239569  
2023-06-15 11:16:02.903: [iter 35 : loss : 1.0938 = 0.1491 + 0.9377 + 0.0071, time: 44.856997]
2023-06-15 11:16:03.347: epoch 35:	0.08724542  	0.16284688  	0.16211700  
2023-06-15 11:16:48.757: [iter 36 : loss : 1.0862 = 0.1419 + 0.9368 + 0.0074, time: 45.402432]
2023-06-15 11:16:49.157: epoch 36:	0.08708957  	0.16225444  	0.16166480  
2023-06-15 11:17:30.530: [iter 37 : loss : 1.0787 = 0.1351 + 0.9359 + 0.0077, time: 41.363844]
2023-06-15 11:17:31.151: epoch 37:	0.08700358  	0.16190128  	0.16126931  
2023-06-15 11:18:11.880: [iter 38 : loss : 1.0724 = 0.1292 + 0.9352 + 0.0080, time: 40.720894]
2023-06-15 11:18:12.282: epoch 38:	0.08672965  	0.16132599  	0.16071047  
2023-06-15 11:18:53.846: [iter 39 : loss : 1.0668 = 0.1242 + 0.9344 + 0.0082, time: 41.557324]
2023-06-15 11:18:54.277: epoch 39:	0.08642344  	0.15991929  	0.15955272  
2023-06-15 11:19:39.373: [iter 40 : loss : 1.0616 = 0.1193 + 0.9338 + 0.0085, time: 45.090798]
2023-06-15 11:19:39.818: epoch 40:	0.08610653  	0.15859891  	0.15886439  
2023-06-15 11:20:25.640: [iter 41 : loss : 1.0561 = 0.1144 + 0.9330 + 0.0088, time: 45.815767]
2023-06-15 11:20:26.048: epoch 41:	0.08596155  	0.15802802  	0.15843648  
2023-06-15 11:21:07.843: [iter 42 : loss : 1.0516 = 0.1101 + 0.9325 + 0.0090, time: 41.787648]
2023-06-15 11:21:08.472: epoch 42:	0.08560164  	0.15705737  	0.15748322  
2023-06-15 11:21:49.708: [iter 43 : loss : 1.0472 = 0.1061 + 0.9319 + 0.0093, time: 41.229225]
2023-06-15 11:21:50.150: epoch 43:	0.08562312  	0.15653586  	0.15717658  
2023-06-15 11:22:33.130: [iter 44 : loss : 1.0435 = 0.1025 + 0.9314 + 0.0095, time: 42.972349]
2023-06-15 11:22:33.779: epoch 44:	0.08528471  	0.15588240  	0.15653864  
2023-06-15 11:23:19.860: [iter 45 : loss : 1.0405 = 0.0999 + 0.9309 + 0.0097, time: 46.073567]
2023-06-15 11:23:20.288: epoch 45:	0.08489259  	0.15500595  	0.15567063  
2023-06-15 11:24:06.095: [iter 46 : loss : 1.0368 = 0.0963 + 0.9305 + 0.0099, time: 45.798761]
2023-06-15 11:24:06.707: epoch 46:	0.08466157  	0.15446684  	0.15497616  
2023-06-15 11:24:48.976: [iter 47 : loss : 1.0333 = 0.0932 + 0.9300 + 0.0102, time: 42.247719]
2023-06-15 11:24:49.609: epoch 47:	0.08444676  	0.15383717  	0.15445648  
2023-06-15 11:25:30.711: [iter 48 : loss : 1.0305 = 0.0905 + 0.9296 + 0.0104, time: 41.094743]
2023-06-15 11:25:31.136: epoch 48:	0.08446825  	0.15335828  	0.15414964  
2023-06-15 11:26:14.742: [iter 49 : loss : 1.0280 = 0.0882 + 0.9292 + 0.0106, time: 43.597531]
2023-06-15 11:26:15.151: epoch 49:	0.08394178  	0.15221295  	0.15316020  
2023-06-15 11:27:00.429: [iter 50 : loss : 1.0255 = 0.0860 + 0.9287 + 0.0108, time: 45.271276]
2023-06-15 11:27:00.837: epoch 50:	0.08380214  	0.15176037  	0.15263125  
2023-06-15 11:27:45.766: [iter 51 : loss : 1.0230 = 0.0835 + 0.9285 + 0.0110, time: 44.921650]
2023-06-15 11:27:46.409: epoch 51:	0.08363561  	0.15113810  	0.15213193  
2023-06-15 11:28:29.549: [iter 52 : loss : 1.0210 = 0.0816 + 0.9282 + 0.0112, time: 43.131866]
2023-06-15 11:28:30.207: epoch 52:	0.08343147  	0.15057869  	0.15155211  
2023-06-15 11:29:13.787: [iter 53 : loss : 1.0185 = 0.0793 + 0.9278 + 0.0114, time: 43.573862]
2023-06-15 11:29:14.623: epoch 53:	0.08320589  	0.14958730  	0.15088521  
2023-06-15 11:29:14.623: Early stopping is trigger at epoch: 53
2023-06-15 11:29:14.623: best_result@epoch 28:

2023-06-15 11:29:14.623: 		0.0873      	0.1642      	0.1640      
2023-06-15 11:29:52.135: my pid: 12460
2023-06-15 11:29:52.135: model: model.general_recommender.SGL
2023-06-15 11:29:52.135: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 11:29:52.135: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 11:29:57.133: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 11:30:41.168: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 44.033827]
2023-06-15 11:30:41.656: epoch 1:	0.00352921  	0.00806983  	0.00675302  
2023-06-15 11:30:41.656: Find a better model.
2023-06-15 11:31:22.142: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 40.471030]
2023-06-15 11:31:22.805: epoch 2:	0.00429735  	0.00953553  	0.00799393  
2023-06-15 11:31:22.805: Find a better model.
2023-06-15 11:32:02.096: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 39.285015]
2023-06-15 11:32:02.615: epoch 3:	0.00549523  	0.01117663  	0.00978408  
2023-06-15 11:32:02.615: Find a better model.
2023-06-15 11:32:45.155: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 42.533989]
2023-06-15 11:32:45.594: epoch 4:	0.00626875  	0.01274596  	0.01106683  
2023-06-15 11:32:45.594: Find a better model.
2023-06-15 11:33:29.204: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 43.602809]
2023-06-15 11:33:29.635: epoch 5:	0.00735385  	0.01428721  	0.01302923  
2023-06-15 11:33:29.635: Find a better model.
2023-06-15 11:34:09.681: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 40.039469]
2023-06-15 11:34:10.320: epoch 6:	0.00829932  	0.01630731  	0.01472900  
2023-06-15 11:34:10.321: Find a better model.
2023-06-15 11:34:49.680: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.348711]
2023-06-15 11:34:50.113: epoch 7:	0.00909436  	0.01779987  	0.01627699  
2023-06-15 11:34:50.113: Find a better model.
2023-06-15 11:35:32.042: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 41.922037]
2023-06-15 11:35:32.484: epoch 8:	0.01006667  	0.01980377  	0.01807538  
2023-06-15 11:35:32.485: Find a better model.
2023-06-15 11:36:16.268: [iter 9 : loss : 1.6054 = 0.6926 + 0.9128 + 0.0000, time: 43.777262]
2023-06-15 11:36:16.880: epoch 9:	0.01196830  	0.02373352  	0.02193638  
2023-06-15 11:36:16.880: Find a better model.
2023-06-15 11:37:01.500: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 44.613254]
2023-06-15 11:37:02.170: epoch 10:	0.01365507  	0.02830753  	0.02569942  
2023-06-15 11:37:02.170: Find a better model.
2023-06-15 11:37:43.636: [iter 11 : loss : 1.6050 = 0.6921 + 0.9128 + 0.0000, time: 41.458764]
2023-06-15 11:37:44.044: epoch 11:	0.01614768  	0.03268122  	0.03004397  
2023-06-15 11:37:44.045: Find a better model.
2023-06-15 11:38:26.192: [iter 12 : loss : 1.6049 = 0.6918 + 0.9131 + 0.0000, time: 42.140137]
2023-06-15 11:38:26.607: epoch 12:	0.01889270  	0.03793244  	0.03600673  
2023-06-15 11:38:26.607: Find a better model.
2023-06-15 11:39:11.504: [iter 13 : loss : 1.6046 = 0.6912 + 0.9133 + 0.0000, time: 44.890493]
2023-06-15 11:39:11.976: epoch 13:	0.02258856  	0.04682239  	0.04406631  
2023-06-15 11:39:11.976: Find a better model.
2023-06-15 11:39:57.315: [iter 14 : loss : 1.6040 = 0.6903 + 0.9136 + 0.0000, time: 45.331280]
2023-06-15 11:39:57.811: epoch 14:	0.02819666  	0.05789413  	0.05504684  
2023-06-15 11:39:57.811: Find a better model.
2023-06-15 11:40:39.018: [iter 15 : loss : 1.6027 = 0.6887 + 0.9140 + 0.0000, time: 41.186915]
2023-06-15 11:40:39.669: epoch 15:	0.03571115  	0.07208972  	0.07041907  
2023-06-15 11:40:39.669: Find a better model.
2023-06-15 11:41:20.738: [iter 16 : loss : 1.6003 = 0.6855 + 0.9147 + 0.0001, time: 41.062492]
2023-06-15 11:41:21.177: epoch 16:	0.04518102  	0.09119417  	0.08907130  
2023-06-15 11:41:21.177: Find a better model.
2023-06-15 11:42:05.254: [iter 17 : loss : 1.5946 = 0.6787 + 0.9157 + 0.0001, time: 44.069788]
2023-06-15 11:42:05.664: epoch 17:	0.05703600  	0.11178096  	0.11107963  
2023-06-15 11:42:05.664: Find a better model.
2023-06-15 11:42:50.888: [iter 18 : loss : 1.5816 = 0.6635 + 0.9178 + 0.0002, time: 45.216655]
2023-06-15 11:42:51.294: epoch 18:	0.06838596  	0.13048004  	0.13140360  
2023-06-15 11:42:51.294: Find a better model.
2023-06-15 11:43:35.185: [iter 19 : loss : 1.5546 = 0.6328 + 0.9214 + 0.0004, time: 43.878393]
2023-06-15 11:43:35.844: epoch 19:	0.07611021  	0.14328913  	0.14480573  
2023-06-15 11:43:35.844: Find a better model.
2023-06-15 11:44:16.858: [iter 20 : loss : 1.5109 = 0.5833 + 0.9268 + 0.0007, time: 41.007133]
2023-06-15 11:44:17.258: epoch 20:	0.08071353  	0.15175112  	0.15255405  
2023-06-15 11:44:17.258: Find a better model.
2023-06-15 11:44:59.649: [iter 21 : loss : 1.4557 = 0.5215 + 0.9331 + 0.0011, time: 42.383607]
2023-06-15 11:45:00.141: epoch 21:	0.08329728  	0.15656105  	0.15734038  
2023-06-15 11:45:00.141: Find a better model.
2023-06-15 11:45:45.263: [iter 22 : loss : 1.3990 = 0.4587 + 0.9387 + 0.0016, time: 45.114184]
2023-06-15 11:45:45.675: epoch 22:	0.08479054  	0.15987252  	0.15985550  
2023-06-15 11:45:45.675: Find a better model.
2023-06-15 11:46:31.408: [iter 23 : loss : 1.3481 = 0.4034 + 0.9426 + 0.0021, time: 45.725923]
2023-06-15 11:46:31.851: epoch 23:	0.08588096  	0.16241461  	0.16178614  
2023-06-15 11:46:31.851: Find a better model.
2023-06-15 11:47:14.034: [iter 24 : loss : 1.3041 = 0.3566 + 0.9448 + 0.0027, time: 42.174918]
2023-06-15 11:47:14.694: epoch 24:	0.08686399  	0.16408280  	0.16308530  
2023-06-15 11:47:14.694: Find a better model.
2023-06-15 11:47:55.834: [iter 25 : loss : 1.2679 = 0.3190 + 0.9457 + 0.0031, time: 41.132763]
2023-06-15 11:47:56.236: epoch 25:	0.08728843  	0.16525313  	0.16388460  
2023-06-15 11:47:56.236: Find a better model.
2023-06-15 11:48:38.568: [iter 26 : loss : 1.2364 = 0.2872 + 0.9457 + 0.0036, time: 42.325660]
2023-06-15 11:48:39.070: epoch 26:	0.08742271  	0.16595313  	0.16443241  
2023-06-15 11:48:39.070: Find a better model.
2023-06-15 11:49:24.199: [iter 27 : loss : 1.2102 = 0.2609 + 0.9452 + 0.0041, time: 45.122659]
2023-06-15 11:49:24.601: epoch 27:	0.08782557  	0.16639301  	0.16479219  
2023-06-15 11:49:24.601: Find a better model.
2023-06-15 11:50:10.217: [iter 28 : loss : 1.1883 = 0.2392 + 0.9446 + 0.0045, time: 45.610191]
2023-06-15 11:50:10.619: epoch 28:	0.08768589  	0.16618511  	0.16453038  
2023-06-15 11:50:53.603: [iter 29 : loss : 1.1695 = 0.2211 + 0.9435 + 0.0049, time: 42.976001]
2023-06-15 11:50:54.237: epoch 29:	0.08775029  	0.16579647  	0.16441560  
2023-06-15 11:51:33.578: [iter 30 : loss : 1.1528 = 0.2050 + 0.9425 + 0.0053, time: 39.334728]
2023-06-15 11:51:33.981: epoch 30:	0.08762679  	0.16565502  	0.16417322  
2023-06-15 11:52:13.124: [iter 31 : loss : 1.1378 = 0.1907 + 0.9415 + 0.0057, time: 39.136139]
2023-06-15 11:52:13.517: epoch 31:	0.08763220  	0.16535027  	0.16401730  
2023-06-15 11:52:52.562: [iter 32 : loss : 1.1256 = 0.1792 + 0.9404 + 0.0060, time: 39.038291]
2023-06-15 11:52:52.980: epoch 32:	0.08740668  	0.16455069  	0.16331156  
2023-06-15 11:53:32.424: [iter 33 : loss : 1.1139 = 0.1682 + 0.9394 + 0.0064, time: 39.437759]
2023-06-15 11:53:32.829: epoch 33:	0.08728850  	0.16370167  	0.16287169  
2023-06-15 11:54:11.902: [iter 34 : loss : 1.1045 = 0.1593 + 0.9384 + 0.0067, time: 39.067816]
2023-06-15 11:54:12.310: epoch 34:	0.08701992  	0.16296986  	0.16205274  
2023-06-15 11:54:51.666: [iter 35 : loss : 1.0951 = 0.1505 + 0.9376 + 0.0070, time: 39.350708]
2023-06-15 11:54:52.094: epoch 35:	0.08695544  	0.16238216  	0.16156474  
2023-06-15 11:55:31.517: [iter 36 : loss : 1.0873 = 0.1433 + 0.9367 + 0.0073, time: 39.415256]
2023-06-15 11:55:31.920: epoch 36:	0.08690169  	0.16210918  	0.16128640  
2023-06-15 11:56:11.241: [iter 37 : loss : 1.0796 = 0.1362 + 0.9359 + 0.0076, time: 39.314012]
2023-06-15 11:56:11.639: epoch 37:	0.08670834  	0.16159247  	0.16090882  
2023-06-15 11:56:50.795: [iter 38 : loss : 1.0732 = 0.1303 + 0.9350 + 0.0079, time: 39.149188]
2023-06-15 11:56:51.214: epoch 38:	0.08637527  	0.16044027  	0.16014598  
2023-06-15 11:57:30.624: [iter 39 : loss : 1.0673 = 0.1248 + 0.9343 + 0.0082, time: 39.402877]
2023-06-15 11:57:31.026: epoch 39:	0.08617117  	0.15970793  	0.15940565  
2023-06-15 11:58:10.439: [iter 40 : loss : 1.0622 = 0.1200 + 0.9337 + 0.0085, time: 39.405347]
2023-06-15 11:58:10.846: epoch 40:	0.08589726  	0.15899660  	0.15871854  
2023-06-15 11:58:50.228: [iter 41 : loss : 1.0567 = 0.1150 + 0.9330 + 0.0087, time: 39.376147]
2023-06-15 11:58:50.633: epoch 41:	0.08571463  	0.15864345  	0.15815169  
2023-06-15 11:59:29.765: [iter 42 : loss : 1.0523 = 0.1109 + 0.9324 + 0.0090, time: 39.125599]
2023-06-15 11:59:30.167: epoch 42:	0.08545146  	0.15780847  	0.15752201  
2023-06-15 12:00:09.569: [iter 43 : loss : 1.0477 = 0.1066 + 0.9319 + 0.0092, time: 39.394453]
2023-06-15 12:00:09.968: epoch 43:	0.08523122  	0.15709555  	0.15685412  
2023-06-15 12:00:49.437: [iter 44 : loss : 1.0438 = 0.1029 + 0.9314 + 0.0095, time: 39.462330]
2023-06-15 12:00:49.836: epoch 44:	0.08498410  	0.15646248  	0.15615427  
2023-06-15 12:01:29.529: [iter 45 : loss : 1.0408 = 0.1002 + 0.9309 + 0.0097, time: 39.686507]
2023-06-15 12:01:29.931: epoch 45:	0.08476929  	0.15553819  	0.15549058  
2023-06-15 12:02:09.292: [iter 46 : loss : 1.0370 = 0.0967 + 0.9304 + 0.0099, time: 39.353977]
2023-06-15 12:02:09.696: epoch 46:	0.08442551  	0.15496556  	0.15480457  
2023-06-15 12:02:48.920: [iter 47 : loss : 1.0340 = 0.0939 + 0.9299 + 0.0101, time: 39.218085]
2023-06-15 12:02:49.322: epoch 47:	0.08430195  	0.15445666  	0.15447412  
2023-06-15 12:03:29.093: [iter 48 : loss : 1.0307 = 0.0909 + 0.9294 + 0.0104, time: 39.764961]
2023-06-15 12:03:29.500: epoch 48:	0.08415694  	0.15365514  	0.15382865  
2023-06-15 12:04:08.919: [iter 49 : loss : 1.0283 = 0.0887 + 0.9291 + 0.0106, time: 39.412078]
2023-06-15 12:04:09.321: epoch 49:	0.08392594  	0.15279585  	0.15320832  
2023-06-15 12:04:49.009: [iter 50 : loss : 1.0257 = 0.0862 + 0.9287 + 0.0108, time: 39.680096]
2023-06-15 12:04:49.408: epoch 50:	0.08352299  	0.15187083  	0.15244472  
2023-06-15 12:05:28.830: [iter 51 : loss : 1.0234 = 0.0840 + 0.9284 + 0.0110, time: 39.416449]
2023-06-15 12:05:29.233: epoch 51:	0.08345850  	0.15141098  	0.15193221  
2023-06-15 12:06:08.787: [iter 52 : loss : 1.0208 = 0.0816 + 0.9281 + 0.0111, time: 39.546691]
2023-06-15 12:06:09.195: epoch 52:	0.08316845  	0.15074278  	0.15139218  
2023-06-15 12:06:09.196: Early stopping is trigger at epoch: 52
2023-06-15 12:06:09.196: best_result@epoch 27:

2023-06-15 12:06:09.196: 		0.0878      	0.1664      	0.1648      
2023-06-15 14:33:10.005: my pid: 13760
2023-06-15 14:33:10.005: model: model.general_recommender.SGL
2023-06-15 14:33:10.005: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 14:33:10.005: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 14:33:14.991: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 14:33:54.084: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 39.092704]
2023-06-15 14:33:54.544: epoch 1:	0.00352921  	0.00806983  	0.00675302  
2023-06-15 14:33:54.544: Find a better model.
2023-06-15 14:34:37.927: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 43.376252]
2023-06-15 14:34:38.344: epoch 2:	0.00429735  	0.00953553  	0.00799393  
2023-06-15 14:34:38.345: Find a better model.
2023-06-15 14:35:17.956: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 39.599183]
2023-06-15 14:35:18.592: epoch 3:	0.00549523  	0.01117663  	0.00978408  
2023-06-15 14:35:18.592: Find a better model.
2023-06-15 14:35:57.712: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 39.112669]
2023-06-15 14:35:58.121: epoch 4:	0.00626875  	0.01274596  	0.01106683  
2023-06-15 14:35:58.122: Find a better model.
2023-06-15 14:36:40.798: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 42.670711]
2023-06-15 14:36:41.225: epoch 5:	0.00735385  	0.01428721  	0.01302923  
2023-06-15 14:36:41.225: Find a better model.
2023-06-15 14:37:25.216: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 43.984340]
2023-06-15 14:37:25.647: epoch 6:	0.00829932  	0.01630731  	0.01472900  
2023-06-15 14:37:25.647: Find a better model.
2023-06-15 14:38:05.152: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.496683]
2023-06-15 14:38:05.784: epoch 7:	0.00909436  	0.01779987  	0.01627699  
2023-06-15 14:38:05.784: Find a better model.
2023-06-15 14:38:45.109: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 39.318880]
2023-06-15 14:38:45.537: epoch 8:	0.01006667  	0.01980377  	0.01807538  
2023-06-15 14:38:45.537: Find a better model.
2023-06-15 14:39:28.191: [iter 9 : loss : 1.6054 = 0.6926 + 0.9128 + 0.0000, time: 42.647251]
2023-06-15 14:39:28.635: epoch 9:	0.01196830  	0.02373352  	0.02193638  
2023-06-15 14:39:28.635: Find a better model.
2023-06-15 14:40:12.515: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 43.873135]
2023-06-15 14:40:12.924: epoch 10:	0.01365507  	0.02830753  	0.02569942  
2023-06-15 14:40:12.924: Find a better model.
2023-06-15 14:40:53.939: [iter 11 : loss : 1.6050 = 0.6921 + 0.9128 + 0.0000, time: 41.006869]
2023-06-15 14:40:54.592: epoch 11:	0.01614768  	0.03268122  	0.03004397  
2023-06-15 14:40:54.592: Find a better model.
2023-06-15 14:41:34.697: [iter 12 : loss : 1.6049 = 0.6918 + 0.9131 + 0.0000, time: 40.097691]
2023-06-15 14:41:35.107: epoch 12:	0.01889270  	0.03793244  	0.03600673  
2023-06-15 14:41:35.107: Find a better model.
2023-06-15 14:42:16.724: [iter 13 : loss : 1.6046 = 0.6912 + 0.9133 + 0.0000, time: 41.610280]
2023-06-15 14:42:17.163: epoch 13:	0.02258856  	0.04682239  	0.04406631  
2023-06-15 14:42:17.163: Find a better model.
2023-06-15 14:43:01.727: [iter 14 : loss : 1.6040 = 0.6903 + 0.9136 + 0.0000, time: 44.557826]
2023-06-15 14:43:02.181: epoch 14:	0.02819666  	0.05789413  	0.05504684  
2023-06-15 14:43:02.181: Find a better model.
2023-06-15 14:43:47.629: [iter 15 : loss : 1.6027 = 0.6887 + 0.9140 + 0.0000, time: 45.441366]
2023-06-15 14:43:48.044: epoch 15:	0.03571115  	0.07208972  	0.07041907  
2023-06-15 14:43:48.044: Find a better model.
2023-06-15 14:44:29.298: [iter 16 : loss : 1.6003 = 0.6855 + 0.9147 + 0.0001, time: 41.246312]
2023-06-15 14:44:29.927: epoch 16:	0.04518102  	0.09119417  	0.08907130  
2023-06-15 14:44:29.927: Find a better model.
2023-06-15 14:45:10.766: [iter 17 : loss : 1.5946 = 0.6787 + 0.9157 + 0.0001, time: 40.831499]
2023-06-15 14:45:11.212: epoch 17:	0.05703600  	0.11178096  	0.11107963  
2023-06-15 14:45:11.212: Find a better model.
2023-06-15 14:45:53.208: [iter 18 : loss : 1.5816 = 0.6635 + 0.9178 + 0.0002, time: 41.989773]
2023-06-15 14:45:54.055: epoch 18:	0.06838596  	0.13048004  	0.13140360  
2023-06-15 14:45:54.055: Find a better model.
2023-06-15 14:46:38.585: [iter 19 : loss : 1.5546 = 0.6328 + 0.9214 + 0.0004, time: 44.523212]
2023-06-15 14:46:38.998: epoch 19:	0.07611021  	0.14328913  	0.14480573  
2023-06-15 14:46:38.998: Find a better model.
2023-06-15 14:47:25.032: [iter 20 : loss : 1.5109 = 0.5833 + 0.9268 + 0.0007, time: 46.019344]
2023-06-15 14:47:25.536: epoch 20:	0.08071353  	0.15175112  	0.15255405  
2023-06-15 14:47:25.537: Find a better model.
2023-06-15 14:48:06.728: [iter 21 : loss : 1.4557 = 0.5215 + 0.9331 + 0.0011, time: 41.172722]
2023-06-15 14:48:07.354: epoch 21:	0.08329728  	0.15656105  	0.15734038  
2023-06-15 14:48:07.354: Find a better model.
2023-06-15 14:48:48.561: [iter 22 : loss : 1.3990 = 0.4587 + 0.9387 + 0.0016, time: 41.199287]
2023-06-15 14:48:48.993: epoch 22:	0.08479054  	0.15987252  	0.15985550  
2023-06-15 14:48:48.993: Find a better model.
2023-06-15 14:49:32.745: [iter 23 : loss : 1.3481 = 0.4034 + 0.9426 + 0.0021, time: 43.746251]
2023-06-15 14:49:33.147: epoch 23:	0.08588096  	0.16241461  	0.16178614  
2023-06-15 14:49:33.147: Find a better model.
2023-06-15 14:50:18.524: [iter 24 : loss : 1.3041 = 0.3566 + 0.9448 + 0.0027, time: 45.369891]
2023-06-15 14:50:19.033: epoch 24:	0.08686399  	0.16408280  	0.16308530  
2023-06-15 14:50:19.033: Find a better model.
2023-06-15 14:51:04.069: [iter 25 : loss : 1.2679 = 0.3190 + 0.9457 + 0.0031, time: 45.027511]
2023-06-15 14:51:04.804: epoch 25:	0.08728843  	0.16525313  	0.16388460  
2023-06-15 14:51:04.804: Find a better model.
2023-06-15 14:51:48.102: [iter 26 : loss : 1.2364 = 0.2872 + 0.9457 + 0.0036, time: 43.290506]
2023-06-15 14:51:48.717: epoch 26:	0.08742271  	0.16595313  	0.16443241  
2023-06-15 14:51:48.717: Find a better model.
2023-06-15 14:52:30.471: [iter 27 : loss : 1.2102 = 0.2609 + 0.9452 + 0.0041, time: 41.746765]
2023-06-15 14:52:30.888: epoch 27:	0.08782557  	0.16639301  	0.16479219  
2023-06-15 14:52:30.889: Find a better model.
2023-06-15 14:53:11.739: [iter 28 : loss : 1.1883 = 0.2392 + 0.9446 + 0.0045, time: 40.844496]
2023-06-15 14:53:12.148: epoch 28:	0.08768589  	0.16618511  	0.16453038  
2023-06-15 14:53:56.582: [iter 29 : loss : 1.1695 = 0.2211 + 0.9435 + 0.0049, time: 44.427083]
2023-06-15 14:53:56.985: epoch 29:	0.08775029  	0.16579647  	0.16441560  
2023-06-15 14:54:42.042: [iter 30 : loss : 1.1528 = 0.2050 + 0.9425 + 0.0053, time: 45.050145]
2023-06-15 14:54:42.470: epoch 30:	0.08762679  	0.16565502  	0.16417322  
2023-06-15 14:55:24.353: [iter 31 : loss : 1.1378 = 0.1907 + 0.9415 + 0.0057, time: 41.874676]
2023-06-15 14:55:24.984: epoch 31:	0.08763220  	0.16535027  	0.16401730  
2023-06-15 14:56:05.796: [iter 32 : loss : 1.1256 = 0.1792 + 0.9404 + 0.0060, time: 40.804094]
2023-06-15 14:56:06.199: epoch 32:	0.08740668  	0.16455069  	0.16331156  
2023-06-15 14:56:48.004: [iter 33 : loss : 1.1139 = 0.1682 + 0.9394 + 0.0064, time: 41.798249]
2023-06-15 14:56:48.455: epoch 33:	0.08728850  	0.16370167  	0.16287169  
2023-06-15 14:57:33.167: [iter 34 : loss : 1.1045 = 0.1593 + 0.9384 + 0.0067, time: 44.704103]
2023-06-15 14:57:33.584: epoch 34:	0.08701992  	0.16296986  	0.16205274  
2023-06-15 14:58:18.741: [iter 35 : loss : 1.0951 = 0.1505 + 0.9376 + 0.0070, time: 45.150850]
2023-06-15 14:58:19.143: epoch 35:	0.08695544  	0.16238216  	0.16156474  
2023-06-15 14:59:02.975: [iter 36 : loss : 1.0873 = 0.1433 + 0.9367 + 0.0073, time: 43.823549]
2023-06-15 14:59:03.641: epoch 36:	0.08690169  	0.16210918  	0.16128640  
2023-06-15 14:59:44.890: [iter 37 : loss : 1.0796 = 0.1362 + 0.9359 + 0.0076, time: 41.242072]
2023-06-15 14:59:45.555: epoch 37:	0.08670834  	0.16159247  	0.16090882  
2023-06-15 15:00:26.513: [iter 38 : loss : 1.0732 = 0.1303 + 0.9350 + 0.0079, time: 40.949099]
2023-06-15 15:00:26.943: epoch 38:	0.08637527  	0.16044027  	0.16014598  
2023-06-15 15:01:10.033: [iter 39 : loss : 1.0673 = 0.1248 + 0.9343 + 0.0082, time: 43.082545]
2023-06-15 15:01:10.681: epoch 39:	0.08617117  	0.15970793  	0.15940565  
2023-06-15 15:01:56.733: [iter 40 : loss : 1.0622 = 0.1200 + 0.9337 + 0.0085, time: 46.044888]
2023-06-15 15:01:57.163: epoch 40:	0.08589726  	0.15899660  	0.15871854  
2023-06-15 15:02:43.166: [iter 41 : loss : 1.0567 = 0.1150 + 0.9330 + 0.0087, time: 45.995888]
2023-06-15 15:02:43.977: epoch 41:	0.08571463  	0.15864345  	0.15815169  
2023-06-15 15:03:26.109: [iter 42 : loss : 1.0523 = 0.1109 + 0.9324 + 0.0090, time: 42.123515]
2023-06-15 15:03:26.728: epoch 42:	0.08545146  	0.15780847  	0.15752201  
2023-06-15 15:04:07.792: [iter 43 : loss : 1.0477 = 0.1066 + 0.9319 + 0.0092, time: 41.057050]
2023-06-15 15:04:08.242: epoch 43:	0.08523122  	0.15709555  	0.15685412  
2023-06-15 15:04:50.911: [iter 44 : loss : 1.0438 = 0.1029 + 0.9314 + 0.0095, time: 42.660314]
2023-06-15 15:04:51.627: epoch 44:	0.08498410  	0.15646248  	0.15615427  
2023-06-15 15:05:36.989: [iter 45 : loss : 1.0408 = 0.1002 + 0.9309 + 0.0097, time: 45.355435]
2023-06-15 15:05:37.466: epoch 45:	0.08476929  	0.15553819  	0.15549058  
2023-06-15 15:06:23.519: [iter 46 : loss : 1.0370 = 0.0967 + 0.9304 + 0.0099, time: 46.044621]
2023-06-15 15:06:23.982: epoch 46:	0.08442551  	0.15496556  	0.15480457  
2023-06-15 15:07:05.769: [iter 47 : loss : 1.0340 = 0.0939 + 0.9299 + 0.0101, time: 41.778552]
2023-06-15 15:07:06.440: epoch 47:	0.08430195  	0.15445666  	0.15447412  
2023-06-15 15:07:47.722: [iter 48 : loss : 1.0307 = 0.0909 + 0.9294 + 0.0104, time: 41.273705]
2023-06-15 15:07:48.162: epoch 48:	0.08415694  	0.15365514  	0.15382865  
2023-06-15 15:08:31.014: [iter 49 : loss : 1.0283 = 0.0887 + 0.9291 + 0.0106, time: 42.845802]
2023-06-15 15:08:31.786: epoch 49:	0.08392594  	0.15279585  	0.15320832  
2023-06-15 15:09:18.312: [iter 50 : loss : 1.0257 = 0.0862 + 0.9287 + 0.0108, time: 46.518819]
2023-06-15 15:09:18.798: epoch 50:	0.08352299  	0.15187083  	0.15244472  
2023-06-15 15:10:04.451: [iter 51 : loss : 1.0234 = 0.0840 + 0.9284 + 0.0110, time: 45.644946]
2023-06-15 15:10:05.160: epoch 51:	0.08345850  	0.15141098  	0.15193221  
2023-06-15 15:10:34.671: my pid: 8176
2023-06-15 15:10:34.671: model: model.general_recommender.SGL
2023-06-15 15:10:34.671: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 15:10:34.671: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 15:10:40.237: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 15:11:25.583: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 45.344410]
2023-06-15 15:11:25.998: epoch 1:	0.00352921  	0.00806983  	0.00675302  
2023-06-15 15:11:25.998: Find a better model.
2023-06-15 15:12:05.112: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 39.106241]
2023-06-15 15:12:05.555: epoch 2:	0.00429735  	0.00953553  	0.00799393  
2023-06-15 15:12:05.555: Find a better model.
2023-06-15 15:12:46.077: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.516767]
2023-06-15 15:12:46.562: epoch 3:	0.00549523  	0.01117663  	0.00978408  
2023-06-15 15:12:46.562: Find a better model.
2023-06-15 15:13:30.194: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 43.624841]
2023-06-15 15:13:30.678: epoch 4:	0.00626875  	0.01274596  	0.01106683  
2023-06-15 15:13:30.678: Find a better model.
2023-06-15 15:14:14.533: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 43.847013]
2023-06-15 15:14:15.126: epoch 5:	0.00735385  	0.01428721  	0.01302923  
2023-06-15 15:14:15.127: Find a better model.
2023-06-15 15:14:54.705: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 39.569441]
2023-06-15 15:14:55.126: epoch 6:	0.00829932  	0.01630731  	0.01472900  
2023-06-15 15:14:55.126: Find a better model.
2023-06-15 15:15:35.369: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 40.236207]
2023-06-15 15:15:35.820: epoch 7:	0.00909436  	0.01779987  	0.01627699  
2023-06-15 15:15:35.820: Find a better model.
2023-06-15 15:16:19.901: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 44.073253]
2023-06-15 15:16:20.339: epoch 8:	0.01006667  	0.01980377  	0.01807538  
2023-06-15 15:16:20.339: Find a better model.
2023-06-15 15:17:04.458: [iter 9 : loss : 1.6054 = 0.6926 + 0.9128 + 0.0000, time: 44.110558]
2023-06-15 15:17:04.874: epoch 9:	0.01196830  	0.02373352  	0.02193638  
2023-06-15 15:17:04.874: Find a better model.
2023-06-15 15:17:44.110: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 39.227686]
2023-06-15 15:17:44.745: epoch 10:	0.01365507  	0.02830753  	0.02569942  
2023-06-15 15:17:44.745: Find a better model.
2023-06-15 15:18:25.930: [iter 11 : loss : 1.6050 = 0.6921 + 0.9128 + 0.0000, time: 41.178044]
2023-06-15 15:18:26.413: epoch 11:	0.01614768  	0.03268122  	0.03004397  
2023-06-15 15:18:26.414: Find a better model.
2023-06-15 15:19:10.334: [iter 12 : loss : 1.6049 = 0.6918 + 0.9131 + 0.0000, time: 43.903508]
2023-06-15 15:19:10.757: epoch 12:	0.01889270  	0.03793244  	0.03600673  
2023-06-15 15:19:10.757: Find a better model.
2023-06-15 15:19:55.684: [iter 13 : loss : 1.6046 = 0.6912 + 0.9133 + 0.0000, time: 44.920262]
2023-06-15 15:19:56.086: epoch 13:	0.02258856  	0.04682239  	0.04406631  
2023-06-15 15:19:56.086: Find a better model.
2023-06-15 15:20:37.559: [iter 14 : loss : 1.6040 = 0.6903 + 0.9136 + 0.0000, time: 41.466781]
2023-06-15 15:20:38.202: epoch 14:	0.02819666  	0.05789413  	0.05504684  
2023-06-15 15:20:38.202: Find a better model.
2023-06-15 15:21:18.968: [iter 15 : loss : 1.6027 = 0.6887 + 0.9140 + 0.0000, time: 40.759171]
2023-06-15 15:21:19.439: epoch 15:	0.03571115  	0.07208972  	0.07041907  
2023-06-15 15:21:19.440: Find a better model.
2023-06-15 15:22:02.224: [iter 16 : loss : 1.6003 = 0.6855 + 0.9147 + 0.0001, time: 42.766238]
2023-06-15 15:22:02.644: epoch 16:	0.04518102  	0.09119417  	0.08907130  
2023-06-15 15:22:02.645: Find a better model.
2023-06-15 15:22:47.800: [iter 17 : loss : 1.5946 = 0.6787 + 0.9157 + 0.0001, time: 45.148057]
2023-06-15 15:22:48.531: epoch 17:	0.05703600  	0.11178096  	0.11107963  
2023-06-15 15:22:48.531: Find a better model.
2023-06-15 15:23:32.500: [iter 18 : loss : 1.5816 = 0.6635 + 0.9178 + 0.0002, time: 43.951814]
2023-06-15 15:23:33.140: epoch 18:	0.06838596  	0.13048004  	0.13140360  
2023-06-15 15:23:33.140: Find a better model.
2023-06-15 15:24:14.200: [iter 19 : loss : 1.5546 = 0.6328 + 0.9214 + 0.0004, time: 41.053523]
2023-06-15 15:24:14.674: epoch 19:	0.07611021  	0.14328913  	0.14480573  
2023-06-15 15:24:14.674: Find a better model.
2023-06-15 15:24:57.094: [iter 20 : loss : 1.5109 = 0.5833 + 0.9268 + 0.0007, time: 42.413076]
2023-06-15 15:24:57.530: epoch 20:	0.08071353  	0.15175112  	0.15255405  
2023-06-15 15:24:57.530: Find a better model.
2023-06-15 15:25:43.177: [iter 21 : loss : 1.4557 = 0.5215 + 0.9331 + 0.0011, time: 45.640408]
2023-06-15 15:25:43.641: epoch 21:	0.08329728  	0.15656105  	0.15734038  
2023-06-15 15:25:43.641: Find a better model.
2023-06-15 15:26:27.440: [iter 22 : loss : 1.3990 = 0.4587 + 0.9387 + 0.0016, time: 43.790322]
2023-06-15 15:26:28.075: epoch 22:	0.08479054  	0.15987252  	0.15985550  
2023-06-15 15:26:28.075: Find a better model.
2023-06-15 15:27:09.116: [iter 23 : loss : 1.3481 = 0.4034 + 0.9426 + 0.0021, time: 41.033834]
2023-06-15 15:27:09.540: epoch 23:	0.08588096  	0.16241461  	0.16178614  
2023-06-15 15:27:09.540: Find a better model.
2023-06-15 15:27:51.919: [iter 24 : loss : 1.3041 = 0.3566 + 0.9448 + 0.0027, time: 42.372068]
2023-06-15 15:27:52.821: epoch 24:	0.08686399  	0.16408280  	0.16308530  
2023-06-15 15:27:52.821: Find a better model.
2023-06-15 15:28:37.998: [iter 25 : loss : 1.2679 = 0.3190 + 0.9457 + 0.0031, time: 45.168982]
2023-06-15 15:28:38.480: epoch 25:	0.08728843  	0.16525313  	0.16388460  
2023-06-15 15:28:38.481: Find a better model.
2023-06-15 15:29:24.243: [iter 26 : loss : 1.2364 = 0.2872 + 0.9457 + 0.0036, time: 45.754167]
2023-06-15 15:29:24.786: epoch 26:	0.08742271  	0.16595313  	0.16443241  
2023-06-15 15:29:24.787: Find a better model.
2023-06-15 15:30:06.773: [iter 27 : loss : 1.2102 = 0.2609 + 0.9452 + 0.0041, time: 41.978430]
2023-06-15 15:30:07.411: epoch 27:	0.08782557  	0.16639301  	0.16479219  
2023-06-15 15:30:07.412: Find a better model.
2023-06-15 15:30:48.581: [iter 28 : loss : 1.1883 = 0.2392 + 0.9446 + 0.0045, time: 41.153255]
2023-06-15 15:30:49.087: epoch 28:	0.08768589  	0.16618511  	0.16453038  
2023-06-15 15:31:33.128: [iter 29 : loss : 1.1695 = 0.2211 + 0.9435 + 0.0049, time: 44.034467]
2023-06-15 15:31:33.556: epoch 29:	0.08775029  	0.16579647  	0.16441560  
2023-06-15 15:32:19.095: [iter 30 : loss : 1.1528 = 0.2050 + 0.9425 + 0.0053, time: 45.533120]
2023-06-15 15:32:19.524: epoch 30:	0.08762679  	0.16565502  	0.16417322  
2023-06-15 15:33:04.779: [iter 31 : loss : 1.1378 = 0.1907 + 0.9415 + 0.0057, time: 45.246954]
2023-06-15 15:33:05.385: epoch 31:	0.08763220  	0.16535027  	0.16401730  
2023-06-15 15:33:46.159: [iter 32 : loss : 1.1256 = 0.1792 + 0.9404 + 0.0060, time: 40.767505]
2023-06-15 15:33:46.573: epoch 32:	0.08740668  	0.16455069  	0.16331156  
2023-06-15 15:34:25.427: [iter 33 : loss : 1.1139 = 0.1682 + 0.9394 + 0.0064, time: 38.846237]
2023-06-15 15:34:25.829: epoch 33:	0.08728850  	0.16370167  	0.16287169  
2023-06-15 15:35:04.729: [iter 34 : loss : 1.1045 = 0.1593 + 0.9384 + 0.0067, time: 38.892209]
2023-06-15 15:35:05.130: epoch 34:	0.08701992  	0.16296986  	0.16205274  
2023-06-15 15:35:44.322: [iter 35 : loss : 1.0951 = 0.1505 + 0.9376 + 0.0070, time: 39.184738]
2023-06-15 15:35:44.722: epoch 35:	0.08695544  	0.16238216  	0.16156474  
2023-06-15 15:36:23.964: [iter 36 : loss : 1.0873 = 0.1433 + 0.9367 + 0.0073, time: 39.236623]
2023-06-15 15:36:24.366: epoch 36:	0.08690169  	0.16210918  	0.16128640  
2023-06-15 15:37:03.516: [iter 37 : loss : 1.0796 = 0.1362 + 0.9359 + 0.0076, time: 39.143489]
2023-06-15 15:37:03.916: epoch 37:	0.08670834  	0.16159247  	0.16090882  
2023-06-15 15:37:43.090: [iter 38 : loss : 1.0732 = 0.1303 + 0.9350 + 0.0079, time: 39.167598]
2023-06-15 15:37:43.487: epoch 38:	0.08637527  	0.16044027  	0.16014598  
2023-06-15 15:38:22.460: [iter 39 : loss : 1.0673 = 0.1248 + 0.9343 + 0.0082, time: 38.966804]
2023-06-15 15:38:22.867: epoch 39:	0.08617117  	0.15970793  	0.15940565  
2023-06-15 15:39:01.896: [iter 40 : loss : 1.0622 = 0.1200 + 0.9337 + 0.0085, time: 39.023138]
2023-06-15 15:39:02.293: epoch 40:	0.08589726  	0.15899660  	0.15871854  
2023-06-15 15:39:41.673: [iter 41 : loss : 1.0567 = 0.1150 + 0.9330 + 0.0087, time: 39.371879]
2023-06-15 15:39:42.080: epoch 41:	0.08571463  	0.15864345  	0.15815169  
2023-06-15 15:40:22.266: [iter 42 : loss : 1.0523 = 0.1109 + 0.9324 + 0.0090, time: 40.178995]
2023-06-15 15:40:22.691: epoch 42:	0.08545146  	0.15780847  	0.15752201  
2023-06-15 15:40:51.209: my pid: 3000
2023-06-15 15:40:51.209: model: model.general_recommender.SGL
2023-06-15 15:40:51.209: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 15:40:51.209: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 15:40:56.331: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 15:41:34.382: [iter 1 : loss : 1.6081 = 0.6931 + 0.9150 + 0.0000, time: 38.049964]
2023-06-15 15:41:34.788: epoch 1:	0.00336805  	0.00782167  	0.00645013  
2023-06-15 15:41:34.788: Find a better model.
2023-06-15 15:42:12.417: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 37.621697]
2023-06-15 15:42:12.825: epoch 2:	0.00445313  	0.01012850  	0.00845032  
2023-06-15 15:42:12.825: Find a better model.
2023-06-15 15:42:50.350: [iter 3 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 37.519705]
2023-06-15 15:42:50.767: epoch 3:	0.00532871  	0.01088185  	0.00987880  
2023-06-15 15:42:50.767: Find a better model.
2023-06-15 15:43:28.306: [iter 4 : loss : 1.6055 = 0.6930 + 0.9125 + 0.0000, time: 37.531988]
2023-06-15 15:43:28.713: epoch 4:	0.00613446  	0.01262330  	0.01116329  
2023-06-15 15:43:28.713: Find a better model.
2023-06-15 15:44:06.577: [iter 5 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 37.856714]
2023-06-15 15:44:06.984: epoch 5:	0.00721418  	0.01404968  	0.01272023  
2023-06-15 15:44:06.984: Find a better model.
2023-06-15 15:44:44.888: [iter 6 : loss : 1.6055 = 0.6928 + 0.9126 + 0.0000, time: 37.898095]
2023-06-15 15:44:45.297: epoch 6:	0.00818112  	0.01631770  	0.01470392  
2023-06-15 15:44:45.297: Find a better model.
2023-06-15 15:45:23.271: [iter 7 : loss : 1.6055 = 0.6928 + 0.9127 + 0.0000, time: 37.968740]
2023-06-15 15:45:23.696: epoch 7:	0.00912658  	0.01726629  	0.01601532  
2023-06-15 15:45:23.696: Find a better model.
2023-06-15 15:46:01.407: [iter 8 : loss : 1.6053 = 0.6926 + 0.9127 + 0.0000, time: 37.703873]
2023-06-15 15:46:01.810: epoch 8:	0.01058237  	0.02059912  	0.01912290  
2023-06-15 15:46:01.810: Find a better model.
2023-06-15 15:46:39.470: [iter 9 : loss : 1.6054 = 0.6925 + 0.9129 + 0.0000, time: 37.652097]
2023-06-15 15:46:39.880: epoch 9:	0.01230137  	0.02390923  	0.02281375  
2023-06-15 15:46:39.880: Find a better model.
2023-06-15 15:47:17.855: [iter 10 : loss : 1.6052 = 0.6923 + 0.9130 + 0.0000, time: 37.967646]
2023-06-15 15:47:18.257: epoch 10:	0.01397739  	0.02708709  	0.02526993  
2023-06-15 15:47:18.257: Find a better model.
2023-06-15 15:47:57.042: [iter 11 : loss : 1.6050 = 0.6919 + 0.9130 + 0.0000, time: 38.779095]
2023-06-15 15:47:57.450: epoch 11:	0.01757120  	0.03488193  	0.03252594  
2023-06-15 15:47:57.450: Find a better model.
2023-06-15 15:48:35.865: [iter 12 : loss : 1.6047 = 0.6915 + 0.9132 + 0.0000, time: 38.408547]
2023-06-15 15:48:36.268: epoch 12:	0.02161623  	0.04223566  	0.04020881  
2023-06-15 15:48:36.268: Find a better model.
2023-06-15 15:49:15.098: [iter 13 : loss : 1.6043 = 0.6907 + 0.9135 + 0.0000, time: 38.824003]
2023-06-15 15:49:15.503: epoch 13:	0.02617697  	0.05223836  	0.04996176  
2023-06-15 15:49:15.503: Find a better model.
2023-06-15 15:49:54.235: [iter 14 : loss : 1.6034 = 0.6895 + 0.9139 + 0.0000, time: 38.725640]
2023-06-15 15:49:54.640: epoch 14:	0.03233265  	0.06476603  	0.06354573  
2023-06-15 15:49:54.640: Find a better model.
2023-06-15 15:50:33.169: [iter 15 : loss : 1.6015 = 0.6871 + 0.9144 + 0.0001, time: 38.521814]
2023-06-15 15:50:33.573: epoch 15:	0.04146934  	0.08251753  	0.08198068  
2023-06-15 15:50:33.573: Find a better model.
2023-06-15 15:51:12.218: [iter 16 : loss : 1.5977 = 0.6823 + 0.9153 + 0.0001, time: 38.637734]
2023-06-15 15:51:12.623: epoch 16:	0.05200297  	0.10208553  	0.10256272  
2023-06-15 15:51:12.623: Find a better model.
2023-06-15 15:51:51.253: [iter 17 : loss : 1.5886 = 0.6717 + 0.9167 + 0.0002, time: 38.623606]
2023-06-15 15:51:51.659: epoch 17:	0.06364292  	0.12236631  	0.12390930  
2023-06-15 15:51:51.659: Find a better model.
2023-06-15 15:52:30.354: [iter 18 : loss : 1.5685 = 0.6487 + 0.9195 + 0.0003, time: 38.687562]
2023-06-15 15:52:30.757: epoch 18:	0.07254885  	0.13751835  	0.13986994  
2023-06-15 15:52:30.757: Find a better model.
2023-06-15 15:53:09.381: [iter 19 : loss : 1.5316 = 0.6067 + 0.9243 + 0.0006, time: 38.618874]
2023-06-15 15:53:09.779: epoch 19:	0.07854345  	0.14724144  	0.14944267  
2023-06-15 15:53:09.780: Find a better model.
2023-06-15 15:53:48.584: [iter 20 : loss : 1.4799 = 0.5483 + 0.9307 + 0.0009, time: 38.797600]
2023-06-15 15:53:48.983: epoch 20:	0.08155677  	0.15317756  	0.15451157  
2023-06-15 15:53:48.983: Find a better model.
2023-06-15 15:54:27.577: [iter 21 : loss : 1.4227 = 0.4843 + 0.9370 + 0.0014, time: 38.587156]
2023-06-15 15:54:27.974: epoch 21:	0.08325429  	0.15603758  	0.15739322  
2023-06-15 15:54:27.974: Find a better model.
2023-06-15 15:55:06.499: [iter 22 : loss : 1.3687 = 0.4251 + 0.9418 + 0.0019, time: 38.518502]
2023-06-15 15:55:06.897: epoch 22:	0.08430175  	0.15875062  	0.15956225  
2023-06-15 15:55:06.897: Find a better model.
2023-06-15 15:55:45.350: [iter 23 : loss : 1.3221 = 0.3751 + 0.9445 + 0.0024, time: 38.445381]
2023-06-15 15:55:45.751: epoch 23:	0.08534391  	0.16040500  	0.16111505  
2023-06-15 15:55:45.752: Find a better model.
2023-06-15 15:56:24.731: [iter 24 : loss : 1.2825 = 0.3337 + 0.9459 + 0.0029, time: 38.972721]
2023-06-15 15:56:25.134: epoch 24:	0.08611740  	0.16236444  	0.16215922  
2023-06-15 15:56:25.134: Find a better model.
2023-06-15 15:57:03.877: [iter 25 : loss : 1.2499 = 0.3004 + 0.9460 + 0.0034, time: 38.735753]
2023-06-15 15:57:04.279: epoch 25:	0.08631080  	0.16271083  	0.16222551  
2023-06-15 15:57:04.279: Find a better model.
2023-06-15 15:57:42.850: [iter 26 : loss : 1.2215 = 0.2720 + 0.9457 + 0.0039, time: 38.563575]
2023-06-15 15:57:43.249: epoch 26:	0.08649337  	0.16339420  	0.16259135  
2023-06-15 15:57:43.250: Find a better model.
2023-06-15 15:58:22.244: [iter 27 : loss : 1.1974 = 0.2482 + 0.9449 + 0.0043, time: 38.987857]
2023-06-15 15:58:22.649: epoch 27:	0.08673505  	0.16386420  	0.16257310  
2023-06-15 15:58:22.650: Find a better model.
2023-06-15 15:59:01.262: [iter 28 : loss : 1.1772 = 0.2284 + 0.9441 + 0.0047, time: 38.606499]
2023-06-15 15:59:01.662: epoch 28:	0.08690160  	0.16418801  	0.16259597  
2023-06-15 15:59:01.662: Find a better model.
2023-06-15 15:59:40.412: [iter 29 : loss : 1.1601 = 0.2120 + 0.9430 + 0.0051, time: 38.742750]
2023-06-15 15:59:40.805: epoch 29:	0.08711110  	0.16423300  	0.16263534  
2023-06-15 15:59:40.805: Find a better model.
2023-06-15 16:00:19.805: [iter 30 : loss : 1.1447 = 0.1972 + 0.9420 + 0.0055, time: 38.991348]
2023-06-15 16:00:20.205: epoch 30:	0.08712179  	0.16431080  	0.16238008  
2023-06-15 16:00:20.205: Find a better model.
2023-06-15 16:00:59.166: [iter 31 : loss : 1.1307 = 0.1840 + 0.9408 + 0.0059, time: 38.952900]
2023-06-15 16:00:59.570: epoch 31:	0.08712721  	0.16428837  	0.16215368  
2023-06-15 16:01:38.425: [iter 32 : loss : 1.1193 = 0.1733 + 0.9398 + 0.0062, time: 38.848420]
2023-06-15 16:01:38.834: epoch 32:	0.08706273  	0.16392419  	0.16202615  
2023-06-15 16:02:18.340: [iter 33 : loss : 1.1082 = 0.1628 + 0.9388 + 0.0065, time: 39.500012]
2023-06-15 16:02:18.785: epoch 33:	0.08705743  	0.16361575  	0.16171306  
2023-06-15 16:02:58.143: [iter 34 : loss : 1.0995 = 0.1548 + 0.9379 + 0.0069, time: 39.352072]
2023-06-15 16:02:58.536: epoch 34:	0.08684797  	0.16301073  	0.16124608  
2023-06-15 16:03:38.536: [iter 35 : loss : 1.0904 = 0.1461 + 0.9371 + 0.0072, time: 39.991963]
2023-06-15 16:03:38.949: epoch 35:	0.08686945  	0.16292028  	0.16095312  
2023-06-15 16:04:24.107: [iter 36 : loss : 1.0835 = 0.1398 + 0.9362 + 0.0075, time: 45.149967]
2023-06-15 16:04:24.512: epoch 36:	0.08643962  	0.16208261  	0.16008651  
2023-06-15 16:05:08.205: [iter 37 : loss : 1.0758 = 0.1326 + 0.9353 + 0.0078, time: 43.683037]
2023-06-15 16:05:08.832: epoch 37:	0.08650416  	0.16167933  	0.15981983  
2023-06-15 16:05:50.030: [iter 38 : loss : 1.0699 = 0.1272 + 0.9346 + 0.0081, time: 41.192138]
2023-06-15 16:05:50.437: epoch 38:	0.08615500  	0.16107707  	0.15931769  
2023-06-15 16:06:31.176: [iter 39 : loss : 1.0643 = 0.1220 + 0.9339 + 0.0083, time: 40.731247]
2023-06-15 16:06:31.584: epoch 39:	0.08605830  	0.16024163  	0.15864412  
2023-06-15 16:07:15.658: [iter 40 : loss : 1.0591 = 0.1173 + 0.9332 + 0.0086, time: 44.066896]
2023-06-15 16:07:16.078: epoch 40:	0.08562863  	0.15905157  	0.15781029  
2023-06-15 16:08:01.203: [iter 41 : loss : 1.0541 = 0.1127 + 0.9325 + 0.0089, time: 45.116332]
2023-06-15 16:08:01.622: epoch 41:	0.08556953  	0.15849747  	0.15733889  
2023-06-15 16:08:46.931: [iter 42 : loss : 1.0501 = 0.1089 + 0.9321 + 0.0091, time: 45.300742]
2023-06-15 16:08:47.467: epoch 42:	0.08542988  	0.15815066  	0.15692309  
2023-06-15 16:09:29.022: [iter 43 : loss : 1.0455 = 0.1047 + 0.9315 + 0.0094, time: 41.544981]
2023-06-15 16:09:29.657: epoch 43:	0.08536009  	0.15782011  	0.15650292  
2023-06-15 16:10:10.505: [iter 44 : loss : 1.0418 = 0.1011 + 0.9311 + 0.0096, time: 40.840802]
2023-06-15 16:10:10.918: epoch 44:	0.08494643  	0.15684283  	0.15576452  
2023-06-15 16:10:51.896: [iter 45 : loss : 1.0389 = 0.0986 + 0.9305 + 0.0098, time: 40.971678]
2023-06-15 16:10:52.376: epoch 45:	0.08450066  	0.15567660  	0.15473892  
2023-06-15 16:11:35.626: [iter 46 : loss : 1.0352 = 0.0950 + 0.9301 + 0.0100, time: 43.244604]
2023-06-15 16:11:36.041: epoch 46:	0.08432338  	0.15507108  	0.15421861  
2023-06-15 16:12:21.651: [iter 47 : loss : 1.0322 = 0.0923 + 0.9296 + 0.0103, time: 45.604277]
2023-06-15 16:12:22.107: epoch 47:	0.08425356  	0.15453507  	0.15361592  
2023-06-15 16:13:08.284: [iter 48 : loss : 1.0293 = 0.0896 + 0.9292 + 0.0105, time: 46.171173]
2023-06-15 16:13:08.793: epoch 48:	0.08405481  	0.15389660  	0.15321003  
2023-06-15 16:13:51.554: [iter 49 : loss : 1.0265 = 0.0870 + 0.9288 + 0.0107, time: 42.751630]
2023-06-15 16:13:52.195: epoch 49:	0.08403331  	0.15355632  	0.15283559  
2023-06-15 16:14:33.839: [iter 50 : loss : 1.0241 = 0.0848 + 0.9284 + 0.0109, time: 41.637419]
2023-06-15 16:14:34.270: epoch 50:	0.08383455  	0.15280892  	0.15226454  
2023-06-15 16:15:16.617: [iter 51 : loss : 1.0221 = 0.0828 + 0.9282 + 0.0111, time: 42.338273]
2023-06-15 16:15:17.107: epoch 51:	0.08346388  	0.15196428  	0.15156867  
2023-06-15 16:16:02.858: [iter 52 : loss : 1.0198 = 0.0807 + 0.9279 + 0.0113, time: 45.743882]
2023-06-15 16:16:03.264: epoch 52:	0.08336184  	0.15153904  	0.15107808  
2023-06-15 16:16:49.762: [iter 53 : loss : 1.0176 = 0.0786 + 0.9275 + 0.0115, time: 46.492716]
2023-06-15 16:16:50.175: epoch 53:	0.08314157  	0.15056437  	0.15051374  
2023-06-15 16:17:36.237: [iter 54 : loss : 1.0152 = 0.0763 + 0.9272 + 0.0116, time: 46.055036]
2023-06-15 16:17:36.893: epoch 54:	0.08285684  	0.14996532  	0.14987418  
2023-06-15 16:18:19.354: [iter 55 : loss : 1.0137 = 0.0750 + 0.9270 + 0.0118, time: 42.453530]
2023-06-15 16:18:20.007: epoch 55:	0.08249158  	0.14899927  	0.14935452  
2023-06-15 16:18:20.007: Early stopping is trigger at epoch: 55
2023-06-15 16:18:20.007: best_result@epoch 30:

2023-06-15 16:18:20.007: 		0.0871      	0.1643      	0.1624      
2023-06-15 16:48:45.108: my pid: 9404
2023-06-15 16:48:45.108: model: model.general_recommender.SGL
2023-06-15 16:48:45.108: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 16:48:45.108: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 16:48:50.429: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 16:49:34.360: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 43.929713]
2023-06-15 16:49:34.900: epoch 1:	0.00373870  	0.00883169  	0.00749494  
2023-06-15 16:49:34.900: Find a better model.
2023-06-15 16:50:14.277: [iter 2 : loss : 1.6056 = 0.6931 + 0.9126 + 0.0000, time: 39.368106]
2023-06-15 16:50:14.685: epoch 2:	0.00487749  	0.01061287  	0.00912384  
2023-06-15 16:50:14.685: Find a better model.
2023-06-15 16:50:55.439: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 40.747293]
2023-06-15 16:50:56.111: epoch 3:	0.00559192  	0.01292084  	0.01043731  
2023-06-15 16:50:56.112: Find a better model.
2023-06-15 16:51:39.327: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 43.208409]
2023-06-15 16:51:39.749: epoch 4:	0.00607000  	0.01299237  	0.01147062  
2023-06-15 16:51:39.749: Find a better model.
2023-06-15 16:52:22.357: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 42.599616]
2023-06-15 16:52:23.040: epoch 5:	0.00706914  	0.01511571  	0.01319606  
2023-06-15 16:52:23.040: Find a better model.
2023-06-15 16:53:02.643: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 39.597125]
2023-06-15 16:53:03.111: epoch 6:	0.00805757  	0.01680825  	0.01506839  
2023-06-15 16:53:03.111: Find a better model.
2023-06-15 16:53:44.022: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 40.903208]
2023-06-15 16:53:44.638: epoch 7:	0.00972287  	0.02030187  	0.01796624  
2023-06-15 16:53:44.638: Find a better model.
2023-06-15 16:54:28.252: [iter 8 : loss : 1.6053 = 0.6927 + 0.9126 + 0.0000, time: 43.606638]
2023-06-15 16:54:28.660: epoch 8:	0.01060386  	0.02199993  	0.02009856  
2023-06-15 16:54:28.660: Find a better model.
2023-06-15 16:55:11.580: [iter 9 : loss : 1.6054 = 0.6925 + 0.9128 + 0.0000, time: 42.913014]
2023-06-15 16:55:12.209: epoch 9:	0.01217245  	0.02409360  	0.02246948  
2023-06-15 16:55:12.209: Find a better model.
2023-06-15 16:55:51.649: [iter 10 : loss : 1.6052 = 0.6923 + 0.9129 + 0.0000, time: 39.432207]
2023-06-15 16:55:52.066: epoch 10:	0.01356913  	0.02731876  	0.02549988  
2023-06-15 16:55:52.066: Find a better model.
2023-06-15 16:56:33.474: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 41.401771]
2023-06-15 16:56:34.096: epoch 11:	0.01653445  	0.03392222  	0.03078435  
2023-06-15 16:56:34.096: Find a better model.
2023-06-15 16:57:18.841: [iter 12 : loss : 1.6048 = 0.6916 + 0.9131 + 0.0000, time: 44.738105]
2023-06-15 16:57:19.270: epoch 12:	0.01981129  	0.04018230  	0.03747260  
2023-06-15 16:57:19.270: Find a better model.
2023-06-15 16:58:04.733: [iter 13 : loss : 1.6045 = 0.6910 + 0.9134 + 0.0000, time: 45.455959]
2023-06-15 16:58:05.225: epoch 13:	0.02410342  	0.04912125  	0.04673545  
2023-06-15 16:58:05.225: Find a better model.
2023-06-15 16:58:46.533: [iter 14 : loss : 1.6037 = 0.6900 + 0.9137 + 0.0000, time: 41.300295]
2023-06-15 16:58:47.202: epoch 14:	0.03000681  	0.06108710  	0.05882053  
2023-06-15 16:58:47.202: Find a better model.
2023-06-15 16:59:28.305: [iter 15 : loss : 1.6023 = 0.6881 + 0.9141 + 0.0001, time: 41.094545]
2023-06-15 16:59:28.815: epoch 15:	0.03815511  	0.07691714  	0.07498685  
2023-06-15 16:59:28.815: Find a better model.
2023-06-15 17:00:12.624: [iter 16 : loss : 1.5994 = 0.6844 + 0.9149 + 0.0001, time: 43.796518]
2023-06-15 17:00:13.059: epoch 16:	0.04811404  	0.09571034  	0.09446217  
2023-06-15 17:00:13.059: Find a better model.
2023-06-15 17:00:58.135: [iter 17 : loss : 1.5926 = 0.6764 + 0.9161 + 0.0001, time: 45.068540]
2023-06-15 17:00:58.538: epoch 17:	0.05967876  	0.11640796  	0.11593053  
2023-06-15 17:00:58.538: Find a better model.
2023-06-15 17:01:42.070: [iter 18 : loss : 1.5774 = 0.6587 + 0.9184 + 0.0002, time: 43.526278]
2023-06-15 17:01:42.708: epoch 18:	0.06973959  	0.13285929  	0.13361016  
2023-06-15 17:01:42.708: Find a better model.
2023-06-15 17:02:23.959: [iter 19 : loss : 1.5469 = 0.6241 + 0.9223 + 0.0005, time: 41.243937]
2023-06-15 17:02:24.355: epoch 19:	0.07677083  	0.14503199  	0.14633149  
2023-06-15 17:02:24.355: Find a better model.
2023-06-15 17:03:06.507: [iter 20 : loss : 1.5003 = 0.5714 + 0.9281 + 0.0008, time: 42.144587]
2023-06-15 17:03:07.184: epoch 20:	0.08069206  	0.15246861  	0.15351439  
2023-06-15 17:03:07.185: Find a better model.
2023-06-15 17:03:52.409: [iter 21 : loss : 1.4440 = 0.5084 + 0.9344 + 0.0012, time: 45.187843]
2023-06-15 17:03:52.828: epoch 21:	0.08317909  	0.15730673  	0.15743175  
2023-06-15 17:03:52.828: Find a better model.
2023-06-15 17:04:38.116: [iter 22 : loss : 1.3880 = 0.4465 + 0.9397 + 0.0017, time: 45.272547]
2023-06-15 17:04:38.692: epoch 22:	0.08437160  	0.15977356  	0.15983360  
2023-06-15 17:04:38.692: Find a better model.
2023-06-15 17:05:19.699: [iter 23 : loss : 1.3386 = 0.3932 + 0.9432 + 0.0023, time: 40.999909]
2023-06-15 17:05:20.100: epoch 23:	0.08544588  	0.16182055  	0.16169359  
2023-06-15 17:05:20.100: Find a better model.
2023-06-15 17:06:01.815: [iter 24 : loss : 1.2962 = 0.3484 + 0.9451 + 0.0028, time: 41.707018]
2023-06-15 17:06:02.534: epoch 24:	0.08597768  	0.16240995  	0.16284323  
2023-06-15 17:06:02.534: Find a better model.
2023-06-15 17:06:48.006: [iter 25 : loss : 1.2614 = 0.3125 + 0.9457 + 0.0032, time: 45.465681]
2023-06-15 17:06:48.462: epoch 25:	0.08668137  	0.16337118  	0.16358927  
2023-06-15 17:06:48.462: Find a better model.
2023-06-15 17:07:34.098: [iter 26 : loss : 1.2311 = 0.2818 + 0.9456 + 0.0037, time: 45.628656]
2023-06-15 17:07:34.597: epoch 26:	0.08690697  	0.16369691  	0.16385624  
2023-06-15 17:07:34.597: Find a better model.
2023-06-15 17:08:16.189: [iter 27 : loss : 1.2058 = 0.2566 + 0.9451 + 0.0042, time: 41.584453]
2023-06-15 17:08:16.673: epoch 27:	0.08716485  	0.16449198  	0.16427287  
2023-06-15 17:08:16.673: Find a better model.
2023-06-15 17:08:58.022: [iter 28 : loss : 1.1845 = 0.2355 + 0.9444 + 0.0046, time: 41.341543]
2023-06-15 17:08:58.429: epoch 28:	0.08725069  	0.16447978  	0.16420183  
2023-06-15 17:09:43.406: [iter 29 : loss : 1.1663 = 0.2180 + 0.9433 + 0.0050, time: 44.971968]
2023-06-15 17:09:43.863: epoch 29:	0.08723458  	0.16439639  	0.16400944  
2023-06-15 17:10:29.430: [iter 30 : loss : 1.1501 = 0.2024 + 0.9423 + 0.0054, time: 45.550745]
2023-06-15 17:10:30.107: epoch 30:	0.08730451  	0.16432054  	0.16413786  
2023-06-15 17:11:11.771: [iter 31 : loss : 1.1354 = 0.1885 + 0.9411 + 0.0057, time: 41.609868]
2023-06-15 17:11:12.476: epoch 31:	0.08734745  	0.16386741  	0.16354875  
2023-06-15 17:11:55.638: [iter 32 : loss : 1.1236 = 0.1773 + 0.9402 + 0.0061, time: 43.155164]
2023-06-15 17:11:56.145: epoch 32:	0.08707891  	0.16305473  	0.16308346  
2023-06-15 17:12:43.156: [iter 33 : loss : 1.1120 = 0.1664 + 0.9392 + 0.0064, time: 47.005131]
2023-06-15 17:12:43.823: epoch 33:	0.08712733  	0.16290794  	0.16284616  
2023-06-15 17:14:08.784: my pid: 11696
2023-06-15 17:14:08.784: model: model.general_recommender.SGL
2023-06-15 17:14:08.784: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 17:14:08.784: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 17:14:14.928: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 17:14:55.330: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 40.401792]
2023-06-15 17:14:55.739: epoch 1:	0.00336268  	0.00805990  	0.00660252  
2023-06-15 17:14:55.739: Find a better model.
2023-06-15 17:15:36.363: [iter 2 : loss : 1.6055 = 0.6931 + 0.9125 + 0.0000, time: 40.616571]
2023-06-15 17:15:36.792: epoch 2:	0.00415769  	0.00937556  	0.00763559  
2023-06-15 17:15:36.792: Find a better model.
2023-06-15 17:16:21.311: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 44.511958]
2023-06-15 17:16:21.762: epoch 3:	0.00509773  	0.01122569  	0.00945159  
2023-06-15 17:16:21.762: Find a better model.
2023-06-15 17:17:05.810: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 44.042061]
2023-06-15 17:17:06.261: epoch 4:	0.00571547  	0.01210655  	0.01034839  
2023-06-15 17:17:06.261: Find a better model.
2023-06-15 17:17:45.930: [iter 5 : loss : 1.6053 = 0.6929 + 0.9123 + 0.0000, time: 39.654922]
2023-06-15 17:17:46.582: epoch 5:	0.00633858  	0.01298956  	0.01136375  
2023-06-15 17:17:46.582: Find a better model.
2023-06-15 17:18:26.208: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 39.620023]
2023-06-15 17:18:26.631: epoch 6:	0.00756873  	0.01544854  	0.01313406  
2023-06-15 17:18:26.632: Find a better model.
2023-06-15 17:19:09.099: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 42.459687]
2023-06-15 17:19:09.507: epoch 7:	0.00837451  	0.01592887  	0.01442589  
2023-06-15 17:19:09.507: Find a better model.
2023-06-15 17:19:53.705: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 44.190794]
2023-06-15 17:19:54.195: epoch 8:	0.00964765  	0.01914116  	0.01755748  
2023-06-15 17:19:54.196: Find a better model.
2023-06-15 17:20:35.730: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 41.524901]
2023-06-15 17:20:36.381: epoch 9:	0.01130756  	0.02217403  	0.02032675  
2023-06-15 17:20:36.382: Find a better model.
2023-06-15 17:21:16.306: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 39.917434]
2023-06-15 17:21:16.737: epoch 10:	0.01269889  	0.02562805  	0.02287430  
2023-06-15 17:21:16.737: Find a better model.
2023-06-15 17:22:00.322: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 43.576826]
2023-06-15 17:22:00.734: epoch 11:	0.01482615  	0.03006952  	0.02739858  
2023-06-15 17:22:00.734: Find a better model.
2023-06-15 17:22:46.136: [iter 12 : loss : 1.6048 = 0.6917 + 0.9131 + 0.0000, time: 45.396318]
2023-06-15 17:22:46.581: epoch 12:	0.01818361  	0.03702565  	0.03452205  
2023-06-15 17:22:46.581: Find a better model.
2023-06-15 17:23:30.389: [iter 13 : loss : 1.6045 = 0.6912 + 0.9133 + 0.0000, time: 43.801692]
2023-06-15 17:23:31.045: epoch 13:	0.02150344  	0.04396077  	0.04145292  
2023-06-15 17:23:31.045: Find a better model.
2023-06-15 17:24:12.219: [iter 14 : loss : 1.6039 = 0.6902 + 0.9136 + 0.0000, time: 41.167480]
2023-06-15 17:24:12.628: epoch 14:	0.02710092  	0.05621796  	0.05232686  
2023-06-15 17:24:12.629: Find a better model.
2023-06-15 17:24:54.573: [iter 15 : loss : 1.6026 = 0.6886 + 0.9140 + 0.0001, time: 41.937158]
2023-06-15 17:24:55.027: epoch 15:	0.03463686  	0.07165711  	0.06834337  
2023-06-15 17:24:55.027: Find a better model.
2023-06-15 17:25:40.021: [iter 16 : loss : 1.6000 = 0.6853 + 0.9147 + 0.0001, time: 44.987202]
2023-06-15 17:25:40.469: epoch 16:	0.04448271  	0.09031839  	0.08780764  
2023-06-15 17:25:40.469: Find a better model.
2023-06-15 17:26:25.964: [iter 17 : loss : 1.5942 = 0.6783 + 0.9158 + 0.0001, time: 45.486427]
2023-06-15 17:26:26.673: epoch 17:	0.05675138  	0.11184207  	0.11028782  
2023-06-15 17:26:26.673: Find a better model.
2023-06-15 17:27:08.180: [iter 18 : loss : 1.5808 = 0.6627 + 0.9178 + 0.0002, time: 41.499854]
2023-06-15 17:27:08.818: epoch 18:	0.06792402  	0.12991266  	0.13026895  
2023-06-15 17:27:08.818: Find a better model.
2023-06-15 17:27:49.629: [iter 19 : loss : 1.5531 = 0.6313 + 0.9215 + 0.0004, time: 40.803991]
2023-06-15 17:27:50.184: epoch 19:	0.07607793  	0.14335297  	0.14491239  
2023-06-15 17:27:50.184: Find a better model.
2023-06-15 17:28:33.241: [iter 20 : loss : 1.5086 = 0.5809 + 0.9270 + 0.0007, time: 43.047050]
2023-06-15 17:28:33.645: epoch 20:	0.08050944  	0.15171283  	0.15290512  
2023-06-15 17:28:33.646: Find a better model.
2023-06-15 17:29:18.797: [iter 21 : loss : 1.4526 = 0.5181 + 0.9333 + 0.0012, time: 45.144244]
2023-06-15 17:29:19.254: epoch 21:	0.08325433  	0.15675518  	0.15713894  
2023-06-15 17:29:19.254: Find a better model.
2023-06-15 17:30:03.875: [iter 22 : loss : 1.3959 = 0.4551 + 0.9391 + 0.0017, time: 44.610770]
2023-06-15 17:30:04.492: epoch 22:	0.08488727  	0.16000140  	0.15997396  
2023-06-15 17:30:04.492: Find a better model.
2023-06-15 17:30:46.849: [iter 23 : loss : 1.3451 = 0.4000 + 0.9429 + 0.0022, time: 42.350312]
2023-06-15 17:30:47.263: epoch 23:	0.08591326  	0.16197705  	0.16170381  
2023-06-15 17:30:47.263: Find a better model.
2023-06-15 17:31:29.741: [iter 24 : loss : 1.3016 = 0.3539 + 0.9450 + 0.0027, time: 42.470759]
2023-06-15 17:31:30.177: epoch 24:	0.08678343  	0.16407719  	0.16299419  
2023-06-15 17:31:30.177: Find a better model.
2023-06-15 17:32:15.618: [iter 25 : loss : 1.2658 = 0.3168 + 0.9458 + 0.0032, time: 45.433867]
2023-06-15 17:32:16.089: epoch 25:	0.08716481  	0.16463104  	0.16380228  
2023-06-15 17:32:16.089: Find a better model.
2023-06-15 17:33:02.207: [iter 26 : loss : 1.2344 = 0.2851 + 0.9457 + 0.0036, time: 46.112060]
2023-06-15 17:33:02.609: epoch 26:	0.08756218  	0.16558990  	0.16447471  
2023-06-15 17:33:02.609: Find a better model.
2023-06-15 17:33:45.275: [iter 27 : loss : 1.2086 = 0.2593 + 0.9452 + 0.0041, time: 42.657784]
2023-06-15 17:33:45.931: epoch 27:	0.08771268  	0.16614245  	0.16452536  
2023-06-15 17:33:45.931: Find a better model.
2023-06-15 17:34:26.914: [iter 28 : loss : 1.1866 = 0.2376 + 0.9445 + 0.0045, time: 40.975060]
2023-06-15 17:34:27.448: epoch 28:	0.08783624  	0.16599698  	0.16425580  
2023-06-15 17:35:09.948: [iter 29 : loss : 1.1682 = 0.2198 + 0.9435 + 0.0049, time: 42.491620]
2023-06-15 17:35:10.739: epoch 29:	0.08794368  	0.16594014  	0.16406012  
2023-06-15 17:35:56.232: [iter 30 : loss : 1.1516 = 0.2039 + 0.9424 + 0.0053, time: 45.485796]
2023-06-15 17:35:56.684: epoch 30:	0.08805110  	0.16609077  	0.16392536  
2023-06-15 17:36:42.717: [iter 31 : loss : 1.1366 = 0.1897 + 0.9413 + 0.0057, time: 46.026657]
2023-06-15 17:36:43.248: epoch 31:	0.08802421  	0.16593236  	0.16335346  
2023-06-15 17:37:25.736: [iter 32 : loss : 1.1246 = 0.1783 + 0.9402 + 0.0060, time: 42.481235]
2023-06-15 17:37:26.386: epoch 32:	0.08805107  	0.16608053  	0.16330257  
2023-06-15 17:38:07.685: [iter 33 : loss : 1.1130 = 0.1673 + 0.9393 + 0.0064, time: 41.292039]
2023-06-15 17:38:08.185: epoch 33:	0.08778246  	0.16564101  	0.16287044  
2023-06-15 17:38:51.182: [iter 34 : loss : 1.1037 = 0.1586 + 0.9384 + 0.0067, time: 42.990380]
2023-06-15 17:38:51.932: epoch 34:	0.08749240  	0.16440473  	0.16219220  
2023-06-15 17:39:37.559: [iter 35 : loss : 1.0943 = 0.1497 + 0.9376 + 0.0070, time: 45.610029]
2023-06-15 17:39:38.028: epoch 35:	0.08754076  	0.16405557  	0.16193739  
2023-06-15 17:40:24.205: [iter 36 : loss : 1.0866 = 0.1425 + 0.9367 + 0.0073, time: 46.170732]
2023-06-15 17:40:24.606: epoch 36:	0.08733668  	0.16315281  	0.16133960  
2023-06-15 17:41:07.584: [iter 37 : loss : 1.0789 = 0.1355 + 0.9358 + 0.0076, time: 42.969923]
2023-06-15 17:41:08.232: epoch 37:	0.08720776  	0.16275194  	0.16099294  
2023-06-15 17:41:49.984: [iter 38 : loss : 1.0724 = 0.1294 + 0.9351 + 0.0079, time: 41.746441]
2023-06-15 17:41:50.387: epoch 38:	0.08704662  	0.16187549  	0.16054380  
2023-06-15 17:42:32.908: [iter 39 : loss : 1.0668 = 0.1242 + 0.9343 + 0.0082, time: 42.515427]
2023-06-15 17:42:33.578: epoch 39:	0.08674577  	0.16123033  	0.15984505  
2023-06-15 17:43:19.254: [iter 40 : loss : 1.0616 = 0.1195 + 0.9336 + 0.0085, time: 45.668457]
2023-06-15 17:43:19.657: epoch 40:	0.08652017  	0.16036341  	0.15919954  
2023-06-15 17:44:05.698: [iter 41 : loss : 1.0562 = 0.1145 + 0.9330 + 0.0087, time: 46.034554]
2023-06-15 17:44:06.197: epoch 41:	0.08626769  	0.15985414  	0.15857615  
2023-06-15 17:44:49.405: [iter 42 : loss : 1.0519 = 0.1105 + 0.9324 + 0.0090, time: 43.200650]
2023-06-15 17:44:50.065: epoch 42:	0.08625163  	0.15965126  	0.15809985  
2023-06-15 17:45:31.552: [iter 43 : loss : 1.0472 = 0.1062 + 0.9318 + 0.0092, time: 41.481419]
2023-06-15 17:45:31.981: epoch 43:	0.08605284  	0.15919122  	0.15774263  
2023-06-15 17:46:14.724: [iter 44 : loss : 1.0434 = 0.1025 + 0.9314 + 0.0095, time: 42.736297]
2023-06-15 17:46:15.204: epoch 44:	0.08597767  	0.15861382  	0.15731275  
2023-06-15 17:47:00.781: [iter 45 : loss : 1.0404 = 0.0999 + 0.9308 + 0.0097, time: 45.569692]
2023-06-15 17:47:01.228: epoch 45:	0.08554257  	0.15775836  	0.15670420  
2023-06-15 17:47:41.661: [iter 46 : loss : 1.0367 = 0.0963 + 0.9304 + 0.0099, time: 40.425266]
2023-06-15 17:47:42.083: epoch 46:	0.08519343  	0.15717913  	0.15604396  
2023-06-15 17:48:21.577: [iter 47 : loss : 1.0335 = 0.0935 + 0.9299 + 0.0102, time: 39.487472]
2023-06-15 17:48:21.980: epoch 47:	0.08506454  	0.15675671  	0.15554990  
2023-06-15 17:49:01.537: [iter 48 : loss : 1.0305 = 0.0906 + 0.9295 + 0.0104, time: 39.550866]
2023-06-15 17:49:01.938: epoch 48:	0.08482818  	0.15596955  	0.15490334  
2023-06-15 17:49:41.324: [iter 49 : loss : 1.0278 = 0.0881 + 0.9291 + 0.0106, time: 39.378649]
2023-06-15 17:49:41.723: epoch 49:	0.08457577  	0.15516914  	0.15434134  
2023-06-15 17:50:20.942: [iter 50 : loss : 1.0254 = 0.0859 + 0.9288 + 0.0108, time: 39.212215]
2023-06-15 17:50:21.354: epoch 50:	0.08428569  	0.15462084  	0.15401290  
2023-06-15 17:51:00.600: [iter 51 : loss : 1.0229 = 0.0835 + 0.9284 + 0.0110, time: 39.238204]
2023-06-15 17:51:00.998: epoch 51:	0.08399560  	0.15398593  	0.15330863  
2023-06-15 17:51:40.102: [iter 52 : loss : 1.0210 = 0.0817 + 0.9281 + 0.0112, time: 39.098343]
2023-06-15 17:51:40.502: epoch 52:	0.08384522  	0.15339692  	0.15289991  
2023-06-15 17:51:40.502: Early stopping is trigger at epoch: 52
2023-06-15 17:51:40.502: best_result@epoch 27:

2023-06-15 17:51:40.502: 		0.0877      	0.1661      	0.1645      
2023-06-15 18:38:17.765: my pid: 10280
2023-06-15 18:38:17.765: model: model.general_recommender.SGL
2023-06-15 18:38:17.765: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 18:38:17.765: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 18:38:22.908: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 18:39:01.725: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 38.816140]
2023-06-15 18:39:02.136: epoch 1:	0.00336268  	0.00805990  	0.00660252  
2023-06-15 18:39:02.136: Find a better model.
2023-06-15 18:39:40.156: [iter 2 : loss : 1.6055 = 0.6931 + 0.9125 + 0.0000, time: 38.012393]
2023-06-15 18:39:40.590: epoch 2:	0.00415769  	0.00937556  	0.00763559  
2023-06-15 18:39:40.590: Find a better model.
2023-06-15 18:40:18.527: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 37.931118]
2023-06-15 18:40:18.927: epoch 3:	0.00509773  	0.01122569  	0.00945159  
2023-06-15 18:40:18.928: Find a better model.
2023-06-15 18:40:56.443: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 37.509623]
2023-06-15 18:40:56.856: epoch 4:	0.00571547  	0.01210655  	0.01034839  
2023-06-15 18:40:56.856: Find a better model.
2023-06-15 18:41:34.526: [iter 5 : loss : 1.6053 = 0.6929 + 0.9123 + 0.0000, time: 37.662656]
2023-06-15 18:41:34.934: epoch 5:	0.00633858  	0.01298956  	0.01136375  
2023-06-15 18:41:34.934: Find a better model.
2023-06-15 18:42:13.036: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 38.095236]
2023-06-15 18:42:13.439: epoch 6:	0.00756873  	0.01544854  	0.01313406  
2023-06-15 18:42:13.439: Find a better model.
2023-06-15 18:42:51.035: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 37.589842]
2023-06-15 18:42:51.455: epoch 7:	0.00837451  	0.01592887  	0.01442589  
2023-06-15 18:42:51.455: Find a better model.
2023-06-15 18:43:29.275: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 37.814392]
2023-06-15 18:43:29.681: epoch 8:	0.00964765  	0.01914116  	0.01755748  
2023-06-15 18:43:29.681: Find a better model.
2023-06-15 18:44:07.520: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 37.831933]
2023-06-15 18:44:07.937: epoch 9:	0.01130756  	0.02217403  	0.02032675  
2023-06-15 18:44:07.937: Find a better model.
2023-06-15 18:44:46.034: [iter 10 : loss : 1.6052 = 0.6924 + 0.9128 + 0.0000, time: 38.089507]
2023-06-15 18:44:46.440: epoch 10:	0.01269889  	0.02562805  	0.02287430  
2023-06-15 18:44:46.440: Find a better model.
2023-06-15 18:45:24.827: [iter 11 : loss : 1.6050 = 0.6921 + 0.9129 + 0.0000, time: 38.379917]
2023-06-15 18:45:25.233: epoch 11:	0.01482615  	0.03006952  	0.02739858  
2023-06-15 18:45:25.233: Find a better model.
2023-06-15 18:46:03.811: [iter 12 : loss : 1.6048 = 0.6917 + 0.9131 + 0.0000, time: 38.570864]
2023-06-15 18:46:04.214: epoch 12:	0.01818361  	0.03702565  	0.03452205  
2023-06-15 18:46:04.214: Find a better model.
2023-06-15 18:46:42.755: [iter 13 : loss : 1.6045 = 0.6912 + 0.9133 + 0.0000, time: 38.535091]
2023-06-15 18:46:43.172: epoch 13:	0.02150344  	0.04396077  	0.04145292  
2023-06-15 18:46:43.172: Find a better model.
2023-06-15 18:47:21.943: [iter 14 : loss : 1.6039 = 0.6902 + 0.9136 + 0.0000, time: 38.764261]
2023-06-15 18:47:22.349: epoch 14:	0.02710092  	0.05621796  	0.05232686  
2023-06-15 18:47:22.349: Find a better model.
2023-06-15 18:48:01.011: [iter 15 : loss : 1.6026 = 0.6886 + 0.9140 + 0.0001, time: 38.655642]
2023-06-15 18:48:01.410: epoch 15:	0.03463686  	0.07165711  	0.06834337  
2023-06-15 18:48:01.411: Find a better model.
2023-06-15 18:48:39.955: [iter 16 : loss : 1.6000 = 0.6853 + 0.9147 + 0.0001, time: 38.537620]
2023-06-15 18:48:40.367: epoch 16:	0.04448271  	0.09031839  	0.08780764  
2023-06-15 18:48:40.368: Find a better model.
2023-06-15 18:49:19.168: [iter 17 : loss : 1.5942 = 0.6783 + 0.9158 + 0.0001, time: 38.793960]
2023-06-15 18:49:19.575: epoch 17:	0.05675138  	0.11184207  	0.11028782  
2023-06-15 18:49:19.575: Find a better model.
2023-06-15 18:49:58.173: [iter 18 : loss : 1.5808 = 0.6627 + 0.9178 + 0.0002, time: 38.591887]
2023-06-15 18:49:58.586: epoch 18:	0.06792402  	0.12991266  	0.13026895  
2023-06-15 18:49:58.586: Find a better model.
2023-06-15 18:50:37.119: [iter 19 : loss : 1.5531 = 0.6313 + 0.9215 + 0.0004, time: 38.525564]
2023-06-15 18:50:37.528: epoch 19:	0.07607793  	0.14335297  	0.14491239  
2023-06-15 18:50:37.528: Find a better model.
2023-06-15 18:51:16.242: [iter 20 : loss : 1.5086 = 0.5809 + 0.9270 + 0.0007, time: 38.706895]
2023-06-15 18:51:16.649: epoch 20:	0.08050944  	0.15171283  	0.15290512  
2023-06-15 18:51:16.650: Find a better model.
2023-06-15 18:51:55.166: [iter 21 : loss : 1.4526 = 0.5181 + 0.9333 + 0.0012, time: 38.509332]
2023-06-15 18:51:55.579: epoch 21:	0.08325433  	0.15675518  	0.15713894  
2023-06-15 18:51:55.580: Find a better model.
2023-06-15 18:52:34.270: [iter 22 : loss : 1.3959 = 0.4551 + 0.9391 + 0.0017, time: 38.682961]
2023-06-15 18:52:34.673: epoch 22:	0.08488727  	0.16000140  	0.15997396  
2023-06-15 18:52:34.673: Find a better model.
2023-06-15 18:53:13.260: [iter 23 : loss : 1.3451 = 0.4000 + 0.9429 + 0.0022, time: 38.581065]
2023-06-15 18:53:13.666: epoch 23:	0.08591326  	0.16197705  	0.16170381  
2023-06-15 18:53:13.666: Find a better model.
2023-06-15 18:53:52.440: [iter 24 : loss : 1.3016 = 0.3539 + 0.9450 + 0.0027, time: 38.767867]
2023-06-15 18:53:52.843: epoch 24:	0.08678343  	0.16407719  	0.16299419  
2023-06-15 18:53:52.843: Find a better model.
2023-06-15 18:54:31.801: [iter 25 : loss : 1.2658 = 0.3168 + 0.9458 + 0.0032, time: 38.949245]
2023-06-15 18:54:32.199: epoch 25:	0.08716481  	0.16463104  	0.16380228  
2023-06-15 18:54:32.199: Find a better model.
2023-06-15 18:55:11.037: [iter 26 : loss : 1.2344 = 0.2851 + 0.9457 + 0.0036, time: 38.830768]
2023-06-15 18:55:11.435: epoch 26:	0.08756218  	0.16558990  	0.16447471  
2023-06-15 18:55:11.435: Find a better model.
2023-06-15 18:55:50.083: [iter 27 : loss : 1.2086 = 0.2593 + 0.9452 + 0.0041, time: 38.641726]
2023-06-15 18:55:50.483: epoch 27:	0.08771268  	0.16614245  	0.16452536  
2023-06-15 18:55:50.484: Find a better model.
2023-06-15 18:56:29.157: [iter 28 : loss : 1.1866 = 0.2376 + 0.9445 + 0.0045, time: 38.665758]
2023-06-15 18:56:29.555: epoch 28:	0.08783624  	0.16599698  	0.16425580  
2023-06-15 18:57:08.217: [iter 29 : loss : 1.1682 = 0.2198 + 0.9435 + 0.0049, time: 38.655787]
2023-06-15 18:57:08.619: epoch 29:	0.08794368  	0.16594014  	0.16406012  
2023-06-15 18:57:47.139: [iter 30 : loss : 1.1516 = 0.2039 + 0.9424 + 0.0053, time: 38.513177]
2023-06-15 18:57:47.539: epoch 30:	0.08805110  	0.16609077  	0.16392536  
2023-06-15 18:58:26.143: [iter 31 : loss : 1.1366 = 0.1897 + 0.9413 + 0.0057, time: 38.597876]
2023-06-15 18:58:26.541: epoch 31:	0.08802421  	0.16593236  	0.16335346  
2023-06-15 18:59:05.133: [iter 32 : loss : 1.1246 = 0.1783 + 0.9402 + 0.0060, time: 38.585197]
2023-06-15 18:59:05.530: epoch 32:	0.08805107  	0.16608053  	0.16330257  
2023-06-15 18:59:44.548: [iter 33 : loss : 1.1130 = 0.1673 + 0.9393 + 0.0064, time: 39.010555]
2023-06-15 18:59:44.961: epoch 33:	0.08778246  	0.16564101  	0.16287044  
2023-06-15 19:00:23.876: [iter 34 : loss : 1.1037 = 0.1586 + 0.9384 + 0.0067, time: 38.907152]
2023-06-15 19:00:24.273: epoch 34:	0.08749240  	0.16440473  	0.16219220  
2023-06-15 19:01:03.266: [iter 35 : loss : 1.0943 = 0.1497 + 0.9376 + 0.0070, time: 38.987225]
2023-06-15 19:01:03.675: epoch 35:	0.08754076  	0.16405557  	0.16193739  
2023-06-15 19:01:42.489: [iter 36 : loss : 1.0866 = 0.1425 + 0.9367 + 0.0073, time: 38.805883]
2023-06-15 19:01:42.912: epoch 36:	0.08733668  	0.16315281  	0.16133960  
2023-06-15 19:02:21.467: [iter 37 : loss : 1.0789 = 0.1355 + 0.9358 + 0.0076, time: 38.547397]
2023-06-15 19:02:21.870: epoch 37:	0.08720776  	0.16275194  	0.16099294  
2023-06-15 19:03:00.848: [iter 38 : loss : 1.0724 = 0.1294 + 0.9351 + 0.0079, time: 38.970736]
2023-06-15 19:03:01.263: epoch 38:	0.08704662  	0.16187549  	0.16054380  
2023-06-15 19:03:40.265: [iter 39 : loss : 1.0668 = 0.1242 + 0.9343 + 0.0082, time: 38.996008]
2023-06-15 19:03:40.671: epoch 39:	0.08674577  	0.16123033  	0.15984505  
2023-06-15 19:04:19.804: [iter 40 : loss : 1.0616 = 0.1195 + 0.9336 + 0.0085, time: 39.124921]
2023-06-15 19:04:20.211: epoch 40:	0.08652017  	0.16036341  	0.15919954  
2023-06-15 19:04:59.073: [iter 41 : loss : 1.0562 = 0.1145 + 0.9330 + 0.0087, time: 38.853738]
2023-06-15 19:04:59.477: epoch 41:	0.08626769  	0.15985414  	0.15857615  
2023-06-15 19:05:38.398: [iter 42 : loss : 1.0519 = 0.1105 + 0.9324 + 0.0090, time: 38.913487]
2023-06-15 19:05:38.801: epoch 42:	0.08625163  	0.15965126  	0.15809985  
2023-06-15 19:06:17.538: [iter 43 : loss : 1.0472 = 0.1062 + 0.9318 + 0.0092, time: 38.731368]
2023-06-15 19:06:17.937: epoch 43:	0.08605284  	0.15919122  	0.15774263  
2023-06-15 19:06:56.962: [iter 44 : loss : 1.0434 = 0.1025 + 0.9314 + 0.0095, time: 39.018452]
2023-06-15 19:06:57.376: epoch 44:	0.08597767  	0.15861382  	0.15731275  
2023-06-15 19:07:36.600: [iter 45 : loss : 1.0404 = 0.0999 + 0.9308 + 0.0097, time: 39.216990]
2023-06-15 19:07:37.001: epoch 45:	0.08554257  	0.15775836  	0.15670420  
2023-06-15 19:08:16.208: [iter 46 : loss : 1.0367 = 0.0963 + 0.9304 + 0.0099, time: 39.200972]
2023-06-15 19:08:16.608: epoch 46:	0.08519343  	0.15717913  	0.15604396  
2023-06-15 19:08:55.548: [iter 47 : loss : 1.0335 = 0.0935 + 0.9299 + 0.0102, time: 38.933506]
2023-06-15 19:08:55.954: epoch 47:	0.08506454  	0.15675671  	0.15554990  
2023-06-15 19:09:34.890: [iter 48 : loss : 1.0305 = 0.0906 + 0.9295 + 0.0104, time: 38.928956]
2023-06-15 19:09:35.293: epoch 48:	0.08482818  	0.15596955  	0.15490334  
2023-06-15 19:10:14.452: [iter 49 : loss : 1.0278 = 0.0881 + 0.9291 + 0.0106, time: 39.152772]
2023-06-15 19:10:14.851: epoch 49:	0.08457577  	0.15516914  	0.15434134  
2023-06-15 19:10:54.070: [iter 50 : loss : 1.0254 = 0.0859 + 0.9288 + 0.0108, time: 39.211729]
2023-06-15 19:10:54.493: epoch 50:	0.08428569  	0.15462084  	0.15401290  
2023-06-15 19:11:33.740: [iter 51 : loss : 1.0229 = 0.0835 + 0.9284 + 0.0110, time: 39.235053]
2023-06-15 19:11:34.143: epoch 51:	0.08399560  	0.15398593  	0.15330863  
2023-06-15 19:12:13.082: [iter 52 : loss : 1.0210 = 0.0817 + 0.9281 + 0.0112, time: 38.931229]
2023-06-15 19:12:13.486: epoch 52:	0.08384522  	0.15339692  	0.15289991  
2023-06-15 19:12:13.486: Early stopping is trigger at epoch: 52
2023-06-15 19:12:13.486: best_result@epoch 27:

2023-06-15 19:12:13.486: 		0.0877      	0.1661      	0.1645      
2023-06-15 19:18:16.240: my pid: 7296
2023-06-15 19:18:16.241: model: model.general_recommender.SGL
2023-06-15 19:18:16.241: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 19:18:16.241: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 19:18:21.012: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 19:18:58.896: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 37.882657]
2023-06-15 19:18:59.305: epoch 1:	0.00305650  	0.00766221  	0.00603154  
2023-06-15 19:18:59.305: Find a better model.
2023-06-15 19:19:36.914: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 37.601813]
2023-06-15 19:19:37.320: epoch 2:	0.00394282  	0.00949738  	0.00765707  
2023-06-15 19:19:37.320: Find a better model.
2023-06-15 19:20:15.236: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 37.909045]
2023-06-15 19:20:15.647: epoch 3:	0.00468948  	0.01013406  	0.00875677  
2023-06-15 19:20:15.647: Find a better model.
2023-06-15 19:20:53.625: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 37.972506]
2023-06-15 19:20:54.033: epoch 4:	0.00511922  	0.01161769  	0.00945804  
2023-06-15 19:20:54.033: Find a better model.
2023-06-15 19:21:31.901: [iter 5 : loss : 1.6053 = 0.6929 + 0.9123 + 0.0000, time: 37.861336]
2023-06-15 19:21:32.307: epoch 5:	0.00634395  	0.01367284  	0.01157503  
2023-06-15 19:21:32.307: Find a better model.
2023-06-15 19:22:10.067: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 37.753886]
2023-06-15 19:22:10.477: epoch 6:	0.00695632  	0.01557123  	0.01309450  
2023-06-15 19:22:10.477: Find a better model.
2023-06-15 19:22:48.327: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 37.843095]
2023-06-15 19:22:48.737: epoch 7:	0.00777823  	0.01688768  	0.01454398  
2023-06-15 19:22:48.737: Find a better model.
2023-06-15 19:23:26.376: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 37.632881]
2023-06-15 19:23:26.781: epoch 8:	0.00860551  	0.01855218  	0.01603965  
2023-06-15 19:23:26.782: Find a better model.
2023-06-15 19:24:04.690: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 37.902321]
2023-06-15 19:24:05.094: epoch 9:	0.01022783  	0.02175437  	0.01850762  
2023-06-15 19:24:05.094: Find a better model.
2023-06-15 19:24:42.854: [iter 10 : loss : 1.6052 = 0.6923 + 0.9128 + 0.0000, time: 37.753908]
2023-06-15 19:24:43.257: epoch 10:	0.01167822  	0.02480207  	0.02185698  
2023-06-15 19:24:43.257: Find a better model.
2023-06-15 19:25:22.015: [iter 11 : loss : 1.6049 = 0.6921 + 0.9128 + 0.0000, time: 38.734874]
2023-06-15 19:25:22.426: epoch 11:	0.01445013  	0.03079781  	0.02788438  
2023-06-15 19:25:22.427: Find a better model.
2023-06-15 19:26:01.013: [iter 12 : loss : 1.6048 = 0.6917 + 0.9131 + 0.0000, time: 38.579045]
2023-06-15 19:26:01.417: epoch 12:	0.01777000  	0.03769938  	0.03411731  
2023-06-15 19:26:01.417: Find a better model.
2023-06-15 19:26:40.006: [iter 13 : loss : 1.6044 = 0.6911 + 0.9133 + 0.0000, time: 38.582664]
2023-06-15 19:26:40.408: epoch 13:	0.02191170  	0.04637385  	0.04293881  
2023-06-15 19:26:40.408: Find a better model.
2023-06-15 19:27:19.123: [iter 14 : loss : 1.6038 = 0.6901 + 0.9136 + 0.0000, time: 38.707766]
2023-06-15 19:27:19.525: epoch 14:	0.02736415  	0.05727971  	0.05434175  
2023-06-15 19:27:19.525: Find a better model.
2023-06-15 19:27:58.387: [iter 15 : loss : 1.6025 = 0.6884 + 0.9141 + 0.0001, time: 38.855792]
2023-06-15 19:27:58.801: epoch 15:	0.03524918  	0.07278279  	0.07043840  
2023-06-15 19:27:58.801: Find a better model.
2023-06-15 19:28:37.305: [iter 16 : loss : 1.5998 = 0.6850 + 0.9147 + 0.0001, time: 38.489509]
2023-06-15 19:28:37.712: epoch 16:	0.04577195  	0.09314413  	0.09109279  
2023-06-15 19:28:37.712: Find a better model.
2023-06-15 19:29:16.371: [iter 17 : loss : 1.5936 = 0.6776 + 0.9159 + 0.0001, time: 38.651805]
2023-06-15 19:29:16.776: epoch 17:	0.05770743  	0.11317539  	0.11294675  
2023-06-15 19:29:16.776: Find a better model.
2023-06-15 19:29:55.272: [iter 18 : loss : 1.5797 = 0.6613 + 0.9181 + 0.0002, time: 38.490356]
2023-06-15 19:29:55.671: epoch 18:	0.06862766  	0.13210268  	0.13246575  
2023-06-15 19:29:55.671: Find a better model.
2023-06-15 19:30:34.278: [iter 19 : loss : 1.5512 = 0.6289 + 0.9219 + 0.0004, time: 38.599357]
2023-06-15 19:30:34.677: epoch 19:	0.07631960  	0.14507198  	0.14593752  
2023-06-15 19:30:34.678: Find a better model.
2023-06-15 19:31:13.340: [iter 20 : loss : 1.5060 = 0.5779 + 0.9274 + 0.0008, time: 38.655103]
2023-06-15 19:31:13.743: epoch 20:	0.08089070  	0.15243700  	0.15349767  
2023-06-15 19:31:13.743: Find a better model.
2023-06-15 19:31:52.447: [iter 21 : loss : 1.4500 = 0.5152 + 0.9337 + 0.0012, time: 38.696550]
2023-06-15 19:31:52.848: epoch 21:	0.08320041  	0.15677260  	0.15737449  
2023-06-15 19:31:52.848: Find a better model.
2023-06-15 19:32:31.694: [iter 22 : loss : 1.3936 = 0.4525 + 0.9394 + 0.0017, time: 38.839042]
2023-06-15 19:32:32.096: epoch 22:	0.08470989  	0.15997936  	0.15988162  
2023-06-15 19:32:32.096: Find a better model.
2023-06-15 19:33:10.682: [iter 23 : loss : 1.3432 = 0.3979 + 0.9431 + 0.0022, time: 38.579985]
2023-06-15 19:33:11.083: epoch 23:	0.08581641  	0.16259959  	0.16181235  
2023-06-15 19:33:11.083: Find a better model.
2023-06-15 19:33:49.804: [iter 24 : loss : 1.3001 = 0.3521 + 0.9453 + 0.0027, time: 38.714112]
2023-06-15 19:33:50.207: epoch 24:	0.08649863  	0.16358371  	0.16281191  
2023-06-15 19:33:50.208: Find a better model.
2023-06-15 19:34:28.853: [iter 25 : loss : 1.2643 = 0.3151 + 0.9460 + 0.0032, time: 38.638631]
2023-06-15 19:34:29.254: epoch 25:	0.08714862  	0.16520828  	0.16378251  
2023-06-15 19:34:29.254: Find a better model.
2023-06-15 19:35:07.800: [iter 26 : loss : 1.2335 = 0.2839 + 0.9460 + 0.0037, time: 38.538995]
2023-06-15 19:35:08.197: epoch 26:	0.08742267  	0.16552685  	0.16433075  
2023-06-15 19:35:08.197: Find a better model.
2023-06-15 19:35:46.829: [iter 27 : loss : 1.2076 = 0.2582 + 0.9454 + 0.0041, time: 38.624350]
2023-06-15 19:35:47.229: epoch 27:	0.08752482  	0.16573009  	0.16455251  
2023-06-15 19:35:47.229: Find a better model.
2023-06-15 19:36:26.007: [iter 28 : loss : 1.1860 = 0.2367 + 0.9447 + 0.0045, time: 38.770577]
2023-06-15 19:36:26.405: epoch 28:	0.08770742  	0.16619806  	0.16474144  
2023-06-15 19:36:26.405: Find a better model.
2023-06-15 19:37:04.948: [iter 29 : loss : 1.1674 = 0.2189 + 0.9436 + 0.0049, time: 38.537111]
2023-06-15 19:37:05.348: epoch 29:	0.08768591  	0.16607475  	0.16464894  
2023-06-15 19:37:44.112: [iter 30 : loss : 1.1512 = 0.2033 + 0.9426 + 0.0053, time: 38.757693]
2023-06-15 19:37:44.515: epoch 30:	0.08799740  	0.16630331  	0.16483504  
2023-06-15 19:37:44.515: Find a better model.
2023-06-15 19:38:23.133: [iter 31 : loss : 1.1362 = 0.1891 + 0.9414 + 0.0057, time: 38.610562]
2023-06-15 19:38:23.535: epoch 31:	0.08754627  	0.16536270  	0.16400969  
2023-06-15 19:39:02.123: [iter 32 : loss : 1.1244 = 0.1779 + 0.9405 + 0.0061, time: 38.581948]
2023-06-15 19:39:02.527: epoch 32:	0.08741194  	0.16507421  	0.16364084  
2023-06-15 19:39:41.481: [iter 33 : loss : 1.1127 = 0.1669 + 0.9395 + 0.0064, time: 38.947542]
2023-06-15 19:39:41.885: epoch 33:	0.08737423  	0.16469841  	0.16331191  
2023-06-15 19:40:20.765: [iter 34 : loss : 1.1034 = 0.1581 + 0.9385 + 0.0067, time: 38.872668]
2023-06-15 19:40:21.168: epoch 34:	0.08735286  	0.16429095  	0.16322106  
2023-06-15 19:41:00.032: [iter 35 : loss : 1.0943 = 0.1495 + 0.9377 + 0.0070, time: 38.858791]
2023-06-15 19:41:00.433: epoch 35:	0.08728299  	0.16370583  	0.16301161  
2023-06-15 19:41:39.030: [iter 36 : loss : 1.0864 = 0.1422 + 0.9369 + 0.0073, time: 38.589688]
2023-06-15 19:41:39.431: epoch 36:	0.08706285  	0.16288048  	0.16260372  
2023-06-15 19:42:18.029: [iter 37 : loss : 1.0788 = 0.1352 + 0.9359 + 0.0077, time: 38.591477]
2023-06-15 19:42:18.437: epoch 37:	0.08700910  	0.16260405  	0.16208579  
2023-06-15 19:42:57.230: [iter 38 : loss : 1.0726 = 0.1295 + 0.9352 + 0.0079, time: 38.785323]
2023-06-15 19:42:57.629: epoch 38:	0.08678347  	0.16208230  	0.16159548  
2023-06-15 19:43:36.620: [iter 39 : loss : 1.0670 = 0.1244 + 0.9344 + 0.0082, time: 38.985166]
2023-06-15 19:43:37.025: epoch 39:	0.08632687  	0.16096659  	0.16078955  
2023-06-15 19:44:16.010: [iter 40 : loss : 1.0614 = 0.1192 + 0.9338 + 0.0085, time: 38.978290]
2023-06-15 19:44:16.408: epoch 40:	0.08632690  	0.16047318  	0.16011702  
2023-06-15 19:44:55.138: [iter 41 : loss : 1.0563 = 0.1144 + 0.9331 + 0.0087, time: 38.722467]
2023-06-15 19:44:55.535: epoch 41:	0.08606362  	0.15964459  	0.15951608  
2023-06-15 19:45:34.172: [iter 42 : loss : 1.0518 = 0.1103 + 0.9325 + 0.0090, time: 38.630197]
2023-06-15 19:45:34.572: epoch 42:	0.08596154  	0.15915041  	0.15897517  
2023-06-15 19:46:14.773: [iter 43 : loss : 1.0472 = 0.1060 + 0.9320 + 0.0092, time: 40.194788]
2023-06-15 19:46:15.197: epoch 43:	0.08570907  	0.15836944  	0.15834844  
2023-06-15 19:46:31.267: my pid: 2108
2023-06-15 19:46:31.268: model: model.general_recommender.SGL
2023-06-15 19:46:31.268: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 19:46:31.268: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 19:46:36.520: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 19:47:14.776: [iter 1 : loss : 1.6081 = 0.6931 + 0.9149 + 0.0000, time: 38.255553]
2023-06-15 19:47:15.181: epoch 1:	0.00288461  	0.00801798  	0.00589164  
2023-06-15 19:47:15.181: Find a better model.
2023-06-15 19:47:52.992: [iter 2 : loss : 1.6057 = 0.6931 + 0.9126 + 0.0000, time: 37.803459]
2023-06-15 19:47:53.412: epoch 2:	0.00367961  	0.00988283  	0.00738443  
2023-06-15 19:47:53.412: Find a better model.
2023-06-15 19:48:31.574: [iter 3 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 38.155683]
2023-06-15 19:48:31.978: epoch 3:	0.00454445  	0.01104000  	0.00845225  
2023-06-15 19:48:31.979: Find a better model.
2023-06-15 19:49:09.729: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 37.743572]
2023-06-15 19:49:10.135: epoch 4:	0.00492047  	0.01159938  	0.00931328  
2023-06-15 19:49:10.135: Find a better model.
2023-06-15 19:49:47.943: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 37.801141]
2023-06-15 19:49:48.375: epoch 5:	0.00620429  	0.01488577  	0.01210053  
2023-06-15 19:49:48.375: Find a better model.
2023-06-15 19:50:26.333: [iter 6 : loss : 1.6054 = 0.6929 + 0.9125 + 0.0000, time: 37.951360]
2023-06-15 19:50:26.741: epoch 6:	0.00707988  	0.01620220  	0.01329413  
2023-06-15 19:50:26.742: Find a better model.
2023-06-15 19:51:04.749: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 38.001389]
2023-06-15 19:51:05.158: epoch 7:	0.00784269  	0.01846160  	0.01480722  
2023-06-15 19:51:05.159: Find a better model.
2023-06-15 19:51:43.060: [iter 8 : loss : 1.6052 = 0.6926 + 0.9126 + 0.0000, time: 37.893728]
2023-06-15 19:51:43.469: epoch 8:	0.00872906  	0.01916127  	0.01626716  
2023-06-15 19:51:43.469: Find a better model.
2023-06-15 19:52:21.472: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 37.996750]
2023-06-15 19:52:21.880: epoch 9:	0.01013650  	0.02281691  	0.01966269  
2023-06-15 19:52:21.880: Find a better model.
2023-06-15 19:52:59.918: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 38.032451]
2023-06-15 19:53:00.324: epoch 10:	0.01177493  	0.02609298  	0.02306260  
2023-06-15 19:53:00.324: Find a better model.
2023-06-15 19:53:39.107: [iter 11 : loss : 1.6049 = 0.6920 + 0.9129 + 0.0000, time: 38.776665]
2023-06-15 19:53:39.514: epoch 11:	0.01460591  	0.03223737  	0.02868553  
2023-06-15 19:53:39.514: Find a better model.
2023-06-15 19:54:18.017: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 38.497246]
2023-06-15 19:54:18.425: epoch 12:	0.01763566  	0.03734135  	0.03488232  
2023-06-15 19:54:18.425: Find a better model.
2023-06-15 19:54:57.225: [iter 13 : loss : 1.6043 = 0.6909 + 0.9134 + 0.0000, time: 38.793663]
2023-06-15 19:54:57.631: epoch 13:	0.02204601  	0.04807608  	0.04396785  
2023-06-15 19:54:57.631: Find a better model.
2023-06-15 19:55:36.416: [iter 14 : loss : 1.6036 = 0.6898 + 0.9137 + 0.0000, time: 38.778938]
2023-06-15 19:55:36.838: epoch 14:	0.02741247  	0.05854201  	0.05499824  
2023-06-15 19:55:36.838: Find a better model.
2023-06-15 19:56:15.429: [iter 15 : loss : 1.6021 = 0.6878 + 0.9142 + 0.0001, time: 38.585081]
2023-06-15 19:56:15.848: epoch 15:	0.03613008  	0.07498171  	0.07228982  
2023-06-15 19:56:15.848: Find a better model.
2023-06-15 19:56:54.601: [iter 16 : loss : 1.5989 = 0.6838 + 0.9150 + 0.0001, time: 38.745860]
2023-06-15 19:56:55.007: epoch 16:	0.04666896  	0.09410027  	0.09287252  
2023-06-15 19:56:55.008: Find a better model.
2023-06-15 19:57:33.781: [iter 17 : loss : 1.5917 = 0.6752 + 0.9163 + 0.0001, time: 38.765991]
2023-06-15 19:57:34.186: epoch 17:	0.05917918  	0.11625370  	0.11633170  
2023-06-15 19:57:34.186: Find a better model.
2023-06-15 19:58:12.756: [iter 18 : loss : 1.5755 = 0.6565 + 0.9187 + 0.0003, time: 38.563587]
2023-06-15 19:58:13.156: epoch 18:	0.06986842  	0.13398252  	0.13512228  
2023-06-15 19:58:13.156: Find a better model.
2023-06-15 19:58:51.925: [iter 19 : loss : 1.5440 = 0.6207 + 0.9228 + 0.0005, time: 38.763798]
2023-06-15 19:58:52.328: epoch 19:	0.07706643  	0.14594156  	0.14736921  
2023-06-15 19:58:52.328: Find a better model.
2023-06-15 19:59:31.178: [iter 20 : loss : 1.4966 = 0.5671 + 0.9287 + 0.0008, time: 38.842841]
2023-06-15 19:59:31.574: epoch 20:	0.08108430  	0.15271387  	0.15437819  
2023-06-15 19:59:31.574: Find a better model.
2023-06-15 20:00:10.549: [iter 21 : loss : 1.4402 = 0.5038 + 0.9351 + 0.0013, time: 38.969506]
2023-06-15 20:00:10.944: epoch 21:	0.08329183  	0.15725783  	0.15818739  
2023-06-15 20:00:10.944: Find a better model.
2023-06-15 20:00:49.527: [iter 22 : loss : 1.3848 = 0.4424 + 0.9405 + 0.0018, time: 38.577657]
2023-06-15 20:00:49.924: epoch 22:	0.08487651  	0.15997605  	0.16049732  
2023-06-15 20:00:49.924: Find a better model.
2023-06-15 20:01:28.727: [iter 23 : loss : 1.3357 = 0.3895 + 0.9440 + 0.0023, time: 38.795835]
2023-06-15 20:01:29.125: epoch 23:	0.08584336  	0.16226491  	0.16219096  
2023-06-15 20:01:29.125: Find a better model.
2023-06-15 20:02:08.129: [iter 24 : loss : 1.2941 = 0.3455 + 0.9458 + 0.0028, time: 38.996590]
2023-06-15 20:02:08.526: epoch 24:	0.08655242  	0.16354941  	0.16312781  
2023-06-15 20:02:08.526: Find a better model.
2023-06-15 20:02:47.521: [iter 25 : loss : 1.2593 = 0.3098 + 0.9462 + 0.0033, time: 38.988729]
2023-06-15 20:02:47.915: epoch 25:	0.08711641  	0.16492452  	0.16403738  
2023-06-15 20:02:47.915: Find a better model.
2023-06-15 20:03:26.678: [iter 26 : loss : 1.2293 = 0.2795 + 0.9461 + 0.0037, time: 38.757027]
2023-06-15 20:03:27.076: epoch 26:	0.08735272  	0.16536069  	0.16434440  
2023-06-15 20:03:27.076: Find a better model.
2023-06-15 20:04:05.670: [iter 27 : loss : 1.2044 = 0.2548 + 0.9454 + 0.0042, time: 38.586648]
2023-06-15 20:04:06.067: epoch 27:	0.08739571  	0.16516238  	0.16418360  
2023-06-15 20:04:44.846: [iter 28 : loss : 1.1833 = 0.2340 + 0.9447 + 0.0046, time: 38.772016]
2023-06-15 20:04:45.245: epoch 28:	0.08776636  	0.16572686  	0.16444097  
2023-06-15 20:04:45.245: Find a better model.
2023-06-15 20:05:24.022: [iter 29 : loss : 1.1652 = 0.2166 + 0.9436 + 0.0050, time: 38.769583]
2023-06-15 20:05:24.441: epoch 29:	0.08777709  	0.16582817  	0.16436340  
2023-06-15 20:05:24.441: Find a better model.
2023-06-15 20:06:04.099: [iter 30 : loss : 1.1492 = 0.2012 + 0.9426 + 0.0054, time: 39.652539]
2023-06-15 20:06:04.504: epoch 30:	0.08768572  	0.16521154  	0.16421255  
2023-06-15 20:06:46.980: [iter 31 : loss : 1.1346 = 0.1873 + 0.9415 + 0.0058, time: 42.468516]
2023-06-15 20:06:47.670: epoch 31:	0.08764810  	0.16487350  	0.16362655  
2023-06-15 20:07:29.897: [iter 32 : loss : 1.1228 = 0.1763 + 0.9404 + 0.0061, time: 42.220907]
2023-06-15 20:07:30.440: epoch 32:	0.08765354  	0.16473846  	0.16341087  
2023-06-15 20:08:15.583: [iter 33 : loss : 1.1114 = 0.1655 + 0.9394 + 0.0065, time: 45.118317]
2023-06-15 20:08:15.990: epoch 33:	0.08738498  	0.16405654  	0.16291171  
2023-06-15 20:09:03.522: [iter 34 : loss : 1.1025 = 0.1572 + 0.9384 + 0.0068, time: 47.524785]
2023-06-15 20:09:03.981: epoch 34:	0.08723992  	0.16349784  	0.16246794  
2023-06-15 20:09:12.234: my pid: 11952
2023-06-15 20:09:12.234: model: model.general_recommender.SGL
2023-06-15 20:09:12.234: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 20:09:12.234: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 20:09:18.045: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 20:10:03.078: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 45.031599]
2023-06-15 20:10:03.496: epoch 1:	0.00300278  	0.00900967  	0.00640522  
2023-06-15 20:10:03.496: Find a better model.
2023-06-15 20:10:47.963: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 44.459049]
2023-06-15 20:10:48.385: epoch 2:	0.00379779  	0.01046421  	0.00795091  
2023-06-15 20:10:48.385: Find a better model.
2023-06-15 20:11:28.110: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 39.707606]
2023-06-15 20:11:28.736: epoch 3:	0.00430272  	0.01176009  	0.00910888  
2023-06-15 20:11:28.736: Find a better model.
2023-06-15 20:12:08.475: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 39.731546]
2023-06-15 20:12:08.896: epoch 4:	0.00467337  	0.01201221  	0.00938729  
2023-06-15 20:12:08.896: Find a better model.
2023-06-15 20:12:52.577: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 43.674854]
2023-06-15 20:12:52.994: epoch 5:	0.00504938  	0.01277854  	0.01019857  
2023-06-15 20:12:52.994: Find a better model.
2023-06-15 20:13:37.471: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 44.469648]
2023-06-15 20:13:37.915: epoch 6:	0.00613446  	0.01527448  	0.01230637  
2023-06-15 20:13:37.915: Find a better model.
2023-06-15 20:14:17.575: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.653008]
2023-06-15 20:14:18.107: epoch 7:	0.00664476  	0.01633241  	0.01333372  
2023-06-15 20:14:18.107: Find a better model.
2023-06-15 20:14:58.508: [iter 8 : loss : 1.6052 = 0.6926 + 0.9125 + 0.0000, time: 40.393890]
2023-06-15 20:14:58.933: epoch 8:	0.00757947  	0.01876265  	0.01498748  
2023-06-15 20:14:58.934: Find a better model.
2023-06-15 20:15:43.553: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 44.611636]
2023-06-15 20:15:43.996: epoch 9:	0.00879353  	0.02168391  	0.01758640  
2023-06-15 20:15:43.996: Find a better model.
2023-06-15 20:16:28.273: [iter 10 : loss : 1.6052 = 0.6923 + 0.9128 + 0.0000, time: 44.265599]
2023-06-15 20:16:28.911: epoch 10:	0.00993775  	0.02414144  	0.02015172  
2023-06-15 20:16:28.911: Find a better model.
2023-06-15 20:17:10.242: [iter 11 : loss : 1.6049 = 0.6920 + 0.9129 + 0.0000, time: 41.323975]
2023-06-15 20:17:10.657: epoch 11:	0.01230674  	0.02829974  	0.02497199  
2023-06-15 20:17:10.657: Find a better model.
2023-06-15 20:17:52.878: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 42.212856]
2023-06-15 20:17:53.720: epoch 12:	0.01571253  	0.03500619  	0.03101219  
2023-06-15 20:17:53.720: Find a better model.
2023-06-15 20:18:39.193: [iter 13 : loss : 1.6044 = 0.6910 + 0.9134 + 0.0000, time: 45.465117]
2023-06-15 20:18:39.661: epoch 13:	0.01962329  	0.04387646  	0.03955731  
2023-06-15 20:18:39.661: Find a better model.
2023-06-15 20:19:25.362: [iter 14 : loss : 1.6037 = 0.6899 + 0.9137 + 0.0000, time: 45.692225]
2023-06-15 20:19:26.010: epoch 14:	0.02498444  	0.05460459  	0.05086988  
2023-06-15 20:19:26.011: Find a better model.
2023-06-15 20:20:07.337: [iter 15 : loss : 1.6022 = 0.6880 + 0.9141 + 0.0001, time: 41.318379]
2023-06-15 20:20:07.748: epoch 15:	0.03430926  	0.07268242  	0.06852400  
2023-06-15 20:20:07.748: Find a better model.
2023-06-15 20:20:49.955: [iter 16 : loss : 1.5992 = 0.6842 + 0.9149 + 0.0001, time: 42.198389]
2023-06-15 20:20:50.836: epoch 16:	0.04484803  	0.09154040  	0.08951186  
2023-06-15 20:20:50.836: Find a better model.
2023-06-15 20:21:36.070: [iter 17 : loss : 1.5923 = 0.6761 + 0.9161 + 0.0001, time: 45.226876]
2023-06-15 20:21:36.542: epoch 17:	0.05763221  	0.11297540  	0.11287289  
2023-06-15 20:21:36.542: Find a better model.
2023-06-15 20:22:22.561: [iter 18 : loss : 1.5769 = 0.6581 + 0.9185 + 0.0003, time: 46.011039]
2023-06-15 20:22:23.070: epoch 18:	0.06864911  	0.13075735  	0.13205625  
2023-06-15 20:22:23.070: Find a better model.
2023-06-15 20:23:04.805: [iter 19 : loss : 1.5462 = 0.6231 + 0.9226 + 0.0005, time: 41.727113]
2023-06-15 20:23:05.226: epoch 19:	0.07605109  	0.14275266  	0.14514396  
2023-06-15 20:23:05.226: Find a better model.
2023-06-15 20:23:47.434: [iter 20 : loss : 1.4993 = 0.5697 + 0.9288 + 0.0008, time: 42.201096]
2023-06-15 20:23:47.981: epoch 20:	0.08063304  	0.15113403  	0.15286368  
2023-06-15 20:23:47.981: Find a better model.
2023-06-15 20:24:33.501: [iter 21 : loss : 1.4432 = 0.5066 + 0.9353 + 0.0013, time: 45.511631]
2023-06-15 20:24:33.947: epoch 21:	0.08300734  	0.15572263  	0.15701869  
2023-06-15 20:24:33.948: Find a better model.
2023-06-15 20:25:19.396: [iter 22 : loss : 1.3877 = 0.4452 + 0.9408 + 0.0017, time: 45.440578]
2023-06-15 20:25:19.973: epoch 22:	0.08456505  	0.15901144  	0.15991563  
2023-06-15 20:25:19.973: Find a better model.
2023-06-15 20:26:01.512: [iter 23 : loss : 1.3388 = 0.3924 + 0.9441 + 0.0023, time: 41.531936]
2023-06-15 20:26:01.961: epoch 23:	0.08576291  	0.16122280  	0.16186625  
2023-06-15 20:26:01.962: Find a better model.
2023-06-15 20:26:43.231: [iter 24 : loss : 1.2970 = 0.3482 + 0.9460 + 0.0028, time: 41.263042]
2023-06-15 20:26:43.675: epoch 24:	0.08657392  	0.16332126  	0.16317570  
2023-06-15 20:26:43.675: Find a better model.
2023-06-15 20:27:28.691: [iter 25 : loss : 1.2622 = 0.3126 + 0.9464 + 0.0032, time: 45.009874]
2023-06-15 20:27:29.130: epoch 25:	0.08714323  	0.16437705  	0.16395923  
2023-06-15 20:27:29.131: Find a better model.
2023-06-15 20:28:14.976: [iter 26 : loss : 1.2322 = 0.2823 + 0.9463 + 0.0037, time: 45.839073]
2023-06-15 20:28:15.818: epoch 26:	0.08748703  	0.16480225  	0.16480573  
2023-06-15 20:28:15.819: Find a better model.
2023-06-15 20:28:57.169: [iter 27 : loss : 1.2069 = 0.2571 + 0.9456 + 0.0041, time: 41.343815]
2023-06-15 20:28:57.819: epoch 27:	0.08755685  	0.16475835  	0.16480003  
2023-06-15 20:29:38.888: [iter 28 : loss : 1.1854 = 0.2360 + 0.9448 + 0.0046, time: 41.060418]
2023-06-15 20:29:39.389: epoch 28:	0.08782005  	0.16503726  	0.16540498  
2023-06-15 20:29:39.389: Find a better model.
2023-06-15 20:30:23.535: [iter 29 : loss : 1.1671 = 0.2184 + 0.9437 + 0.0050, time: 44.127983]
2023-06-15 20:30:23.954: epoch 29:	0.08800808  	0.16534814  	0.16541681  
2023-06-15 20:30:23.954: Find a better model.
2023-06-15 20:31:09.810: [iter 30 : loss : 1.1512 = 0.2031 + 0.9427 + 0.0054, time: 45.849656]
2023-06-15 20:31:10.211: epoch 30:	0.08787915  	0.16534831  	0.16498356  
2023-06-15 20:31:10.211: Find a better model.
2023-06-15 20:31:52.323: [iter 31 : loss : 1.1362 = 0.1889 + 0.9416 + 0.0057, time: 42.103742]
2023-06-15 20:31:52.950: epoch 31:	0.08769110  	0.16479339  	0.16449943  
2023-06-15 20:32:31.795: [iter 32 : loss : 1.1243 = 0.1777 + 0.9405 + 0.0061, time: 38.838110]
2023-06-15 20:32:32.197: epoch 32:	0.08783077  	0.16475488  	0.16436838  
2023-06-15 20:33:11.844: [iter 33 : loss : 1.1129 = 0.1668 + 0.9396 + 0.0064, time: 39.639180]
2023-06-15 20:33:12.241: epoch 33:	0.08775026  	0.16433032  	0.16384074  
2023-06-15 20:33:52.178: [iter 34 : loss : 1.1037 = 0.1583 + 0.9387 + 0.0068, time: 39.930794]
2023-06-15 20:33:52.613: epoch 34:	0.08765354  	0.16400732  	0.16346990  
2023-06-15 20:34:32.612: [iter 35 : loss : 1.0942 = 0.1493 + 0.9379 + 0.0071, time: 39.991682]
2023-06-15 20:34:33.013: epoch 35:	0.08768046  	0.16382632  	0.16303708  
2023-06-15 20:35:13.103: [iter 36 : loss : 1.0865 = 0.1422 + 0.9369 + 0.0074, time: 40.082716]
2023-06-15 20:35:13.541: epoch 36:	0.08734737  	0.16278507  	0.16229130  
2023-06-15 20:35:59.298: [iter 37 : loss : 1.0791 = 0.1353 + 0.9361 + 0.0077, time: 45.750233]
2023-06-15 20:35:59.732: epoch 37:	0.08728286  	0.16201839  	0.16181372  
2023-06-15 20:36:46.199: [iter 38 : loss : 1.0727 = 0.1295 + 0.9353 + 0.0080, time: 46.459887]
2023-06-15 20:36:46.654: epoch 38:	0.08691226  	0.16107200  	0.16108298  
2023-06-15 20:37:28.992: [iter 39 : loss : 1.0670 = 0.1242 + 0.9345 + 0.0082, time: 42.332006]
2023-06-15 20:37:29.662: epoch 39:	0.08652018  	0.15963714  	0.16016953  
2023-06-15 20:38:11.053: [iter 40 : loss : 1.0617 = 0.1193 + 0.9339 + 0.0085, time: 41.382087]
2023-06-15 20:38:11.527: epoch 40:	0.08652558  	0.15962669  	0.15983018  
2023-06-15 20:38:55.371: [iter 41 : loss : 1.0563 = 0.1143 + 0.9332 + 0.0088, time: 43.820187]
2023-06-15 20:38:55.819: epoch 41:	0.08641270  	0.15897734  	0.15931375  
2023-06-15 20:39:43.084: [iter 42 : loss : 1.0523 = 0.1106 + 0.9327 + 0.0090, time: 47.256455]
2023-06-15 20:39:43.584: epoch 42:	0.08617097  	0.15831968  	0.15878116  
2023-06-15 20:40:30.606: [iter 43 : loss : 1.0476 = 0.1063 + 0.9321 + 0.0093, time: 47.014207]
2023-06-15 20:40:31.121: epoch 43:	0.08598299  	0.15786278  	0.15841630  
2023-06-15 20:41:13.428: [iter 44 : loss : 1.0436 = 0.1025 + 0.9316 + 0.0095, time: 42.295148]
2023-06-15 20:41:14.106: epoch 44:	0.08563383  	0.15687945  	0.15765229  
2023-06-15 20:41:55.908: [iter 45 : loss : 1.0406 = 0.0997 + 0.9311 + 0.0097, time: 41.793674]
2023-06-15 20:41:56.353: epoch 45:	0.08533309  	0.15596096  	0.15708861  
2023-06-15 20:42:40.202: [iter 46 : loss : 1.0369 = 0.0964 + 0.9306 + 0.0100, time: 43.841776]
2023-06-15 20:42:40.914: epoch 46:	0.08485497  	0.15496124  	0.15616380  
2023-06-15 20:43:27.121: [iter 47 : loss : 1.0342 = 0.0938 + 0.9302 + 0.0102, time: 46.199498]
2023-06-15 20:43:27.628: epoch 47:	0.08462398  	0.15440892  	0.15574570  
2023-06-15 20:44:15.045: [iter 48 : loss : 1.0306 = 0.0905 + 0.9297 + 0.0104, time: 47.409779]
2023-06-15 20:44:15.574: epoch 48:	0.08450579  	0.15374915  	0.15517139  
2023-06-15 20:44:58.308: [iter 49 : loss : 1.0281 = 0.0881 + 0.9294 + 0.0106, time: 42.723534]
2023-06-15 20:44:58.842: epoch 49:	0.08425868  	0.15295093  	0.15432453  
2023-06-15 20:45:41.933: [iter 50 : loss : 1.0256 = 0.0858 + 0.9289 + 0.0108, time: 43.084195]
2023-06-15 20:45:42.436: epoch 50:	0.08399006  	0.15222634  	0.15383415  
2023-06-15 20:46:27.490: [iter 51 : loss : 1.0231 = 0.0835 + 0.9287 + 0.0110, time: 45.046197]
2023-06-15 20:46:27.913: epoch 51:	0.08380207  	0.15162238  	0.15318322  
2023-06-15 20:47:14.126: [iter 52 : loss : 1.0209 = 0.0813 + 0.9284 + 0.0112, time: 46.205905]
2023-06-15 20:47:14.586: epoch 52:	0.08364099  	0.15122363  	0.15273911  
2023-06-15 20:48:00.081: [iter 53 : loss : 1.0188 = 0.0794 + 0.9280 + 0.0114, time: 45.485897]
2023-06-15 20:48:00.753: epoch 53:	0.08350674  	0.15075518  	0.15228736  
2023-06-15 20:48:43.948: [iter 54 : loss : 1.0162 = 0.0769 + 0.9277 + 0.0116, time: 43.187476]
2023-06-15 20:48:44.378: epoch 54:	0.08317907  	0.14978647  	0.15148146  
2023-06-15 20:49:27.727: [iter 55 : loss : 1.0149 = 0.0757 + 0.9275 + 0.0117, time: 43.341709]
2023-06-15 20:49:28.394: epoch 55:	0.08286753  	0.14895669  	0.15087995  
2023-06-15 20:49:28.394: Early stopping is trigger at epoch: 55
2023-06-15 20:49:28.394: best_result@epoch 30:

2023-06-15 20:49:28.394: 		0.0879      	0.1653      	0.1650      
2023-06-15 20:51:40.197: my pid: 10784
2023-06-15 20:51:40.197: model: model.general_recommender.SGL
2023-06-15 20:51:40.197: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 20:51:40.197: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 20:51:45.809: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 20:52:28.330: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 42.520271]
2023-06-15 20:52:28.767: epoch 1:	0.00266437  	0.00858730  	0.00583589  
2023-06-15 20:52:28.767: Find a better model.
2023-06-15 20:53:14.059: [iter 2 : loss : 1.6055 = 0.6931 + 0.9124 + 0.0000, time: 45.284279]
2023-06-15 20:53:14.613: epoch 2:	0.00302964  	0.00930261  	0.00652192  
2023-06-15 20:53:14.613: Find a better model.
2023-06-15 20:53:57.889: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 43.260367]
2023-06-15 20:53:58.613: epoch 3:	0.00403951  	0.01119749  	0.00855453  
2023-06-15 20:53:58.613: Find a better model.
2023-06-15 20:54:44.440: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 45.819616]
2023-06-15 20:54:44.875: epoch 4:	0.00449073  	0.01226099  	0.00940068  
2023-06-15 20:54:44.875: Find a better model.
2023-06-15 20:55:26.228: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 41.344715]
2023-06-15 20:55:26.908: epoch 5:	0.00544152  	0.01411084  	0.01147060  
2023-06-15 20:55:26.908: Find a better model.
2023-06-15 20:56:07.323: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 40.406919]
2023-06-15 20:56:07.759: epoch 6:	0.00623115  	0.01626450  	0.01310461  
2023-06-15 20:56:07.759: Find a better model.
2023-06-15 20:56:52.097: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 44.329690]
2023-06-15 20:56:52.555: epoch 7:	0.00695095  	0.01760466  	0.01425795  
2023-06-15 20:56:52.555: Find a better model.
2023-06-15 20:57:37.561: [iter 8 : loss : 1.6051 = 0.6927 + 0.9125 + 0.0000, time: 44.999957]
2023-06-15 20:57:37.982: epoch 8:	0.00754724  	0.01903015  	0.01565808  
2023-06-15 20:57:37.982: Find a better model.
2023-06-15 20:58:18.296: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 40.305693]
2023-06-15 20:58:18.967: epoch 9:	0.00916419  	0.02256574  	0.01837139  
2023-06-15 20:58:18.967: Find a better model.
2023-06-15 20:58:59.375: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 40.400821]
2023-06-15 20:58:59.876: epoch 10:	0.00993774  	0.02486652  	0.02068479  
2023-06-15 20:58:59.876: Find a better model.
2023-06-15 20:59:44.781: [iter 11 : loss : 1.6049 = 0.6920 + 0.9128 + 0.0000, time: 44.898576]
2023-06-15 20:59:45.224: epoch 11:	0.01282243  	0.03156661  	0.02657807  
2023-06-15 20:59:45.224: Find a better model.
2023-06-15 21:00:31.237: [iter 12 : loss : 1.6047 = 0.6916 + 0.9130 + 0.0000, time: 46.006906]
2023-06-15 21:00:31.677: epoch 12:	0.01610470  	0.03752849  	0.03230973  
2023-06-15 21:00:31.678: Find a better model.
2023-06-15 21:01:17.405: [iter 13 : loss : 1.6043 = 0.6910 + 0.9133 + 0.0000, time: 45.721076]
2023-06-15 21:01:18.053: epoch 13:	0.01927414  	0.04560382  	0.03927362  
2023-06-15 21:01:18.053: Find a better model.
2023-06-15 21:01:59.902: [iter 14 : loss : 1.6036 = 0.6899 + 0.9137 + 0.0000, time: 41.842425]
2023-06-15 21:02:00.578: epoch 14:	0.02480179  	0.05689928  	0.05157372  
2023-06-15 21:02:00.579: Find a better model.
2023-06-15 21:02:42.142: [iter 15 : loss : 1.6023 = 0.6881 + 0.9141 + 0.0001, time: 41.555803]
2023-06-15 21:02:42.739: epoch 15:	0.03299868  	0.07158524  	0.06774956  
2023-06-15 21:02:42.739: Find a better model.
2023-06-15 21:03:26.411: [iter 16 : loss : 1.5994 = 0.6844 + 0.9149 + 0.0001, time: 43.660546]
2023-06-15 21:03:26.835: epoch 16:	0.04423031  	0.09220731  	0.08911142  
2023-06-15 21:03:26.835: Find a better model.
2023-06-15 21:04:13.248: [iter 17 : loss : 1.5929 = 0.6766 + 0.9161 + 0.0001, time: 46.404006]
2023-06-15 21:04:13.737: epoch 17:	0.05698765  	0.11340795  	0.11258595  
2023-06-15 21:04:13.737: Find a better model.
2023-06-15 21:04:59.546: [iter 18 : loss : 1.5784 = 0.6596 + 0.9186 + 0.0002, time: 45.801966]
2023-06-15 21:05:00.198: epoch 18:	0.06848270  	0.13130793  	0.13182063  
2023-06-15 21:05:00.199: Find a better model.
2023-06-15 21:05:42.556: [iter 19 : loss : 1.5494 = 0.6265 + 0.9224 + 0.0005, time: 42.347402]
2023-06-15 21:05:43.198: epoch 19:	0.07557846  	0.14267246  	0.14448507  
2023-06-15 21:05:43.198: Find a better model.
2023-06-15 21:06:25.442: [iter 20 : loss : 1.5043 = 0.5754 + 0.9281 + 0.0008, time: 42.238009]
2023-06-15 21:06:25.954: epoch 20:	0.08000454  	0.15041225  	0.15201555  
2023-06-15 21:06:25.954: Find a better model.
2023-06-15 21:07:10.492: [iter 21 : loss : 1.4496 = 0.5139 + 0.9345 + 0.0012, time: 44.530058]
2023-06-15 21:07:10.913: epoch 21:	0.08253993  	0.15437175  	0.15604623  
2023-06-15 21:07:10.913: Find a better model.
2023-06-15 21:07:57.095: [iter 22 : loss : 1.3943 = 0.4527 + 0.9399 + 0.0017, time: 46.174524]
2023-06-15 21:07:57.743: epoch 22:	0.08430713  	0.15883137  	0.15904965  
2023-06-15 21:07:57.745: Find a better model.
2023-06-15 21:08:43.008: [iter 23 : loss : 1.3448 = 0.3992 + 0.9434 + 0.0022, time: 45.208013]
2023-06-15 21:08:43.652: epoch 23:	0.08563389  	0.16163619  	0.16113311  
2023-06-15 21:08:43.652: Find a better model.
2023-06-15 21:09:25.965: [iter 24 : loss : 1.3019 = 0.3537 + 0.9455 + 0.0027, time: 42.307624]
2023-06-15 21:09:26.388: epoch 24:	0.08634289  	0.16329606  	0.16243373  
2023-06-15 21:09:26.388: Find a better model.
2023-06-15 21:10:09.054: [iter 25 : loss : 1.2666 = 0.3172 + 0.9462 + 0.0032, time: 42.658156]
2023-06-15 21:10:09.515: epoch 25:	0.08691766  	0.16452262  	0.16332716  
2023-06-15 21:10:09.515: Find a better model.
2023-06-15 21:10:55.523: [iter 26 : loss : 1.2359 = 0.2861 + 0.9462 + 0.0037, time: 45.994291]
2023-06-15 21:10:55.959: epoch 26:	0.08752471  	0.16554451  	0.16376990  
2023-06-15 21:10:55.959: Find a better model.
2023-06-15 21:11:42.665: [iter 27 : loss : 1.2100 = 0.2603 + 0.9457 + 0.0041, time: 46.698350]
2023-06-15 21:11:43.086: epoch 27:	0.08762678  	0.16571674  	0.16378747  
2023-06-15 21:11:43.086: Find a better model.
2023-06-15 21:12:26.309: [iter 28 : loss : 1.1882 = 0.2387 + 0.9450 + 0.0045, time: 43.215271]
2023-06-15 21:12:26.967: epoch 28:	0.08780935  	0.16583006  	0.16403730  
2023-06-15 21:12:26.967: Find a better model.
2023-06-15 21:13:09.070: [iter 29 : loss : 1.1695 = 0.2206 + 0.9439 + 0.0049, time: 42.094908]
2023-06-15 21:13:09.483: epoch 29:	0.08804038  	0.16589536  	0.16434892  
2023-06-15 21:13:09.484: Find a better model.
2023-06-15 21:13:52.879: [iter 30 : loss : 1.1530 = 0.2047 + 0.9430 + 0.0053, time: 43.379202]
2023-06-15 21:13:53.332: epoch 30:	0.08806719  	0.16583927  	0.16416851  
2023-06-15 21:14:39.720: [iter 31 : loss : 1.1380 = 0.1904 + 0.9419 + 0.0057, time: 46.381644]
2023-06-15 21:14:40.145: epoch 31:	0.08818534  	0.16575450  	0.16413794  
2023-06-15 21:15:27.112: [iter 32 : loss : 1.1258 = 0.1789 + 0.9409 + 0.0060, time: 46.961307]
2023-06-15 21:15:27.570: epoch 32:	0.08805110  	0.16509771  	0.16365974  
2023-06-15 21:16:10.608: [iter 33 : loss : 1.1141 = 0.1678 + 0.9399 + 0.0064, time: 43.031186]
2023-06-15 21:16:11.241: epoch 33:	0.08780944  	0.16453505  	0.16312875  
2023-06-15 21:16:54.186: [iter 34 : loss : 1.1049 = 0.1592 + 0.9389 + 0.0067, time: 42.938126]
2023-06-15 21:16:54.977: epoch 34:	0.08774497  	0.16423288  	0.16281430  
2023-06-15 21:17:40.484: [iter 35 : loss : 1.0953 = 0.1502 + 0.9381 + 0.0070, time: 45.498325]
2023-06-15 21:17:41.111: epoch 35:	0.08771279  	0.16365500  	0.16245785  
2023-06-15 21:18:22.871: [iter 36 : loss : 1.0874 = 0.1428 + 0.9372 + 0.0073, time: 41.751046]
2023-06-15 21:18:23.282: epoch 36:	0.08761611  	0.16299275  	0.16201270  
2023-06-15 21:19:05.617: [iter 37 : loss : 1.0798 = 0.1358 + 0.9364 + 0.0076, time: 42.327413]
2023-06-15 21:19:06.072: epoch 37:	0.08730455  	0.16205470  	0.16129678  
2023-06-15 21:19:50.575: [iter 38 : loss : 1.0736 = 0.1301 + 0.9356 + 0.0079, time: 44.496376]
2023-06-15 21:19:51.007: epoch 38:	0.08692856  	0.16115920  	0.16047247  
2023-06-15 21:20:27.721: my pid: 11380
2023-06-15 21:20:27.721: model: model.general_recommender.SGL
2023-06-15 21:20:27.721: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-15 21:20:27.722: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-15 21:20:33.433: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-15 21:21:19.722: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 46.279723]
2023-06-15 21:21:20.299: epoch 1:	0.00279866  	0.00849293  	0.00621043  
2023-06-15 21:21:20.299: Find a better model.
2023-06-15 21:22:00.997: [iter 2 : loss : 1.6055 = 0.6931 + 0.9124 + 0.0000, time: 40.690200]
2023-06-15 21:22:01.652: epoch 2:	0.00344863  	0.01026127  	0.00750719  
2023-06-15 21:22:01.652: Find a better model.
2023-06-15 21:22:42.554: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 40.895653]
2023-06-15 21:22:42.991: epoch 3:	0.00391596  	0.01126966  	0.00852381  
2023-06-15 21:22:42.991: Find a better model.
2023-06-15 21:23:26.656: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 43.657242]
2023-06-15 21:23:27.087: epoch 4:	0.00435107  	0.01202363  	0.00938878  
2023-06-15 21:23:27.087: Find a better model.
2023-06-15 21:24:12.395: [iter 5 : loss : 1.6052 = 0.6929 + 0.9122 + 0.0000, time: 45.301739]
2023-06-15 21:24:13.007: epoch 5:	0.00511922  	0.01487574  	0.01121951  
2023-06-15 21:24:13.007: Find a better model.
2023-06-15 21:24:57.871: [iter 6 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 44.856290]
2023-06-15 21:24:58.538: epoch 6:	0.00593033  	0.01599761  	0.01249782  
2023-06-15 21:24:58.538: Find a better model.
2023-06-15 21:25:40.228: [iter 7 : loss : 1.6052 = 0.6928 + 0.9125 + 0.0000, time: 41.682158]
2023-06-15 21:25:40.673: epoch 7:	0.00660716  	0.01772829  	0.01412554  
2023-06-15 21:25:40.673: Find a better model.
2023-06-15 21:26:22.743: [iter 8 : loss : 1.6051 = 0.6926 + 0.9124 + 0.0000, time: 42.064275]
2023-06-15 21:26:23.173: epoch 8:	0.00745592  	0.01982647  	0.01562363  
2023-06-15 21:26:23.173: Find a better model.
2023-06-15 21:27:08.685: [iter 9 : loss : 1.6052 = 0.6925 + 0.9127 + 0.0000, time: 45.502938]
2023-06-15 21:27:09.132: epoch 9:	0.00913195  	0.02266714  	0.01891566  
2023-06-15 21:27:09.132: Find a better model.
2023-06-15 21:27:55.067: [iter 10 : loss : 1.6050 = 0.6923 + 0.9127 + 0.0000, time: 45.926082]
2023-06-15 21:27:55.616: epoch 10:	0.01028154  	0.02551244  	0.02109152  
2023-06-15 21:27:55.616: Find a better model.
2023-06-15 21:28:38.292: [iter 11 : loss : 1.6048 = 0.6920 + 0.9127 + 0.0000, time: 42.667930]
2023-06-15 21:28:38.976: epoch 11:	0.01263442  	0.03031315  	0.02630696  
2023-06-15 21:28:38.976: Find a better model.
2023-06-15 21:29:21.597: [iter 12 : loss : 1.6046 = 0.6916 + 0.9130 + 0.0000, time: 42.614587]
2023-06-15 21:29:22.037: epoch 12:	0.01543855  	0.03539241  	0.03168043  
2023-06-15 21:29:22.037: Find a better model.
2023-06-15 21:30:07.188: [iter 13 : loss : 1.6043 = 0.6910 + 0.9132 + 0.0000, time: 45.144636]
2023-06-15 21:30:07.652: epoch 13:	0.01894642  	0.04342682  	0.03918988  
2023-06-15 21:30:07.652: Find a better model.
2023-06-15 21:30:53.955: [iter 14 : loss : 1.6036 = 0.6900 + 0.9135 + 0.0000, time: 46.297086]
2023-06-15 21:30:54.372: epoch 14:	0.02419476  	0.05317123  	0.04908108  
2023-06-15 21:30:54.372: Find a better model.
2023-06-15 21:31:38.097: [iter 15 : loss : 1.6022 = 0.6882 + 0.9140 + 0.0001, time: 43.715781]
2023-06-15 21:31:38.750: epoch 15:	0.03225204  	0.06910181  	0.06496648  
2023-06-15 21:31:38.751: Find a better model.
2023-06-15 21:32:21.122: [iter 16 : loss : 1.5995 = 0.6847 + 0.9147 + 0.0001, time: 42.363536]
2023-06-15 21:32:21.667: epoch 16:	0.04325808  	0.08899596  	0.08554383  
2023-06-15 21:32:21.668: Find a better model.
2023-06-15 21:33:05.435: [iter 17 : loss : 1.5932 = 0.6771 + 0.9160 + 0.0001, time: 43.759805]
2023-06-15 21:33:06.106: epoch 17:	0.05580058  	0.11158626  	0.10940561  
2023-06-15 21:33:06.106: Find a better model.
2023-06-15 21:33:53.307: [iter 18 : loss : 1.5790 = 0.6605 + 0.9182 + 0.0002, time: 47.192943]
2023-06-15 21:33:53.819: epoch 18:	0.06737601  	0.13094124  	0.13063249  
2023-06-15 21:33:53.819: Find a better model.
2023-06-15 21:34:41.133: [iter 19 : loss : 1.5501 = 0.6275 + 0.9221 + 0.0004, time: 47.306170]
2023-06-15 21:34:41.980: epoch 19:	0.07552465  	0.14323983  	0.14411843  
2023-06-15 21:34:41.981: Find a better model.
2023-06-15 21:35:25.304: [iter 20 : loss : 1.5046 = 0.5756 + 0.9282 + 0.0008, time: 43.317673]
2023-06-15 21:35:25.935: epoch 20:	0.07983807  	0.15048446  	0.15201636  
2023-06-15 21:35:25.935: Find a better model.
2023-06-15 21:36:08.294: [iter 21 : loss : 1.4487 = 0.5125 + 0.9350 + 0.0012, time: 42.351582]
2023-06-15 21:36:08.905: epoch 21:	0.08255068  	0.15519364  	0.15613438  
2023-06-15 21:36:08.905: Find a better model.
2023-06-15 21:36:52.687: [iter 22 : loss : 1.3928 = 0.4505 + 0.9406 + 0.0017, time: 43.776070]
2023-06-15 21:36:53.411: epoch 22:	0.08402775  	0.15853658  	0.15891060  
2023-06-15 21:36:53.411: Find a better model.
2023-06-15 21:37:39.989: [iter 23 : loss : 1.3431 = 0.3967 + 0.9442 + 0.0022, time: 46.515168]
2023-06-15 21:37:40.428: epoch 23:	0.08503235  	0.16044401  	0.16092026  
2023-06-15 21:37:40.428: Find a better model.
2023-06-15 21:38:27.472: [iter 24 : loss : 1.3005 = 0.3517 + 0.9461 + 0.0027, time: 47.036169]
2023-06-15 21:38:28.254: epoch 24:	0.08582195  	0.16262928  	0.16249087  
2023-06-15 21:38:28.254: Find a better model.
2023-06-15 21:39:11.770: [iter 25 : loss : 1.2653 = 0.3154 + 0.9467 + 0.0032, time: 43.509634]
2023-06-15 21:39:12.417: epoch 25:	0.08620872  	0.16368020  	0.16306491  
2023-06-15 21:39:12.417: Find a better model.
2023-06-15 21:39:54.968: [iter 26 : loss : 1.2344 = 0.2843 + 0.9464 + 0.0037, time: 42.543702]
2023-06-15 21:39:55.416: epoch 26:	0.08676193  	0.16460963  	0.16389659  
2023-06-15 21:39:55.417: Find a better model.
2023-06-15 21:40:41.001: [iter 27 : loss : 1.2089 = 0.2590 + 0.9458 + 0.0041, time: 45.576729]
2023-06-15 21:40:41.434: epoch 27:	0.08687473  	0.16466606  	0.16373146  
2023-06-15 21:40:41.434: Find a better model.
2023-06-15 21:41:38.152: [iter 28 : loss : 1.1872 = 0.2376 + 0.9450 + 0.0045, time: 56.711411]
2023-06-15 21:41:38.660: epoch 28:	0.08669212  	0.16411155  	0.16373082  
2023-06-15 21:42:34.911: [iter 29 : loss : 1.1687 = 0.2198 + 0.9439 + 0.0049, time: 56.237161]
2023-06-15 21:42:35.562: epoch 29:	0.08684250  	0.16435893  	0.16350517  
2023-06-15 21:43:32.495: [iter 30 : loss : 1.1522 = 0.2040 + 0.9429 + 0.0053, time: 56.926281]
2023-06-15 21:43:33.412: epoch 30:	0.08664376  	0.16432847  	0.16324644  
2023-06-15 21:44:26.604: [iter 31 : loss : 1.1372 = 0.1898 + 0.9418 + 0.0057, time: 53.183588]
2023-06-15 21:44:27.280: epoch 31:	0.08655783  	0.16363560  	0.16289516  
2023-06-15 21:45:18.466: [iter 32 : loss : 1.1252 = 0.1785 + 0.9407 + 0.0061, time: 51.179471]
2023-06-15 21:45:19.163: epoch 32:	0.08643968  	0.16335779  	0.16249765  
2023-06-15 21:46:12.744: [iter 33 : loss : 1.1136 = 0.1675 + 0.9397 + 0.0064, time: 53.574021]
2023-06-15 21:46:13.389: epoch 33:	0.08649337  	0.16306871  	0.16206589  
2023-06-15 21:47:08.771: [iter 34 : loss : 1.1044 = 0.1590 + 0.9387 + 0.0067, time: 55.375645]
2023-06-15 21:47:09.448: epoch 34:	0.08626785  	0.16221653  	0.16146769  
2023-06-15 21:48:04.617: [iter 35 : loss : 1.0948 = 0.1499 + 0.9379 + 0.0071, time: 55.161885]
2023-06-15 21:48:05.055: epoch 35:	0.08607982  	0.16150928  	0.16090395  
2023-06-15 21:49:00.414: [iter 36 : loss : 1.0873 = 0.1430 + 0.9370 + 0.0074, time: 55.349998]
2023-06-15 21:49:01.101: epoch 36:	0.08596160  	0.16096732  	0.16040078  
2023-06-15 21:49:56.932: [iter 37 : loss : 1.0795 = 0.1357 + 0.9361 + 0.0077, time: 55.816054]
2023-06-15 21:49:57.564: epoch 37:	0.08570378  	0.16058166  	0.16003564  
2023-06-15 21:50:51.527: [iter 38 : loss : 1.0732 = 0.1300 + 0.9353 + 0.0080, time: 53.946298]
2023-06-15 21:50:52.176: epoch 38:	0.08560174  	0.15993056  	0.15953687  
2023-06-15 21:51:43.804: [iter 39 : loss : 1.0674 = 0.1246 + 0.9346 + 0.0082, time: 51.616842]
2023-06-15 21:51:44.533: epoch 39:	0.08550504  	0.15931804  	0.15899916  
2023-06-15 21:52:37.264: [iter 40 : loss : 1.0619 = 0.1195 + 0.9339 + 0.0085, time: 52.724732]
2023-06-15 21:52:37.940: epoch 40:	0.08517194  	0.15811014  	0.15814440  
2023-06-15 21:53:32.547: [iter 41 : loss : 1.0568 = 0.1149 + 0.9332 + 0.0088, time: 54.599145]
2023-06-15 21:53:33.229: epoch 41:	0.08510210  	0.15760066  	0.15763259  
2023-06-15 21:54:28.811: [iter 42 : loss : 1.0521 = 0.1106 + 0.9326 + 0.0090, time: 55.569362]
2023-06-15 21:54:29.765: epoch 42:	0.08501079  	0.15679930  	0.15715197  
2023-06-15 21:55:25.204: [iter 43 : loss : 1.0477 = 0.1064 + 0.9321 + 0.0093, time: 55.428869]
2023-06-15 21:55:25.805: epoch 43:	0.08480668  	0.15635429  	0.15654686  
2023-06-15 21:56:21.698: [iter 44 : loss : 1.0438 = 0.1027 + 0.9316 + 0.0095, time: 55.883394]
2023-06-15 21:56:22.371: epoch 44:	0.08465087  	0.15569074  	0.15617193  
2023-06-15 21:57:18.773: [iter 45 : loss : 1.0408 = 0.1000 + 0.9311 + 0.0097, time: 56.389038]
2023-06-15 21:57:19.382: epoch 45:	0.08436619  	0.15477681  	0.15556031  
2023-06-15 21:58:16.302: [iter 46 : loss : 1.0372 = 0.0965 + 0.9307 + 0.0100, time: 56.910931]
2023-06-15 21:58:17.298: epoch 46:	0.08419967  	0.15411493  	0.15490170  
2023-06-15 21:59:11.127: [iter 47 : loss : 1.0340 = 0.0937 + 0.9301 + 0.0102, time: 53.820599]
2023-06-15 21:59:11.844: epoch 47:	0.08401706  	0.15352471  	0.15439174  
2023-06-15 21:59:55.668: [iter 48 : loss : 1.0308 = 0.0908 + 0.9296 + 0.0104, time: 43.816503]
2023-06-15 21:59:56.083: epoch 48:	0.08387743  	0.15256535  	0.15366690  
2023-06-15 22:00:39.112: [iter 49 : loss : 1.0283 = 0.0883 + 0.9293 + 0.0106, time: 43.021358]
2023-06-15 22:00:39.628: epoch 49:	0.08335099  	0.15155371  	0.15291376  
2023-06-15 22:01:23.262: [iter 50 : loss : 1.0257 = 0.0860 + 0.9289 + 0.0108, time: 43.615206]
2023-06-15 22:01:23.730: epoch 50:	0.08305562  	0.15095745  	0.15241046  
2023-06-15 22:02:09.660: [iter 51 : loss : 1.0233 = 0.0837 + 0.9286 + 0.0110, time: 45.922445]
2023-06-15 22:02:10.076: epoch 51:	0.08292671  	0.15053494  	0.15218389  
2023-06-15 22:02:57.996: [iter 52 : loss : 1.0210 = 0.0815 + 0.9283 + 0.0112, time: 47.912857]
2023-06-15 22:02:58.413: epoch 52:	0.08275477  	0.15003972  	0.15190873  
2023-06-15 22:02:58.413: Early stopping is trigger at epoch: 52
2023-06-15 22:02:58.413: best_result@epoch 27:

2023-06-15 22:02:58.413: 		0.0869      	0.1647      	0.1637      
2023-06-16 09:19:37.715: my pid: 3592
2023-06-16 09:19:37.715: model: model.general_recommender.SGL
2023-06-16 09:19:37.715: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 09:19:37.715: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 09:19:43.618: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 09:20:26.207: [iter 1 : loss : 1.6080 = 0.6931 + 0.9148 + 0.0000, time: 42.587493]
2023-06-16 09:20:26.621: epoch 1:	0.00285237  	0.00849077  	0.00617783  
2023-06-16 09:20:26.621: Find a better model.
2023-06-16 09:21:08.615: [iter 2 : loss : 1.6055 = 0.6931 + 0.9124 + 0.0000, time: 41.987251]
2023-06-16 09:21:09.323: epoch 2:	0.00356143  	0.01017699  	0.00757307  
2023-06-16 09:21:09.323: Find a better model.
2023-06-16 09:21:53.638: [iter 3 : loss : 1.6052 = 0.6930 + 0.9122 + 0.0000, time: 44.298557]
2023-06-16 09:21:54.087: epoch 3:	0.00441553  	0.01144387  	0.00849019  
2023-06-16 09:21:54.088: Find a better model.
2023-06-16 09:22:39.905: [iter 4 : loss : 1.6052 = 0.6930 + 0.9122 + 0.0000, time: 45.799999]
2023-06-16 09:22:40.485: epoch 4:	0.00475932  	0.01223763  	0.00947723  
2023-06-16 09:22:40.485: Find a better model.
2023-06-16 09:23:22.170: [iter 5 : loss : 1.6051 = 0.6929 + 0.9122 + 0.0000, time: 41.676344]
2023-06-16 09:23:22.851: epoch 5:	0.00533408  	0.01303858  	0.01063934  
2023-06-16 09:23:22.852: Find a better model.
2023-06-16 09:24:09.898: [iter 6 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 47.038876]
2023-06-16 09:24:10.385: epoch 6:	0.00610760  	0.01504500  	0.01228184  
2023-06-16 09:24:10.386: Find a better model.
2023-06-16 09:25:00.844: [iter 7 : loss : 1.6052 = 0.6928 + 0.9124 + 0.0000, time: 50.439356]
2023-06-16 09:25:01.710: epoch 7:	0.00713897  	0.01732737  	0.01417027  
2023-06-16 09:25:01.711: Find a better model.
2023-06-16 09:25:53.540: [iter 8 : loss : 1.6051 = 0.6927 + 0.9124 + 0.0000, time: 51.814758]
2023-06-16 09:25:54.207: epoch 8:	0.00792326  	0.01897532  	0.01588002  
2023-06-16 09:25:54.208: Find a better model.
2023-06-16 09:26:47.970: [iter 9 : loss : 1.6052 = 0.6925 + 0.9127 + 0.0000, time: 53.756330]
2023-06-16 09:26:48.503: epoch 9:	0.00896542  	0.02178524  	0.01801530  
2023-06-16 09:26:48.503: Find a better model.
2023-06-16 09:27:50.339: [iter 10 : loss : 1.6050 = 0.6924 + 0.9127 + 0.0000, time: 61.829266]
2023-06-16 09:27:51.022: epoch 10:	0.01039436  	0.02464173  	0.02094161  
2023-06-16 09:27:51.022: Find a better model.
2023-06-16 09:28:53.847: [iter 11 : loss : 1.6048 = 0.6921 + 0.9127 + 0.0000, time: 62.816727]
2023-06-16 09:28:54.963: epoch 11:	0.01257533  	0.02894056  	0.02528089  
2023-06-16 09:28:54.964: Find a better model.
2023-06-16 09:29:56.517: [iter 12 : loss : 1.6046 = 0.6917 + 0.9129 + 0.0000, time: 61.544763]
2023-06-16 09:29:57.287: epoch 12:	0.01572865  	0.03592641  	0.03225300  
2023-06-16 09:29:57.287: Find a better model.
2023-06-16 09:30:59.349: [iter 13 : loss : 1.6044 = 0.6912 + 0.9132 + 0.0000, time: 62.041488]
2023-06-16 09:31:00.106: epoch 13:	0.01936007  	0.04321939  	0.03982218  
2023-06-16 09:31:00.106: Find a better model.
2023-06-16 09:32:05.991: [iter 14 : loss : 1.6038 = 0.6902 + 0.9135 + 0.0000, time: 65.876908]
2023-06-16 09:32:06.782: epoch 14:	0.02455470  	0.05313851  	0.04986595  
2023-06-16 09:32:06.783: Find a better model.
2023-06-16 09:33:08.537: [iter 15 : loss : 1.6025 = 0.6886 + 0.9139 + 0.0001, time: 61.745932]
2023-06-16 09:33:09.321: epoch 15:	0.03208015  	0.06814068  	0.06544508  
2023-06-16 09:33:09.321: Find a better model.
2023-06-16 09:34:00.895: [iter 16 : loss : 1.6001 = 0.6854 + 0.9146 + 0.0001, time: 51.564355]
2023-06-16 09:34:01.605: epoch 16:	0.04220528  	0.08618064  	0.08456303  
2023-06-16 09:34:01.605: Find a better model.
2023-06-16 09:34:54.737: [iter 17 : loss : 1.5945 = 0.6787 + 0.9157 + 0.0001, time: 53.124583]
2023-06-16 09:34:55.159: epoch 17:	0.05392590  	0.10788678  	0.10668848  
2023-06-16 09:34:55.159: Find a better model.
2023-06-16 09:35:47.459: [iter 18 : loss : 1.5819 = 0.6638 + 0.9179 + 0.0002, time: 52.292766]
2023-06-16 09:35:47.949: epoch 18:	0.06574313  	0.12682599  	0.12719713  
2023-06-16 09:35:47.949: Find a better model.
2023-06-16 09:36:42.246: [iter 19 : loss : 1.5556 = 0.6336 + 0.9216 + 0.0004, time: 54.289619]
2023-06-16 09:36:42.664: epoch 19:	0.07416569  	0.14014915  	0.14126967  
2023-06-16 09:36:42.664: Find a better model.
2023-06-16 09:37:38.213: [iter 20 : loss : 1.5127 = 0.5847 + 0.9272 + 0.0007, time: 55.541279]
2023-06-16 09:37:39.065: epoch 20:	0.07891944  	0.14892299  	0.14959581  
2023-06-16 09:37:39.065: Find a better model.
2023-06-16 09:38:41.343: [iter 21 : loss : 1.4583 = 0.5234 + 0.9337 + 0.0011, time: 62.269548]
2023-06-16 09:38:42.138: epoch 21:	0.08185761  	0.15351941  	0.15430412  
2023-06-16 09:38:42.138: Find a better model.
2023-06-16 09:39:38.752: [iter 22 : loss : 1.4021 = 0.4610 + 0.9395 + 0.0016, time: 56.605714]
2023-06-16 09:39:39.482: epoch 22:	0.08366783  	0.15713637  	0.15763843  
2023-06-16 09:39:39.482: Find a better model.
2023-06-16 09:40:37.233: [iter 23 : loss : 1.3515 = 0.4060 + 0.9434 + 0.0021, time: 57.743746]
2023-06-16 09:40:37.718: epoch 23:	0.08482812  	0.15965989  	0.15969510  
2023-06-16 09:40:37.718: Find a better model.
2023-06-16 09:41:34.650: [iter 24 : loss : 1.3077 = 0.3595 + 0.9456 + 0.0026, time: 56.922730]
2023-06-16 09:41:35.381: epoch 24:	0.08589160  	0.16183846  	0.16127849  
2023-06-16 09:41:35.381: Find a better model.
2023-06-16 09:42:32.635: [iter 25 : loss : 1.2712 = 0.3218 + 0.9463 + 0.0031, time: 57.238283]
2023-06-16 09:42:33.320: epoch 25:	0.08639124  	0.16250308  	0.16190171  
2023-06-16 09:42:33.320: Find a better model.
2023-06-16 09:43:31.442: [iter 26 : loss : 1.2395 = 0.2897 + 0.9463 + 0.0036, time: 58.114101]
2023-06-16 09:43:32.143: epoch 26:	0.08655243  	0.16318339  	0.16236560  
2023-06-16 09:43:32.143: Find a better model.
2023-06-16 09:44:30.316: [iter 27 : loss : 1.2129 = 0.2631 + 0.9457 + 0.0040, time: 58.165436]
2023-06-16 09:44:31.055: epoch 27:	0.08692845  	0.16374677  	0.16291650  
2023-06-16 09:44:31.055: Find a better model.
2023-06-16 09:46:21.341: [iter 28 : loss : 1.1908 = 0.2413 + 0.9450 + 0.0045, time: 110.273319]
2023-06-16 09:46:21.959: epoch 28:	0.08711114  	0.16413181  	0.16320078  
2023-06-16 09:46:21.959: Find a better model.
2023-06-16 09:48:18.435: [iter 29 : loss : 1.1717 = 0.2228 + 0.9440 + 0.0049, time: 116.466963]
2023-06-16 09:48:19.522: epoch 29:	0.08729374  	0.16417658  	0.16296282  
2023-06-16 09:48:19.522: Find a better model.
2023-06-16 09:50:16.162: [iter 30 : loss : 1.1548 = 0.2066 + 0.9429 + 0.0053, time: 116.633338]
2023-06-16 09:50:16.874: epoch 30:	0.08737431  	0.16425730  	0.16283262  
2023-06-16 09:50:16.874: Find a better model.
2023-06-16 09:52:15.115: [iter 31 : loss : 1.1396 = 0.1922 + 0.9418 + 0.0056, time: 118.232700]
2023-06-16 09:52:15.811: epoch 31:	0.08735827  	0.16402766  	0.16237502  
2023-06-16 09:54:08.990: [iter 32 : loss : 1.1271 = 0.1803 + 0.9408 + 0.0060, time: 113.161975]
2023-06-16 09:54:13.616: epoch 32:	0.08734221  	0.16335170  	0.16217573  
2023-06-16 09:56:07.908: [iter 33 : loss : 1.1154 = 0.1691 + 0.9399 + 0.0064, time: 114.284769]
2023-06-16 09:56:12.366: epoch 33:	0.08729917  	0.16293746  	0.16176434  
2023-06-16 09:58:11.309: [iter 34 : loss : 1.1060 = 0.1604 + 0.9389 + 0.0067, time: 118.928744]
2023-06-16 09:58:12.037: epoch 34:	0.08724540  	0.16263980  	0.16147508  
2023-06-16 10:00:09.028: [iter 35 : loss : 1.0962 = 0.1512 + 0.9380 + 0.0070, time: 116.984344]
2023-06-16 10:00:13.545: epoch 35:	0.08716486  	0.16225190  	0.16127142  
2023-06-16 10:01:56.598: [iter 36 : loss : 1.0886 = 0.1441 + 0.9372 + 0.0073, time: 103.045661]
2023-06-16 10:01:57.425: epoch 36:	0.08672442  	0.16114467  	0.16050881  
2023-06-16 10:03:07.051: [iter 37 : loss : 1.0807 = 0.1368 + 0.9362 + 0.0076, time: 69.612024]
2023-06-16 10:03:07.898: epoch 37:	0.08657403  	0.16078475  	0.16012257  
2023-06-16 10:04:16.679: [iter 38 : loss : 1.0742 = 0.1309 + 0.9354 + 0.0079, time: 68.768977]
2023-06-16 10:04:17.539: epoch 38:	0.08633224  	0.16044691  	0.15971091  
2023-06-16 10:05:25.750: [iter 39 : loss : 1.0685 = 0.1257 + 0.9347 + 0.0082, time: 68.202541]
2023-06-16 10:05:26.631: epoch 39:	0.08602604  	0.15986387  	0.15907498  
2023-06-16 10:06:35.737: [iter 40 : loss : 1.0630 = 0.1206 + 0.9340 + 0.0084, time: 69.099190]
2023-06-16 10:06:36.614: epoch 40:	0.08586489  	0.15920456  	0.15831213  
2023-06-16 10:07:36.836: [iter 41 : loss : 1.0573 = 0.1153 + 0.9333 + 0.0087, time: 60.212850]
2023-06-16 10:07:37.693: epoch 41:	0.08574135  	0.15857145  	0.15798214  
2023-06-16 10:08:35.981: [iter 42 : loss : 1.0532 = 0.1115 + 0.9328 + 0.0090, time: 58.281023]
2023-06-16 10:08:36.626: epoch 42:	0.08544593  	0.15816210  	0.15754785  
2023-06-16 10:09:34.661: [iter 43 : loss : 1.0483 = 0.1069 + 0.9322 + 0.0092, time: 58.028286]
2023-06-16 10:09:35.300: epoch 43:	0.08534381  	0.15773623  	0.15704767  
2023-06-16 10:10:32.637: [iter 44 : loss : 1.0445 = 0.1034 + 0.9317 + 0.0095, time: 57.314988]
2023-06-16 10:10:33.480: epoch 44:	0.08511811  	0.15661277  	0.15633762  
2023-06-16 10:11:31.407: [iter 45 : loss : 1.0413 = 0.1005 + 0.9311 + 0.0097, time: 57.921208]
2023-06-16 10:11:31.999: epoch 45:	0.08487646  	0.15603261  	0.15577807  
2023-06-16 10:12:10.141: my pid: 9336
2023-06-16 10:12:10.141: model: model.general_recommender.SGL
2023-06-16 10:12:10.141: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 10:12:10.141: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 10:12:17.125: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 10:13:25.428: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 68.300065]
2023-06-16 10:13:26.257: epoch 1:	0.00323376  	0.00935801  	0.00697653  
2023-06-16 10:13:26.257: Find a better model.
2023-06-16 10:14:34.204: [iter 2 : loss : 1.6055 = 0.6931 + 0.9125 + 0.0000, time: 67.938471]
2023-06-16 10:14:34.882: epoch 2:	0.00364738  	0.00961826  	0.00725443  
2023-06-16 10:14:34.882: Find a better model.
2023-06-16 10:15:42.030: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 67.138845]
2023-06-16 10:15:42.904: epoch 3:	0.00454982  	0.01154697  	0.00909569  
2023-06-16 10:15:42.904: Find a better model.
2023-06-16 10:16:51.751: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 68.835445]
2023-06-16 10:16:52.674: epoch 4:	0.00503327  	0.01274242  	0.00987879  
2023-06-16 10:16:52.674: Find a better model.
2023-06-16 10:18:00.933: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 68.248806]
2023-06-16 10:18:01.765: epoch 5:	0.00624726  	0.01507173  	0.01212151  
2023-06-16 10:18:01.765: Find a better model.
2023-06-16 10:19:09.266: [iter 6 : loss : 1.6053 = 0.6928 + 0.9124 + 0.0000, time: 67.480073]
2023-06-16 10:19:10.130: epoch 6:	0.00709600  	0.01670481  	0.01340774  
2023-06-16 10:19:10.130: Find a better model.
2023-06-16 10:20:18.324: [iter 7 : loss : 1.6053 = 0.6928 + 0.9126 + 0.0000, time: 68.186346]
2023-06-16 10:20:19.092: epoch 7:	0.00784269  	0.01808335  	0.01497992  
2023-06-16 10:20:19.092: Find a better model.
2023-06-16 10:21:26.493: [iter 8 : loss : 1.6051 = 0.6926 + 0.9125 + 0.0000, time: 67.392053]
2023-06-16 10:21:27.379: epoch 8:	0.00903526  	0.02112939  	0.01729729  
2023-06-16 10:21:27.379: Find a better model.
2023-06-16 10:22:33.601: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 66.212282]
2023-06-16 10:22:34.506: epoch 9:	0.01073815  	0.02423118  	0.02095622  
2023-06-16 10:22:34.506: Find a better model.
2023-06-16 10:23:44.176: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 69.660559]
2023-06-16 10:23:45.035: epoch 10:	0.01274184  	0.02818405  	0.02462117  
2023-06-16 10:23:45.035: Find a better model.
2023-06-16 10:24:54.855: [iter 11 : loss : 1.6048 = 0.6920 + 0.9128 + 0.0000, time: 69.809306]
2023-06-16 10:24:55.698: epoch 11:	0.01552450  	0.03308515  	0.02972195  
2023-06-16 10:24:55.698: Find a better model.
2023-06-16 10:26:04.663: [iter 12 : loss : 1.6046 = 0.6915 + 0.9131 + 0.0000, time: 68.950706]
2023-06-16 10:26:05.556: epoch 12:	0.01886583  	0.04113471  	0.03718356  
2023-06-16 10:26:05.556: Find a better model.
2023-06-16 10:27:14.140: [iter 13 : loss : 1.6042 = 0.6908 + 0.9134 + 0.0000, time: 68.577530]
2023-06-16 10:27:15.026: epoch 13:	0.02277114  	0.04867207  	0.04561481  
2023-06-16 10:27:15.027: Find a better model.
2023-06-16 10:28:25.187: [iter 14 : loss : 1.6034 = 0.6896 + 0.9137 + 0.0000, time: 70.152370]
2023-06-16 10:28:26.128: epoch 14:	0.02900235  	0.06174345  	0.05824060  
2023-06-16 10:28:26.128: Find a better model.
2023-06-16 10:29:35.091: [iter 15 : loss : 1.6018 = 0.6875 + 0.9142 + 0.0001, time: 68.955700]
2023-06-16 10:29:35.900: epoch 15:	0.03754276  	0.07774636  	0.07524591  
2023-06-16 10:29:35.900: Find a better model.
2023-06-16 10:30:44.585: [iter 16 : loss : 1.5984 = 0.6833 + 0.9150 + 0.0001, time: 68.676731]
2023-06-16 10:30:45.260: epoch 16:	0.04804408  	0.09654529  	0.09504589  
2023-06-16 10:30:45.260: Find a better model.
2023-06-16 10:31:55.345: [iter 17 : loss : 1.5907 = 0.6741 + 0.9164 + 0.0002, time: 70.075792]
2023-06-16 10:31:56.109: epoch 17:	0.06023201  	0.11723411  	0.11698000  
2023-06-16 10:31:56.109: Find a better model.
2023-06-16 10:33:05.929: [iter 18 : loss : 1.5737 = 0.6545 + 0.9189 + 0.0003, time: 69.808205]
2023-06-16 10:33:06.800: epoch 18:	0.07038414  	0.13390255  	0.13519131  
2023-06-16 10:33:06.800: Find a better model.
2023-06-16 10:34:14.721: [iter 19 : loss : 1.5412 = 0.6177 + 0.9230 + 0.0005, time: 67.912003]
2023-06-16 10:34:15.632: epoch 19:	0.07747450  	0.14536689  	0.14732021  
2023-06-16 10:34:15.633: Find a better model.
2023-06-16 10:35:23.002: [iter 20 : loss : 1.4933 = 0.5635 + 0.9289 + 0.0009, time: 67.360500]
2023-06-16 10:35:23.838: epoch 20:	0.08124534  	0.15234427  	0.15361428  
2023-06-16 10:35:23.838: Find a better model.
2023-06-16 10:36:25.565: [iter 21 : loss : 1.4371 = 0.5005 + 0.9353 + 0.0013, time: 61.719620]
2023-06-16 10:36:26.335: epoch 21:	0.08325428  	0.15614387  	0.15699327  
2023-06-16 10:36:26.335: Find a better model.
2023-06-16 10:37:30.494: [iter 22 : loss : 1.3820 = 0.4395 + 0.9406 + 0.0018, time: 64.140039]
2023-06-16 10:37:31.340: epoch 22:	0.08452206  	0.15891059  	0.15928125  
2023-06-16 10:37:31.340: Find a better model.
2023-06-16 10:38:40.858: [iter 23 : loss : 1.3335 = 0.3873 + 0.9439 + 0.0023, time: 69.506884]
2023-06-16 10:38:41.683: epoch 23:	0.08566618  	0.16147323  	0.16129623  
2023-06-16 10:38:41.683: Find a better model.
2023-06-16 10:39:51.803: [iter 24 : loss : 1.2919 = 0.3433 + 0.9457 + 0.0028, time: 70.111837]
2023-06-16 10:39:52.668: epoch 24:	0.08647193  	0.16340995  	0.16251026  
2023-06-16 10:39:52.668: Find a better model.
2023-06-16 10:41:01.049: [iter 25 : loss : 1.2578 = 0.3083 + 0.9462 + 0.0033, time: 68.369443]
2023-06-16 10:41:01.878: epoch 25:	0.08700366  	0.16474116  	0.16337293  
2023-06-16 10:41:01.878: Find a better model.
2023-06-16 10:42:12.523: [iter 26 : loss : 1.2281 = 0.2783 + 0.9460 + 0.0038, time: 70.636427]
2023-06-16 10:42:13.446: epoch 26:	0.08740653  	0.16502607  	0.16376342  
2023-06-16 10:42:13.446: Find a better model.
2023-06-16 10:43:24.082: [iter 27 : loss : 1.2032 = 0.2536 + 0.9454 + 0.0042, time: 70.616093]
2023-06-16 10:43:24.947: epoch 27:	0.08759999  	0.16512275  	0.16401772  
2023-06-16 10:43:24.947: Find a better model.
2023-06-16 10:44:35.088: [iter 28 : loss : 1.1821 = 0.2329 + 0.9445 + 0.0046, time: 70.133323]
2023-06-16 10:44:35.787: epoch 28:	0.08768589  	0.16556858  	0.16406068  
2023-06-16 10:44:35.787: Find a better model.
2023-06-16 10:45:47.559: [iter 29 : loss : 1.1641 = 0.2157 + 0.9434 + 0.0050, time: 71.761414]
2023-06-16 10:45:48.310: epoch 29:	0.08761608  	0.16489995  	0.16366237  
2023-06-16 10:47:00.113: [iter 30 : loss : 1.1483 = 0.2005 + 0.9424 + 0.0054, time: 71.759540]
2023-06-16 10:47:00.896: epoch 30:	0.08778799  	0.16491626  	0.16341665  
2023-06-16 10:48:14.101: [iter 31 : loss : 1.1341 = 0.1869 + 0.9414 + 0.0058, time: 73.194350]
2023-06-16 10:48:14.913: epoch 31:	0.08757848  	0.16456348  	0.16307735  
2023-06-16 10:49:26.538: [iter 32 : loss : 1.1220 = 0.1757 + 0.9402 + 0.0061, time: 71.613241]
2023-06-16 10:49:27.381: epoch 32:	0.08758387  	0.16445442  	0.16299184  
2023-06-16 10:50:41.907: [iter 33 : loss : 1.1107 = 0.1650 + 0.9392 + 0.0065, time: 74.517703]
2023-06-16 10:50:43.073: epoch 33:	0.08744951  	0.16400433  	0.16277727  
2023-06-16 10:51:56.845: [iter 34 : loss : 1.1020 = 0.1568 + 0.9384 + 0.0068, time: 73.756390]
2023-06-16 10:51:57.819: epoch 34:	0.08737963  	0.16336663  	0.16238785  
2023-06-16 10:53:14.097: [iter 35 : loss : 1.0925 = 0.1479 + 0.9375 + 0.0071, time: 76.268384]
2023-06-16 10:53:14.997: epoch 35:	0.08727224  	0.16282356  	0.16213973  
2023-06-16 10:54:31.016: [iter 36 : loss : 1.0849 = 0.1409 + 0.9366 + 0.0074, time: 76.004640]
2023-06-16 10:54:31.895: epoch 36:	0.08687471  	0.16164236  	0.16130000  
2023-06-16 10:55:46.264: [iter 37 : loss : 1.0776 = 0.1342 + 0.9357 + 0.0077, time: 74.359499]
2023-06-16 10:55:47.059: epoch 37:	0.08668672  	0.16092499  	0.16077352  
2023-06-16 10:57:04.528: [iter 38 : loss : 1.0714 = 0.1284 + 0.9351 + 0.0080, time: 77.456866]
2023-06-16 10:57:05.256: epoch 38:	0.08660065  	0.16018897  	0.16026214  
2023-06-16 10:58:20.373: [iter 39 : loss : 1.0657 = 0.1233 + 0.9342 + 0.0083, time: 75.106180]
2023-06-16 10:58:21.285: epoch 39:	0.08626230  	0.15946971  	0.15971209  
2023-06-16 10:59:37.414: [iter 40 : loss : 1.0607 = 0.1186 + 0.9336 + 0.0085, time: 76.092346]
2023-06-16 10:59:38.598: epoch 40:	0.08602058  	0.15870193  	0.15911996  
2023-06-16 11:00:55.514: [iter 41 : loss : 1.0552 = 0.1135 + 0.9329 + 0.0088, time: 76.907913]
2023-06-16 11:00:56.372: epoch 41:	0.08599904  	0.15852249  	0.15889640  
2023-06-16 11:02:12.634: [iter 42 : loss : 1.0512 = 0.1098 + 0.9323 + 0.0091, time: 76.252077]
2023-06-16 11:02:13.524: epoch 42:	0.08580567  	0.15791608  	0.15831645  
2023-06-16 11:03:29.459: [iter 43 : loss : 1.0465 = 0.1054 + 0.9319 + 0.0093, time: 75.927369]
2023-06-16 11:03:30.370: epoch 43:	0.08567137  	0.15710925  	0.15778923  
2023-06-16 11:04:46.409: [iter 44 : loss : 1.0428 = 0.1019 + 0.9313 + 0.0095, time: 76.028394]
2023-06-16 11:04:47.407: epoch 44:	0.08541366  	0.15641525  	0.15710132  
2023-06-16 11:06:03.045: [iter 45 : loss : 1.0397 = 0.0991 + 0.9308 + 0.0098, time: 75.627033]
2023-06-16 11:06:03.913: epoch 45:	0.08519338  	0.15569213  	0.15650666  
2023-06-16 11:07:20.114: [iter 46 : loss : 1.0361 = 0.0957 + 0.9304 + 0.0100, time: 76.192863]
2023-06-16 11:07:21.009: epoch 46:	0.08502687  	0.15508562  	0.15581556  
2023-06-16 11:08:35.802: [iter 47 : loss : 1.0329 = 0.0928 + 0.9299 + 0.0102, time: 74.779980]
2023-06-16 11:08:36.593: epoch 47:	0.08477979  	0.15450774  	0.15523966  
2023-06-16 11:09:53.761: [iter 48 : loss : 1.0299 = 0.0900 + 0.9294 + 0.0104, time: 77.147505]
2023-06-16 11:09:54.760: epoch 48:	0.08453804  	0.15391105  	0.15461399  
2023-06-16 11:11:10.826: [iter 49 : loss : 1.0271 = 0.0875 + 0.9291 + 0.0106, time: 76.057699]
2023-06-16 11:11:11.701: epoch 49:	0.08423188  	0.15282027  	0.15392031  
2023-06-16 11:12:28.683: [iter 50 : loss : 1.0247 = 0.0852 + 0.9286 + 0.0108, time: 76.965758]
2023-06-16 11:12:29.631: epoch 50:	0.08397939  	0.15235345  	0.15342459  
2023-06-16 11:13:44.860: [iter 51 : loss : 1.0222 = 0.0827 + 0.9285 + 0.0110, time: 75.217718]
2023-06-16 11:13:45.836: epoch 51:	0.08374844  	0.15175690  	0.15289284  
2023-06-16 11:15:03.070: [iter 52 : loss : 1.0205 = 0.0812 + 0.9281 + 0.0112, time: 77.225669]
2023-06-16 11:15:04.011: epoch 52:	0.08346378  	0.15084021  	0.15214290  
2023-06-16 11:16:16.373: [iter 53 : loss : 1.0178 = 0.0787 + 0.9277 + 0.0114, time: 72.353760]
2023-06-16 11:16:17.240: epoch 53:	0.08320056  	0.15041547  	0.15160190  
2023-06-16 11:16:17.240: Early stopping is trigger at epoch: 53
2023-06-16 11:16:17.240: best_result@epoch 28:

2023-06-16 11:16:17.240: 		0.0877      	0.1656      	0.1641      
2023-06-16 11:19:19.922: my pid: 11296
2023-06-16 11:19:19.922: model: model.general_recommender.SGL
2023-06-16 11:19:19.922: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 11:19:19.922: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 11:19:27.152: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 11:20:41.315: my pid: 1316
2023-06-16 11:20:41.315: model: model.general_recommender.SGL
2023-06-16 11:20:41.315: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 11:20:41.315: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 11:20:48.271: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 11:22:02.451: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 74.171835]
2023-06-16 11:22:03.308: epoch 1:	0.00312633  	0.00881037  	0.00654789  
2023-06-16 11:22:03.308: Find a better model.
2023-06-16 11:23:17.366: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 74.026470]
2023-06-16 11:23:18.312: epoch 2:	0.00376019  	0.00905933  	0.00719123  
2023-06-16 11:23:18.312: Find a better model.
2023-06-16 11:24:32.385: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 74.051882]
2023-06-16 11:24:33.200: epoch 3:	0.00463577  	0.01031312  	0.00866927  
2023-06-16 11:24:33.200: Find a better model.
2023-06-16 11:25:47.088: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 73.877153]
2023-06-16 11:25:47.920: epoch 4:	0.00546300  	0.01259970  	0.01010383  
2023-06-16 11:25:47.920: Find a better model.
2023-06-16 11:27:00.992: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 73.063919]
2023-06-16 11:27:01.992: epoch 5:	0.00641915  	0.01405859  	0.01149713  
2023-06-16 11:27:01.992: Find a better model.
2023-06-16 11:28:14.764: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 72.762975]
2023-06-16 11:28:15.672: epoch 6:	0.00705302  	0.01571138  	0.01288086  
2023-06-16 11:28:15.672: Find a better model.
2023-06-16 11:29:30.518: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 74.829720]
2023-06-16 11:29:31.258: epoch 7:	0.00804146  	0.01724666  	0.01478850  
2023-06-16 11:29:31.258: Find a better model.
2023-06-16 11:30:46.049: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 74.778214]
2023-06-16 11:30:46.970: epoch 8:	0.00866461  	0.01953301  	0.01679193  
2023-06-16 11:30:46.970: Find a better model.
2023-06-16 11:32:00.080: [iter 9 : loss : 1.6052 = 0.6925 + 0.9127 + 0.0000, time: 73.099628]
2023-06-16 11:32:00.990: epoch 9:	0.01044806  	0.02221001  	0.01999090  
2023-06-16 11:32:00.990: Find a better model.
2023-06-16 11:33:13.132: [iter 10 : loss : 1.6051 = 0.6924 + 0.9127 + 0.0000, time: 72.132437]
2023-06-16 11:33:13.980: epoch 10:	0.01202203  	0.02522146  	0.02269203  
2023-06-16 11:33:13.980: Find a better model.
2023-06-16 11:34:28.579: [iter 11 : loss : 1.6049 = 0.6921 + 0.9128 + 0.0000, time: 74.576107]
2023-06-16 11:34:29.564: epoch 11:	0.01428359  	0.03033332  	0.02745387  
2023-06-16 11:34:29.564: Find a better model.
2023-06-16 11:35:44.934: [iter 12 : loss : 1.6047 = 0.6917 + 0.9130 + 0.0000, time: 75.362205]
2023-06-16 11:35:45.655: epoch 12:	0.01737246  	0.03675675  	0.03337935  
2023-06-16 11:35:45.655: Find a better model.
2023-06-16 11:37:00.061: [iter 13 : loss : 1.6044 = 0.6911 + 0.9132 + 0.0000, time: 74.394050]
2023-06-16 11:37:00.961: epoch 13:	0.02121335  	0.04448145  	0.04122061  
2023-06-16 11:37:00.961: Find a better model.
2023-06-16 11:38:14.368: [iter 14 : loss : 1.6038 = 0.6902 + 0.9135 + 0.0000, time: 73.400705]
2023-06-16 11:38:15.222: epoch 14:	0.02638109  	0.05583496  	0.05180121  
2023-06-16 11:38:15.222: Find a better model.
2023-06-16 11:39:25.115: [iter 15 : loss : 1.6025 = 0.6886 + 0.9139 + 0.0001, time: 69.886654]
2023-06-16 11:39:25.837: epoch 15:	0.03407288  	0.07131901  	0.06737838  
2023-06-16 11:39:25.837: Find a better model.
2023-06-16 11:40:29.979: [iter 16 : loss : 1.6000 = 0.6853 + 0.9146 + 0.0001, time: 64.133208]
2023-06-16 11:40:30.712: epoch 16:	0.04442364  	0.08958868  	0.08707920  
2023-06-16 11:40:30.712: Find a better model.
2023-06-16 11:41:35.590: [iter 17 : loss : 1.5943 = 0.6785 + 0.9157 + 0.0001, time: 64.869964]
2023-06-16 11:41:36.461: epoch 17:	0.05578984  	0.11032446  	0.10899120  
2023-06-16 11:41:36.461: Find a better model.
2023-06-16 11:42:41.186: [iter 18 : loss : 1.5811 = 0.6631 + 0.9179 + 0.0002, time: 64.717917]
2023-06-16 11:42:41.915: epoch 18:	0.06725249  	0.12994182  	0.12945136  
2023-06-16 11:42:41.915: Find a better model.
2023-06-16 11:43:46.574: [iter 19 : loss : 1.5538 = 0.6318 + 0.9216 + 0.0004, time: 64.652173]
2023-06-16 11:43:47.337: epoch 19:	0.07514863  	0.14246438  	0.14277698  
2023-06-16 11:43:47.337: Find a better model.
2023-06-16 11:44:47.789: [iter 20 : loss : 1.5096 = 0.5817 + 0.9272 + 0.0007, time: 60.442623]
2023-06-16 11:44:48.643: epoch 20:	0.07968222  	0.15016937  	0.15063623  
2023-06-16 11:44:48.643: Find a better model.
2023-06-16 11:45:51.661: [iter 21 : loss : 1.4540 = 0.5192 + 0.9336 + 0.0012, time: 63.010742]
2023-06-16 11:45:52.381: epoch 21:	0.08214224  	0.15417436  	0.15470892  
2023-06-16 11:45:52.381: Find a better model.
2023-06-16 11:46:53.846: [iter 22 : loss : 1.3974 = 0.4564 + 0.9394 + 0.0016, time: 61.453093]
2023-06-16 11:46:54.664: epoch 22:	0.08376449  	0.15726468  	0.15753332  
2023-06-16 11:46:54.664: Find a better model.
2023-06-16 11:47:55.690: [iter 23 : loss : 1.3466 = 0.4012 + 0.9432 + 0.0022, time: 61.017930]
2023-06-16 11:47:56.547: epoch 23:	0.08494625  	0.15981191  	0.15944120  
2023-06-16 11:47:56.548: Find a better model.
2023-06-16 11:48:56.416: [iter 24 : loss : 1.3029 = 0.3549 + 0.9453 + 0.0027, time: 59.861264]
2023-06-16 11:48:57.203: epoch 24:	0.08586478  	0.16147688  	0.16120364  
2023-06-16 11:48:57.203: Find a better model.
2023-06-16 11:49:59.099: [iter 25 : loss : 1.2666 = 0.3175 + 0.9460 + 0.0032, time: 61.880483]
2023-06-16 11:49:59.946: epoch 25:	0.08658987  	0.16292278  	0.16232181  
2023-06-16 11:49:59.946: Find a better model.
2023-06-16 11:51:01.932: [iter 26 : loss : 1.2356 = 0.2861 + 0.9459 + 0.0036, time: 61.975950]
2023-06-16 11:51:02.630: epoch 26:	0.08679407  	0.16315913  	0.16284545  
2023-06-16 11:51:02.631: Find a better model.
2023-06-16 11:52:02.675: [iter 27 : loss : 1.2093 = 0.2600 + 0.9452 + 0.0041, time: 60.030438]
2023-06-16 11:52:03.517: epoch 27:	0.08718617  	0.16392389  	0.16328545  
2023-06-16 11:52:03.517: Find a better model.
2023-06-16 11:53:03.639: [iter 28 : loss : 1.1875 = 0.2384 + 0.9446 + 0.0045, time: 60.115506]
2023-06-16 11:53:04.495: epoch 28:	0.08702505  	0.16365340  	0.16298689  
2023-06-16 11:54:05.043: [iter 29 : loss : 1.1687 = 0.2203 + 0.9435 + 0.0049, time: 60.537750]
2023-06-16 11:54:05.881: epoch 29:	0.08698207  	0.16361463  	0.16277134  
2023-06-16 11:55:07.277: [iter 30 : loss : 1.1523 = 0.2045 + 0.9425 + 0.0053, time: 61.385157]
2023-06-16 11:55:08.125: epoch 30:	0.08727753  	0.16384780  	0.16247746  
2023-06-16 11:56:08.682: [iter 31 : loss : 1.1372 = 0.1901 + 0.9414 + 0.0057, time: 60.549232]
2023-06-16 11:56:09.364: epoch 31:	0.08724532  	0.16401944  	0.16238387  
2023-06-16 11:56:09.364: Find a better model.
2023-06-16 11:56:58.527: [iter 32 : loss : 1.1251 = 0.1788 + 0.9403 + 0.0060, time: 49.149988]
2023-06-16 11:56:59.359: epoch 32:	0.08728296  	0.16369769  	0.16213362  
2023-06-16 11:57:49.624: [iter 33 : loss : 1.1136 = 0.1678 + 0.9394 + 0.0064, time: 50.248393]
2023-06-16 11:57:50.464: epoch 33:	0.08726146  	0.16346264  	0.16166143  
2023-06-16 11:58:39.962: [iter 34 : loss : 1.1040 = 0.1590 + 0.9383 + 0.0067, time: 49.491944]
2023-06-16 11:58:40.624: epoch 34:	0.08714865  	0.16299354  	0.16104414  
2023-06-16 11:59:28.838: [iter 35 : loss : 1.0947 = 0.1501 + 0.9375 + 0.0070, time: 48.197075]
2023-06-16 11:59:29.668: epoch 35:	0.08691765  	0.16205473  	0.16031191  
2023-06-16 12:00:20.612: [iter 36 : loss : 1.0869 = 0.1429 + 0.9366 + 0.0073, time: 50.936607]
2023-06-16 12:00:21.016: epoch 36:	0.08668667  	0.16146451  	0.15989640  
2023-06-16 12:01:09.508: [iter 37 : loss : 1.0794 = 0.1360 + 0.9358 + 0.0076, time: 48.485907]
2023-06-16 12:01:09.915: epoch 37:	0.08649869  	0.16100059  	0.15937750  
2023-06-16 12:01:58.317: [iter 38 : loss : 1.0729 = 0.1299 + 0.9350 + 0.0079, time: 48.393576]
2023-06-16 12:01:59.136: epoch 38:	0.08651478  	0.16083121  	0.15912746  
2023-06-16 12:02:49.139: [iter 39 : loss : 1.0672 = 0.1247 + 0.9343 + 0.0082, time: 49.990744]
2023-06-16 12:02:49.891: epoch 39:	0.08625150  	0.15960404  	0.15856262  
2023-06-16 12:03:38.677: [iter 40 : loss : 1.0619 = 0.1197 + 0.9336 + 0.0085, time: 48.776749]
2023-06-16 12:03:39.528: epoch 40:	0.08590247  	0.15849832  	0.15775406  
2023-06-16 12:04:30.409: [iter 41 : loss : 1.0564 = 0.1148 + 0.9329 + 0.0087, time: 50.871797]
2023-06-16 12:04:31.244: epoch 41:	0.08554255  	0.15783161  	0.15707579  
2023-06-16 12:05:20.899: [iter 42 : loss : 1.0519 = 0.1105 + 0.9324 + 0.0090, time: 49.648888]
2023-06-16 12:05:21.444: epoch 42:	0.08530086  	0.15703140  	0.15642561  
2023-06-16 12:06:09.091: [iter 43 : loss : 1.0474 = 0.1063 + 0.9318 + 0.0092, time: 47.634975]
2023-06-16 12:06:09.911: epoch 43:	0.08513963  	0.15641846  	0.15582383  
2023-06-16 12:07:01.084: [iter 44 : loss : 1.0437 = 0.1029 + 0.9313 + 0.0095, time: 51.167636]
2023-06-16 12:07:01.489: epoch 44:	0.08495697  	0.15566979  	0.15529729  
2023-06-16 12:07:50.070: [iter 45 : loss : 1.0404 = 0.0999 + 0.9308 + 0.0097, time: 48.573486]
2023-06-16 12:07:50.482: epoch 45:	0.08467767  	0.15515001  	0.15455388  
2023-06-16 12:08:38.268: [iter 46 : loss : 1.0367 = 0.0964 + 0.9303 + 0.0099, time: 47.769478]
2023-06-16 12:08:39.064: epoch 46:	0.08435540  	0.15420491  	0.15376434  
2023-06-16 12:09:30.515: [iter 47 : loss : 1.0336 = 0.0936 + 0.9298 + 0.0102, time: 51.445380]
2023-06-16 12:09:31.019: epoch 47:	0.08421569  	0.15366431  	0.15329781  
2023-06-16 12:10:19.514: [iter 48 : loss : 1.0304 = 0.0906 + 0.9294 + 0.0104, time: 48.488074]
2023-06-16 12:10:19.915: epoch 48:	0.08402770  	0.15297846  	0.15285483  
2023-06-16 12:11:08.651: [iter 49 : loss : 1.0280 = 0.0884 + 0.9290 + 0.0106, time: 48.729974]
2023-06-16 12:11:09.467: epoch 49:	0.08371619  	0.15194152  	0.15190923  
2023-06-16 12:11:59.873: [iter 50 : loss : 1.0254 = 0.0860 + 0.9286 + 0.0108, time: 50.399619]
2023-06-16 12:12:00.289: epoch 50:	0.08343692  	0.15108533  	0.15131523  
2023-06-16 12:12:49.144: [iter 51 : loss : 1.0231 = 0.0837 + 0.9284 + 0.0110, time: 48.842167]
2023-06-16 12:12:49.973: epoch 51:	0.08332942  	0.15096425  	0.15124911  
2023-06-16 12:13:40.766: [iter 52 : loss : 1.0209 = 0.0817 + 0.9280 + 0.0112, time: 50.783093]
2023-06-16 12:13:41.594: epoch 52:	0.08317374  	0.15038772  	0.15056054  
2023-06-16 12:14:30.896: [iter 53 : loss : 1.0184 = 0.0794 + 0.9277 + 0.0114, time: 49.294479]
2023-06-16 12:14:31.757: epoch 53:	0.08291055  	0.14983736  	0.15012321  
2023-06-16 12:15:21.997: [iter 54 : loss : 1.0162 = 0.0773 + 0.9274 + 0.0116, time: 50.230400]
2023-06-16 12:15:22.853: epoch 54:	0.08276550  	0.14912580  	0.14962462  
2023-06-16 12:16:12.846: [iter 55 : loss : 1.0148 = 0.0759 + 0.9272 + 0.0117, time: 49.986291]
2023-06-16 12:16:13.418: epoch 55:	0.08263128  	0.14885351  	0.14908454  
2023-06-16 12:17:01.833: [iter 56 : loss : 1.0129 = 0.0741 + 0.9269 + 0.0119, time: 48.406046]
2023-06-16 12:17:02.662: epoch 56:	0.08248089  	0.14823973  	0.14856990  
2023-06-16 12:17:02.662: Early stopping is trigger at epoch: 56
2023-06-16 12:17:02.662: best_result@epoch 31:

2023-06-16 12:17:02.662: 		0.0872      	0.1640      	0.1624      
2023-06-16 14:26:21.221: my pid: 2464
2023-06-16 14:26:21.221: model: model.general_recommender.SGL
2023-06-16 14:26:21.221: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 14:26:21.221: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 14:26:26.263: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 14:27:07.577: [iter 1 : loss : 1.6077 = 0.6931 + 0.9146 + 0.0000, time: 41.312432]
2023-06-16 14:27:08.001: epoch 1:	0.00362589  	0.00870312  	0.00696696  
2023-06-16 14:27:08.001: Find a better model.
2023-06-16 14:27:47.507: [iter 2 : loss : 1.6054 = 0.6931 + 0.9124 + 0.0000, time: 39.500179]
2023-06-16 14:27:47.950: epoch 2:	0.00453907  	0.01059106  	0.00902180  
2023-06-16 14:27:47.950: Find a better model.
2023-06-16 14:28:29.120: [iter 3 : loss : 1.6053 = 0.6930 + 0.9122 + 0.0000, time: 41.164195]
2023-06-16 14:28:29.539: epoch 3:	0.00519442  	0.01149086  	0.00975186  
2023-06-16 14:28:29.539: Find a better model.
2023-06-16 14:29:10.400: [iter 4 : loss : 1.6052 = 0.6930 + 0.9122 + 0.0000, time: 40.855478]
2023-06-16 14:29:10.859: epoch 4:	0.00586587  	0.01245885  	0.01066181  
2023-06-16 14:29:10.859: Find a better model.
2023-06-16 14:29:51.040: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 40.173904]
2023-06-16 14:29:51.521: epoch 5:	0.00684352  	0.01433939  	0.01283906  
2023-06-16 14:29:51.521: Find a better model.
2023-06-16 14:30:31.911: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 40.383410]
2023-06-16 14:30:32.441: epoch 6:	0.00773526  	0.01653717  	0.01413273  
2023-06-16 14:30:32.441: Find a better model.
2023-06-16 14:31:13.217: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 40.768440]
2023-06-16 14:31:13.618: epoch 7:	0.00881501  	0.01800350  	0.01611263  
2023-06-16 14:31:13.618: Find a better model.
2023-06-16 14:31:54.810: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 41.178371]
2023-06-16 14:31:55.231: epoch 8:	0.00968527  	0.01954087  	0.01755548  
2023-06-16 14:31:55.231: Find a better model.
2023-06-16 14:32:35.642: [iter 9 : loss : 1.6053 = 0.6925 + 0.9127 + 0.0000, time: 40.405963]
2023-06-16 14:32:36.042: epoch 9:	0.01125922  	0.02398932  	0.02097641  
2023-06-16 14:32:36.042: Find a better model.
2023-06-16 14:33:15.729: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 39.679694]
2023-06-16 14:33:16.137: epoch 10:	0.01292451  	0.02723201  	0.02404989  
2023-06-16 14:33:16.137: Find a better model.
2023-06-16 14:33:58.295: [iter 11 : loss : 1.6049 = 0.6921 + 0.9128 + 0.0000, time: 42.151242]
2023-06-16 14:33:58.738: epoch 11:	0.01550840  	0.03242988  	0.02939294  
2023-06-16 14:33:58.738: Find a better model.
2023-06-16 14:34:40.411: [iter 12 : loss : 1.6047 = 0.6917 + 0.9130 + 0.0000, time: 41.665671]
2023-06-16 14:34:40.861: epoch 12:	0.01902699  	0.03990167  	0.03647991  
2023-06-16 14:34:40.861: Find a better model.
2023-06-16 14:35:22.446: [iter 13 : loss : 1.6044 = 0.6911 + 0.9133 + 0.0000, time: 41.578153]
2023-06-16 14:35:22.862: epoch 13:	0.02265839  	0.04702935  	0.04426131  
2023-06-16 14:35:22.862: Find a better model.
2023-06-16 14:36:03.601: [iter 14 : loss : 1.6037 = 0.6901 + 0.9136 + 0.0000, time: 40.732822]
2023-06-16 14:36:04.121: epoch 14:	0.02852432  	0.05823492  	0.05598475  
2023-06-16 14:36:04.121: Find a better model.
2023-06-16 14:36:45.684: [iter 15 : loss : 1.6023 = 0.6883 + 0.9140 + 0.0001, time: 41.554754]
2023-06-16 14:36:46.201: epoch 15:	0.03690359  	0.07517745  	0.07251934  
2023-06-16 14:36:46.201: Find a better model.
2023-06-16 14:37:27.552: [iter 16 : loss : 1.5995 = 0.6847 + 0.9147 + 0.0001, time: 41.344618]
2023-06-16 14:37:28.037: epoch 16:	0.04695910  	0.09418935  	0.09226504  
2023-06-16 14:37:28.038: Find a better model.
2023-06-16 14:38:10.299: [iter 17 : loss : 1.5929 = 0.6769 + 0.9159 + 0.0001, time: 42.254360]
2023-06-16 14:38:10.728: epoch 17:	0.05880335  	0.11506191  	0.11400163  
2023-06-16 14:38:10.728: Find a better model.
2023-06-16 14:38:53.290: [iter 18 : loss : 1.5783 = 0.6598 + 0.9182 + 0.0002, time: 42.554497]
2023-06-16 14:38:53.740: epoch 18:	0.06915407  	0.13231070  	0.13245133  
2023-06-16 14:38:53.740: Find a better model.
2023-06-16 14:39:34.644: [iter 19 : loss : 1.5486 = 0.6260 + 0.9222 + 0.0005, time: 40.897413]
2023-06-16 14:39:35.065: epoch 19:	0.07686213  	0.14421917  	0.14444166  
2023-06-16 14:39:35.065: Find a better model.
2023-06-16 14:40:17.257: [iter 20 : loss : 1.5026 = 0.5738 + 0.9280 + 0.0008, time: 42.185445]
2023-06-16 14:40:17.797: epoch 20:	0.08079939  	0.15112776  	0.15153503  
2023-06-16 14:40:17.797: Find a better model.
2023-06-16 14:41:00.431: [iter 21 : loss : 1.4465 = 0.5108 + 0.9344 + 0.0012, time: 42.628902]
2023-06-16 14:41:00.867: epoch 21:	0.08300708  	0.15573308  	0.15582605  
2023-06-16 14:41:00.867: Find a better model.
2023-06-16 14:41:41.785: [iter 22 : loss : 1.3905 = 0.4487 + 0.9400 + 0.0017, time: 40.912433]
2023-06-16 14:41:42.188: epoch 22:	0.08443055  	0.15876696  	0.15867865  
2023-06-16 14:41:42.188: Find a better model.
2023-06-16 14:42:24.560: [iter 23 : loss : 1.3407 = 0.3949 + 0.9436 + 0.0022, time: 42.364672]
2023-06-16 14:42:24.984: epoch 23:	0.08550491  	0.16090794  	0.16037068  
2023-06-16 14:42:24.984: Find a better model.
2023-06-16 14:43:06.105: [iter 24 : loss : 1.2981 = 0.3498 + 0.9455 + 0.0028, time: 41.114289]
2023-06-16 14:43:06.495: epoch 24:	0.08622996  	0.16239427  	0.16191655  
2023-06-16 14:43:06.495: Find a better model.
2023-06-16 14:43:45.115: [iter 25 : loss : 1.2628 = 0.3135 + 0.9461 + 0.0032, time: 38.612897]
2023-06-16 14:43:45.507: epoch 25:	0.08679404  	0.16371159  	0.16276343  
2023-06-16 14:43:45.507: Find a better model.
2023-06-16 14:44:24.368: [iter 26 : loss : 1.2326 = 0.2829 + 0.9460 + 0.0037, time: 38.854434]
2023-06-16 14:44:24.770: epoch 26:	0.08695520  	0.16412209  	0.16337322  
2023-06-16 14:44:24.770: Find a better model.
2023-06-16 14:45:03.863: [iter 27 : loss : 1.2070 = 0.2575 + 0.9453 + 0.0041, time: 39.086756]
2023-06-16 14:45:04.252: epoch 27:	0.08725064  	0.16488576  	0.16366550  
2023-06-16 14:45:04.253: Find a better model.
2023-06-16 14:45:43.053: [iter 28 : loss : 1.1853 = 0.2362 + 0.9446 + 0.0046, time: 38.793545]
2023-06-16 14:45:43.445: epoch 28:	0.08746556  	0.16550581  	0.16392988  
2023-06-16 14:45:43.446: Find a better model.
2023-06-16 14:46:22.512: [iter 29 : loss : 1.1672 = 0.2187 + 0.9435 + 0.0050, time: 39.059379]
2023-06-16 14:46:22.902: epoch 29:	0.08770195  	0.16559167  	0.16396914  
2023-06-16 14:46:22.903: Find a better model.
2023-06-16 14:47:01.727: [iter 30 : loss : 1.1507 = 0.2030 + 0.9424 + 0.0054, time: 38.817287]
2023-06-16 14:47:02.117: epoch 30:	0.08780397  	0.16583793  	0.16395040  
2023-06-16 14:47:02.117: Find a better model.
2023-06-16 14:47:41.203: [iter 31 : loss : 1.1360 = 0.1889 + 0.9413 + 0.0057, time: 39.079207]
2023-06-16 14:47:41.601: epoch 31:	0.08776636  	0.16493474  	0.16360663  
2023-06-16 14:48:20.658: [iter 32 : loss : 1.1241 = 0.1778 + 0.9402 + 0.0061, time: 39.051692]
2023-06-16 14:48:21.050: epoch 32:	0.08754074  	0.16450556  	0.16304636  
2023-06-16 14:48:59.874: [iter 33 : loss : 1.1126 = 0.1668 + 0.9393 + 0.0064, time: 38.817241]
2023-06-16 14:49:00.269: epoch 33:	0.08753535  	0.16416615  	0.16264194  
2023-06-16 14:49:39.474: [iter 34 : loss : 1.1033 = 0.1583 + 0.9383 + 0.0068, time: 39.198267]
2023-06-16 14:49:39.873: epoch 34:	0.08739038  	0.16352965  	0.16209576  
2023-06-16 14:50:18.990: [iter 35 : loss : 1.0941 = 0.1495 + 0.9375 + 0.0071, time: 39.109249]
2023-06-16 14:50:19.382: epoch 35:	0.08713255  	0.16298240  	0.16159107  
2023-06-16 14:50:58.551: [iter 36 : loss : 1.0864 = 0.1424 + 0.9366 + 0.0074, time: 39.163659]
2023-06-16 14:50:58.949: epoch 36:	0.08711112  	0.16257246  	0.16104065  
2023-06-16 14:51:37.927: [iter 37 : loss : 1.0789 = 0.1355 + 0.9357 + 0.0077, time: 38.971626]
2023-06-16 14:51:38.319: epoch 37:	0.08689091  	0.16204998  	0.16061111  
2023-06-16 14:52:17.382: [iter 38 : loss : 1.0726 = 0.1297 + 0.9349 + 0.0080, time: 39.055455]
2023-06-16 14:52:17.784: epoch 38:	0.08664373  	0.16169629  	0.15999547  
2023-06-16 14:52:57.374: [iter 39 : loss : 1.0666 = 0.1243 + 0.9341 + 0.0083, time: 39.582766]
2023-06-16 14:52:57.777: epoch 39:	0.08640201  	0.16074128  	0.15931149  
2023-06-16 14:53:36.936: [iter 40 : loss : 1.0614 = 0.1194 + 0.9335 + 0.0085, time: 39.153166]
2023-06-16 14:53:37.326: epoch 40:	0.08629988  	0.16010344  	0.15878032  
2023-06-16 14:54:16.527: [iter 41 : loss : 1.0561 = 0.1145 + 0.9328 + 0.0088, time: 39.195019]
2023-06-16 14:54:16.927: epoch 41:	0.08613332  	0.15974206  	0.15826672  
2023-06-16 14:54:56.123: [iter 42 : loss : 1.0517 = 0.1104 + 0.9323 + 0.0090, time: 39.188003]
2023-06-16 14:54:56.513: epoch 42:	0.08587010  	0.15862745  	0.15756141  
2023-06-16 14:55:35.556: [iter 43 : loss : 1.0471 = 0.1061 + 0.9317 + 0.0093, time: 39.035765]
2023-06-16 14:55:35.952: epoch 43:	0.08565526  	0.15803571  	0.15699799  
2023-06-16 14:56:15.120: [iter 44 : loss : 1.0433 = 0.1026 + 0.9312 + 0.0095, time: 39.160523]
2023-06-16 14:56:15.510: epoch 44:	0.08544583  	0.15745385  	0.15648165  
2023-06-16 14:56:54.655: [iter 45 : loss : 1.0403 = 0.0999 + 0.9307 + 0.0097, time: 39.138101]
2023-06-16 14:56:55.048: epoch 45:	0.08514506  	0.15664776  	0.15580335  
2023-06-16 14:57:34.429: [iter 46 : loss : 1.0367 = 0.0965 + 0.9302 + 0.0100, time: 39.374386]
2023-06-16 14:57:34.825: epoch 46:	0.08497318  	0.15611708  	0.15541139  
2023-06-16 14:58:14.045: [iter 47 : loss : 1.0337 = 0.0938 + 0.9297 + 0.0102, time: 39.212777]
2023-06-16 14:58:14.436: epoch 47:	0.08477982  	0.15520981  	0.15481724  
2023-06-16 14:58:53.455: [iter 48 : loss : 1.0303 = 0.0906 + 0.9293 + 0.0104, time: 39.013662]
2023-06-16 14:58:53.852: epoch 48:	0.08467776  	0.15445022  	0.15408669  
2023-06-16 14:59:33.508: [iter 49 : loss : 1.0276 = 0.0880 + 0.9290 + 0.0106, time: 39.648742]
2023-06-16 14:59:33.905: epoch 49:	0.08434475  	0.15359855  	0.15344970  
2023-06-16 15:00:13.036: [iter 50 : loss : 1.0252 = 0.0858 + 0.9285 + 0.0108, time: 39.123563]
2023-06-16 15:00:13.429: epoch 50:	0.08394189  	0.15254924  	0.15264997  
2023-06-16 15:00:52.784: [iter 51 : loss : 1.0231 = 0.0838 + 0.9283 + 0.0110, time: 39.349642]
2023-06-16 15:00:53.175: epoch 51:	0.08388814  	0.15202881  	0.15226308  
2023-06-16 15:01:32.774: [iter 52 : loss : 1.0208 = 0.0816 + 0.9280 + 0.0112, time: 39.592614]
2023-06-16 15:01:33.167: epoch 52:	0.08350139  	0.15070260  	0.15150370  
2023-06-16 15:02:12.608: [iter 53 : loss : 1.0183 = 0.0794 + 0.9275 + 0.0114, time: 39.434219]
2023-06-16 15:02:13.001: epoch 53:	0.08330801  	0.15008371  	0.15093260  
2023-06-16 15:02:52.362: [iter 54 : loss : 1.0164 = 0.0775 + 0.9273 + 0.0116, time: 39.354383]
2023-06-16 15:02:52.758: epoch 54:	0.08312007  	0.14951445  	0.15032901  
2023-06-16 15:03:32.118: [iter 55 : loss : 1.0146 = 0.0758 + 0.9270 + 0.0117, time: 39.353633]
2023-06-16 15:03:32.513: epoch 55:	0.08278163  	0.14871712  	0.14969310  
2023-06-16 15:03:32.513: Early stopping is trigger at epoch: 55
2023-06-16 15:03:32.513: best_result@epoch 30:

2023-06-16 15:03:32.513: 		0.0878      	0.1658      	0.1640      
2023-06-16 19:09:15.412: my pid: 3228
2023-06-16 19:09:15.412: model: model.general_recommender.SGL
2023-06-16 19:09:15.412: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 19:09:15.413: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 19:09:20.926: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 19:10:02.630: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 41.703465]
2023-06-16 19:10:03.141: epoch 1:	0.00356143  	0.00838000  	0.00691316  
2023-06-16 19:10:03.141: Find a better model.
2023-06-16 19:10:44.177: [iter 2 : loss : 1.6055 = 0.6931 + 0.9125 + 0.0000, time: 41.029661]
2023-06-16 19:10:44.594: epoch 2:	0.00436718  	0.01027131  	0.00843081  
2023-06-16 19:10:44.594: Find a better model.
2023-06-16 19:11:26.155: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 41.554759]
2023-06-16 19:11:26.592: epoch 3:	0.00565101  	0.01194698  	0.01050170  
2023-06-16 19:11:26.592: Find a better model.
2023-06-16 19:12:07.326: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 40.725885]
2023-06-16 19:12:07.775: epoch 4:	0.00613446  	0.01351425  	0.01172612  
2023-06-16 19:12:07.775: Find a better model.
2023-06-16 19:12:49.545: [iter 5 : loss : 1.6053 = 0.6929 + 0.9123 + 0.0000, time: 41.762971]
2023-06-16 19:12:49.976: epoch 5:	0.00711749  	0.01467186  	0.01324691  
2023-06-16 19:12:49.976: Find a better model.
2023-06-16 19:13:31.394: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 41.409747]
2023-06-16 19:13:31.807: epoch 6:	0.00845510  	0.01776996  	0.01569880  
2023-06-16 19:13:31.807: Find a better model.
2023-06-16 19:14:12.649: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 40.834490]
2023-06-16 19:14:13.159: epoch 7:	0.00970674  	0.01996136  	0.01837361  
2023-06-16 19:14:13.159: Find a better model.
2023-06-16 19:14:54.620: [iter 8 : loss : 1.6052 = 0.6927 + 0.9126 + 0.0000, time: 41.454306]
2023-06-16 19:14:55.049: epoch 8:	0.01100136  	0.02310582  	0.02059919  
2023-06-16 19:14:55.049: Find a better model.
2023-06-16 19:15:36.261: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 41.204937]
2023-06-16 19:15:36.696: epoch 9:	0.01272575  	0.02620837  	0.02427444  
2023-06-16 19:15:36.696: Find a better model.
2023-06-16 19:16:18.031: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 41.328371]
2023-06-16 19:16:18.541: epoch 10:	0.01442327  	0.03052702  	0.02829151  
2023-06-16 19:16:18.541: Find a better model.
2023-06-16 19:17:01.634: [iter 11 : loss : 1.6049 = 0.6920 + 0.9129 + 0.0000, time: 43.086524]
2023-06-16 19:17:02.054: epoch 11:	0.01751213  	0.03601560  	0.03300736  
2023-06-16 19:17:02.054: Find a better model.
2023-06-16 19:17:44.624: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 42.562190]
2023-06-16 19:17:45.042: epoch 12:	0.02057948  	0.04172894  	0.04003725  
2023-06-16 19:17:45.043: Find a better model.
2023-06-16 19:18:26.977: [iter 13 : loss : 1.6043 = 0.6909 + 0.9134 + 0.0000, time: 41.921763]
2023-06-16 19:18:27.487: epoch 13:	0.02498978  	0.05049897  	0.04919590  
2023-06-16 19:18:27.487: Find a better model.
2023-06-16 19:19:10.444: [iter 14 : loss : 1.6035 = 0.6898 + 0.9137 + 0.0000, time: 42.949944]
2023-06-16 19:19:10.862: epoch 14:	0.03059232  	0.06249902  	0.06085321  
2023-06-16 19:19:10.862: Find a better model.
2023-06-16 19:19:52.698: [iter 15 : loss : 1.6020 = 0.6878 + 0.9142 + 0.0001, time: 41.828582]
2023-06-16 19:19:53.243: epoch 15:	0.03922950  	0.07952610  	0.07775551  
2023-06-16 19:19:53.243: Find a better model.
2023-06-16 19:20:36.174: [iter 16 : loss : 1.5986 = 0.6836 + 0.9149 + 0.0001, time: 42.922481]
2023-06-16 19:20:36.581: epoch 16:	0.04949449  	0.09819209  	0.09666926  
2023-06-16 19:20:36.581: Find a better model.
2023-06-16 19:21:18.264: [iter 17 : loss : 1.5911 = 0.6746 + 0.9163 + 0.0001, time: 41.674667]
2023-06-16 19:21:18.693: epoch 17:	0.06022673  	0.11650835  	0.11718038  
2023-06-16 19:21:18.693: Find a better model.
2023-06-16 19:22:01.643: [iter 18 : loss : 1.5741 = 0.6550 + 0.9189 + 0.0003, time: 42.943011]
2023-06-16 19:22:02.059: epoch 18:	0.07031968  	0.13368137  	0.13486320  
2023-06-16 19:22:02.059: Find a better model.
2023-06-16 19:22:45.423: [iter 19 : loss : 1.5415 = 0.6179 + 0.9231 + 0.0005, time: 43.356947]
2023-06-16 19:22:45.850: epoch 19:	0.07714154  	0.14544979  	0.14619884  
2023-06-16 19:22:45.850: Find a better model.
2023-06-16 19:23:27.781: [iter 20 : loss : 1.4934 = 0.5635 + 0.9290 + 0.0009, time: 41.924401]
2023-06-16 19:23:28.352: epoch 20:	0.08125073  	0.15255637  	0.15355639  
2023-06-16 19:23:28.352: Find a better model.
2023-06-16 19:24:11.603: [iter 21 : loss : 1.4374 = 0.5008 + 0.9353 + 0.0013, time: 43.242824]
2023-06-16 19:24:12.041: epoch 21:	0.08353901  	0.15676275  	0.15736827  
2023-06-16 19:24:12.041: Find a better model.
2023-06-16 19:24:54.311: [iter 22 : loss : 1.3825 = 0.4403 + 0.9404 + 0.0018, time: 42.261927]
2023-06-16 19:24:54.748: epoch 22:	0.08476369  	0.16044688  	0.15996426  
2023-06-16 19:24:54.748: Find a better model.
2023-06-16 19:25:37.753: [iter 23 : loss : 1.3343 = 0.3883 + 0.9437 + 0.0023, time: 42.997801]
2023-06-16 19:25:38.218: epoch 23:	0.08578423  	0.16269161  	0.16186199  
2023-06-16 19:25:38.218: Find a better model.
2023-06-16 19:26:21.203: [iter 24 : loss : 1.2928 = 0.3445 + 0.9454 + 0.0028, time: 42.978219]
2023-06-16 19:26:21.615: epoch 24:	0.08639124  	0.16409296  	0.16324018  
2023-06-16 19:26:21.615: Find a better model.
2023-06-16 19:27:04.476: [iter 25 : loss : 1.2586 = 0.3094 + 0.9459 + 0.0033, time: 42.852679]
2023-06-16 19:27:04.992: epoch 25:	0.08696608  	0.16573299  	0.16426727  
2023-06-16 19:27:04.992: Find a better model.
2023-06-16 19:27:48.685: [iter 26 : loss : 1.2289 = 0.2795 + 0.9456 + 0.0038, time: 43.685422]
2023-06-16 19:27:49.172: epoch 26:	0.08708429  	0.16596723  	0.16447778  
2023-06-16 19:27:49.172: Find a better model.
2023-06-16 19:28:31.455: [iter 27 : loss : 1.2038 = 0.2546 + 0.9450 + 0.0042, time: 42.275177]
2023-06-16 19:28:32.010: epoch 27:	0.08719176  	0.16624428  	0.16462317  
2023-06-16 19:28:32.010: Find a better model.
2023-06-16 19:29:15.548: [iter 28 : loss : 1.1829 = 0.2339 + 0.9444 + 0.0046, time: 43.531760]
2023-06-16 19:29:15.980: epoch 28:	0.08739044  	0.16675074  	0.16485275  
2023-06-16 19:29:15.980: Find a better model.
2023-06-16 19:29:58.490: [iter 29 : loss : 1.1650 = 0.2167 + 0.9432 + 0.0050, time: 42.497687]
2023-06-16 19:29:59.024: epoch 29:	0.08743879  	0.16648562  	0.16457427  
2023-06-16 19:30:42.734: [iter 30 : loss : 1.1486 = 0.2010 + 0.9422 + 0.0054, time: 43.702188]
2023-06-16 19:30:43.202: epoch 30:	0.08734743  	0.16585085  	0.16408452  
2023-06-16 19:31:26.059: [iter 31 : loss : 1.1345 = 0.1875 + 0.9411 + 0.0058, time: 42.849397]
2023-06-16 19:31:26.573: epoch 31:	0.08729370  	0.16575377  	0.16393983  
2023-06-16 19:32:06.806: [iter 32 : loss : 1.1226 = 0.1764 + 0.9400 + 0.0061, time: 40.223515]
2023-06-16 19:32:07.222: epoch 32:	0.08734203  	0.16563652  	0.16368629  
2023-06-16 19:32:47.324: [iter 33 : loss : 1.1112 = 0.1657 + 0.9391 + 0.0065, time: 40.094952]
2023-06-16 19:32:47.720: epoch 33:	0.08724009  	0.16513687  	0.16355722  
2023-06-16 19:33:27.899: [iter 34 : loss : 1.1022 = 0.1572 + 0.9382 + 0.0068, time: 40.171121]
2023-06-16 19:33:28.323: epoch 34:	0.08700368  	0.16411121  	0.16277105  
2023-06-16 19:34:08.474: [iter 35 : loss : 1.0930 = 0.1485 + 0.9373 + 0.0071, time: 40.144965]
2023-06-16 19:34:08.871: epoch 35:	0.08684797  	0.16392003  	0.16222166  
2023-06-16 19:34:49.092: [iter 36 : loss : 1.0854 = 0.1415 + 0.9365 + 0.0074, time: 40.213859]
2023-06-16 19:34:49.494: epoch 36:	0.08669757  	0.16349675  	0.16170067  
2023-06-16 19:35:29.867: [iter 37 : loss : 1.0778 = 0.1345 + 0.9356 + 0.0077, time: 40.364949]
2023-06-16 19:35:30.294: epoch 37:	0.08663301  	0.16327262  	0.16147171  
2023-06-16 19:36:11.074: [iter 38 : loss : 1.0715 = 0.1287 + 0.9347 + 0.0080, time: 40.774167]
2023-06-16 19:36:11.475: epoch 38:	0.08635373  	0.16239436  	0.16090411  
2023-06-16 19:36:52.107: [iter 39 : loss : 1.0659 = 0.1237 + 0.9340 + 0.0083, time: 40.622808]
2023-06-16 19:36:52.586: epoch 39:	0.08626238  	0.16217850  	0.16050376  
2023-06-16 19:37:35.496: [iter 40 : loss : 1.0608 = 0.1188 + 0.9334 + 0.0085, time: 42.902346]
2023-06-16 19:37:36.000: epoch 40:	0.08610122  	0.16131061  	0.15973501  
2023-06-16 19:38:19.281: [iter 41 : loss : 1.0555 = 0.1140 + 0.9327 + 0.0088, time: 43.274583]
2023-06-16 19:38:19.699: epoch 41:	0.08591864  	0.16050580  	0.15910465  
2023-06-16 19:39:03.440: [iter 42 : loss : 1.0511 = 0.1099 + 0.9322 + 0.0091, time: 43.734009]
2023-06-16 19:39:03.866: epoch 42:	0.08562317  	0.15953173  	0.15824614  
2023-06-16 19:39:46.399: [iter 43 : loss : 1.0466 = 0.1057 + 0.9316 + 0.0093, time: 42.526090]
2023-06-16 19:39:46.966: epoch 43:	0.08548350  	0.15877752  	0.15774746  
2023-06-16 19:40:30.291: [iter 44 : loss : 1.0431 = 0.1024 + 0.9312 + 0.0095, time: 43.317514]
2023-06-16 19:40:30.727: epoch 44:	0.08510211  	0.15800206  	0.15696248  
2023-06-16 19:41:13.340: [iter 45 : loss : 1.0397 = 0.0993 + 0.9306 + 0.0098, time: 42.605543]
2023-06-16 19:41:13.908: epoch 45:	0.08493023  	0.15752804  	0.15636458  
2023-06-16 19:41:57.315: [iter 46 : loss : 1.0361 = 0.0960 + 0.9302 + 0.0100, time: 43.399328]
2023-06-16 19:41:57.737: epoch 46:	0.08468322  	0.15653889  	0.15556183  
2023-06-16 19:42:40.290: [iter 47 : loss : 1.0332 = 0.0933 + 0.9297 + 0.0102, time: 42.545261]
2023-06-16 19:42:40.733: epoch 47:	0.08441460  	0.15560792  	0.15491652  
2023-06-16 19:43:24.302: [iter 48 : loss : 1.0301 = 0.0903 + 0.9293 + 0.0104, time: 43.560449]
2023-06-16 19:43:24.744: epoch 48:	0.08417822  	0.15460199  	0.15430722  
2023-06-16 19:44:12.348: my pid: 2172
2023-06-16 19:44:12.348: model: model.general_recommender.SGL
2023-06-16 19:44:12.348: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 19:44:12.348: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 19:44:17.917: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 19:45:00.169: [iter 1 : loss : 1.6079 = 0.6931 + 0.9147 + 0.0000, time: 42.251657]
2023-06-16 19:45:00.603: epoch 1:	0.00375481  	0.00916205  	0.00734853  
2023-06-16 19:45:00.603: Find a better model.
2023-06-16 19:45:42.295: [iter 2 : loss : 1.6055 = 0.6931 + 0.9124 + 0.0000, time: 41.685018]
2023-06-16 19:45:42.734: epoch 2:	0.00456594  	0.01003046  	0.00829924  
2023-06-16 19:45:42.734: Find a better model.
2023-06-16 19:46:23.467: [iter 3 : loss : 1.6053 = 0.6930 + 0.9122 + 0.0000, time: 40.725471]
2023-06-16 19:46:23.900: epoch 3:	0.00542003  	0.01112858  	0.00977958  
2023-06-16 19:46:23.900: Find a better model.
2023-06-16 19:47:05.749: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 41.842109]
2023-06-16 19:47:06.199: epoch 4:	0.00591959  	0.01240903  	0.01082131  
2023-06-16 19:47:06.200: Find a better model.
2023-06-16 19:47:48.274: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 42.066491]
2023-06-16 19:47:48.729: epoch 5:	0.00721418  	0.01475099  	0.01318435  
2023-06-16 19:47:48.730: Find a better model.
2023-06-16 19:48:29.773: [iter 6 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 41.034834]
2023-06-16 19:48:30.246: epoch 6:	0.00829393  	0.01639548  	0.01486202  
2023-06-16 19:48:30.246: Find a better model.
2023-06-16 19:49:12.268: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 42.014535]
2023-06-16 19:49:12.684: epoch 7:	0.00920716  	0.01783748  	0.01665525  
2023-06-16 19:49:12.684: Find a better model.
2023-06-16 19:49:54.788: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 42.097526]
2023-06-16 19:49:55.289: epoch 8:	0.01051253  	0.02098795  	0.01944868  
2023-06-16 19:49:55.289: Find a better model.
2023-06-16 19:50:36.206: [iter 9 : loss : 1.6053 = 0.6926 + 0.9127 + 0.0000, time: 40.910368]
2023-06-16 19:50:36.658: epoch 9:	0.01183400  	0.02340970  	0.02217294  
2023-06-16 19:50:36.658: Find a better model.
2023-06-16 19:51:18.974: [iter 10 : loss : 1.6051 = 0.6924 + 0.9127 + 0.0000, time: 42.308090]
2023-06-16 19:51:19.529: epoch 10:	0.01370879  	0.02733913  	0.02555753  
2023-06-16 19:51:19.530: Find a better model.
2023-06-16 19:52:02.692: [iter 11 : loss : 1.6049 = 0.6921 + 0.9128 + 0.0000, time: 43.155943]
2023-06-16 19:52:03.204: epoch 11:	0.01623360  	0.03208201  	0.03061279  
2023-06-16 19:52:03.204: Find a better model.
2023-06-16 19:52:45.540: [iter 12 : loss : 1.6048 = 0.6917 + 0.9130 + 0.0000, time: 42.327991]
2023-06-16 19:52:45.991: epoch 12:	0.01954808  	0.03856622  	0.03691941  
2023-06-16 19:52:45.991: Find a better model.
2023-06-16 19:53:29.057: [iter 13 : loss : 1.6044 = 0.6912 + 0.9132 + 0.0000, time: 43.060173]
2023-06-16 19:53:29.574: epoch 13:	0.02331378  	0.04715471  	0.04519895  
2023-06-16 19:53:29.575: Find a better model.
2023-06-16 19:54:12.973: [iter 14 : loss : 1.6038 = 0.6902 + 0.9136 + 0.0000, time: 43.390631]
2023-06-16 19:54:13.429: epoch 14:	0.02843299  	0.05833836  	0.05629005  
2023-06-16 19:54:13.429: Find a better model.
2023-06-16 19:54:55.412: [iter 15 : loss : 1.6025 = 0.6885 + 0.9139 + 0.0001, time: 41.975232]
2023-06-16 19:54:55.835: epoch 15:	0.03597435  	0.07390637  	0.07143679  
2023-06-16 19:54:55.836: Find a better model.
2023-06-16 19:55:38.880: [iter 16 : loss : 1.6000 = 0.6853 + 0.9146 + 0.0001, time: 43.038332]
2023-06-16 19:55:39.334: epoch 16:	0.04622857  	0.09242442  	0.09125268  
2023-06-16 19:55:39.334: Find a better model.
2023-06-16 19:56:22.426: [iter 17 : loss : 1.5940 = 0.6782 + 0.9157 + 0.0001, time: 43.086127]
2023-06-16 19:56:22.843: epoch 17:	0.05793307  	0.11273625  	0.11303452  
2023-06-16 19:56:22.843: Find a better model.
2023-06-16 19:57:04.767: [iter 18 : loss : 1.5805 = 0.6624 + 0.9179 + 0.0002, time: 41.916217]
2023-06-16 19:57:05.327: epoch 18:	0.06944939  	0.13206656  	0.13267425  
2023-06-16 19:57:05.327: Find a better model.
2023-06-16 19:57:48.641: [iter 19 : loss : 1.5526 = 0.6306 + 0.9215 + 0.0004, time: 43.307209]
2023-06-16 19:57:49.121: epoch 19:	0.07645387  	0.14477800  	0.14543667  
2023-06-16 19:57:49.121: Find a better model.
2023-06-16 19:58:31.462: [iter 20 : loss : 1.5081 = 0.5801 + 0.9273 + 0.0007, time: 42.318276]
2023-06-16 19:58:31.892: epoch 20:	0.08047702  	0.15223266  	0.15255098  
2023-06-16 19:58:31.892: Find a better model.
2023-06-16 19:59:15.032: [iter 21 : loss : 1.4524 = 0.5176 + 0.9336 + 0.0012, time: 43.132885]
2023-06-16 19:59:15.473: epoch 21:	0.08310916  	0.15637180  	0.15642676  
2023-06-16 19:59:15.473: Find a better model.
2023-06-16 19:59:58.525: [iter 22 : loss : 1.3959 = 0.4550 + 0.9393 + 0.0017, time: 43.046155]
2023-06-16 19:59:58.940: epoch 22:	0.08468837  	0.15941331  	0.15903951  
2023-06-16 19:59:58.940: Find a better model.
2023-06-16 20:00:42.018: [iter 23 : loss : 1.3454 = 0.4001 + 0.9431 + 0.0022, time: 43.064506]
2023-06-16 20:00:42.544: epoch 23:	0.08578948  	0.16187152  	0.16110986  
2023-06-16 20:00:42.545: Find a better model.
2023-06-16 20:01:26.158: [iter 24 : loss : 1.3021 = 0.3542 + 0.9452 + 0.0027, time: 43.578411]
2023-06-16 20:01:26.582: epoch 24:	0.08651467  	0.16349714  	0.16237487  
2023-06-16 20:01:26.582: Find a better model.
2023-06-16 20:02:06.916: [iter 25 : loss : 1.2662 = 0.3172 + 0.9459 + 0.0032, time: 40.325780]
2023-06-16 20:02:07.332: epoch 25:	0.08713773  	0.16459729  	0.16338669  
2023-06-16 20:02:07.332: Find a better model.
2023-06-16 20:02:47.079: [iter 26 : loss : 1.2352 = 0.2856 + 0.9459 + 0.0036, time: 39.738717]
2023-06-16 20:02:47.477: epoch 26:	0.08740630  	0.16492252  	0.16382690  
2023-06-16 20:02:47.477: Find a better model.
2023-06-16 20:03:27.543: [iter 27 : loss : 1.2091 = 0.2598 + 0.9452 + 0.0041, time: 40.060376]
2023-06-16 20:03:27.938: epoch 27:	0.08756219  	0.16524729  	0.16413848  
2023-06-16 20:03:27.938: Find a better model.
2023-06-16 20:04:08.081: [iter 28 : loss : 1.1872 = 0.2383 + 0.9444 + 0.0045, time: 40.134951]
2023-06-16 20:04:08.477: epoch 28:	0.08749782  	0.16541941  	0.16419992  
2023-06-16 20:04:08.477: Find a better model.
2023-06-16 20:04:48.818: [iter 29 : loss : 1.1687 = 0.2204 + 0.9434 + 0.0049, time: 40.334942]
2023-06-16 20:04:49.232: epoch 29:	0.08731513  	0.16498224  	0.16389541  
2023-06-16 20:05:29.205: [iter 30 : loss : 1.1520 = 0.2043 + 0.9423 + 0.0053, time: 39.965716]
2023-06-16 20:05:29.601: epoch 30:	0.08756229  	0.16539942  	0.16412905  
2023-06-16 20:06:09.786: [iter 31 : loss : 1.1372 = 0.1902 + 0.9413 + 0.0057, time: 40.177916]
2023-06-16 20:06:10.201: epoch 31:	0.08751396  	0.16557540  	0.16382091  
2023-06-16 20:06:10.201: Find a better model.
2023-06-16 20:06:50.395: [iter 32 : loss : 1.1252 = 0.1789 + 0.9402 + 0.0061, time: 40.186618]
2023-06-16 20:06:50.792: epoch 32:	0.08765902  	0.16563527  	0.16379929  
2023-06-16 20:06:50.792: Find a better model.
2023-06-16 20:07:30.841: [iter 33 : loss : 1.1135 = 0.1679 + 0.9392 + 0.0064, time: 40.042922]
2023-06-16 20:07:31.255: epoch 33:	0.08744414  	0.16492416  	0.16329411  
2023-06-16 20:08:11.521: [iter 34 : loss : 1.1041 = 0.1592 + 0.9382 + 0.0067, time: 40.259588]
2023-06-16 20:08:11.917: epoch 34:	0.08727757  	0.16430885  	0.16270119  
2023-06-16 20:08:52.500: [iter 35 : loss : 1.0947 = 0.1502 + 0.9374 + 0.0071, time: 40.577692]
2023-06-16 20:08:52.905: epoch 35:	0.08717015  	0.16378060  	0.16222307  
2023-06-16 20:09:35.503: [iter 36 : loss : 1.0868 = 0.1430 + 0.9365 + 0.0074, time: 42.591692]
2023-06-16 20:09:35.927: epoch 36:	0.08699290  	0.16304252  	0.16163833  
2023-06-16 20:10:18.950: [iter 37 : loss : 1.0793 = 0.1361 + 0.9356 + 0.0077, time: 43.015377]
2023-06-16 20:10:19.450: epoch 37:	0.08670282  	0.16237640  	0.16104652  
2023-06-16 20:11:02.791: [iter 38 : loss : 1.0728 = 0.1300 + 0.9348 + 0.0080, time: 43.333212]
2023-06-16 20:11:03.276: epoch 38:	0.08655779  	0.16160233  	0.16043657  
2023-06-16 20:11:45.186: [iter 39 : loss : 1.0670 = 0.1247 + 0.9341 + 0.0082, time: 41.901034]
2023-06-16 20:11:45.613: epoch 39:	0.08628918  	0.16084878  	0.15957318  
2023-06-16 20:12:28.888: [iter 40 : loss : 1.0619 = 0.1200 + 0.9334 + 0.0085, time: 43.267661]
2023-06-16 20:12:29.329: epoch 40:	0.08621936  	0.16038898  	0.15913026  
2023-06-16 20:13:12.280: [iter 41 : loss : 1.0565 = 0.1150 + 0.9327 + 0.0088, time: 42.943915]
2023-06-16 20:13:12.778: epoch 41:	0.08587556  	0.15939701  	0.15823372  
2023-06-16 20:13:56.467: [iter 42 : loss : 1.0520 = 0.1108 + 0.9322 + 0.0090, time: 43.682509]
2023-06-16 20:13:56.881: epoch 42:	0.08563386  	0.15880981  	0.15776476  
2023-06-16 20:14:40.353: [iter 43 : loss : 1.0472 = 0.1064 + 0.9316 + 0.0093, time: 43.465194]
2023-06-16 20:14:40.768: epoch 43:	0.08545665  	0.15826072  	0.15722214  
2023-06-16 20:15:24.536: [iter 44 : loss : 1.0437 = 0.1031 + 0.9312 + 0.0095, time: 43.761214]
2023-06-16 20:15:24.958: epoch 44:	0.08514502  	0.15773980  	0.15665959  
2023-06-16 20:15:44.856: my pid: 11040
2023-06-16 20:15:44.856: model: model.general_recommender.SGL
2023-06-16 20:15:44.856: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 20:15:44.856: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 20:15:50.463: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 20:16:31.864: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 41.401183]
2023-06-16 20:16:32.378: epoch 1:	0.00342714  	0.00802059  	0.00639309  
2023-06-16 20:16:32.378: Find a better model.
2023-06-16 20:17:14.471: [iter 2 : loss : 1.6056 = 0.6931 + 0.9126 + 0.0000, time: 42.085274]
2023-06-16 20:17:14.892: epoch 2:	0.00463039  	0.00996830  	0.00830404  
2023-06-16 20:17:14.892: Find a better model.
2023-06-16 20:17:53.982: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 39.083935]
2023-06-16 20:17:54.398: epoch 3:	0.00570473  	0.01187801  	0.01021312  
2023-06-16 20:17:54.398: Find a better model.
2023-06-16 20:18:33.326: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 38.922337]
2023-06-16 20:18:33.731: epoch 4:	0.00640304  	0.01356152  	0.01175140  
2023-06-16 20:18:33.731: Find a better model.
2023-06-16 20:19:12.628: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 38.890516]
2023-06-16 20:19:13.033: epoch 5:	0.00745055  	0.01475574  	0.01316854  
2023-06-16 20:19:13.033: Find a better model.
2023-06-16 20:19:51.697: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 38.658508]
2023-06-16 20:19:52.129: epoch 6:	0.00827246  	0.01690003  	0.01498211  
2023-06-16 20:19:52.129: Find a better model.
2023-06-16 20:20:31.140: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 39.002938]
2023-06-16 20:20:31.572: epoch 7:	0.00963692  	0.01937053  	0.01739179  
2023-06-16 20:20:31.572: Find a better model.
2023-06-16 20:21:10.506: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 38.927935]
2023-06-16 20:21:10.911: epoch 8:	0.01070055  	0.02171359  	0.01962973  
2023-06-16 20:21:10.911: Find a better model.
2023-06-16 20:21:49.724: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 38.805100]
2023-06-16 20:21:50.174: epoch 9:	0.01218318  	0.02448993  	0.02276001  
2023-06-16 20:21:50.174: Find a better model.
2023-06-16 20:22:29.059: [iter 10 : loss : 1.6052 = 0.6923 + 0.9128 + 0.0000, time: 38.878159]
2023-06-16 20:22:29.468: epoch 10:	0.01378400  	0.02811194  	0.02598878  
2023-06-16 20:22:29.468: Find a better model.
2023-06-16 20:23:09.280: [iter 11 : loss : 1.6049 = 0.6920 + 0.9128 + 0.0000, time: 39.805178]
2023-06-16 20:23:09.710: epoch 11:	0.01707699  	0.03474191  	0.03224210  
2023-06-16 20:23:09.710: Find a better model.
2023-06-16 20:23:49.474: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 39.757383]
2023-06-16 20:23:49.874: epoch 12:	0.02059023  	0.04195422  	0.04010173  
2023-06-16 20:23:49.874: Find a better model.
2023-06-16 20:24:29.441: [iter 13 : loss : 1.6044 = 0.6910 + 0.9133 + 0.0000, time: 39.560764]
2023-06-16 20:24:29.866: epoch 13:	0.02464598  	0.05036412  	0.04777714  
2023-06-16 20:24:29.867: Find a better model.
2023-06-16 20:25:09.590: [iter 14 : loss : 1.6037 = 0.6900 + 0.9137 + 0.0000, time: 39.716902]
2023-06-16 20:25:09.990: epoch 14:	0.03040963  	0.06170401  	0.05992696  
2023-06-16 20:25:09.990: Find a better model.
2023-06-16 20:25:49.592: [iter 15 : loss : 1.6022 = 0.6881 + 0.9141 + 0.0001, time: 39.593679]
2023-06-16 20:25:49.994: epoch 15:	0.03813906  	0.07787848  	0.07628591  
2023-06-16 20:25:49.994: Find a better model.
2023-06-16 20:26:29.694: [iter 16 : loss : 1.5992 = 0.6843 + 0.9148 + 0.0001, time: 39.693244]
2023-06-16 20:26:30.147: epoch 16:	0.04821604  	0.09631646  	0.09488423  
2023-06-16 20:26:30.147: Find a better model.
2023-06-16 20:27:09.842: [iter 17 : loss : 1.5923 = 0.6761 + 0.9161 + 0.0001, time: 39.687644]
2023-06-16 20:27:10.258: epoch 17:	0.06003317  	0.11720801  	0.11619605  
2023-06-16 20:27:10.258: Find a better model.
2023-06-16 20:27:50.024: [iter 18 : loss : 1.5767 = 0.6580 + 0.9185 + 0.0003, time: 39.760061]
2023-06-16 20:27:50.433: epoch 18:	0.07054526  	0.13556616  	0.13563056  
2023-06-16 20:27:50.433: Find a better model.
2023-06-16 20:28:30.173: [iter 19 : loss : 1.5457 = 0.6229 + 0.9224 + 0.0005, time: 39.732177]
2023-06-16 20:28:30.576: epoch 19:	0.07732423  	0.14615324  	0.14695518  
2023-06-16 20:28:30.576: Find a better model.
2023-06-16 20:29:10.388: [iter 20 : loss : 1.4985 = 0.5694 + 0.9283 + 0.0008, time: 39.805204]
2023-06-16 20:29:10.785: epoch 20:	0.08114322  	0.15274642  	0.15376255  
2023-06-16 20:29:10.785: Find a better model.
2023-06-16 20:29:50.538: [iter 21 : loss : 1.4420 = 0.5061 + 0.9346 + 0.0013, time: 39.747262]
2023-06-16 20:29:50.934: epoch 21:	0.08329725  	0.15669033  	0.15735240  
2023-06-16 20:29:50.934: Find a better model.
2023-06-16 20:30:30.751: [iter 22 : loss : 1.3860 = 0.4441 + 0.9402 + 0.0018, time: 39.810473]
2023-06-16 20:30:31.191: epoch 22:	0.08477979  	0.16002491  	0.15999885  
2023-06-16 20:30:31.191: Find a better model.
2023-06-16 20:31:10.953: [iter 23 : loss : 1.3366 = 0.3907 + 0.9436 + 0.0023, time: 39.755008]
2023-06-16 20:31:11.367: epoch 23:	0.08576812  	0.16222423  	0.16177462  
2023-06-16 20:31:11.367: Find a better model.
2023-06-16 20:31:51.043: [iter 24 : loss : 1.2945 = 0.3462 + 0.9455 + 0.0028, time: 39.669413]
2023-06-16 20:31:51.445: epoch 24:	0.08655229  	0.16375579  	0.16306958  
2023-06-16 20:31:51.445: Find a better model.
2023-06-16 20:32:31.268: [iter 25 : loss : 1.2596 = 0.3104 + 0.9460 + 0.0033, time: 39.816248]
2023-06-16 20:32:31.666: epoch 25:	0.08720218  	0.16488379  	0.16386403  
2023-06-16 20:32:31.666: Find a better model.
2023-06-16 20:33:11.691: [iter 26 : loss : 1.2296 = 0.2801 + 0.9458 + 0.0037, time: 40.018588]
2023-06-16 20:33:12.113: epoch 26:	0.08755675  	0.16567637  	0.16403256  
2023-06-16 20:33:12.113: Find a better model.
2023-06-16 20:33:52.125: [iter 27 : loss : 1.2044 = 0.2550 + 0.9452 + 0.0042, time: 39.999627]
2023-06-16 20:33:52.521: epoch 27:	0.08755678  	0.16582501  	0.16435251  
2023-06-16 20:33:52.521: Find a better model.
2023-06-16 20:34:32.257: [iter 28 : loss : 1.1832 = 0.2342 + 0.9444 + 0.0046, time: 39.727311]
2023-06-16 20:34:32.653: epoch 28:	0.08768039  	0.16659091  	0.16456816  
2023-06-16 20:34:32.653: Find a better model.
2023-06-16 20:35:12.840: [iter 29 : loss : 1.1651 = 0.2168 + 0.9432 + 0.0050, time: 40.180235]
2023-06-16 20:35:13.255: epoch 29:	0.08761589  	0.16599938  	0.16412520  
2023-06-16 20:35:53.214: [iter 30 : loss : 1.1490 = 0.2014 + 0.9423 + 0.0054, time: 39.951863]
2023-06-16 20:35:53.642: epoch 30:	0.08759439  	0.16605477  	0.16411613  
2023-06-16 20:36:33.735: [iter 31 : loss : 1.1344 = 0.1876 + 0.9411 + 0.0058, time: 40.086962]
2023-06-16 20:36:34.183: epoch 31:	0.08758368  	0.16601755  	0.16395424  
2023-06-16 20:37:14.423: [iter 32 : loss : 1.1226 = 0.1764 + 0.9401 + 0.0061, time: 40.232482]
2023-06-16 20:37:14.844: epoch 32:	0.08757301  	0.16584523  	0.16354740  
2023-06-16 20:37:54.790: [iter 33 : loss : 1.1114 = 0.1658 + 0.9391 + 0.0065, time: 39.938712]
2023-06-16 20:37:55.230: epoch 33:	0.08736354  	0.16502155  	0.16318728  
2023-06-16 20:38:35.305: [iter 34 : loss : 1.1024 = 0.1575 + 0.9381 + 0.0068, time: 40.068283]
2023-06-16 20:38:35.700: epoch 34:	0.08715396  	0.16416909  	0.16260527  
2023-06-16 20:39:15.929: [iter 35 : loss : 1.0929 = 0.1485 + 0.9373 + 0.0071, time: 40.222033]
2023-06-16 20:39:16.336: epoch 35:	0.08704657  	0.16354442  	0.16225055  
2023-06-16 20:39:56.514: [iter 36 : loss : 1.0855 = 0.1417 + 0.9364 + 0.0074, time: 40.171405]
2023-06-16 20:39:56.911: epoch 36:	0.08685320  	0.16283636  	0.16159697  
2023-06-16 20:40:37.288: [iter 37 : loss : 1.0778 = 0.1345 + 0.9356 + 0.0077, time: 40.368999]
2023-06-16 20:40:37.686: epoch 37:	0.08655237  	0.16187273  	0.16114797  
2023-06-16 20:41:18.105: [iter 38 : loss : 1.0718 = 0.1291 + 0.9348 + 0.0080, time: 40.412264]
2023-06-16 20:41:18.508: epoch 38:	0.08642881  	0.16158353  	0.16076128  
2023-06-16 20:41:58.835: [iter 39 : loss : 1.0659 = 0.1236 + 0.9340 + 0.0083, time: 40.319060]
2023-06-16 20:41:59.255: epoch 39:	0.08624614  	0.16093534  	0.16045655  
2023-06-16 20:42:39.480: [iter 40 : loss : 1.0606 = 0.1187 + 0.9334 + 0.0085, time: 40.218445]
2023-06-16 20:42:39.882: epoch 40:	0.08597756  	0.16007248  	0.15953600  
2023-06-16 20:43:20.252: [iter 41 : loss : 1.0555 = 0.1141 + 0.9326 + 0.0088, time: 40.362361]
2023-06-16 20:43:20.651: epoch 41:	0.08570363  	0.15890387  	0.15873827  
2023-06-16 20:44:01.124: [iter 42 : loss : 1.0511 = 0.1099 + 0.9322 + 0.0090, time: 40.465626]
2023-06-16 20:44:01.546: epoch 42:	0.08551026  	0.15832569  	0.15827267  
2023-06-16 20:44:42.003: [iter 43 : loss : 1.0467 = 0.1058 + 0.9315 + 0.0093, time: 40.450630]
2023-06-16 20:44:42.408: epoch 43:	0.08535991  	0.15817735  	0.15781984  
2023-06-16 20:45:22.569: [iter 44 : loss : 1.0428 = 0.1022 + 0.9311 + 0.0095, time: 40.153631]
2023-06-16 20:45:22.993: epoch 44:	0.08502687  	0.15698639  	0.15729624  
2023-06-16 20:46:03.392: [iter 45 : loss : 1.0399 = 0.0996 + 0.9305 + 0.0098, time: 40.388873]
2023-06-16 20:46:03.808: epoch 45:	0.08470457  	0.15626976  	0.15666316  
2023-06-16 20:46:44.341: [iter 46 : loss : 1.0364 = 0.0963 + 0.9302 + 0.0100, time: 40.526751]
2023-06-16 20:46:44.740: epoch 46:	0.08474218  	0.15610337  	0.15619417  
2023-06-16 20:47:25.209: [iter 47 : loss : 1.0333 = 0.0934 + 0.9296 + 0.0102, time: 40.462917]
2023-06-16 20:47:25.610: epoch 47:	0.08439308  	0.15546961  	0.15549327  
2023-06-16 20:48:05.949: [iter 48 : loss : 1.0300 = 0.0904 + 0.9292 + 0.0104, time: 40.333957]
2023-06-16 20:48:06.362: epoch 48:	0.08419434  	0.15468436  	0.15491898  
2023-06-16 20:48:46.719: [iter 49 : loss : 1.0277 = 0.0882 + 0.9288 + 0.0106, time: 40.350506]
2023-06-16 20:48:47.148: epoch 49:	0.08401711  	0.15383185  	0.15428127  
2023-06-16 20:49:27.516: [iter 50 : loss : 1.0248 = 0.0855 + 0.9285 + 0.0108, time: 40.360486]
2023-06-16 20:49:27.916: epoch 50:	0.08382367  	0.15317945  	0.15371938  
2023-06-16 20:50:08.589: [iter 51 : loss : 1.0226 = 0.0834 + 0.9282 + 0.0110, time: 40.667024]
2023-06-16 20:50:09.020: epoch 51:	0.08363029  	0.15283267  	0.15305956  
2023-06-16 20:50:49.512: [iter 52 : loss : 1.0203 = 0.0812 + 0.9279 + 0.0112, time: 40.485121]
2023-06-16 20:50:49.936: epoch 52:	0.08335102  	0.15207973  	0.15238611  
2023-06-16 20:51:30.510: [iter 53 : loss : 1.0182 = 0.0793 + 0.9275 + 0.0114, time: 40.567328]
2023-06-16 20:51:30.934: epoch 53:	0.08306636  	0.15142928  	0.15183057  
2023-06-16 20:51:30.934: Early stopping is trigger at epoch: 53
2023-06-16 20:51:30.934: best_result@epoch 28:

2023-06-16 20:51:30.934: 		0.0877      	0.1666      	0.1646      
2023-06-16 21:09:19.903: my pid: 2656
2023-06-16 21:09:19.903: model: model.general_recommender.SGL
2023-06-16 21:09:19.903: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 21:09:19.903: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 21:09:24.936: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 21:10:04.442: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 39.505605]
2023-06-16 21:10:04.879: epoch 1:	0.00342714  	0.00802059  	0.00639309  
2023-06-16 21:10:04.879: Find a better model.
2023-06-16 21:10:46.740: [iter 2 : loss : 1.6056 = 0.6931 + 0.9126 + 0.0000, time: 41.853544]
2023-06-16 21:10:47.158: epoch 2:	0.00463039  	0.00996830  	0.00830404  
2023-06-16 21:10:47.158: Find a better model.
2023-06-16 21:11:29.673: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 42.509429]
2023-06-16 21:11:30.099: epoch 3:	0.00570473  	0.01187801  	0.01021312  
2023-06-16 21:11:30.099: Find a better model.
2023-06-16 21:12:11.258: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 41.151946]
2023-06-16 21:12:11.725: epoch 4:	0.00640304  	0.01356152  	0.01175140  
2023-06-16 21:12:11.725: Find a better model.
2023-06-16 21:12:53.787: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 42.054906]
2023-06-16 21:12:54.223: epoch 5:	0.00745055  	0.01475574  	0.01316854  
2023-06-16 21:12:54.223: Find a better model.
2023-06-16 21:13:35.907: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 41.676954]
2023-06-16 21:13:36.356: epoch 6:	0.00827246  	0.01690003  	0.01498211  
2023-06-16 21:13:36.356: Find a better model.
2023-06-16 21:14:17.706: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 41.343160]
2023-06-16 21:14:18.150: epoch 7:	0.00963692  	0.01937053  	0.01739179  
2023-06-16 21:14:18.150: Find a better model.
2023-06-16 21:15:00.086: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 41.928276]
2023-06-16 21:15:00.521: epoch 8:	0.01070055  	0.02171359  	0.01962973  
2023-06-16 21:15:00.521: Find a better model.
2023-06-16 21:15:42.649: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 42.118986]
2023-06-16 21:15:43.080: epoch 9:	0.01218318  	0.02448993  	0.02276001  
2023-06-16 21:15:43.080: Find a better model.
2023-06-16 21:16:24.133: [iter 10 : loss : 1.6052 = 0.6923 + 0.9128 + 0.0000, time: 41.046395]
2023-06-16 21:16:24.615: epoch 10:	0.01378400  	0.02811194  	0.02598878  
2023-06-16 21:16:24.615: Find a better model.
2023-06-16 21:17:07.436: [iter 11 : loss : 1.6049 = 0.6920 + 0.9128 + 0.0000, time: 42.813804]
2023-06-16 21:17:07.987: epoch 11:	0.01707699  	0.03474191  	0.03224210  
2023-06-16 21:17:07.987: Find a better model.
2023-06-16 21:17:50.002: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 42.007662]
2023-06-16 21:17:50.437: epoch 12:	0.02059023  	0.04195422  	0.04010173  
2023-06-16 21:17:50.437: Find a better model.
2023-06-16 21:18:33.271: [iter 13 : loss : 1.6044 = 0.6910 + 0.9133 + 0.0000, time: 42.827098]
2023-06-16 21:18:33.855: epoch 13:	0.02464598  	0.05036412  	0.04777714  
2023-06-16 21:18:33.855: Find a better model.
2023-06-16 21:19:15.911: [iter 14 : loss : 1.6037 = 0.6900 + 0.9137 + 0.0000, time: 42.050143]
2023-06-16 21:19:16.354: epoch 14:	0.03040963  	0.06170401  	0.05992696  
2023-06-16 21:19:16.354: Find a better model.
2023-06-16 21:19:59.050: [iter 15 : loss : 1.6022 = 0.6881 + 0.9141 + 0.0001, time: 42.688462]
2023-06-16 21:19:59.469: epoch 15:	0.03813906  	0.07787848  	0.07628591  
2023-06-16 21:19:59.469: Find a better model.
2023-06-16 21:20:42.519: [iter 16 : loss : 1.5992 = 0.6843 + 0.9148 + 0.0001, time: 43.044263]
2023-06-16 21:20:42.988: epoch 16:	0.04821604  	0.09631646  	0.09488423  
2023-06-16 21:20:42.988: Find a better model.
2023-06-16 21:21:24.977: [iter 17 : loss : 1.5923 = 0.6761 + 0.9161 + 0.0001, time: 41.982153]
2023-06-16 21:21:25.520: epoch 17:	0.06003317  	0.11720801  	0.11619605  
2023-06-16 21:21:25.520: Find a better model.
2023-06-16 21:22:08.469: [iter 18 : loss : 1.5767 = 0.6580 + 0.9185 + 0.0003, time: 42.942110]
2023-06-16 21:22:08.873: epoch 18:	0.07054526  	0.13556616  	0.13563056  
2023-06-16 21:22:08.873: Find a better model.
2023-06-16 21:22:48.889: [iter 19 : loss : 1.5457 = 0.6229 + 0.9224 + 0.0005, time: 40.010109]
2023-06-16 21:22:49.287: epoch 19:	0.07732423  	0.14615324  	0.14695518  
2023-06-16 21:22:49.287: Find a better model.
2023-06-16 21:23:29.259: [iter 20 : loss : 1.4985 = 0.5694 + 0.9283 + 0.0008, time: 39.964746]
2023-06-16 21:23:29.677: epoch 20:	0.08114322  	0.15274642  	0.15376255  
2023-06-16 21:23:29.677: Find a better model.
2023-06-16 21:24:09.415: [iter 21 : loss : 1.4420 = 0.5061 + 0.9346 + 0.0013, time: 39.730618]
2023-06-16 21:24:09.827: epoch 21:	0.08329725  	0.15669033  	0.15735240  
2023-06-16 21:24:09.828: Find a better model.
2023-06-16 21:24:49.644: [iter 22 : loss : 1.3860 = 0.4441 + 0.9402 + 0.0018, time: 39.808117]
2023-06-16 21:24:50.041: epoch 22:	0.08477979  	0.16002491  	0.15999885  
2023-06-16 21:24:50.041: Find a better model.
2023-06-16 21:25:30.056: [iter 23 : loss : 1.3366 = 0.3907 + 0.9436 + 0.0023, time: 40.006304]
2023-06-16 21:25:30.452: epoch 23:	0.08576812  	0.16222423  	0.16177462  
2023-06-16 21:25:30.452: Find a better model.
2023-06-16 21:26:10.329: [iter 24 : loss : 1.2945 = 0.3462 + 0.9455 + 0.0028, time: 39.870958]
2023-06-16 21:26:10.737: epoch 24:	0.08655229  	0.16375579  	0.16306958  
2023-06-16 21:26:10.737: Find a better model.
2023-06-16 21:26:50.540: [iter 25 : loss : 1.2596 = 0.3104 + 0.9460 + 0.0033, time: 39.795473]
2023-06-16 21:26:50.933: epoch 25:	0.08720218  	0.16488379  	0.16386403  
2023-06-16 21:26:50.933: Find a better model.
2023-06-16 21:27:30.932: [iter 26 : loss : 1.2296 = 0.2801 + 0.9458 + 0.0037, time: 39.990898]
2023-06-16 21:27:31.354: epoch 26:	0.08755675  	0.16567637  	0.16403256  
2023-06-16 21:27:31.354: Find a better model.
2023-06-16 21:28:11.222: [iter 27 : loss : 1.2044 = 0.2550 + 0.9452 + 0.0042, time: 39.862370]
2023-06-16 21:28:11.643: epoch 27:	0.08755678  	0.16582501  	0.16435251  
2023-06-16 21:28:11.643: Find a better model.
2023-06-16 21:28:51.561: [iter 28 : loss : 1.1832 = 0.2342 + 0.9444 + 0.0046, time: 39.912177]
2023-06-16 21:28:51.955: epoch 28:	0.08768039  	0.16659091  	0.16456816  
2023-06-16 21:28:51.955: Find a better model.
2023-06-16 21:29:32.632: [iter 29 : loss : 1.1651 = 0.2168 + 0.9432 + 0.0050, time: 40.670441]
2023-06-16 21:29:33.055: epoch 29:	0.08761589  	0.16599938  	0.16412520  
2023-06-16 21:30:16.230: [iter 30 : loss : 1.1490 = 0.2014 + 0.9423 + 0.0054, time: 43.166905]
2023-06-16 21:30:16.789: epoch 30:	0.08759439  	0.16605477  	0.16411613  
2023-06-16 21:31:12.570: [iter 31 : loss : 1.1344 = 0.1876 + 0.9411 + 0.0058, time: 55.767706]
2023-06-16 21:31:13.398: epoch 31:	0.08758368  	0.16601755  	0.16395424  
2023-06-16 21:32:09.947: [iter 32 : loss : 1.1226 = 0.1764 + 0.9401 + 0.0061, time: 56.536561]
2023-06-16 21:32:10.783: epoch 32:	0.08757301  	0.16584523  	0.16354740  
2023-06-16 21:32:38.811: my pid: 12236
2023-06-16 21:32:38.811: model: model.general_recommender.SGL
2023-06-16 21:32:38.811: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-16 21:32:38.811: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-16 21:32:45.426: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-16 21:33:41.226: [iter 1 : loss : 1.6080 = 0.6931 + 0.9149 + 0.0000, time: 55.792355]
2023-06-16 21:33:42.073: epoch 1:	0.00342714  	0.00802059  	0.00639309  
2023-06-16 21:33:42.073: Find a better model.
2023-06-16 21:34:37.880: [iter 2 : loss : 1.6056 = 0.6931 + 0.9126 + 0.0000, time: 55.798648]
2023-06-16 21:34:38.684: epoch 2:	0.00463039  	0.00996830  	0.00830404  
2023-06-16 21:34:38.684: Find a better model.
2023-06-16 21:35:33.656: [iter 3 : loss : 1.6054 = 0.6930 + 0.9123 + 0.0000, time: 54.964039]
2023-06-16 21:35:34.431: epoch 3:	0.00570473  	0.01187801  	0.01021312  
2023-06-16 21:35:34.431: Find a better model.
2023-06-16 21:36:30.615: [iter 4 : loss : 1.6054 = 0.6930 + 0.9124 + 0.0000, time: 56.178441]
2023-06-16 21:36:31.178: epoch 4:	0.00640304  	0.01356152  	0.01175140  
2023-06-16 21:36:31.178: Find a better model.
2023-06-16 21:37:25.585: [iter 5 : loss : 1.6053 = 0.6929 + 0.9124 + 0.0000, time: 54.399820]
2023-06-16 21:37:26.343: epoch 5:	0.00745055  	0.01475574  	0.01316854  
2023-06-16 21:37:26.343: Find a better model.
2023-06-16 21:38:21.013: [iter 6 : loss : 1.6053 = 0.6929 + 0.9125 + 0.0000, time: 54.662031]
2023-06-16 21:38:21.818: epoch 6:	0.00827246  	0.01690003  	0.01498211  
2023-06-16 21:38:21.818: Find a better model.
2023-06-16 21:39:18.120: [iter 7 : loss : 1.6054 = 0.6928 + 0.9126 + 0.0000, time: 56.290903]
2023-06-16 21:39:18.906: epoch 7:	0.00963692  	0.01937053  	0.01739179  
2023-06-16 21:39:18.906: Find a better model.
2023-06-16 21:40:13.213: [iter 8 : loss : 1.6052 = 0.6927 + 0.9125 + 0.0000, time: 54.298069]
2023-06-16 21:40:14.025: epoch 8:	0.01070055  	0.02171359  	0.01962973  
2023-06-16 21:40:14.025: Find a better model.
2023-06-16 21:41:09.576: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 55.544374]
2023-06-16 21:41:10.011: epoch 9:	0.01218318  	0.02448993  	0.02276001  
2023-06-16 21:41:10.012: Find a better model.
2023-06-16 21:42:04.277: [iter 10 : loss : 1.6052 = 0.6923 + 0.9128 + 0.0000, time: 54.253097]
2023-06-16 21:42:04.992: epoch 10:	0.01378400  	0.02811194  	0.02598878  
2023-06-16 21:42:04.993: Find a better model.
2023-06-16 21:43:01.960: [iter 11 : loss : 1.6049 = 0.6920 + 0.9128 + 0.0000, time: 56.958960]
2023-06-16 21:43:02.727: epoch 11:	0.01707699  	0.03474191  	0.03224210  
2023-06-16 21:43:02.727: Find a better model.
2023-06-16 21:43:57.851: [iter 12 : loss : 1.6047 = 0.6916 + 0.9131 + 0.0000, time: 55.117808]
2023-06-16 21:43:58.610: epoch 12:	0.02059023  	0.04195422  	0.04010173  
2023-06-16 21:43:58.611: Find a better model.
2023-06-16 21:44:53.086: [iter 13 : loss : 1.6044 = 0.6910 + 0.9133 + 0.0000, time: 54.466085]
2023-06-16 21:44:53.910: epoch 13:	0.02464598  	0.05036412  	0.04777714  
2023-06-16 21:44:53.910: Find a better model.
2023-06-16 21:45:49.375: [iter 14 : loss : 1.6037 = 0.6900 + 0.9137 + 0.0000, time: 55.456135]
2023-06-16 21:45:50.199: epoch 14:	0.03040963  	0.06170401  	0.05992696  
2023-06-16 21:45:50.199: Find a better model.
2023-06-16 21:46:45.873: [iter 15 : loss : 1.6022 = 0.6881 + 0.9141 + 0.0001, time: 55.664135]
2023-06-16 21:46:46.731: epoch 15:	0.03813906  	0.07787848  	0.07628591  
2023-06-16 21:46:46.731: Find a better model.
2023-06-16 21:47:43.334: [iter 16 : loss : 1.5992 = 0.6843 + 0.9148 + 0.0001, time: 56.594909]
2023-06-16 21:47:44.171: epoch 16:	0.04821604  	0.09631646  	0.09488423  
2023-06-16 21:47:44.172: Find a better model.
2023-06-16 21:48:40.151: [iter 17 : loss : 1.5923 = 0.6761 + 0.9161 + 0.0001, time: 55.969803]
2023-06-16 21:48:41.034: epoch 17:	0.06003317  	0.11720801  	0.11619605  
2023-06-16 21:48:41.034: Find a better model.
2023-06-16 21:49:37.593: [iter 18 : loss : 1.5767 = 0.6580 + 0.9185 + 0.0003, time: 56.543750]
2023-06-16 21:49:38.376: epoch 18:	0.07054526  	0.13556616  	0.13563056  
2023-06-16 21:49:38.376: Find a better model.
2023-06-16 21:50:34.117: [iter 19 : loss : 1.5457 = 0.6229 + 0.9224 + 0.0005, time: 55.728808]
2023-06-16 21:50:34.951: epoch 19:	0.07732423  	0.14615324  	0.14695518  
2023-06-16 21:50:34.952: Find a better model.
2023-06-16 21:51:18.949: [iter 20 : loss : 1.4985 = 0.5694 + 0.9283 + 0.0008, time: 43.991455]
2023-06-16 21:51:19.378: epoch 20:	0.08114322  	0.15274642  	0.15376255  
2023-06-16 21:51:19.378: Find a better model.
2023-06-16 21:52:00.779: [iter 21 : loss : 1.4420 = 0.5061 + 0.9346 + 0.0013, time: 41.394622]
2023-06-16 21:52:01.187: epoch 21:	0.08329725  	0.15669033  	0.15735240  
2023-06-16 21:52:01.188: Find a better model.
2023-06-16 21:52:43.835: [iter 22 : loss : 1.3860 = 0.4441 + 0.9402 + 0.0018, time: 42.639809]
2023-06-16 21:52:44.340: epoch 22:	0.08477979  	0.16002491  	0.15999885  
2023-06-16 21:52:44.340: Find a better model.
2023-06-16 21:53:25.991: [iter 23 : loss : 1.3366 = 0.3907 + 0.9436 + 0.0023, time: 41.643777]
2023-06-16 21:53:26.422: epoch 23:	0.08576812  	0.16222423  	0.16177462  
2023-06-16 21:53:26.422: Find a better model.
2023-06-16 21:54:08.877: [iter 24 : loss : 1.2945 = 0.3462 + 0.9455 + 0.0028, time: 42.447931]
2023-06-16 21:54:09.313: epoch 24:	0.08655229  	0.16375579  	0.16306958  
2023-06-16 21:54:09.313: Find a better model.
2023-06-16 21:54:50.923: [iter 25 : loss : 1.2596 = 0.3104 + 0.9460 + 0.0033, time: 41.575575]
2023-06-16 21:54:51.349: epoch 25:	0.08720218  	0.16488379  	0.16386403  
2023-06-16 21:54:51.349: Find a better model.
2023-06-16 21:55:34.018: [iter 26 : loss : 1.2296 = 0.2801 + 0.9458 + 0.0037, time: 42.663486]
2023-06-16 21:55:34.533: epoch 26:	0.08755675  	0.16567637  	0.16403256  
2023-06-16 21:55:34.533: Find a better model.
2023-06-16 21:56:16.551: [iter 27 : loss : 1.2044 = 0.2550 + 0.9452 + 0.0042, time: 42.001993]
2023-06-16 21:56:16.967: epoch 27:	0.08755678  	0.16582501  	0.16435251  
2023-06-16 21:56:16.967: Find a better model.
2023-06-16 21:56:59.649: [iter 28 : loss : 1.1832 = 0.2342 + 0.9444 + 0.0046, time: 42.674809]
2023-06-16 21:57:00.075: epoch 28:	0.08768039  	0.16659091  	0.16456816  
2023-06-16 21:57:00.075: Find a better model.
2023-06-16 21:57:41.914: [iter 29 : loss : 1.1651 = 0.2168 + 0.9432 + 0.0050, time: 41.832655]
2023-06-16 21:57:42.379: epoch 29:	0.08761589  	0.16599938  	0.16412520  
2023-06-16 21:58:24.955: [iter 30 : loss : 1.1490 = 0.2014 + 0.9423 + 0.0054, time: 42.568268]
2023-06-16 21:58:25.401: epoch 30:	0.08759439  	0.16605477  	0.16411613  
2023-06-16 21:59:07.213: [iter 31 : loss : 1.1344 = 0.1876 + 0.9411 + 0.0058, time: 41.803126]
2023-06-16 21:59:07.761: epoch 31:	0.08758368  	0.16601755  	0.16395424  
2023-06-16 21:59:50.899: [iter 32 : loss : 1.1226 = 0.1764 + 0.9401 + 0.0061, time: 43.131268]
2023-06-16 21:59:51.308: epoch 32:	0.08757301  	0.16584523  	0.16354740  
2023-06-16 22:00:33.618: [iter 33 : loss : 1.1114 = 0.1658 + 0.9391 + 0.0065, time: 42.303908]
2023-06-16 22:00:34.160: epoch 33:	0.08736354  	0.16502155  	0.16318728  
2023-06-16 22:01:16.741: [iter 34 : loss : 1.1024 = 0.1575 + 0.9381 + 0.0068, time: 42.574512]
2023-06-16 22:01:17.131: epoch 34:	0.08715396  	0.16416909  	0.16260527  
2023-06-16 22:01:59.827: [iter 35 : loss : 1.0929 = 0.1485 + 0.9373 + 0.0071, time: 42.689015]
2023-06-16 22:02:00.214: epoch 35:	0.08704657  	0.16354442  	0.16225055  
2023-06-16 22:02:42.360: [iter 36 : loss : 1.0855 = 0.1417 + 0.9364 + 0.0074, time: 42.139781]
2023-06-16 22:02:42.821: epoch 36:	0.08685320  	0.16283636  	0.16159697  
2023-06-16 22:03:25.713: [iter 37 : loss : 1.0778 = 0.1345 + 0.9356 + 0.0077, time: 42.883931]
2023-06-16 22:03:26.147: epoch 37:	0.08655237  	0.16187273  	0.16114797  
2023-06-16 22:04:07.909: [iter 38 : loss : 1.0718 = 0.1291 + 0.9348 + 0.0080, time: 41.754778]
2023-06-16 22:04:08.438: epoch 38:	0.08642881  	0.16158353  	0.16076128  
2023-06-16 22:04:51.045: [iter 39 : loss : 1.0659 = 0.1236 + 0.9340 + 0.0083, time: 42.599652]
2023-06-16 22:04:51.447: epoch 39:	0.08624614  	0.16093534  	0.16045655  
2023-06-16 22:05:34.183: [iter 40 : loss : 1.0606 = 0.1187 + 0.9334 + 0.0085, time: 42.726933]
2023-06-16 22:05:34.755: epoch 40:	0.08597756  	0.16007248  	0.15953600  
2023-06-16 22:06:14.984: [iter 41 : loss : 1.0555 = 0.1141 + 0.9326 + 0.0088, time: 40.223545]
2023-06-16 22:06:15.379: epoch 41:	0.08570363  	0.15890387  	0.15873827  
2023-06-16 22:06:54.687: [iter 42 : loss : 1.0511 = 0.1099 + 0.9322 + 0.0090, time: 39.301574]
2023-06-16 22:06:55.083: epoch 42:	0.08551026  	0.15832569  	0.15827267  
2023-06-16 22:07:34.365: [iter 43 : loss : 1.0467 = 0.1058 + 0.9315 + 0.0093, time: 39.274971]
2023-06-16 22:07:34.760: epoch 43:	0.08535991  	0.15817735  	0.15781984  
2023-06-16 22:08:14.414: [iter 44 : loss : 1.0428 = 0.1022 + 0.9311 + 0.0095, time: 39.645785]
2023-06-16 22:08:14.802: epoch 44:	0.08502687  	0.15698639  	0.15729624  
2023-06-16 22:08:53.826: [iter 45 : loss : 1.0399 = 0.0996 + 0.9305 + 0.0098, time: 39.017564]
2023-06-16 22:08:54.218: epoch 45:	0.08470457  	0.15626976  	0.15666316  
2023-06-16 22:09:33.519: [iter 46 : loss : 1.0364 = 0.0963 + 0.9302 + 0.0100, time: 39.293936]
2023-06-16 22:09:33.916: epoch 46:	0.08474218  	0.15610337  	0.15619417  
2023-06-16 22:10:13.434: [iter 47 : loss : 1.0333 = 0.0934 + 0.9296 + 0.0102, time: 39.511893]
2023-06-16 22:10:13.840: epoch 47:	0.08439308  	0.15546961  	0.15549327  
2023-06-16 22:10:53.270: [iter 48 : loss : 1.0300 = 0.0904 + 0.9292 + 0.0104, time: 39.423564]
2023-06-16 22:10:53.674: epoch 48:	0.08419434  	0.15468436  	0.15491898  
2023-06-16 22:11:33.325: [iter 49 : loss : 1.0277 = 0.0882 + 0.9288 + 0.0106, time: 39.644428]
2023-06-16 22:11:33.730: epoch 49:	0.08401711  	0.15383185  	0.15428127  
2023-06-16 22:12:13.332: [iter 50 : loss : 1.0248 = 0.0855 + 0.9285 + 0.0108, time: 39.596123]
2023-06-16 22:12:13.734: epoch 50:	0.08382367  	0.15317945  	0.15371938  
2023-06-16 22:12:53.361: [iter 51 : loss : 1.0226 = 0.0834 + 0.9282 + 0.0110, time: 39.620497]
2023-06-16 22:12:53.763: epoch 51:	0.08363029  	0.15283267  	0.15305956  
2023-06-16 22:13:33.307: [iter 52 : loss : 1.0203 = 0.0812 + 0.9279 + 0.0112, time: 39.537764]
2023-06-16 22:13:33.711: epoch 52:	0.08335102  	0.15207973  	0.15238611  
2023-06-16 22:14:13.496: [iter 53 : loss : 1.0182 = 0.0793 + 0.9275 + 0.0114, time: 39.778713]
2023-06-16 22:14:13.901: epoch 53:	0.08306636  	0.15142928  	0.15183057  
2023-06-16 22:14:13.902: Early stopping is trigger at epoch: 53
2023-06-16 22:14:13.902: best_result@epoch 28:

2023-06-16 22:14:13.902: 		0.0877      	0.1666      	0.1646      
2023-06-18 13:26:29.019: my pid: 5144
2023-06-18 13:26:29.019: model: model.general_recommender.SGL
2023-06-18 13:26:29.019: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-18 13:26:29.019: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-18 13:26:34.620: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-18 13:27:16.752: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 42.129885]
2023-06-18 13:27:17.178: epoch 1:	0.00363126  	0.00851699  	0.00683331  
2023-06-18 13:27:17.178: Find a better model.
2023-06-18 13:27:58.327: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 41.142531]
2023-06-18 13:27:58.887: epoch 2:	0.00486675  	0.01117320  	0.00883662  
2023-06-18 13:27:58.888: Find a better model.
2023-06-18 13:28:40.902: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 42.006232]
2023-06-18 13:28:41.342: epoch 3:	0.00622041  	0.01374303  	0.01118770  
2023-06-18 13:28:41.342: Find a better model.
2023-06-18 13:29:23.204: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 41.846250]
2023-06-18 13:29:23.659: epoch 4:	0.00664477  	0.01385416  	0.01193857  
2023-06-18 13:29:23.659: Find a better model.
2023-06-18 13:30:04.859: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 41.192863]
2023-06-18 13:30:05.434: epoch 5:	0.00748815  	0.01623570  	0.01371718  
2023-06-18 13:30:05.434: Find a better model.
2023-06-18 13:30:47.604: [iter 6 : loss : 1.6052 = 0.6929 + 0.9124 + 0.0000, time: 42.161919]
2023-06-18 13:30:48.046: epoch 6:	0.00826707  	0.01781434  	0.01538539  
2023-06-18 13:30:48.046: Find a better model.
2023-06-18 13:31:29.477: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 41.422874]
2023-06-18 13:31:29.947: epoch 7:	0.00953485  	0.02037249  	0.01776276  
2023-06-18 13:31:29.947: Find a better model.
2023-06-18 13:32:12.218: [iter 8 : loss : 1.6052 = 0.6926 + 0.9125 + 0.0000, time: 42.263824]
2023-06-18 13:32:12.707: epoch 8:	0.01108733  	0.02213649  	0.02007034  
2023-06-18 13:32:12.707: Find a better model.
2023-06-18 13:32:54.051: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 41.334541]
2023-06-18 13:32:54.573: epoch 9:	0.01286004  	0.02606249  	0.02417994  
2023-06-18 13:32:54.573: Find a better model.
2023-06-18 13:33:36.660: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 42.079612]
2023-06-18 13:33:37.100: epoch 10:	0.01457906  	0.02923584  	0.02730620  
2023-06-18 13:33:37.100: Find a better model.
2023-06-18 13:34:19.476: [iter 11 : loss : 1.6048 = 0.6920 + 0.9128 + 0.0000, time: 42.370622]
2023-06-18 13:34:19.937: epoch 11:	0.01761955  	0.03568909  	0.03324732  
2023-06-18 13:34:19.937: Find a better model.
2023-06-18 13:35:02.797: [iter 12 : loss : 1.6046 = 0.6916 + 0.9130 + 0.0000, time: 42.853834]
2023-06-18 13:35:03.230: epoch 12:	0.02047740  	0.04114734  	0.03950129  
2023-06-18 13:35:03.231: Find a better model.
2023-06-18 13:35:45.516: [iter 13 : loss : 1.6043 = 0.6909 + 0.9133 + 0.0000, time: 42.276905]
2023-06-18 13:35:46.068: epoch 13:	0.02487696  	0.04973302  	0.04810160  
2023-06-18 13:35:46.068: Find a better model.
2023-06-18 13:36:29.607: [iter 14 : loss : 1.6035 = 0.6898 + 0.9136 + 0.0000, time: 43.532869]
2023-06-18 13:36:30.028: epoch 14:	0.03058154  	0.06201562  	0.06084223  
2023-06-18 13:36:30.028: Find a better model.
2023-06-18 13:37:12.652: [iter 15 : loss : 1.6019 = 0.6878 + 0.9141 + 0.0001, time: 42.614528]
2023-06-18 13:37:13.134: epoch 15:	0.03884805  	0.07740105  	0.07700145  
2023-06-18 13:37:13.134: Find a better model.
2023-06-18 13:37:56.234: [iter 16 : loss : 1.5987 = 0.6838 + 0.9148 + 0.0001, time: 43.091704]
2023-06-18 13:37:56.666: epoch 16:	0.04911844  	0.09676940  	0.09662777  
2023-06-18 13:37:56.666: Find a better model.
2023-06-18 13:38:39.961: [iter 17 : loss : 1.5912 = 0.6750 + 0.9161 + 0.0001, time: 43.288292]
2023-06-18 13:38:40.525: epoch 17:	0.06097861  	0.11789299  	0.11860768  
2023-06-18 13:38:40.525: Find a better model.
2023-06-18 13:39:23.593: [iter 18 : loss : 1.5744 = 0.6556 + 0.9185 + 0.0003, time: 43.062129]
2023-06-18 13:39:24.098: epoch 18:	0.07096968  	0.13532043  	0.13646892  
2023-06-18 13:39:24.098: Find a better model.
2023-06-18 13:40:07.939: [iter 19 : loss : 1.5417 = 0.6183 + 0.9228 + 0.0005, time: 43.832640]
2023-06-18 13:40:08.393: epoch 19:	0.07731891  	0.14593332  	0.14721246  
2023-06-18 13:40:08.393: Find a better model.
2023-06-18 13:40:51.178: [iter 20 : loss : 1.4930 = 0.5631 + 0.9290 + 0.0009, time: 42.768183]
2023-06-18 13:40:51.647: epoch 20:	0.08077810  	0.15144706  	0.15326063  
2023-06-18 13:40:51.647: Find a better model.
2023-06-18 13:41:34.924: [iter 21 : loss : 1.4363 = 0.4994 + 0.9356 + 0.0013, time: 43.268466]
2023-06-18 13:41:35.496: epoch 21:	0.08306647  	0.15573180  	0.15675505  
2023-06-18 13:41:35.496: Find a better model.
2023-06-18 13:42:18.045: [iter 22 : loss : 1.3810 = 0.4383 + 0.9408 + 0.0018, time: 42.541701]
2023-06-18 13:42:18.519: epoch 22:	0.08418378  	0.15805611  	0.15881933  
2023-06-18 13:42:18.519: Find a better model.
2023-06-18 13:43:01.937: [iter 23 : loss : 1.3326 = 0.3863 + 0.9440 + 0.0023, time: 43.411780]
2023-06-18 13:43:02.463: epoch 23:	0.08536544  	0.16024661  	0.16042429  
2023-06-18 13:43:02.463: Find a better model.
2023-06-18 13:43:44.932: [iter 24 : loss : 1.2914 = 0.3429 + 0.9457 + 0.0028, time: 42.462094]
2023-06-18 13:43:45.499: epoch 24:	0.08569307  	0.16110998  	0.16134164  
2023-06-18 13:43:45.499: Find a better model.
2023-06-18 13:44:28.834: [iter 25 : loss : 1.2572 = 0.3080 + 0.9459 + 0.0033, time: 43.329260]
2023-06-18 13:44:29.288: epoch 25:	0.08637528  	0.16246155  	0.16247182  
2023-06-18 13:44:29.288: Find a better model.
2023-06-18 13:45:11.973: [iter 26 : loss : 1.2276 = 0.2782 + 0.9456 + 0.0038, time: 42.676026]
2023-06-18 13:45:12.546: epoch 26:	0.08672978  	0.16350292  	0.16296217  
2023-06-18 13:45:12.546: Find a better model.
2023-06-18 13:45:56.186: [iter 27 : loss : 1.2027 = 0.2536 + 0.9448 + 0.0042, time: 43.632307]
2023-06-18 13:45:56.645: epoch 27:	0.08704130  	0.16413720  	0.16286692  
2023-06-18 13:45:56.646: Find a better model.
2023-06-18 13:46:39.890: [iter 28 : loss : 1.1816 = 0.2329 + 0.9441 + 0.0046, time: 43.235851]
2023-06-18 13:46:40.519: epoch 28:	0.08728304  	0.16475902  	0.16323222  
2023-06-18 13:46:40.519: Find a better model.
2023-06-18 13:47:24.070: [iter 29 : loss : 1.1639 = 0.2159 + 0.9429 + 0.0050, time: 43.543243]
2023-06-18 13:47:24.514: epoch 29:	0.08721320  	0.16446845  	0.16312476  
2023-06-18 13:48:08.398: [iter 30 : loss : 1.1480 = 0.2007 + 0.9419 + 0.0054, time: 43.877507]
2023-06-18 13:48:08.811: epoch 30:	0.08736898  	0.16476202  	0.16310775  
2023-06-18 13:48:08.811: Find a better model.
2023-06-18 13:48:51.722: [iter 31 : loss : 1.1333 = 0.1867 + 0.9408 + 0.0058, time: 42.903496]
2023-06-18 13:48:52.163: epoch 31:	0.08719706  	0.16442008  	0.16240072  
2023-06-18 13:49:36.038: [iter 32 : loss : 1.1218 = 0.1760 + 0.9397 + 0.0062, time: 43.867548]
2023-06-18 13:49:36.536: epoch 32:	0.08711646  	0.16366525  	0.16192895  
2023-06-18 13:50:19.079: [iter 33 : loss : 1.1104 = 0.1651 + 0.9387 + 0.0065, time: 42.536656]
2023-06-18 13:50:19.625: epoch 33:	0.08712722  	0.16370073  	0.16154458  
2023-06-18 13:51:03.865: [iter 34 : loss : 1.1014 = 0.1569 + 0.9377 + 0.0068, time: 44.232902]
2023-06-18 13:51:04.299: epoch 34:	0.08717559  	0.16363126  	0.16122928  
2023-06-18 13:51:47.656: [iter 35 : loss : 1.0920 = 0.1480 + 0.9369 + 0.0072, time: 43.343516]
2023-06-18 13:51:48.176: epoch 35:	0.08682106  	0.16278471  	0.16075373  
2023-06-18 13:52:31.811: [iter 36 : loss : 1.0848 = 0.1413 + 0.9361 + 0.0074, time: 43.611553]
2023-06-18 13:52:32.322: epoch 36:	0.08661150  	0.16187400  	0.16018598  
2023-06-18 13:53:16.332: [iter 37 : loss : 1.0770 = 0.1341 + 0.9351 + 0.0078, time: 43.991318]
2023-06-18 13:53:16.770: epoch 37:	0.08650406  	0.16148221  	0.15983532  
2023-06-18 13:53:59.852: [iter 38 : loss : 1.0711 = 0.1287 + 0.9344 + 0.0080, time: 43.073980]
2023-06-18 13:54:00.311: epoch 38:	0.08631600  	0.16066775  	0.15932713  
2023-06-18 13:54:44.117: [iter 39 : loss : 1.0652 = 0.1233 + 0.9336 + 0.0083, time: 43.799260]
2023-06-18 13:54:44.587: epoch 39:	0.08609579  	0.15972766  	0.15864104  
2023-06-18 13:55:28.319: [iter 40 : loss : 1.0603 = 0.1187 + 0.9330 + 0.0086, time: 43.723148]
2023-06-18 13:55:28.869: epoch 40:	0.08606355  	0.15926978  	0.15820825  
2023-06-18 13:56:12.189: [iter 41 : loss : 1.0549 = 0.1137 + 0.9323 + 0.0088, time: 43.311990]
2023-06-18 13:56:12.685: epoch 41:	0.08589169  	0.15830033  	0.15763442  
2023-06-18 13:56:56.896: [iter 42 : loss : 1.0506 = 0.1097 + 0.9318 + 0.0091, time: 44.203480]
2023-06-18 13:56:57.338: epoch 42:	0.08566075  	0.15776299  	0.15717064  
2023-06-18 13:57:41.114: [iter 43 : loss : 1.0459 = 0.1054 + 0.9311 + 0.0093, time: 43.746199]
2023-06-18 13:57:41.648: epoch 43:	0.08540294  	0.15691744  	0.15658846  
2023-06-18 13:58:24.724: [iter 44 : loss : 1.0425 = 0.1021 + 0.9308 + 0.0096, time: 43.069304]
2023-06-18 13:58:25.161: epoch 44:	0.08520956  	0.15636529  	0.15609337  
2023-06-18 13:59:09.221: [iter 45 : loss : 1.0394 = 0.0993 + 0.9302 + 0.0098, time: 44.052745]
2023-06-18 13:59:09.716: epoch 45:	0.08508604  	0.15598650  	0.15565163  
2023-06-18 13:59:53.457: [iter 46 : loss : 1.0355 = 0.0957 + 0.9298 + 0.0100, time: 43.730232]
2023-06-18 13:59:53.986: epoch 46:	0.08482283  	0.15520124  	0.15493356  
2023-06-18 14:00:37.695: [iter 47 : loss : 1.0326 = 0.0931 + 0.9293 + 0.0102, time: 43.701567]
2023-06-18 14:00:38.135: epoch 47:	0.08468319  	0.15461574  	0.15446955  
2023-06-18 14:01:22.397: [iter 48 : loss : 1.0295 = 0.0902 + 0.9289 + 0.0105, time: 44.255954]
2023-06-18 14:01:22.822: epoch 48:	0.08444682  	0.15382719  	0.15387185  
2023-06-18 14:02:07.194: [iter 49 : loss : 1.0267 = 0.0876 + 0.9285 + 0.0107, time: 44.362725]
2023-06-18 14:02:07.654: epoch 49:	0.08422663  	0.15307622  	0.15313718  
2023-06-18 14:02:50.945: [iter 50 : loss : 1.0244 = 0.0855 + 0.9281 + 0.0109, time: 43.282843]
2023-06-18 14:02:51.448: epoch 50:	0.08418906  	0.15293698  	0.15288803  
2023-06-18 14:03:35.773: [iter 51 : loss : 1.0221 = 0.0833 + 0.9278 + 0.0111, time: 44.318848]
2023-06-18 14:03:36.208: epoch 51:	0.08409236  	0.15250888  	0.15240654  
2023-06-18 14:04:20.507: [iter 52 : loss : 1.0200 = 0.0812 + 0.9275 + 0.0112, time: 44.291837]
2023-06-18 14:04:20.915: epoch 52:	0.08363038  	0.15124105  	0.15138054  
2023-06-18 14:05:04.005: [iter 53 : loss : 1.0177 = 0.0791 + 0.9272 + 0.0114, time: 43.082723]
2023-06-18 14:05:04.514: epoch 53:	0.08333499  	0.15059699  	0.15070143  
2023-06-18 14:05:48.918: [iter 54 : loss : 1.0155 = 0.0771 + 0.9268 + 0.0116, time: 44.396138]
2023-06-18 14:05:49.419: epoch 54:	0.08303958  	0.14990006  	0.15022139  
2023-06-18 14:06:33.566: [iter 55 : loss : 1.0139 = 0.0754 + 0.9266 + 0.0118, time: 44.139329]
2023-06-18 14:06:34.095: epoch 55:	0.08289993  	0.14942570  	0.14976339  
2023-06-18 14:06:34.095: Early stopping is trigger at epoch: 55
2023-06-18 14:06:34.095: best_result@epoch 30:

2023-06-18 14:06:34.095: 		0.0874      	0.1648      	0.1631      
2023-06-18 16:58:42.219: my pid: 3972
2023-06-18 16:58:42.219: model: model.general_recommender.SGL
2023-06-18 16:58:42.219: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-18 16:58:42.219: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-4
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-18 16:58:47.153: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-18 16:59:26.590: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 39.436825]
2023-06-18 16:59:26.991: epoch 1:	0.00363126  	0.00851699  	0.00683331  
2023-06-18 16:59:26.991: Find a better model.
2023-06-18 17:00:06.212: [iter 2 : loss : 1.6056 = 0.6931 + 0.9125 + 0.0000, time: 39.213696]
2023-06-18 17:00:06.617: epoch 2:	0.00486675  	0.01117320  	0.00883662  
2023-06-18 17:00:06.617: Find a better model.
2023-06-18 17:00:45.821: [iter 3 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 39.196317]
2023-06-18 17:00:46.237: epoch 3:	0.00622041  	0.01374303  	0.01118770  
2023-06-18 17:00:46.238: Find a better model.
2023-06-18 17:01:25.471: [iter 4 : loss : 1.6053 = 0.6930 + 0.9123 + 0.0000, time: 39.226885]
2023-06-18 17:01:25.878: epoch 4:	0.00664477  	0.01385416  	0.01193857  
2023-06-18 17:01:25.879: Find a better model.
2023-06-18 17:02:05.087: [iter 5 : loss : 1.6052 = 0.6929 + 0.9123 + 0.0000, time: 39.202346]
2023-06-18 17:02:05.491: epoch 5:	0.00748815  	0.01623570  	0.01371718  
2023-06-18 17:02:05.491: Find a better model.
2023-06-18 17:02:44.785: [iter 6 : loss : 1.6052 = 0.6929 + 0.9124 + 0.0000, time: 39.287517]
2023-06-18 17:02:45.204: epoch 6:	0.00826707  	0.01781434  	0.01538539  
2023-06-18 17:02:45.205: Find a better model.
2023-06-18 17:03:24.577: [iter 7 : loss : 1.6053 = 0.6928 + 0.9125 + 0.0000, time: 39.365791]
2023-06-18 17:03:24.978: epoch 7:	0.00953485  	0.02037249  	0.01776276  
2023-06-18 17:03:24.979: Find a better model.
2023-06-18 17:04:04.646: [iter 8 : loss : 1.6052 = 0.6926 + 0.9125 + 0.0000, time: 39.660195]
2023-06-18 17:04:05.093: epoch 8:	0.01108733  	0.02213649  	0.02007034  
2023-06-18 17:04:05.093: Find a better model.
2023-06-18 17:04:44.574: [iter 9 : loss : 1.6053 = 0.6925 + 0.9128 + 0.0000, time: 39.473643]
2023-06-18 17:04:44.976: epoch 9:	0.01286004  	0.02606249  	0.02417994  
2023-06-18 17:04:44.976: Find a better model.
2023-06-18 17:05:24.623: [iter 10 : loss : 1.6051 = 0.6923 + 0.9128 + 0.0000, time: 39.640895]
2023-06-18 17:05:25.081: epoch 10:	0.01457906  	0.02923584  	0.02730620  
2023-06-18 17:05:25.081: Find a better model.
2023-06-18 17:06:17.250: [iter 11 : loss : 1.6048 = 0.6920 + 0.9128 + 0.0000, time: 52.160389]
2023-06-18 17:06:18.071: epoch 11:	0.01761955  	0.03568909  	0.03324732  
2023-06-18 17:06:18.071: Find a better model.
2023-06-18 17:07:12.859: [iter 12 : loss : 1.6046 = 0.6916 + 0.9130 + 0.0000, time: 54.781096]
2023-06-18 17:07:13.368: epoch 12:	0.02047740  	0.04114734  	0.03950129  
2023-06-18 17:07:13.369: Find a better model.
2023-06-18 17:08:05.403: [iter 13 : loss : 1.6043 = 0.6909 + 0.9133 + 0.0000, time: 52.025091]
2023-06-18 17:08:06.236: epoch 13:	0.02487696  	0.04973302  	0.04810160  
2023-06-18 17:08:06.236: Find a better model.
2023-06-18 17:08:59.096: [iter 14 : loss : 1.6035 = 0.6898 + 0.9136 + 0.0000, time: 52.852051]
2023-06-18 17:08:59.878: epoch 14:	0.03058154  	0.06201562  	0.06084223  
2023-06-18 17:08:59.878: Find a better model.
2023-06-18 17:09:52.516: [iter 15 : loss : 1.6019 = 0.6878 + 0.9141 + 0.0001, time: 52.631957]
2023-06-18 17:09:53.317: epoch 15:	0.03884805  	0.07740105  	0.07700145  
2023-06-18 17:09:53.317: Find a better model.
2023-06-18 17:10:37.480: [iter 16 : loss : 1.5987 = 0.6838 + 0.9148 + 0.0001, time: 44.156272]
2023-06-18 17:10:37.914: epoch 16:	0.04911844  	0.09676940  	0.09662777  
2023-06-18 17:10:37.914: Find a better model.
2023-06-18 17:11:30.414: [iter 17 : loss : 1.5912 = 0.6750 + 0.9161 + 0.0001, time: 52.491887]
2023-06-18 17:11:31.211: epoch 17:	0.06097861  	0.11789299  	0.11860768  
2023-06-18 17:11:31.211: Find a better model.
2023-06-18 17:12:23.998: [iter 18 : loss : 1.5744 = 0.6556 + 0.9185 + 0.0003, time: 52.779062]
2023-06-18 17:12:24.769: epoch 18:	0.07096968  	0.13532043  	0.13646892  
2023-06-18 17:12:24.769: Find a better model.
2023-06-18 17:13:17.522: [iter 19 : loss : 1.5417 = 0.6183 + 0.9228 + 0.0005, time: 52.746671]
2023-06-18 17:13:18.291: epoch 19:	0.07731891  	0.14593332  	0.14721246  
2023-06-18 17:13:18.291: Find a better model.
2023-06-18 17:14:11.260: [iter 20 : loss : 1.4930 = 0.5631 + 0.9290 + 0.0009, time: 52.959604]
2023-06-18 17:14:12.049: epoch 20:	0.08077810  	0.15144706  	0.15326063  
2023-06-18 17:14:12.049: Find a better model.
2023-06-18 17:15:06.260: [iter 21 : loss : 1.4363 = 0.4994 + 0.9356 + 0.0013, time: 54.199877]
2023-06-18 17:15:06.715: epoch 21:	0.08306647  	0.15573180  	0.15675505  
2023-06-18 17:15:06.716: Find a better model.
2023-06-18 17:15:59.066: [iter 22 : loss : 1.3810 = 0.4383 + 0.9408 + 0.0018, time: 52.337028]
2023-06-18 17:15:59.857: epoch 22:	0.08418378  	0.15805611  	0.15881933  
2023-06-18 17:15:59.857: Find a better model.
2023-06-18 17:16:52.777: [iter 23 : loss : 1.3326 = 0.3863 + 0.9440 + 0.0023, time: 52.909544]
2023-06-18 17:16:53.563: epoch 23:	0.08536544  	0.16024661  	0.16042429  
2023-06-18 17:16:53.563: Find a better model.
2023-06-18 17:17:46.412: [iter 24 : loss : 1.2914 = 0.3429 + 0.9457 + 0.0028, time: 52.840235]
2023-06-18 17:17:47.190: epoch 24:	0.08569307  	0.16110998  	0.16134164  
2023-06-18 17:17:47.190: Find a better model.
2023-06-18 17:18:40.100: [iter 25 : loss : 1.2572 = 0.3080 + 0.9459 + 0.0033, time: 52.901759]
2023-06-18 17:18:40.875: epoch 25:	0.08637528  	0.16246155  	0.16247182  
2023-06-18 17:18:40.875: Find a better model.
2023-06-18 17:19:35.120: [iter 26 : loss : 1.2276 = 0.2782 + 0.9456 + 0.0038, time: 54.238157]
2023-06-18 17:19:35.572: epoch 26:	0.08672978  	0.16350292  	0.16296217  
2023-06-18 17:19:35.572: Find a better model.
2023-06-18 17:20:27.864: [iter 27 : loss : 1.2027 = 0.2536 + 0.9448 + 0.0042, time: 52.283036]
2023-06-18 17:20:28.654: epoch 27:	0.08704130  	0.16413720  	0.16286692  
2023-06-18 17:20:28.654: Find a better model.
2023-06-18 17:21:21.789: [iter 28 : loss : 1.1816 = 0.2329 + 0.9441 + 0.0046, time: 53.127464]
2023-06-18 17:21:22.588: epoch 28:	0.08728304  	0.16475902  	0.16323222  
2023-06-18 17:21:22.588: Find a better model.
2023-06-18 17:22:16.477: [iter 29 : loss : 1.1639 = 0.2159 + 0.9429 + 0.0050, time: 53.881763]
2023-06-18 17:22:17.265: epoch 29:	0.08721320  	0.16446845  	0.16312476  
2023-06-18 17:23:11.251: [iter 30 : loss : 1.1480 = 0.2007 + 0.9419 + 0.0054, time: 53.976532]
2023-06-18 17:23:12.077: epoch 30:	0.08736898  	0.16476202  	0.16310775  
2023-06-18 17:23:12.077: Find a better model.
2023-06-18 17:24:07.481: [iter 31 : loss : 1.1333 = 0.1867 + 0.9408 + 0.0058, time: 55.396692]
2023-06-18 17:24:07.950: epoch 31:	0.08719706  	0.16442008  	0.16240072  
2023-06-18 17:25:01.388: [iter 32 : loss : 1.1218 = 0.1760 + 0.9397 + 0.0062, time: 53.420354]
2023-06-18 17:25:02.192: epoch 32:	0.08711646  	0.16366525  	0.16192895  
2023-06-18 17:25:56.882: [iter 33 : loss : 1.1104 = 0.1651 + 0.9387 + 0.0065, time: 54.681289]
2023-06-18 17:25:57.689: epoch 33:	0.08712722  	0.16370073  	0.16154458  
2023-06-18 17:26:53.706: [iter 34 : loss : 1.1014 = 0.1569 + 0.9377 + 0.0068, time: 56.004786]
2023-06-18 17:26:54.575: epoch 34:	0.08717559  	0.16363126  	0.16122928  
2023-06-18 17:27:52.674: [iter 35 : loss : 1.0920 = 0.1480 + 0.9369 + 0.0072, time: 58.086246]
2023-06-18 17:27:53.558: epoch 35:	0.08682106  	0.16278471  	0.16075373  
2023-06-18 17:28:53.164: [iter 36 : loss : 1.0848 = 0.1413 + 0.9361 + 0.0074, time: 59.593938]
2023-06-18 17:28:54.038: epoch 36:	0.08661150  	0.16187400  	0.16018598  
2023-06-18 17:29:53.204: [iter 37 : loss : 1.0770 = 0.1341 + 0.9351 + 0.0078, time: 59.151572]
2023-06-18 17:29:54.127: epoch 37:	0.08650406  	0.16148221  	0.15983532  
2023-06-18 17:30:53.196: [iter 38 : loss : 1.0711 = 0.1287 + 0.9344 + 0.0080, time: 59.057204]
2023-06-18 17:30:54.091: epoch 38:	0.08631600  	0.16066775  	0.15932713  
2023-06-18 17:31:55.730: [iter 39 : loss : 1.0652 = 0.1233 + 0.9336 + 0.0083, time: 61.622897]
2023-06-18 17:31:56.606: epoch 39:	0.08609579  	0.15972766  	0.15864104  
2023-06-18 17:33:00.506: [iter 40 : loss : 1.0603 = 0.1187 + 0.9330 + 0.0086, time: 63.891483]
2023-06-18 17:33:01.383: epoch 40:	0.08606355  	0.15926978  	0.15820825  
2023-06-18 17:34:04.188: [iter 41 : loss : 1.0549 = 0.1137 + 0.9323 + 0.0088, time: 62.785752]
2023-06-18 17:34:05.034: epoch 41:	0.08589169  	0.15830033  	0.15763442  
2023-06-18 17:35:10.520: [iter 42 : loss : 1.0506 = 0.1097 + 0.9318 + 0.0091, time: 65.454465]
2023-06-18 17:35:11.365: epoch 42:	0.08566075  	0.15776299  	0.15717064  
2023-06-18 17:36:19.097: [iter 43 : loss : 1.0459 = 0.1054 + 0.9311 + 0.0093, time: 67.715260]
2023-06-18 17:36:19.956: epoch 43:	0.08540294  	0.15691744  	0.15658846  
2023-06-18 17:37:30.193: [iter 44 : loss : 1.0425 = 0.1021 + 0.9308 + 0.0096, time: 70.228558]
2023-06-18 17:37:31.082: epoch 44:	0.08520956  	0.15636529  	0.15609337  
2023-06-18 17:38:41.893: [iter 45 : loss : 1.0394 = 0.0993 + 0.9302 + 0.0098, time: 70.801478]
2023-06-18 17:38:42.715: epoch 45:	0.08508604  	0.15598650  	0.15565163  
2023-06-18 17:39:52.891: [iter 46 : loss : 1.0355 = 0.0957 + 0.9298 + 0.0100, time: 70.160401]
2023-06-18 17:39:54.110: epoch 46:	0.08482283  	0.15520124  	0.15493356  
2023-06-18 17:41:02.493: [iter 47 : loss : 1.0326 = 0.0931 + 0.9293 + 0.0102, time: 68.356081]
2023-06-18 17:41:03.330: epoch 47:	0.08468319  	0.15461574  	0.15446955  
2023-06-18 17:42:10.895: [iter 48 : loss : 1.0295 = 0.0902 + 0.9289 + 0.0105, time: 67.558589]
2023-06-18 17:42:11.399: epoch 48:	0.08444682  	0.15382719  	0.15387185  
2023-06-18 17:43:18.735: [iter 49 : loss : 1.0267 = 0.0876 + 0.9285 + 0.0107, time: 67.327740]
2023-06-18 17:43:19.513: epoch 49:	0.08422663  	0.15307622  	0.15313718  
2023-06-18 17:44:26.725: [iter 50 : loss : 1.0244 = 0.0855 + 0.9281 + 0.0109, time: 67.194846]
2023-06-18 17:44:27.498: epoch 50:	0.08418906  	0.15293698  	0.15288803  
2023-06-18 17:45:35.450: [iter 51 : loss : 1.0221 = 0.0833 + 0.9278 + 0.0111, time: 67.936327]
2023-06-18 17:45:36.235: epoch 51:	0.08409236  	0.15250888  	0.15240654  
2023-06-18 17:46:43.997: [iter 52 : loss : 1.0200 = 0.0812 + 0.9275 + 0.0112, time: 67.746882]
2023-06-18 17:46:44.783: epoch 52:	0.08363038  	0.15124105  	0.15138054  
2023-06-18 17:47:52.476: [iter 53 : loss : 1.0177 = 0.0791 + 0.9272 + 0.0114, time: 67.687154]
2023-06-18 17:47:53.001: epoch 53:	0.08333499  	0.15059699  	0.15070143  
2023-06-18 17:48:59.231: [iter 54 : loss : 1.0155 = 0.0771 + 0.9268 + 0.0116, time: 66.218724]
2023-06-18 17:49:00.121: epoch 54:	0.08303958  	0.14990006  	0.15022139  
2023-06-18 17:50:06.484: [iter 55 : loss : 1.0139 = 0.0754 + 0.9266 + 0.0118, time: 66.348930]
2023-06-18 17:50:07.405: epoch 55:	0.08289993  	0.14942570  	0.14976339  
2023-06-18 17:50:07.405: Early stopping is trigger at epoch: 55
2023-06-18 17:50:07.405: best_result@epoch 30:

2023-06-18 17:50:07.405: 		0.0874      	0.1648      	0.1631      
2023-06-18 18:27:10.782: my pid: 10760
2023-06-18 18:27:10.782: model: model.general_recommender.SGL
2023-06-18 18:27:10.782: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-06-18 18:27:10.782: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-2
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-06-18 18:27:17.113: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-06-18 18:28:08.147: [iter 1 : loss : 1.6083 = 0.6931 + 0.9150 + 0.0002, time: 51.031843]
2023-06-18 18:28:08.930: epoch 1:	0.00314244  	0.00686717  	0.00598234  
2023-06-18 18:28:08.930: Find a better model.
2023-06-18 18:28:59.973: [iter 2 : loss : 1.6061 = 0.6931 + 0.9127 + 0.0003, time: 51.033214]
2023-06-18 18:29:00.797: epoch 2:	0.00357755  	0.00810584  	0.00670132  
2023-06-18 18:29:00.797: Find a better model.
2023-06-18 18:30:06.280: [iter 3 : loss : 1.6059 = 0.6930 + 0.9125 + 0.0004, time: 65.476872]
2023-06-18 18:30:07.105: epoch 3:	0.00432421  	0.00894491  	0.00743161  
2023-06-18 18:30:07.106: Find a better model.
2023-06-18 18:31:12.767: [iter 4 : loss : 1.6059 = 0.6930 + 0.9125 + 0.0005, time: 65.647613]
2023-06-18 18:31:13.589: epoch 4:	0.00437256  	0.00872271  	0.00743340  
2023-06-18 18:32:19.669: [iter 5 : loss : 1.6059 = 0.6930 + 0.9124 + 0.0005, time: 66.071756]
2023-06-18 18:32:20.503: epoch 5:	0.00487749  	0.00913830  	0.00797683  
2023-06-18 18:32:20.504: Find a better model.
2023-06-18 18:33:27.461: [iter 6 : loss : 1.6060 = 0.6929 + 0.9125 + 0.0006, time: 66.943793]
2023-06-18 18:33:28.254: epoch 6:	0.00577993  	0.01109895  	0.00970955  
2023-06-18 18:33:28.254: Find a better model.
2023-06-18 18:34:34.874: [iter 7 : loss : 1.6061 = 0.6929 + 0.9125 + 0.0007, time: 66.603734]
2023-06-18 18:34:35.722: epoch 7:	0.00608074  	0.01128859  	0.00992207  
2023-06-18 18:34:35.722: Find a better model.
2023-06-18 18:35:42.803: [iter 8 : loss : 1.6060 = 0.6929 + 0.9124 + 0.0008, time: 67.072974]
2023-06-18 18:35:43.653: epoch 8:	0.00638156  	0.01163199  	0.01058525  
2023-06-18 18:35:43.653: Find a better model.
2023-06-18 18:36:51.786: [iter 9 : loss : 1.6062 = 0.6928 + 0.9125 + 0.0008, time: 68.124967]
2023-06-18 18:36:52.351: epoch 9:	0.00702079  	0.01372124  	0.01152871  
2023-06-18 18:36:52.352: Find a better model.
2023-06-18 18:37:59.695: [iter 10 : loss : 1.6061 = 0.6928 + 0.9125 + 0.0009, time: 67.318086]
2023-06-18 18:38:00.569: epoch 10:	0.00736997  	0.01330467  	0.01245911  
2023-06-18 18:39:08.645: [iter 11 : loss : 1.6061 = 0.6927 + 0.9124 + 0.0010, time: 68.068426]
2023-06-18 18:39:09.499: epoch 11:	0.00785344  	0.01510740  	0.01347973  
2023-06-18 18:39:09.499: Find a better model.
2023-06-18 18:40:16.746: [iter 12 : loss : 1.6061 = 0.6926 + 0.9125 + 0.0010, time: 67.239269]
2023-06-18 18:40:17.668: epoch 12:	0.00866998  	0.01617971  	0.01490591  
2023-06-18 18:40:17.668: Find a better model.
2023-06-18 18:41:24.888: [iter 13 : loss : 1.6061 = 0.6926 + 0.9125 + 0.0011, time: 67.202213]
2023-06-18 18:41:26.138: epoch 13:	0.00949724  	0.01830262  	0.01651957  
2023-06-18 18:41:26.138: Find a better model.
2023-06-18 18:42:33.581: [iter 14 : loss : 1.6062 = 0.6925 + 0.9125 + 0.0012, time: 67.433190]
2023-06-18 18:42:34.413: epoch 14:	0.00986789  	0.01882957  	0.01708933  
2023-06-18 18:42:34.414: Find a better model.
2023-06-18 18:43:41.731: [iter 15 : loss : 1.6061 = 0.6924 + 0.9125 + 0.0012, time: 67.307933]
2023-06-18 18:43:42.633: epoch 15:	0.01045881  	0.01958959  	0.01791855  
2023-06-18 18:43:42.634: Find a better model.
2023-06-18 18:44:50.892: [iter 16 : loss : 1.6062 = 0.6923 + 0.9125 + 0.0013, time: 68.252642]
2023-06-18 18:44:51.399: epoch 16:	0.01118939  	0.02154701  	0.02033079  
2023-06-18 18:44:51.399: Find a better model.
2023-06-18 18:45:58.692: [iter 17 : loss : 1.6061 = 0.6922 + 0.9124 + 0.0014, time: 67.260179]
2023-06-18 18:45:59.914: epoch 17:	0.01176955  	0.02331019  	0.02151381  
2023-06-18 18:45:59.914: Find a better model.
2023-06-18 18:47:08.426: [iter 18 : loss : 1.6061 = 0.6921 + 0.9125 + 0.0015, time: 68.499999]
2023-06-18 18:47:09.682: epoch 18:	0.01298358  	0.02488619  	0.02379599  
2023-06-18 18:47:09.683: Find a better model.
2023-06-18 18:48:17.686: [iter 19 : loss : 1.6061 = 0.6920 + 0.9125 + 0.0016, time: 67.981245]
2023-06-18 18:48:18.943: epoch 19:	0.01417616  	0.02793145  	0.02544674  
2023-06-18 18:48:18.943: Find a better model.
2023-06-18 18:49:26.775: [iter 20 : loss : 1.6061 = 0.6919 + 0.9126 + 0.0017, time: 67.823533]
2023-06-18 18:49:27.655: epoch 20:	0.01474022  	0.02942135  	0.02716993  
2023-06-18 18:49:27.656: Find a better model.
2023-06-18 18:50:36.076: [iter 21 : loss : 1.6061 = 0.6917 + 0.9126 + 0.0018, time: 68.413653]
2023-06-18 18:50:36.797: epoch 21:	0.01552989  	0.03007815  	0.02825399  
2023-06-18 18:50:36.797: Find a better model.
2023-06-18 18:51:44.061: [iter 22 : loss : 1.6061 = 0.6916 + 0.9127 + 0.0019, time: 67.255627]
2023-06-18 18:51:44.914: epoch 22:	0.01692120  	0.03319276  	0.03134740  
2023-06-18 18:51:44.914: Find a better model.
2023-06-18 18:52:54.034: [iter 23 : loss : 1.6061 = 0.6914 + 0.9127 + 0.0020, time: 69.112040]
2023-06-18 18:52:54.848: epoch 23:	0.01746377  	0.03487599  	0.03257066  
2023-06-18 18:52:54.848: Find a better model.
2023-06-18 18:54:03.455: [iter 24 : loss : 1.6061 = 0.6912 + 0.9127 + 0.0021, time: 68.587742]
2023-06-18 18:54:04.707: epoch 24:	0.01925263  	0.03950015  	0.03622640  
2023-06-18 18:54:04.708: Find a better model.
2023-06-18 18:55:12.788: [iter 25 : loss : 1.6061 = 0.6910 + 0.9128 + 0.0023, time: 68.056456]
2023-06-18 18:55:14.014: epoch 25:	0.02112203  	0.04207358  	0.04026944  
2023-06-18 18:55:14.014: Find a better model.
2023-06-18 18:56:22.247: [iter 26 : loss : 1.6060 = 0.6906 + 0.9129 + 0.0025, time: 68.225477]
2023-06-18 18:56:23.066: epoch 26:	0.02315797  	0.04746441  	0.04507899  
2023-06-18 18:56:23.066: Find a better model.
2023-06-18 18:57:32.397: [iter 27 : loss : 1.6060 = 0.6903 + 0.9130 + 0.0027, time: 69.322205]
2023-06-18 18:57:33.182: epoch 27:	0.02511870  	0.05140740  	0.04932739  
2023-06-18 18:57:33.182: Find a better model.
2023-06-18 18:58:43.266: [iter 28 : loss : 1.6059 = 0.6898 + 0.9131 + 0.0030, time: 70.064683]
2023-06-18 18:58:44.026: epoch 28:	0.02765420  	0.05723974  	0.05480676  
2023-06-18 18:58:44.026: Find a better model.
2023-06-18 18:59:54.155: [iter 29 : loss : 1.6058 = 0.6891 + 0.9132 + 0.0034, time: 70.118412]
2023-06-18 18:59:54.985: epoch 29:	0.03093065  	0.06480908  	0.06130974  
2023-06-18 18:59:54.985: Find a better model.
2023-06-18 19:01:05.559: [iter 30 : loss : 1.6056 = 0.6883 + 0.9135 + 0.0039, time: 70.565786]
2023-06-18 19:01:06.415: epoch 30:	0.03454557  	0.07220030  	0.06925727  
2023-06-18 19:01:06.415: Find a better model.
2023-06-18 19:02:16.160: [iter 31 : loss : 1.6053 = 0.6870 + 0.9137 + 0.0046, time: 69.726903]
2023-06-18 19:02:16.991: epoch 31:	0.03998684  	0.08206246  	0.07981808  
2023-06-18 19:02:16.991: Find a better model.
2023-06-18 19:03:26.900: [iter 32 : loss : 1.6049 = 0.6852 + 0.9141 + 0.0056, time: 69.901569]
2023-06-18 19:03:27.749: epoch 32:	0.04509513  	0.09214365  	0.09101955  
2023-06-18 19:03:27.749: Find a better model.
2023-06-18 19:04:38.640: [iter 33 : loss : 1.6041 = 0.6824 + 0.9146 + 0.0070, time: 70.880569]
2023-06-18 19:04:39.523: epoch 33:	0.05243801  	0.10509212  	0.10411967  
2023-06-18 19:04:39.523: Find a better model.
2023-06-18 19:05:50.495: [iter 34 : loss : 1.6026 = 0.6779 + 0.9154 + 0.0093, time: 70.954722]
2023-06-18 19:05:51.331: epoch 34:	0.06009778  	0.11881606  	0.11864146  
2023-06-18 19:05:51.331: Find a better model.
2023-06-18 19:07:01.381: [iter 35 : loss : 1.5999 = 0.6704 + 0.9165 + 0.0130, time: 70.026413]
2023-06-18 19:07:02.201: epoch 35:	0.06762855  	0.13083555  	0.13188036  
2023-06-18 19:07:02.201: Find a better model.
2023-06-18 19:08:12.866: [iter 36 : loss : 1.5951 = 0.6583 + 0.9181 + 0.0187, time: 70.652228]
2023-06-18 19:08:13.729: epoch 36:	0.07441286  	0.14212708  	0.14411984  
2023-06-18 19:08:13.729: Find a better model.
2023-06-18 19:09:23.852: [iter 37 : loss : 1.5873 = 0.6396 + 0.9204 + 0.0272, time: 70.113038]
2023-06-18 19:09:24.683: epoch 37:	0.07982205  	0.15110222  	0.15262853  
2023-06-18 19:09:24.683: Find a better model.
2023-06-18 19:10:34.710: [iter 38 : loss : 1.5764 = 0.6143 + 0.9235 + 0.0386, time: 70.013791]
2023-06-18 19:10:35.567: epoch 38:	0.08324369  	0.15711297  	0.15883312  
2023-06-18 19:10:35.567: Find a better model.
2023-06-18 19:11:31.998: [iter 39 : loss : 1.5635 = 0.5840 + 0.9273 + 0.0523, time: 56.421980]
2023-06-18 19:11:32.550: epoch 39:	0.08511828  	0.16109863  	0.16228215  
2023-06-18 19:11:32.551: Find a better model.
2023-06-18 19:12:28.330: [iter 40 : loss : 1.5500 = 0.5516 + 0.9312 + 0.0672, time: 55.771500]
2023-06-18 19:12:28.823: epoch 40:	0.08650950  	0.16416731  	0.16500369  
2023-06-18 19:12:28.824: Find a better model.
2023-06-18 19:13:24.786: [iter 41 : loss : 1.5369 = 0.5194 + 0.9352 + 0.0823, time: 55.954957]
2023-06-18 19:13:25.283: epoch 41:	0.08773421  	0.16676086  	0.16688852  
2023-06-18 19:13:25.283: Find a better model.
2023-06-18 19:14:21.361: [iter 42 : loss : 1.5256 = 0.4902 + 0.9387 + 0.0967, time: 56.067355]
2023-06-18 19:14:21.850: epoch 42:	0.08859904  	0.16890834  	0.16860142  
2023-06-18 19:14:21.850: Find a better model.
2023-06-18 19:15:18.063: [iter 43 : loss : 1.5157 = 0.4635 + 0.9418 + 0.1103, time: 56.203518]
2023-06-18 19:15:18.584: epoch 43:	0.08923286  	0.17050613  	0.17004082  
2023-06-18 19:15:18.584: Find a better model.
2023-06-18 19:16:14.933: [iter 44 : loss : 1.5077 = 0.4408 + 0.9443 + 0.1226, time: 56.341206]
2023-06-18 19:16:15.486: epoch 44:	0.08985061  	0.17187050  	0.17122653  
2023-06-18 19:16:15.486: Find a better model.
2023-06-18 19:17:11.260: [iter 45 : loss : 1.5013 = 0.4213 + 0.9464 + 0.1336, time: 55.764612]
2023-06-18 19:17:11.764: epoch 45:	0.09052737  	0.17336349  	0.17189194  
2023-06-18 19:17:11.764: Find a better model.
2023-06-18 19:18:08.068: [iter 46 : loss : 1.4957 = 0.4041 + 0.9482 + 0.1434, time: 56.295541]
2023-06-18 19:18:08.601: epoch 46:	0.09075300  	0.17424804  	0.17222445  
2023-06-18 19:18:08.601: Find a better model.
2023-06-18 19:19:04.652: [iter 47 : loss : 1.4907 = 0.3889 + 0.9496 + 0.1522, time: 56.041611]
2023-06-18 19:19:05.202: epoch 47:	0.09118273  	0.17505074  	0.17292756  
2023-06-18 19:19:05.202: Find a better model.
2023-06-18 19:20:15.256: [iter 48 : loss : 1.4873 = 0.3763 + 0.9509 + 0.1601, time: 70.037992]
2023-06-18 19:20:16.059: epoch 48:	0.09160172  	0.17560211  	0.17305791  
2023-06-18 19:20:16.060: Find a better model.
2023-07-01 19:35:15.917: my pid: 1460
2023-07-01 19:35:15.921: model: model.general_recommender.SGL
2023-07-01 19:35:15.921: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-07-01 19:35:15.922: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=1e-2
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.3
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-07-01 19:35:44.429: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-07-11 16:52:48.150: my pid: 12188
2023-07-11 16:52:48.151: model: model.general_recommender.SGL
2023-07-11 16:52:48.151: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-07-11 16:52:48.151: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-07-11 16:52:54.178: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-07-11 16:53:44.601: [iter 1 : loss : 1.6094 = 0.6931 + 0.9163 + 0.0000, time: 50.422138]
2023-07-11 16:53:45.179: epoch 1:	0.00287386  	0.00683150  	0.00530060  
2023-07-11 16:53:45.179: Find a better model.
2023-07-11 16:54:34.728: [iter 2 : loss : 1.6076 = 0.6931 + 0.9146 + 0.0000, time: 49.540404]
2023-07-11 16:54:35.294: epoch 2:	0.00373870  	0.00818415  	0.00679151  
2023-07-11 16:54:35.295: Find a better model.
2023-07-11 16:55:25.078: [iter 3 : loss : 1.6077 = 0.6930 + 0.9146 + 0.0000, time: 49.775022]
2023-07-11 16:55:25.641: epoch 3:	0.00436181  	0.00907280  	0.00777465  
2023-07-11 16:55:25.641: Find a better model.
2023-07-11 16:56:15.368: [iter 4 : loss : 1.6079 = 0.6930 + 0.9149 + 0.0000, time: 49.718773]
2023-07-11 16:56:15.933: epoch 4:	0.00489898  	0.00952057  	0.00835018  
2023-07-11 16:56:15.933: Find a better model.
2023-07-11 16:57:05.713: [iter 5 : loss : 1.6080 = 0.6929 + 0.9151 + 0.0000, time: 49.772304]
2023-07-11 16:57:06.276: epoch 5:	0.00581753  	0.01161104  	0.01024400  
2023-07-11 16:57:06.276: Find a better model.
2023-07-11 16:57:56.097: [iter 6 : loss : 1.6082 = 0.6928 + 0.9154 + 0.0000, time: 49.813365]
2023-07-11 16:57:56.660: epoch 6:	0.00673608  	0.01332423  	0.01227190  
2023-07-11 16:57:56.661: Find a better model.
2023-07-11 16:58:46.284: [iter 7 : loss : 1.6084 = 0.6927 + 0.9157 + 0.0000, time: 49.616472]
2023-07-11 16:58:46.856: epoch 7:	0.00724642  	0.01429121  	0.01297587  
2023-07-11 16:58:46.856: Find a better model.
2023-07-11 16:59:36.399: [iter 8 : loss : 1.6084 = 0.6926 + 0.9158 + 0.0000, time: 49.535652]
2023-07-11 16:59:36.966: epoch 8:	0.00794477  	0.01621892  	0.01461405  
2023-07-11 16:59:36.966: Find a better model.
2023-07-11 17:00:26.842: [iter 9 : loss : 1.6087 = 0.6924 + 0.9162 + 0.0000, time: 49.869494]
2023-07-11 17:00:27.415: epoch 9:	0.01002369  	0.01932777  	0.01794993  
2023-07-11 17:00:27.416: Find a better model.
2023-07-11 17:01:17.103: [iter 10 : loss : 1.6087 = 0.6922 + 0.9164 + 0.0000, time: 49.679753]
2023-07-11 17:01:17.675: epoch 10:	0.01143112  	0.02163101  	0.02024972  
2023-07-11 17:01:17.675: Find a better model.
2023-07-11 17:02:09.191: [iter 11 : loss : 1.6087 = 0.6919 + 0.9167 + 0.0000, time: 51.507641]
2023-07-11 17:02:09.767: epoch 11:	0.01370878  	0.02674098  	0.02541286  
2023-07-11 17:02:09.768: Find a better model.
2023-07-11 17:03:01.362: [iter 12 : loss : 1.6087 = 0.6915 + 0.9172 + 0.0000, time: 51.585608]
2023-07-11 17:03:01.929: epoch 12:	0.01699638  	0.03314845  	0.03148945  
2023-07-11 17:03:01.929: Find a better model.
2023-07-11 17:03:53.516: [iter 13 : loss : 1.6085 = 0.6908 + 0.9176 + 0.0000, time: 51.578431]
2023-07-11 17:03:54.097: epoch 13:	0.02147118  	0.04297397  	0.04122334  
2023-07-11 17:03:54.097: Find a better model.
2023-07-11 17:04:46.028: [iter 14 : loss : 1.6080 = 0.6898 + 0.9183 + 0.0000, time: 51.922422]
2023-07-11 17:04:46.593: epoch 14:	0.02751448  	0.05413333  	0.05301647  
2023-07-11 17:04:46.593: Find a better model.
2023-07-11 17:05:38.125: [iter 15 : loss : 1.6069 = 0.6879 + 0.9190 + 0.0000, time: 51.523915]
2023-07-11 17:05:38.697: epoch 15:	0.03657600  	0.07139388  	0.07057779  
2023-07-11 17:05:38.697: Find a better model.
2023-07-11 17:06:30.103: [iter 16 : loss : 1.6046 = 0.6842 + 0.9203 + 0.0000, time: 51.399333]
2023-07-11 17:06:30.669: epoch 16:	0.04760914  	0.09208250  	0.09139109  
2023-07-11 17:06:30.669: Find a better model.
2023-07-11 17:07:22.060: [iter 17 : loss : 1.5987 = 0.6766 + 0.9221 + 0.0000, time: 51.384656]
2023-07-11 17:07:22.619: epoch 17:	0.05986150  	0.11355734  	0.11371226  
2023-07-11 17:07:22.619: Find a better model.
2023-07-11 17:08:14.096: [iter 18 : loss : 1.5854 = 0.6603 + 0.9251 + 0.0000, time: 51.468446]
2023-07-11 17:08:14.659: epoch 18:	0.06999201  	0.13107914  	0.13211152  
2023-07-11 17:08:14.659: Find a better model.
2023-07-11 17:09:05.880: [iter 19 : loss : 1.5581 = 0.6284 + 0.9297 + 0.0000, time: 51.213163]
2023-07-11 17:09:06.448: epoch 19:	0.07654534  	0.14233740  	0.14425682  
2023-07-11 17:09:06.448: Find a better model.
2023-07-11 17:09:57.722: [iter 20 : loss : 1.5150 = 0.5788 + 0.9361 + 0.0000, time: 51.265829]
2023-07-11 17:09:58.286: epoch 20:	0.08054172  	0.14999399  	0.15142982  
2023-07-11 17:09:58.286: Find a better model.
2023-07-11 17:10:49.591: [iter 21 : loss : 1.4608 = 0.5176 + 0.9432 + 0.0000, time: 51.297807]
2023-07-11 17:10:50.167: epoch 21:	0.08242720  	0.15412562  	0.15529101  
2023-07-11 17:10:50.167: Find a better model.
2023-07-11 17:11:41.346: [iter 22 : loss : 1.4049 = 0.4559 + 0.9489 + 0.0000, time: 51.171604]
2023-07-11 17:11:41.914: epoch 22:	0.08409237  	0.15810531  	0.15850501  
2023-07-11 17:11:41.915: Find a better model.
2023-07-11 17:12:33.375: [iter 23 : loss : 1.3544 = 0.4015 + 0.9529 + 0.0000, time: 51.453014]
2023-07-11 17:12:33.940: epoch 23:	0.08534386  	0.16102669  	0.16101989  
2023-07-11 17:12:33.940: Find a better model.
2023-07-11 17:13:25.848: [iter 24 : loss : 1.3103 = 0.3554 + 0.9549 + 0.0000, time: 51.901023]
2023-07-11 17:13:26.419: epoch 24:	0.08631616  	0.16292664  	0.16244680  
2023-07-11 17:13:26.419: Find a better model.
2023-07-11 17:14:18.410: [iter 25 : loss : 1.2732 = 0.3179 + 0.9553 + 0.0000, time: 51.983812]
2023-07-11 17:14:18.984: epoch 25:	0.08657936  	0.16390772  	0.16327657  
2023-07-11 17:14:18.984: Find a better model.
2023-07-11 17:15:10.447: [iter 26 : loss : 1.2414 = 0.2862 + 0.9552 + 0.0000, time: 51.456227]
2023-07-11 17:15:11.010: epoch 26:	0.08696070  	0.16471957  	0.16377468  
2023-07-11 17:15:11.011: Find a better model.
2023-07-11 17:16:02.380: [iter 27 : loss : 1.2144 = 0.2599 + 0.9545 + 0.0000, time: 51.360558]
2023-07-11 17:16:02.946: epoch 27:	0.08746024  	0.16574296  	0.16438353  
2023-07-11 17:16:02.946: Find a better model.
2023-07-11 17:16:54.518: [iter 28 : loss : 1.1914 = 0.2377 + 0.9537 + 0.0000, time: 51.563639]
2023-07-11 17:16:55.081: epoch 28:	0.08751942  	0.16584566  	0.16448644  
2023-07-11 17:16:55.081: Find a better model.
2023-07-11 17:17:46.830: [iter 29 : loss : 1.1719 = 0.2195 + 0.9524 + 0.0000, time: 51.739801]
2023-07-11 17:17:47.396: epoch 29:	0.08779866  	0.16625977  	0.16476919  
2023-07-11 17:17:47.396: Find a better model.
2023-07-11 17:18:39.163: [iter 30 : loss : 1.1547 = 0.2035 + 0.9513 + 0.0000, time: 51.759248]
2023-07-11 17:18:39.733: epoch 30:	0.08769663  	0.16640016  	0.16471273  
2023-07-11 17:18:39.734: Find a better model.
2023-07-11 17:19:31.666: [iter 31 : loss : 1.1391 = 0.1890 + 0.9501 + 0.0000, time: 51.924786]
2023-07-11 17:19:32.244: epoch 31:	0.08746023  	0.16580586  	0.16410047  
2023-07-11 17:20:25.506: [iter 32 : loss : 1.1265 = 0.1776 + 0.9490 + 0.0000, time: 53.254488]
2023-07-11 17:20:26.100: epoch 32:	0.08735283  	0.16519715  	0.16363956  
2023-07-11 17:21:19.057: [iter 33 : loss : 1.1142 = 0.1662 + 0.9479 + 0.0000, time: 52.947638]
2023-07-11 17:21:19.679: epoch 33:	0.08743877  	0.16482753  	0.16358620  
2023-07-11 17:22:12.517: [iter 34 : loss : 1.1043 = 0.1574 + 0.9468 + 0.0000, time: 52.827796]
2023-07-11 17:22:13.098: epoch 34:	0.08714866  	0.16388224  	0.16292377  
2023-07-11 17:23:05.813: [iter 35 : loss : 1.0945 = 0.1484 + 0.9460 + 0.0000, time: 52.707356]
2023-07-11 17:23:06.385: epoch 35:	0.08712178  	0.16378793  	0.16260393  
2023-07-11 17:23:58.732: [iter 36 : loss : 1.0863 = 0.1413 + 0.9450 + 0.0000, time: 52.340265]
2023-07-11 17:23:59.317: epoch 36:	0.08710026  	0.16352324  	0.16213381  
2023-07-11 17:24:51.476: [iter 37 : loss : 1.0780 = 0.1340 + 0.9441 + 0.0000, time: 52.150848]
2023-07-11 17:24:52.049: epoch 37:	0.08690151  	0.16261826  	0.16153519  
2023-07-11 17:25:44.269: [iter 38 : loss : 1.0713 = 0.1281 + 0.9432 + 0.0000, time: 52.210713]
2023-07-11 17:25:44.834: epoch 38:	0.08677794  	0.16203167  	0.16096541  
2023-07-11 17:26:36.918: [iter 39 : loss : 1.0650 = 0.1226 + 0.9424 + 0.0000, time: 52.075952]
2023-07-11 17:26:37.485: epoch 39:	0.08652013  	0.16115589  	0.16033766  
2023-07-11 17:27:30.958: [iter 40 : loss : 1.0596 = 0.1179 + 0.9417 + 0.0000, time: 53.464746]
2023-07-11 17:27:31.922: epoch 40:	0.08626765  	0.16084337  	0.15980782  
2023-07-11 17:28:25.890: [iter 41 : loss : 1.0539 = 0.1129 + 0.9410 + 0.0000, time: 53.958998]
2023-07-11 17:28:26.480: epoch 41:	0.08617104  	0.16027826  	0.15933825  
2023-07-11 17:29:19.862: [iter 42 : loss : 1.0491 = 0.1086 + 0.9404 + 0.0000, time: 53.375409]
2023-07-11 17:29:20.434: epoch 42:	0.08593470  	0.15948063  	0.15858376  
2023-07-11 17:30:12.049: [iter 43 : loss : 1.0442 = 0.1043 + 0.9399 + 0.0000, time: 51.607291]
2023-07-11 17:30:12.618: epoch 43:	0.08570368  	0.15890992  	0.15822716  
2023-07-11 17:31:04.269: [iter 44 : loss : 1.0401 = 0.1007 + 0.9394 + 0.0000, time: 51.643072]
2023-07-11 17:31:04.835: epoch 44:	0.08549417  	0.15838654  	0.15784927  
2023-07-11 17:31:56.796: [iter 45 : loss : 1.0368 = 0.0981 + 0.9388 + 0.0000, time: 51.952661]
2023-07-11 17:31:57.365: epoch 45:	0.08523097  	0.15748172  	0.15721808  
2023-07-11 17:32:50.590: [iter 46 : loss : 1.0331 = 0.0948 + 0.9383 + 0.0000, time: 53.218078]
2023-07-11 17:32:51.163: epoch 46:	0.08507520  	0.15712315  	0.15684350  
2023-07-11 17:33:43.154: [iter 47 : loss : 1.0296 = 0.0919 + 0.9377 + 0.0000, time: 51.983015]
2023-07-11 17:33:43.743: epoch 47:	0.08493018  	0.15626377  	0.15618497  
2023-07-11 17:34:35.754: [iter 48 : loss : 1.0262 = 0.0889 + 0.9373 + 0.0000, time: 52.002755]
2023-07-11 17:34:36.316: epoch 48:	0.08469918  	0.15512058  	0.15541857  
2023-07-11 17:35:28.925: [iter 49 : loss : 1.0234 = 0.0865 + 0.9369 + 0.0000, time: 52.601328]
2023-07-11 17:35:29.509: epoch 49:	0.08457561  	0.15518427  	0.15510778  
2023-07-11 17:36:21.342: [iter 50 : loss : 1.0205 = 0.0841 + 0.9364 + 0.0000, time: 51.826650]
2023-07-11 17:36:21.907: epoch 50:	0.08436076  	0.15505441  	0.15461758  
2023-07-11 17:37:14.115: [iter 51 : loss : 1.0181 = 0.0819 + 0.9363 + 0.0000, time: 52.199977]
2023-07-11 17:37:14.688: epoch 51:	0.08414054  	0.15413631  	0.15405975  
2023-07-11 17:38:06.877: [iter 52 : loss : 1.0156 = 0.0797 + 0.9359 + 0.0000, time: 52.180465]
2023-07-11 17:38:07.450: epoch 52:	0.08393108  	0.15346564  	0.15338108  
2023-07-11 17:38:59.594: [iter 53 : loss : 1.0132 = 0.0777 + 0.9354 + 0.0000, time: 52.134452]
2023-07-11 17:39:00.161: epoch 53:	0.08370549  	0.15269879  	0.15285887  
2023-07-11 17:39:52.032: [iter 54 : loss : 1.0105 = 0.0753 + 0.9352 + 0.0000, time: 51.862672]
2023-07-11 17:39:52.601: epoch 54:	0.08363562  	0.15231347  	0.15242562  
2023-07-11 17:40:44.281: [iter 55 : loss : 1.0087 = 0.0739 + 0.9349 + 0.0000, time: 51.672495]
2023-07-11 17:40:44.843: epoch 55:	0.08349597  	0.15189497  	0.15199573  
2023-07-11 17:40:44.844: Early stopping is trigger at epoch: 55
2023-07-11 17:40:44.844: best_result@epoch 30:

2023-07-11 17:40:44.844: 		0.0877      	0.1664      	0.1647      
2023-11-28 16:17:11.142: my pid: 69300
2023-11-28 16:17:11.142: model: model.general_recommender.SGL
2023-11-28 16:17:11.142: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 16:17:11.142: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 16:17:19.622: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-28 16:18:13.718: [iter 1 : loss : 1.6094 = 0.6931 + 0.9163 + 0.0000, time: 54.082798]
2023-11-28 16:18:14.383: epoch 1:	0.00287386  	0.00683150  	0.00530060  
2023-11-28 16:18:14.383: Find a better model.
2023-11-28 16:37:03.280: my pid: 5968
2023-11-28 16:37:03.281: model: model.general_recommender.SGL
2023-11-28 16:37:03.281: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 16:37:03.281: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 16:37:09.379: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-28 16:37:42.067: [iter 1 : loss : 1.6088 = 0.6931 + 0.9157 + 0.0000, time: 32.685296]
2023-11-28 16:37:42.738: epoch 1:	0.00277717  	0.00721994  	0.00543786  
2023-11-28 16:37:42.738: Find a better model.
2023-11-28 16:38:14.998: [iter 2 : loss : 1.6062 = 0.6931 + 0.9131 + 0.0000, time: 32.246904]
2023-11-28 16:38:15.668: epoch 2:	0.00305650  	0.00746159  	0.00565972  
2023-11-28 16:38:15.668: Find a better model.
2023-11-28 16:38:47.786: [iter 3 : loss : 1.6060 = 0.6930 + 0.9129 + 0.0000, time: 32.109480]
2023-11-28 16:38:48.453: epoch 3:	0.00349698  	0.00792959  	0.00636834  
2023-11-28 16:38:48.453: Find a better model.
2023-11-28 16:39:21.064: [iter 4 : loss : 1.6060 = 0.6930 + 0.9130 + 0.0000, time: 32.596497]
2023-11-28 16:39:21.767: epoch 4:	0.00379242  	0.00844711  	0.00703054  
2023-11-28 16:39:21.768: Find a better model.
2023-11-28 16:39:54.005: [iter 5 : loss : 1.6059 = 0.6929 + 0.9130 + 0.0000, time: 32.218984]
2023-11-28 16:39:54.662: epoch 5:	0.00452833  	0.01036430  	0.00873115  
2023-11-28 16:39:54.663: Find a better model.
2023-11-28 16:40:27.242: [iter 6 : loss : 1.6060 = 0.6929 + 0.9131 + 0.0000, time: 32.571270]
2023-11-28 16:40:27.927: epoch 6:	0.00509236  	0.01085562  	0.00925856  
2023-11-28 16:40:27.927: Find a better model.
2023-11-28 16:41:00.440: [iter 7 : loss : 1.6060 = 0.6928 + 0.9133 + 0.0000, time: 32.505838]
2023-11-28 16:41:01.097: epoch 7:	0.00584976  	0.01242752  	0.01068116  
2023-11-28 16:41:01.097: Find a better model.
2023-11-28 16:41:33.362: [iter 8 : loss : 1.6059 = 0.6927 + 0.9132 + 0.0000, time: 32.256672]
2023-11-28 16:41:34.011: epoch 8:	0.00644601  	0.01402741  	0.01196626  
2023-11-28 16:41:34.011: Find a better model.
2023-11-28 16:42:06.326: [iter 9 : loss : 1.6060 = 0.6925 + 0.9135 + 0.0000, time: 32.306018]
2023-11-28 16:42:06.988: epoch 9:	0.00771914  	0.01679463  	0.01465807  
2023-11-28 16:42:06.988: Find a better model.
2023-11-28 16:42:38.969: [iter 10 : loss : 1.6059 = 0.6924 + 0.9135 + 0.0000, time: 31.972095]
2023-11-28 16:42:39.652: epoch 10:	0.00913196  	0.01969652  	0.01742046  
2023-11-28 16:42:39.652: Find a better model.
2023-11-28 16:43:12.998: [iter 11 : loss : 1.6058 = 0.6921 + 0.9137 + 0.0000, time: 33.338014]
2023-11-28 16:43:13.608: epoch 11:	0.01135592  	0.02421683  	0.02165654  
2023-11-28 16:43:13.608: Find a better model.
2023-11-28 16:43:47.390: [iter 12 : loss : 1.6056 = 0.6917 + 0.9138 + 0.0000, time: 33.773490]
2023-11-28 16:43:48.024: epoch 12:	0.01437492  	0.03001362  	0.02752927  
2023-11-28 16:43:48.024: Find a better model.
2023-11-28 16:44:21.178: [iter 13 : loss : 1.6053 = 0.6911 + 0.9141 + 0.0000, time: 33.146846]
2023-11-28 16:44:21.784: epoch 13:	0.01802783  	0.03689830  	0.03487544  
2023-11-28 16:44:21.784: Find a better model.
2023-11-28 16:44:55.168: [iter 14 : loss : 1.6046 = 0.6902 + 0.9144 + 0.0000, time: 33.377195]
2023-11-28 16:44:55.828: epoch 14:	0.02339971  	0.04926920  	0.04653366  
2023-11-28 16:44:55.828: Find a better model.
2023-11-28 16:45:29.122: [iter 15 : loss : 1.6034 = 0.6885 + 0.9149 + 0.0000, time: 33.259295]
2023-11-28 16:45:29.719: epoch 15:	0.03116162  	0.06534801  	0.06211298  
2023-11-28 16:45:29.720: Find a better model.
2023-11-28 16:46:02.924: [iter 16 : loss : 1.6007 = 0.6851 + 0.9156 + 0.0000, time: 33.197411]
2023-11-28 16:46:03.538: epoch 16:	0.04129212  	0.08382388  	0.08166629  
2023-11-28 16:46:03.538: Find a better model.
2023-11-28 16:46:36.701: [iter 17 : loss : 1.5947 = 0.6779 + 0.9168 + 0.0000, time: 33.154160]
2023-11-28 16:46:37.302: epoch 17:	0.05407647  	0.10728325  	0.10561398  
2023-11-28 16:46:37.302: Find a better model.
2023-11-28 16:47:10.510: [iter 18 : loss : 1.5810 = 0.6620 + 0.9190 + 0.0000, time: 33.198737]
2023-11-28 16:47:11.134: epoch 18:	0.06611381  	0.12763223  	0.12705037  
2023-11-28 16:47:11.134: Find a better model.
2023-11-28 16:47:44.334: [iter 19 : loss : 1.5525 = 0.6296 + 0.9228 + 0.0000, time: 33.190958]
2023-11-28 16:47:45.014: epoch 19:	0.07469748  	0.14077775  	0.14192922  
2023-11-28 16:47:45.014: Find a better model.
2023-11-28 16:48:18.286: [iter 20 : loss : 1.5067 = 0.5780 + 0.9287 + 0.0000, time: 33.262938]
2023-11-28 16:48:18.920: epoch 20:	0.07923641  	0.14812760  	0.14986730  
2023-11-28 16:48:18.920: Find a better model.
2023-11-28 16:48:52.096: [iter 21 : loss : 1.4499 = 0.5144 + 0.9355 + 0.0000, time: 33.168405]
2023-11-28 16:48:52.699: epoch 21:	0.08209396  	0.15364611  	0.15447897  
2023-11-28 16:48:52.699: Find a better model.
2023-11-28 16:49:25.834: [iter 22 : loss : 1.3924 = 0.4510 + 0.9414 + 0.0000, time: 33.128065]
2023-11-28 16:49:26.443: epoch 22:	0.08393642  	0.15747480  	0.15788051  
2023-11-28 16:49:26.443: Find a better model.
2023-11-28 16:49:59.696: [iter 23 : loss : 1.3414 = 0.3961 + 0.9453 + 0.0000, time: 33.226466]
2023-11-28 16:50:00.337: epoch 23:	0.08535990  	0.16042101  	0.16019407  
2023-11-28 16:50:00.337: Find a better model.
2023-11-28 16:50:33.381: [iter 24 : loss : 1.2977 = 0.3505 + 0.9472 + 0.0000, time: 33.033574]
2023-11-28 16:50:34.054: epoch 24:	0.08631070  	0.16260488  	0.16174880  
2023-11-28 16:50:34.054: Find a better model.
2023-11-28 16:51:07.846: [iter 25 : loss : 1.2612 = 0.3135 + 0.9477 + 0.0000, time: 33.783837]
2023-11-28 16:51:08.504: epoch 25:	0.08688560  	0.16389309  	0.16270179  
2023-11-28 16:51:08.504: Find a better model.
2023-11-28 16:51:42.401: [iter 26 : loss : 1.2301 = 0.2826 + 0.9475 + 0.0000, time: 33.888940]
2023-11-28 16:51:43.053: epoch 26:	0.08717018  	0.16394159  	0.16301750  
2023-11-28 16:51:43.054: Find a better model.
2023-11-28 16:52:17.277: [iter 27 : loss : 1.2039 = 0.2570 + 0.9469 + 0.0000, time: 34.205572]
2023-11-28 16:52:17.943: epoch 27:	0.08737966  	0.16443923  	0.16343896  
2023-11-28 16:52:17.944: Find a better model.
2023-11-28 16:52:51.956: [iter 28 : loss : 1.1818 = 0.2357 + 0.9461 + 0.0000, time: 34.004240]
2023-11-28 16:52:52.622: epoch 28:	0.08756235  	0.16511248  	0.16373126  
2023-11-28 16:52:52.622: Find a better model.
2023-11-28 16:53:26.818: [iter 29 : loss : 1.1629 = 0.2179 + 0.9449 + 0.0000, time: 34.188161]
2023-11-28 16:53:27.551: epoch 29:	0.08744425  	0.16471304  	0.16342038  
2023-11-28 16:54:01.569: [iter 30 : loss : 1.1460 = 0.2022 + 0.9438 + 0.0000, time: 34.008714]
2023-11-28 16:54:02.226: epoch 30:	0.08724540  	0.16431291  	0.16295908  
2023-11-28 16:54:36.302: [iter 31 : loss : 1.1310 = 0.1884 + 0.9426 + 0.0000, time: 34.064784]
2023-11-28 16:54:36.965: epoch 31:	0.08698213  	0.16384155  	0.16241841  
2023-11-28 16:55:11.133: [iter 32 : loss : 1.1187 = 0.1771 + 0.9415 + 0.0000, time: 34.159333]
2023-11-28 16:55:11.803: epoch 32:	0.08680493  	0.16311695  	0.16202685  
2023-11-28 16:55:45.735: [iter 33 : loss : 1.1065 = 0.1659 + 0.9406 + 0.0000, time: 33.918725]
2023-11-28 16:55:46.394: epoch 33:	0.08690701  	0.16268815  	0.16180626  
2023-11-28 16:56:20.756: [iter 34 : loss : 1.0969 = 0.1574 + 0.9395 + 0.0000, time: 34.355021]
2023-11-28 16:56:21.471: epoch 34:	0.08691236  	0.16256064  	0.16191801  
2023-11-28 16:57:03.116: [iter 35 : loss : 1.0871 = 0.1485 + 0.9386 + 0.0000, time: 41.633286]
2023-11-28 16:57:03.952: epoch 35:	0.08669752  	0.16196868  	0.16114096  
2023-11-28 16:57:44.394: [iter 36 : loss : 1.0792 = 0.1415 + 0.9377 + 0.0000, time: 40.434731]
2023-11-28 16:57:45.135: epoch 36:	0.08665995  	0.16152044  	0.16077232  
2023-11-28 16:58:25.228: [iter 37 : loss : 1.0712 = 0.1345 + 0.9368 + 0.0000, time: 40.078457]
2023-11-28 16:58:25.896: epoch 37:	0.08644510  	0.16091344  	0.16015513  
2023-11-28 16:58:33.570: my pid: 68812
2023-11-28 16:58:33.570: model: model.general_recommender.SGL
2023-11-28 16:58:33.570: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 16:58:33.570: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 16:58:43.063: metrics:	Precision@20	Recall@20   	NDCG@20     
2023-11-28 16:59:10.019: [iter 38 : loss : 1.0645 = 0.1284 + 0.9360 + 0.0000, time: 44.116159]
2023-11-28 16:59:10.817: epoch 38:	0.08617116  	0.16035655  	0.15954901  
2023-11-28 16:59:25.957: [iter 1 : loss : 1.6079 = 0.6931 + 0.9148 + 0.0000, time: 42.894016]
2023-11-28 16:59:26.809: epoch 1:	0.00415769  	0.00923240  	0.00767231  
2023-11-28 16:59:26.809: Find a better model.
2023-11-28 16:59:50.582: [iter 39 : loss : 1.0583 = 0.1232 + 0.9352 + 0.0000, time: 39.754327]
2023-11-28 16:59:51.273: epoch 39:	0.08591330  	0.15975673  	0.15901209  
2023-11-28 17:00:09.588: [iter 2 : loss : 1.6054 = 0.6931 + 0.9123 + 0.0000, time: 42.769384]
2023-11-28 17:00:10.275: epoch 2:	0.00574770  	0.01277659  	0.01054179  
2023-11-28 17:00:10.275: Find a better model.
2023-11-28 17:00:31.072: [iter 40 : loss : 1.0531 = 0.1185 + 0.9345 + 0.0000, time: 39.786855]
2023-11-28 17:00:31.949: epoch 40:	0.08578975  	0.15952843  	0.15855211  
2023-11-28 17:00:56.633: [iter 3 : loss : 1.6052 = 0.6930 + 0.9121 + 0.0000, time: 46.346413]
2023-11-28 17:00:57.412: epoch 3:	0.00698856  	0.01503217  	0.01260975  
2023-11-28 17:00:57.412: Find a better model.
2023-11-28 17:01:10.615: [iter 41 : loss : 1.0474 = 0.1136 + 0.9338 + 0.0000, time: 38.656771]
2023-11-28 17:01:11.297: epoch 41:	0.08573065  	0.15905897  	0.15809689  
2023-11-28 17:01:50.421: [iter 4 : loss : 1.6051 = 0.6930 + 0.9122 + 0.0000, time: 52.998508]
2023-11-28 17:01:51.175: epoch 4:	0.00745054  	0.01523722  	0.01356350  
2023-11-28 17:01:51.175: Find a better model.
2023-11-28 17:01:58.255: [iter 42 : loss : 1.0425 = 0.1092 + 0.9333 + 0.0000, time: 46.950374]
2023-11-28 17:01:59.067: epoch 42:	0.08570916  	0.15878749  	0.15769242  
2023-11-28 17:02:53.287: [iter 5 : loss : 1.6051 = 0.6929 + 0.9121 + 0.0000, time: 62.103164]
2023-11-28 17:02:54.045: epoch 5:	0.00921253  	0.01858127  	0.01663651  
2023-11-28 17:02:54.046: Find a better model.
2023-11-28 17:02:55.927: [iter 43 : loss : 1.0374 = 0.1048 + 0.9326 + 0.0000, time: 56.834372]
2023-11-28 17:02:56.703: epoch 43:	0.08540833  	0.15810047  	0.15704623  
2023-11-28 17:03:55.865: [iter 44 : loss : 1.0339 = 0.1017 + 0.9321 + 0.0000, time: 59.148099]
2023-11-28 17:03:56.646: epoch 44:	0.08529015  	0.15742104  	0.15664048  
2023-11-28 17:03:58.192: [iter 6 : loss : 1.6051 = 0.6929 + 0.9122 + 0.0000, time: 64.138243]
2023-11-28 17:03:59.164: epoch 6:	0.00989476  	0.01963661  	0.01772532  
2023-11-28 17:03:59.164: Find a better model.
2023-11-28 17:04:49.257: [iter 45 : loss : 1.0302 = 0.0986 + 0.9316 + 0.0000, time: 52.600265]
2023-11-28 17:04:49.972: epoch 45:	0.08495715  	0.15657379  	0.15602560  
2023-11-28 17:04:55.538: [iter 7 : loss : 1.6052 = 0.6928 + 0.9124 + 0.0000, time: 56.359639]
2023-11-28 17:04:56.238: epoch 7:	0.01049104  	0.02199872  	0.01969354  
2023-11-28 17:04:56.238: Find a better model.
2023-11-28 17:05:38.343: [iter 46 : loss : 1.0262 = 0.0951 + 0.9311 + 0.0000, time: 48.358334]
2023-11-28 17:05:39.135: epoch 46:	0.08470472  	0.15589404  	0.15538569  
2023-11-28 17:05:47.337: [iter 8 : loss : 1.6050 = 0.6927 + 0.9124 + 0.0000, time: 51.085969]
2023-11-28 17:05:48.927: epoch 8:	0.01233897  	0.02444655  	0.02257719  
2023-11-28 17:05:48.927: Find a better model.
2023-11-28 17:06:22.219: [iter 47 : loss : 1.0227 = 0.0921 + 0.9306 + 0.0000, time: 43.072830]
2023-11-28 17:06:22.951: epoch 47:	0.08445230  	0.15530638  	0.15483509  
2023-11-28 17:06:34.829: [iter 9 : loss : 1.6051 = 0.6925 + 0.9126 + 0.0000, time: 45.883982]
2023-11-28 17:06:35.721: epoch 9:	0.01434804  	0.02765008  	0.02591904  
2023-11-28 17:06:35.722: Find a better model.
2023-11-28 17:07:02.614: [iter 48 : loss : 1.0197 = 0.0894 + 0.9302 + 0.0000, time: 39.654369]
2023-11-28 17:07:03.304: epoch 48:	0.08415143  	0.15409163  	0.15406381  
2023-11-28 17:07:17.764: [iter 10 : loss : 1.6050 = 0.6923 + 0.9127 + 0.0000, time: 42.030291]
2023-11-28 17:07:18.667: epoch 10:	0.01543318  	0.03073969  	0.02848000  
2023-11-28 17:07:18.667: Find a better model.
2023-11-28 17:07:43.402: [iter 49 : loss : 1.0166 = 0.0868 + 0.9298 + 0.0000, time: 40.086514]
2023-11-28 17:07:44.037: epoch 49:	0.08387211  	0.15326808  	0.15332146  
2023-11-28 17:08:01.915: [iter 11 : loss : 1.6048 = 0.6921 + 0.9127 + 0.0000, time: 43.234791]
2023-11-28 17:08:02.582: epoch 11:	0.01825878  	0.03704299  	0.03427725  
2023-11-28 17:08:02.582: Find a better model.
2023-11-28 17:08:21.938: [iter 50 : loss : 1.0139 = 0.0845 + 0.9293 + 0.0000, time: 37.893668]
2023-11-28 17:08:22.668: epoch 50:	0.08371099  	0.15242890  	0.15265968  
2023-11-28 17:08:55.376: [iter 12 : loss : 1.6047 = 0.6917 + 0.9130 + 0.0000, time: 52.784842]
2023-11-28 17:08:56.096: epoch 12:	0.02120262  	0.04320225  	0.04001394  
2023-11-28 17:08:56.096: Find a better model.
2023-11-28 17:09:06.911: [iter 51 : loss : 1.0112 = 0.0821 + 0.9291 + 0.0000, time: 44.232393]
2023-11-28 17:09:08.159: epoch 51:	0.08362509  	0.15198925  	0.15221703  
2023-11-28 17:09:58.884: [iter 13 : loss : 1.6043 = 0.6911 + 0.9133 + 0.0000, time: 62.779741]
2023-11-28 17:09:59.637: epoch 13:	0.02521003  	0.05080095  	0.04774493  
2023-11-28 17:09:59.637: Find a better model.
2023-11-28 17:10:03.545: [iter 52 : loss : 1.0092 = 0.0804 + 0.9288 + 0.0000, time: 55.303706]
2023-11-28 17:10:04.250: epoch 52:	0.08325449  	0.15110397  	0.15153916  
2023-11-28 17:11:03.246: [iter 53 : loss : 1.0062 = 0.0779 + 0.9283 + 0.0000, time: 58.987833]
2023-11-28 17:11:04.102: epoch 53:	0.08320075  	0.15033790  	0.15090325  
2023-11-28 17:11:04.102: Early stopping is trigger at epoch: 53
2023-11-28 17:11:04.103: best_result@epoch 28:

2023-11-28 17:11:04.103: 		0.0876      	0.1651      	0.1637      
2023-11-28 17:11:05.315: [iter 14 : loss : 1.6037 = 0.6900 + 0.9136 + 0.0000, time: 65.665792]
2023-11-28 17:11:06.163: epoch 14:	0.03073728  	0.06201936  	0.05840775  
2023-11-28 17:11:06.163: Find a better model.
2023-11-28 17:11:46.987: [iter 15 : loss : 1.6023 = 0.6882 + 0.9141 + 0.0000, time: 40.807147]
2023-11-28 17:11:47.673: epoch 15:	0.03841298  	0.07695358  	0.07345505  
2023-11-28 17:11:47.673: Find a better model.
2023-11-28 17:12:29.813: [iter 16 : loss : 1.5994 = 0.6845 + 0.9149 + 0.0000, time: 42.130285]
2023-11-28 17:12:30.467: epoch 16:	0.04804410  	0.09456962  	0.09285519  
2023-11-28 17:12:30.467: Find a better model.
2023-11-28 17:13:12.447: [iter 17 : loss : 1.5927 = 0.6764 + 0.9162 + 0.0000, time: 41.953369]
2023-11-28 17:13:13.093: epoch 17:	0.05856163  	0.11297449  	0.11319787  
2023-11-28 17:13:13.094: Find a better model.
2023-11-28 17:13:59.470: [iter 18 : loss : 1.5776 = 0.6590 + 0.9186 + 0.0000, time: 46.369061]
2023-11-28 17:14:00.105: epoch 18:	0.06804226  	0.12890808  	0.13051680  
2023-11-28 17:14:00.105: Find a better model.
2023-11-28 17:14:40.590: [iter 19 : loss : 1.5482 = 0.6259 + 0.9223 + 0.0000, time: 40.478421]
2023-11-28 17:14:41.198: epoch 19:	0.07506815  	0.14096291  	0.14274468  
2023-11-28 17:14:41.198: Find a better model.
2023-11-28 17:15:24.047: [iter 20 : loss : 1.5033 = 0.5757 + 0.9276 + 0.0000, time: 42.841753]
2023-11-28 17:15:24.714: epoch 20:	0.07904313  	0.14806528  	0.14954560  
2023-11-28 17:15:24.714: Find a better model.
2023-11-28 17:16:05.438: [iter 21 : loss : 1.4488 = 0.5154 + 0.9334 + 0.0000, time: 40.716586]
2023-11-28 17:16:06.161: epoch 21:	0.08164285  	0.15274034  	0.15435137  
2023-11-28 17:16:06.162: Find a better model.
2023-11-28 17:16:47.736: [iter 22 : loss : 1.3933 = 0.4549 + 0.9384 + 0.0000, time: 41.557003]
2023-11-28 17:16:48.438: epoch 22:	0.08320580  	0.15572239  	0.15706210  
2023-11-28 17:16:48.438: Find a better model.
2023-11-28 17:17:29.808: [iter 23 : loss : 1.3432 = 0.4013 + 0.9419 + 0.0000, time: 41.358606]
2023-11-28 17:17:30.410: epoch 23:	0.08447360  	0.15850401  	0.15937123  
2023-11-28 17:17:30.410: Find a better model.
2023-11-28 17:18:11.053: [iter 24 : loss : 1.2994 = 0.3555 + 0.9439 + 0.0000, time: 40.634304]
2023-11-28 17:18:11.703: epoch 24:	0.08540831  	0.16047487  	0.16092846  
2023-11-28 17:18:11.703: Find a better model.
2023-11-28 17:18:53.361: [iter 25 : loss : 1.2630 = 0.3183 + 0.9447 + 0.0000, time: 41.650192]
2023-11-28 17:18:54.053: epoch 25:	0.08628383  	0.16194153  	0.16237031  
2023-11-28 17:18:54.053: Find a better model.
2023-11-28 17:19:38.277: [iter 26 : loss : 1.2313 = 0.2865 + 0.9448 + 0.0000, time: 44.214341]
2023-11-28 17:19:39.013: epoch 26:	0.08653097  	0.16237406  	0.16264662  
2023-11-28 17:19:39.013: Find a better model.
2023-11-28 17:20:20.470: [iter 27 : loss : 1.2045 = 0.2602 + 0.9443 + 0.0000, time: 41.446764]
2023-11-28 17:20:21.118: epoch 27:	0.08676191  	0.16330923  	0.16292863  
2023-11-28 17:20:21.119: Find a better model.
2023-11-28 17:21:02.077: [iter 28 : loss : 1.1816 = 0.2379 + 0.9437 + 0.0000, time: 40.948822]
2023-11-28 17:21:02.812: epoch 28:	0.08698758  	0.16312928  	0.16312122  
2023-11-28 17:21:49.202: [iter 29 : loss : 1.1627 = 0.2199 + 0.9428 + 0.0000, time: 46.380162]
2023-11-28 17:21:50.004: epoch 29:	0.08728833  	0.16391742  	0.16322091  
2023-11-28 17:21:50.004: Find a better model.
2023-11-28 17:22:34.777: [iter 30 : loss : 1.1452 = 0.2034 + 0.9418 + 0.0000, time: 44.758021]
2023-11-28 17:22:35.444: epoch 30:	0.08738501  	0.16442488  	0.16317759  
2023-11-28 17:22:35.444: Find a better model.
2023-11-28 17:22:49.634: my pid: 70748
2023-11-28 17:22:49.634: model: model.general_recommender.SGL
2023-11-28 17:22:49.634: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 17:22:49.634: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 17:23:19.264: [iter 31 : loss : 1.1299 = 0.1892 + 0.9408 + 0.0000, time: 43.805991]
2023-11-28 17:23:19.902: epoch 31:	0.08744941  	0.16445403  	0.16285878  
2023-11-28 17:23:19.902: Find a better model.
2023-11-28 17:24:00.995: my pid: 67564
2023-11-28 17:24:00.995: model: model.general_recommender.SGL
2023-11-28 17:24:00.995: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 17:24:00.995: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 17:24:02.422: [iter 32 : loss : 1.1173 = 0.1775 + 0.9398 + 0.0000, time: 42.511278]
2023-11-28 17:24:03.203: epoch 32:	0.08742798  	0.16406153  	0.16266033  
2023-11-28 17:24:45.430: [iter 33 : loss : 1.1053 = 0.1663 + 0.9389 + 0.0000, time: 42.214223]
2023-11-28 17:24:46.076: epoch 33:	0.08726680  	0.16314003  	0.16210683  
2023-11-28 17:25:27.486: [iter 34 : loss : 1.0952 = 0.1573 + 0.9380 + 0.0000, time: 41.400669]
2023-11-28 17:25:28.105: epoch 34:	0.08699279  	0.16242462  	0.16165696  
2023-11-28 17:26:08.826: [iter 35 : loss : 1.0858 = 0.1486 + 0.9372 + 0.0000, time: 40.712976]
2023-11-28 17:26:09.488: epoch 35:	0.08702498  	0.16255698  	0.16131783  
2023-11-28 17:26:50.230: [iter 36 : loss : 1.0776 = 0.1413 + 0.9363 + 0.0000, time: 40.732955]
2023-11-28 17:26:50.896: epoch 36:	0.08669741  	0.16202705  	0.16077672  
2023-11-28 17:27:20.992: my pid: 71208
2023-11-28 17:27:20.992: model: model.general_recommender.SGL
2023-11-28 17:27:20.992: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 17:27:20.992: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 17:27:32.774: [iter 37 : loss : 1.0696 = 0.1341 + 0.9354 + 0.0000, time: 41.871328]
2023-11-28 17:27:33.419: epoch 37:	0.08669204  	0.16161576  	0.16046716  
2023-11-28 17:28:14.995: [iter 38 : loss : 1.0629 = 0.1282 + 0.9347 + 0.0000, time: 41.565010]
2023-11-28 17:28:16.141: epoch 38:	0.08665445  	0.16129753  	0.16023102  
2023-11-28 17:28:57.804: [iter 39 : loss : 1.0566 = 0.1227 + 0.9339 + 0.0000, time: 41.654038]
2023-11-28 17:28:58.454: epoch 39:	0.08649327  	0.16102472  	0.15978612  
2023-11-28 17:29:39.756: [iter 40 : loss : 1.0512 = 0.1179 + 0.9333 + 0.0000, time: 41.292742]
2023-11-28 17:29:40.408: epoch 40:	0.08612809  	0.16003248  	0.15902904  
2023-11-28 17:30:13.525: my pid: 32124
2023-11-28 17:30:13.525: model: model.general_recommender.SGL
2023-11-28 17:30:13.526: Dataset statistics:
Name: Douban_polluted
The number of users: 9308
The number of items: 15471
The number of ratings: 727931
Average actions of users: 78.20
Average actions of items: 47.05
The sparsity of the dataset: 99.494507%

The number of training: 595175
The number of validation: 0
The number of testing: 132756
2023-11-28 17:30:13.526: NeuRec:[NeuRec]:
recommender=SGL
dataset=Douban_polluted
file_column=UI
sep=','
gpu_id=0
gpu_mem=0.99
metric=["Precision", "Recall", "NDCG"]
top_k=[20]
test_thread=8
test_batch_size=128
seed=2021
start_testing_epoch=0

SGL:[hyperparameters]:
aug_type=ED
reg=0 # 1e-3
embed_size=64
n_layers=3
ssl_reg=0.1
ssl_ratio=0.5
ssl_temp=0.2
ssl_mode=both_side
lr=0.001
learner=adam
adj_type=pre
epochs=1000
batch_size=2048
num_negatives=1
param_init=xavier_uniform
stddev=0.01
verbose=1
stop_cnt=25
pretrain_flag=0
save_flag=0
2023-11-28 17:30:23.824: [iter 41 : loss : 1.0455 = 0.1129 + 0.9326 + 0.0000, time: 43.408767]
2023-11-28 17:30:24.434: epoch 41:	0.08592928  	0.15944380  	0.15845282  
2023-11-28 17:31:06.105: [iter 42 : loss : 1.0408 = 0.1087 + 0.9321 + 0.0000, time: 41.662625]
2023-11-28 17:31:06.892: epoch 42:	0.08576811  	0.15850691  	0.15789108  
2023-11-28 17:31:52.231: [iter 43 : loss : 1.0358 = 0.1043 + 0.9315 + 0.0000, time: 45.327354]
2023-11-28 17:31:52.973: epoch 43:	0.08556942  	0.15746437  	0.15715376  
2023-11-28 17:32:46.680: [iter 44 : loss : 1.0320 = 0.1009 + 0.9310 + 0.0000, time: 53.700378]
2023-11-28 17:32:47.295: epoch 44:	0.08525252  	0.15689005  	0.15658495  
2023-11-28 17:33:34.816: [iter 45 : loss : 1.0283 = 0.0979 + 0.9304 + 0.0000, time: 47.512708]
2023-11-28 17:33:35.776: epoch 45:	0.08509146  	0.15631430  	0.15623425  
2023-11-28 17:34:28.011: [iter 46 : loss : 1.0247 = 0.0946 + 0.9301 + 0.0000, time: 52.200107]
2023-11-28 17:34:28.856: epoch 46:	0.08492493  	0.15571328  	0.15576909  
2023-11-28 17:35:24.663: [iter 47 : loss : 1.0211 = 0.0915 + 0.9295 + 0.0000, time: 55.798560]
2023-11-28 17:35:25.345: epoch 47:	0.08461338  	0.15464848  	0.15499957  
2023-11-28 17:36:24.125: [iter 48 : loss : 1.0180 = 0.0889 + 0.9292 + 0.0000, time: 58.767737]
2023-11-28 17:36:24.927: epoch 48:	0.08438240  	0.15372655  	0.15438062  
2023-11-28 17:37:23.917: [iter 49 : loss : 1.0150 = 0.0862 + 0.9287 + 0.0000, time: 58.982291]
2023-11-28 17:37:25.126: epoch 49:	0.08417290  	0.15294972  	0.15369645  
2023-11-28 17:38:24.662: [iter 50 : loss : 1.0119 = 0.0836 + 0.9284 + 0.0000, time: 59.518948]
2023-11-28 17:38:25.346: epoch 50:	0.08394729  	0.15229385  	0.15318863  
